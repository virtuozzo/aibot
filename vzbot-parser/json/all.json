[
    {
        "title": "Managing infrastructure networks",
        "content": "Managing infrastructure networks\nIn Virtuozzo Hybrid Infrastructure, you can manage infrastructure networks and assign different types of traffic to them. In addition, you can change nodes' IP addresses and network configuration if the cluster is moved to another location or the network topology needs to be modified.\nPrerequisites\n\nYour infrastructure networks are set up, as described in Setting up networks.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-infrastructure-networks.html"
    },
    {
        "title": "Monitoring object storage",
        "content": "Monitoring object storage\nYou can monitor the S3 cluster and its components on the Storage services > S3 > Overview screen with the following charts:\n\nAvailability of NS, OS, and GW services. If an S3 GW service has the \u00e2\u0080\u009cfailed\u00e2\u0080\u009d status, most probably the node hosting it is down. It is not critical for the S3 cluster: high availability of the S3 service is based on the DNS records. If the DNS records are properly configured, the S3 service remains fully accessible via S3 clients. On the other hand, if an OS or NS service fails, it is critical: the whole S3 cluster cannot operate normally. If you see that some of the NS or OS services are offline, but all of the cluster nodes are healthy, and the network with the OSTOR private traffic type is working well, contact the technical support team. You can also refer to the Grafana dashboards to find out the failure causes.\nOperation rate. The chart shows the overall cluster load by S3 users\u00e2\u0080\u0099 requests, including all operation types.\nRequest failure rate. The requests are generated by users or their applications. Some requests cannot be processed: for example, they may request nonexistent objects, or mismatch the access rights, or use unsupported features (refer to Supported Amazon S3 features). So, it is normal if the error rate makes up a small proportion of the total operations rate. However, it can also indicate that the S3 application used for access is not working properly. In addition, if the S3 cluster is open for public access, it might be scanned by Internet crawlers. In this case, the error spikes would reflect all the issues with their mismatching access rights. It is not a critical issue for the cluster though.\nBandwidth. The chart shows the overall cluster load by the S3 users\u00e2\u0080\u0099 requests.\nPUT latency and GET latency. These values are measured from the time the last byte of the user request was received until the time the first byte of the response was sent.\n\nAdvanced S3 monitoring via Grafana\nFor advanced monitoring of the S3 cluster, go to the Storage services > S3 > Overview screen, and then click Grafana dashboard. A separate browser tab will open with preconfigured Grafana dashboards. To see a detailed description for each chart, click the i icon in its left corner.\nFor the detailed monitoring of the OS and NS services, use the Object Storage overview, Object Storage OS details, and Object Storage NS details dashboards. Filter the data by nodes or volumes to detect the ones with abnormal service usage. Note the Task delays chart: it shows the proportion of time wasted on waiting for CPU, for available memory (reclaim), for memory transfer from swap (swap in), and for I/O completion.\nThe S3 overview dashboard shows primarily the S3 GW service information. Here, you can monitor the object storage and S3 interface with the following charts:\n\nS3 gateways availability, NS services availability, and OS services availability. The charts show the information on the corresponding S3 services. Time periods when the services are unavailable are highlighted in red.\nGET latency and PUT latency. The charts show the average latency and 95th, 99th, and max latency percentiles of S3 GET and PUT requests. This value is measured from the time the last byte of the request was received until the time the first byte of the response was sent.\nBandwidth. The chart shows the total amount of read or write operations passing through all S3 gateways per second.\nOperation rates. The chart shows the total number of GET, PUT, LIST, and DELETE S3 operations per second across all S3 gateways.\n\nThe S3 geo-replication overview dashboard is intended for monitoring data replicated in multiple geographically distributed datacenters:\n\nReplication backlog and Replication queue depth are the most important charts here. If the values are growing constantly, the replication efficiency is falling. It means that the cluster receives more data than it sends.\nLocal S3 error rate and Remote S3 error rate help locate connection problems. A small number of errors is possible if the clusters are replicated over the Internet with unstable latency.\n\nSee also\n\nManaging object storage\n\nObject storage metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-object-storage.html"
    },
    {
        "title": "Listing virtual networks",
        "content": "Listing virtual networksGET /v2.0/networks\r\n\nList networks to which the project has access.\nDefault policy settings return only networks that the project who submits the\r\nrequest owns, unless an administrative user submits the request. In addition,\r\nnetworks shared with the project who submits the request are also returned.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-networks-detail#list-networks\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nadmin_state_up (Optional)\nquery\nboolean\nFilter the list result by the administrative state of the resource,\r\nwhich is up (true) or down (false).\n\nid (Optional)\nquery\nstring\nFilter the list result by the ID of the resource.\n\nmtu (Optional)\nquery\ninteger\nFilter the network list result by the maximum transmission unit (MTU)\r\nvalue to address fragmentation. Minimum value is 68 for IPv4,\r\nand 1280 for IPv6.\n\nname (Optional)\nquery\nstring\nFilter the list result by the human-readable name of the resource.\n\nproject_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\nprovider:network_type (Optional)\nquery\nstring\nFilter the list result by the type of physical network that this\r\nnetwork/segment is mapped to. For example, flat, vlan, vxlan,\r\nor gre. Valid values depend on a networking back-end.\n\nprovider:physical_network (Optional)\nquery\nstring\nFilter the list result by the physical network where\r\nthis network/segment is implemented.\n\nprovider:segmentation_id (Optional)\nquery\ninteger\nFilter the list result by the ID of the isolated segment\r\non the physical network.\n\nrevision_number (Optional)\nquery\ninteger\nFilter the list result by the revision number of the network.\n\nrouter:external (Optional)\nquery\nboolean\nFilter the network list result based on whether the network has an\r\nexternal routing facility that\u00e2\u0080\u0099s not managed by the networking service.\n\nshared (Optional)\nquery\nboolean\nFilter the network list result based on if the network is shared across\r\nall tenants.\n\nstatus (Optional)\nquery\nstring\nFilter the network list result by network status. Values are ACTIVE,\r\nDOWN, BUILD or ERROR.\n\ntenant_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\nvlan_transparent (Optional)\nquery\nboolean\nFilter the network list by the VLAN transparency mode of the network,\r\nwhich is VLAN transparent (true) or not VLAN transparent (false).\n\ndescription (Optional)\nquery\nstring\nFilter the list result by the human-readable description of the resource.\n\nis_default (Optional)\nquery\nboolean\nFilter the network list result based on if the network is default pool\r\nor not.\n\ntags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be returned.\r\nTags in query must be separated by comma.\n\ntags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be returned.\r\nTags in query must be separated by comma.\n\nnot-tags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be excluded.\r\nTags in query must be separated by comma.\n\nnot-tags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be excluded.\r\nTags in query must be separated by comma.\n\nsort_dir (Optional)\nquery\nstring\nSort direction. A valid value is asc (ascending) or desc\r\n(descending). You can specify multiple pairs of sort key and\r\nsort direction query parameters.\n\nsort_key (Optional)\nquery\nstring\n\nSorts by a network attribute. You can specify multiple pairs of sort key\r\nand sort direction query parameters. The sort keys are limited to:\n\nadmin_state_up\n\navailability_zone_hints\n\nid\n\nmtu\n\nname\n\nstatus\n\ntenant_id\n\nproject_id\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/networks\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nnetworks\n\nbody\narray\nA list of network objects.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the network, which is\r\nup (true) or down (false).\n\navailability_zone_hints\n\nbody\narray\nThe availability zone candidate for the network.\n\navailability_zones\n\nbody\narray\nThe availability zone for the network.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\nid\n\nbody\nstring\nThe ID of the network.\n\nipv4_address_scope\n\nbody\nstring\nThe ID of the IPv4 address scope that the network is associated with.\n\nipv6_address_scope\n\nbody\nstring\nThe ID of the IPv6 address scope that the network is associated with.\n\nl2_adjacency\n\nbody\nboolean\nIndicates whether L2 connectivity is available throughout\r\nthe network.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to\r\naddress fragmentation. Minimum value is 68 for IPv4, and 1280 for\r\nIPv6.\n\nname\n\nbody\nstring\nHuman-readable name of the network.\n\nport_security_enabled\n\nbody\nboolean\nThe port security status of the network. Valid values are\r\nenabled (true) and disabled (false).\r\nThis value is used as the default value of port_security_enabled\r\nfield of a newly created port.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nprovider:network_type\n\nbody\nstring\nThe type of physical network that this network is mapped to.\r\nFor example, flat, vlan, vxlan, or gre.\r\nValid values depend on a networking back-end.\n\nprovider:physical_network\n\nbody\nstring\nThe physical network where this network/segment is implemented.\n\nprovider:segmentation_id\n\nbody\ninteger\nThe ID of the isolated segment on the physical network.\r\nThe network_type attribute defines the segmentation model.\r\nFor example, if the network_type value is vlan, this ID is a vlan\r\nidentifier. If the network_type value is gre, this ID is a gre key.\n\nqos_policy_id\n\nbody\nstring\nThe ID of the QoS policy associated with the network.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the network.\n\nrouter:external\n\nbody\nboolean\nIndicates whether the network has an external routing facility that\u00e2\u0080\u0099s not\r\nmanaged by the networking service. If the network is updated from external\r\nto internal the unused floating IPs of this network are automatically\r\ndeleted when extension floatingip-autodelete-internal is present.\n\nsegments\n\nbody\narray\nA list of provider segment objects.\n\nshared\n\nbody\nboolean\nIndicates whether this network is shared across all tenants. By default,\r\nonly administrative users can change this value.\n\nstatus\n\nbody\nstring\nThe network status. Values are ACTIVE, DOWN, BUILD or ERROR.\n\nsubnets\n\nbody\narray\nThe associated subnets.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvlan_transparent\n\nbody\nboolean\nIndicates the VLAN transparency mode of the network, which is\r\nVLAN transparent (true) or not VLAN transparent (false).\n\ndefault_vnic_type\n\nbody\nstring\nThe default value of the vnic_type parameter for each virtual port created in this network.\n\ndescription\n\nbody\nstring\nA human-readable description for the network.\n\nis_default\n\nbody\nboolean\nThe network is default pool or not.\n\ntags\n\nbody\narray\nThe list of tags on the network.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"networks\": [\r\n    {\r\n      \"provider:physical_network\": \"Public\",\r\n      \"ipv6_address_scope\": null,\r\n      \"revision_number\": 2,\r\n      \"port_security_enabled\": true,\r\n      \"mtu\": 1500,\r\n      \"id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n      \"router:external\": true,\r\n      \"availability_zone_hints\": [],\r\n      \"availability_zones\": [\r\n        \"nova\"\r\n      ],\r\n      \"ipv4_address_scope\": null,\r\n      \"shared\": true,\r\n      \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"status\": \"ACTIVE\",\r\n      \"subnets\": [\r\n        \"351884c7-ee37-4a7d-9dcb-4cff4a1bba27\"\r\n      ],\r\n      \"description\": \"\",\r\n      \"tags\": [],\r\n      \"updated_at\": \"2020-02-17T11:58:16Z\",\r\n      \"is_default\": false,\r\n      \"provider:segmentation_id\": null,\r\n      \"name\": \"pubnet1\",\r\n      \"admin_state_up\": true,\r\n      \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"created_at\": \"2020-02-17T11:58:15Z\",\r\n      \"provider:network_type\": \"flat\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-virtual-networks.html"
    },
    {
        "title": "Uploading image data",
        "content": "Uploading image dataPUT /v2/images/{image_id}/file\r\n\nUpload a binary image file to an image record created, according to Creating image records.\nBefore you can store binary image data, you must meet the following\r\npreconditions:\n\nThe image must exist.\nYou must set the disk and container formats in the image.\nThe image status must be queued.\nYour image storage quota must be sufficient.\nThe size of the data that you want to store must not exceed the\r\nsize that the OpenStack Image service allows.\n\nAfter the operation completes, the image status will change to active.\nSource: https://docs.openstack.org/api-ref/image/v2/index.html?expanded=upload-binary-image-data-detail#upload-binary-image-data\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nContent-Type\n\nheader\nstring\nThe media type descriptor for the request body.  Use\r\napplication/openstack-images-v2.1-json-patch.  (You can also use\r\napplication/openstack-images-v2.0-json-patch, but keep in mind that\r\nit\u00e2\u0080\u0099s deprecated.)\n\nX-Image-Meta-Store (Optional)\nheader\nstring\n\nA store identifier to upload or import image data.  Should only be included\r\nwhen making a request to a cloud that supports multiple backing stores. Use\r\nthe store discovery call to determine an appropriate store identifier. \r\nSimply omit this header to use the default store.\nNew in version 2.8\n\nimage_id\n\npath\nstring\nThe UUID of the image.\n\nExample\nSet the Content-Type request header to application/octet-stream.# curl -ks -X PUT -H 'Content-Type: application/octet-stream' -H 'X-Auth-Token: gAAAAA<...>' \\\r\n--data-binary @cirros2.qcow2 \\\r\nhttps://<node_IP_addr>:9292/v2/images/8988013f-9079-4f7d-855f-d2cb67e9d71c/file\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n410 - Gone\n\nThe access request to the target resource is no longer available.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n415 - Unsupported Media Type\n\nThe request entity has a media type which the server or resource does not support.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/uploading-image-data.html"
    },
    {
        "title": "Creating virtual machines with different vGPU types",
        "content": "Creating virtual machines with different vGPU types\nIf you want to use multiple vGPU types in the compute cluster, you need to manually create CUSTOM_NVIDIA_XXX traits and assign them to corresponding vGPU resource providers first. Then, you can proceed to create flavors and virtual machines with the assigned traits.\nLimitations\n\nVirtual machines with attached vGPUs cannot be suspended and live migrated.\n\nThe default QLX driver for the VNC console and the NVIDIA GPU driver are incompatible\n\nAfter installing the NVIDIA GPU driver inside a virtual machine with an attached vGPU, the VNC console stops working. You can use RDP for a remote connection. Alternatively, for templates that already have the NVIDIA GPU driver installed, you can set the hw_use_vgpu_display property, to disable the integrated QLX driver. For example:# openstack --insecure image set --property hw_use_vgpu_display 007db63f-9b41-4918-b572-2c5eef4c8f4b\n\nPrerequisites\n\nThe compute cluster is reconfigured for vGPU support, as described in Enabling PCI passthrough and vGPU support.\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo configure multiple vGPU types for the compute cluster\n\nList resource providers in the compute cluster to obtain their IDs. For example:# openstack --insecure resource provider list\r\n+--------------------------------------+-----------------------------------------+------------+--------------------+----------------------+\r\n| uuid                                 | name                                    | generation | root_provider_uuid | parent_provider_uuid |\r\n+--------------------------------------+-----------------------------------------+------------+--------------------+----------------------+\r\n| 7d2ef259-42df-4ef8-8eaa-66c3b7448fc3 | node001.vstoragedomain_pci_0000_85_00_0 |         62 | 1f08c319-f270-<\u00e2\u0080\u00a6>  | 1f08c319-f270-<\u00e2\u0080\u00a6>    |\r\n| 94a84fc6-2f28-46d5-93e1-e588e347dd3b | node001.vstoragedomain_pci_0000_10_00_0 |         38 | 1f08c319-f270-<\u00e2\u0080\u00a6>  | 1f08c319-f270-<\u00e2\u0080\u00a6>    |\r\n| 41c177e3-6998-4e56-8d29-f98f72fef910 | node002.vstoragedomain_pci_0000_85_00_0 |         13 | 9dbc8c64-0048-<\u00e2\u0080\u00a6>  | 9dbc8c64-0048-<\u00e2\u0080\u00a6>    |\r\n| 7fd1d10f-9ceb-4cd1-acec-a1254755211b | node002.vstoragedomain_pci_0000_10_00_0 |         13 | 9dbc8c64-0048-<\u00e2\u0080\u00a6>  | 9dbc8c64-0048-<\u00e2\u0080\u00a6>    |\r\n+--------------------------------------+-----------------------------------------+------------+--------------------+----------------------+\n\nCreate custom traits that correspond to different GPU types. For example, to create the traits CUSTOM_NVIDIA_231 and CUSTOM_NVIDIA_232, run:# openstack --insecure trait create CUSTOM_NVIDIA_231\r\n# openstack --insecure trait create CUSTOM_NVIDIA_232\n\nAdd the corresponding trait to the resource provider matching the GPU. For example:# openstack --insecure resource provider trait set --trait CUSTOM_NVIDIA_231 7d2ef259-42df-4ef8-8eaa-66c3b7448fc3\r\n+-------------------+\r\n| name              |\r\n+-------------------+\r\n| CUSTOM_NVIDIA_231 |\r\n+-------------------+\r\n# openstack --insecure resource provider trait set --trait CUSTOM_NVIDIA_231 94a84fc6-2f28-46d5-93e1-e588e347dd3b\r\n+-------------------+\r\n| name              |\r\n+-------------------+\r\n| CUSTOM_NVIDIA_231 |\r\n+-------------------+\nNow, the trait CUSTOM_NVIDIA_231 is assigned to the vGPU resource providers of the node node001. To assign the trait CUSTOM_NVIDIA_232 to the vGPU resource providers of the node node002, run:# openstack --insecure resource provider trait set --trait CUSTOM_NVIDIA_232 41c177e3-6998-4e56-8d29-f98f72fef910\r\n+-------------------+\r\n| name              |\r\n+-------------------+\r\n| CUSTOM_NVIDIA_232 |\r\n+-------------------+\r\n# openstack --insecure resource provider trait set --trait CUSTOM_NVIDIA_232 7fd1d10f-9ceb-4cd1-acec-a1254755211b\r\n+-------------------+\r\n| name              |\r\n+-------------------+\r\n| CUSTOM_NVIDIA_232 |\r\n+-------------------+\n\nTo create virtual machines with different vGPU types\n\nCreate flavors with the resources property specifying the number of vGPUs to use. For example, to create the vgpu231-flavor flavor with 2 vCPUs and 4 GiB of RAM and the vgpu232-flavor flavor with 4 vCPUs and 8 GiB of RAM, run:# openstack --insecure flavor create --ram 4096 --vcpus 2 --property resources:VGPU=1 --public vgpu231-flavor\r\n# openstack --insecure flavor create --ram 8192 --vcpus 4 --property resources:VGPU=1 --public vgpu232-flavor\n\nAdd the requested traits to your flavors. For example, to add the traits CUSTOM_NVIDIA_231 and CUSTOM_NVIDIA_232 to the flavors vgpu231-flavor and vgpu232-flavor, run:# openstack --insecure flavor set --property trait:CUSTOM_NVIDIA_231=required vgpu231-flavor\r\n# openstack --insecure flavor set --property trait:CUSTOM_NVIDIA_232=required vgpu232-flavor\n\nCreate virtual machines specifying the prepared flavors. For example, to create the vm vgpu231-vm with the vgpu231-flavor flavor and the vol1 volume, and the vm vgpu232-vm with the vgpu232-flavor flavor and the vol2 volume, run:# openstack --insecure server create --volume vol1 --flavor vgpu231-flavor vgpu231-vm\r\n# openstack --insecure server create --volume vol2 --flavor vgpu232-flavor vgpu232-vm\n\nThe created virtual machines will have virtual GPUs of different types that are configured in the compute cluster.\nSee also\n\nCreating virtual machines with virtual GPUs\n\nCreating virtual machines with physical GPUs\n\nCreating virtual machines with SR-IOV network ports\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtual-machines-with-different-vgpu-types.html"
    },
    {
        "title": "Accessing S3 storage with CyberDuck",
        "content": "Accessing S3 storage with CyberDuck\nTo access Virtuozzo Hybrid Infrastructure with CyberDuck, do the following:\n\nIn CyberDuck, click Open Connection.\n\nSpecify your credentials:\n\nThe DNS name of the S3 endpoint.\nThe Access Key ID and the Password, the secret access key of an object storage user.\n\nBy default, the connection is established over HTTPS. To use CyberDuck over HTTP, you must install a special S3 profile.\n\nOnce the connection is established, click File > New Folder to create a bucket.\n\nSpecify a name for the new bucket, and then click Create. Use bucket names that comply with DNS naming conventions. For more information on bucket naming, refer to S3 bucket and key naming policies.\n\nThe new bucket will appear in CyberDuck. You can manage it and its contents.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/accessing-s3-storage-with-cyberduck.html"
    },
    {
        "title": "Enabling and disabling RAM overcommitment",
        "content": "Enabling and disabling RAM overcommitment\nRAM overcommitment for virtual machines is only available if a compute node has enough swap space. If you want to enable RAM overcommitment for the entire compute cluster, ensure that enough swap space exists on all of the compute nodes.\nPrerequisites\n\nA swap file is created, as described in Adding swap space.\n\nTo enable RAM overcommitment per cluster\nUse the command vinfra service compute set with the --nova-compute-ram-allocation-ratio option. For example, to set the RAM overcommitment ratio to 1.5, run:# vinfra service compute set --nova-compute-ram-allocation-ratio 1.5\nTo check that the ratio is successfully modified, execute the vinfra service compute show command:# vinfra service compute show\r\n+--------------+-------------------------------------------+\r\n| Field        | Value                                     |\r\n+--------------+-------------------------------------------+\r\n| <...>        | <...>                                     |\r\n| options      | cpu_model: ''                             |\r\n|              | custom_params:                            |\r\n|              | - config_file: nova.conf                  |\r\n|              |   property: ram_allocation_ratio          |\r\n|              |   section: DEFAULT                        |\r\n|              |   service_name: nova-compute              |\r\n|              |   value: 1.5                              |\r\n| <...>        | <...>                                     |\r\n+--------------+-------------------------------------------+\r\n\nTo enable RAM overcommitment per node\nUse the command vinfra service compute set with the --nova-compute-ram-allocation-ratio option and specify particular nodes with the --nodes option. For example, to set the RAM overcommitment ratio to 1.5 on the node node001, run:# vinfra service compute set --nova-compute-ram-allocation-ratio 1.5 --nodes node001\nTo check that the ratio is successfully modified, execute the vinfra service compute node show command:# vinfra service compute node show node001\r\n+----------------+------------------------------------------+\r\n| Field          | Value                                    |\r\n+----------------+------------------------------------------+\r\n| custom_params  | - config_file: nova.conf                 |\r\n|                |   property: ram_allocation_ratio         |\r\n|                |   section: DEFAULT                       |\r\n|                |   service_name: nova-compute             |\r\n|                |   value: 1.5                             |\r\n| fenced_reason  |                                          |\r\n| host           | node001.vstoragedomain                   |\r\n| <...>          | <...>                                    |\r\n+----------------+------------------------------------------+\nTo disable RAM overcommitment per cluster\nChange the ratio to 1 by running:# vinfra service compute set --nova-compute-ram-allocation-ratio 1\nIn this case, the swap space is not required anymore and the swap file can be removed. Run this script on each node in the compute cluster to remove the swap file from all of the compute nodes:# /usr/libexec/vstorage-ui-agent/bin/configure-swap.sh --remove-all\nTo disable RAM overcommitment per node\nChange the node overcommitment ratio to the default cluster value by setting it to 0:# vinfra service compute set --nova-compute-ram-allocation-ratio 0 --node node001\nIn this case, the swap space is not required anymore and the swap file can be removed. Run this script on the required node to remove the swap file from it:# /usr/libexec/vstorage-ui-agent/bin/configure-swap.sh --remove-all\nSee also\n\nChanging virtual CPU overcommitment\n\nChanging parameters in OpenStack configuration files",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-and-disabling-ram-overcommitment.html"
    },
    {
        "title": "GET service ostor-buckets",
        "content": "GET service ostor-buckets\nDescription\nLists information on all buckets or the buckets of the user specified by either email or ID.\nRequests\nSyntaxGET /?ostor-buckets HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-buckets&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-buckets&id=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nGET service ostor-buckets parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nNo*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nNo*\n\n* Only one of the required parameters can be set in a single request.\nIf neither emailAddress nor id are set, the response is the list of all buckets, otherwise the response is the bucket list of the user with the specified email or ID.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nA JSON dictionary with a bucket list in the following format:{\r\n\"Buckets\": [\r\n{\r\n     \"name\": <name>,\r\n     \"epoch\": <epoch>,\r\n     \"creation_date\": <date>,\r\n     \"owner_id\": <id>,\r\n     \"size\":\r\n     {\r\n          \"current\" : <cur>,\r\n          \"hmax\": <hmax>,\r\n          \"h_integral\": <hint>,\r\n          \"last_ts\": <last_ts>\r\n     }\r\n},\r\n{\r\n...\r\n}]\r\n}\nErrors\nReturns Error Code 400 if more than one parameter is set.\nExamples\nSample request\nReturns information on all buckets in S3.GET /?ostor-buckets HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 30 Apr 2016 22:32:00 GMT\r\nAuthorization: <authorization_string>\nSample response{\r\n\"Buckets\": [\r\n    {\r\n        \"size\": {\r\n            \"current\": 12288,\r\n            \"h_integral\": 7360512,\r\n            \"hmax\": 12288,\r\n            \"last_ts\": 424241\r\n        },\r\n        \"epoch\": 0,\r\n        \"owner_id\": \"ba7eba06129464c5\",\r\n        \"name\": \"bucket1\",\r\n        \"creation_date\": \"2018-05-25T17:12:00.000Z\"\r\n    },\r\n    {\r\n        \"size\": {\r\n            \"current\": 46700160,\r\n            \"h_integral\": 28160196480,\r\n            \"hmax\": 46700160,\r\n            \"last_ts\": 424237\r\n        },\r\n        \"epoch\": 0,\r\n        \"owner_id\": \"ccbec013d9fd3918\",\r\n        \"name\": \"bucket2\",\r\n        \"creation_date\": \"2018-05-25T13:51:55.000Z\"\r\n    },\r\n    {\r\n        \"size\": {\r\n            \"current\": 12288,\r\n            \"h_integral\": 8036352,\r\n            \"hmax\": 12288,\r\n            \"last_ts\": 424186\r\n        },\r\n        \"epoch\": 0,\r\n        \"owner_id\": \"9d80d59edbe2862a\",\r\n        \"name\": \"bucket3\",\r\n        \"creation_date\": \"2018-05-23T10:30:49.000Z\"\r\n    }\r\n]}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/get-service-ostor-buckets.html"
    },
    {
        "title": "Mounting NFS exports on Linux",
        "content": "Mounting NFS exports on Linux\nYou can mount an NFS export created in Virtuozzo Hybrid Infrastructure like any other directory exported via NFS. You will need the share IP address (or hostname) and the volume identifier.\nIn console, run the following commands:# mkdir /mnt/nfs\r\n# mount -t nfs -o vers=4.0 <share_IP>:/<share_name>/ /mnt/nfs\r\n\nwhere:\n\n-o vers=4.0 is the NFS version to use.\nVirtuozzo Hybrid Infrastructure supports NFS versions 4.0 and 4.1.\n\n<share_IP> is the share IP address. You can also use the share hostname.\n/<share_name>/ is the root export path, like share1. For user exports, specify their full path, for example: /<share_name>/export1.\n/mnt/nfs is an existing local directory to mount the export to.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/mounting-nfs-exports-on-linux.html"
    },
    {
        "title": "Monitoring block storage",
        "content": "Monitoring block storage\nAfter creating a target group, you can monitor it on the Overview tab. The charts show the read and write I/O activity and latency across all LUNs attached to the target group.\n\nAdvanced iSCSI monitoring via Grafana\nFor advanced monitoring of target groups, go to the Monitoring > Dashboard screen, and then click Grafana dashboard. A separate browser tab will open with preconfigured Grafana dashboards. Two of them are dedicated to the iSCSI service. To see a detailed description for each chart, click i in the chart\u00e2\u0080\u0099s top left corner.\nOn the iSCSI overview dashboard, note the following charts:\n\niSCSI availability. The chart shows target availability. Time periods when the targets have not been available will be highlighted in red. In this case, check /var/log/vstorage/iscsi/vstorage-target-monitor.log on the nodes with the failed service and report a problem.\nLatency. The chart shows the time spent on read and write I/O operations across all iSCSI LUNs. It should average a few dozens of milliseconds with peak values below 1s.\n\nThe iSCSI details dashboard is intended for troubleshooting by the technical support team. To monitor a particular target group, target, session, or LUN, select it from a drop-down list above.\n\nSee also\n\nManaging block storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-block-storage.html"
    },
    {
        "title": "Creating IKE policies",
        "content": "Creating IKE policiesPOST /v2.0/vpn/ikepolicies\nCreate an IKE policy.\nThe IKE policy is used for phases one and two negotiation of the VPN connection. You can specify both the authentication and encryption algorithms for connections.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-ike-policy-detail#create-ike-policy\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicy\n\nbody\nobject\nAn ikepolicy object.\n\nname (Optional)\r\n                    \nbody\nstring\n\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\n\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nphase1_negotiation_mode (Optional)\nbody\nstring\nThe IKE mode. A valid value is main, which is the default.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\n\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nike_version (Optional)\n\nbody\nstring\n\nThe IKE version. A valid value is v1 or v2. Default is v1.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"ikepolicy\": {\r\n        \"phase1_negotiation_mode\": \"main\",\r\n        \"auth_algorithm\": \"sha1\",\r\n        \"encryption_algorithm\": \"aes-128\",\r\n        \"pfs\": \"group5\",\r\n        \"lifetime\": {\r\n            \"units\": \"seconds\",\r\n            \"value\": 7200\r\n        },\r\n        \"ike_version\": \"v1\",\r\n        \"name\": \"ikepolicy1\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/ikepolicies\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicies\n\nbody\narray\nA list of ikepolicy objects.\n\nikepolicy\n\nbody\nobject\nAn ikepolicy object.\n\nname (Optional)\r\n                    \nbody\nstring\n\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\n\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nphase1_negotiation_mode (Optional)\nbody\nstring\nThe IKE mode. A valid value is main, which is the default.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\n\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IKE policy.\n\nike_version (Optional)\n\nbody\nstring\n\nThe IKE version. A valid value is v1 or v2. Default is v1.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"ikepolicy\": {\r\n    \"id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"ikepolicy1\",\r\n    \"description\": \"\",\r\n    \"auth_algorithm\": \"sha1\",\r\n    \"encryption_algorithm\": \"aes-128\",\r\n    \"phase1_negotiation_mode\": \"main\",\r\n    \"lifetime\": {\r\n      \"units\": \"seconds\",\r\n      \"value\": 7200\r\n    },\r\n    \"ike_version\": \"v1\",\r\n    \"pfs\": \"group5\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-ike-policies.html"
    },
    {
        "title": "Restoring volumes from backups",
        "content": "Restoring volumes from backups\nDuring the restore process, a new volume is created and the existing volume is not overwritten. You can restore a volume from a backup of a data or boot volume.\nPrerequisites\n\nA volume backup is created automatically, as described in Creating backup plans, or manually,  as described in Creating and deleting backups manually.\n\nTo restore a volume\n\nAdmin panel\n\nOn the Compute > Backup > Recovery points tab, click the recovery point from which you want to restore a volume.\nOn the right pane, click Restore volume.\n\nIn the Restore volume window, specify a volume name and select a storage policy, and then click Restore.\n\nThe new volume will appear on the Compute > Storage > Volumes screen.\n\nCommand-line interface\nUse the following command:vinfra service compute volume backup restore [--name <name>] [--storage-policy <storage-policy>]\r\n                                             <volume-backup>\n\n<volume-backup>\n\nVolume backup ID or name\n--name <name>\n\nName of a new volume\n--storage-policy <storage-policy>\n\nThe name or ID of storage policy for a new volume\n\nFor example, to restore a new volume with the name myvolume and the default storage policy from the backup mybackup, run:# vinfra service compute volume backup restore mybackup --name myvolume --storage-policy default\n\nSee also\n\nManaging compute volumes\n\nRestoring virtual machines from backups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume backup restore [--name <name>] [--storage-policy <storage-policy>]\r\n                                             <volume-backup>\n\n<volume-backup>\n\nVolume backup ID or name\n--name <name>\n\nName of a new volume\n--storage-policy <storage-policy>\n\nThe name or ID of storage policy for a new volume\n\nFor example, to restore a new volume with the name myvolume and the default storage policy from the backup mybackup, run:# vinfra service compute volume backup restore mybackup --name myvolume --storage-policy default\n",
                "title": "To restore a volume"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Recovery points tab, click the recovery point from which you want to restore a volume.\nOn the right pane, click Restore volume.\n\nIn the Restore volume window, specify a volume name and select a storage policy, and then click Restore.\n\n\n\n\n\n\nThe new volume will appear on the Compute > Storage > Volumes screen.\n",
                "title": "To restore a volume"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/restoring-volumes-from-backups.html"
    },
    {
        "title": "Configuring inbound firewall rules",
        "content": "Configuring inbound firewall rules\nTo prevent access from untrusted sources to the cluster, you can configure inbound firewall rules on your nodes. To enable traffic filtering, you need to configure allow and deny lists for a network or a traffic type. By default, the lists are empty and all incoming traffic is allowed. You can create access rules in them to configure access for incoming traffic. Access rules in the allow list have higher priority than those in the deny list. If you have access rules for both networks and traffic types, access lists configured for traffic types will have higher priority than those of networks.\nLimitations\n\nIf you create allow rules but leave the deny list empty, all incoming traffic will still be allowed.\n\nTo filter incoming traffic for a network\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Edit.\n\nIn the Edit network window, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\nClick Save to apply your changes.\n\nThe updated access rules will be applied on all nodes connected to this network.\n\nCommand-line interface\nUse the following command:vinfra cluster network set [--inbound-allow-list <addresses> | --add-inbound-allow-list <addresses> |\r\n                           --del-inbound-allow-list <addresses> | --clear-inbound-allow-list]\r\n                           [--inbound-deny-list <addresses> | --add-inbound-deny-list <addresses> |\r\n                           --del-inbound-deny-list <addresses> | --clear-inbound-deny-list] <network>\r\n\n--inbound-allow-list <addresses>\nA comma-separated list of IP addresses (overwrites the current inbound allow rules)\n--add-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound allow rules)\n--del-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound allow rules)\n--clear-inbound-allow-list\n\nClear all inbound allow rules\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (overwrites the current inbound deny rules)\n--add-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound deny rules)\n--del-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound deny rules)\n--clear-inbound-deny-list <addresses>\n\nClear all inbound deny rules\n<network>\n\nNetwork ID or name\n\nFor example, to allow traffic from the subnet 10.136.100.0/24 in the MyNet network, run:# vinfra cluster network set MyNet --add-inbound-allow-list 10.136.100.0/24 --add-inbound-deny-list 0.0.0.0/0\n\nTo filter incoming traffic for a regular or custom traffic type\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the pencil icon next to the traffic type name.\n\nIn the Edit regular traffic type window, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\nClick Save to apply your changes.\n\nAfter you edit the allow and deny lists, the updated access rules are applied on all nodes connected to the network with this traffic type.\n\nCommand-line interface\nUse the following command:vinfra cluster traffic-type set [--inbound-allow-list <addresses> | --add-inbound-allow-list <addresses> |\r\n                                --del-inbound-allow-list <addresses> | --clear-inbound-allow-list]\r\n                                [--inbound-deny-list <addresses> | --add-inbound-deny-list <addresses> |\r\n                                --del-inbound-deny-list <addresses> | --clear-inbound-deny-list] <traffic-type>\r\n\n--inbound-allow-list <addresses>\nA comma-separated list of IP addresses (overwrites the current inbound allow rules)\n--add-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound allow rules)\n--del-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound allow rules)\n--clear-inbound-allow-list\n\nClear all inbound allow rules\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (overwrites the current inbound deny rules)\n--add-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound deny rules)\n--del-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound deny rules)\n--clear-inbound-deny-list <addresses>\n\nClear all inbound deny rules\n<traffic-type>\n\nTraffic type name\n\nFor example, to allow traffic from the subnet 10.136.100.0/24 for the MyTrafficType traffic type, run:# vinfra cluster traffic-type set MyTrafficType --add-inbound-allow-list 10.136.100.0/24 --add-inbound-deny-list 0.0.0.0/0\n\nTo view access rules for a network or traffic type\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, find a network or a traffic type with the shield icon next to its name.\nHover over the icon to see what access rules are configured.\n\nCommand-line interface\n\nFor a network, use vinfra cluster network show. For example:# vinfra cluster network show MyNet\r\n+---------------------+------------------------------------------+\r\n| Field               | Value                                    |\r\n+---------------------+------------------------------------------+\r\n| id                  | db43aed5-82ec-4c60-8c5a-d60767203d89     |\r\n| inbound_allow_list  | - 10.136.100.0/24                        |\r\n| inbound_deny_list   | - 0.0.0.0/0                              |\r\n| name                | MyNet                                    |\r\n| outbound_allow_list | - 0.0.0.0:tcp:8888:Admin panel           |\r\n|                     | - 0.0.0.0:tcp:80:HTTP                    |\r\n|                     | - 0.0.0.0:tcp:443:HTTPS                  |\r\n|                     | - 0.0.0.0:udp:53:DNS                     |\r\n|                     | - 0.0.0.0:tcp:53:DNS                     |\r\n|                     | - 0.0.0.0:udp:123:NTP                    |\r\n|                     | - 0.0.0.0:tcp:8443:ABGW registration     |\r\n|                     | - 0.0.0.0:tcp:44445:ABGW Geo-replication |\r\n|                     | - 0.0.0.0:tcp:9877:Acronis Cyber Protect |\r\n|                     | - 0.0.0.0:tcp:5900-6079:VM VNC Legacy    |\r\n|                     | - 0.0.0.0:udp:4789:VXLAN                 |\r\n|                     | - 0.0.0.0:tcp:15900-16900:VM VNC         |\r\n|                     | - 0.0.0.0:udp:2049:NFS                   |\r\n|                     | - 0.0.0.0:tcp:2049:NFS                   |\r\n|                     | - 0.0.0.0:tcp:111:NFS Rpcbind            |\r\n|                     | - 0.0.0.0:any:0:Allow all                |\r\n| traffic_types       |                                          |\r\n| vlan                |                                          |\r\n+---------------------+------------------------------------------+\n\nFor a traffic type, use vinfra cluster traffic-type show. For example:# vinfra cluster traffic-type show MyTrafficType\r\n+--------------------+-------------------+\r\n| Field              | Value             |\r\n+--------------------+-------------------+\r\n| exclusive          | False             |\r\n| hidden             | False             |\r\n| inbound_allow_list | - 10.136.100.0/24 |\r\n| inbound_deny_list  | - 0.0.0.0/0       |\r\n| name               | MyTrafficType     |\r\n| port               | 6900              |\r\n| type               | custom            |\r\n+--------------------+-------------------+\r\n\n\nSee also\n\nConfiguring outbound firewall rules\n\nManaging networks\n\nConfiguring data-in-transit encryption\n\nManaging traffic types",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network set [--inbound-allow-list <addresses> | --add-inbound-allow-list <addresses> |\r\n                           --del-inbound-allow-list <addresses> | --clear-inbound-allow-list]\r\n                           [--inbound-deny-list <addresses> | --add-inbound-deny-list <addresses> |\r\n                           --del-inbound-deny-list <addresses> | --clear-inbound-deny-list] <network>\r\n\n--inbound-allow-list <addresses>\nA comma-separated list of IP addresses (overwrites the current inbound allow rules)\n--add-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound allow rules)\n--del-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound allow rules)\n--clear-inbound-allow-list\n\nClear all inbound allow rules\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (overwrites the current inbound deny rules)\n--add-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound deny rules)\n--del-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound deny rules)\n--clear-inbound-deny-list <addresses>\n\nClear all inbound deny rules\n<network>\n\nNetwork ID or name\n\nFor example, to allow traffic from the subnet 10.136.100.0/24 in the MyNet network, run:# vinfra cluster network set MyNet --add-inbound-allow-list 10.136.100.0/24 --add-inbound-deny-list 0.0.0.0/0\n",
                "title": "To filter incoming traffic for a network"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster traffic-type set [--inbound-allow-list <addresses> | --add-inbound-allow-list <addresses> |\r\n                                --del-inbound-allow-list <addresses> | --clear-inbound-allow-list]\r\n                                [--inbound-deny-list <addresses> | --add-inbound-deny-list <addresses> |\r\n                                --del-inbound-deny-list <addresses> | --clear-inbound-deny-list] <traffic-type>\r\n\n--inbound-allow-list <addresses>\nA comma-separated list of IP addresses (overwrites the current inbound allow rules)\n--add-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound allow rules)\n--del-inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound allow rules)\n--clear-inbound-allow-list\n\nClear all inbound allow rules\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (overwrites the current inbound deny rules)\n--add-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (adds the specified inbound deny rules)\n--del-inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses (removes the specified inbound deny rules)\n--clear-inbound-deny-list <addresses>\n\nClear all inbound deny rules\n<traffic-type>\n\nTraffic type name\n\nFor example, to allow traffic from the subnet 10.136.100.0/24 for the MyTrafficType traffic type, run:# vinfra cluster traffic-type set MyTrafficType --add-inbound-allow-list 10.136.100.0/24 --add-inbound-deny-list 0.0.0.0/0\n",
                "title": "To filter incoming traffic for a regular or custom traffic type"
            },
            {
                "example": "\nCommand-line interface\n\n\nFor a network, use vinfra cluster network show. For example:# vinfra cluster network show MyNet\r\n+---------------------+------------------------------------------+\r\n| Field               | Value                                    |\r\n+---------------------+------------------------------------------+\r\n| id                  | db43aed5-82ec-4c60-8c5a-d60767203d89     |\r\n| inbound_allow_list  | - 10.136.100.0/24                        |\r\n| inbound_deny_list   | - 0.0.0.0/0                              |\r\n| name                | MyNet                                    |\r\n| outbound_allow_list | - 0.0.0.0:tcp:8888:Admin panel           |\r\n|                     | - 0.0.0.0:tcp:80:HTTP                    |\r\n|                     | - 0.0.0.0:tcp:443:HTTPS                  |\r\n|                     | - 0.0.0.0:udp:53:DNS                     |\r\n|                     | - 0.0.0.0:tcp:53:DNS                     |\r\n|                     | - 0.0.0.0:udp:123:NTP                    |\r\n|                     | - 0.0.0.0:tcp:8443:ABGW registration     |\r\n|                     | - 0.0.0.0:tcp:44445:ABGW Geo-replication |\r\n|                     | - 0.0.0.0:tcp:9877:Acronis Cyber Protect |\r\n|                     | - 0.0.0.0:tcp:5900-6079:VM VNC Legacy    |\r\n|                     | - 0.0.0.0:udp:4789:VXLAN                 |\r\n|                     | - 0.0.0.0:tcp:15900-16900:VM VNC         |\r\n|                     | - 0.0.0.0:udp:2049:NFS                   |\r\n|                     | - 0.0.0.0:tcp:2049:NFS                   |\r\n|                     | - 0.0.0.0:tcp:111:NFS Rpcbind            |\r\n|                     | - 0.0.0.0:any:0:Allow all                |\r\n| traffic_types       |                                          |\r\n| vlan                |                                          |\r\n+---------------------+------------------------------------------+\n\n\nFor a traffic type, use vinfra cluster traffic-type show. For example:# vinfra cluster traffic-type show MyTrafficType\r\n+--------------------+-------------------+\r\n| Field              | Value             |\r\n+--------------------+-------------------+\r\n| exclusive          | False             |\r\n| hidden             | False             |\r\n| inbound_allow_list | - 10.136.100.0/24 |\r\n| inbound_deny_list  | - 0.0.0.0/0       |\r\n| name               | MyTrafficType     |\r\n| port               | 6900              |\r\n| type               | custom            |\r\n+--------------------+-------------------+\r\n\n\n\n",
                "title": "To view access rules for a network or traffic type"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Edit.\n\nIn the Edit network window, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\n\n\n\n\n\nClick Save to apply your changes.\n\nThe updated access rules will be applied on all nodes connected to this network.\n",
                "title": "To filter incoming traffic for a network"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the pencil icon next to the traffic type name.\n\nIn the Edit regular traffic type window, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\n\n\n\n\n\nClick Save to apply your changes.\n\nAfter you edit the allow and deny lists, the updated access rules are applied on all nodes connected to the network with this traffic type.\n",
                "title": "To filter incoming traffic for a regular or custom traffic type"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, find a network or a traffic type with the shield icon next to its name.\nHover over the icon to see what access rules are configured.\n\n",
                "title": "To view access rules for a network or traffic type"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-inbound-firewall-rules.html"
    },
    {
        "title": "4. Creating Networks for Leostream\u00c2\u00b6",
        "content": "4. Creating Networks for Leostream | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n4. Creating Networks for Leostream\u00c2\u00b6\nAfter creating the domain, project, and users for your Leostream environment, use the self-service portal to configure the required network. The self-service portal is typically available at:\nhttps://<admin_panel_virtual_IP_address>:8800\n\n\nLog in to the self-service portal, with the credentials for the project user.\n\nGo to the Networks page to create four networks for your deployment:\n\nVDI-network\nAD-Network\nGateway-Network\nBroker-Network.\n\nClick the Create virtual network button and proceed through the wizard to configure the networks as per your requirements. For more info on how to create networks check here Creating Compute Networks and look for the steps to create a virtual network.\nIf you are integrating with Active Directory, add your Active Directory IP as your DNS Server for the VDI-network as shown in the following figure.\n\nGo to the Routers page to create a Virtual Router. Ensure that you enable SNAT, as shown in the following figure, in order to allow the VMs access to the internet. For more information, see Creating virtual routers.\n\nWhen completed, your virtual router appears similar to the example shown in the following figure. Security groups can be created in order to restrict and isolate the networks if needed.  Later in this document we will enumerate the ports that must be allowed between the Leostream Connection Broker, the Leostream Gateway and the virtual desktops.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/creating-networks.html"
    },
    {
        "title": "Compute cluster requirements",
        "content": "Compute cluster requirements\n\nGeneral requirements are listed in General requirements.\n\nNote the additional requirements for the compute cluster:\n\nTo be able to deploy and work with the compute cluster, run Virtuozzo Hybrid Infrastructure on physical servers.\nUse 64-bit x86 AMD-V or Intel VT processors with hardware virtualization extensions enabled. For Intel processors, enable \u00e2\u0080\u009cunrestricted guest\u00e2\u0080\u009d and VT-x with Extended Page Tables in BIOS. \nUse the same CPU models on each node to avoid VM live migration issues. If you need to use different CPU models in the compute cluster, create a placement for each group of compute nodes with the same CPU model.\nIf you intend to enable RAM overcommitment for virtual machines, ensure that the system disk has enough space for swap and additionally 100 GiB of free space.\n\nTo better understand how to calculate the hardware configuration for the compute cluster, consider the following example with RAM and CPU reservations.\nExample. If you have 10 nodes (1 system disk, 1 metadata disk, 1 cache disk, 10 storage disks) and want to use them for the compute cluster, refer to the table below for the calculations. Note that three nodes are used for the management node high availability, and each of them meets the requirements for the management node.\n\n10 nodes for the compute service with MN HA\r\n                    \n\nService\nManagement nodes (nodes 1-3)\nSecondary nodes (nodes 4-10)\n\nSystem\n4.5 GB, 3.3 cores\n1.5 GB, 1.1 cores\n\nStorage services\n\n10 storage disks, 1 metadata, and 1 cache disk (each takes 0.5 GB and 0.2 cores), that is 6 GB and 2.4 cores in total\n\n10 storage disks, 1 metadata, and 1 cache disk (each takes 0.5 GB and 0.2 cores), that is 6 GB and 2.4 cores in total\n\nCompute\n10 GB, 4 cores\n \n\nLoad balancer\n1.5 GB, 0.5 cores\n \n\nKubernetes\n1 GB, 0.5 cores\n \n\nService reservations\n23 GB of RAM and\r\n10.7 cores\n7.5 GB of RAM and\r\n3.5 cores\n\nRecommended hardware configuration\n64 GB1 All extra RAM is used for allocation to virtual machines. of RAM and\r\n16 cores\n64 GB2 All extra RAM is used for allocation to virtual machines. of RAM and\r\n16 cores\n\nSee also\n\nCompute cluster network requirements\n\nProvisioning compute resources",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/compute-requirements.html"
    },
    {
        "title": "Querying bucket quotas via REST API",
        "content": "Querying bucket quotas via REST API\nYou can display the specific quotas per bucket with the ostor-quotas service and parameter bucket specifying the bucket name:# s3_curl GET \"http://s3.example.com/?ostor-quotas&bucket=bucket1\"\r\n{\r\n    \"version\": \"1\",\r\n    \"type\": \"bucket\",\r\n    \"size\": \"256\"\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-bucket-quotas-via-rest-api.html"
    },
    {
        "title": "Listing Kubernetes cluster templates",
        "content": "Listing Kubernetes cluster templatesGET /v1/clustertemplates\r\n\nList available cluster templates.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=list-all-cluster-templates-detail#list-all-cluster-templates\nRequest\nExample# curl -ks -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9513/v1/clustertemplates\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nclustertemplates\n\nbody\narray\nThe list of all cluster templates in Magnum.\n\ninsecure_registry\n\nbody\nstring\nThe URL pointing to users\u00e2\u0080\u0099s own private insecure docker registry to\r\ndeploy and run docker containers.\n\nlinks\n\nbody\narray\nLinks to the resources in question.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nfloating_ip_enabled\n\nbody\nboolean\nWhether enable or not using the floating IP of cloud provider. Some\r\ncloud providers used floating IP, some used public IP, thus Magnum\r\nprovide this option for specifying the choice of using floating IP.\n\nfixed_subnet (Optional)\nbody\nstring\nFixed subnet that are using to allocate network address for nodes in\r\nbay/cluster.\n\nmaster_flavor_id (Optional)\nbody\nstring\nThe flavor of the master node for this baymodel/cluster template.\n\nuuid\n\nbody\nUUID\nThe UUID of the cluster template.\n\nno_proxy (Optional)\nbody\nstring\nWhen a proxy server is used, some sites should not go through the proxy\r\nand should be accessed normally. In this case, users can specify these\r\nsites as a comma separated list of IPs. The default is None.\n\nhttps_proxy (Optional)\nbody\nstring\nThe IP address for a proxy to use when direct HTTPS access from the\r\nservers to sites on the external internet is blocked. This may happen in\r\ncertain countries or enterprises, and the proxy allows the servers and\r\ncontainers to access these sites. The format is a URL including a port\r\nnumber. The default is None.\n\ntls_disabled\n\nbody\nboolean\nTransport Layer Security (TLS) is normally enabled to secure the\r\nbay/cluster. In some cases, users may want to disable TLS in the\r\nbay/cluster, for instance during development or to troubleshoot certain\r\nproblems. Specifying this parameter will disable TLS so that users can\r\naccess the COE endpoints without a certificate. The default is TLS enabled.\n\nkeypair_id\n\nbody\nstring\nThe name of the SSH keypair to configure in the bay/cluster servers\r\nfor ssh access. Users will need the key to be able to ssh to the servers in\r\nthe bay/cluster. The login name is specific to the bay/cluster driver, for\r\nexample with fedora-atomic image, default login name is fedora.\n\npublic\n\nbody\nboolean\nAccess to a baymodel/cluster template is normally limited to the admin,\r\nowner or users within the same tenant as the owners. Setting this flag\r\nmakes the baymodel/cluster template public and accessible by other users.\r\nThe default is not public.\n\nlabels (Optional)\nbody\narray\nArbitrary labels in the form of key=value pairs. The accepted keys and\r\nvalid values are defined in the bay/cluster drivers. They are used as a way\r\nto pass additional parameters that are specific to a bay/cluster driver.\n\ndocker_volume_size\n\nbody\ninteger\nThe size in GB for the local storage on each server for the Docker daemon\r\nto cache the images and host the containers. Cinder volumes provide the\r\nstorage. The default is 25 GB. For the devicemapper storage driver,\r\nthe minimum value is 3 GB. For the overlay storage driver, the minimum\r\nvalue is 1 GB.\n\nserver_type\n\nbody\nstring\nThe servers in the bay/cluster can be vm or baremetal. This\r\nparameter selects the type of server to create for the bay/cluster.\r\nThe default is vm.\n\nexternal_network_id\n\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to the\r\nexternal internet for the bay/cluster. This network must be an external\r\nnetwork, i.e. its attribute router:external must be True. The\r\nservers in the bay/cluster will be connected to a private network and\r\nMagnum will create a router between this private network and the external\r\nnetwork. This will allow the servers to download images, access discovery\r\nservice, etc, and the containers to install packages, etc. In the opposite\r\ndirection, floating IPs will be allocated from the external network to\r\nprovide access from the external internet to servers and the container\r\nservices hosted in the bay/cluster.\n\ncluster_distro\n\nbody\nstring\nDisplay the attribute os_distro defined as appropriate metadata in\r\nimage for the bay/cluster driver.\n\nimage_id\n\nbody\nstring\nThe name or UUID of the base image in Glance to boot the servers for the\r\nbay/cluster. The image must have the attribute os_distro defined as\r\nappropriate for the bay/cluster driver.\n\nvolume_driver\n\nbody\nstring\nThe name of a volume driver for managing the persistent storage for the containers. The functionality supported are specific to the driver.\n\nregistry_enabled (Optional)\nbody\nboolean\nDocker images by default are pulled from the public Docker registry,\r\nbut in some cases, users may want to use a private registry. This option\r\nprovides an alternative registry based on the Registry V2: Magnum will\r\ncreate a local registry in the bay/cluster backed by swift to host the\r\nimages. The default is to use the public registry.\n\ndocker_storage_driver\n\nbody\nstring\nThe name of a driver to manage the storage for the images and the\r\ncontainer\u00e2\u0080\u0099s writable layer. The default is devicemapper.\n\napiserver_port\n\nbody\ninteger\nThe exposed port of COE API server.\n\nname\n\nbody\nstring\nName of the resource.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nnetwork_driver\n\nbody\nstring\nThe name of a network driver for providing the networks for the containers.\r\nNote that this is different and separate from the Neutron network for the\r\nbay/cluster. The operation and networking model are specific to the\r\nparticular driver.\n\nfixed_network (Optional)\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to\r\nthe internal network for the bay/cluster.\n\ncoe\n\nbody\nstring\nSpecify the Container Orchestration Engine to use. Supported COEs\r\ninclude kubernetes, swarm, mesos. If your environment has\r\nadditional bay/cluster drivers installed, refer to the bay/cluster driver\r\ndocumentation for the new COE names.\n\nflavor_id\n\nbody\nstring\nThe nova flavor ID or name for booting the node servers. The default is\r\nm1.small.\n\nmaster_lb_enabled\n\nbody\nboolean\nSince multiple masters may exist in a bay/cluster, a Neutron load balancer\r\nis created to provide the API endpoint for the bay/cluster and to direct\r\nrequests to the masters. In some cases, such as when the LBaaS service is\r\nnot available, this option can be set to false to create a bay/cluster\r\nwithout the load balancer. In this case, one of the masters will serve as\r\nthe API endpoint. The default is true, i.e. to create the load\r\nbalancer for the bay.\n\ndns_nameserver\n\nbody\nstring\nThe DNS nameserver for the servers and containers in the bay/cluster to\r\nuse. This is configured in the private Neutron network for the bay/cluster.\r\nThe default is 8.8.8.8.\n\nhidden (Optional)\nbody\nboolean\nIndicates whether the ClusterTemplate is hidden or not, the default\r\nvalue is false.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"clustertemplates\": [\r\n    {\r\n      \"insecure_registry\": null,\r\n      \"links\": [\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:9513/v1/clustertemplates/b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n          \"rel\": \"self\"\r\n        },\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:9513/clustertemplates/b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n          \"rel\": \"bookmark\"\r\n        }\r\n      ],\r\n      \"http_proxy\": null,\r\n      \"updated_at\": null,\r\n      \"floating_ip_enabled\": true,\r\n      \"fixed_subnet\": \"43b25f61-657c-407f-935c-3a456aab7943\",\r\n      \"master_flavor_id\": null,\r\n      \"user_id\": \"2a55cfc7747b4383b0856a0a622914dd\",\r\n      \"uuid\": \"b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n      \"no_proxy\": null,\r\n      \"https_proxy\": null,\r\n      \"tls_disabled\": false,\r\n      \"keypair_id\": null,\r\n      \"hidden\": false,\r\n      \"project_id\": \"888ea5e76b284d83a18b3bfaa6fdde16\",\r\n      \"public\": false,\r\n      \"labels\": {\r\n        \"kube_tag\": \"v1.15.6\",\r\n        \"cloud_provider_enabled\": \"true\",\r\n        \"cloud_provider_tag\": \"v1.15.0\",\r\n        \"kube_version\": \"v1.15.6\",\r\n        \"boot_volume_type\": \"default\",\r\n        \"flannel_tag\": \"v0.11.0-amd64\",\r\n        \"boot_volume_size\": \"10\",\r\n        \"heat_container_agent_tag\": \"hci-3.5-latest\",\r\n        \"docker_volume_type\": \"default\"\r\n      },\r\n      \"docker_volume_size\": 10,\r\n      \"server_type\": \"vm\",\r\n      \"external_network_id\": \"7cc2fa27-b387-4a67-8b89-94b608295623\",\r\n      \"cluster_distro\": \"fedora-atomic\",\r\n      \"image_id\": \"f1e62c6a-37d8-4e73-9729-ad957e509c11\",\r\n      \"volume_driver\": \"cinder\",\r\n      \"registry_enabled\": false,\r\n      \"docker_storage_driver\": \"devicemapper\",\r\n      \"apiserver_port\": null,\r\n      \"name\": \"kub1_template\",\r\n      \"created_at\": \"2020-04-14T13:26:01+00:00\",\r\n      \"network_driver\": \"flannel\",\r\n      \"fixed_network\": \"666d0a98-9de7-45df-9301-5ed12a7efea1\",\r\n      \"coe\": \"kubernetes\",\r\n      \"flavor_id\": null,\r\n      \"master_lb_enabled\": true,\r\n      \"dns_nameserver\": null\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-kubernetes-cluster-templates.html"
    },
    {
        "title": "Provisioning Acronis Backup Storage space",
        "content": "Provisioning Acronis Backup Storage space\nStorage space for backups from the Acronis Cyber suite is provisioned via Backup Gateway, which connects Acronis Cyber Protect Cloud or Acronis Cyber Protect to a destination storage. The destination storage can be one of the following:\n\nThe local Virtuozzo Hybrid Infrastructure cluster\nAn external Network File System (NFS) share\nA public cloud\n\nLimitations\n\nTwo-factor authentication (2FA) is not supported for Backup Gateway registration in Acronis Cyber Protect Cloud. To register Backup Gateway, mark a user as a service account, as described in the Acronis Cyber Protect Cloud documentation, and specify the user credentials during the registration.\n\nPrerequisites\n\nA clear understanding of backup storage, which is explained in About Acronis Backup Storage.\nYour hardware meets the requirements listed in Acronis Backup Storage requirements.\nYour infrastructure networks are set up, as described in Setting up networks for backup storage.\nThe storage cluster is created by following the instructions in Deploying the storage cluster.\nA partner account exists in Acronis Cyber Protect Cloud.\n\nIf you have enabled login control for the Acronis Cyber Protect Cloud web interface, ensure that the public IP address of your backup storage cluster is specified among the allowed IP addresses, as instructed in the Acronis Cyber Protect Cloud documentation.\n\nProvisioning overview\n\nCreate backup storage on this cluster, an NFS share, or in a public cloud.\n Configure Acronis Cyber Protect Cloud to use the new backup location.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-backup-storage.html"
    },
    {
        "title": "Setting up user authentication and authorization",
        "content": "Setting up user authentication and authorization\nVirtuozzo Hybrid Infrastructure allows you to authenticate users in specific NFS shares via Kerberos and authorize them to access specific NFS exports inside these shares via LDAP.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-user-authentication-and-authorization.html"
    },
    {
        "title": "Supported authentication schemes",
        "content": "Supported authentication schemes\nThe following authentication schemes are supported by the Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol:\n\nSignature Version 2\n\nSignature Version 4\n\nThe following authentication methods are supported by the Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol:\n\nUsing the authorization header\n\nTransferring payload in a single chunk\n\nTransferring payload in multiple chunks\n\nUsing query parameters\n\nBrowser-based uploads using POST\n\nSee also\n\nSupported Amazon S3 REST operations\n\nSupported Amazon request headers\n\nSupported Amazon response headers\n\nSupported Amazon error response headers\n\nAmazon S3 features supported by bucket policies\n\nSupported Amazon S3 object expiration actions",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-authentication-schemes.html"
    },
    {
        "title": "12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nAfter you create your centers and the Connection Broker inventories your desktops, you can logically group the desktops into pools.\nThe Leostream Connection Broker defines a pool as any group of desktops. Pools can be nested within one another, to create sub-pools. Pools and sub-pools have three distinct functions in Leostream.\n\nOrganizing desktops on the Resources > Desktops page.\nProvisioning new instances in your Virtuozzo Hybrid Infrastructure project.\nIndicating the desktops that a user may connect to and how the Connection Broker manages the user\u00e2\u0080\u0099s connection to those desktops.\n\nIn this chapter:\n\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/pooling-and-provisioning/index.html"
    },
    {
        "title": "Changing Kubernetes node flavors",
        "content": "Changing Kubernetes node flavors\nYou can modify the default flavors that will be used for Kubernetes master and worker nodes. If required, self-service users are able to select other flavors, instead of the default ones, when creating Kubernetes clusters.\nTo change the flavor for Kubernetes master nodes\nUse the following command:vinfra service compute k8saas defaults set --master-flavor <flavor> <version>\n\n--master-flavor <flavor>\n\nThe flavor to be used for Kubernetes master nodes.\n<version>\n\nKubernetes version to apply new defaults for.\n\nFor example, to set the master node flavor to xlarge and apply this change for all of the supported Kubernetes versions, run:# vinfra service compute k8saas defaults set --master-flavor xlarge\nTo set this flavor only for version 1.24.3, append the version number to the command:# vinfra service compute k8saas defaults set --master-flavor xlarge v1.24.3\r\n\nTo change the flavor for Kubernetes worker nodes\nUse the following command:vinfra service compute k8saas defaults set --flavor <flavor> <version>\n\n--flavor <flavor>\n\nThe flavor to be used for Kubernetes worker nodes.\n<version>\n\nKubernetes version to apply new defaults for.\n\nFor example, to set the worker node flavor to medium and apply this change for all of the supported Kubernetes versions, run:# vinfra service compute k8saas defaults set --flavor medium\nTo set this flavor only for version 1.24.3, append the version number to the command:# vinfra service compute k8saas defaults set --flavor medium v1.24.3\nSee also\n\nConfiguring the Kubernetes system volume\n\nConfiguring Kubernetes load balancers\n\nConfiguring Kubernetes DNS and discovery parameters",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-kubernetes-node-flavors.html"
    },
    {
        "title": "Creating virtual routers",
        "content": "Creating virtual routersPOST /v2.0/routers\r\n\nCreates a logical router.\nThis operation creates a logical router. The logical router does\r\nnot have any internal interface and it is not associated with any\r\nsubnet. You can optionally specify an external gateway for a router\r\nat create time. The external gateway for the router must be plugged\r\ninto an external network. An external network has its\r\nrouter:external extended field set to true. To specify an\r\nexternal gateway, the ID of the external network must be passed\r\nin the network_id parameter of the external_gateway_info\r\nattribute in the request body.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-router-detail#create-router\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nrouter\n\nbody\nobject\nA router object.\n\ntenant_id (Optional)\nbody\nstring\nThe ID of the project that owns the resource.\r\nOnly administrative and users with advsvc role can specify\r\na project ID other than their own.\r\nYou cannot change this value through authorization policies.\n\nproject_id (Optional)\nbody\nstring\nThe ID of the project that owns the resource.\r\nOnly administrative and users with advsvc role can specify\r\na project ID other than their own.\r\nYou cannot change this value through authorization policies.\n\nname (Optional)\nbody\nstring\nHuman-readable name of the resource.\r\nDefault is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource.\r\nDefault is an empty string.\n\nadmin_state_up (Optional)\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\r\nDefault is true.\n\nexternal_gateway_info (Optional)\nbody\nobject\nThe external gateway information of the router.\r\nIf the router has an external gateway, this would be a dictionary \r\nof network_id, enable_snat and external_fixed_ips.\r\nOtherwise, this would be null.\n\nnetwork_id\n\nbody\nstring\nNetwork ID which the router gateway is connected to.\n\nenable_snat (Optional)\nbody\nboolean\nEnable Source NAT (SNAT) attribute. Default is\r\ntrue. To persist this attribute value, set the\r\nenable_snat_by_default option in the neutron.conf file.\r\nIt is available when ext-gw-mode extension is enabled.\n\nexternal_fixed_ips (Optional)\nbody\narray\nIP address(es) of the external gateway interface of the router.\r\nUse ip_version to automatically allocate an IP address from \r\nany subnet of the specified type.\n\nexternal_fixed_ips.ip_version\n\nbody\ninteger\nThe IP protocol version. Value is 4 or 6.\n\ndistributed (Optional)\nbody\nboolean\ntrue indicates a distributed router.\r\nIt is available when dvr extension is enabled.\n\nha (Optional)\nbody\nboolean\ntrue indicates a highly-available router.\r\nIt is available when l3-ha extension is enabled.\n\navailability_zone_hints (Optional)\nbody\narray\nThe availability zone candidates for the router.\r\nIt is available when router_availability_zone extension is enabled.\n\nservice_type_id (Optional)\nbody\nstring\nThe ID of the service type associated with the router.\n\nflavor_id (Optional)\nbody\nstring\nThe ID of the flavor associated with the router.\n\nExample\nCreate a router with an attached public interface. You will need to specify the public network ID and the ID of its subnet.\nThe new interface will attempt to use the selected network\u00e2\u0080\u0099s gateway IP address by default. You can also pass a custom IP address from the selected network in the ip_address parameter.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"router\": {\r\n    \"name\": \"router1\",\r\n    \"external_gateway_info\": {\r\n      \"network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n      \"enable_snat\": true,\r\n      \"external_fixed_ips\": [\r\n        {\r\n          \"ip_version\": 4\r\n        }\r\n      ]\r\n    }\r\n  }\r\n}' https://<node_IP_addr>:9696/v2.0/routers\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nrouter\n\nbody\nobject\nA router object.\n\nid\n\nbody\nstring\nThe ID of the router.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\n\nstatus\n\nbody\nstring\nThe router status.\n\nexternal_gateway_info\n\nbody\nobject\nThe external gateway information of the router.\r\nIf the router has an external gateway, this would be a dictionary \r\nof network_id, enable_snat and external_fixed_ips.\r\nOtherwise, this would be null.\n\nnetwork_id\n\nbody\nstring\nNetwork ID which the router gateway is connected to.\n\nenable_snat\n\nbody\nboolean\nEnable Source NAT (SNAT) attribute.\r\ntrue means Network Address Translation (NAT) is enabled\r\nfor traffic generated by subnets attached to the router\r\nwhen the traffic is sent to/received from the external network.\r\nfalse means no NAT is applied for traffic from/to the external network.\r\nIt is available when ext-gw-mode extension is enabled.\n\nexternal_fixed_ips\n\nbody\narray\nIP address(es) of the external gateway of the router.\r\nIt is a list of IP addresses. Each element of the list\r\nis a dictionary of ip_address and subnet_id.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nroutes\n\nbody\narray\nThe extra routes configuration for L3 router.\r\nA list of dictionaries with destination and nexthop parameters.\r\nIt is available when extraroute extension is enabled.\n\ndestination\n\nbody\nstring\nThe destination CIDR.\n\nnexthop\n\nbody\nstring\nThe IP address of the next hop for the corresponding destination.\r\nThe next hop IP address must be a part of one of the subnets to\r\nwhich the router interfaces are connected.\n\ndistributed\n\nbody\nboolean\ntrue indicates a distributed router.\r\nIt is available when dvr extension is enabled.\n\nha\n\nbody\nboolean\ntrue indicates a highly-available router.\r\nIt is available when l3-ha extension is enabled.\n\navailability_zone_hints\n\nbody\narray\nThe availability zone candidates for the router.\r\nIt is available when router_availability_zone extension is enabled.\n\navailability_zones\n\nbody\narray\nThe availability zone(s) for the router.\r\nIt is available when router_availability_zone extension is enabled.\n\nservice_type_id\n\nbody\nstring\nThe ID of the service type associated with the router.\n\nflavor_id\n\nbody\nstring\nThe ID of the flavor associated with the router.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ntags\n\nbody\narray\nThe list of tags on the router.\n\nconntrack_helpers\n\nbody\narray\nThe associated conntrack helper resources for the router. If the\r\nrouter has multiple conntrack helper resources, this field has\r\nmultiple entries. Each entry consists of netfilter conntrack helper\r\n(helper), the network protocol (protocol), the network port\r\n(port).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"router\": {\r\n    \"status\": \"ACTIVE\",\r\n    \"external_gateway_info\": {\r\n      \"network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n      \"enable_snat\": true,\r\n      \"external_fixed_ips\": [\r\n        {\r\n          \"subnet_id\": \"351884c7-ee37-4a7d-9dcb-4cff4a1bba27\",\r\n          \"ip_address\": \"10.94.139.171\"\r\n        }\r\n      ]\r\n    },\r\n    \"availability_zone_hints\": [],\r\n    \"availability_zones\": [],\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-03-04T16:12:16Z\",\r\n    \"admin_state_up\": true,\r\n    \"distributed\": false,\r\n    \"updated_at\": \"2020-03-04T16:12:18Z\",\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"flavor_id\": null,\r\n    \"revision_number\": 3,\r\n    \"routes\": [],\r\n    \"ha\": false,\r\n    \"id\": \"02542148-44cb-470d-a551-58f370c47b83\",\r\n    \"name\": \"router1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-virtual-routers.html"
    },
    {
        "title": "4. SECaaS Service Offering with HostBill BitNinja Module\u00c2\u00b6",
        "content": "4. SECaaS Service Offering with HostBill BitNinja Module | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n4. SECaaS Service Offering with HostBill BitNinja Module\u00c2\u00b6\nHostBill is a web-based billing and invoicing solution that can be integrated with any of our Solutions (VHS, VHI, OnApp). Thanks to the HostBill BitNinja module you can start reselling BitNinja licenses, either as a separate product or as a sub-product to your existing hosting services. This section aims to explain how a cloud provider can configure the BitNinja module on HostBill.\n\nIn this chapter:\n\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/hostbill-bitninja/index.html"
    },
    {
        "title": "Managing floating IPs",
        "content": "Managing floating IPs",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-floating-ips.html"
    },
    {
        "title": "Protecting data during a power outage",
        "content": "Protecting data during a power outage\nTo protect Virtuozzo Hybrid Infrastructure against power outages, it is recommended to use an Uninterruptable Power Supply (UPS) for all servers and network switches.\nAdditionally, you can prevent data loss and preserve data integrity by using enterprise-grade SSD drives. Unlike HDD drives, enterprise-grade SSD drives can properly handle power loss events. Enterprise-grade SSD drives that operate correctly usually have the power loss protection property in their technical specification. Some of the market names for this technology are Enhanced Power Loss Data Protection (Intel), Cache Power Protection (Samsung), Power-Failure Support (Kingston), and Complete Power Fail Protection (OCZ).\nIt is also recommended to ensure that all storage devices that will be added to your cluster can flush data from cache to disk in case of a power outage. You can check the data flushing capabilities of your disks, as explained in Checking disk data flushing capabilities.\nSee also\n\nQuantity of disks per node\n\nHDD/SSD configuration\n\nServer requirements\n\nNetwork requirements and recommendations",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/protecting-data-during-a-power-outage.html"
    },
    {
        "title": "User management",
        "content": "User management\nThis section describes how to manage S3 users and list S3 buckets.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/user-management.html"
    },
    {
        "title": "Revoking S3 user access key pairs via CLI",
        "content": "Revoking S3 user access key pairs via CLI\nYou can revoke the specified access key pair of the specified user with the ostor-s3-admin revoke-access-key command. You need to specify the access key in the key pair you want to delete as well as  the user email or S3 ID. For example:# ostor-s3-admin revoke-access-key -e user@email.com -k de86d1c19e616455YIPU -V 0100000000000002\r\nRevoke access key: user id=de86d1c19e616455, access key id=de86d1c19e616455YIPU\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/revoking-s3-user-access-key-pairs-via-cli.html"
    },
    {
        "title": "Introduction",
        "content": "Introduction\nThe guide briefly explains how to use the OpenStack API to manage the compute cluster in Virtuozzo Hybrid Infrastructure. It gives examples of requests and responses for actions that you can perform in the admin and self-service panels.\n\nThe guide reuses parts of the official OpenStack API documentation as permitted by the Creative Commons Attribution 3.0 License.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/introduction.html"
    },
    {
        "title": "Disabling S3 users in WHMCS",
        "content": "Disabling S3 users in WHMCS\nYou can disable users with the ostor-users service and parameter emailAddress specifying the user email address. WHMCS disables read and write access to S3 cluster when you click Disable User. Create a file S3_disableUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Disable user.\r\nfunction S3_disableUser($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Disable user.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'] . \"&disable\",\r\n        \"POST\"\r\n    );\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_disableUser($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/disabling-s3-users-in-whmcs.html"
    },
    {
        "title": "Migrating virtual machines from VMware vCenter",
        "content": "Migrating virtual machines from VMware vCenter\nStarting from Virtuozzo Hybrid Infrastructure 3.5, you can migrate virtual machines from VMware vCenter 5.0 or newer to Virtuozzo Hybrid Infrastructure using the virt-v2v tool. You will need to create a virt-v2v appliance virtual machine to transfer and convert the data from.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/migrating-vms-from-vmware-vcenter.html"
    },
    {
        "title": "Configuring the Kubernetes system volume",
        "content": "Configuring the Kubernetes system volume\nYou can modify the size and storage policy of the system volume on Kubernetes master nodes. The system volume is used by the Kubernetes management services and etcd.\nAfter updating the parameters, they will be applied only in new Kubernetes clusters. Existing Kubernetes clusters will retain their previous parameters.\n\nTo improve the stability of Kubernetes clusters, it is highly recommended to select a storage policy with an SSD-based tier.\n\nTo change the system volume parameters\n\nAdmin panel\n\nClick Settings on the Kubernetes clusters screen.\n\nSet the desired storage policy and size for the system volume, and then click Done.\n\nCommand-line interface\nUse the following command:vinfra service compute k8saas defaults set --labels boot_volume_size=<size>,boot_volume_type=<storage-policy> <version>\n\n--labels <key1=value1,key2=value2,key3=value3...>\n\nArbitrary labels in the form of key=value pairs to associate with a cluster:\n\nboot_volume_size=<size>: set the size for the Kubernetes system volume\nboot_volume_type=<storage-policy>: set the storage policy for the Kubernetes system volume\n\n<version>\n\nKubernetes version to apply new defaults for.\n\nFor example, to change the size of the Kubernetes system volume to 30 GiB and use the mypolicy storage policy for it, for all Kubernetes versions, run:# vinfra service compute k8saas defaults set --labels boot_volume_size=30,boot_volume_type=mypolicy\nTo set these parameters only for version 1.24.3, append the version number to the command:# vinfra service compute k8saas defaults set --labels boot_volume_size=30,boot_volume_type=mypolicy v1.24.3\n\nSee also\n\nChanging Kubernetes node flavors\n\nConfiguring Kubernetes load balancers\n\nConfiguring Kubernetes DNS and discovery parameters",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute k8saas defaults set --labels boot_volume_size=<size>,boot_volume_type=<storage-policy> <version>\n\n--labels <key1=value1,key2=value2,key3=value3...>\n\n\nArbitrary labels in the form of key=value pairs to associate with a cluster:\n\nboot_volume_size=<size>: set the size for the Kubernetes system volume\nboot_volume_type=<storage-policy>: set the storage policy for the Kubernetes system volume\n\n\n<version>\n\nKubernetes version to apply new defaults for.\n\nFor example, to change the size of the Kubernetes system volume to 30 GiB and use the mypolicy storage policy for it, for all Kubernetes versions, run:# vinfra service compute k8saas defaults set --labels boot_volume_size=30,boot_volume_type=mypolicy\nTo set these parameters only for version 1.24.3, append the version number to the command:# vinfra service compute k8saas defaults set --labels boot_volume_size=30,boot_volume_type=mypolicy v1.24.3\n",
                "title": "To change the system volume parameters"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nClick Settings on the Kubernetes clusters screen.\n\nSet the desired storage policy and size for the system volume, and then click Done.\n\n\n\n\n\n\n",
                "title": "To change the system volume parameters"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-kubernetes-system-volume.html"
    },
    {
        "title": "DELETE service ostor-users",
        "content": "DELETE service ostor-users\nDescription\nDeletes the user specified by email or ID.\n\nObjects and buckets owned by a deleted user are unaffected and continue to be stored in the system.\n\nRequests\nSyntaxDELETE /?ostor-users&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nDELETE service ostor-users parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nYes*\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nErrors\nReturns Error Code 400 if more than one required parameter is set.\nIf a user is successfully deleted, Status204NoContent is returned.\nExamples\nSample request\nDeletes the user with the email test@test.test.DELETE /?ostor-users&emailAddress=test@test.test HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 30 Apr 2016 22:32:00 GMT\r\nAuthorization: <authorization_string>\nSample responseHTTP/1.1 203 No Content\r\nx-amz-req-time-micros : 172807\r\nServer : nginx/1.8.1\r\nConnection : closed\r\nx-amz-request-id : 80000000000000030005c8ca5862476a\r\nDate : Wed, 30 Apr 2016 22:32:03 GMT\r\nContent-type : application/xml",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/delete-service-ostor-users.html"
    },
    {
        "title": "Preparing the environment",
        "content": "Preparing the environment\nExamples in this chapter use cURL for authentication as well as GET, PUT, POST, and DELETE requests run in Bash. To make sending requests easier, you can create the following script ~/.s3_environment, replacing s3_key with S3AcessKeyId and s3_secret with S3SecretAccessKey of a system user:# S3 login variables.\r\ns3_key=\"a14040e0b2ef8b28FZZ8\"\r\ns3_secret=\"dbwTnQTW602aAAdq8DQVFzB6yrTCFTNiGB8C8RFA\"\r\n\r\n# Sign S3 requests and run curl.\r\nfunction s3_curl() {\r\n\r\n    # Parse command line.\r\n    [ -z \"${2}\" ] && {\r\n        echo \"Usage: ${FUNCNAME[0]} <request_type> <s3_url>\"\r\n        return 1\r\n    }\r\n\r\n    # Prepare a signature.\r\n    s3_url=\"${2%/*}\"\r\n    s3_host=\"${s3_url##*://}\"\r\n    s3_query=\"${2##*/}\"\r\n    s3_date=\"$(date -R)\"\r\n\r\n    # Generate a signature.\r\n    s3_signature=\"$(echo -en \"${1}\\n\\n\\n${s3_date}\\n/${s3_query%%&*}\" |\\\r\n        openssl dgst -sha1 -hmac ${s3_secret} -binary | base64)\"\r\n\r\n    # Make the request.\r\n    curl -H \"Host: ${s3_host}\" \\\r\n         -H \"Accept: */*\" \\\r\n         -H \"Date: ${s3_date}\" \\\r\n         -H \"Authorization: AWS ${s3_key}:${s3_signature}\" \\\r\n         -X \"${1}\" \\\r\n         \"${s3_url}/${s3_query}\"\r\n}\r\n\nLoad the script into your default environment to make the s3_curl function available.# source ~/.s3_environment\r\n\nOnce the script is loaded, you can make S3 requests using s3_curl.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/preparing-the-environment.html"
    },
    {
        "title": "11.1. Connecting to Authentication Servers\u00c2\u00b6",
        "content": "11.1. Connecting to Authentication Servers | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n11.1. Connecting to Authentication Servers\u00c2\u00b6\nThe Connection Broker can authenticate users against Microsoft Active Directory and OpenLDAP authentication servers. To authenticate users, you first register your domain with your Connection Broker.\n\nGo to the Setup > Authentication Servers menu.\nClick the Add Authentication Server link.\nIn the Add Authentication Server form, select Active Directory from the Type drop-down list.\nEnter the name for this server in the Connection Broker in the Authentication Server name edit field, as shown in the below image.\nIn the Domain edit field, enter the domain name associated with this Active Directory server.\n\nIn the Connection Settings section, shown in the following figure, use the following procedure to integrate with your Active Directory authentication server.\n\nFrom the Specify address using drop-down menu, select Hostname or IP address.\nEnter the authentication server hostname or IP address in the Hostname or IP address edit field.\nEnter the port number in the Port edit field.\nCheck the Encrypt connection to authentication server using SSL (LDAPS) checkbox if you need a secure connection to the authentication server.\n\nIn the Search Settings section, shown in the following figure, enter the username and password for an account that has read access to the user records. Leostream does not need full administrator rights to your Active Directory authentication server.\n\nIn the User Login Search section, ensure that the Match Login name against this field edit field is set to sAMAccountName. This is the attribute that the Connection Broker uses to locate the user in the authentication server, based on the information the user enters when logging into Leostream.\nClick Save.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-external-systems/connecting-authenticating-servers.html"
    },
    {
        "title": "Placement modes",
        "content": "Placement modes\nPlacements for compute nodes have two modes: hard and soft. The hard mode is the default one. To better understand how these modes work, let's consider an example when a system administrator creates placements and assigns them to images, flavors, and nodes as follows:\n\nIn the figure above:\n\nPlacement1 in the hard mode is assigned to the Win2k19 image and the nodes Node1, Node2, and Node4.\nPlacement2 in the soft mode is assigned to the Win10 image and the nodes Node5, Node6, and Node7.\nPlacement3 in the soft mode is assigned to the Medium flavor and the nodes Node4, Node6, and Node7.\nPlacement4 in the hard mode is assigned to the Large flavor and the nodes Node1, Node3, Node5, and Node6.\nThe Linux image, the Small flavor, and node Node8 have no placements assigned.\n\nWhen a user starts creating virtual machines, they inherit placements from the selected images and flavors. Depending on its placement mode, a virtual machine can be placed on different nodes.\nVirtual machines with the hard placement mode\nWith the hard placement mode, a virtual machine is placed on a node that has exactly the same placements as the virtual machine.\n\nIn the figure above:\n\nVM1 is created from the Win2k19 image with Placement1 and the Large flavor with Placement4. The VM inherits Placement1 and Placement4 in the hard mode. VM1 can be placed only on Node1 because only this node has both Placement1 and Placement4 assigned.\nVM2 is created from the Win2k19 image with Placement1 and the Small flavor without placements. The VM inherits Placement1 in the hard mode. VM2 can be placed only on Node2 because only this node has single Placement1 assigned.\nVM3 is created from the Linux image without placements and with the Large flavor with Placement4. The VM inherits Placement4 in the hard mode. VM3 can be placed only on Node3 because only this node has single Placement4 assigned.\n\nVirtual machines with the soft placement mode\nWith the soft placement mode, a VM is placed on a node that has at least the same placements as the VM.\n\nIn the figure above:\n\nVM4 is created from the Win10 image with Placement2 and the Medium flavor with Placement3. The VM inherits Placement2 and Placement3 in the soft mode. VM4 can be placed on Node6 and Node7 because these nodes have both Placement2 and Placement3 assigned.\nVM5 is created from the Win10 image with Placement2 and the Small flavor without placements. The VM inherits Placement2 in the soft mode. VM5 can be placed Node5, Node6, and Node7 because all of these nodes have Placement2 assigned.\nVM6 is created from the Linux image without placements and with the Medium flavor with Placement3. The VM inherits Placement3 in the soft mode. VM6 can be placed on Node4, Node6, and Node7 because all of these nodes have Placement3 assigned.\n\nVirtual machines with both placement modes and without placements\nA VM can have placements in the both soft and hard modes. In this case, VM placements use the soft mode, that is a VM is placed on a node that has at least the same placements as the VM.\nWhen a VM has no placements assigned, it can be placed either on a node with placements in the soft mode or on a node that is not added to any placements\n\nIn the figure above:\n\nVM7 is created from the Win2k19 image with Placement1 and the Medium flavor with Placement3. The VM inherits Placement1 in the hard mode and Placement3 in the soft mode. VM7 can be placed on Node4 because only this node has both Placement1 and Placement3 assigned.\nVM8 is created from the Win10 image with Placement2 and the Large flavor with Placement4. The VM inherits Placement4 in the hard mode and Placement2 in the soft mode. VM7 can be placed on Node5 and Node6 because these nodes have both Placement2 and Placement4 assigned.\nVM9 is created from the Linux image without placements and the Small flavor without placements. The VM inherits no placements. VM6 can be placed on Node7 because this node has placements in the soft mode. Also, VM6 can be placed on Node8 because this node has no placements assigned.\n\nWhat's next\n\nCreating placements",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/placement-modes.html"
    },
    {
        "title": "Authentication",
        "content": "Authentication\nManagement request must be authenticated with the AWS Access Key ID corresponding to the S3 system user. You can create system users with the ostor-s3-admin create-user -S command.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/authentication.html"
    },
    {
        "title": "Deleting registrations",
        "content": "Deleting registrations\nYou can unregister backup storage from your Acronis backup software by deleting its registrations. When you delete a registration, backup data remains in backup storage. You can delete your backup data in Acronis Cyber Protect Cloud. If you want to delete the backup data in Virtuozzo Hybrid Infrastructure, destroy the backup storage cluster.\nPrerequisites\n\nThe backup storage cluster is created and registered in the Cloud Management Panel, as described in Provisioning Acronis Backup Storage space.\n\nTo delete a backup storage registration\n\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Registrations tab. \nSelect a backup storage registration, and then click Delete.\n\nIn the Delete registration window:\n\nTo delete the registration and unregister the backup storage from your Acronis backup software, select (Recommended) Gracefully, and then specify the credentials of your administrator account in your backup software.\n\nTo delete the registration but do not unregister the backup storage from your Acronis backup software, select Forcibly, and then enter Delete in the input field.\n\nSelect this option only if you are sure that the backup storage is already unregistered from your Acronis backup software.\n\nClick Delete.\n\nCommand-line interface\nUse the following command:vinfra service backup registration delete [--username <username>] [--stdin] [--force]\r\n                                          <registration>\n\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--stdin\n\nUse for setting registration password from stdin.\n--force\n\nForcibly delete the registration but do not unregister the backup storage from your Acronis backup software.\n\nChoose this option only if you are sure that the cluster has already been unregistered from your backup software.\n\n<registration>\n\nRegistration ID or name\n\nFor example, to delete the backup storage registration registration2, run:# vinfra service backup registration delete --username account@example.com --stdin registration2\nSpecify the registration password when prompted.\n\nSee also\n\nUpdating registration certificates\n\nWhat's next\n\nReleasing nodes from backup storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup registration delete [--username <username>] [--stdin] [--force]\r\n                                          <registration>\n\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--stdin\n\nUse for setting registration password from stdin.\n--force\n\n\nForcibly delete the registration but do not unregister the backup storage from your Acronis backup software.\n\nChoose this option only if you are sure that the cluster has already been unregistered from your backup software.\n\n\n<registration>\n\nRegistration ID or name\n\nFor example, to delete the backup storage registration registration2, run:# vinfra service backup registration delete --username account@example.com --stdin registration2\nSpecify the registration password when prompted.\n",
                "title": "To delete a backup storage registration"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Registrations tab. \nSelect a backup storage registration, and then click Delete.\n\nIn the Delete registration window:\n\nTo delete the registration and unregister the backup storage from your Acronis backup software, select (Recommended) Gracefully, and then specify the credentials of your administrator account in your backup software.\n\nTo delete the registration but do not unregister the backup storage from your Acronis backup software, select Forcibly, and then enter Delete in the input field.\n\nSelect this option only if you are sure that the backup storage is already unregistered from your Acronis backup software.\n\n\n\n\nClick Delete.\n\n",
                "title": "To delete a backup storage registration"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/deleting-registrations.html"
    },
    {
        "title": "Listing volumes of virtual machines",
        "content": "Listing volumes of virtual machinesGET /servers/{server_id}/os-volume_attachments\r\n\nList volumes that are attached to the given virtual machine.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=list-volume-attachments-for-an-instance-detail#list-volume-attachments-for-an-instance\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nlimit (Optional)\nquery\ninteger\nUsed in conjunction with offset to return a slice of items. limit\r\nis the maximum number of items to return. If limit is not specified,\r\nor exceeds the configurable max_limit, then max_limit will be\r\nused instead.\n\noffset (Optional)\nquery\ninteger\nUsed in conjunction with limit to return a slice of items. offset\r\nis where to start in the list.\n\nExample\nList all volumes that are attached to a VM with the specified ID.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/b906404c55bb44729da99987536ac5bc/servers/0785ee80-1eca-426b-b8c4-5b499fc7f614/os-volume_attachments\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvolumeAttachments\n\nbody\narray\nThe list of volume attachments.\n\ndevice\n\nbody\nstring\nName of the device such as, /dev/vdb.\n\nid\n\nbody\nstring\nThe UUID of the volume.\n\nserverId (Optional)\nbody\nstring\nThe UUID of the server.\n\nvolumeId (Optional)\nbody\nstring\nThe UUID of the attached volume.\n\ntag\n\nbody\nstring\n\nThe device tag applied to the volume block device or null.\nNew in version 2.70\n\ndelete_on_termination\n\nbody\nboolean\n\nA flag indicating if the attached volume will be deleted when the server is\r\ndeleted.\nNew in version 2.79\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"volumeAttachments\": [\r\n    {\r\n      \"device\": \"/dev/vdb\",\r\n      \"serverId\": \"0785ee80-1eca-426b-b8c4-5b499fc7f614\",\r\n      \"id\": \"16cd801e-f3c1-4cac-aa6c-aecf22642a89\",\r\n      \"volumeId\": \"16cd801e-f3c1-4cac-aa6c-aecf22642a89\"\r\n    }, \r\n    {\r\n      \"device\": \"/dev/vda\",\r\n      \"serverId\": \"0785ee80-1eca-426b-b8c4-5b499fc7f614\",\r\n      \"id\": \"57a6d81f-520b-4bb1-9fcd-1117ae56b9fb\",\r\n      \"volumeId\": \"57a6d81f-520b-4bb1-9fcd-1117ae56b9fb\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-volumes-of-virtual-machines.html"
    },
    {
        "title": "Managing router interfaces",
        "content": "Managing router interfaces\nPrerequisites\n\nYou have a virtual router created, as described in Managing virtual routers.\n\nTo add an external router interface\n\nIf you already have an external gateway, remove the existing one first.\nOn the Routers screen, click the router name. Open the Interfaces tab to view the list of its interfaces.\nClick Add on the toolbar, or click Add interface if there are no interfaces to show.\n\nIn the Add interface window, do the following:\n\nSelect External gateway.\nFrom the Network drop-down menu, select a physical network to connect to the router. The new interface will pick an unused IP address from the selected physical network. You can also provide a specific IP address from the selected physical network to assign to the interface in the IP address field.\n\nSelect or deselect the SNAT check box to enable or disable SNAT on the external gateway of the router. With SNAT enabled, the router replaces VM private IP addresses with the public IP address of its external gateway.\n\nClick Add.\n\nTo add an internal router interface\n\nOn the Routers screen, click the router name to open the list of its interfaces.\nClick Add.\n\nIn the Add interface window, select a network to connect to the router from the Network drop-down menu. The new interface will attempt to use the gateway IP address of the selected virtual network by default. If it is in use, specify an unused IP address from the selected virtual network to assign to the interface in the IP address field.\n\nClick Add.\n\nTo edit external interface parameters\n\nClick the ellipsis icon next to the external interface, and then click Edit. \nIn the Edit interface window, change the  IP address or configure SNAT. \nClick Save to save your changes.\n\nTo remove a router interface \n\nSelect the interface you want to remove.\nClick the ellipsis icon next to it, and then click Delete.\nIn the confirmation window, click Delete.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-router-interfaces.html"
    },
    {
        "title": "Connecting remote iSCSI devices to cluster nodes",
        "content": "Connecting remote iSCSI devices to cluster nodes\nVirtuozzo Hybrid Infrastructure allows you to connect remote iSCSI devices to nodes and perceives their LUNs as storage disks. You can connect iSCSI devices to nodes at any time. \nAfter the iSCSI device is connected to a cluster node, you need to assign the Storage disk role to all its LUNs. Even though you can assign the Metadata or Cache roles to such disks, it is only supported for single-node installations of backup storage with SAN-provided redundancy.\nLimitations\n\nRemote iSCSI devices that are connected to cluster nodes as storage disks can only be used for backup storage. Do not use such disks for other services, including the compute service. To learn how to connect external iSCSI devices to the compute cluster, refer to Attaching external iSCSI storage.\niSCSI targets can only be used for storage if they have synchronous writes enabled.\nRemote iSCSI devices cannot be attached to hosts that belong to iSCSI target groups.\nOnly one IQN can be used per node. You can connect multiple iSCSI targets by using other cluster nodes.\nAn iSCSI IQN name may contain only lowercase letters, numbers, periods, colons, and dashes. Allowed characters for iSCSI names are described in String Profile for iSCSI Names.\n\nPrerequisites\n\nIf you have restricted outbound traffic in your cluster, you need to manually add a rule that will allow outbound traffic on the specified port, as described in Configuring outbound firewall rules.\n\nTo connect a remote iSCSI device to a node\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the required node name. On the Disks tab, click iSCSI target.\n\nIn the Remote iSCSI Target window:\n\nSpecify the IQN of the target.\nIn the Portal and Port fields, specify the target\u00e2\u0080\u0099s IP address and, optionally, specify a port number.\n\nTo enable CHAP authentication for the target, select CHAP authentication and specify the credentials.\n\nClick Connect.\n\nThe target will be connected and all of its LUNs will be initiated. Devices of the iSCSI type will appear in the node\u00e2\u0080\u0099s Disks list.\n\nIf you add another LUN to a connected target, rescan it by running iscsiadm -m node -R in the host\u00e2\u0080\u0099s console.\n\nCommand-line interface\nUse the following command:vinfra node iscsi target add [--auth-username <auth-username>] [--auth-password <auth-password>]\r\n                             --portal <portal> --node <node> <target-name>\r\n\n\n--auth-username <auth-username>\n\nUser name\n--auth-password <auth-password>\n\nUser password\n--portal <portal>\n\nPortal IP address in the format IP:port (this option can be specified multiple times)\n--node <node>\n\nNode ID or hostname\n<target-name>\n\nTarget name\n\nFor example, to connect the iSCSI target iqn.2014-06.com.vstorage:target1 with the IP address 172.16.24.244 and port 3260 to the node node003, run:# vinfra node iscsi target add iqn.2014-06.com.vstorage:target1 --portal 172.16.24.244:3260 --node node003\n\nTo assign disk roles to iSCSI LUNs\n\nAdmin panel\n\nSelect a disk with the iSCSI type, and then click Assign.\nIn the Choose role window, select Storage, and then click Done.\nRepeat the above steps for every disk with the iSCSI type.\n\nCommand-line interface\nUse the following command:vinfra node disk assign --disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>] [--node <node>]\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n\nFor example, to assign the storage role to the iSCSI disk sde, run:# vinfra node disk assign --disk sde:cs:tier=0 --node node003\n\nTo remove an iSCSI target\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the required node name. On the Disks tab, click iSCSI target.\n\nIn the Remote iSCSI Target window, click Delete connection, and then click Delete to confirm.\n\nCommand-line interface\nUse the following command:vinfra node iscsi target delete --node <node> <target-name>\r\n\n\n--node <node>\n\nNode ID or hostname\n<target-name>\n\nTarget name\n\nFor example, to disconnect the iSCSI target iqn.2014-06.com.vstorage:target1 from the node node003, run:# vinfra node iscsi target delete iqn.2014-06.com.vstorage:target1 --node node003\r\n\n\nSee also\n\nConfiguring new disks manually",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iscsi target add [--auth-username <auth-username>] [--auth-password <auth-password>]\r\n                             --portal <portal> --node <node> <target-name>\r\n\n\n--auth-username <auth-username>\n\nUser name\n--auth-password <auth-password>\n\nUser password\n--portal <portal>\n\nPortal IP address in the format IP:port (this option can be specified multiple times)\n--node <node>\n\nNode ID or hostname\n<target-name>\n\nTarget name\n\nFor example, to connect the iSCSI target iqn.2014-06.com.vstorage:target1 with the IP address 172.16.24.244 and port 3260 to the node node003, run:# vinfra node iscsi target add iqn.2014-06.com.vstorage:target1 --portal 172.16.24.244:3260 --node node003\n",
                "title": "To connect a remote iSCSI device to a node"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node disk assign --disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>] [--node <node>]\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n\nFor example, to assign the storage role to the iSCSI disk sde, run:# vinfra node disk assign --disk sde:cs:tier=0 --node node003\n",
                "title": "To assign disk roles to iSCSI LUNs"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iscsi target delete --node <node> <target-name>\r\n\n\n--node <node>\n\nNode ID or hostname\n<target-name>\n\nTarget name\n\nFor example, to disconnect the iSCSI target iqn.2014-06.com.vstorage:target1 from the node node003, run:# vinfra node iscsi target delete iqn.2014-06.com.vstorage:target1 --node node003\r\n\n",
                "title": "To remove an iSCSI target"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOn the Infrastructure > Nodes screen, click the required node name. On the Disks tab, click iSCSI target.\n\n\nIn the Remote iSCSI Target window:\n\nSpecify the IQN of the target.\nIn the Portal and Port fields, specify the target\u00e2\u0080\u0099s IP address and, optionally, specify a port number.\n\nTo enable CHAP authentication for the target, select CHAP authentication and specify the credentials.\n\nClick Connect.\n\n\n\n\n\n\n\nThe target will be connected and all of its LUNs will be initiated. Devices of the iSCSI type will appear in the node\u00e2\u0080\u0099s Disks list.\n\nIf you add another LUN to a connected target, rescan it by running iscsiadm -m node -R in the host\u00e2\u0080\u0099s console.\n\n",
                "title": "To connect a remote iSCSI device to a node"
            },
            {
                "example": "\nAdmin panel\n\nSelect a disk with the iSCSI type, and then click Assign.\nIn the Choose role window, select Storage, and then click Done.\nRepeat the above steps for every disk with the iSCSI type.\n\n",
                "title": "To assign disk roles to iSCSI LUNs"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the required node name. On the Disks tab, click iSCSI target.\n\nIn the Remote iSCSI Target window, click Delete connection, and then click Delete to confirm.\n\n\n\n\n",
                "title": "To remove an iSCSI target"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/connecting-remote-iscsi-devices.html"
    },
    {
        "title": "Creating virtual machines",
        "content": "Creating virtual machinesPOST /servers\r\n\nCreate a virtual machine.\nThe progress of this operation depends on the location of the\r\nrequested image, network I/O, host load, selected flavor, and other\r\nfactors.\nTo check the progress of the request, make a GET /servers/{id}\r\nrequest. This call returns a progress attribute, which is a percentage\r\nvalue from 0 to 100.\nWhen you create a server, the response shows only the server ID, its\r\nlinks, and the admin password. You can get additional attributes\r\nthrough subsequent GET requests on the server.\nInclude the block_device_mapping_v2 parameter in the create\r\nrequest body to boot a server from a volume.\nInclude the key_name parameter in the create request body to add a\r\nkey pair to the server when you create it. Creating key pairs is described in Creating and importing SSH keys.\n\nStarting with the microversion 2.37, the networks field is required.\n\nPreconditions:\n\nThe user must have sufficient server quota to create the number of\r\nservers requested.\nThe connection to the image service must be valid.\n\nAsynchronous postconditions:\n\nWith correct permissions, you can see the server status as\r\nACTIVE through API calls.\nWith correct access, you can see the created server in the compute\r\nnode that OpenStack Compute manages.\n\nTroubleshooting:\n\nIf the server status remains BUILDING or shows another error\r\nstatus, the request failed. Ensure you meet the preconditions then\r\ninvestigate the compute node.\nThe server is not created in the compute node that OpenStack Compute\r\nmanages.\nThe compute node needs enough free resource to match the resource of\r\nthe server creation request.\nEnsure that the scheduler selection filter can fulfill the request\r\nwith the available compute nodes that match the selection criteria\r\nof the filter.\n\nSource: https://docs.openstack.org/api-ref/compute/?expanded=create-server-detail#create-server\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver\n\nbody\nobject\nA server object.\n\nflavorRef\n\nbody\nstring\nThe flavor reference, as an ID (including a UUID) or full URL,\r\nfor the flavor for your server instance.\n\nname\n\nbody\nstring\nThe server name.\n\nnetworks\n\nbody\narray\n\nA list of network object. Required parameter when there are multiple\r\nnetworks defined for the tenant. When you do not specify the networks\r\nparameter, the server attaches to the only network created for the\r\ncurrent tenant.  Optionally, you can create one or more NICs on the server.\r\nTo provision the server instance with a NIC for a network, specify\r\nthe UUID of the network in the uuid attribute in a networks\r\nobject.  To provision the server instance with a NIC for an already\r\nexisting port, specify the port-id in the port attribute in a\r\nnetworks object.\nIf multiple networks are defined, the order in which they appear in the\r\nguest operating system will not necessarily reflect the order in which they\r\nare given in the server boot request. Guests should therefore not depend\r\non device order to deduce any information about their network devices.\r\nInstead, device role tags should be used: introduced in 2.32, broken in\r\n2.37, and re-introduced and fixed in 2.42, the tag is an optional,\r\nstring attribute that can be used to assign a tag to a virtual network\r\ninterface. This tag is then exposed to the guest in the metadata API and\r\nthe config drive and is associated to hardware metadata for that network\r\ninterface, such as bus (ex: PCI), bus address (ex: 0000:00:02.0), and MAC\r\naddress.\nA bug has caused the tag attribute to no longer be accepted starting\r\nwith version 2.37. Therefore, network interfaces could only be tagged in\r\nversions 2.32 to 2.36 inclusively. Version 2.42 has restored the tag\r\nattribute.\nStarting with microversion 2.37, this field is required and the special\r\nstring values auto and none can be specified for networks. auto\r\ntells the Compute service to use a network that is available to the\r\nproject, if one exists. If one does not exist, the Compute service will\r\nattempt to automatically allocate a network for the project (if possible).\r\nnone tells the Compute service to not allocate a network for the\r\ninstance. The auto and none values cannot be used with any other\r\nnetwork values, including other network uuids, ports, fixed IPs or device\r\ntags. These are requested as strings for the networks value, not in a\r\nlist. See the associated example.\n\nnetworks.uuid (Optional)\nbody\nstring\n\nTo provision the server instance with a NIC for a network, specify the UUID of\r\nthe network in the uuid attribute in a networks object. Required if you\r\nomit the port attribute.\nStarting with microversion 2.37, this value is strictly enforced to be in\r\nUUID format.\n\nnetworks.port (Optional)\nbody\nstring\nTo provision the server instance with a NIC for an already existing port,\r\nspecify the port-id in the port attribute in a networks object.\r\nThe port status must be DOWN. Required if you omit the uuid\r\nattribute. Requested security groups are not applied to pre-existing ports.\n\nnetworks.fixed_ips (Optional)\nbody\narray\nFixed IP addresses.  If you request a specific fixed IP address without\r\na network\u00e2\u0080\u0099s uuid or net_id, the request returns a Bad Request (400) \r\nresponse code.\n\nnetworks.ip_address (Optional)\nbody\nstring\nThe IP address.\n\nnetworks.ip_version (Optional)\nbody\ninteger\nThe IP protocol version. Valid value is 4 or\r\n6. Default is 4.\n\nnetworks.port_security_enabled\n\nbody\nboolean\n\nThe port security status of the network. Valid values are\r\nenabled (true) and disabled (false).\r\nThis value is used as the default value of port_security_enabled\r\nfield of a newly created port.\nNew in version 2.42\n\nnetworks.security_groups\n\nbody\narray\n\nThe IDs of security groups applied to the port.\nNew in version 2.67\n\nnetworks.tag (Optional)\nbody\nstring\n\nA device role tag that can be applied to a network interface. The guest OS\r\nof a server that has devices tagged in this manner can access hardware\r\nmetadata about the tagged devices from the metadata API and on the config\r\ndrive, if enabled.\n\nDue to a bug, network interface tags are accepted between 2.32\r\nand 2.36 inclusively, and subsequently starting with version 2.42.\n\nNew in version 2.32\n\naccessIPv4 (Optional)\nbody\nstring\nIPv4 address that should be used to access this server.\n\naccessIPv6 (Optional)\nbody\nstring\nIPv6 address that should be used to access this server.\n\nadminPass (Optional)\nbody\nstring\nThe administrative password of the server. If you omit this parameter, the operation\r\ngenerates a new password.\n\navailability_zone (Optional)\nbody\nstring\n\nThe availability zone from which to launch the server. When you\r\nprovision resources, you specify from which availability zone you\r\nwant your instance to be built.  Typically, an admin user will use\r\navailability zones to arrange OpenStack compute hosts into logical\r\ngroups.\nAn availability zone provides a form of physical isolation and redundancy from\r\nother availability zones. For instance, if some racks in your data center are\r\non a separate power source, you can put servers in those racks in their own availability\r\nzone. Availability zones can also help separate different classes of hardware.  By\r\nsegregating resources into availability zones, you can ensure that your application\r\nresources are spread across disparate machines to achieve high availability in\r\nthe event of hardware or other failure. See\r\nAvailability Zones (AZs) for more information.\nYou can list the available availability zones by calling the\r\nos-availability-zone API, but you should avoid using the default\r\navailability zone\r\nwhen creating the server.  The default availability zone is named nova.\r\nThis AZ is only shown when listing the availability zones as an admin.\n\nblock_device_mapping_v2 (Optional)\nbody\narray\n\nEnables fine grained control of the block device mapping for an instance. This\r\nis typically used for booting servers from volumes.  An example format would look\r\nas follows:\"block_device_mapping_v2\": [{\r\n    \"boot_index\": \"0\",\r\n    \"uuid\": \"ac408821-c95a-448f-9292-73986c790911\",\r\n    \"source_type\": \"image\",\r\n    \"volume_size\": \"25\",\r\n    \"destination_type\": \"volume\",\r\n    \"delete_on_termination\": true,\r\n    \"tag\": \"disk1\",\r\n    \"disk_bus\": \"scsi\"}]\nIn microversion 2.32, tag is an optional string attribute that can\r\nbe used to assign a tag to the block device. This tag is then exposed to\r\nthe guest in the metadata API and the config drive and is associated to\r\nhardware metadata for that block device, such as bus (ex: SCSI), bus\r\naddress (ex: 1:0:2:0), and serial.\nA bug has caused the tag attribute to no longer be accepted starting\r\nwith version 2.33. It has been restored in version 2.42.\n\nblock_device_mapping_v2.boot_index\n\nbody\ninteger\nDefines the order in which a hypervisor tries devices when it attempts to boot\r\nthe guest from storage.  Give each device a unique boot index starting from 0.\r\nTo disable a device from booting, set the boot index to a negative value or use\r\nthe default boot index value, which is None.  The simplest usage is, set the\r\nboot index of the boot device to 0 and use the default boot index value, None,\r\nfor any other devices. Some hypervisors might not support booting from multiple\r\ndevices; these hypervisors consider only the device with a boot index of 0.  Some\r\nhypervisors support booting from multiple devices but only if the devices are\r\nof different types. For example, a disk and CD-ROM.\n\nblock_device_mapping_v2.delete_on_termination (Optional)\nbody\nboolean\nTo delete the boot volume when the server is destroyed, specify true.\r\nOtherwise, specify false. Default: false\n\nblock_device_mapping_v2.destination_type (Optional)\nbody\nstring\n\nDefines where the block device mapping will reside. Valid values are:\n\nlocal: The ephemeral disk resides local to the compute host on\r\nwhich the server runs\nvolume: The persistent volume is stored in the block storage service\n\nblock_device_mapping_v2.device_name (Optional)\nbody\nstring\nA path to the device for the volume that you want to use to boot the server.\r\nNote that as of the 12.0.0 Liberty release, the Nova libvirt driver no\r\nlonger honors a user-supplied device name. This is the same behavior as if\r\nthe device name parameter is not supplied on the request.\n\nblock_device_mapping_v2.device_type (Optional)\nbody\nstring\nThe device type. For example, disk, cdrom.\n\nblock_device_mapping_v2.disk_bus (Optional)\nbody\nstring\nDisk bus type, some hypervisors (currently only libvirt) support\r\nspecify this parameter. Some example disk_bus values can be: fdc,\r\nide, sata, scsi, usb, virtio, xen, lxc\r\nand uml. Support for each bus type depends on the virtualization driver\r\nand underlying hypervisor.\n\nblock_device_mapping_v2.guest_format (Optional)\nbody\nstring\n\nSpecifies the guest server disk file system format, such as ext2,\r\next3, ext4, xfs or swap.\nSwap block device mappings have the following restrictions:\n\nThe source_type must be blank\nThe destination_type must be local\nThere can only be one swap disk per server\nThe size of the swap disk must be less than or equal to the swap\r\nsize of the flavor\n\nblock_device_mapping_v2.no_device (Optional)\nbody\nboolean\nIt is no device if True.\n\nblock_device_mapping_v2.source_type (Optional)\nbody\nstring\n\nThe source type of the block device. Valid values are:\n\nblank: Depending on the destination_type and guest_format,\r\nthis will either be a blank persistent volume or an ephemeral (or swap)\r\ndisk local to the compute host on which the server resides\nimage: This is only valid with destination_type=volume; creates\r\nan image-backed volume in the block storage service and attaches it to\r\nthe server\nsnapshot: This is only valid with destination_type=volume;\r\ncreates a volume backed by the given volume snapshot referenced via the\r\nblock_device_mapping_v2.uuid parameter and attaches it to the server\nvolume: This is only valid with destination_type=volume; uses\r\nthe existing persistent volume referenced via the\r\nblock_device_mapping_v2.uuid parameter and attaches it to the server\n\nThis parameter is required unless block_device_mapping_v2.no_device is\r\nspecified.\nSee Block Device Mapping in Nova\r\nfor more details on valid source and destination types.\n\nblock_device_mapping_v2.uuid (Optional)\nbody\nstring\nThis is the uuid of source resource. The uuid points to different resources\r\nbased on the source_type. For example, if source_type is image,\r\nthe block device is created based on the specified image which is retrieved\r\nfrom the image service. Similarly, if source_type is snapshot then\r\nthe uuid refers to a volume snapshot in the block storage service. If\r\nsource_type is volume then the uuid refers to a volume in the block\r\nstorage service.\n\nblock_device_mapping_v2.volume_size (Optional)\nbody\ninteger\n\nThe size of the volume (in GiB).\r\nThis is integer value from range 1 to 2147483647\r\nwhich can be requested as integer and string.\r\nThis parameter must be specified in the following cases:\n\nAn image to volume caseblock_device_mapping_v2.source_type is imageblock_device_mapping_v2.destination_type is volume\nA blank to volume caseblock_device_mapping_v2.source_type is blankblock_device_mapping_v2.destination_type is volume\n\nblock_device_mapping_v2.tag (Optional)\nbody\nstring\n\nA device role tag that can be applied to a block device. The guest OS of a\r\nserver that has devices tagged in this manner can access hardware metadata\r\nabout the tagged devices from the metadata API and on the config drive, if\r\nenabled.\n\nDue to a bug, block device tags are accepted in version 2.32 and\r\nsubsequently starting with version 2.42.\n\nNew in version 2.32\n\nblock_device_mapping_v2.volume_type (Optional)\nbody\nstring\n\nThe device volume_type. This can be used to specify the type of volume\r\nwhich the compute service will create and attach to the server.\r\nIf not specified, the block storage service will provide a default volume\r\ntype. See the block storage volume types API\r\nfor more details.\r\nThere are some restrictions on volume_type:\n\nIt can be a volume type ID or name.\nIt is only supported with source_type of blank, image or\r\nsnapshot.\nIt is only supported with destination_type of volume.\n\nNew in version 2.67\n\nconfig_drive (Optional)\nbody\nboolean\nIndicates whether a config drive enables metadata injection. The config_drive\r\nsetting provides information about a drive that the instance can mount at boot\r\ntime. The instance reads files from the drive to get information that is normally\r\navailable through the metadata service. This metadata is different from the user\r\ndata. Not all cloud providers enable the config_drive. Read more in the\r\nOpenStack End User Guide.\n\nimageRef (Optional)\nbody\nstring\nThe UUID of the image to use for your server instance.\r\nThis is not required in case of boot from volume.\r\nIn all other cases it is required and must be a valid UUID\r\notherwise API will return 400.\n\nkey_name (Optional)\nbody\nstring\n\nKey pair name.\n\nThe null value was allowed in the Nova legacy v2 API,\r\nbut due to strict input validation, it is not allowed in\r\nthe Nova v2.1 API.\n\nmetadata (Optional)\nbody\nobject\nMetadata key and value pairs. The maximum size of the metadata key and value is\r\n255 bytes each.\n\nOS-DCF:diskConfig (Optional)\nbody\nstring\n\nControls how the API partitions the disk when you create, rebuild, or resize servers.\r\nA server inherits the OS-DCF:diskConfig value from the image from which it\r\nwas created, and an image inherits the OS-DCF:diskConfig value from the server\r\nfrom which it was created. To override the inherited setting, you can include\r\nthis attribute in the request body of a server create, rebuild, or resize request.  If\r\nthe OS-DCF:diskConfig value for an image is MANUAL, you cannot create\r\na server from that image and set its OS-DCF:diskConfig value to AUTO.\r\nA valid value is:\n\nAUTO. The API builds the server with a single partition the size of the\r\ntarget flavor disk. The API automatically adjusts the file system to fit the\r\nentire partition.\nMANUAL. The API builds the server by using whatever partition scheme and\r\nfile system is in the source image. If the target flavor disk is larger, the API\r\ndoes not partition the remaining disk space.\n\npersonality (Optional)\nbody\narray\n\nThe file path and contents, text only, to inject into the server at launch. The\r\nmaximum size of the file path data is 255 bytes. The maximum limit is the number\r\nof allowed bytes in the decoded, rather than encoded, data.\nAvailable until version 2.56\n\nuser_data (Optional)\nbody\nstring\n\nConfiguration information or scripts to use upon launch.\r\nMust be Base64 encoded. Restricted to 65535 bytes.\n\nThe null value allowed in Nova legacy v2 API, but due to the strict\r\ninput validation, it isn\u00e2\u0080\u0099t allowed in Nova v2.1 API.\n\ndescription (Optional)\nbody\nstring\n\nA free form description of the server. Limited to 255 characters\r\nin length. Before microversion 2.19 this was set to the server\r\nname.\nNew in version 2.19\n\ntags (Optional)\nbody\narray\n\nA list of tags. Tags have the following restrictions:\n\nTag is a Unicode bytestring no longer than 60 characters.\nTag is a non-empty string.\n\u00e2\u0080\u0098/\u00e2\u0080\u0099 is not allowed to be in a tag name\nComma is not allowed to be in a tag name in order to simplify\r\nrequests that specify lists of tags\nAll other characters are allowed to be in a tag name\nEach server can have up to 50 tags.\n\nNew in version 2.52\n\ntrusted_image_certificates (Optional)\nbody\narray\n\nA list of trusted certificate IDs, which are used during image\r\nsignature verification to verify the signing certificate. The list is\r\nrestricted to a maximum of 50 IDs. This parameter is optional in server\r\ncreate requests if allowed by policy, and is not supported for\r\nvolume-backed instances.\nNew in version 2.63\n\nhost (Optional)\nbody\nstring\n\nThe name of the compute service host on which the server is to be created.\r\nThe API will return 400 if no compute services are found with the given\r\nhost name. By default, it can be specified by administrators only.\nNew in version 2.74\n\nhypervisor_hostname (Optional)\nbody\nstring\n\nThe hostname of the hypervisor on which the server is to be created.\r\nThe API will return 400 if no hypervisors are found with the given\r\nhostname. By default, it can be specified by administrators only.\nNew in version 2.74\n\nos:scheduler_hints (Optional)\nbody\nobject\n\nThe dictionary of data to send to the scheduler. Alternatively, you can specify\r\nOS-SCH-HNT:scheduler_hints as the key in the request body.\n\nThis is a top-level key in the request body, not part of the\r\nserver portion of the request body.\n\nThere are a few caveats with scheduler hints:\n\nThe request validation schema is per hint. For example, some require a\r\nsingle string value, and some accept a list of values.\nHints are only used based on the cloud scheduler configuration, which\r\nvaries per deployment.\nHints are pluggable per deployment, meaning that a cloud can have custom\r\nhints which may not be available in another cloud.\n\nFor these reasons, it is important to consult each cloud\u00e2\u0080\u0099s user\r\ndocumentation to know what is available for scheduler hints.\n\nos:scheduler_hints.build_near_host_ip (Optional)\nbody\nstring\nSchedule the server on a host in the network specified with this parameter\r\nand a CIDR (os:scheduler_hints.cidr).\r\nIt is available when SimpleCIDRAffinityFilter is available\r\non cloud side.\n\nos:scheduler_hints.cidr (Optional)\nbody\nstring\nSchedule the server on a host in the network specified with an IP address\r\n(os:scheduler_hints:build_near_host_ip) and this parameter.\r\nIf os:scheduler_hints:build_near_host_ip is specified and\r\nthis paramete is omitted, /24 is used.\r\nIt is available when SimpleCIDRAffinityFilter is available\r\non cloud side.\n\nos:scheduler_hints.different_cell (Optional)\nbody\narray\nA list of cell routes or a cell route (string).\r\nSchedule the server in a cell that is not specified.\r\nIt is available when DifferentCellFilter is available on cloud side\r\nthat is cell v1 environment.\n\nos:scheduler_hints.different_host (Optional)\nbody\narray\nA list of server UUIDs or a server UUID.\r\nSchedule the server on a different host from a set of servers.\r\nIt is available when DifferentHostFilter is available on cloud side.\n\nos:scheduler_hints.group (Optional)\nbody\nstring\nThe server group UUID. Schedule the server according to a policy of\r\nthe server group (anti-affinity, affinity, soft-anti-affinity\r\nor soft-affinity).\r\nIt is available when ServerGroupAffinityFilter,\r\nServerGroupAntiAffinityFilter, ServerGroupSoftAntiAffinityWeigher,\r\nServerGroupSoftAffinityWeigher are available on cloud side.\n\nos:scheduler_hints.query (Optional)\nbody\nstring\n\nSchedule the server by using a custom filter in JSON format.\r\nFor example:\"query\": \"[\\\">=\\\",\\\"$free_ram_mb\\\",1024]\"\r\n\nIt is available when JsonFilter is available on cloud side.\n\nos:scheduler_hints.same_host (Optional)\nbody\narray\nA list of server UUIDs or a server UUID.\r\nSchedule the server on the same host as another server in a set of\r\nservers.\r\nIt is available when SameHostFilter is available on cloud side.\n\nos:scheduler_hints.target_cell (Optional)\nbody\nstring\nA target cell name. Schedule the server in a host in the cell specified.\r\nIt is available when TargetCellFilter is available on cloud side\r\nthat is cell v1 environment.\n\nExample\nCreate a VM with the specified flavor, from the specified image. Create two NICs in the specified networks, assign one IP address manually and the other one automatically from the IPv4 subnet. The placement will be inherited from the image.# curl -ks -H 'Content-Type: application/json' -H 'X-OpenStack-Nova-API-Version: 2.67' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"server\": {\r\n    \"name\": \"vm2\",\r\n    \"flavorRef\": \"100\",\r\n    \"networks\": [\r\n      {\r\n        \"uuid\": \"0bb6b7a7-da8d-432c-b8d5-12139f7924d1\",\r\n        \"fixed_ips\": [{\"ip_address\": \"192.168.128.10\"}],\r\n        \"port_security_enabled\": true,\r\n        \"security_groups\": [\"5c2f26d9-c599-41db-b67b-b47811b58e28\"]\r\n      },\r\n      {\r\n        \"uuid\": \"17062703-8551-46e3-bf37-5509d9f93462\",\r\n        \"fixed_ips\": [{\"ip_version\": 4}],\r\n        \"port_security_enabled\": true,\r\n        \"security_groups\": [\"5c2f26d9-c599-41db-b67b-b47811b58e28\"]\r\n      }\r\n    ],\r\n    \"block_device_mapping_v2\": [\r\n      {\r\n        \"boot_index\": \"0\",\r\n        \"uuid\": \"c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n        \"source_type\": \"image\",\r\n        \"volume_size\": \"1\",\r\n        \"destination_type\": \"volume\",\r\n        \"delete_on_termination\": true\r\n      }\r\n    ]\r\n  }\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nLocation\n\nheader\nstring\nThe location URL of the server, HTTP header\r\n\u00e2\u0080\u009cLocation: <server location URL>\u00e2\u0080\u009d will be returned.\n\nserver\n\nbody\nobject\nA server object.\n\nid\n\nbody\nstring\nThe UUID of the server.\n\nlinks\n\nbody\narray\nLinks to the resources in question. See API Guide / Links and\r\nReferences\r\nfor more info.\n\nadminPass (Optional)\nbody\nstring\nThe administrative password for the server. If you set enable_instance_password configuration\r\noption to False, the API wouldn\u00e2\u0080\u0099t return the adminPass field in response.\n\nsecurity_groups\n\nbody\narray\nOne or more security groups objects.\n\nsecurity_groups.name\n\nbody\nstring\n\nThe security group name.\n\nOS-DCF:diskConfig\n\nbody\nstring\n\nDisk configuration. The value is either:\n\nAUTO: The API builds the server with a single partition the size of\r\nthe target flavor disk. The API automatically adjusts the file system to\r\nfit the entire partition.\nMANUAL: The API builds the server by using the partition scheme and\r\nfile system that is in the source image. If the target flavor disk is\r\nlarger, The API does not partition the remaining disk space.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"server\": {\r\n    \"security_groups\": [\r\n      {\r\n        \"name\": \"default\"\r\n      }\r\n    ],\r\n    \"OS-DCF:diskConfig\": \"MANUAL\",\r\n    \"id\": \"c3f154f1-c656-49b4-a6c0-4dd1e088817c\",\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/c3f154f1-c656-49b4-a6c0-4dd1e088817c\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/servers/c3f154f1-c656-49b4-a6c0-4dd1e088817c\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"adminPass\": \"54e8z6YWPoEp\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-virtual-machines.html"
    },
    {
        "title": "Monitoring load balancers",
        "content": "Monitoring load balancers\nTo monitor a load balancer\n\nAdmin panel\nOn the Compute > Network > Load balancers tab, select the required load balancer and open the Overview tab. The following charts are available:\n\nMembers state\n\nThe total number of members in the balancing pools grouped by status: \u00e2\u0080\u009cHealthy\u00e2\u0080\u009d, \u00e2\u0080\u009cUnhealthy\u00e2\u0080\u009d, \u00e2\u0080\u009cError\u00e2\u0080\u009d, and \u00e2\u0080\u009cDisabled\u00e2\u0080\u009d.\nNetwork\n\nIncoming and outgoing network traffic.\nActive connections\n\nThe number of active connections.\nError requests\n\nThe number of error requests.\n\nCommand-line interface\nUse the following command:vinfra service compute load-balancer stats <load-balancer>\r\n\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to view the statistics for the load balancer mylbaas, run:# vinfra service compute load-balancer stats mylbaas\r\n+-------+-------------------------------------------------------+\r\n| Field | Value                                                 |\r\n+-------+-------------------------------------------------------+\r\n| stats | active_connections: 0                                 |\r\n|       | bytes_in: 0                                           |\r\n|       | bytes_out: 0                                          |\r\n|       | listeners: null                                       |\r\n|       | loadbalancer_id: 17cfa86f-c374-4ca3-8cd6-f638a5234fe7 |\r\n|       | request_errors: 0                                     |\r\n|       | total_connections: 0                                  |\r\n+-------+-------------------------------------------------------+\r\n\n\nSee also\n\nMonitoring compute nodes\n\nMonitoring virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute load-balancer stats <load-balancer>\r\n\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to view the statistics for the load balancer mylbaas, run:# vinfra service compute load-balancer stats mylbaas\r\n+-------+-------------------------------------------------------+\r\n| Field | Value                                                 |\r\n+-------+-------------------------------------------------------+\r\n| stats | active_connections: 0                                 |\r\n|       | bytes_in: 0                                           |\r\n|       | bytes_out: 0                                          |\r\n|       | listeners: null                                       |\r\n|       | loadbalancer_id: 17cfa86f-c374-4ca3-8cd6-f638a5234fe7 |\r\n|       | request_errors: 0                                     |\r\n|       | total_connections: 0                                  |\r\n+-------+-------------------------------------------------------+\r\n\n",
                "title": "To monitor a load balancer"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nOn the Compute > Network > Load balancers tab, select the required load balancer and open the Overview tab. The following charts are available:\n\nMembers state\n\nThe total number of members in the balancing pools grouped by status: \u00e2\u0080\u009cHealthy\u00e2\u0080\u009d, \u00e2\u0080\u009cUnhealthy\u00e2\u0080\u009d, \u00e2\u0080\u009cError\u00e2\u0080\u009d, and \u00e2\u0080\u009cDisabled\u00e2\u0080\u009d.\nNetwork\n\nIncoming and outgoing network traffic.\nActive connections\n\nThe number of active connections.\nError requests\n\nThe number of error requests.\n\n",
                "title": "To monitor a load balancer"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-load-balancers.html"
    },
    {
        "title": "Generating S3 account access keys via REST API",
        "content": "Generating S3 account access keys via REST API\nYou can generate a new or additional access key pair for the specified account of an S3 user by sending a POST request to the ostor-users service along with the user email address, account name, and the genKey parameter:# s3_curl POST \"http://s3.example.com/?ostor-users&emailAddress=user@email.com&accountName=account&genKey\"\r\n{\r\n  \"UserEmail\": \"user@email.com\",\r\n  \"UserId\": \"b09693b73b3c7686\",\r\n  \"AWSAccessKeys\": [\r\n    {\r\n      \"AWSAccessKeyId\": \"b09693b73b3c7686Z8BU\",\r\n      \"AWSSecretAccessKey\": \"m8PgWFLXPeJVSWojCE3DxWDoRk80g7CMyB7xK3Hd\"\r\n    }\r\n  ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/generating-s3-account-access-keys-via-rest-api.html"
    },
    {
        "title": "Showing project details",
        "content": "Showing project detailsGET /v3/projects/{project_id}\r\n\nShow details of a project with the specified ID.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=show-project-details-detail#show-project-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe project ID.\n\nparents_as_list (Optional)\nquery\nkey-only, no value expected\n\nThe parent hierarchy will be included as a list in the response.\r\nThis list will contain the projects found by traversing up the\r\nhierarchy to the top-level project. The returned list will be\r\nfiltered against the projects the user has an effective role\r\nassignment on.\nNew in version 3.4\n\nsubtree_as_list (Optional)\nquery\nkey-only, no value expected\n\nThe child hierarchy will be included as a list in the response.\r\nThis list will contain the projects found by traversing down\r\nthe hierarchy. The returned list will be filtered against the\r\nprojects the user has an effective role assignment on.\nNew in version 3.4\n\nparents_as_ids (Optional)\nquery\nkey-only, no value expected\n\nThe entire parent hierarchy will be included as\r\nnested dictionaries in the response. It will contain\r\nall projects ids found by traversing up the hierarchy\r\nto the top-level project.\nNew in version 3.4\n\nsubtree_as_ids (Optional)\nquery\nkey-only, no value expected\n\nThe entire child hierarchy will be included as nested dictionaries\r\nin the response. It will contain all the projects ids found by\r\ntraversing down the hierarchy.\nNew in version 3.4\n\ninclude_limits (Optional)\nquery\nkey-only, no value expected\nIt should be used together with parents_as_list or subtree_as_list\r\nfilter to add the related project\u00e2\u0080\u0099s limits into the response body.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/projects/ec35eb7ceb594ad696839fc867817e4c\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nproject\n\nbody\nobject\nA project object.\n\nname\n\nbody\nstring\nThe unique name of the project within the\r\nowning domain.\n\nis_domain\n\nbody\nboolean\n\nIndicates whether the project also acts as a domain. If set to true,\r\nthis project acts as both a project and domain. As a domain, the project\r\nprovides a name space in which you can create users, groups, and other\r\nprojects. If set to false, this project behaves as a regular project\r\nthat contains only resources.\nNew in version 3.6\n\ndescription\n\nbody\nstring\nThe description of the project.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain for the project.\n\nenabled\n\nbody\nboolean\nIf set to true, project is enabled. If set to\r\nfalse, project is disabled.\n\nid\n\nbody\nstring\nThe ID for the project.\n\nlinks\n\nbody\nobject\nThe link to the project resource.\n\nparent_id\n\nbody\nstring\n\nThe ID of the parent for the project.\nNew in version 3.4\n\noptions\n\nbody\nobject\nThe resource options for the project. Available resource options are\r\nimmutable.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"project\": {\r\n    \"is_domain\": false,\r\n    \"description\": \"Project description\",\r\n    \"links\": {\r\n      \"self\": \"https://<node_IP_addr>:5000/v3/projects/ec35eb7ceb594ad696839fc867817e4c\"\r\n    },\r\n    \"tags\": [],\r\n    \"enabled\": true,\r\n    \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"parent_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"id\": \"ec35eb7ceb594ad696839fc867817e4c\",\r\n    \"name\": \"project1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-project-details.html"
    },
    {
        "title": "Managing SSH keys",
        "content": "Managing SSH keys\nUse of SSH keys allows you to secure SSH access to virtual machines. You can generate a key pair on a client from which you will connect to VMs via SSH. The private key will be stored on the client and you will be able to copy it to other nodes. The public key will need to be uploaded to Virtuozzo Hybrid Infrastructure and specified during VM creation. It will be injected into the VM by cloud-init and used for OpenSSH authentication. Keys injection is supported for both Linux and Windows virtual machines.\nLimitations\n\nYou can specify an SSH key only if you deploy a VM from a template or boot volume (not an ISO image).\nIf a key has been injected into one or more VMs, it will remain inside those VMs even if you delete it from the panel.\n\nPrerequisites\n\nThe cloud-init utility and OpenSSH Server are installed in a VM template or boot volume, as instructed in Preparing templates.\n\nTo add a public key\n\nGenerate an SSH key pair on a client by using the ssh-keygen utility:# ssh-keygen -t rsa\n\nOn the SSH keys screen, click Add key.\n\nIn the Add SSH key window, specify a key name and copy the key value from the generated public key located in /root/.ssh/id_rsa.pub. Optionally, you can add a key description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nTo delete a public key\n\nOn the SSH keys screen, select the SSH key you want to delete, and then click Delete.\nClick Delete in the confirmation window.\n\nIf this key has been injected into one or more virtual machines, it will remain inside those virtual machines.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-ssh-keys.html"
    },
    {
        "title": "Creating custom flavors for virtual machines",
        "content": "Creating custom flavors for virtual machines\nIn the compute cluster, a configuration template for virtual machines is called a flavor. Flavors simplify VM deployment. They allow you to set the number of virtual CPU cores and the amount of RAM a virtual machine will use. By default, five predefined flavors are created with the following parameters:\n\nName\nvCPUs\nMemory\n\ntiny\n1\n512 MiB\n\nsmall\n1\n2 GiB\n\nmedium\n2\n4 GiB\n\nlarge\n4\n8 GiB\n\nxlarge\n8\n16 GiB\n\nYou can create custom flavors with different sets of vCPU and RAM resources: public flavors (default), shared between all of the projects, and private flavors, shared with specific projects. Also, you can delete existing flavors, including the predefined ones.\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo create a public flavor\n\nAdmin panel\n\nOn the Compute > Virtual machines > Flavors tab, click Create flavor.\n\nIn the Create flavor window, specify a flavor name, a number of virtual CPU cores, an amount of RAM, and then click Create.\n\nThe created flavor will be available to all of the projects.\n\nCommand-line interface\nUse the following command:vinfra service compute flavor create [--swap <size-mb>] --vcpus <vcpus> --ram <size-mb> <flavor-name>\r\n\n\n--swap <size-mb>\n\nSwap space size, in megabytes\n--vcpus <vcpus>\n\nNumber of virtual CPUs\n--ram <size-mb>\n\nMemory size, in megabytes\n<flavor-name>\n\nFlavor name\n\nFor example, to create a flavor called myflavor with 1 vCPU and 3 GB of RAM, run:# vinfra service compute flavor create myflavor --vcpus 1 --ram 3072\r\n\nThe new flavor will appear in the vinfra service compute flavor list output:# vinfra service compute flavor list\r\n+--------------------------------------+----------+-------+------+-------+\r\n| id                                   | name     | ram   | swap | vcpus |\r\n+--------------------------------------+----------+-------+------+-------+\r\n| 100                                  | tiny     | 512   | 0    | 1     |\r\n| 101                                  | small    | 2048  | 0    | 1     |\r\n| 102                                  | medium   | 4096  | 0    | 2     |\r\n| 103                                  | large    | 8192  | 0    | 4     |\r\n| 104                                  | xlarge   | 16384 | 0    | 8     |\r\n| 2e32ebd2-5d83-45fd-a526-3ae4a6658078 | myflavor | 3072  | 0    | 1     |\r\n+--------------------------------------+----------+-------+------+-------+\r\n\n\nTo create a private flavor\n\nCreate a flavor with the --private option. For example, to create the flavor private_tiny with 1 vCPU, 512 MiB of RAM, and the automatically generated UUID, run:# openstack --insecure flavor create private_tiny --private --id auto --ram 512 --disk 0 --vcpus 1\n\nAssign the flavor to a project. For example, to assign the flavor private_tiny to the project myproject within the domain mydomain, run:# openstack --insecure flavor set private_tiny --project myproject --project-domain mydomain\n\nThe created flavor will only be available to the assigned project.\nTo delete a flavor\n\nAdmin panel\n\nOn the Compute > Virtual machines > Flavors tab, select the flavor you want to delete, and then click Delete.\n\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute flavor delete <flavor>\r\n\n\n<flavor>\n\nFlavor ID or name\n\nFor example, to delete the flavor myflavor, run:# vinfra service compute flavor delete myflavor\n\nSee also\n\nCreating virtual machines\n\nChanging virtual machine resources",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute flavor create [--swap <size-mb>] --vcpus <vcpus> --ram <size-mb> <flavor-name>\r\n\n\n--swap <size-mb>\n\nSwap space size, in megabytes\n--vcpus <vcpus>\n\nNumber of virtual CPUs\n--ram <size-mb>\n\nMemory size, in megabytes\n<flavor-name>\n\nFlavor name\n\nFor example, to create a flavor called myflavor with 1 vCPU and 3 GB of RAM, run:# vinfra service compute flavor create myflavor --vcpus 1 --ram 3072\r\n\nThe new flavor will appear in the vinfra service compute flavor list output:# vinfra service compute flavor list\r\n+--------------------------------------+----------+-------+------+-------+\r\n| id                                   | name     | ram   | swap | vcpus |\r\n+--------------------------------------+----------+-------+------+-------+\r\n| 100                                  | tiny     | 512   | 0    | 1     |\r\n| 101                                  | small    | 2048  | 0    | 1     |\r\n| 102                                  | medium   | 4096  | 0    | 2     |\r\n| 103                                  | large    | 8192  | 0    | 4     |\r\n| 104                                  | xlarge   | 16384 | 0    | 8     |\r\n| 2e32ebd2-5d83-45fd-a526-3ae4a6658078 | myflavor | 3072  | 0    | 1     |\r\n+--------------------------------------+----------+-------+------+-------+\r\n\n",
                "title": "To create a public flavor"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute flavor delete <flavor>\r\n\n\n<flavor>\n\nFlavor ID or name\n\nFor example, to delete the flavor myflavor, run:# vinfra service compute flavor delete myflavor\n",
                "title": "To delete a flavor"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Flavors tab, click Create flavor.\n\nIn the Create flavor window, specify a flavor name, a number of virtual CPU cores, an amount of RAM, and then click Create.\n\n\n\n\n\n\nThe created flavor will be available to all of the projects.\n",
                "title": "To create a public flavor"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Flavors tab, select the flavor you want to delete, and then click Delete.\n\nClick Delete in the confirmation window.\n\n\n",
                "title": "To delete a flavor"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-custom-flavors.html"
    },
    {
        "title": "Changing Kubernetes service parameters",
        "content": "Changing Kubernetes service parameters\nFor Kubernetes clusters, you can change the following parameters:\n\nSize and storage policy of the system volume on master nodes\nFlavors for master and worker nodes\nFlavors for Kubernetes  load balancers\nDNS nameserver and discovery URL\n\nYou can modify the default Kubernetes parameters either for all Kubernetes versions or for each version separately.\nTo view the current default Kubernetes parameters\nUse the vinfra service compute k8saas defaults show command:# vinfra service compute k8saas defaults show\r\n+----------+-------------------------------------------------------------+\r\n| Field    | Value                                                       |\r\n+----------+-------------------------------------------------------------+\r\n| default  | discovery_url: null                                         |\r\n|          | dns_nameserver: null                                        |\r\n|          | flavor: null                                                |\r\n|          | labels:                                                     |\r\n|          |   auto_scaling_enabled: true                                |\r\n|          |   availability_zone: nova                                   |\r\n|          |   boot_volume_size: 20                                      |\r\n|          |   boot_volume_type: default                                 |\r\n|          |   cgroup_driver: systemd                                    |\r\n|          |   cinder_csi_enabled: 'true'                                |\r\n|          |   cinder_csi_plugin_tag: v1.22.2                            |\r\n|          |   cloud_provider_enabled: 'true'                            |\r\n|          |   cloud_provider_tag: v1.22.0                               |\r\n|          |   cluster_upgrade_method: legacy                            |\r\n|          |   csi_attacher_tag: v3.1.0                                  |\r\n|          |   csi_snapshotter_tag: v3.0.3                               |\r\n|          |   docker_volume_type: default                               |\r\n|          |   etcd_lb_disabled: 'true'                                  |\r\n|          |   etcd_tag: v3.4.28                                         |\r\n|          |   flannel_tag: v0.11.0-amd64                                |\r\n|          |   heat_container_agent_tag: 5.3.11                          |\r\n|          |   octavia_api_lb_flavor: ACTIVE_STANDBY                     |\r\n|          |   octavia_default_flavor: ACTIVE_STANDBY                    |\r\n|          |   use_podman: 'true'                                        |\r\n|          | master_flavor: null                                         |\r\n| v1.23.5  | labels:                                                     |\r\n|          |   autoscaler_tag: 1.23.1                                    |\r\n|          |   cloud_provider_tag: v1.23.0                               |\r\n|          |   hyperkube_image: docker.io/virtuozzo/hci-binary-hyperkube |\r\n|          |   kube_tag: v1.23.5                                         |\r\n|          |   kube_version: v1.23.5                                     |\r\n| v1.24.3  | labels:                                                     |\r\n|          |   autoscaler_tag: 1.24.3                                    |\r\n|          |   cloud_provider_tag: v1.24.0                               |\r\n|          |   cluster_upgrade_method: replace                           |\r\n|          |   container_runtime: containerd                             |\r\n|          |   hyperkube_image: docker.io/virtuozzo/hci-binary-hyperkube |\r\n|          |   kube_tag: v1.24.3                                         |\r\n|          |   kube_version: v1.24.3                                     |\r\n| v1.25.7  | labels:                                                     |\r\n|          |   autoscaler_tag: 1.25.3                                    |\r\n|          |   cloud_provider_tag: v1.25.5                               |\r\n|          |   cluster_upgrade_method: replace                           |\r\n|          |   container_runtime: containerd                             |\r\n|          |   hyperkube_image: docker.io/virtuozzo/hci-binary-hyperkube |\r\n|          |   kube_tag: v1.25.7                                         |\r\n|          |   kube_version: v1.25.7                                     |\r\n| v1.26.11 | labels:                                                     |\r\n|          |   autoscaler_tag: 1.26.6                                    |\r\n|          |   cloud_provider_tag: v1.26.4                               |\r\n|          |   cluster_upgrade_method: replace                           |\r\n|          |   container_runtime: containerd                             |\r\n|          |   hyperkube_image: docker.io/virtuozzo/hci-binary-hyperkube |\r\n|          |   kube_tag: v1.26.11                                        |\r\n|          |   kube_version: v1.26.11                                    |\r\n| v1.27.8  | labels:                                                     |\r\n|          |   autoscaler_tag: 1.27.5                                    |\r\n|          |   cloud_provider_tag: v1.27.3                               |\r\n|          |   cluster_upgrade_method: replace                           |\r\n|          |   container_runtime: containerd                             |\r\n|          |   hyperkube_image: docker.io/virtuozzo/hci-binary-hyperkube |\r\n|          |   kube_tag: v1.27.8                                         |\r\n|          |   kube_version: v1.27.8                                     |\r\n| v1.28.4  | labels:                                                     |\r\n|          |   autoscaler_tag: 1.28.2                                    |\r\n|          |   cloud_provider_tag: v1.28.1                               |\r\n|          |   cluster_upgrade_method: replace                           |\r\n|          |   container_runtime: containerd                             |\r\n|          |   hyperkube_image: docker.io/virtuozzo/hci-binary-hyperkube |\r\n|          |   kube_tag: v1.28.4                                         |\r\n|          |   kube_version: v1.28.4                                     |\r\n+----------+-------------------------------------------------------------+\n\nSee also\n\nUpdating Kubernetes clusters\n\nTroubleshooting Kubernetes clusters",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-kubernetes-service-parameters.html"
    },
    {
        "title": "3.1. Downloading Module\u00c2\u00b6",
        "content": "3.1. Downloading Module | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n3.1. Downloading Module\u00c2\u00b6\nThe WHMCS module can be downloaded from here or using the following command:\n\n# wget https://downloads.bitninja.io/BitNinja_plugin_for_whmcs.zip\n\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/whmcs-bitninja/downloading-module.html"
    },
    {
        "title": "Querying S3 users in WHMCS",
        "content": "Querying S3 users in WHMCS\nYou can display information and status of a user with the ostor-users service and parameter emailAddress specifying the user email address. WHMCS displays the user information fetched from S3 cluster when you click Query User (on/off). Create a file S3_queryUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Query s3 user.\r\nfunction S3_queryUser($userid) {\r\n\r\n    // Hide now.\r\n    if ($_SESSION['s3_query_user'] == 1) {\r\n\r\n        // Hide.\r\n        $_SESSION['s3_query_user'] = 0;\r\n\r\n        // Redirect back.\r\n        header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n\r\n     // Return immediately.\r\n        return;\r\n    }\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Get s3 user id.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'],\r\n        \"GET\"\r\n    );\r\n\r\n    // Store s3 result.\r\n    $_SESSION['s3_query_user'] = 1;\r\n    $_SESSION['s3_userid'] = $s3_client['UserId'];\r\n    $_SESSION['s3_aws_access_keys'] = $s3_client['AWSAccessKeys'];\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_queryUser($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-s3-users-in-whmcs.html"
    },
    {
        "title": "Quantity of servers",
        "content": "Quantity of servers\nOne of the strongest features of Virtuozzo Hybrid Infrastructure is scalability. The bigger the cluster, the better Virtuozzo Hybrid Infrastructure performs.\nTo achieve the best performance, keep at least 20 percent of the cluster capacity free.\nOne server (no VM redundancy)\nEven though three nodes are recommended even for the minimum configuration, you can start evaluating Virtuozzo Hybrid Infrastructure with just one node and add more nodes later. In this case, you may need to provide data redundancy by using the disk failure domain, not the host failure domain as in a multi-node cluster.\nAt the very least, a storage cluster must have one metadata service and one chunk service running. However, such a configuration will have two key limitations:\n\nJust one MDS will be a single point of failure. If it fails, the entire cluster will stop working.\nJust one CS will be able to store just one chunk replica. If it fails, the data will be lost.\n\nIn a single-node installation, it is not possible to restart virtual machines by using VM\u00a0high availability.\nTwo servers (no VM redundancy)\nIn terms of redundancy, a two-node cluster is the same as a single-node cluster. High availability for virtual machines is not supported in this case.\nThree servers (minimum for high availability)\nThree servers are required to test all of the product features, and this is the minimum number for a production environment.\nThe minimum configuration ensures that the cluster can survive the failure of one node without data loss. The minimum cluster configuration must have at least three metadata services running. SSD/NVMe disks can be assigned the system, metadata, and cache roles at the same time, freeing up more disks for the storage role.\nFive and more servers (recommended for high availability and optimal TCO)\nAt least five nodes are required to ensure that the cluster can survive failure of two nodes without data loss. For improved resilience, performance, and fault tolerance it is recommended to create production clusters from at least ten nodes.\nThe recommended cluster configuration must have five metadata services running.\nSee also\n\nGeneral requirements\n\nConsiderations for using blade servers\n\nHDD/SSD configuration",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/quantity-of-servers.html"
    },
    {
        "title": "Creating domains",
        "content": "Creating domainsPOST /v3/domains\r\n\nCreate a domain with the specified name.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=create-domain-detail#create-domain\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ndomain\n\nbody\nobject\nA domain object.\n\ndescription (Optional)\nbody\nstring\nThe description of the domain.\n\nenabled (Optional)\nbody\nstring\n\nIf set to true, domain is created enabled. If set to\r\nfalse, domain is created disabled. The default is true.\nUsers can only authorize against an enabled domain (and any of its\r\nprojects). In addition, users can only authenticate if the domain that owns\r\nthem is also enabled. Disabling a domain prevents both of these things. \n\nname\n\nbody\nstring\nThe name of the domain.\n\noptions (Optional)\nbody\nobject\nThe resource options for the domain. Available resource options are\r\nimmutable.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"domain\": {\r\n        \"description\": \"Domain description\",\r\n        \"name\": \"domain1\"\r\n    }\r\n}' https://<node_IP_addr>:5000/v3/domains\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ndomain\n\nbody\nobject\nA domain object.\n\ndescription\n\nbody\nstring\nThe description of the domain.\n\nenabled\n\nbody\nstring\nIf set to true, domain is enabled. If set to\r\nfalse, domain is disabled.\n\nid\n\nbody\nstring\nThe ID of the domain.\n\nlinks\n\nbody\nobject\nThe links to the domain resource.\n\nname\n\nbody\nstring\nThe name of the domain.\n\noptions\n\nbody\nobject\nThe resource options for the role. Available resource options are\r\nimmutable.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n405 - Method Not Allowed\n\nMethod is not valid for this endpoint.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n415 - Unsupported Media Type\n\nThe request entity has a media type which the server or resource does not support.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"domain\": {\r\n    \"description\": \"Domain description\",\r\n    \"links\": {\r\n      \"self\": \"https://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\"\r\n    },\r\n    \"tags\": [],\r\n    \"enabled\": true,\r\n    \"id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"name\": \"domain1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-domains.html"
    },
    {
        "title": "Tutorials",
        "content": "TutorialsHow to deploy WordPress in KubernetesHow to use Trilio for KubernetesHow to deploy Osie on KubernetesHow to customize OpenStack servicesHow to deploy VHI on OVHcloudHow to use Velero for KubernetesHow to use Milvus and Kubernetes for RISHow to use IaC tools on VHIHow to deploy nested VHI clustersHow to mirror the VHI repository",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/tutorials/"
    },
    {
        "title": "15. Leostream Official Documentation and FAQs\u00c2\u00b6",
        "content": "15. Leostream Official Documentation and FAQs | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\n\n15. Leostream Official Documentation and FAQs\u00c2\u00b6\nLeostream knowledge base: https://support.leostream.com/support/solutions\nPorts used in a Leostream Environment: https://support.leostream.com/support/solutions/articles/66000460684-network-ports-used-in-a-leostream-environment\nLeostream Connection Broker FAQ/Troubleshooting: https://support.leostream.com/support/solutions/folders/66000395808\nLeostream Gateway FAQ/troubleshooting: https://support.leostream.com/support/solutions/folders/66000397758\nLeostream Agent FAQ/troubleshooting: https://support.leostream.com/support/solutions/folders/66000397493\nLeostream Connect FAQ/troubleshooting: https://support.leostream.com/support/solutions/folders/66000397771\nLeostream Administration Guide (march 2022 version, even if it appears under the 2018 folder): https://leostream.com/wp-content/uploads/2018/11/leostream-9-administrators-guide.pdf\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/faq-and-documentation.html"
    },
    {
        "title": "Querying bucket quotas via CLI",
        "content": "Querying bucket quotas via CLI\nYou can display the specific quotas per bucket with the query-quotas command and parameter -b specifying the bucket name:# ostor-s3-admin query-quotas -b bucket1 -V 0100000000000002\r\nversion: '1'\r\nsize: '256'\r\ntype: 'bucket'",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-bucket-quotas-via-cli.html"
    },
    {
        "title": "Querying user limits via CLI",
        "content": "Querying user limits via CLI\nYou can display the current limits with the query-limits command and parameter -e specifying the email address:# ostor-s3-admin query-limits -e client@example.com\r\nops:default=0.00ops/s\r\nops:get=3600.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=100kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-user-limits-via-cli.html"
    },
    {
        "title": "Accessing iSCSI targets from Linux",
        "content": "Accessing iSCSI targets from Linux\n\nTo mount an iSCSI device to a storage node from another Virtuozzo Hybrid Infrastructure cluster, use the vinfra node iscsi target add/delete commands, as described in the Administrator Guide.\n\nTo connect a Linux-based iSCSI initiator to iSCSI targets of Virtuozzo Hybrid Infrastructure working in the ALUA mode, do the following:\n\nMake sure the required packages are installed.\n\nOn RPM-based systems (CentOS and other), run:# yum install iscsi-initiator-utils device-mapper-multipath\r\n\n\nOn DEB-based systems (Debian and Ubuntu), run:# apt-get install open-iscsi multipath-tools\r\n\n\nCreate and edit the configuration file /etc/multipath.conf as follows:...\r\ndevices {\r\n  device {\r\n    vendor \"VSTORAGE\"\r\n      product \"VSTOR-DISK\"\r\n    features \"2 pg_init_retries 50\"\r\n    hardware_handler \"1 alua\"\r\n    path_grouping_policy group_by_node_name\r\n    path_selector \"round-robin 0\"\r\n      no_path_retry queue\r\n    user_friendly_names no\r\n    flush_on_last_del yes\r\n    failback followover\r\n    path_checker tur\r\n      detect_prio no\r\n    prio alua\r\n  }\r\n}\r\n...\r\n\n\nLoad the kernel module and launch the multipathing service.# modprobe dm-multipath\r\n# systemctl start multipathd; systemctl enable multipathd\r\n\n\nIf necessary, enable CHAP parameters node.session.auth.* and discovery.sendtargets.auth.* in /etc/iscsi/iscsid.conf.\n\nLaunch the iSCSI services:# systemctl start iscsi iscsid\r\n# systemctl enable iscsi iscsid\r\n\n\nDiscover all targets by their IP addresses. For example:# iscsiadm -m discovery -t st -p 10.94.91.49 10.94.91.49 3260,1 \\\r\niqn.2014-06.com.vstorage:target1\r\n# iscsiadm -m discovery -t st -p 10.94.91.54 10.94.91.54:3260,1 \\\r\niqn.2014-06.com.vstorage:target2\r\n# iscsiadm -m discovery -t st -p 10.94.91.55 10.94.91.55:3260,1 \\\r\niqn.2014-06.com.vstorage:target3\r\n\n\nLog in to the discovered targets. For example:# iscsiadm -m node -T iqn.2014-06.com.vstorage:target1 -l\r\n# iscsiadm -m node -T iqn.2014-06.com.vstorage:target2 -l\r\n# iscsiadm -m node -T iqn.2014-06.com.vstorage:target3 -l\r\n\n\nFind out the multipath device ID. For example:# multipath -ll\r\n360000000000000000000b50326ea44e3 dm-10 VSTORAGE,VSTOR-DISK\r\nsize=200G features='2 pg_init_retries 50' hwhandler='1 alua' wp=rw\r\n|-+- policy='round-robin 0' prio=50 status=active\r\n| `- 6:0:0:1 sdf 8:80  active ready running\r\n|-+- policy='round-robin 0' prio=1 status=enabled\r\n| `- 8:0:0:1 sdj 8:144 active ghost running\r\n`-+- policy='round-robin 0' prio=1 status=enabled\r\n  `- 7:0:0:1 sdh 8:112 active ghost running\r\n# fdisk -l | grep 360000000000000000000b50326ea44e3\r\nDisk /dev/mapper/360000000000000000000b50326ea44e3: 10.7 GB, \\\r\n10737418240 bytes, 20971520 sectors\r\n\nYou can also find out the multipath device ID by adding 360000000000000000000 to the last six bytes of the volume ID. In the example above, 360000000000000000000b50326ea44e3 is the multipath device ID mapped from the volume ID 61c9d567-4666-4c16-8030-b50326ea44e3.\n\nNow you can create partitions on the iSCSI device (/dev/mapper/360000000000000000000b50326ea44e3 in this example), as well as format and mount it to your initiator node using standard Linux tools.\nWhen you no longer need the external iSCSI device, you can remove it from the initiator node. Do the following:\n\nMake sure the iSCSI device is not in use.\n\nDisable multipathing to the device. For example:# multipath -f /dev/mapper/360000000000000000000b50326ea44e3\r\n\n\nLog out of the iSCSI targets. For example:# iscsiadm -m node -T iqn.2014-06.com.vstorage:target1 -p 10.94.91.49:3260 -u\r\n# iscsiadm -m node -T iqn.2014-06.com.vstorage:target2 -p 10.94.91.54:3260 -u\r\n# iscsiadm -m node -T iqn.2014-06.com.vstorage:target3 -p 10.94.91.55:3260 -u\r\n\n\nDelete the iSCSI targets. For example:# iscsiadm -m node -o delete -T iqn.2014-06.com.vstorage:target1 \\-p 10.94.91.49:3260\r\n# iscsiadm -m node -o delete -T iqn.2014-06.com.vstorage:target2 \\-p 10.94.91.54:3260\r\n# iscsiadm -m node -o delete -T iqn.2014-06.com.vstorage:target3 \\-p 10.94.91.55:3260\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/accessing-iscsi-targets-from-linux.html"
    },
    {
        "title": "Managing projects",
        "content": "Managing projects\nYou can add more projects, as described in Configuring multitenancy. Also, you can edit project details and quotas, manage user assignment, as well as enable/disable and delete the existing projects. Enabling and disabling projects allows or prohibits access to projects in the self-service panel.\nLimitations\n\nA project cannot be deleted if it has virtual objects.\nYou can set project quotas only after deploying the compute cluster.\nYou cannot configure domain quotas for floating IP addresses, VPN connections, load balancers, Kubernetes clusters, and placements.\n\nPrerequisites\n\nAs quotas can exceed the existing virtual resources and virtual resources are not reserved for each project, the compute cluster must have enough virtual resources for all projects in all domains.\n\nTo edit a project name or description\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nCommand-line interface\nUse the following command:vinfra domain project set [--description <description>] [--name <name>] --domain <domain> <project>\r\n\n\n--description <description>\n\nProject description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--name <name>\n\nProject name\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to change the name of the project myproject within the domain mydomain to newproject, run:# vinfra domain project set myproject --domain mydomain --name newproject\n\nTo assign users to a project\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Manage users.\nIn the Manage users window, select only those users that you want to assign to the project, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra domain user set --assign <project> <role> --domain <domain> <user>\r\n\n\n--assign <project> <role>\n\nAssign a user to a project with one or more permission sets. Specify this option multiple times to assign the user to multiple projects.\n\n<project>: project ID or name\n<role>: user role in the project (project_admin)\n\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to assign the user myuser from the domain mydomain to the project myproject as a project administrator, run:# vinfra domain user set myuser --domain mydomain --assign myproject project_admin\n\nTo unassign users from a project\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab and click the required project.\nOn the Users tab, click the bin icon next to a user that you want to unassign from the project.\n\nCommand-line interface\nUse the following command:vinfra domain project user remove --user <user> --domain <domain> <project>\r\n\n\n--user <user>\n\nUser name or ID\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to remove the user myuser from the project myproject within the domain mydomain, run:# vinfra domain project user remove myproject --domain mydomain --user myuser\n\nTo edit project quotas\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Edit quotas.\n\nDefine quotas for virtual resources that will be available inside the project. To specify a certain value for a resource, clear the Unlimited check box next to it first.\n\nThe default storage policy must be shared with projects that will use the Kubernetes-as-a-service feature.\n\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute quotas update [--cores <cores>] [--ram-size <ram>] [--floatingip <floating-ip>]\r\n                                     [--storage-policy <storage_policy>:<size>]\r\n                                     [--k8saas-cluster <cluster>] [--lbaas-loadbalancer <load-balancer>]\r\n                                     [--placement <placement>] [--volumes-backups <volumes-backups-size>]\r\n                                     <project-id>\r\n\n\n--cores <cores>\n\nNumber of cores\n--ram-size <ram>\n\nNumber of RAM. Use the following units: M or MiB for mebibytes, G or GiB for gibibytes, T or TiB for tebibytes, P or PiB for pebibytes, and E or EiB for exbibytes.\n--floatingip <floating-ip>\n\nNumber of floating IP addresses\n--storage-policy <storage_policy>:<size>\n\nComma-separated list of <storage_policy>:<size>. To specify the size, use the following units: M or MiB for mebibytes, G or GiB for gibibytes, T or TiB for tebibytes, P or PiB for pebibytes, and E or EiB for exbibytes.\n--k8saas-cluster <cluster>\n\nNumber of Kubernetes clusters\n--lbaas-loadbalancer <load-balancer>\n\nThe new value for the load balancer quota limit. The value -1 means unlimited.\n--placement <placement>\n\nComma-separated list of <placement-id>:<size>\n--volumes-backups <volumes-backups-size>\n\nThe new value for the volumes backups size quota limit\n<project-id>\n\nProject ID\n\nFor example, to update quotas for the project with the ID 6ef6f48f01b640ccb8ff53117b830fa3 to 10 vCPUs, 20 GiB of RAM, and 512 GiB of disk space for the default storage policy, run:# vinfra service compute quotas update 6ef6f48f01b640ccb8ff53117b830fa3 --cores 10 --ram-size 10G --storage-policy default:512G\nYou can view the updated quotas in the vinfra service compute quotas show output:# vinfra service compute quotas show 79830e3c64c74ded9bac6bffde5d26e4\r\n+----------------------------------------+----------+\r\n| Field                                  | Value    |\r\n+----------------------------------------+----------+\r\n| compute.cores.limit                    | 10       |\r\n| compute.ram.limit                      | 10.0GiB  |\r\n| compute.ram_quota.limit                | 10.0GiB  |\r\n| lbaas.loadbalancer.limit               | -1       |\r\n| network.floatingip.limit               | -1       |\r\n| storage.gigabytes.default.limit        | 512.0GiB |\r\n| storage.storage_policies.default.limit | 512.0GiB |\r\n| storage.volumes_backups.limit          | -1       |\r\n+----------------------------------------+----------+\r\n\n\nTo enable or disable a project\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Enable or Disable.\n\nCommand-line interface\nUse the following command:vinfra domain project set [--enable | --disable] --domain <domain> <project>\r\n\n\n--enable\n\nEnable project\n--disable\n\nDisable project\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to disable the project myproject within the domain mydomain, run:# vinfra domain project set myproject --domain mydomain --disable\n\nTo delete a project\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Delete.\nIn the confirmation window, click Delete.\n\nCommand-line interface\nUse the following command:vinfra domain project delete --domain <domain> <project>\r\n\n\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to delete the project myproject from the domain mydomain, run:# vinfra domain project delete myproject --domain mydomain\n\nSee also\n\nManaging domains\n\nManaging self-service users",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain project set [--description <description>] [--name <name>] --domain <domain> <project>\r\n\n\n--description <description>\n\n\nProject description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--name <name>\n\nProject name\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to change the name of the project myproject within the domain mydomain to newproject, run:# vinfra domain project set myproject --domain mydomain --name newproject\n",
                "title": "To edit a project name or description"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user set --assign <project> <role> --domain <domain> <user>\r\n\n\n--assign <project> <role>\n\n\nAssign a user to a project with one or more permission sets. Specify this option multiple times to assign the user to multiple projects.\n\n<project>: project ID or name\n<role>: user role in the project (project_admin)\n\n\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to assign the user myuser from the domain mydomain to the project myproject as a project administrator, run:# vinfra domain user set myuser --domain mydomain --assign myproject project_admin\n",
                "title": "To assign users to a project"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain project user remove --user <user> --domain <domain> <project>\r\n\n\n--user <user>\n\nUser name or ID\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to remove the user myuser from the project myproject within the domain mydomain, run:# vinfra domain project user remove myproject --domain mydomain --user myuser\n",
                "title": "To unassign users from a project"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute quotas update [--cores <cores>] [--ram-size <ram>] [--floatingip <floating-ip>]\r\n                                     [--storage-policy <storage_policy>:<size>]\r\n                                     [--k8saas-cluster <cluster>] [--lbaas-loadbalancer <load-balancer>]\r\n                                     [--placement <placement>] [--volumes-backups <volumes-backups-size>]\r\n                                     <project-id>\r\n\n\n--cores <cores>\n\nNumber of cores\n--ram-size <ram>\n\nNumber of RAM. Use the following units: M or MiB for mebibytes, G or GiB for gibibytes, T or TiB for tebibytes, P or PiB for pebibytes, and E or EiB for exbibytes.\n--floatingip <floating-ip>\n\nNumber of floating IP addresses\n--storage-policy <storage_policy>:<size>\n\nComma-separated list of <storage_policy>:<size>. To specify the size, use the following units: M or MiB for mebibytes, G or GiB for gibibytes, T or TiB for tebibytes, P or PiB for pebibytes, and E or EiB for exbibytes.\n--k8saas-cluster <cluster>\n\nNumber of Kubernetes clusters\n--lbaas-loadbalancer <load-balancer>\n\nThe new value for the load balancer quota limit. The value -1 means unlimited.\n--placement <placement>\n\nComma-separated list of <placement-id>:<size>\n--volumes-backups <volumes-backups-size>\n\nThe new value for the volumes backups size quota limit\n<project-id>\n\nProject ID\n\nFor example, to update quotas for the project with the ID 6ef6f48f01b640ccb8ff53117b830fa3 to 10 vCPUs, 20 GiB of RAM, and 512 GiB of disk space for the default storage policy, run:# vinfra service compute quotas update 6ef6f48f01b640ccb8ff53117b830fa3 --cores 10 --ram-size 10G --storage-policy default:512G\nYou can view the updated quotas in the vinfra service compute quotas show output:# vinfra service compute quotas show 79830e3c64c74ded9bac6bffde5d26e4\r\n+----------------------------------------+----------+\r\n| Field                                  | Value    |\r\n+----------------------------------------+----------+\r\n| compute.cores.limit                    | 10       |\r\n| compute.ram.limit                      | 10.0GiB  |\r\n| compute.ram_quota.limit                | 10.0GiB  |\r\n| lbaas.loadbalancer.limit               | -1       |\r\n| network.floatingip.limit               | -1       |\r\n| storage.gigabytes.default.limit        | 512.0GiB |\r\n| storage.storage_policies.default.limit | 512.0GiB |\r\n| storage.volumes_backups.limit          | -1       |\r\n+----------------------------------------+----------+\r\n\n",
                "title": "To edit project quotas"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain project set [--enable | --disable] --domain <domain> <project>\r\n\n\n--enable\n\nEnable project\n--disable\n\nDisable project\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to disable the project myproject within the domain mydomain, run:# vinfra domain project set myproject --domain mydomain --disable\n",
                "title": "To enable or disable a project"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain project delete --domain <domain> <project>\r\n\n\n--domain <domain>\n\nDomain name or ID\n<project>\n\nProject ID or name\n\nFor example, to delete the project myproject from the domain mydomain, run:# vinfra domain project delete myproject --domain mydomain\n",
                "title": "To delete a project"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n",
                "title": "To edit a project name or description"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Manage users.\nIn the Manage users window, select only those users that you want to assign to the project, and then click Save.\n\n",
                "title": "To assign users to a project"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab and click the required project.\nOn the Users tab, click the bin icon next to a user that you want to unassign from the project.\n\n",
                "title": "To unassign users from a project"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Edit quotas.\n\nDefine quotas for virtual resources that will be available inside the project. To specify a certain value for a resource, clear the Unlimited check box next to it first.\n\nThe default storage policy must be shared with projects that will use the Kubernetes-as-a-service feature.\n\n\n\n\n\n\nClick Save to apply your changes.\n\n",
                "title": "To edit project quotas"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Enable or Disable.\n\n",
                "title": "To enable or disable a project"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to manage projects.\nGo to the Projects tab, click the ellipsis icon next to the project, and then click Delete.\nIn the confirmation window, click Delete.\n\n",
                "title": "To delete a project"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-projects.html"
    },
    {
        "title": "Listing IPsec connections",
        "content": "Listing IPsec connectionsGET /v2.0/vpn/ipsec-site-connections\nList all IPsec connections.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-ipsec-connections-detail#list-ipsec-connections\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ipsec-site-connections\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nauth_mode (Optional)\nbody\nstring\nThe authentication mode. A valid value is psk, which is the default.\n\nikepolicy_id\n\nbody\nstring\nThe ID of the IKE policy.\n\nvpnservice_id\n\nbody\nstring\nThe ID of the VPN service.\n\nlocal_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private subnets for the local side of the connection. You must specify this parameter with the peer_ep_group_id parameter.\n\npeer_address\n\nbody\nstring\nThe peer gateway public IPv4 or IPv6 address or FQDN.\n\nid (Optional)\nbody\nstring\nThe ID of the IPsec site-to-site connection.\n\nroute_mode (Optional)\nbody\nstring\nThe route mode. A valid value is static, which is the default.\n\nipsecpolicy_id\n\nbody\nstring\nThe ID of the IPsec policy.\n\npeer_id\n\nbody\nstring\nThe peer router identity for authentication. A valid value is an IPv4 address, IPv6 address, e-mail address, key ID, or FQDN. Typically, this value matches the peer_address value.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec connection is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\npsk\n\nbody\nstring\nThe pre-shared key. A valid value is any string.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ninitiator (Optional)\nbody\nstring\nIndicates whether this VPN can only respond to connections or both respond to and initiate connections. A valid value is response-only or bi-directional. Default is bi-directional.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ninterval (Optional)\nbody\ninteger\nThe dead peer detection (DPD) interval, in seconds. A valid value is a positive integer. Default is 30.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6.\n\npeer_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private CIDRs in the form <net_address>/<prefix> for the peer side of the connection. You must specify this parameter with the local_ep_group_id parameter.\n\ndpd (Optional)\nbody\nobject\nA dictionary with dead peer detection (DPD) protocol controls.\n\ntimeout\n\nbody\ninteger\nThe dead peer detection (DPD) timeout in seconds. A valid value is a positive integer that is greater than the DPD interval value. Default is 120.\n\naction\n\nbody\nstring\nThe dead peer detection (DPD) action. A valid value is clear, hold, restart, disabled, or restart-by-peer. Default value is hold.\n\nlocal_id (Optional)\nbody\nstring\nAn ID to be used instead of the external IP address for a virtual router used in traffic between instances on different networks in east-west traffic. Most often, local ID would be domain name, email address, etc. If this is not configured then the external IP address will be used as the ID.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"ipsec_site_connections\": [\r\n    {\r\n      \"id\": \"324dc68b-bdee-4a78-9d14-3484d8ee97a9\",\r\n      \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n      \"name\": \"vpnconnection1\",\r\n      \"description\": \"\",\r\n      \"peer_address\": \"10.136.18.138\",\r\n      \"peer_id\": \"10.136.18.138\",\r\n      \"local_id\": \"\",\r\n      \"route_mode\": \"static\",\r\n      \"mtu\": 1500,\r\n      \"auth_mode\": \"psk\",\r\n      \"psk\": \"secret\",\r\n      \"initiator\": \"bi-directional\",\r\n      \"dpd\": {\r\n        \"action\": \"hold\",\r\n        \"interval\": 30,\r\n        \"timeout\": 120\r\n      },\r\n      \"admin_state_up\": true,\r\n      \"status\": \"DOWN\",\r\n      \"vpnservice_id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n      \"ikepolicy_id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n      \"ipsecpolicy_id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n      \"peer_cidrs\": [],\r\n      \"local_ep_group_id\": \"646938a8-322e-44b3-ac35-60deadcd4252\",\r\n      \"peer_ep_group_id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n      \"split_selector\": false,\r\n      \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-ipsec-connections.html"
    },
    {
        "title": "Adding nodes to the compute cluster",
        "content": "Adding nodes to the compute cluster\nPrerequisites\n\nA clear understanding of the limitations listed in High availability and the compute cluster.\nEnsure that time is synchronized on a node that will be added to the compute cluster. For automatic time synchronization, the node must have access to the Internet and the chronyd service must be running. To synchronize time immediately, manually restart the service by running systemctl restart chronyd.\n\nTo add nodes to the compute cluster\n\nAdmin panel\n\nGo to the Compute > Nodes screen, and then click Add node.\n\nIn the Add node window, select nodes to add to the compute cluster, and then click Add.\n\nThe added nodes will appear on the Nodes screen.\n\nCommand-line interface\nUse the following command:vinfra service compute node add [--compute] [--controller] [--force] <node>\r\n\n\n--compute\n\nCompute node role\n--controller\n\nCompute controller node role\n--force\n\nSkip checks for minimal hardware requirements\n<node>\n\nNode ID or hostname\n\nFor example, to add the node node005.vstoragedomain to the compute cluster with the compute role, run:# vinfra service compute node add node005.vstoragedomain --compute\r\n\nThe added node will appear in the vinfra service compute node list output:# vinfra service compute node list\r\n+------------------+------------------------+---------------+--------------+\r\n| id               | host                   | state         | roles        |\r\n+------------------+------------------------+---------------+--------------+\r\n| 7ffa9540-5a20<\u00e2\u0080\u00a6> | node001.vstoragedomain | healthy       | - controller |\r\n|                  |                        |               | - compute    |\r\n| 6e8afc28-7f71<\u00e2\u0080\u00a6> | node002.vstoragedomain | healthy       | - compute    |\r\n| 02ff64ae-5800<\u00e2\u0080\u00a6> | node003.vstoragedomain | healthy       | - compute    |\r\n| 827a1f4e-56e5<\u00e2\u0080\u00a6> | node004.vstoragedomain | healthy       | - compute    |\r\n| 37c70bfb-c289<\u00e2\u0080\u00a6> | node005.vstoragedomain | reconfiguring | - compute    |\r\n+------------------+------------------------+---------------+--------------+\n\nSee also\n\nManaging placements for compute nodes\n\nFencing compute nodes\n\nMonitoring compute nodes\n\nReleasing nodes from the compute cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute node add [--compute] [--controller] [--force] <node>\r\n\n\n--compute\n\nCompute node role\n--controller\n\nCompute controller node role\n--force\n\nSkip checks for minimal hardware requirements\n<node>\n\nNode ID or hostname\n\nFor example, to add the node node005.vstoragedomain to the compute cluster with the compute role, run:# vinfra service compute node add node005.vstoragedomain --compute\r\n\nThe added node will appear in the vinfra service compute node list output:# vinfra service compute node list\r\n+------------------+------------------------+---------------+--------------+\r\n| id               | host                   | state         | roles        |\r\n+------------------+------------------------+---------------+--------------+\r\n| 7ffa9540-5a20<\u00e2\u0080\u00a6> | node001.vstoragedomain | healthy       | - controller |\r\n|                  |                        |               | - compute    |\r\n| 6e8afc28-7f71<\u00e2\u0080\u00a6> | node002.vstoragedomain | healthy       | - compute    |\r\n| 02ff64ae-5800<\u00e2\u0080\u00a6> | node003.vstoragedomain | healthy       | - compute    |\r\n| 827a1f4e-56e5<\u00e2\u0080\u00a6> | node004.vstoragedomain | healthy       | - compute    |\r\n| 37c70bfb-c289<\u00e2\u0080\u00a6> | node005.vstoragedomain | reconfiguring | - compute    |\r\n+------------------+------------------------+---------------+--------------+\n",
                "title": "To add nodes to the compute cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Nodes screen, and then click Add node.\n\nIn the Add node window, select nodes to add to the compute cluster, and then click Add.\n\n\n\n\n\n\nThe added nodes will appear on the Nodes screen.\n",
                "title": "To add nodes to the compute cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-compute-nodes.html"
    },
    {
        "title": "Managing virtual routers",
        "content": "Managing virtual routers\nVirtual routers provide L3 services such as routing and Source Network Address Translation (SNAT) between virtual and physical networks, or different virtual networks:\n\nA virtual router between virtual and physical networks provides access to public networks, such as the Internet, for VMs connected to this virtual network.\nA virtual router between different virtual networks provides network communication for VMs connected to these virtual networks.\n\nA virtual router has two types of ports:\n\nAn external gateway that is connected to a physical network.\nAn internal port that is connected to a virtual network.\n\nWith virtual routers, you can do the following:\n\nCreate virtual routers\nChange external or internal router interfaces\nCreate, edit, and delete static routes\nChange a router name\nDelete a router\n\nLimitations\n\nA router can only connect networks that have IP management enabled.\n\nYou can delete a virtual router if no floating IP addresses are associated with any network it is connected to.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-virtual-routers.html"
    },
    {
        "title": "Storage tiers",
        "content": "Storage tiers\nIn Virtuozzo Hybrid Infrastructure terminology, tiers are disk groups that allow you to organize storage workloads based on your criteria. For example, you can use tiers to separate workloads produced by different tenants. Or you can have a tier of fast SSDs for service or virtual environment workloads and a tier of high-capacity HDDs for backup storage.\nManual data migration between tiers (default)\nWhen required, you can manually migrate data from one tier to another. To start data migration, ensure that the target tier has enough free space, and then select the desired tier in the settings of the current storage policy.\nAutomatic data migration between tiers\nAutomatic data migration between tiers works in the inter-tier data allocation mode and is disabled by default. In this mode, data is automatically migrated to a lower tier if the current tier is full. To enable the inter-tier data allocation mode, use vstorage -c <cluster_name> set-config mds.alloc.strict_tier=0 command.\nWhen assigning disks to tiers (which you can do at any time), have in mind that faster storage drives should be assigned to higher tiers. For example, you can use tier 0 for backups and other cold data (CS without SSD cache); tier 1 for virtual environments\u00e2\u0080\u0094a lot of cold data but fast random writes (CS with SSD cache); and tier 2 for hot data (CS on SSD), caches, specific disks, and such.\nThis recommendation is related to how Virtuozzo Hybrid Infrastructure works with storage space in the inter-tier data allocation mode. If a storage tier runs out of free space, Virtuozzo Hybrid Infrastructure will attempt to temporarily use the space of the lower tiers down to the lowest. If the lowest tier also becomes full, Virtuozzo Hybrid Infrastructure will attempt to use a higher one. If you add more storage to the original tier later, the data, temporarily stored elsewhere, will be moved to the tier where it should have been stored originally. For example, if you try to write data to tier 2 and it is full, Virtuozzo Hybrid Infrastructure will attempt to write that data to tier 1, then to tier 0. If you add more storage to tier 2 later, the aforementioned data, now stored on the tier 1 or 0, will be moved back to tier 2, where it was meant to be stored originally.\nSee also\n\nStorage policies\n\nData redundancy\n\nFailure domains\n\n\u00d0\u00a1luster rebuilding",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/storage-tiers.html"
    },
    {
        "title": "About this guide",
        "content": "About this guide\nThis document will help you integrate Amazon S3 compatible services into your WHMCS provisioning and billing system. The guide is primarily intended for developers who already have working storage clusters with properly configured Amazon S3-like roles and gateways.\nIn this document, you will find examples of integrating Virtuozzo Hybrid Infrastructure S3 clusters via CLI and REST API, as well as in WHMCS. Using this guide as a starting point, you will be able to create basic storage-as-a-service offerings based on Virtuozzo Hybrid Infrastructure.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/about-this-guide.html"
    },
    {
        "title": "Storware Backup and Disaster Recovery Guide",
        "content": "Storware Backup and Disaster Recovery GuideStorware Backup and Recovery software allows to perform backup and disaster recovery for virtual machines running on Virtuozzo Hybrid Infrastructure. The goal of this guide is to simplify Storware integration with Virtuozzo.Minimum requirementsStorware Backup & Recovery server64-bit 4 cores processor4 GB RAM20 GB free disk space for the operating system and Storware Backup and Recovery installationStorware Backup & Recovery node64-bit 4 cores processor6 GB RAM20 GB free disk space for the operating system and Storware Backup and Recovery installationFree disk space for data staging. To estimate the free space requirement, use the following equation: (size of the biggest virtual machine) * (number of parallel backup threads)Deploying and configuring Storware Backup & RecoveryPrerequisites1. Deploy two virtual machines with CentOS 8 or 9 on your Virtuozzo Hybrid Infrastructure cluster: one VM for the Storware Backup & Recovery server and one VM for the Storware Backup & Recovery node.2. Connect to the created VMs via SSH.3. In both VMs, create the /etc/yum.repos.d/vProtect.repo file with the following content:1\n2\n3\n4\n5\n# Storware Backup & Recovery - Enterprise backup solution for virtual environments repository\n[vprotect]\nname = vProtect\nbaseurl = https://repo.storware.eu/storware/current/el9/\ngpgcheck = 0\nServer installation steps1. Install the Storware Backup & Recovery server by running:1\n# dnf -y install vprotect-server\n2. Prepare the database root password and run the command:1\n# vprotect-server-configure\n3. Start the Storware Backup & Recovery server service (it can take around a minute for the server to start):1\n# systemctl start vprotect-server\n4. After the server service starts, the server will be listening on port 8181. Open port 8181 on the firewall, so the node and the administrator can access the server. You can also redirect the default HTTPS port 443 to 8181 for easier management.To open port 8181 using the system firewall, run:1\n2\n# firewall-cmd --add-port=8181/tcp --permanent\n# firewall-cmd --complete-reload\nYou can also use port 8080 for the server service. To open it, use these commands:1\n2\n# firewall-cmd --add-port=8080/tcp --permanent\n# firewall-cmd --complete-reload\nTo forward the default HTTPS port (443) to port 8181, you can use the following script:1\n# /opt/vprotect/scripts/ssl_port_forwarding_firewall-cmd.sh\nNode installation steps1. Install the Storware Backup & Recovery node by running:1\n# dnf -y install vprotect-node\n2. Register the node with the following command and provide a password when prompted:1\n# vprotect node -r <node_name> <admin_user> https://<server_address>/api\nWhere:node_name is the name under which the node will appear in the systemadmin_user is the login of the administrative userserver_address is address of the server installed in the previous stepsExample for the default local installation:1\n# vprotect node -r node1 admin https://localhost:8181/api\nIf you use port 8080:1\n# vprotect node -r node1 admin https://localhost:8080/api\n3. Start the Storware Backup & Recovery node service:1\n# systemctl start vprotect-node\n4. Run the script to configure the OS for the node, which includes changing the QEMU user/group to vprotect, disabling SELinux, adding Storware Backup & Recovery to the disk group and sudoers policy to allow it to run privileged commands:1\n# vprotect-node-configure\n5. Reboot the Storware Backup & Recovery VM to apply the OS-specific settings:1\n# reboot\nPost-installation steps1. Wait for the installation to complete successfully.2. Log in to the Storware Backup & Recovery server using https://IP_OF_YOUR_MACHINE with the local node registered and running. By default, Storware Backup & Recovery has one admin account admin with the password vPr0tect.3. Prepare your staging space on the Storware Backup & Recovery node, as described in Staging space configuration.4. Configure access to the hypervisors and backup destinations, as described in Initial Configuration.Configuring the backup destinations on the Storware Backup & Recovery nodeNote: NFS storage is needed for replicating virtual machines between different clusters (from one cluster to another).1. Set up a file system, as described in File system.2. Set up NFS storage:2.1. Deploy the NFS server (for example, on your Virtuozzo Hybrid Infrastructure cluster).2.2. Create a share.2.3. Go to the VM with the Storware agent and run:1\n2\n# mkdir /destination_nfs\n# chown vprotect:vprotect -R /destination_nfs/\n2.4. Add this line to the /etc/fstab file to automatically mount the new file system after reboot:1\n<share_ip>:/storware /destination_nfs nfs defaults  0 0\n2.5. Run the following commands:1\n2\n3\n# mount /destination_nfs/\n# systemctl daemon-reload\n# reboot\nConfiguring the backup destination on the Storware Backup & Recovery admin panel1. Log in to the admin panel (UI).2. Go to the Backup Destinations \u00e2\u0086\u0092 FS screen.3. Create a File System (Synthetic) and specify your NFS share.4. Assign the created backup destination to the node.Adding a new virtualization providerImportant: Select the virtualization provider Virtuozzo.1. Log in to the Storware Backup & Recovery server at https://IP_OF_YOUR_MACHINE.2. Go to Settings \u00e2\u0086\u0092 Global Settings \u00e2\u0086\u0092 License and add your license key.3. Go to Virtual Environment \u00e2\u0086\u0092 Virtual Providers and add the virtual provider. Fill in the fields for hypervisor manager. For example:Note: The node configuration must be created and selected for each node. To create a new node configuration, go to Nodes \u00e2\u0086\u0092 Nodes Configurations and click Create. Then, you need to assign the created node configuration to the node.4. Click Save.5. Check test connectivity.6. Execute the inventory synchronization.7. Add the backup destinations:File systemAmazon S3 / S3-compatible storage (refer to the example with Wasabi)Adding non-default domains to the Storware Backup & Recovery admin panelYou need to create and grant <username> the System administrator role in the Default domain. Storware Backup & Recovery will use this account to back up and restore virtual machines in any child project within the Default domain. To do this, run:1\n2\n3\n4\n# openstack --insecure user create <username> --password <password>\n# openstack --insecure user set --project admin --project-domain Default --domain Default <username>\n# openstack --insecure role add --domain Default --user <username> --user-domain Default compute --inherited\n# openstack --insecure role add --domain Default --user <username> --user-domain Default admin --inherited\nTo manage backups of virtual machines in other domains, run the following command for each domain:1\n# openstack --insecure role add --domain <domain_name> --user <username> --user-domain Default admin --inherited\nImportant! You need to disable the Use domain-scoped authorization option. To do this, go to Virtual Environment \u00e2\u0086\u0092 VP and click Settings.Only one domain should be used for authentication. For example:Changing the inventory synchronization intervalInventory synchronization is a scan for changes in the VM inventory on a Virtuozzo Hybrid Infrastructure cluster. The default synchronization interval is 8 hours.To change this interval, go to the Settings \u00e2\u0086\u0092 Global screen and specify your value in the Periodic inventory synchronization interval field.Please contact us if you have any questions.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/storware-integration/"
    },
    {
        "title": "Infrastructure management with Terraform",
        "content": "Infrastructure management with TerraformThis guide describes how to manage Infrastructure as Code by using Terraform.In this guide, we will dive into a typical Terraform project setup, exploring each file and its role in the broader context of infrastructure automation on Virtuozzo Hybrid Infrastructure. Whether you are new to Terraform or looking to enhance your understanding of best practices in file organization and usage, this guide will provide valuable insights into crafting and managing your Terraform configurations effectively.PrerequisitesAn OS supported by Terraform. In this guide, we are using CentOS Stream 9 as the workstation.Install Terraform.A project in a Virtuozzo Hybrid Infrastructure domain. Ensure that you have the credentials to access this project.Your favorite text editor. In this guide, we are using Vim.Note: You need to change the variables used in this guide, such as image or flavor names, to match your environment.OverviewOur deployment will consist of three Apache web servers behind a load balancer and a database server with MariaDB installed. We will learn how to automatically create all the necessary resources required for this deployment by using Terraform:Creating VXLANs (private networks for your VMs)Configuring security groupsCreating and configuring VMs:Creating network interfacesCreating boot volumesAttaching additional volumesInstalling packagesCreating configuration filesRunning commands automatically on the first bootCreating and configuring a load balancer to leverage 3 web instancesAdding a floating IP address to your load balancerAs a result, the directory where you will be working should contain the following items: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 00-variables.tf # Variables that we will define for our deployment\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 010-ssh-key.tf  # This file will hold your public SSH key to access the environments\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 020-network.tf  # Network creation/configuration \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 030-security_group.tf # Security Groups creation\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 060-instance_http.tf  # Web server instances definition \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 061-instance_db.tf    # DB instance definition \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 070-loadbalancer.tf   # Load balancer definition  \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 provider.tf           # OpenStack provider definition \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 scripts\n\u00e2\u0094\u0082   \u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 first-boot-server1.yaml # Cloud-config example for web servers 1 to 3\n\u00e2\u0094\u0082   \u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 first-boot-server2.yaml\n\u00e2\u0094\u0082   \u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 first-boot-server3.yaml\n\u00e2\u0094\u0082   \u00e2\u0094\u0094\u00e2\u0094\u0080\u00e2\u0094\u0080 mariadb.yml             # Cloud-config example for the Maria DB installation\n\u00e2\u0094\u0094\u00e2\u0094\u0080\u00e2\u0094\u0080 secrets.tfvars              # File with the password and info about your cloud\nStep-by-step guide1. Create the cloud provider file that will define the modules and terraform provider versions: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# cat > provider.tf <<\\EOT\nterraform {\nrequired_version = \">= 0.14.0\"\n  required_providers {\n    openstack = {\n      source  = \"terraform-provider-openstack/openstack\"\n      version = \"~> 1.53.0\"\n    }\n  }\n}\nprovider \"openstack\" {\n  user_name   = var.os_username\n  tenant_name = var.os_tenant_name\n  domain_name = var.os_domain_name\n  password    = var.os_password\n  auth_url    = var.os_auth_url\n  region      = var.os_region\n}\nEOT\n2. Create the secrets.tfvars file to store your secrets:Note: Keep this file locally and safe.1\n2\n3\n4\n5\n6\n7\n8\n# cat > secrets.tfvars <<\\EOT\nos_username   = \"virtuozzo_user_name\"\nos_tenant_name = \"project_name\"\nos_password   = \"password\"\nos_auth_url   = \"https://<your_cloud>.com:5000/v3\"\nos_region     = \"RegionOne\"\nos_domain_name = \"virtuozzo\"\nEOT\n3. Create the variables file and change variables to match your current environment. These variables are used globally in each of the definition files, and their file should be placed in the same directory as the the definition file you are working on. There are also other ways to do this, but this approach is much simpler. 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\ncat > 00-variables.tf <<\\EOT\nvariable \"os_username\" {}\nvariable \"os_tenant_name\" {}\nvariable \"os_password\" {}\nvariable \"os_auth_url\" {}\nvariable \"os_region\" {}\nvariable \"os_domain_name\" {}\n# Params file for variables\n#Set here the storage policy name\nvariable \"volume_type\" {\n  type  = string\n  default = \"standard\" #change this to match the name of your storage policy\n}\n#### GLANCE\nvariable \"image\" {\n  type    = string\n  default = \"CentOS-9\" #change this to match the name of the image you'd like to use (must be centos based)\n}\n#### NEUTRON\nvariable \"external_network\" {\n  type    = string\n  default = \"external-network\"\n}\n# UUID of external gateway\nvariable \"external_gateway\" {\n  type    = string\n  default = \"26e450e5-e600-4174-a1e1-cc023e850095\" # Find your public network on your project. Click on the network and replace the ID\n}\nvariable \"dns_ip\" {\n  type    = list(string)\n  default = [\"8.8.8.8\", \"1.1.1.1\"] # whatever you like to use here \n}\n#### VM HTTP parameters ####\nvariable \"flavor_http\" {\n  type    = string\n  default = \"va-4-8\" # change this to match the available flavor on your cloud\n}\nvariable \"network_http\" {\n  type = map(string)\n  default = {\n    subnet_name = \"subnet-http\"\n    cidr        = \"192.168.1.0/24\"\n  }\n}\nvariable \"http_instance_names\" {\n  description = \"Map of instance names to their cloud-config filenames\"\n  type        = map(string)\n  default     = {\n    \"http-instance-1\" = \"scripts/first-boot-server1.yaml\", #make your you create a subdir called scripts we will populate this later\n    \"http-instance-2\" = \"scripts/first-boot-server2.yaml\",\n    \"http-instance-3\" = \"scripts/first-boot-server3.yaml\"\n  }\n}\n#### MAIN DISK SIZE FOR HTTP\nvariable \"volume_http\" {\n  type    = number\n  default = 10\n}\n#### VM DB parameters ####\nvariable \"flavor_db\" {\n  type    = string\n  default = \"va-4-8\" # change this to match the available flavor on your cloud\n}\nvariable \"network_db\" {\n  type = map(string)\n  default = {\n    subnet_name = \"subnet-db\"\n    cidr        = \"192.168.2.0/24\"\n  }\n}\nvariable \"db_instance_names\" {\n  type = set(string)\n  default = [\"db-instance-1\"]\n}\n#### ATTACHED VOLUME PARAMS\nvariable \"volume_db\" {\n  type    = number\n  default = 15\n}\nEOT\n4. Create the SSH key file that will define the key to be added to workloads. You need to specify your public SSH key.1\n2\n3\n4\n5\n6\n7\n# cat > 010-ssh-key.tf <<\\EOT\n#Define ssh to config in instance\nresource \"openstack_compute_keypair_v2\" \"user_key\" {\n  name       = \"user-key\"\n  public_key = \"ssh-rsa AAAAB3NzaC......\" # Your public SSH key here\n}\nEOT\n5. Create the network configuration for your VMs that will define a network, a router, and two subnets: one is for the HTTP servers (web servers), the other is for the MariaDB server. 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n# cat > 020-network.tf <<\\EOT\n#### NETWORK CONFIGURATION ####\n# Router creation\nresource \"openstack_networking_router_v2\" \"generic\" {\n  name                = \"router\"\n  external_network_id = var.external_gateway\n}\n# Network creation\nresource \"openstack_networking_network_v2\" \"generic\" {\n  name = \"network-generic\"\n}\n#### HTTP SUBNET ####\n# Subnet http configuration\nresource \"openstack_networking_subnet_v2\" \"http\" {\n  name            = var.network_http[\"subnet_name\"]\n  network_id      = openstack_networking_network_v2.generic.id\n  cidr            = var.network_http[\"cidr\"]\n  dns_nameservers = var.dns_ip\n}\n# Router interface configuration\nresource \"openstack_networking_router_interface_v2\" \"http\" {\n  router_id = openstack_networking_router_v2.generic.id\n  subnet_id = openstack_networking_subnet_v2.http.id\n}\n#### DB NETWORK ####\n# Subnet db configuration\nresource \"openstack_networking_subnet_v2\" \"db\" {\n  name            = var.network_db[\"subnet_name\"]\n  network_id      = openstack_networking_network_v2.generic.id\n  cidr            = var.network_db[\"cidr\"]\n  dns_nameservers = var.dns_ip\n}\n# Router interface configuration\nresource \"openstack_networking_router_interface_v2\" \"db\" {\n  router_id = openstack_networking_router_v2.generic.id\n  subnet_id = openstack_networking_subnet_v2.db.id\n}\nEOT\n6. Create the security group file that will define a security group to be created for your VMs, web servers, and database servers: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n# cat > 030-security_group.tf <<\\EOT\n# Access group, open input port 80 and ssh port\nresource \"openstack_compute_secgroup_v2\" \"http\" {\n  name        = \"http\"\n  description = \"Open input http port\"\n  rule {\n    from_port   = 80\n    to_port     = 80\n    ip_protocol = \"tcp\"\n    cidr        = \"0.0.0.0/0\"\n  }\n}\n# Open mariadb port\nresource \"openstack_compute_secgroup_v2\" \"db\" {\n  name        = \"db\"\n  description = \"Open input db port\"\n  rule {\n    from_port   = 3306\n    to_port     = 3306\n    ip_protocol = \"tcp\"\n    cidr        = \"0.0.0.0/0\"\n  }\n}\n# Open Apache2 port\nresource \"openstack_compute_secgroup_v2\" \"ssh\" {\n  name        = \"ssh\"\n  description = \"Open input ssh port\"\n  rule {\n    from_port   = 22\n    to_port     = 22\n    ip_protocol = \"tcp\"\n    cidr        = \"0.0.0.0/0\"\n  }\n}\nEOT\n7. Create the web server file that will define your web server VMs: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n# cat > 060-instance_http.tf <<\\EOT\n# Get the uiid of image\ndata \"openstack_images_image_v2\" \"http\" {\n  name        = var.image\n  most_recent = true\n}\n# Create instance\n#\nresource \"openstack_compute_instance_v2\" \"http\" {\n  for_each    = var.http_instance_names\n  name        = each.key\n  image_name  = var.image\n  flavor_name = var.flavor_http\n  key_pair    = openstack_compute_keypair_v2.user_key.name\n  user_data   = file(each.value)\n  network {\n    port = openstack_networking_port_v2.http[each.key].id\n  }\n # Install system in volume\n  block_device {\n    volume_size           = var.volume_http\n    destination_type      = \"volume\"\n    delete_on_termination = true\n    boot_index            = 0\n    source_type           = \"image\"\n    uuid                  = data.openstack_images_image_v2.http.id\n    volume_type           = var.volume_type\n }\n}\n# Create network port\nresource \"openstack_networking_port_v2\" \"http\" {\n  for_each       = var.http_instance_names\n  name           = \"port-http-${each.key}\"\n  network_id     = openstack_networking_network_v2.generic.id\n  admin_state_up = true\n  security_group_ids = [\n    openstack_compute_secgroup_v2.ssh.id,\n    openstack_compute_secgroup_v2.http.id,\n  ]\n  fixed_ip {\n    subnet_id = openstack_networking_subnet_v2.http.id\n  }\n}\nEOT\n8. Create the database file that will define the database instance: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n# cat > 061-instance_db.tf <<\\EOT\n#### INSTANCE DB ####\n# Get the uiid of image\ndata \"openstack_images_image_v2\" \"db\" {\n  name        = var.image\n  most_recent = true\n}\n# Create instance\n#\nresource \"openstack_compute_instance_v2\" \"db\" {\n  for_each    = var.db_instance_names\n  name        = each.key\n  image_name  = var.image\n  flavor_name = var.flavor_db\n  key_pair    = openstack_compute_keypair_v2.user_key.name\n  user_data   = file(\"scripts/mariadb.yml\")\n  network {\n    port = openstack_networking_port_v2.db[each.key].id\n  }\n # Install system in volume\n  block_device {\n    volume_size           = var.volume_http\n    destination_type      = \"volume\"\n    delete_on_termination = true\n    boot_index            = 0\n    source_type           = \"image\"\n    uuid                  = data.openstack_images_image_v2.db.id\n    volume_type           = var.volume_type\n }\n}\n# Create network port\nresource \"openstack_networking_port_v2\" \"db\" {\n  for_each       = var.db_instance_names\n  name           = \"port-db-${each.key}\"\n  network_id     = openstack_networking_network_v2.generic.id\n  admin_state_up = true\n  security_group_ids = [\n    openstack_compute_secgroup_v2.ssh.id,\n    openstack_compute_secgroup_v2.db.id,\n  ]\n  fixed_ip {\n    subnet_id = openstack_networking_subnet_v2.db.id\n  }\n}\n#### VOLUME MANAGEMENT ####\n# Create volume\nresource \"openstack_blockstorage_volume_v3\" \"db\" {\n # name = \"volume-db\"\n # size = var.volume_db\n  for_each = var.db_instance_names\n  name     = \"volume-db-${each.key}\"\n  size     = var.volume_db\n  volume_type = var.volume_type\n}\n# Attach volume to instance instance db\nresource \"openstack_compute_volume_attach_v2\" \"db\" {\n  for_each    = var.db_instance_names\n  instance_id = openstack_compute_instance_v2.db[each.key].id\n  volume_id   = openstack_blockstorage_volume_v3.db[each.key].id\n}\nEOT\n9. Create the load balancer file will define load balancers for your VMs and also a public IP address for the web server load balancer: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n# cat > 070-loadbalancer.tf <<\\EOT\n# HTTP LOAD BALANCER CONFIGURATION\n#\n# Create load balancer\nresource \"openstack_lb_loadbalancer_v2\" \"http\" {\n  name          = \"elastic_loadbalancer_http\"\n  vip_subnet_id = openstack_networking_subnet_v2.http.id\n  depends_on    = [openstack_compute_instance_v2.http]\n}\n# Create listener\nresource \"openstack_lb_listener_v2\" \"http\" {\n  name            = \"listener_http\"\n  protocol        = \"TCP\"\n  protocol_port   = 80\n  loadbalancer_id = openstack_lb_loadbalancer_v2.http.id\n  depends_on      = [openstack_lb_loadbalancer_v2.http]\n}\n# Set method for load balancer change between instances\nresource \"openstack_lb_pool_v2\" \"http\" {\n  name        = \"pool_http\"\n  protocol    = \"TCP\"\n  lb_method   = \"ROUND_ROBIN\"\n  listener_id = openstack_lb_listener_v2.http.id\n  depends_on  = [openstack_lb_listener_v2.http]\n}\n# Add multiple instances to pool\nresource \"openstack_lb_member_v2\" \"http\" {\n  for_each      = var.http_instance_names\n  address       = openstack_compute_instance_v2.http[each.key].access_ip_v4\n  protocol_port = 80\n  pool_id       = openstack_lb_pool_v2.http.id\n  subnet_id     = openstack_networking_subnet_v2.http.id\n  depends_on    = [openstack_lb_pool_v2.http]\n}\n# Create health monitor to check service instance status\nresource \"openstack_lb_monitor_v2\" \"http\" {\n  name        = \"monitor_http\"\n  pool_id     = openstack_lb_pool_v2.http.id\n  type        = \"TCP\"\n  delay       = 2\n  timeout     = 2\n  max_retries = 2\n  depends_on  = [openstack_lb_member_v2.http]\n}\n# Create floating IP for http load balancer\nresource \"openstack_networking_floatingip_v2\" \"http\" {\n  pool = \"Public\"\n}\n# Associate\nresource \"openstack_networking_floatingip_associate_v2\" \"http_fip_assoc\" {\n  floating_ip = openstack_networking_floatingip_v2.http.address\n  fixed_ip    = openstack_lb_loadbalancer_v2.http.vip_address\n  port_id     = openstack_lb_loadbalancer_v2.http.vip_port_id\n}\n# DB LOAD BALANCER CONFIGURATION\n#\n# Create load balancer\nresource \"openstack_lb_loadbalancer_v2\" \"db\" {\n  name          = \"elastic_loadbalancer_db\"\n  vip_subnet_id = openstack_networking_subnet_v2.db.id\n  depends_on    = [openstack_compute_instance_v2.db]\n}\n# Create listener\nresource \"openstack_lb_listener_v2\" \"db\" {\n  name            = \"listener_db\"\n  protocol        = \"TCP\"\n  protocol_port   = 3306\n  loadbalancer_id = openstack_lb_loadbalancer_v2.db.id\n  depends_on      = [openstack_lb_loadbalancer_v2.db]\n}\n# Set method for load balancer change between instances\nresource \"openstack_lb_pool_v2\" \"db\" {\n  name        = \"pool_db\"\n  protocol    = \"TCP\"\n  lb_method   = \"ROUND_ROBIN\"\n  listener_id = openstack_lb_listener_v2.db.id\n  depends_on  = [openstack_lb_listener_v2.db]\n}\n# Add multiple instances to pool\nresource \"openstack_lb_member_v2\" \"db\" {\n  for_each      = var.db_instance_names\n  address       = openstack_compute_instance_v2.db[each.key].access_ip_v4\n  protocol_port = 3306\n  pool_id       = openstack_lb_pool_v2.db.id\n  subnet_id     = openstack_networking_subnet_v2.db.id\n  depends_on    = [openstack_lb_pool_v2.db]\n}\n# Create health monitor to check service instance status\nresource \"openstack_lb_monitor_v2\" \"db\" {\n  name        = \"monitor_db\"\n  pool_id     = openstack_lb_pool_v2.db.id\n  type        = \"TCP\"\n  delay       = 2\n  timeout     = 2\n  max_retries = 2\n  depends_on  = [openstack_lb_member_v2.db]\n}\nEOT\n10. Create the configuration files with cloud-init (cloud-config) that will configure your instances on the first boot:Important: The directory name should be scripts, as it is referenced in the instance definitions for the database and web server files. All of the YAML definitions should be located inside the scripts directory.10.1. Create the configuration file for the first web server inside the scripts directory: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\nmkdir scripts\ncd scripts \ncat > first-boot-server1.yaml<<\\EOT\n#cloud-config\npackages:\n  - httpd\n  - policycoreutils-python-utils\n  - mariadb # we need this to test access to the mariadb server later\nruncmd:\n  # Update all packages first\n  #- [ dnf, update, -y ] #uncomment this line if you have time. It takes time to install packages\n  # Enable and start Apache\n  - [ systemctl, enable, httpd ]\n  - [ systemctl, start, httpd ]\n  # Configure firewall to allow HTTP and HTTPS traffic\n  - [ firewall-cmd, --permanent, --add-service=http ]\n  - [ firewall-cmd, --reload ]\n  # Configure SELinux to allow Apache to serve content\n  - [ semanage, fcontext, -a, -t, httpd_sys_content_t, \"/var/www/html(/.*)?\" ]\n  - [ restorecon, -Rv, /var/www/html ]\n  # Restart Apache to apply all changes\n  - [ systemctl, restart, httpd ]\n# This will write a basic test page to the web root\nwrite_files:\n  - path: /var/www/html/index.html\n    content: |\n      <html>\n        <head><title>Test Page</title></head>\n        <body>\n          <h1>Hello, HTTP World! in server1</h1>\n        </body>\n      </html>\n    owner: root:root\n    permissions: '0644'\nEOT\n10.2. Create the configuration file for the second web server: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n# cat > first-boot-server2.yaml<<\\EOT\n#cloud-config\npackages:\n  - httpd\n  - policycoreutils-python-utils\n  - mariadb # we need this to test access to the mariadb server later\nruncmd:\n  # Update all packages first\n #- [ dnf, update, -y ] #uncomment this line if you have time. It takes time to install packages\n  # Enable and start Apache\n  - [ systemctl, enable, httpd ]\n  - [ systemctl, start, httpd ]\n  # Configure firewall to allow HTTP and HTTPS traffic\n  - [ firewall-cmd, --permanent, --add-service=http ]\n  - [ firewall-cmd, --reload ]\n  # Configure SELinux to allow Apache to serve content\n  - [ semanage, fcontext, -a, -t, httpd_sys_content_t, \"/var/www/html(/.*)?\" ]\n  - [ restorecon, -Rv, /var/www/html ]\n  # Restart Apache to apply all changes\n  - [ systemctl, restart, httpd ]\n# This will write a basic test page to the web root\nwrite_files:\n  - path: /var/www/html/index.html\n    content: |\n      <html>\n        <head><title>Test Page</title></head>\n        <body>\n          <h1>Hello, HTTP World! in server2</h1>\n        </body>\n      </html>\n    owner: root:root\n    permissions: '0644'\nEOT\n10.3. Create the configuration file for the third web server: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n# cat > first-boot-server3.yaml<<\\EOT\n#cloud-config\npackages:\n  - httpd\n  - policycoreutils-python-utils\n  - mariadb # we need this to test access to the mariadb server later\nruncmd:\n  # Update all packages first\n  #- [ dnf, update, -y ] #uncomment this line if you have time. It takes time to install packages\n  # Enable and start Apache\n  - [ systemctl, enable, httpd ]\n  - [ systemctl, start, httpd ]\n  # Configure firewall to allow HTTP and HTTPS traffic\n  - [ firewall-cmd, --permanent, --add-service=http ]\n  - [ firewall-cmd, --reload ]\n  # Configure SELinux to allow Apache to serve content\n  - [ semanage, fcontext, -a, -t, httpd_sys_content_t, \"/var/www/html(/.*)?\" ]\n  - [ restorecon, -Rv, /var/www/html ]\n  # Restart Apache to apply all changes\n  - [ systemctl, restart, httpd ]\n# This will write a basic test page to the web root\nwrite_files:\n  - path: /var/www/html/index.html\n    content: |\n      <html>\n        <head><title>Test Page</title></head>\n        <body>\n          <h1>Hello, HTTP World! in server3</h1>\n        </body>\n      </html>\n    owner: root:root\n    permissions: '0644'\nEOT\n10.4. Create the configuration file for the database: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n# cat > mariadb.yml <<\\EOT\n#cloud-config\npackages:\n  - mariadb-server\n  - mariadb\n  - firewalld\n  - policycoreutils-python-utils  # Ensure semanage is available\nruncmd:\n  # Update the system\n  #- [ dnf, update, -y ] #uncomment this line if you have time. It takes time to install packages\n  # Enable and start MariaDB and firewalld\n  - [ systemctl, enable, --now, mariadb ]\n  - [ systemctl, enable, --now, firewalld ]\n  # Configure MariaDB to listen on all interfaces\n  - echo \"[mysqld]\" >> /etc/my.cnf.d/mariadb-server.cnf\n  - echo \"bind-address=0.0.0.0\" >> /etc/my.cnf.d/mariadb-server.cnf\n  # Restart MariaDB to apply configuration changes\n  - [ systemctl, restart, mariadb ]\n  # Secure the installation\n  - [ mysql, -e, \"SET PASSWORD FOR 'root'@'localhost' = PASSWORD('yourStrongPasswordHere'); FLUSH PRIVILEGES;\" ]\n  - [ mysql, -e, \"DELETE FROM mysql.user WHERE User = ''; FLUSH PRIVILEGES;\" ]\n  - [ mysql, -e, \"DELETE FROM mysql.user WHERE User = 'root' AND Host NOT IN ('localhost', '127.0.0.1', '::1'); FLUSH PRIVILEGES;\" ]\n  - [ mysql, -e, \"DROP DATABASE IF EXISTS test; FLUSH PRIVILEGES;\" ]\n  - [ mysql, -e, \"CREATE USER 'remote_user'@'%' IDENTIFIED BY 'anotherStrongPassword';\" ]\n  - [ mysql, -e, \"GRANT ALL PRIVILEGES ON *.* TO 'remote_user'@'%' WITH GRANT OPTION; FLUSH PRIVILEGES;\" ]\n  # Open firewall for remote connections\n  - [ firewall-cmd, --permanent, --add-port=3306/tcp ]\n  - [ firewall-cmd, --reload ]\n  # Adjust SELinux to allow MariaDB to accept remote connections\n  - [ semanage, port, -a, -t, mysqld_port_t, -p, tcp, 3306 ]\n  - [ setsebool, -P, mysql_connect_any, 1 ]\nfinal_message: \"MariaDB server setup is complete and running on: $public_ipv4\"\nEOT\nYour directory should have the following contents: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 00-variables.tf # Variables that we will define for our deployment\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 010-ssh-key.tf  # This file will hold your public SSH key to access the environments\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 020-network.tf  # Network creation/configuration \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 030-security_group.tf # Security Groups creation\n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 060-instance_http.tf  # Web server instances definition \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 061-instance_db.tf    # DB instance definition \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 070-loadbalancer.tf   # Load balancer definition  \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 provider.tf           # OpenStack provider definition \n\u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 scripts\n\u00e2\u0094\u0082   \u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 first-boot-server1.yaml # Cloud-config example for web servers 1 to 3\n\u00e2\u0094\u0082   \u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 first-boot-server2.yaml\n\u00e2\u0094\u0082   \u00e2\u0094\u009c\u00e2\u0094\u0080\u00e2\u0094\u0080 first-boot-server3.yaml\n\u00e2\u0094\u0082   \u00e2\u0094\u0094\u00e2\u0094\u0080\u00e2\u0094\u0080 mariadb.yml             # Cloud-config example for the Maria DB installation\n\u00e2\u0094\u0094\u00e2\u0094\u0080\u00e2\u0094\u0080 secrets.tfvars              # File with the password and info about your cloud\n11. The configuration scripts created for the web servers will install HTTPS (Apache on CentOS). Update the system, enable and start the Apache service, configure the firewall, and add the index.html file with a different message to each web server. When testing the load balancer, this message will show us that we are in the round-robin mode.12. Install, configure, and enable MariaDB on the database server.Now, you are ready to run Terraform commands to deploy the defined Infrastructure as Code in to your Virtuozzo Hybrid Infrastructure project.1. Initialize Terraform:1\n# terraform init\nThe command output should be similar to the following:2. Once Terraform is successfully initialized, run the terraform plan command:1\n# terraform plan -var-file=\"secrets.tfvars\"\n3. If the previous command was successful, proceed with the deployment:1\n# terraform apply -var-file=\"secrets.tfvars\"\nThe command will create the following resources:\n\nNow, when you access your web servers at the load balancer public IP address, you will see the following:Finally, add a floating IP address to one of your web servers and try to access MariaDB on the database server (the password is anotherStrongPassword):1\n# mariadb -u remote_user  -e \"SHOW DATABASES;\" -h 192.168.2.26 -p\nTo delete all of the created workloads, run the terraform destroy command:1\n# terraform destroy -var-file=\"secrets.tfvars\"\nTo more details, refer to the Terraform documentation.Enjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/infrastructure-management-with-terraform/"
    },
    {
        "title": "How to deploy Virtuozzo Hybrid Infrastructure on OVHcloud Bare Metal",
        "content": "How to deploy Virtuozzo Hybrid Infrastructure on OVHcloud Bare MetalThis guide describes how to deploy Virtuozzo Hybrid Infrastructure on an OVHcloud Bare Metal instance.Network port considerationsFor deploying Virtuozzo Hybrid Infrastructure, it is recommended to have two high-speed interfaces (25 Gbps) for storage traffic that are bonded in LACP. This will provide both redundancy and load sharing.In this example, two ports with 25 Gbps are assigned inside the vRack, and two ports with 1 Gbps are assigned to the public network. In this case, Virtuozzo Hybrid Infrastructure will use the vRack-based ports only.vRack allocationThe OVHcloud vRack (virtual rack) allows multiple servers, IP subnets, cloud instances, and other, to be grouped together in one logical unit. VLAN-based private communication between bare metal servers is not possible without the vRack, thus Virtuozzo Hybrid Infrastructure needs to have it assigned.In this example, the vRack includes five servers in a single project, and there are two IP subnets that can be assigned to the vRack.Server location recommendationsOVHcloud Bare Metal instances can be gained from multiple OVHcloud data centers. These data centers are located considerably distant from each other. Though they are connected via fiber links, node-to-node latency between them is around 400 microseconds, while typically it is less than 20 microseconds inside a single zone. Thus, it is recommended to place nodes in a single data center, if possible.Such data infrastructure allows deploying data center-based redundancy schemes. In this case, data redundancy is achieved by placing replicas (or erasure codes) in different data centers for each write operation, but high latency decreases storage performance.The server location is displayed in the OVHcloud Control Panel.Let\u2019s take a look at the latency values measured in the Paris data center from multiple zones:Latency inside the same zone is less than 20 microseconds, while it varies significantly between zones, as expected.These values are gathered from servers located in the 3-AZ offers. Keep in mind that latency values in other OVHcloud data centers will vary. It is worth noting that the observed 400-microsecond latency between distant data centers is quite a good (low) value, compared to other offerings in the market. However, to reach the lowest possible latency values, we recommend using servers in the same data center location.vRack construction and VLAN settingsOVHcloud allows servers inside the vRack to communicate with each other by using VLANs. Ports inside the vRack are tagged and allowed for all VLANs. Servers can be configured with arbitrary VLAN numbers, there is no need to configure any VLANs in the OVHcloud Control Panel once ports are inside the vRack. IP addresses that will be used between servers can be assigned by choice. Tagged VLANs are isolated entities enclosed inside the vRack that have no outside communication. Only one VLAN, VLAN 0, is untagged and can communicate with the outside world. IP subnets assigned to the vRack are assigned to VLAN 0. It is not possible to assign a public IP subnet to a tagged VLAN in OVHcloud.Such a structure does not meet the Virtuozzo Hybrid Infrastructure requirements. In this case, we recommend using a public network with a public IP subnet that has its own tagged VLAN.For IP subnets inside VLANs, the setup requires additional components. Instead of having public IP subnets assigned to the vRack, they need to be assigned to an instance, which will be used as a router. This instance with ports inside the vRack will act as a simple router to forward IP subnets to be used in certain VLANs inside the vRack.Here is an example of the required architecture:The router instance has two external ports and ports assigned to the vRack. It routes the public subnets into the VLANs inside the vRack. All public IP subnets are assigned to the router instance only.The router instance can be one of the bare metal servers inside the vRack or a virtual machine that performs routing, with interfaces inside the vRack assigned to appropriate VLANs. The first option is more expensive but provides the best routing performance.Network planning for Virtuozzo Hybrid InfrastructureIn our sample architecture, we use four VLANs configured on top of a bond with the LACP bonding inside the vRack:VLAN A is used for the API and also can be deployed as a reserved IP space. In this case, however, the routing instance needs to perform network address translation (NAT) for the node addresses and, if high availability is enabled, for the virtual IP address of the management node.VLAN B is the public IP address space used by consumers of the cloud platform formed by Virtuozzo Hybrid Infrastructure. There can be multiple such IP subnets, each of which will be assigned to the router instance and will be routed to another VLAN inside the vRack. In Virtuozzo Hybrid Infrastructure, such IP subnets will appear as physical networks with the assigned \u201cVM public\u201d traffic type.VLAN C is used for internal communication between servers.VLAN D is dedicated to storage.VLANs C and D are private networks without external connectivity where one can use any RFC 1918 reserved IP addresses.Installation considerations for Virtuozzo Hybrid InfrastructureOVHcloud bare metal instances have the IPMI console available in the OVHcloud Control panel. The distribution ISO image for Virtuozzo Hybrid Infrastructure can be mapped as a virtual CD-ROM in the OVHcloud Control panel. To boot from the distribution ISO image, a server needs to enter the BIOS setup to change the boot option to the UEFI-based virtual CD-ROM. Since the remote file mapping is performed via the internet, booting and running the installer is quite slow.Virtuozzo Hybrid Infrastructure has a GUI-based installer. After loading Anaconda, the installer switches to the graphical interface. The the web-based console panel may fail to initialize the X Window System that runs the graphical interface. To prevent this, the timeout for initializing the X Window System should be increased. Do the following:1. Stop the installer on the first GRUB screen by pressing E.2. Add inst.xtimeout=480 \u00c4\u00b1n the kernel parameters to increase the X Window System timeout to 480 seconds.3. Press CTRL+X to continue the boot process with the provided parameters, and then wait for the X Window System to run the graphical interface.Enjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/vhi-on-ovhcloud-bare-metal/"
    },
    {
        "title": "4.3. Adding New BitNinja Service (Product)\u00c2\u00b6",
        "content": "4.3. Adding New BitNinja Service (Product) | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n4.3. Adding New BitNinja Service (Product)\u00c2\u00b6\n\nNow we will create a new service, go to Settings > Products & Services, and Add new order Page. From Order Types select Other. After Creating the order page, you can now add a new product. Provide a name and make sure to save the changes.\nIn the product configuration section proceed to Connect with App, make sure you select the BitNinja module and App server created in the previous steps.\nMark the \u00e2\u0080\u009cAllow Client to adjust during order\u00e2\u0080\u009d next to \u00e2\u0080\u009cIP Address\u00e2\u0080\u009d. This will allow the user to provide an IP address which will be associated with a license later on. To use the BitNinja product as a subproduct check https://hostbill.atlassian.net/wiki/spaces/DOCS/pages/377553192/Sub-products.\n\nClick on save changes.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/hostbill-bitninja/adding-bitninja-product.html"
    },
    {
        "title": "1. Integration Overview\u00c2\u00b6",
        "content": "1. Integration Overview | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n1. Integration Overview\u00c2\u00b6\nIn this document, when we refer to BitNinja integration, we are referring to the ways in which a cloud provider can make the BitNinja Full-Server Protection Service available on their Billing Platform marketplace.\nThe installation of the BitNinja Full-Server protection software itself to protect a workload is very simple, it\u00e2\u0080\u0099s just a one-line installation step which we will also describe.\nOur goal is to help cloud providers drive consumption, by simplifying how the end user can purchase the BitNinja Solution Software and offer it as a service on the cloud provider\u00e2\u0080\u0099s Billing/Marketplace platforms integrated with our solutions (VHI, VHS and OnApp).\nWe will discuss the following methods:\n\nWHMCS\u00e2\u0080\u0099s BitNinja Marketplace module (Free).\nHostBill\u00e2\u0080\u0099s BitNinja Marketplace module (Available with the \u00e2\u0080\u009cAll inclusive\u00e2\u0080\u009d HostBill License or the developer addon $99 one-time purchase).\n\nWHMCS and HostBill are billing platforms which also offer leverage a marketplace where the cloud provider can create VPSs packages or sell additional services. We recommend using the available modules for WHMCS and HostBill.\nThis guide will provide a basic overview of the BitNinja solution, enumerate minimum system requirements for the workloads to be protected, and will walk you through the different integration methods. We will also look at the limitations, available support, and documentation for the BitNinja Full-stack server protection on Virtuozzo Hybrid Infrastructure.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/integration-overview.html"
    },
    {
        "title": "10. Preparing Master Images\u00c2\u00b6",
        "content": "10. Preparing Master Images | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n10. Preparing Master Images\u00c2\u00b6\nLeostream can manage connections to existing virtual machines and provision new virtual machines from existing Virtuozzo Hybrid Infrastructure images.\n\nImportant\nCurrently, you cannot create new images within the Leostream interface. All images must be created using native Virtuozzo Hybrid Infrastructure tools.\n\nIn this chapter:\n\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/preparing-master-images/index.html"
    },
    {
        "title": "Welcome to Virtuozzo Hybrid Infrastructure",
        "content": "Welcome to Virtuozzo Hybrid Infrastructure\nVirtuozzo Hybrid Infrastructure, previously known as Virtuozzo Infrastructure Platform, is a hyperconverged solution providing storage, compute, and network resources for businesses and service providers to:\n\nDeliver file storage for any corporate data, S3 object storage for applications and cloud services, and block storage for running virtual machines or databases with iSCSI targets\nBuild and manage private or public clouds with the Disaster Recovery solution\nStore backups from Acronis Cyber Protect solutions on premises, in public clouds, or on NAS by using the Backup Gateway\nCreate and manage virtual machines and software-defined networks\nRun cloud-native applications in production environments, including Kubernetes as a Service, Load Balancer as a Service, Backup and Restore as a Service, and Persistent Storage for Kubernetes\nEnsure high availability for business-critical applications\n\nThe scheme below shows the Virtuozzo Hybrid Infrastructure components and the order, in which you deploy them. You start with deploying the infrastructure, then configure networks and storage, and finally, provision services to end users. Hover over any component to see the list of related links.\n\nAbout the infrastructure\n\nSystem requirements\n\nInstallation\n\nManaging the infrastructure\n\nViewing alerts\n\nViewing audit log\n\nInfrastructure\n\nSetting up networks\n\nConfiguring node network interfaces\n\nEnabling RDMA\n\nAdding external DNS servers\n\nManaging infrastructure networks\n\nNetworks\n\nAbout the storage cluster\n\nDeploying the storage cluster\n\nMonitoring the storage cluster\n\nShutting down and starting up the cluster\n\nReleasing nodes from the storage cluster\n\nStorage\n\nAbout the compute cluster\n\nCompute cluster requirements\n\nProvisioning compute resources\n\nManaging the compute cluster\n\nMonitoring the compute cluster\n\nCompute cluster \n\nAbout Acronis Backup Storage\n\nAcronis Backup Storage requirements\n\nProvisioning Acronis Backup Storage space\n\nManaging Acronis Backup Storage\n\nMonitoring Acronis Backup Storage\n\nBackup storage \n\nAbout block storage\n\nProvisioning block storage space\n\nManaging block storage\n\nMonitoring block storage\n\nAbout object storage\n\nProvisioning object storage space\n\nManaging object storage\n\nMonitoring object storage\n\nAbout file storage\n\nProvisioning file storage space\n\nManaging file storage\n\nMonitoring file storage\n\nBlock storage\n\nObject storage\n\nFile storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/welcome.html"
    },
    {
        "title": "Managing virtual machines",
        "content": "Managing virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-virtual-machines.html"
    },
    {
        "title": "Introduction",
        "content": "Introduction\nVirtuozzo Hybrid Infrastructure represents a new generation of hyperconverged infrastructures targeted at both service providers and end customers. It is a scale-out, cost-efficient, and multi-purpose solution that combines universal storage and high-performance virtualization.\nThis guide describes how to set up a full-fledged storage cluster on three nodes, deploy a compute cluster on top of it, and create a virtual machine.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/introduction.html"
    },
    {
        "title": "Uninstalling guest tools",
        "content": "Uninstalling guest tools\nIf you find out that the guest tools are incompatible with some software inside a virtual machine, you can uninstall them.\nPrerequisites\n\nThe guest tools are installed inside the virtual machine, as described in Installing guest tools.\n\nTo uninstall guest tools\n\nInside a Windows VM:\n\nRemove the QEMU device drivers from the device manager.\n\nDo not remove the VirtIO/SCSI hard disk driver and NetKVM network driver. Without the former, the VM will not boot; without the latter, the VM will lose network connectivity.\n\nUninstall the QEMU guest agent and guest tools from the list of installed applications.\n\nStop and delete Guest Tools Monitor:> sc stop VzGuestToolsMonitor\r\n> sc delete VzGuestToolsMonitor\r\n\n\nUnregister Guest Tools Monitor from Event Log:> reg delete HKLM\\SYSTEM\\CurrentControlSet\\services\\eventlog\\Application\\\\\r\nVzGuestToolsMonitor\r\n\n\nDelete the autorun registry key for RebootNotifier:> reg delete HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run /v \\\r\nVzRebootNotifier\r\n\n\nDelete the C:\\Program Files\\Qemu-ga\\ directory.\nIf VzGuestToolsMonitor.exe is locked, close all the Event Viewer windows. If it remains locked, restart the eventlog service:> sc stop eventlog\r\n> sc start eventlog\r\n\n\nAfter removing the guest tools, restart the virtual machine.\n\nInside a Linux VM:\n\nRemove the packages:\n\nOn RPM-based systems (CentOS and other):# yum remove dkms-vzvirtio_balloon prl_nettool qemu-guest-agent-vz \\vz-guest-udev\r\n\n\nOn DEB-based systems (Debian and Ubuntu):# apt-get remove vzvirtio-balloon-dkms prl-nettool qemu-guest-agent-vz \\vz-guest-udev\r\n\nIf any of the packages listed above are not installed on your system, the command will fail. In this case, exclude these packages from the command and run it again.\n\nRemove the files:# rm -f /usr/bin/prl_backup /usr/share/qemu-ga/VERSION \\/usr/bin/install-tools \\\r\n/etc/udev/rules.d/90-guest_iso.rules /usr/local/bin/fstrim-static \\/etc/cron.weekly/fstrim\r\n\n\nReload the udev rules:# udevadm control --reload\r\n\n\nAfter removing guest tools, restart the virtual machine.\n\nSee also\n\nManaging virtual machine power state\n\nReconfiguring virtual machines\n\nTroubleshooting virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/uninstalling-guest-tools.html"
    },
    {
        "title": "Creating VPN services",
        "content": "Creating VPN servicesPOST /v2.0/vpn/vpnservices\nCreate a VPN service.\nThe service is associated with a router. After you create the service, it can contain multiple VPN connections.\nAn optional flavor_id attribute can be passed to enable dynamic selection of an appropriate provider if configured by the operator. It is only available when vpn-flavors extension is enabled. The basic selection algorithm chooses the provider in the first service profile currently associated with flavor. This option can only be set in POST operation.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-vpn-service-detail#create-vpn-service\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nvpnservice\n\nbody\nobject\nA vpnservice object.\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\nsubnet_id (Optional)\nbody\nstring\nIf you specify only a subnet UUID, the networking service allocates an available IP from that subnet to the port. If you specify both a subnet UUID and an IP address, the networking service tries to allocate the address to the port.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nflavor_id (Optional)\nbody\nstring\nThe ID of the flavor.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"vpnservice\": {\r\n        \"subnet_id\": null,\r\n        \"router_id\": \"66e3b16c-8ce5-40fb-bb49-ab6d8dc3f2aa\",\r\n        \"name\": \"myservice\",\r\n        \"admin_state_up\": true,\r\n        \"flavor_id\": null\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/vpnservices\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvpnservice\n\nbody\nobject\nA vpnservice object.\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec VPN service is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nexternal_v4_ip\n\nbody\nstring\nThe read-only external (public) IPv4 address that is used for the VPN service. The VPN plugin sets this address if an IPv4 interface is available.\n\nexternal_v6_ip\n\nbody\nstring\nThe read-only external (public) IPv6 address that is used for the VPN service. The VPN plugin sets this address if an IPv6 interface is available.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\nsubnet_id (Optional)\nbody\nstring\nIf you specify only a subnet UUID, the networking service allocates an available IP from that subnet to the port. If you specify both a subnet UUID and an IP address, the networking service tries to allocate the address to the port.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nflavor_id\n\nbody\nstring\nThe ID of the flavor.\n\nid\n\nbody\nstring\nThe ID of the VPN service.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"vpnservice\": {\r\n    \"id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n    \"name\": \"vpnservice\",\r\n    \"description\": \"\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"subnet_id\": null,\r\n    \"router_id\": \"923f2578-079e-40f1-b0a9-23c2b48dbdcd\",\r\n    \"flavor_id\": null,\r\n    \"admin_state_up\": true,\r\n    \"external_v4_ip\": \"10.136.18.148\",\r\n    \"external_v6_ip\": null,\r\n    \"status\": \"PENDING_CREATE\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-vpn-services.html"
    },
    {
        "title": "Releasing nodes from the NFS cluster",
        "content": "Releasing nodes from the NFS cluster\nLimitations\n\nWhen the last node in the NFS cluster is removed, the cluster is destroyed and all of the data is deleted.\n\nPrerequisites\n\nThe NFS cluster is created, as described in Creating the NFS cluster.\n\nTo release a node from the NFS cluster\n\nAdmin panel\n\nGo to the Storage services > NFS > Nodes screen.\nClick a node to release, and then click Release on the right pane.\nIf a node has shares, it can only be released after deleting all of them. To release such a node, select Delete all shares on this node, and then click Release in the confirmation window.\n\nCommand-line interface\n\nTo release not the last node from the NFS cluster, run:# vinfra service nfs node release --nodes <node>\n\nTo release the last node and destroy the NFS cluster, run:# vinfra service nfs cluster delete\n\nSee also\n\nMonitoring file storage\n\nAdding nodes to the NFS cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nTo release not the last node from the NFS cluster, run:# vinfra service nfs node release --nodes <node>\n\n\nTo release the last node and destroy the NFS cluster, run:# vinfra service nfs cluster delete\n\n\n",
                "title": "To release a node from the NFS cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Nodes screen.\nClick a node to release, and then click Release on the right pane.\nIf a node has shares, it can only be released after deleting all of them. To release such a node, select Delete all shares on this node, and then click Release in the confirmation window.\n\n",
                "title": "To release a node from the NFS cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/releasing-nfs-nodes.html"
    },
    {
        "title": "Restoring virtual machines from backups",
        "content": "Restoring virtual machines from backups\nDuring the restore process, a new virtual machine is deployed and the existing VM is not overwritten. You can restore a VM from a backup of a boot volume only.\nPrerequisites\n\nA volume backup is created automatically, as described in Creating backup plans, or manually,  as described in Creating and deleting backups manually.\n\nTo restore a virtual machine\n\nAdmin panel\n\nOn the Compute > Backup > Recovery points tab, click the recovery point from which you want to restore a VM.\nOn the right pane, click Restore virtual machine.\n\nIn the Restore virtual machine window, the boot volume will be defined automatically and will be restored from the selected recovery point. Specify all other VM parameters, as described in Creating virtual machines.\n\nClick Deploy.\n\nThe new virtual machine will appear on the Compute > Virtual machines > Virtual machines screen.\n\nCommand-line interface\nUse the following command:vinfra service compute server create [--description <description>]\r\n                                     [--metadata <metadata>]\r\n                                     [--user-data <user-data>]\r\n                                     [--key-name <key-name>]\r\n                                     [--config-drive] [--count <count>]\r\n                                     [--ha-enabled {true,false}]\r\n                                     [--placements <placements>]\r\n                                     [--allow-live-resize] [--uefi]\r\n                                     --network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\r\n                                     --volume <source=source\r\n                                     [,key=value,\u00e2\u0080\u00a6]>\r\n                                     --flavor <flavor> <server-name>\r\n\n\n--description <description>\n\nVirtual machine description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--metadata <metadata>\n\nVirtual machine metadata\n--user-data <user-data>\n\nUser data file\n--key-name <key-name>\n\nKey pair to inject\n--config-drive\n\nUse an ephemeral drive\n--count <count>\n\nIf count is specified and greater than 1, the name argument is treated as a naming pattern.\n--ha-enabled {true,false}\n\nEnable or disable HA for the virtual machine.\n--placements <placements>\n\nNames or IDs of placements to add the virtual machine to.\n--allow-live-resize\n\nAllow online resize for the virtual machine.\n--uefi\n\nAllow UEFI boot for the virtual machine. This option can be used for VMs created from ISO images.\n--network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\n\nCreate a virtual machine with a specified network. Specify this option multiple times to create multiple networks.\n\nid: attach network interface to a specified network (ID or name)\ncomma-separated key=value pairs with keys (optional):mac: MAC address for network interfacefixed-ip: fixed IP address or None to automatically allocate an IP address. This option can be used multiple times.spoofing-protection-enable: enable spoofing protection for network interfacespoofing-protection-disable: disable spoofing protection for network interfacesecurity-group: security group ID or name. This option can be used multiple times.no-security-group: do not use a security group\n\n--volume <source=backup,id=<id>[,storage-policy=<storage-policy>]>\n\nRestore a virtual machine from a backup. Specify this option multiple times to create multiple volumes.\n\nsource: the backup source type\ncomma-separated key=value pairs with keys:id: backup IDstorage-policy: block device storage policy (optional)\n\n--flavor <flavor>\n\nFlavor ID or name\n<server-name>\n\nA new name for the virtual machine\n\nFor example, to restore the virtual machine myvm from the backup with the ID c04ac70b-a436-4271-be1e-b7a93189b44f and the flavor tiny, connect it to the virtual network private with the fixed IP address 192.168.128.200, run:# vinfra service compute server create myvm --network id=private,fixed-ip=192.168.128.200 \\\r\n--volume source=backup,id=c04ac70b-a436-4271-be1e-b7a93189b44f,size=1 --flavor tiny\r\n\n\nSee also\n\nManaging virtual machines\n\nRestoring volumes from backups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server create [--description <description>]\r\n                                     [--metadata <metadata>]\r\n                                     [--user-data <user-data>]\r\n                                     [--key-name <key-name>]\r\n                                     [--config-drive] [--count <count>]\r\n                                     [--ha-enabled {true,false}]\r\n                                     [--placements <placements>]\r\n                                     [--allow-live-resize] [--uefi]\r\n                                     --network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\r\n                                     --volume <source=source\r\n                                     [,key=value,\u00e2\u0080\u00a6]>\r\n                                     --flavor <flavor> <server-name>\r\n\n\n--description <description>\n\n\nVirtual machine description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--metadata <metadata>\n\nVirtual machine metadata\n--user-data <user-data>\n\nUser data file\n--key-name <key-name>\n\nKey pair to inject\n--config-drive\n\nUse an ephemeral drive\n--count <count>\n\nIf count is specified and greater than 1, the name argument is treated as a naming pattern.\n--ha-enabled {true,false}\n\nEnable or disable HA for the virtual machine.\n--placements <placements>\n\nNames or IDs of placements to add the virtual machine to.\n--allow-live-resize\n\nAllow online resize for the virtual machine.\n--uefi\n\nAllow UEFI boot for the virtual machine. This option can be used for VMs created from ISO images.\n--network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\n\n\nCreate a virtual machine with a specified network. Specify this option multiple times to create multiple networks.\n\nid: attach network interface to a specified network (ID or name)\ncomma-separated key=value pairs with keys (optional):mac: MAC address for network interfacefixed-ip: fixed IP address or None to automatically allocate an IP address. This option can be used multiple times.spoofing-protection-enable: enable spoofing protection for network interfacespoofing-protection-disable: disable spoofing protection for network interfacesecurity-group: security group ID or name. This option can be used multiple times.no-security-group: do not use a security group\n\n\n--volume <source=backup,id=<id>[,storage-policy=<storage-policy>]>\n\n\nRestore a virtual machine from a backup. Specify this option multiple times to create multiple volumes.\n\nsource: the backup source type\ncomma-separated key=value pairs with keys:id: backup IDstorage-policy: block device storage policy (optional)\n\n\n--flavor <flavor>\n\nFlavor ID or name\n<server-name>\n\nA new name for the virtual machine\n\nFor example, to restore the virtual machine myvm from the backup with the ID c04ac70b-a436-4271-be1e-b7a93189b44f and the flavor tiny, connect it to the virtual network private with the fixed IP address 192.168.128.200, run:# vinfra service compute server create myvm --network id=private,fixed-ip=192.168.128.200 \\\r\n--volume source=backup,id=c04ac70b-a436-4271-be1e-b7a93189b44f,size=1 --flavor tiny\r\n\n",
                "title": "To restore a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Recovery points tab, click the recovery point from which you want to restore a VM.\nOn the right pane, click Restore virtual machine.\n\nIn the Restore virtual machine window, the boot volume will be defined automatically and will be restored from the selected recovery point. Specify all other VM parameters, as described in Creating virtual machines.\n\n\n\n\n\nClick Deploy.\n\nThe new virtual machine will appear on the Compute > Virtual machines > Virtual machines screen.\n",
                "title": "To restore a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/restoring-vms-from-backups.html"
    },
    {
        "title": "Setting a DNS name for the compute API",
        "content": "Setting a DNS name for the compute API\nBy means of the Compute API traffic type, Virtuozzo Hybrid Infrastructure exposes a public endpoint that listens to OpenStack API requests. By default, it points to the IP address of the management node (or to its virtual IP address if high availability is enabled).\nIn some cases, you need to modify all public endpoints to use the domain name resolvable to the management node IP address (or its virtual IP), for example, to secure OpenStack API traffic with an SSL certificate without the subjectAltName field or to make the Kubernetes service access the compute API via the DNS name.\nTo modify all public endpoints to use the domain name\n Use the following command:vinfra service compute set [--endpoint-hostname <hostname>]\n\n--endpoint-hostname <hostname>\n\nUse the given hostname for a public endpoint. Specify an empty value in quotes to use the raw IP.\n\nFor example, to use dns-name.example for public endpoints, run:# vinfra service compute set --endpoint-hostname dns-name.example\r\n+---------+--------------------------------------+\r\n| Field   | Value                                |\r\n+---------+--------------------------------------+\r\n| task_id | 534391a2-946a-4406-8dc0-756f161cd595 |\r\n+---------+--------------------------------------+\r\n\nWait until the task is complete:# vinfra task show 534391a2-946a-4406-8dc0-756f161cd595\r\n+---------+------------------------------------------------------------------+\r\n| Field   | Value                                                            |\r\n+---------+------------------------------------------------------------------+\r\n| details |                                                                  |\r\n| name    | backend.presentation.compute.tasks.ReconfigureComputeClusterTask |\r\n| result  |                                                                  |\r\n| state   | success                                                          |\r\n| task_id | 534391a2-946a-4406-8dc0-756f161cd595                             |\r\n+---------+------------------------------------------------------------------+\r\n\nTo check that the domain name is used instead of the management node IP address:\n\nGenerate or regenerate the admin OpenRC script:# kolla-ansible post-deploy\r\n\n\nRun the script:# source /etc/kolla/admin-openrc.sh\r\n\n\nList the public endpoints:# openstack --insecure endpoint list | grep public\r\n| 5a845b4b<...> | <...> | https://dns-name.example:8780                    |\r\n| 7d901686<...> | <...> | https://dns-name.example:8776/v2/%(tenant_id)s   |\r\n| 44aa0f53<...> | <...> | https://dns-name.example:8774/v2.1/%(tenant_id)s |\r\n| 0e6d3a39<...> | <...> | https://dns-name.example:9292                    |\r\n| 0b906e51<...> | <...> | https://dns-name.example:9696                    |\r\n| 1b68ac7c<...> | <...> | https://dns-name.example:8776/v3/%(tenant_id)s   |\r\n| d80af756<...> | <...> | https://dns-name.example:8004/v1/%(tenant_id)s   |\r\n| d0e8c7da<...> | <...> | https://dns-name.example:5000/v3                 |\r\n\n\nWhat's next\n\nSecuring OpenStack API traffic with SSL",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-dns-name-for-the-compute-api.html"
    },
    {
        "title": "Hardware recommendations",
        "content": "Hardware recommendations\n\nVirtuozzo Hybrid Infrastructure works on the same hardware that is recommended for Red Hat Enterprise Linux 9, including AMD EPYC processors: servers, components.\nEven though a cluster can be created on top of varied hardware, by using nodes with similar hardware in each node will yield better cluster performance, capacity, and overall balance.\nIt is recommended to use UEFI instead of BIOS if this supported by your hardware. This is recommended particularly if you use NVMe drives.\nAny cluster infrastructure must be tested extensively before it is deployed to production. Such common points of failure as SSD drives and network adapter bonds must always be thoroughly verified.\n\nSee also\n\nServer requirements\n\nDisk requirements\n\nNetwork requirements and recommendations\n\nAdmin panel requirements",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/hardware-recommendations.html"
    },
    {
        "title": "Attaching external iSCSI storage",
        "content": "Attaching external iSCSI storage\nThe OpenStack Cinder iSCSI driver allows you to mount multiple iSCSI targets to your compute cluster and use them as external iSCSI storages. As the driver is based on the iSCSI storage protocol, compute nodes must be configured to support multipathing.\nTo enable multipathing\nOn each compute node, configure and start the multipathing service:\n\nEdit the configuration file /etc/multipath.conf as follows:defaults {\r\n    user_friendly_names yes\r\n    find_multipaths yes\r\n    polling_interval 10\r\n}\r\ndevices {\r\n  device {\r\n    vendor \"PURE\"\r\n    product \"FlashArray\"\r\n    fast_io_fail_tmo 10\r\n    path_grouping_policy \"group_by_prio\"\r\n    failback \"immediate\"\r\n    prio \"alua\"\r\n    hardware_handler \"1 alua\"\r\n    max_sectors_kb 4096\r\n  }\r\n}\r\n\r\nblacklist {\r\n  device {\r\n    vendor \"QEMU\"\r\n    product \".*\"\r\n  }\r\n}\nIn this example, vendor and product specify the vendor and product names of a Pure Storage device. To configure multipathing for other iSCSI storages, you need to specify these attributes according to your storage documentation.\nFor more details about the multipathing configuration, refer to Linux Recommended Settings.\n\nLoad the kernel module:# modprobe dm-multipath\n\nLaunch and enable the multipathing service:\r\n# systemctl start multipathd; systemctl enable multipathd\n\nTo attach an external iSCSI storage\nUse the following command:vinfra service compute storage add <storage_name> --params volume_driver=<openstack_volume_driver_name>,\r\n                               san_ip=<ip_address>,image_volume_cache_enabled=True,use_multipath_for_image_xfer=True\r\n                               --secret-params pure_api_token=<token> [--param <param=value>]\r\n                               [--secret-param <key=value>] --enable\nWhere:\n\n<storage_name> is a custom name of your external storage. The name may only contain letters, numbers, and underscores, and must be 3 to 64 characters long.\nvolume_driver=<openstack_volume_driver_name> is the name of the OpenStack volume driver. For example, cinder.volume.drivers.pure.PureISCSIDriver.\nsan_ip=<ip_address> is the IP address of the external storage to connect to.\nimage_volume_cache_enabled should be set to True to enable image-volume caching for the external storage, to improve the performance of creating a volume from an image.\nuse_multipath_for_image_xfer should be set to True for multipath setups. Do not specify this parameter if multipathing is disabled.\n--secret-params is intended to be used for sensitive data, like passwords or tokens. For example, pure_api_token=<token> is the API token for a Pure Storage solution.\n--param and --secret-param are intended for single parameters with values containing the comma symbol. For example, replication_device=backend_id:<storage_name>,san_ip:<ip_address>,api_token:<token>,type:<replication_type>.\n\nFor example, to add the external storage pure_storage with the IP address 10.10.10.11, run:# vinfra service compute storage add pure_storage --params volume_driver=cinder.volume.drivers.pure.PureISCSIDriver,\\\r\nsan_ip=10.10.10.11,use_multipath_for_image_xfer=True,image_volume_cache_enabled=True \\\r\n--secret-params pure_api_token=7acb5db8-d312-4f66-b076-f556d6fa1232 --enable\nThere is also a storage-specific shortcut. You can specify the --pure option, to automatically set the following parameters required for Pure Storage:\n\nvolume_backend_name to the external storage name specified by <storage_name>.\nvolume_driver to the name of the Pure Storage iSCSI volume driver, which is cinder.volume.drivers.pure.PureISCSIDriver.\nuse_multipath_for_image_xfer to True to allow multipathing.\n\nFor example, to add the external storage pure_storage with the IP address 10.10.10.11, run:# vinfra service compute storage add pure_storage --pure --params san_ip=10.10.10.11,image_volume_cache_enabled=True \\\r\n--secret-params pure_api_token=7acb5db8-d312-4f66-b076-f556d6fa1232 --enable\r\n\n\nEnsure that the data specified is valid. An incorrectly configured storage will lead to the critical state of the cinder-volume service and the node itself. However, all other operations on the node will not be affected.\n\nThe added external storage will appear in the vinfra service compute storage list output:# vinfra service compute storage list\r\n+--------------+-----------------------------------------------------------+-----------------------+---------+------------+\r\n| name         | params                                                    | secret_params         | enabled | configured |\r\n+--------------+-----------------------------------------------------------+-----------------------+---------+------------+\r\n| pure_storage | san_ip: 10.10.10.11                                       | pure_ip_token: ****** | True    | True       |\r\n|              | use_multipath_for_image_xfer: True                        |                       |         |            |\r\n|              | image_volume_cache_enabled: True                          |                       |         |            |\r\n|              | volume_backend_name: pure_storage                         |                       |         |            |\r\n|              | volume_driver: cinder.volume.drivers.pure.PureISCSIDriver |                       |         |            |\r\n+--------------+-----------------------------------------------------------+-----------------------+---------+------------+\nSee also\n\nAttaching external NFS storage\n\nDetaching external storages\n\nWhat's next\n\nCreating external storage policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/attaching-external-iscsi-storage.html"
    },
    {
        "title": "Managing the compute network",
        "content": "Managing the compute network\nIn Virtuozzo Hybrid Infrastructure, compute networking includes compute networks, security groups, virtual routers, floating public IP addresses, and network load balancers.\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-the-compute-network.html"
    },
    {
        "title": "Managing static routes",
        "content": "Managing static routes\nYou can also configure static routes of a router by manually adding entries into its routing table. This can be useful, for example, if you do not need a mutual connection between two virtual networks and want only one virtual network to be accessible from the other.\nConsider the following example:\n\nThe virtual machine VM1 is connected to the virtual network private1 (192.168.128.0/24) via the network interface with IP address 192.168.128.10.\nThe virtual machine VM2 is connected to the virtual network private2 (192.168.30.0/24) via the network interface with IP address 192.168.30.10.\nThe router router1 connects the network private1 to the physical network via the external gateway with the IP address 10.94.129.73.\nThe router router2 connects the network private2 to the physical network via the external gateway with the IP address 10.94.129.74.\n\nTo be able to access VM2 from VM1, you need to add a static route for router1, specifying the CIDR of private2, that is 192.168.30.0/24, as the destination subnet and the external gateway IP address of router2, that is 10.94.129.74, as the next hop IP address. In this case, when an IP packet for 192.168.30.10 reaches router1, it will be forwarded to router2 and then to VM2.\nPrerequisites\n\nYou have a virtual router created, as described in Managing virtual routers.\n\nTo create a static route for a router\n\nOn the Routers screen, click the router name. Open the Static routes tab, and then click Add on the right pane. If there are no routes to show, click Add static route.\n\nIn the Add static route window, specify the destination subnet range and mask in CIDR notation and the next hop\u00e2\u0080\u0099s IP address. The next hop\u00e2\u0080\u0099s IP address must belong to one of the networks that the router is connected to.\n\nClick Add.\n\nTo edit a static route\n\nClick the ellipsis icon next to the required static route, and then click Edit. \nIn the Edit static route window, change the desired parameters, and then click Save.\n\nTo remove a static route\n\nClick the ellipsis icon next to the static route you want to remove, and then click Delete. ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-static-routes.html"
    },
    {
        "title": "Listing statistics objects via REST API",
        "content": "Listing statistics objects via REST API\nYou can list all available statistics objects with the ostor-usage service and no parameters. The output only contains objects that have not been deleted. For example:# s3_curl GET \"http://s3.example.com/?ostor-usage\"\r\n{\r\n    \"nr_items\": 7,\r\n    \"truncated\": false,\r\n    \"items\": [\r\n        \"s3-usage-8000000000000065-2017-02-01T16:31:54.000Z-1800\",\r\n        \"s3-usage-8000000000000067-2017-02-01T16:30:51.000Z-1800\",\r\n        \"s3-usage-8000000000000068-2017-02-01T16:27:25.000Z-1800\",\r\n        \"s3-usage-8000000000000069-2017-02-01T16:27:24.000Z-1800\",\r\n        \"s3-usage-8000000000000069-2017-02-01T16:31:07.000Z-1800\",\r\n        \"s3-usage-800000000000006a-2017-02-01T16:27:24.000Z-1800\",\r\n        \"s3-usage-800000000000006a-2017-02-01T16:31:08.000Z-1800\"\r\n    ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/listing-statistics-objects-via-rest-api.html"
    },
    {
        "title": "Showing virtual machine details",
        "content": "Showing virtual machine detailsGET /servers/{server_id}\r\n\nShow details of a server with the specified ID.\nIncludes server details including configuration drive, extended status, and server usage information.\nThe extended status information appears in the OS-EXT-STS:vm_state, OS-EXT-STS:power_state, and OS-EXT-STS:task_state attributes.\nThe server usage information appears in the OS-SRV-USG:launched_at and OS-SRV-USG:terminated_at attributes.\nPrecondition: the server must exist.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=show-server-details-detail#show-server-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/bb4f4c8d-a6ca-4723-ace3-1683f54cca1e\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nserver\n\nbody\nobject\nA server object.\n\nid\n\nbody\nstring\nThe UUID of the server.\n\nlinks\n\nbody\narray\nLinks to the resources in question. See API Guide / Links and\r\nReferences\r\nfor more info.\n\nname\n\nbody\nstring\nThe server name.\n\naccessIPv4\n\nbody\nstring\nIPv4 address that should be used to access this server. May be\r\nautomatically set by the provider.\n\naccessIPv6\n\nbody\nstring\nIPv6 address that should be used to access this server. May be\r\nautomatically set by the provider.\n\naddresses\n\nbody\nobject\nThe addresses for the server.  Servers with status BUILD hide their\r\naddresses information.\n\nsecurity_groups (Optional)\nbody\narray\n\nOne or more security groups objects.\n\nsecurity_groups.name\n\nbody\nstring\n\nThe security group name.\n\nconfig_drive\n\nbody\nstring\nIndicates whether or not a config drive was used for this server.\r\nThe value is True or an empty string. An empty string stands for\r\nFalse.\n\ncreated\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nflavor\n\nbody\nobject\n\nBefore microversion 2.47 this contains the ID and links for the flavor\r\nused to boot the server instance. This can be an empty object in case\r\nflavor information is no longer present in the system.\nAs of microversion 2.47 this contains a subset of the actual flavor\r\ninformation used to create the server instance, represented as a nested\r\ndictionary.\n\nflavor.id\n\nbody\nstring\n\nThe ID of the flavor. While people often make this look like\r\nan int, this is really a string.\nAvailable until version 2.46\n\nflavor.links\n\nbody\narray\n\nLinks to the flavor resource. See API Guide / Links and\r\nReferences\r\nfor more details.\nAvailable until version 2.46\n\nflavor.vcpus\n\nbody\ninteger\n\nThe number of virtual CPUs that were allocated to the server.\nNew in version 2.47\n\nflavor.ram\n\nbody\ninteger\n\nThe amount of RAM a flavor has, in MiB.\nNew in version 2.47\n\nflavor.disk\n\nbody\ninteger\n\nThe size of the root disk that was created in GiB.\nNew in version 2.47\n\nflavor.ephemeral\n\nbody\ninteger\n\nThe size of the ephemeral disk that was created, in GiB.\nNew in version 2.47\n\nflavor.swap\n\nbody\ninteger\n\nThe size of a dedicated swap disk that was allocated, in MiB.\nNew in version 2.47\n\nflavor.original_name\n\nbody\nstring\n\nThe display name of a flavor.\nNew in version 2.47\n\nflavor.extra_specs (Optional)\nbody\nobject\n\nA dictionary of the flavor\u00e2\u0080\u0099s extra-specs key-and-value pairs.  This will\r\nonly be included if the user is allowed by policy to index flavor\r\nextra_specs.\nNew in version 2.47\n\nflavor.extra_specs.key\n\nbody\nstring\n\nThe extra spec key of a flavor.\nNew in version 2.47\n\nflavor.extra_specs.value\n\nbody\nstring\n\nThe extra spec value of a flavor.\nNew in version 2.47\n\nguest_agent\n\nbody\nobject\nThe guest tools connection state and version.\n\nhci_info\n\nbody\nobject\nThe information about the VM networks, disks, traits, and\r\nOS distribution.\n\nhostId\n\nbody\nstring\nAn ID string representing the host. This is a hashed value so will not actually look like\r\na hostname, and is hashed with data from the project_id, so the same physical host as seen\r\nby two different project_ids, will be different. It is useful when within the same project you\r\nneed to determine if two instances are on the same or different physical hosts for the\r\npurposes of availability or performance.\n\nhost_status (Optional)\nbody\nstring\n\nThe host status. Values where next value in list can override the previous:\n\nUP if nova-compute up.\nUNKNOWN if nova-compute not reported by servicegroup driver.\nDOWN if nova-compute forced down.\nMAINTENANCE if nova-compute is disabled.\nEmpty string indicates there is no host for server.\n\nThis attribute appears in the response only if the policy permits.\r\nBy default, only administrators can get this parameter.\nNew in version 2.16\n\nimage\n\nbody\nobject\nThe UUID and links for the image for your server instance. The image object\r\nwill be an empty string when you boot the server from a volume.\n\nimage_metadata (Optional)\nbody\nobject\nMetadata key and value pairs for the image.\r\nThe maximum size for each metadata key and value pair is 255 bytes.\n\nkey_name\n\nbody\nstring\n\nThe name of associated key pair, if any.\n\nlocked\n\nbody\nboolean\n\nTrue if the instance is locked otherwise False.\nNew in version 2.9\n\nlocked_reason\n\nbody\nstring\n\nThe reason behind locking a server.\nNew in version 2.73\n\nmemory_mb\n\nbody\ninteger\n\nThe memory of this hypervisor (in MiB). This does not take allocation\r\nratios used for overcommit into account so there may be disparity between\r\nthis and the used count.\nAvailable until version 2.87\n\nmetadata\n\nbody\nobject\nA dictionary of metadata key-and-value pairs, which is maintained for backward\r\ncompatibility.\n\nOS-DCF:diskConfig\n\nbody\nstring\n\nDisk configuration. The value is either:\n\nAUTO: The API builds the server with a single partition the size of\r\nthe target flavor disk. The API automatically adjusts the file system to\r\nfit the entire partition.\nMANUAL: The API builds the server by using the partition scheme and\r\nfile system that is in the source image. If the target flavor disk is\r\nlarger, The API does not partition the remaining disk space.\n\nOS-EXT-AZ:availability_zone\n\nbody\nstring\nThe availability zone name.\n\nOS-EXT-SRV-ATTR:host\n\nbody\nstring\nThe name of the compute host on which this instance is running.\r\nAppears in the response for administrative users only.\n\nOS-EXT-SRV-ATTR:hostname (Optional)\nbody\nstring\n\nThe hostname set on the instance when it is booted.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.3\n\nOS-EXT-SRV-ATTR:hypervisor_hostname\n\nbody\nstring\nThe hypervisor host name provided by the Nova virt driver. For the Ironic driver,\r\nit is the Ironic node UUID. Appears in the response for administrative users only.\n\nOS-EXT-SRV-ATTR:instance_name\n\nbody\nstring\nThe instance name. The Compute API generates the instance name from the instance\r\nname template. Appears in the response for administrative users only.\n\nOS-EXT-SRV-ATTR:kernel_id (Optional)\nbody\nstring\n\nThe UUID of the kernel image when using an AMI. Will be null if not.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.3\n\nOS-EXT-SRV-ATTR:launch_index (Optional)\nbody\ninteger\n\nWhen servers are launched via multiple create, this is the\r\nsequence in which the servers were launched.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.3\n\nOS-EXT-SRV-ATTR:reservation_id (Optional)\nbody\nstring\n\nThe reservation id for the server. This is an id that can\r\nbe useful in tracking groups of servers created with multiple\r\ncreate, that will all have the same reservation_id.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.3\n\nOS-EXT-SRV-ATTR:ramdisk_id (Optional)\nbody\nstring\n\nThe UUID of the ramdisk image when using an AMI. Will be null if not.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.3\n\nOS-EXT-SRV-ATTR:root_device_name (Optional)\nbody\nstring\n\nThe root device name for the instance\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.3\n\nOS-EXT-SRV-ATTR:user_data (Optional)\nbody\nstring\n\nThe user_data the instance was created with.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.3\n\nOS-EXT-STS:power_state\n\nbody\ninteger\n\nThe power state of the instance. This is an enum value that is mapped as:\n\n0: NOSTATE\r\n1: RUNNING\r\n3: PAUSED\r\n4: SHUTDOWN\r\n6: CRASHED\r\n7: SUSPENDED\r\n8: SHUTDOWN_ACTIVE\r\n\n\nOS-EXT-STS:task_state\n\nbody\nstring\n\nThe task state of the instance.\n\nOS-EXT-STS:vm_state\n\nbody\nstring\n\nThe VM state.\n\nos-extended-volumes:volumes_attached\n\nbody\narray\n\nThe attached volumes, if any.\n\nos-extended-volumes:volumes_attached.id\n\nbody\nstring\n\nThe attached volume ID.\n\nos-extended-volumes:volumes_attached.delete_on_termination\n\nbody\nboolean\n\nA flag indicating if the attached volume will be deleted\r\nwhen the server is deleted. By default this is False.\nNew in version 2.3\n\nOS-SRV-USG:launched_at\n\nbody\nstring\n\nThe date and time when the server was launched.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nIf the deleted_at date and time stamp is not set, its value is null.\n\nOS-SRV-USG:terminated_at\n\nbody\nstring\n\nThe date and time when the server was deleted.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nIf the deleted_at date and time stamp is not set, its value is null.\n\ndescription\n\nbody\nstring\n\nThe description of the server.\r\nBefore microversion 2.19 this was set to the server name.\nNew in version 2.19\n\nserver_groups\n\nbody\narray\n\nThe UUIDs of the server groups to which the server belongs. Currently\r\nthis can contain at most one entry.\nNew in version 2.71\n\ntags\n\nbody\narray\n\nA list of tags. The maximum count of tags in this list is 50.\nNew in version 2.26\n\ntrusted_image_certificates\n\nbody\narray\n\nA list of trusted certificate IDs, that were used during image signature\r\nverification to verify the signing certificate. The list is restricted\r\nto a maximum of 50 IDs. The value is null if trusted certificate IDs\r\nare not set.\nNew in version 2.63\n\nprogress (Optional)\nbody\ninteger\nA percentage value of the operation progress.\r\nThis parameter only appears when the server status is ACTIVE,\r\nBUILD, REBUILD, RESIZE, VERIFY_RESIZE or MIGRATING.\n\nstatus\n\nbody\nstring\nThe server status.\n\ntenant_id\n\nbody\nstring\nThe UUID of the tenant in a multi-tenancy cloud.\n\nupdated\n\nbody\nstring\n\nThe date and time when the resource was updated.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nuser_id\n\nbody\nstring\nThe user ID of the user who owns the server.\n\nfault (Optional)\nbody\nobject\nA fault object. Only displayed when the server status is ERROR or\r\nDELETED and a fault occurred.\n\nfault.code\n\nbody\ninteger\nThe error response code.\n\nfault.created\n\nbody\nstring\n\nThe date and time when the exception was raised.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nfault.message\n\nbody\nstring\nThe error message.\n\nfault.details (Optional)\nbody\nstring\nThe stack trace. It is available if the response code is not 500 or\r\nyou have the administrator privilege\n\nvcpu_model\n\nbody\nobject\nThe description of the used virtual CPU model.\n\nvcpus\n\nbody\ninteger\nThe number of virtual CPUs that the server uses.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"server\": {\r\n    \"server_groups\": [],\r\n    \"OS-EXT-STS:task_state\": null,\r\n    \"addresses\": {\r\n      \"private\": [\r\n        {\r\n          \"OS-EXT-IPS-MAC:mac_addr\": \"fa:16:3e:3b:ce:89\",\r\n          \"version\": 4,\r\n          \"addr\": \"192.168.128.20\",\r\n          \"OS-EXT-IPS:type\": \"fixed\"\r\n        }\r\n      ]\r\n    },\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/bb4f4c8d-a6ca-4723-ace3-1683f54cca1e\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/servers/bb4f4c8d-a6ca-4723-ace3-1683f54cca1e\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"image\": \"\",\r\n    \"OS-EXT-SRV-ATTR:user_data\": null,\r\n    \"OS-EXT-STS:vm_state\": \"active\",\r\n    \"OS-EXT-SRV-ATTR:instance_name\": \"instance-00000034\",\r\n    \"OS-EXT-SRV-ATTR:root_device_name\": \"/dev/vda\",\r\n    \"OS-SRV-USG:launched_at\": \"2021-02-09T20:50:19.000000\",\r\n    \"flavor\": {\r\n      \"ephemeral\": 0,\r\n      \"ram\": 512,\r\n      \"original_name\": \"tiny\",\r\n      \"vcpus\": 1,\r\n      \"extra_specs\": {},\r\n      \"swap\": 0,\r\n      \"disk\": 0\r\n    },\r\n    \"id\": \"bb4f4c8d-a6ca-4723-ace3-1683f54cca1e\",\r\n    \"security_groups\": [\r\n      {\r\n        \"name\": \"default\"\r\n      }\r\n    ],\r\n    \"description\": \"vm1\",\r\n    \"host_status\": \"UP\",\r\n    \"user_id\": \"ee8e3378b56145ba9989228db6cad4b8\",\r\n    \"OS-EXT-SRV-ATTR:hostname\": \"vm1\",\r\n    \"OS-DCF:diskConfig\": \"MANUAL\",\r\n    \"memory_mb\": 512,\r\n    \"accessIPv4\": \"\",\r\n    \"accessIPv6\": \"\",\r\n    \"OS-EXT-SRV-ATTR:reservation_id\": \"r-rq1oigx3\",\r\n    \"progress\": 0,\r\n    \"OS-EXT-STS:power_state\": 1,\r\n    \"OS-EXT-AZ:availability_zone\": \"nova\",\r\n    \"config_drive\": \"\",\r\n    \"status\": \"ACTIVE\",\r\n    \"OS-EXT-SRV-ATTR:ramdisk_id\": \"\",\r\n    \"updated\": \"2021-02-09T20:50:18Z\",\r\n    \"hostId\": \"02a55bdaebde6d78b39e8413ee3645b6da7ff04db2c2a950f1092162\",\r\n    \"OS-EXT-SRV-ATTR:host\": \"node1.vstoragedomain\",\r\n    \"OS-SRV-USG:terminated_at\": null,\r\n    \"tags\": [],\r\n    \"vcpu_model\": {\r\n      \"vendor\": null,\r\n      \"features\": [],\r\n      \"mode\": \"host-model\",\r\n      \"model\": null,\r\n      \"arch\": null,\r\n      \"match\": \"exact\",\r\n      \"topology\": {\r\n        \"nova_object.version\": \"1.0\",\r\n        \"nova_object.changes\": [\r\n          \"cores\",\r\n          \"threads\",\r\n          \"sockets\"\r\n        ],\r\n        \"nova_object.name\": \"VirtCPUTopology\",\r\n        \"nova_object.data\": {\r\n          \"cores\": 1,\r\n          \"threads\": 1,\r\n          \"sockets\": 1\r\n        },\r\n        \"nova_object.namespace\": \"nova\"\r\n      }\r\n    },\r\n    \"key_name\": null,\r\n    \"OS-EXT-SRV-ATTR:kernel_id\": \"\",\r\n    \"locked\": false,\r\n    \"hci_info\": {\r\n      \"os_distro\": \"linux\",\r\n      \"network\": [\r\n        {\r\n          \"port_security_enabled\": true,\r\n          \"mac\": \"fa:16:3e:3b:ce:89\",\r\n          \"emulation_type\": \"virtio\",\r\n          \"network\": {\r\n            \"bridge\": \"br-int\",\r\n            \"label\": \"private\",\r\n            \"meta\": {\r\n              \"injected\": true,\r\n              \"tunneled\": true,\r\n              \"mtu\": 1400,\r\n              \"physical_network\": null,\r\n              \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\"\r\n            },\r\n            \"id\": \"bda82e1d-571d-4450-81cc-454808e8e68b\",\r\n            \"subnets\": [\r\n              {\r\n                \"ips\": [\r\n                  {\r\n                    \"meta\": {},\r\n                    \"type\": \"fixed\",\r\n                    \"version\": 4,\r\n                    \"address\": \"192.168.128.20\",\r\n                    \"floating_ips\": []\r\n                  }\r\n                ],\r\n                \"version\": 4,\r\n                \"meta\": {\r\n                  \"dhcp_server\": \"192.168.128.1\"\r\n                },\r\n                \"dns\": [\r\n                  {\r\n                    \"meta\": {},\r\n                    \"type\": \"dns\",\r\n                    \"version\": 4,\r\n                    \"address\": \"0.0.0.0\"\r\n                  }\r\n                ],\r\n                \"routes\": [],\r\n                \"cidr\": \"192.168.128.0/24\",\r\n                \"gateway\": {\r\n                  \"meta\": {},\r\n                  \"type\": \"gateway\",\r\n                  \"version\": null,\r\n                  \"address\": null\r\n                }\r\n              }\r\n            ]\r\n          },\r\n          \"ips\": [\r\n            \"192.168.128.20\"\r\n          ]\r\n        }\r\n      ],\r\n      \"boot_order\": [\r\n        \"hd\"\r\n      ],\r\n      \"vzhardware\": \"1.0.2\",\r\n      \"disks\": [\r\n        {\r\n          \"bus\": \"virtio\",\r\n          \"address\": \"0000:00:06.0\",\r\n          \"readonly\": false,\r\n          \"physical_block_size\": \"4096\",\r\n          \"device_type\": \"disk\",\r\n          \"logical_block_size\": \"512\",\r\n          \"serial\": \"380dd098-e53f-4e8e-ab37-109c4c564a53\"\r\n        }\r\n      ],\r\n      \"required_traits\": [],\r\n      \"os_type\": \"linux\"\r\n    },\r\n    \"image_metadata\": {\r\n      \"os_distro\": \"linux\",\r\n      \"image_validated\": \"yes\",\r\n      \"container_format\": \"bare\",\r\n      \"min_ram\": \"0\",\r\n      \"disk_format\": \"qcow2\",\r\n      \"base_image_ref\": \"200ab392-03ed-41ee-b889-b57d13962c01\",\r\n      \"min_disk\": \"1\",\r\n      \"os_type\": \"linux\",\r\n      \"hw_disk_bus\": \"virtio\"\r\n    },\r\n    \"root_gb\": 0,\r\n    \"OS-EXT-SRV-ATTR:hypervisor_hostname\": \"node1.vstoragedomain\",\r\n    \"name\": \"vm1\",\r\n    \"OS-EXT-SRV-ATTR:launch_index\": 0,\r\n    \"created\": \"2021-02-09T20:50:05Z\",\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"os-extended-volumes:volumes_attached\": [\r\n      {\r\n        \"id\": \"380dd098-e53f-4e8e-ab37-109c4c564a53\",\r\n        \"delete_on_termination\": true\r\n      }\r\n    ],\r\n    \"guest_agent\": {\r\n      \"status\": \"unknown\",\r\n      \"version\": null\r\n    },\r\n    \"vcpus\": 1,\r\n    \"trusted_image_certificates\": null,\r\n    \"metadata\": {},\r\n    \"OS-EXT-SRV-ATTR:vm_mode\": null\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-virtual-machine-details.html"
    },
    {
        "title": "11. Integrating External Systems\u00c2\u00b6",
        "content": "11. Integrating External Systems | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n11. Integrating External Systems\u00c2\u00b6\n\nIn this chapter:\n\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-external-systems/index.html"
    },
    {
        "title": "Changing load balancer resources",
        "content": "Changing load balancer resources\nBy default, a load balancer instance is created with 2 vCPUs and 4 GB of memory. When a load balancer needs more resources, you can add them by applying another flavor to the load balancer. To do this, you need to perform a manual load balancer failover.\nBy default, a load balancer is created by using the private amphora flavor that cannot be managed via vinfra. You can, however, change it by using the OpenStack command-line tool.\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo change the default load balancer flavor\n\nCheck if the default amphora flavor exists:# openstack --insecure flavor list --all\r\n+---------+---------+-------+------+-----------+-------+-----------+\r\n| ID      | Name    |   RAM | Disk | Ephemeral | VCPUs | Is Public |\r\n+---------+---------+-------+------+-----------+-------+-----------+\r\n| 100     | tiny    |   512 |    0 |         0 |     1 | True      |\r\n| 101     | small   |  2048 |    0 |         0 |     1 | True      |\r\n| 102     | medium  |  4096 |    0 |         0 |     2 | True      |\r\n| 103     | large   |  8192 |    0 |         0 |     4 | True      |\r\n| 104     | xlarge  | 16384 |    0 |         0 |     8 | True      |\r\n| amphora | amphora |  4096 |   30 |         0 |     2 | False     |\r\n+---------+---------+-------+------+-----------+-------+-----------+\n\nDelete this flavor:# openstack --insecure flavor delete amphora\r\n\n\nCreate a new amphora flavor with custom parameters. For example:# openstack --insecure flavor create amphora --id amphora --ram 8192 \\\r\n--vcpus 4 --disk 60 --private\r\n+----------------------------+---------+\r\n| Field                      | Value   |\r\n+----------------------------+---------+\r\n| OS-FLV-DISABLED:disabled   | False   |\r\n| OS-FLV-EXT-DATA:ephemeral  | 0       |\r\n| disk                       | 60      |\r\n| id                         | amphora |\r\n| name                       | amphora |\r\n| os-flavor-access:is_public | False   |\r\n| properties                 |         |\r\n| ram                        | 8192    |\r\n| rxtx_factor                | 1.0     |\r\n| swap                       |         |\r\n| vcpus                      | 4       |\r\n+----------------------------+---------+\r\n\n\nChange the load balancer flavor by performing its failover. For example:# openstack --insecure loadbalancer failover mylbaas\r\n\n\nThe load balancer mylbaas will be re-created with 4 vCPUs, 8 GB of RAM, and 60 GB of disk space.\nSee also\n\nCreating custom load balancer flavors\n\nChanging the default load balancer image\n\nManaging balancing pools",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-load-balancer-resources.html"
    },
    {
        "title": "Querying S3 account information via CLI",
        "content": "Querying S3 account information via CLI\nTo display information about the specified account, use the ostor-s3-admin query-account-info command. You need to specify either the user email (-e) or S3 ID (-i) and the account name. For example:# ostor-s3-admin query-account-info -V 0100000000000002 -n account -e user@email.com\r\nUserEmail:user@email.com\r\nUserId:b09693b73b3c7686\r\nAccountName:account\r\nFlags:none\r\nKeyPair[0]:S3AccessKeyId:b09693b73b3c7686ESY0\r\nKeyPair[0]:S3SecretAccessKey:VxGZc12KKECUe1361IWrvXSVvZOdZAsfg4pL4M7T",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-s3-account-information-via-cli.html"
    },
    {
        "title": "Adding nodes to backup storage",
        "content": "Adding nodes to backup storage\nYou can add more nodes  that will serve as targets for backups from Acronis Cyber Protect and/or Acronis Cyber Protect Cloud for high availability and scalability of your backup storage.\nPrerequisites\n\nThe backup storage cluster is created and registered in the Cloud Management Panel, as described in Provisioning Acronis Backup Storage space.\n\nTo add nodes to backup storage\n\nAdmin panel\n\nGo to the Storage services > Backup storage > Nodes screen.\nClick  Add node. \nSelect nodes to join the backup storage cluster and click Add.\n\nThe nodes will be added to your backup storage and will run Backup Gateway.\n\nEach time you change the number of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\nCommand-line interface\nUse the following command:vinfra service backup node add --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n\nFor example, to add the node with the ID 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb to the backup cluster, run:# vinfra service backup node add --nodes 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb\nThe added node will appear in the vinfra service backup node list output:# vinfra service backup node list\r\n+--------------------------------------+------------------------+-----------+\r\n| id                                   | host                   | is_online |\r\n+--------------------------------------+------------------------+-----------+\r\n| 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb | node003.vstoragedomain | True      |\r\n| 74cbd22b-fb1b-4441-ae52-532078c54f9a | node001.vstoragedomain | True      |\r\n| eeb06dce-4cfd-4c89-bc7f-4689ea5c7058 | node002.vstoragedomain | True      |\r\n+--------------------------------------+------------------------+-----------+\r\n\n\nSee also\n\nChanging the redundancy scheme for backup storage\n\nManaging registrations for backup storage\n\nManaging geo-replication for backup storage\n\nMonitoring Acronis Backup Storage\n\nReleasing nodes from backup storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup node add --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n\nFor example, to add the node with the ID 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb to the backup cluster, run:# vinfra service backup node add --nodes 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb\nThe added node will appear in the vinfra service backup node list output:# vinfra service backup node list\r\n+--------------------------------------+------------------------+-----------+\r\n| id                                   | host                   | is_online |\r\n+--------------------------------------+------------------------+-----------+\r\n| 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb | node003.vstoragedomain | True      |\r\n| 74cbd22b-fb1b-4441-ae52-532078c54f9a | node001.vstoragedomain | True      |\r\n| eeb06dce-4cfd-4c89-bc7f-4689ea5c7058 | node002.vstoragedomain | True      |\r\n+--------------------------------------+------------------------+-----------+\r\n\n",
                "title": "To add nodes to backup storage"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > Backup storage > Nodes screen.\nClick  Add node. \nSelect nodes to join the backup storage cluster and click Add.\n\nThe nodes will be added to your backup storage and will run Backup Gateway.\n\nEach time you change the number of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\n",
                "title": "To add nodes to backup storage"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-nodes-to-backup-storage.html"
    },
    {
        "title": "Creating external load balancers in Kubernetes",
        "content": "Creating external load balancers in Kubernetes\nIn Kubernetes, you can create a service with an external load balancer that provides access to it from public networks. The load balancer will receive a publicly accessible IP address and route incoming requests to the correct port on the Kubernetes cluster nodes.\nPrerequisites\n\nTo be able to assign a specific floating IP address to an external load balancer during its deployment, this floating IP address must be created in advance, as described in Managing floating IP addresses.\n\nTo create a service with an external load balancer\n\n\r\n                    Access the Kubernetes cluster via the dashboard. Click Kubernetes access for instructions.\r\n                \n\nOn the Kubernetes dashboard, create a deployment and service of the LoadBalancer type. To do it, click + Create and specify a YAML file that defines these objects. For example:\n\nIf you have deployed the Kubernetes cluster in a shared physical network, specify the following manifest:apiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: nginx\r\nspec:\r\n  replicas: 2\r\n  selector:\r\n    matchLabels:\r\n      app: nginx\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: nginx\r\n    spec:\r\n      containers:\r\n      - name: nginx\r\n        image: nginx\r\n        ports:\r\n        - containerPort: 80\r\n---\r\nkind: Service\r\napiVersion: v1\r\nmetadata:\r\n  name: load-balancer\r\n  annotations:\r\n    service.beta.kubernetes.io/openstack-internal-load-balancer: \"true\"\r\nspec:\r\n  selector:\r\n    app: nginx\r\n  type: LoadBalancer\r\n  ports:\r\n  - port: 80\r\n    targetPort: 80\r\n    protocol: TCP\r\n\nThe manifest above describes the deployment nginx with a replica set of two pods and the service load-balancer with the LoadBalancer type. The annotation used for the service indicates that the load balancer will be internal.\nOnce the load balancer is created, it will be allocated an IP address from the shared physical network and can be accessed at this external endpoint.\n\n\r\n                            If you have deployed the Kubernetes cluster in a virtual network linked to a physical one via a virtual router, you can use the YAML file above without the annotations section for the load-balancer service. The created load balancer will receive a floating IP address from the physical network and can be accessed at this external endpoint. To use a specific floating IP address, create it in the self-service panel in advance, and then specify it with the loadBalancerIP parameter:<...>\r\n---\r\nkind: Service\r\napiVersion: v1\r\nmetadata:\r\n  name: load-balancer\r\nspec:\r\n  selector:\r\n    app: nginx\r\n  type: LoadBalancer\r\n  loadBalancerIP: 10.10.10.100\r\n  ports:\r\n  - port: 80\r\n    targetPort: 80\r\n    protocol: TCP\r\n\n\nIf you want to choose whether to create highly available load balancers for your service or not, you can make use of load balancer flavors. To specify a flavor for a load balancer add loadbalancer.openstack.org/flavor-id: <flavor-id> to the annotations section. The flavor ID can be obtained from your system administrator.\n\nThe load balancer will also appear in the self-service panel, where you can monitor its performance and health. For example:",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-external-load-balancers-in-kubernetes.html"
    },
    {
        "title": "Managing load balancers",
        "content": "Managing load balancers\nLoad balancers are created and managed by self-service users, as described in \"Managing load balancers\" in the Self-Service Guide. In the admin panel, you can monitor, manage balancing pools, disable/enable, and delete a load balancer. Additionally, in case of a load balancer failure, it is possible to perform a manual failover in the command-line interface.\nLimitations\n\nIPv6 is supported for load balancers that are connected to physical networks.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\nThe load balancer service is installed during the compute cluster deployment or later, as described in Provisioning load balancers.\n\nTo view load balancer properties \n\nAdmin panel\n\nOn the Compute > Network > Load balancers tab, select the required load balancer.\nOpen the Properties tab. In the Virtual machines field, you can see the name of load balancer instances.\nClick the instance name to open the VM\u00e2\u0080\u0099s panel.\n\nCommand-line interface\nUse the following command:vinfra service compute load-balancer show <load-balancer>\r\n\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to view the details of the load balancer mylbaas, run:# vinfra service compute load-balancer show mylbaas\r\n+---------------+----------------------------------------------------+\r\n| Field         | Value                                              |\r\n+---------------+----------------------------------------------------+\r\n| address       | 192.168.30.230                                     |\r\n| amphorae      | - active: true                                     |\r\n|               |   compute_id: b0c4793f-e1b1-4251-91c2-94e34787f537 |\r\n|               |   created_at: '2019-11-18T12:59:12.742446'         |\r\n|               |   id: b7b23106-a87b-412d-9ce6-7c69b5594342         |\r\n|               |   image_id: 6d1ba6f9-cf86-4ea4-a32d-f138868a9742   |\r\n|               |   role: STANDALONE                                 |\r\n|               |   status: ALLOCATED                                |\r\n|               |   updated_at: '2019-11-18T13:01:07.601184'         |\r\n| created_at    | 2019-11-18T12:59:08.243413                         |\r\n| description   |                                                    |\r\n| enabled       | True                                               |\r\n| floating_ip   | 10.94.129.70                                       |\r\n| ha_enabled    | False                                              |\r\n| id            | 941bf637-2d55-40f0-92c0-e65d6567b468               |\r\n| members_count | 0                                                  |\r\n| name          | mylbaas                                            |\r\n| network_id    | 2b821d00-e428-4a76-b1ae-d181c9f5ae7f               |\r\n| pools         | []                                                 |\r\n| port_id       | 2d8ab88a-847c-4396-857e-11eaa80e1b24               |\r\n| project_id    | e4e059c67dee4736851df14d4519a5a5                   |\r\n| status        | ACTIVE                                             |\r\n| updated_at    | 2019-11-18T13:01:10.983144                         |\r\n+---------------+----------------------------------------------------+\r\n\n\nTo enable/disable a load balancer\n\nAdmin panel\n\nOn the Compute > Network > Load balancers tab, select a load balancer.\nClick the ellipsis icon next to it, and then click Enable or Disable.\n\nCommand-line interface\nUse the following command:vinfra service compute load-balancer set [--enable | --disable] [--description <description>] <load-balancer>\n\n--enable\n\nEnable the load balancer\n--disable\n\nDisable the load balancer\n--description <description>\n\nLoad balancer description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to disable the load balancer mylbaas, run:# vinfra service compute load-balancer set mylbaas --disable \\\r\n--description \"Disabled load balancer\"\r\n+---------------+--------------------------------------+\r\n| Field         | Value                                |\r\n+---------------+--------------------------------------+\r\n| address       | 192.168.30.230                       |\r\n| amphorae      |                                      |\r\n| created_at    | 2019-11-18T12:59:08.243413           |\r\n| description   | Disabled load balancer               |\r\n| enabled       | False                                |\r\n| floating_ip   |                                      |\r\n| ha_enabled    |                                      |\r\n| id            | 941bf637-2d55-40f0-92c0-e65d6567b468 |\r\n| members_count | 0                                    |\r\n| name          | mylbaas                              |\r\n| network_id    | 2b821d00-e428-4a76-b1ae-d181c9f5ae7f |\r\n| pools         | []                                   |\r\n| port_id       | 2d8ab88a-847c-4396-857e-11eaa80e1b24 |\r\n| project_id    | e4e059c67dee4736851df14d4519a5a5     |\r\n| status        | DISABLED                             |\r\n| updated_at    | 2019-11-18T13:09:09.151442           |\r\n+---------------+--------------------------------------+\r\n\n\nTo perform a load balancer failover\nUse the following command:vinfra service compute load-balancer failover <load-balancer>\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to perform a failover of the load balancer mylbaas, run:# vinfra service compute load-balancer failover mylbaas\nTo delete a load balancer\n\nAdmin panel\n\nOn the Compute > Network > Load balancers tab, select a load balancer.\nClick the ellipsis icon next to it, and then click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute load-balancer delete <load-balancer>\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to delete the load balancer mylbaas, run:# vinfra service compute load-balancer delete mylbaas\n\nSee also\n\nMonitoring load balancers\n\nManaging compute networks\n\nManaging virtual routers\n\nManaging floating IP addresses",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute load-balancer show <load-balancer>\r\n\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to view the details of the load balancer mylbaas, run:# vinfra service compute load-balancer show mylbaas\r\n+---------------+----------------------------------------------------+\r\n| Field         | Value                                              |\r\n+---------------+----------------------------------------------------+\r\n| address       | 192.168.30.230                                     |\r\n| amphorae      | - active: true                                     |\r\n|               |   compute_id: b0c4793f-e1b1-4251-91c2-94e34787f537 |\r\n|               |   created_at: '2019-11-18T12:59:12.742446'         |\r\n|               |   id: b7b23106-a87b-412d-9ce6-7c69b5594342         |\r\n|               |   image_id: 6d1ba6f9-cf86-4ea4-a32d-f138868a9742   |\r\n|               |   role: STANDALONE                                 |\r\n|               |   status: ALLOCATED                                |\r\n|               |   updated_at: '2019-11-18T13:01:07.601184'         |\r\n| created_at    | 2019-11-18T12:59:08.243413                         |\r\n| description   |                                                    |\r\n| enabled       | True                                               |\r\n| floating_ip   | 10.94.129.70                                       |\r\n| ha_enabled    | False                                              |\r\n| id            | 941bf637-2d55-40f0-92c0-e65d6567b468               |\r\n| members_count | 0                                                  |\r\n| name          | mylbaas                                            |\r\n| network_id    | 2b821d00-e428-4a76-b1ae-d181c9f5ae7f               |\r\n| pools         | []                                                 |\r\n| port_id       | 2d8ab88a-847c-4396-857e-11eaa80e1b24               |\r\n| project_id    | e4e059c67dee4736851df14d4519a5a5                   |\r\n| status        | ACTIVE                                             |\r\n| updated_at    | 2019-11-18T13:01:10.983144                         |\r\n+---------------+----------------------------------------------------+\r\n\n",
                "title": "To view load balancer properties "
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute load-balancer set [--enable | --disable] [--description <description>] <load-balancer>\n\n--enable\n\nEnable the load balancer\n--disable\n\nDisable the load balancer\n--description <description>\n\n\nLoad balancer description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to disable the load balancer mylbaas, run:# vinfra service compute load-balancer set mylbaas --disable \\\r\n--description \"Disabled load balancer\"\r\n+---------------+--------------------------------------+\r\n| Field         | Value                                |\r\n+---------------+--------------------------------------+\r\n| address       | 192.168.30.230                       |\r\n| amphorae      |                                      |\r\n| created_at    | 2019-11-18T12:59:08.243413           |\r\n| description   | Disabled load balancer               |\r\n| enabled       | False                                |\r\n| floating_ip   |                                      |\r\n| ha_enabled    |                                      |\r\n| id            | 941bf637-2d55-40f0-92c0-e65d6567b468 |\r\n| members_count | 0                                    |\r\n| name          | mylbaas                              |\r\n| network_id    | 2b821d00-e428-4a76-b1ae-d181c9f5ae7f |\r\n| pools         | []                                   |\r\n| port_id       | 2d8ab88a-847c-4396-857e-11eaa80e1b24 |\r\n| project_id    | e4e059c67dee4736851df14d4519a5a5     |\r\n| status        | DISABLED                             |\r\n| updated_at    | 2019-11-18T13:09:09.151442           |\r\n+---------------+--------------------------------------+\r\n\n",
                "title": "To enable/disable a load balancer"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute load-balancer delete <load-balancer>\n\n<load-balancer>\n\nLoad balancer ID or name\n\nFor example, to delete the load balancer mylbaas, run:# vinfra service compute load-balancer delete mylbaas\n",
                "title": "To delete a load balancer"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Load balancers tab, select the required load balancer.\nOpen the Properties tab. In the Virtual machines field, you can see the name of load balancer instances.\nClick the instance name to open the VM\u00e2\u0080\u0099s panel.\n\n",
                "title": "To view load balancer properties "
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Load balancers tab, select a load balancer.\nClick the ellipsis icon next to it, and then click Enable or Disable.\n\n",
                "title": "To enable/disable a load balancer"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Load balancers tab, select a load balancer.\nClick the ellipsis icon next to it, and then click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a load balancer"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-load-balancers.html"
    },
    {
        "title": "Managing buckets via the Virtuozzo Hybrid Infrastructure user panel",
        "content": "Managing buckets via the Virtuozzo Hybrid Infrastructure user panel\nThis section describes how to manage buckets and their contents from the Virtuozzo Hybrid Infrastructure user panel.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/managing-buckets-via-the-user-panel.html"
    },
    {
        "title": "12.4. Joining Instances to Domain\u00c2\u00b6",
        "content": "12.4. Joining Instances to Domain | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n12.4. Joining Instances to Domain\u00c2\u00b6\nYou can use Leostream to join Windows virtual machines to an Active Directory domain. When enabled, the Connection Broker attempts to join the desktop to the domain any time the Leostream Agent on the desktop registers with the Connection Broker, for example, when a desktop is provisioned or when you reboot the desktop.\nBefore configuring a pool to join desktops to a domain, you must define the Active Directory domain on the Setup > Authentication Servers page.\nTo enable domain joining for a pool:\n\nSelect the Join virtual machine to a domain option in the Domain Join section, shown in the following figure.\n\nSelect the domain from the Domain drop-down menu.\nOptionally, from the Organizational Unit drop-down menu, select an OU for the desktops.\nTo reset the desktops hostname when joining it to the domain, select the Set desktop hostname to virtual machine name check box. With this option selected, the Leostream Agent attempts to set the hostname to the value shown in the Name column on the Resources > Desktops page.\n\nIf the pool provisions new desktops, this is the name found in the Virtual machine name edit field. The Name field must contain a valid hostname, as follows:\n\nThe name uses only the standard character set for Computer Name, which includes letters, numbers, and the following symbols: ! @ # $ % ^ & ' ) ( . - _ { } ~.\nThen Name cannot be longer than 15 characters.\n\nLeostream performs the domain join for any desktop in the pool that is not already joined to a domain. Leostream does not have to provision the desktop to perform the domain join.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/pooling-and-provisioning/joining-domain.html"
    },
    {
        "title": "Uploading and downloading files",
        "content": "Uploading and downloading files\nOn the bucket or folder contents screen:\n\nTo upload files to S3, click Upload, and then choose files to upload.\n\nTo download files, select them, and then click Download.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/uploading-and-downloading-files.html"
    },
    {
        "title": "1. Hystax Acura Overview\u00c2\u00b6",
        "content": "1. Hystax Acura Overview | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nPrev\nNext\n\n1. Hystax Acura Overview\u00c2\u00b6\nHystax is a cloud migration and Disaster Recovery company focusing on consistent replication of IT workloads and providing real-time migration and Best-In-Class Disaster Recovery.\nThis guide aims to explain how to migrate modern workloads from VMware to Virtuozzo Hybrid Infrastructure using Hystax Acura migration solution.\nTo deploy the Hystax Acura solution, refer to the Integration Guide for Hystax Acura.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/overview.html"
    },
    {
        "title": "Detaching volumes from virtual machines",
        "content": "Detaching volumes from virtual machinesDELETE /servers/{server_id}/os-volume_attachments/{volume_id}\r\n\nDetach a volume from the given virtual machine.\n\nThis is an asynchronous API, callers should poll the status and list of volume attachments within the volume API, to determine when the detachment has completed successfully.\n\nSource: https://docs.openstack.org/api-ref/compute/?expanded=detach-a-volume-from-an-instance-detail#detach-a-volume-from-an-instance\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nvolume_id\n\npath\nstring\nThe UUID of the volume to detach.\n\nExample\nDetach a volume with the specified ID from a VM with the specified ID.# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/b906404c55bb44729da99987536ac5bc/servers/0785ee80-1eca-426b-b8c4-5b499fc7f614/os-volume_attachments/16cd801e-f3c1-4cac-aa6c-aecf22642a89\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/detaching-volumes-from-virtual-machines.html"
    },
    {
        "title": "Listing IPsec policies",
        "content": "Listing IPsec policiesGET /v2.0/vpn/ipsecpolicies\nList IPsec policies.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-ipsec-policies-detail#list-ipsec-policies\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ipsecpolicies\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicies\n\nbody\narray\nA list of ipsecpolicy objects.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencapsulation_mode (Optional)\nbody\nstring\nThe encapsulation mode. A valid value is tunnel or transport. Default is tunnel.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\ntransform_protocol (Optional)\nbody\nstring\nThe transform protocol. A valid value is ESP, AH, or AH- ESP. Default is ESP.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IPsec policy.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"ipsecpolicies\": [\r\n    {\r\n      \"id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n      \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n      \"name\": \"ipsecpolicy1\",\r\n      \"description\": \"\",\r\n      \"transform_protocol\": \"esp\",\r\n      \"auth_algorithm\": \"sha1\",\r\n      \"encryption_algorithm\": \"aes-128\",\r\n      \"encapsulation_mode\": \"tunnel\",\r\n      \"lifetime\": {\r\n        \"units\": \"seconds\",\r\n        \"value\": 7200\r\n      },\r\n      \"pfs\": \"group5\",\r\n      \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-ipsec-policies.html"
    },
    {
        "title": "Enabling and disabling users and projects",
        "content": "Enabling and disabling users and projects\nDomain administrators can allow or prohibit other users' login by enabling and disabling their accounts. They can also allow or prohibit access to projects by enabling and disabling them.\nPrerequisites\n\nA domain administrator must have the Project and quota management permission granted, to be able to enable and disable projects.\n\nTo enable or disable a user\n\nSelect the domain in the drop-down list in the top right corner.\nOn the Users screen, click the ellipsis icon next to the user, and then click Enable or Disable.\n\nTo enable or disable a project\n\nSelect the domain in the drop-down list in the top right corner.\nOn the Projects screen, click the ellipsis icon next to the project, and then click Enable or Disable.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/enabling-disabling-users-and-projects.html"
    },
    {
        "title": "Creating a virtual machine",
        "content": "Creating a virtual machine\n\nFor supported guest operating systems and other information, refer to \"Managing virtual machines\" in the Administrator Guide.\n\nOn the Virtual machines screen, click Create virtual machine. A window will open where you will need to specify the VM parameters.\n\nSpecify a name for the new VM.\n\nSelect the VM boot media:\n\nIf you have an ISO image or a template\n\nSelect Image in the Deploy from section, and then click Specify in the Image section.\n\nIn the Images window, select the ISO image or template, and then click Done.\n\nIf you have a compute boot volume\n\nSelect Volume in the Deploy from section, and then click Specify in the Volumes section.\nIn the Volumes window, click Attach.\n\nIn the Attach volume window, find and select the volume, and then click Attach.\n\nIf you attach more than one volume, the first attached volume becomes the boot volume, by default. To select another volume as bootable, place it first in the list by clicking the up arrow button next to it.\n\nIf you select an image or volume with an assigned placement, the created VM will also inherit this placement.\n\nAfter selecting the boot media, volumes required for this media to boot will be automatically added to the Volumes section.\n\nConfigure the VM disks:\n\nIn the Volumes window, make sure the default boot volume is large enough to accommodate the guest OS. Otherwise, click the ellipsis icon next to it, and then Edit. Change the volume size and click Save.\n\nAdd more disks to the VM by creating or attaching volumes. To do this, click the pencil icon in the Volumes section, and then Add or Attach in the Volumes window.\n\nSelect volumes that will be removed during the VM deletion. To do this, click the pencil icon in the Volumes section, click the ellipsis icon next to the needed volume, and then Edit. Enable Delete on termination and click Save.\nWhen you finish configuring the VM disks, click Done.\n\nChoose the amount of RAM and CPU resources that will be allocated to the VM in the Flavor section. In the Flavor window, select a flavor, and then click Done.\n\nWhen choosing a flavor for a VM, ensure it satisfies the hardware requirements of the guest OS.\n\nTo select a flavor with an assigned placement, you can filter flavors by placement. The VM created from such a flavor will also inherit this placement.\n\nAdd network interfaces to the VM in the Networks section:\n\nIn the Network interfaces window, click Add to attach a network interface.\n\nIn the Add network interface window, select a compute network to connect to, and then specify MAC address, IPv4 and/or IPv6 addresses, and security groups. By default, MAC and primary IP addresses are assigned automatically. To specify them manually, clear the Assign automatically check boxes, and enter the desired addresses. Optionally, assign additional IP addresses to the network interface in the Secondary IP addresses section. Note that a secondary IPv6 address is not available for an IPv6 subnet that works in the SLAAC or DHCPv6 stateless mode.\n\nSecondary IP addresses, unlike the primary one, will not be automatically assigned to the network interface inside the virtual machine guest OS. You should assign them manually.\n\nIf you selected a virtual network with enabled IP address management\n\nIn this case, spoofing protection is enabled and the default security group is selected by default. This security group allows all incoming and outgoing traffic on all the VM ports. If required, you can select another security group or multiple security groups.\nTo disable spoofing protection, clear all of the check boxes and turn off the toggle switch. Security groups cannot be configured with disabled spoofing protection.\n\nIf you selected a virtual network with disabled IP address management\nIn this case, spoofing protection is disabled by default and cannot be enabled. Security groups cannot be configured for such a network.\n\nIf you selected a shared physical network\n\nIn this case, spoofing protection cannot be configured by a self-service user. If you want to enable or disable spoofing protection, contact your system administrator.\r\n                        \n\nAfter specifying the network interface parameters, click Add. The network interface will appear in the Network interfaces list.\n\nIf required, edit IP addresses and security groups of newly added network interfaces. To do this, click the ellipsis icon, click Edit, and then set the parameters.\n\nWhen you finish configuring the VM network interfaces, click Done.\n\nIf you have chosen to boot from a template or volume, which has cloud-init and OpenSSH installed:\n\nAs cloud images have no default password, you can access VMs deployed from them only by using the key authentication method with SSH.\n\nAdd an SSH key to the VM, to be able to access it via SSH without a password. \n\nIn the Select an SSH key window, select an SSH key  and then click Done.\n\nAdd user data to customize the VM after launch, for example, change a user password. \n\nWrite a cloud-config or shell script in the Customization script field or browse a file on your local server to load the script from.\n\nTo inject a script in a Windows VM, refer to the Cloudbase-Init documentation. For example, you can set a new password for the account using the following script:#ps1\r\nnet user <username> <new_password>\r\n\n\nEnable CPU and RAM hot plug for the VM in Advanced options, to be able to change its flavor when the VM is running. You can also enable hot plug after the VM is created.\n\nIf you do not see this option, CPU and RAM hot plug is disabled in your project. To enable it, contact your system administrator.\n\nIf you have chosen to boot from an ISO image, enable UEFI boot in Advanced options, to be able to boot the VM in the UEFI mode. This option cannot be configured after the VM is created.\n\nYou cannot configure UEFI boot if you have selected a template as the VM boot media. If your template has UEFI boot enabled, the option is automatically enabled for the VM, and vice versa.\n\nAfter configuring all of the VM parameters, click Deploy to create and boot the VM.\n\nIf you are deploying the VM from an ISO image, you need to install the guest OS inside the VM by using the built-in VNC console. For VMs with UEFI boot enabled, open the VNC console, and then press any key to boot from the chosen ISO image. Virtual machines created from a template or a boot volume already have a preinstalled guest OS.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/creating-a-virtual-machine.html"
    },
    {
        "title": "Deleting domains",
        "content": "Deleting domainsDELETE /v3/domains/{domain_id}\r\n\nDelete a domain with the specified ID. You need to disable the domain first.\nThis call also deletes all entities owned by the domain, such as users, groups, and projects, and any credentials and granted roles that relate to those entities.\nIf you try to delete an enabled domain, this call returns the\r\nForbidden (403) response code.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=delete-domain-detail#delete-domain\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ndomain_id\n\npath\nstring\nThe domain ID.\n\nExample\nDisable a domain:# curl -ks -X PATCH -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"domain\": {\r\n    \"enabled\": false\r\n  }\r\n}' https://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\r\n\nDelete a domain:# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n405 - Method Not Allowed\n\nMethod is not valid for this endpoint.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n415 - Unsupported Media Type\n\nThe request entity has a media type which the server or resource does not support.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-domains.html"
    },
    {
        "title": "Setting operations per second for users via REST API",
        "content": "Setting operations per second for users via REST API\nYou can limit operations rate with the ostor-limits service and the following parameters: emailAddress specifying the email address, ops specifying the limit type, and default=, get=, put=, list=, or delete= specifying the limit value:# s3_curl PUT \"http://s3.example.com/?ostor-limits&emailAddress=client@example.com&limit-type=ops&limit-resource=get&limit-value=3600\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-operations-per-second-for-users-via-rest-api.html"
    },
    {
        "title": "Viewing resource usage per project",
        "content": "Viewing resource usage per project\nTo get usage of compute resources allocated to all virtual machines that belong to a particular project, you can use either the vinfra command or the gnocchi tool. The latter, however, collects resource usage for a specific period of time.\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo view resource usage per project via vinfra\nUse the command vinfra service compute quotas show --usage <project_id>. For example:# vinfra service compute quotas show 6ef6f48f01b640ccb8ff53117b830fa3 --usage\r\n+---------------------------------+-------+\r\n| Field                           | Value |\r\n+---------------------------------+-------+\r\n| compute.cores.limit             | 20    |\r\n| compute.cores.used              | 2     |\r\n| compute.ram.limit               | 40960 |\r\n| compute.ram.used                | 4096  |\r\n| k8saas.cluster.limit            | 10    |\r\n| k8saas.cluster.used             | 0     |\r\n| lbaas.loadbalancer.limit        | 10    |\r\n| lbaas.loadbalancer.used         | 0     |\r\n| network.floatingip.limit        | 10    |\r\n| network.floatingip.used         | 0     |\r\n| storage.gigabytes.default.limit | 1024  |\r\n| storage.gigabytes.default.used  | 66    |\r\n+---------------------------------+-------+\r\n\nThe output shows that VMs included in the project with the ID 62af79f31ae5488aa33077d02af48282 were allocated 2 vCPUs, 4 GB of RAM, and 66 GB of disk space.\nTo view resource usage per project via gnocchi\nUse the following commands, for example, for the project with the ID 75521ab61d1f4e9090aac5836c219492 from 12:00 PM July 18, 2021, to 12:00 PM July 19, 2021:\n\nTo aggregate the number of provisioned vCPUs:# gnocchi --insecure aggregates --resource-type instance --needed-overlap 0 \"(aggregate sum (metric vcpus mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nTo aggregate the amount of provisioned RAM:# gnocchi --insecure aggregates --resource-type instance --needed-overlap 0 \"(aggregate sum (metric memory mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nTo aggregate the total size of provisioned storage space:# gnocchi --insecure aggregates --resource-type volume --needed-overlap 0 \"(aggregate sum (metric volume.size mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nTo aggregate the size of provisioned storage space with the storage policy with the ID 10056d2e-6fc9-4f2e-92c2-dbebb1714778:# gnocchi --insecure aggregates --resource-type volume --needed-overlap 0 \\\r\n\"(aggregate sum (metric volume.size.10056d2e-6fc9-4f2e-92c2-dbebb1714778 mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nTo aggregate the number of used floating IP addresses:# gnocchi --insecure aggregates --resource-type network --needed-overlap 0 \"(aggregate sum (metric ip.floating mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nTo aggregate the size of outgoing network traffic:# gnocchi --insecure aggregates --resource-type network --needed-overlap 0 \"(aggregate sum (metric bandwidth mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nTo aggregate the number of load balancers:# gnocchi --insecure aggregates --resource-type loadbalancer --needed-overlap 0 \\\r\n\"(aggregate sum (metric network.services.lb.loadbalancer mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nTo aggregate the number of Kubernetes clusters:\n\nKubernetes clusters may be created with an empty project ID. In this case, specify None for the project_id attribute.\n# gnocchi --insecure aggregates --resource-type coe_cluster --needed-overlap 0 \"(aggregate sum (metric magnum.cluster mean))\" \\\r\n\"project_id=75521ab61d1f4e9090aac5836c219492\" --start 2021-07-18T12:00:00 --stop 2021-07-19T12:00:00\n\nSee also\n\nViewing resources, metrics, and measures\n\nViewing outgoing traffic usage\n\nChanging retention period for metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-resource-usage-per-project.html"
    },
    {
        "title": "3. Installation Steps\u00c2\u00b6",
        "content": "3. Installation Steps | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n3. Installation Steps\u00c2\u00b6\nThe installation process will be divided into three sections:\n\nVirtuozzo Hybrid Infrastructure Platform resources planning and configuration.\nDeploying the Hystax Acura Solution on Virtuozzo Hybrid Infrastructure Platform.\nSimple Test Migration.\n\nIn this chapter:\n\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/installation-steps/index.html"
    },
    {
        "title": "Compute metrics",
        "content": "Compute metrics\nMetrics that are used to generate compute alerts are added to the alerting rules and can be found in these files on any node in the cluster:\n\n/var/lib/prometheus/alerts/docker.rules\n\n/var/lib/prometheus/alerts/openstack_cluster.rules\n\n/var/lib/prometheus/alerts/openstack_node.rules\n\n/var/lib/prometheus/alerts/openstack_projects.rules\n\n/var/lib/prometheus/alerts/openstack_services.rules\n\n/var/lib/prometheus/alerts/rabbitmq.rules\n\nThe most important of these metrics are described in the table:\n\nMetric\nDescription\n\nService state metrics\n\nopenstack_cinder_up\n\nShows if the OpenStack Block Storage (Cinder) service is up and running\n\nopenstack_cinder_agent_state\n\nState of the OpenStack Block Storage (Cinder) agent\n\nopenstack_glance_up\n\nShows if the OpenStack Image (Glance) service is up and running\n\nopenstack_heat_up\n\nShows if the OpenStack Orchestration  (Heat) service is up and running\n\nopenstack_container_infra_up\n\nShows if the OpenStack Container (Magnum) service is up and running\n\nopenstack_neutron_up\n\nShows if the OpenStack Networking (Neutron) service is up and running\n\nopenstack_neutron_agent_state\n\nState of the OpenStack Networking (Neutron) agent\n\nopenstack_nova_up\n\nShows if the OpenStack Compute (Nova) service is up and running\n\nopenstack_nova_agent_state\n\nState of the OpenStack Compute (Nova) agent\n\nopenstack_loadbalancer_up\n\nShows if the OpenStack Load Balancer (Octavia) service is up and running\n\nopenstack_placement_up\n\nShows if the OpenStack Placement service is up and running\n\nResource metrics\n\nopenstack_nova_limits_memory_max\n\nProject memory quota, in megabytes\n\nopenstack_nova_limits_memory_used\n\nMemory used by a project, in megabytes\n\nopenstack_nova_limits_vcpus_max\n\nProject vCPU quota\n\nopenstack_nova_limits_vcpus_used\n\nvCPUs used by a project\n\nopenstack_neutron_network_ip_availabilities_total\n\nProject IP address quota\n\nopenstack_neutron_network_ip_availabilities_used\n\nIP addresses used by a project\n\nopenstack_placement_resource_allocation_ratio\n\nVirtual CPU/RAM to physical CPU/RAM allocation ratio\n\nopenstack_placement_resource_reserved\n\nNumber of vCPUs or amount of RAM reserved for the system or storage services\n\nopenstack_placement_resource_total\n\nTotal number of vCPUs or total amount of RAM\n\nopenstack_placement_resource_usage\n\nNumber of vCPUs or amount of RAM provisioned fo virtual machines\n\nRabbitMQ metrics\n\nsoftwareupdates_node_info\n\nCurrently installed version and available version for a specific node\n\nbackend_ha_reconfigure\n\nShows if the HA reconfiguration task is in progress\n\nbackend_node_management\n\nNumber of management nodes. Shows whether high availability is enabled or not.\n\nrabbitmq_build_info\n\nNumber of nodes in the RabbitMQ cluster\n\nrabbitmq_queues\n\nNumber of RabbitMQ queues\n\nOther metrics\n\nopenstack_identity_project_info\n\nProject information\n\nopenstack_nova_server_status\n\nVirtual machine status\n\nnode_systemd_unit_state\n\nState of the systemd services on a node\n\nneutron_network_dhcp_reply_count\n\nShows availability of the virtual DHCP servers:\n\n0.0 \u00e2\u0080\u0093 The DHCP server is not available\n1.0 \u00e2\u0080\u0093 The HA mode is not working\n2.0 \u00e2\u0080\u0093 The DHCP servers are working in the HA mode\n3.0+ \u00e2\u0080\u0093 There are too many DHCP servers in the cluster\n\nSee also\n\nCompute alerts\n\nCore storage metrics\n\nObject storage metrics\n\nBackup storage metrics\n\nCluster update metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/compute-metrics.html"
    },
    {
        "title": "Managing licenses",
        "content": "Managing licenses\nVirtuozzo Hybrid Infrastructure comes with a trial license that allows you to evaluate its features. The trial license has no expiration date but limits storage capacity to 1TB.\nVirtuozzo Hybrid Infrastructure uses license keys as a licensing model for production environments. Implementing the provisioning model, keys are time-limited (subscription) or perpetual and grant a certain storage capacity. If a commercial license is already installed, a key augments its expiration date or storage limit.\n\nIf a license expires, all write operations to the storage cluster stop until a valid license is installed.\n\nLimitations\n\nBlock storage space used by iSCSI LUNs and compute volumes is not fully thin provisioned. After user data removal, unused storage space is not reclaimed and is reported as actual used space, which is charged according to your licensing model. For more details, refer to Logical space chart.\n\nPrerequisites\n\nThe storage cluster is created by following the instructions in Deploying the storage cluster.\n\nTo install a license key\n\nAdmin panel\n\nOn the Settings > License screen, click Register key.\n\nIn the Register key window, paste the license key, and then click Activate.\n\nThe expiration date or storage capacity will change according to what the key grants.\n\nCommand-line interface\nUse the following command:vinfra cluster license load <license-key>\n\n<license-key>\n\nLicense key to register.\n\nFor example, to install the license from the key A38600-3P6W74-RZSK58-Y9ZH05-2X7J48, run:# vinfra cluster license load A38600-3P6W74-RZSK58-Y9ZH05-2X7J48\nYou can view the details of the currently installed license in the vinfra cluster license show output:# vinfra cluster license show\r\n+---------------+------------------------+\r\n| Field         | Value                  |\r\n+---------------+------------------------+\r\n| capacity      | 7036767043584000       |\r\n| expiration_ts | 1549583999             |\r\n| free_size     | 7036766991361913       |\r\n| keynumber     | VZSTOR.74418710.0000   |\r\n| spla          | registered: false      |\r\n|               | registration_url: null |\r\n| status        | active                 |\r\n| total_size    | 7036767043584000       |\r\n| used_size     | 52222087               |\r\n+---------------+------------------------+",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster license load <license-key>\n\n<license-key>\n\nLicense key to register.\n\nFor example, to install the license from the key A38600-3P6W74-RZSK58-Y9ZH05-2X7J48, run:# vinfra cluster license load A38600-3P6W74-RZSK58-Y9ZH05-2X7J48\nYou can view the details of the currently installed license in the vinfra cluster license show output:# vinfra cluster license show\r\n+---------------+------------------------+\r\n| Field         | Value                  |\r\n+---------------+------------------------+\r\n| capacity      | 7036767043584000       |\r\n| expiration_ts | 1549583999             |\r\n| free_size     | 7036766991361913       |\r\n| keynumber     | VZSTOR.74418710.0000   |\r\n| spla          | registered: false      |\r\n|               | registration_url: null |\r\n| status        | active                 |\r\n| total_size    | 7036767043584000       |\r\n| used_size     | 52222087               |\r\n+---------------+------------------------+\n",
                "title": "To install a license key"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOn the Settings > License screen, click Register key.\n\n\n\n\nIn the Register key window, paste the license key, and then click Activate.\n\n\n\n\nThe expiration date or storage capacity will change according to what the key grants.\n",
                "title": "To install a license key"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-licenses.html"
    },
    {
        "title": "Configuring Kubernetes DNS and discovery parameters",
        "content": "Configuring Kubernetes DNS and discovery parameters\nYou can set a custom DNS nameserver and discovery URL for Kubernetes clusters. The default DNS nameserver is 8.8.8.8. The discovery URL is used by Kubernetes to discover members of the etcd cluster. By default, Kubernetes uses the public discovery service at https://discovery.etcd.io and generates a unique URL for each cluster.\nTo change the DNS nameserver\nUse the following command:vinfra service compute k8saas defaults set --dns-nameserver <dns-nameserver> <version>\n\n--dns-nameserver <dns-nameserver>\n\nThe DNS nameserver to be used for Kubernetes clusters.\n<version>\n\nKubernetes version to apply new defaults for.\n\nFor example, to set the DNS nameserver to 1.1.1.1 and apply this change for all of the supported Kubernetes versions, run:# vinfra service compute k8saas defaults set --dns-nameserver 1.1.1.1\nTo set this DNS nameserver only for version 1.24.3, append the version number to the command:# vinfra service compute k8saas defaults set --dns-nameserver 1.1.1.1 v1.24.3\r\n\nTo change the discovery URL\nUse the following command:vinfra service compute k8saas defaults set --discovery-url <discovery-url> <version>\n\n--discovery-url <discovery-url>\n\nSpecifies a custom delivery URL for node discovery.\n<version>\n\nKubernetes version to apply new defaults for.\n\nFor example, to set the discovery URL to medium and apply this change for all of the supported Kubernetes versions, run:# vinfra service compute k8saas defaults set --discovery-url my.discovery.url\nTo set this flavor only for version 1.24.3, append the version number to the command:# vinfra service compute k8saas defaults set --discovery-url my.discovery.url v1.24.3\nSee also\n\nConfiguring the Kubernetes system volume\n\nChanging Kubernetes node flavors\n\nConfiguring Kubernetes load balancers",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-kubernetes-dns-and-discovery-parameters.html"
    },
    {
        "title": "Adding S3 users via CLI",
        "content": "Adding S3 users via CLI\nYou can generate a unique random S3 user ID and an access key pair (S3 Access Key ID, S3 Secret Access Key) using the ostor-s3-admin create-user command. You need to specify a user email. For example:# ostor-s3-admin create-user -e user@email.com -V 0100000000000002\r\nUserEmail:user@email.com\r\nUserId:a49e12a226bd760f\r\nKeyPair[0]:S3AccessKeyId:a49e12a226bd760fGHQ7\r\nKeyPair[0]:S3SecretAccessKey:HSDu2DA00JNGjnRcAhLKfhrvlymzOVdLPsCK2dcq\r\nFlags:none\r\n\nS3 user ID is a 16-digit hexadecimal string. The generated access key pair is used to sign requests to the S3 object storage according to the Amazon S3 Signature Version 2 authentication scheme.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/adding-s3-users-via-cli.html"
    },
    {
        "title": "Network recommendations",
        "content": "Network recommendations\nRecommendations for network hardware\n\nNetwork latency dramatically reduces cluster performance. Use quality network equipment with low latency links. Do not use consumer-grade network switches.\nDo not use desktop network adapters like Intel EXPI9301CTBLK or Realtek 8129 as they are not designed for heavy load and may not support full-duplex links. Also use non-blocking Ethernet switches.\n\nWe recommend using NVIDIA Mellanox ConnectX-5 or ConnectX-6 adapters for the RDMA mode. If you want to use other adapters in the RDMA mode, contact the technical support team for recommendations.\n\nIf you use NVIDIA Mellanox network adapters and AMD Epyc Rome CPU together on physical nodes, ensure that SR-IOV is properly enabled. Otherwise, this may lead to data loss and performance degradation.\nTo enable SR-IOV\n\nEnable SR-IOV in BIOS.\n\nEnable IOMMU on the node: \n\nIn the /etc/default/grub file, locate the GRUB_CMDLINE_LINUX line, and then add the iommu=pt kernel parameter. The resulting line may look as follows:GRUB_CMDLINE_LINUX=\"crashkernel=auto tcache.enabled=0 quiet iommu=pt\"\n\nRegenerate the GRUB configuration file by running:# grub2-mkconfig -o /boot/grub2/grub.cfg\n\nThe default location is different on a UEFI-based system.\n\nWe do not recommend using the BNX2X driver for Broadcom-based network adapters, such as BCM57840 NetXtreme II 10/20-Gigabit Ethernet / HPE FlexFabric 10Gb 2-port 536FLB Adapter. This driver limits MTU to 3616, which affects the cluster performance. Ensure that the BNXT driver is used instead.\n\nRDMA is not supported for the compute service. Therefore, the compute and storage networks must be physically separated on different NICs. If you use the recommended approach with bonded network interfaces, you should have one network card with two bonded network interfaces for the storage network and one network card with two bonded network interfaces for the compute network. To learn how to use a compute trunk network, refer to Connecting virtual switches to trunk interfaces.\n\nRecommendations for network security\n\nUse separate networks (and, ideally albeit optionally, separate network adapters) for internal and public traffic. Doing so will prevent public traffic from affecting cluster I/O performance and also prevent possible denial-of-service attacks from the outside.\nTo avoid intrusions, Virtuozzo Hybrid Infrastructure should be on a dedicated internal network inaccessible from outside.\nEven though cluster nodes have the necessary iptables rules configured, we recommend using an external firewall for untrusted public networks, such as the Internet.\n\nRecommendations for network performance\n\nUse one 1 Gbit/s link per each two HDDs on the node (rounded up). For one or two HDDs on a node, two bonded network interfaces are still recommended for high network availability. The reason for this recommendation is that 1 Gbit/s Ethernet networks can deliver 110-120 MB/s of throughput, which is close to sequential I/O performance of a single disk. Since several disks on a server can deliver higher throughput than a single 1 Gbit/s Ethernet link, networking may become a bottleneck.\nFor maximum sequential I/O performance, use one 1 Gbit/s link per each hard drive or one 10+ Gbit/s link per node. Even though I/O operations are most often random in real-life scenarios, sequential I/O is important in backup scenarios.\nFor maximum overall performance, we recommend using 25 or 40 Gbit/s network adapters. Using 10 Gbit/s adapters is also possible, but not recommended.\nIt is not recommended to configure 1 Gbit/s network adapters to use non-default MTUs (for example, 9000-byte jumbo frames). Such settings require additional configuration of switches and often lead to human error. 10+ Gbit/s network adapters, on the other hand, need to be configured to use jumbo frames to achieve full performance. You will need to configure the same MTU value on each router and switch on the network (refer to your network equipment manuals), as well as on each node\u00e2\u0080\u0099s network card, bond, or VLAN. The MTU value is set to 1500 by default. \n\nNetwork recommendations for clients\nThe following table lists the maximum network performance a client can get with the specified network interface. The recommendation for clients is to use 10 Gbps network hardware between any two cluster nodes and minimize network latencies, especially if SSD disks are used.\n\nMaximum client network performance\r\n            \n\nStorage network interface\nNode max. I/O\nVM max. I/O (replication)\nVM max. I/O (erasure coding)\n\n1 Gbps\n100 MB/s\n100 MB/s\n70 MB/s\n\n2 x 1 Gbps\n~175 MB/s\n100 MB/s\n~130 MB/s\n\n3 x 1 Gbps\n~250 MB/s\n100 MB/s\n~180 MB/s\n\n10 Gbps\n1 GB/s\n1 GB/s\n700 MB/s\n\n2 x 10 Gbps\n1.75 GB/s\n1 GB/s\n1.3 GB/s\n\nSee also\n\nNetwork requirements\n\nNetwork ports",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/network-recommendations.html"
    },
    {
        "title": "Setting user limits in WHMCS",
        "content": "Setting user limits in WHMCS\nYou can limit operations rate with the ostor-limits service and the following parameters: emailAddress specifying the email address, default=, get=, put=, list=, or delete= specifying the limit value.\nSimilarly, you can limit outgoing bandwidth of a response with the following parameters: emailAddress specifying the email address, out= specifying the limit value. WHMCS configures user limits in an S3 cluster when you click the Set button. Create a file S3_setLimitsForUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Set s3 user limits.\r\nfunction S3_setLimitsForUser($vars) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($vars['userid'], $s3_config['whmcs_username']);\r\n\r\n    // Set only if value specified.\r\n    if (!empty($vars['ops-value'])) {\r\n\r\n        // Set s3 bucket limits (ops).\r\n        S3_requestCurl(\r\n            $s3_config['s3_key'],\r\n            $s3_config['s3_secret'],\r\n            $s3_config['s3_gateway'],\r\n                \"/?ostor-limits&emailAddress=\" . $s3_whmcs['email'] .\r\n                \"&limit-type=ops&limit-resource=\" . $vars['ops-name'] .\r\n                    '&limit-value=' . $vars['ops-value'],\r\n            \"PUT\"\r\n        );\r\n    }\r\n\r\n    // Set only if value specified.\r\n    if (!empty($vars['bandwidth-value'])) {\r\n\r\n        // Set s3 bucket limits (bandwidth).\r\n        S3_requestCurl(\r\n            $s3_config['s3_key'],\r\n            $s3_config['s3_secret'],\r\n            $s3_config['s3_gateway'],\r\n                \"/?ostor-limits&emailAddress=\" . $s3_whmcs['email'] .\r\n                \"&limit-type=bandwidth&limit-resource=\" . $vars['bandwidth-name'] .\r\n                    '&limit-value=' . $vars['bandwidth-value'],\r\n            \"PUT\"\r\n        );\r\n    }\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_setLimitsForUser($_GET);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-user-limits-in-whmcs.html"
    },
    {
        "title": "Listing S3 users in WHMCS",
        "content": "Listing S3 users in WHMCS\nYou can list information about all users with the ostor-users service. Additional rows may list S3 access key pairs associated with the user. WHMCS lists the users information fetched from S3 cluster when you click List Users (on/off). Create a file S3_listUsers.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// List s3 users.\r\nfunction S3_listUsers() {\r\n\r\n    // Hide now.\r\n    if ($_SESSION['s3_list_users'] == 1) {\r\n\r\n        // Hide.\r\n        $_SESSION['s3_list_users'] = 0;\r\n\r\n        // Redirect back.\r\n        header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n\r\n     // Return immediately.\r\n        return;\r\n    }\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get s3 users.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users\",\r\n        \"GET\"\r\n    );\r\n\r\n    // Store s3 result.\r\n    $_SESSION['s3_list_users'] = 1;\r\n    $_SESSION['s3_list'] = $s3_client;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_listUsers();\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/listing-s3-users-in-whmcs.html"
    },
    {
        "title": "Viewing cluster logs",
        "content": "Viewing cluster logs\nWhen you encounter a problem in Virtuozzo Hybrid Infrastructure, you can send a problem report, as described in Getting technical support. The report will gather all the logs needed to troubleshoot the problem and send them to the technical support team.\nAlternatively, you can investigate the root cause of your problem by using the logs listed in table below.\n\nService\nLog location\nDescription\n\nMetadata\n/vstorage/mds/logs/mds.log.zst on the storage node\r\nhosting an MDS service\nStorage metadata service events\n\nStorage\n\n/vstorage/<id>/cs/logs/cs.log.zst on the storage node\r\nhosting a CS service\n\nTo find out the log location of a particular CS\r\non the node, run\r\nvstorage -c <cluster_name> list-services -C.\n\nChunk service events\n\nStorage mountpoint\n/var/log/vstorage/<cluster_name>/vstorage-mount.*.blog\r\non any storage node\nSoftware-defined storage mounting on\r\neach node\n\nManagement node\n/var/log/vstorage-ui-backend/messages.log and\r\n/var/log/vstorage-ui-backend/celery*.log on the\r\nmanagement node\nManagement node and admin panel events\n\n/var/log/vstorage-ui-agent/* on any storage node\nAgent controller component events\n\nBackup Gateway\n\n/var/log/abgw/abgw.log*zst on any node in the\r\nBackup Gateway cluster\n\nThe latest log is abgw.log.zst, older ones\r\nare renamed to abgw.log.0.zst, abgw.log.1.zst,\r\netc.\n\nBackup Gateway cluster deployment and\r\nmanagement\n\niSCSI\n/var/log/vstorage/iscsi/vstorage-target.log on any\r\nnode in an iSCSI target group\niSCSI target management\n\n/var/log/vstorage/iscsi/vstorage-target-monitor.log on\r\nany node in an iSCSI target group\niSCSI target monitoring\n\n/var/log/vstorage/iscsi/scst.log.zst on any node in an\r\niSCSI target group\nSCST service logs\n\nS3\n/var/log/ostor/NS-* on the S3 node with NS services\nS3 name server events\n\n/var/log/ostor/OS-* on the S3 node with OS services\nS3 object server events\n\n/var/log/ostor/S3GW-* on the S3 node with GW services\nS3 gateway events\n\n/var/log/nginx/* on any node in the S3 cluster\nnginx service logs\n\n/var/log/ostor/GR-* on the S3 node with GR services\nS3 geo-replicator service events\n\n/var/log/ostor/ACC-* on the S3 node with ACC services\nS3 account control service events\n\n/var/log/ostor/ostorcfgd.log*.zst on the S3 node with the Object storage configuration service (ostor-cfgd.service)\nObject storage configuration service events\n\n/var/log/ostor/ostor-agent.log*.zst on any S3 node\nObject storage host agent service events\n\nNFS\n/var/log/ganesha/ganesha.log and\r\n/var/log/ostor/ostorfs.log.gz on any node in the NFS\r\ncluster\nNFS server events\n\n/var/log/vstorage/vstorage-nfsd.log on any node in\r\nthe NFS cluster\nNFS service events\n\n/var/log/ostor/FS-* on the node hosting an NFS share\nFS service events\n\n/var/log/ostor/OS-* on the node hosting an NFS share\nOS service events\n\n/var/log/ostor/ostorcfgd.log*.zst on the NFS node with the Object storage configuration service (ostor-cfgd.service)\nObject storage configuration service events\n\n/var/log/ostor/ostor-agent.log*.zst on any NFS node\nObject storage host agent service events\n\nCompute\n/var/log/vstorage-ui-backend/ansible.log on the\r\ncontroller node\nCompute cluster and add-on deployment\n\n/var/log/hci/beholder/beholder.log on the controller\r\nnode\nNotifications about all compute\r\nevents, including VM placement\n\n/var/log/hci/nova/* on the compute node hosting a VM\n\nIn case of problems during VM migration, view\r\n/var/log/hci/nova/nova-compute.log on the source\r\nand destination compute nodes.\n\nVirtual machine management\n\n/var/log/hci/neutron/neutron-l3-agent.log on any\r\ncompute node\nVirtual routing events\n\n/var/log/hci/neutron/neutron-openvswitch-agent.log\r\non the compute node hosting a VM\nVM network interface management\n\n/var/log/hci/cinder/* on the controller node\nCompute volume management\n\n/var/log/hci/glance/glance-api.log on the controller\r\nnode\nImage service API requests\n\n/var/log/hci/octavia/octavia-worker.log and\r\n/var/log/hci/octavia/octavia-api.log on the\r\ncontroller node\nLoad balancing service management\n\n/var/log/hci/magnum/magnum-conductor.log,\r\n/var/log/hci/magnum/magnum-api.log, and\r\n/var/log/hci/heat/heat-engine.log on the\r\ncontroller node\nKubernetes service and VM stack\r\ndeployment and management\n\n/var/log/hci/gnocchi/* and\r\n/var/log/hci/ceilometer/* on any compute node\nBilling metering service management\n\n/var/log/hci/freezer/freezer-scheduler.log and\r\n/var/log/hci/freezer/freezer-api.log on the\r\ncontroller node\nBackup service management\n\nHigh availability\n/var/log/vstorage-ui-backend/ha.log on all management\r\nnodes\nHigh availability management\n\nUpdates\n/var/log/vstorage-ui-backend/software-updates.log on\r\nthe management node\nSoftware update orchestration\n\n/var/log/vstorage-ui-agent/software-updates.log on\r\nany storage node\nSoftware update downloading and\r\ninstallation on each node\n\nTo open log files\nUse the following commands:\n\nfor LOG files:# less <log_file>.log\r\n\n\nfor BLOG files:# blogcat <log_file>.blog | less\r\n\n\nfor GZ files:# zless <log_file>.gz\r\n\n\nfor ZST files:# zstdless <log_file>.zst\r\n\n\nSee also\n\nUsing Filebeat for log forwarding\n\nViewing alerts\n\nViewing audit log",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-cluster-logs.html"
    },
    {
        "title": "About the infrastructure",
        "content": "About the infrastructure\nVirtuozzo Hybrid Infrastructure installed on bare-metal servers unites them into a single cluster, which can be easily scaled by adding disks or nodes. The cluster is managed via a highly available web-based admin panel and the command line. The admin panel provides extensive monitoring of all components. The overview dashboards are integrated with Prometheus, Grafana, SNMP, and Zabbix, to provide an insight into the infrastructure status. In addition, the alerts system keeps the administrator informed about misconfiguration, failures, and other issues.\nClustering helps avoid data loss with replication and erasure coding. With high availability enabled, the cluster and services have no single point of failure. The storage cluster is self-healing: if a node or disk fails, the cluster will automatically try to restore the lost data. Besides, with non-disruptive rolling updates the data stays available even when updating the nodes. In case of a node maintenance or applying hotfixes, the workload is migrated to other available nodes.\nThis section describes the major infrastructure components and their architecture: the storage and compute clusters, as well as backup, block, object, and file storage. \n\nSee also\n\nInstallation",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/about-the-infrastructure.html"
    },
    {
        "title": "Disabling and enabling S3 users via REST API",
        "content": "Disabling and enabling S3 users via REST API\nYou can disable a user (users are enabled by default) by sending a POST request to the ostor-users service along with the user email address and the disable parameter:# s3_curl POST \"http://s3.example.com/?ostor-users&emailAddress=user@example.com&disable\"\r\n\nYou can enable a previously disabled user by sending a POST request to the ostor-users service along with the user email address and the enable parameter:# s3_curl POST \"http://s3.example.com/?ostor-users&emailAddress=user@example.com&enable\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/disabling-and-enabling-s3-users-via-rest-api.html"
    },
    {
        "title": "Changing security group assignment",
        "content": "Changing security group assignment\nWhen you create a VM, you select security groups for the VM\u00a0network interfaces. You can also change assigned security groups later.\nLimitations\n\nYou cannot configure security groups if spoofing protection is disabled or IP address management is disabled for the selected network.\n\nTo view virtual machines assigned to a security group\n\nOn the Compute > Network > Security groups tab, click the required security group.\nOn the group right pane, navigate to the Assigned VMs tab. All the assigned virtual machines will be shown along with their status.\n\nYou can click the VM name to go to the VM Overview pane and change the security group assignment for its network interfaces.\nTo assign a security group to a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Networks section. \nClick the ellipsis icon next to the network interface to assign a security group to, and then click Edit.\nIn the Edit network interface window, go to the Security groups tab.\nSelect one or more security groups from the drop-down list, and then click Save.\n\nThe rules from chosen security groups will be applied at runtime.\n\nCommand-line interface\n\nList the VM's network interfaces with assigned security groups. For example:# vinfra service compute server iface list --server myvm -c id -c security_groups --long\r\n+--------------------------------------+----------------------------------------+\r\n| id                                   | security_groups                        |\r\n+--------------------------------------+----------------------------------------+\r\n| 8c11c29b-9a73-4017-baff-1e872b18b54b | - d3a7d0c3-0f5c-4e77-8add-dafebae4a225 |\r\n+--------------------------------------+----------------------------------------+\r\n\n\nEdit the security group of the network interface. For example:# vinfra service compute server iface set --server myvm --security-group mygroup \\\r\n8c11c29b-9a73-4017-baff-1e872b18b54b\r\n+---------------------+--------------------------------------+\r\n| Field               | Value                                |\r\n+---------------------+--------------------------------------+\r\n| fixed_ips           | - 192.168.128.100                    |\r\n| id                  | 8c11c29b-9a73-4017-baff-1e872b18b54b |\r\n| mac_addr            | fa:16:3e:a6:d4:32                    |\r\n| network_id          | 8774a1a4-f7a0-4729-be9b-d282751434c5 |\r\n| security_groups     | 12e6b260-0b61-4551-8168-3e59602a2433 |\r\n| spoofing_protection | True                                 |\r\n+---------------------+--------------------------------------+\r\n\n\nSee also\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nList the VM's network interfaces with assigned security groups. For example:# vinfra service compute server iface list --server myvm -c id -c security_groups --long\r\n+--------------------------------------+----------------------------------------+\r\n| id                                   | security_groups                        |\r\n+--------------------------------------+----------------------------------------+\r\n| 8c11c29b-9a73-4017-baff-1e872b18b54b | - d3a7d0c3-0f5c-4e77-8add-dafebae4a225 |\r\n+--------------------------------------+----------------------------------------+\r\n\n\n\nEdit the security group of the network interface. For example:# vinfra service compute server iface set --server myvm --security-group mygroup \\\r\n8c11c29b-9a73-4017-baff-1e872b18b54b\r\n+---------------------+--------------------------------------+\r\n| Field               | Value                                |\r\n+---------------------+--------------------------------------+\r\n| fixed_ips           | - 192.168.128.100                    |\r\n| id                  | 8c11c29b-9a73-4017-baff-1e872b18b54b |\r\n| mac_addr            | fa:16:3e:a6:d4:32                    |\r\n| network_id          | 8774a1a4-f7a0-4729-be9b-d282751434c5 |\r\n| security_groups     | 12e6b260-0b61-4551-8168-3e59602a2433 |\r\n| spoofing_protection | True                                 |\r\n+---------------------+--------------------------------------+\r\n\n\n\n",
                "title": "To assign a security group to a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Networks section. \nClick the ellipsis icon next to the network interface to assign a security group to, and then click Edit.\nIn the Edit network interface window, go to the Security groups tab.\nSelect one or more security groups from the drop-down list, and then click Save.\n\nThe rules from chosen security groups will be applied at runtime.\n",
                "title": "To assign a security group to a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-security-group-assignment.html"
    },
    {
        "title": "I/O activity charts",
        "content": "I/O activity charts\n\nAdmin panel\nThe Read and Write charts show the history of the cluster I/O activity as the speed of read and write I/O operations in megabytes per second, and the number of read and write I/O operations per second (IOPS). For example:\n\nCommand-line interface\nUse the following command:vstorage -c <cluster_name> top\nFor example, to view the I/O activity in the cluster cluster1, take a look at this line from the command output:IO:       read 30.5MB/s (523ops/s), write  108MB/s (5.9Kop/s)\r\n\n\nIO\n\nDisk I/O activity in the cluster:\n\nSpeed of read and write I/O operations, in bytes per second\nNumber of read and write I/O operations per second\n\nSee also\n\nServices chart\n\nChunks chart\n\nPhysical space chart\n\nLogical space chart",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/i-o-activity-charts.html"
    },
    {
        "title": "Managing access control lists",
        "content": "Managing access control lists\nAn access control list (ACL) limits access to chosen LUNs for specific initiators. Initiators not on the list have access to all LUNs in iSCSI target groups.\nPrerequisites\n\nA target group is created, as described in Creating target groups.\n\nTo add an initiator to a target group\u00e2\u0080\u0099s ACL\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, and then click the desired target group in the list (anywhere except the group\u00e2\u0080\u0099s name).\n\nOn the group right pane, open the Access control tab, and then click the pencil icon.\n\nIn the Access control window, select ACL, and then click Add.\n\nIn the Add ACL window, specify the initiator\u00e2\u0080\u0099s IQN, enter an alias, select the LUNs that it will be able to access, and then click Add. The initiator will appear in the ACL.\n\nHaving populated the ACL with initiators, click Save.\n\nCommand-line interface\n\nAdd an initiator  to the ACL of the target group:vinfra service block-storage target-group acl add [--alias <alias>] [--lun <lun>] <target-group> <wwn>\n\n--alias <alias>\n\nInitiator name\n--lun <lun>\n\nLUN ID\n<target-group>\n\nTarget group name or ID\n<wwn>\n\nWorld wide name (WWN) of the target, that is, IQN\n\nFor example, to add the initiator initiator1 to the ACL of the target group tg1, run:# vinfra service block-storage target-group acl add --lun 0 --alias initiator1 tg1 iqn.2014-06.com.vstorage:target1\n\nEnable ACL for the target group:vinfra service block-storage target-group set --enable-acl <target-group>\n\n--enable-acl\n\nEnable ACL\n<target-group>\n\nTarget group name or ID\n\nFor example, to enable ACL for the target group tg1, run:# vinfra service block-storage target-group set --enable-acl tg1\n\nTo edit an initiator in the ACL\n\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon.\nIn the Access control window, click the pencil icon of the desired initiator, and then click Edit.\nHaving changed the ACL, click Save.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group acl set (--lun <lun> | --no-luns) <target-group> <wwn>\n\n--lun <lun>\n\nLUN ID\n--no-luns\n\nNo LUNs\n<target-group>\n\nTarget group name or ID\n<wwn>\n\nWorld wide name (WWN) of the target, that is, IQN\n\nFor example, to change the LUN ID to 1 for the ACL of the target group tg1, run:# vinfra service block-storage target-group acl set --lun 1 tg1 iqn.2014-06.com.vstorage:target1\n\nTo disable the ACL for a target group\n\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon in the ACL section.\n\nIn the Access control window, clear ACL, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group set --disable-acl <target-group>\n\n--disable-acl\n\nDisable ACL\n<target-group>\n\nTarget group name or ID\n\nFor example, to disable the ACL for the target group tg1, run:# vinfra service block-storage target-group set --disable-acl tg1\n\nTo delete an initiator from the ACL\n\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon in the ACL section.\nIn the Access control window, click the pencil icon of the desired initiator, and then click Delete.\nClick Save to apply the changes.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group acl delete <target-group> <wwn>\n\n<target-group>\n\nTarget group name or ID\n<wwn>\n\nWorld wide name (WWN) of the target, that is, IQN\n\nFor example, to remove the initiator from the ACL of the target group tg1, run:# vinfra service block-storage target-group acl delete tg1 iqn.2014-06.com.vstorage:target1\n\nSee also\n\nManaging CHAP users",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nAdd an initiator  to the ACL of the target group:vinfra service block-storage target-group acl add [--alias <alias>] [--lun <lun>] <target-group> <wwn>\n\n--alias <alias>\n\nInitiator name\n--lun <lun>\n\nLUN ID\n<target-group>\n\nTarget group name or ID\n<wwn>\n\nWorld wide name (WWN) of the target, that is, IQN\n\nFor example, to add the initiator initiator1 to the ACL of the target group tg1, run:# vinfra service block-storage target-group acl add --lun 0 --alias initiator1 tg1 iqn.2014-06.com.vstorage:target1\n\n\nEnable ACL for the target group:vinfra service block-storage target-group set --enable-acl <target-group>\n\n--enable-acl\n\nEnable ACL\n<target-group>\n\nTarget group name or ID\n\nFor example, to enable ACL for the target group tg1, run:# vinfra service block-storage target-group set --enable-acl tg1\n\n\n",
                "title": "To add an initiator to a target group\u00e2\u0080\u0099s ACL"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group acl set (--lun <lun> | --no-luns) <target-group> <wwn>\n\n--lun <lun>\n\nLUN ID\n--no-luns\n\nNo LUNs\n<target-group>\n\nTarget group name or ID\n<wwn>\n\nWorld wide name (WWN) of the target, that is, IQN\n\nFor example, to change the LUN ID to 1 for the ACL of the target group tg1, run:# vinfra service block-storage target-group acl set --lun 1 tg1 iqn.2014-06.com.vstorage:target1\n",
                "title": "To edit an initiator in the ACL"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group set --disable-acl <target-group>\n\n--disable-acl\n\nDisable ACL\n<target-group>\n\nTarget group name or ID\n\nFor example, to disable the ACL for the target group tg1, run:# vinfra service block-storage target-group set --disable-acl tg1\n",
                "title": "To disable the ACL for a target group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group acl delete <target-group> <wwn>\n\n<target-group>\n\nTarget group name or ID\n<wwn>\n\nWorld wide name (WWN) of the target, that is, IQN\n\nFor example, to remove the initiator from the ACL of the target group tg1, run:# vinfra service block-storage target-group acl delete tg1 iqn.2014-06.com.vstorage:target1\n",
                "title": "To delete an initiator from the ACL"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, and then click the desired target group in the list (anywhere except the group\u00e2\u0080\u0099s name).\n\nOn the group right pane, open the Access control tab, and then click the pencil icon.\n\n\n\n\n\n\nIn the Access control window, select ACL, and then click Add.\n\n\n\n\n\n\nIn the Add ACL window, specify the initiator\u00e2\u0080\u0099s IQN, enter an alias, select the LUNs that it will be able to access, and then click Add. The initiator will appear in the ACL.\n\n\n\n\n\nHaving populated the ACL with initiators, click Save.\n\n",
                "title": "To add an initiator to a target group\u00e2\u0080\u0099s ACL"
            },
            {
                "example": "\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon.\nIn the Access control window, click the pencil icon of the desired initiator, and then click Edit.\nHaving changed the ACL, click Save.\n\n",
                "title": "To edit an initiator in the ACL"
            },
            {
                "example": "\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon in the ACL section.\n\nIn the Access control window, clear ACL, and then click Save.\n\n\n\n\n\n\n",
                "title": "To disable the ACL for a target group"
            },
            {
                "example": "\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon in the ACL section.\nIn the Access control window, click the pencil icon of the desired initiator, and then click Delete.\nClick Save to apply the changes.\n\n",
                "title": "To delete an initiator from the ACL"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-access-control-lists.html"
    },
    {
        "title": "Configuring branding for the self-service panel",
        "content": "Configuring branding for the self-service panel\nYou can customize the user interface of the self-service panel by applying your own branding theme to it. Branding theme includes the product title, favicon, logos, and the panel color scheme.\nThe following branding themes are available:\n\nDefault is the default theme that is configured for and applied to all domains. You can change this theme on the Settings > System settings > Self-service portal screen. If required, you can discard all your changes to the default branding theme by resetting it to factory defaults.\nPersonal is a custom theme that is configured for each domain separately. You can change this theme by navigating to the required domain and switching to the Settings > Branding theme screen. If you want to re-apply the default theme for a domain, reset its personal branding theme to default.\n\nTo configure the branding theme\n\nIn the Product title section, click the pencil icon to change the product title displayed on the self-service web-browser tab. In a window that opens, specify a product title, and then click Save.\nIn the Favicon section, click Upload or the displayed image to upload a favicon for the self-service panel, and then select an image file in the .png or .ico format. The image must be 32 x 32 pixels in dimensions.\nIn the Logos section, upload two versions of the same logo: left-aligned and centered: Under Logo for the header, click Upload or the displayed image, and then browse to the left-aligned logo version. This image will be used as the panel header. Under Logo for the login screen, click Upload or the displayed image, and browse to the centered logo. It will be used at the login screen. \nThe images must be 256 x 64 pixels in dimensions and up to 2 MB in size. The following image formats are supported: .png, .jpg, or .svg. In case of .png, a transparent background is recommended.\nIn the Color scheme section, click Change to select a color scheme for the self-service panel. In a window that opens, select the desired color scheme, and then click Apply.\n\nTo reset the branding theme to default\nClick Reset to default next to the Branding theme field, and then click Reset in the confirmation window.\nAfter the reset, the default branding theme will use factory defaults while a personal branding theme will be replaced by the default theme.\nSee also\n\nManaging domains\n\nChanging the self-service panel IP address",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-branding-for-self-service.html"
    },
    {
        "title": "Managing S3 resources",
        "content": "Managing S3 resources\n\u00a0",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-s3-resources.html"
    },
    {
        "title": "Showing image details",
        "content": "Showing image detailsGET /v2/images/{image_id}\r\n\nShow details of an image with the specified ID.\nSource: https://docs.openstack.org/api-ref/image/v2/index.html?expanded=show-image-detail#show-image\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nimage_id\n\npath\nstring\nThe UUID of the image.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9292/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nchecksum\n\nbody\nstring\nHash that is used over the image data. The Image\r\nservice uses this value for verification.  The value might be\r\nnull (JSON null data type).\n\ncontainer_format\n\nbody\nenum\n\nFormat of the image container.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud.\nExample formats are: ami, ari, aki, bare,\r\novf, ova, or docker.\nThe value might be null (JSON null data type).\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndisk_format\n\nbody\nenum\n\nThe format of the disk.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud. See the Image Schema\r\nresponse from the cloud itself for the valid values available.\nExample formats are: ami, ari, aki, vhd,\r\nvhdx, vmdk, raw, qcow2, vdi, ploop or\r\niso.\nThe value might be null (JSON null data type).\n\nfile\n\nbody\nstring\nThe URL for the virtual machine image file.\n\nid\n\nbody\nstring\n\nA unique, user-defined image UUID, in the format:nnnnnnnn-nnnn-nnnn-nnnn-nnnnnnnnnnnn\r\n\nWhere n is a hexadecimal digit from 0 to f, or F.\nFor example:b2173dd3-7ad6-4362-baa6-a68bce3565cb\r\n\nIf you omit this value, the API generates a UUID for the image.\n\nmin_disk\n\nbody\ninteger\nAmount of disk space in GB that is required to boot the image.\r\nThe value might be null (JSON null data type).\n\nmin_ram\n\nbody\ninteger\nAmount of RAM in MB that is required to boot the image.\r\nThe value might be null (JSON null data type).\n\nname\n\nbody\nstring\nThe name of the image.  Value might be null (JSON null data type).\n\nos_hash_algo\n\nbody\nstring\n\nThe algorithm used to compute a secure hash of the image data for this\r\nimage.  The result of the computation is displayed as the value of the\r\nos_hash_value property.  The value might be null (JSON null\r\ndata type).  The algorithm used is chosen by the cloud operator; it\r\nmay not be configured by end users.\nNew in version 2.7\n\nos_hash_value\n\nbody\nstring\n\nThe hexdigest of the secure hash of the image data computed using the\r\nalgorithm whose name is the value of the os_hash_algo property.\r\nThe value might be null (JSON null data type) if data has not\r\nyet been associated with this image, or if the image was created using\r\na version of the Image Service API prior to version 2.7.\nNew in version 2.7\n\nos_hidden\n\nbody\nboolean\n\nThis field controls whether an image is displayed in the default\r\nimage-list response.  A \u00e2\u0080\u009chidden\u00e2\u0080\u009d image is out of date somehow (for\r\nexample, it may not have the latest updates applied) and hence should\r\nnot be a user\u00e2\u0080\u0099s first choice, but it\u00e2\u0080\u0099s not deleted because it may be\r\nneeded for server rebuilds.  By hiding it from the default image list,\r\nit\u00e2\u0080\u0099s easier for end users to find and use a more up-to-date version of\r\nthis image.\nNew in version 2.7\n\nowner\n\nbody\nstring\nAn identifier for the owner of the image, usually the project (also\r\ncalled the \u00e2\u0080\u009ctenant\u00e2\u0080\u009d) ID.\r\nThe value might be null (JSON null data type).\n\nprotected\n\nbody\nboolean\nA boolean value that must be false or the image cannot be deleted.\n\nschema\n\nbody\nstring\nThe URL for the schema describing a virtual machine image.\n\nself\n\nbody\nstring\nThe URL for the virtual machine image.\n\nsize\n\nbody\ninteger\nThe size of the image data, in bytes.  The value\r\nmight be null (JSON null data type).\n\nstatus\n\nbody\nstring\nThe image status.\n\ntags\n\nbody\narray\nList of tags for this image, possibly an empty list.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvirtual_size\n\nbody\ninteger\nThe virtual size of the image.  The value might\r\nbe null (JSON null data type).\n\nvisibility\n\nbody\nstring\nImage visibility, that is, the access permission for the image.\n\ndirect_url (Optional)\nbody\nstring\n\nThe URL to access the image file kept in external store.  It is present\r\nonly if the show_image_direct_url option is true in the Image\r\nservice\u00e2\u0080\u0099s configuration file.\n\nAs it presents a security risk, this\r\noption is disabled by default.\n\nlocations (Optional)\nbody\narray\n\nA list of objects, each of which describes an image location.  Each object\r\ncontains a url key, whose value is a URL specifying a location, and a\r\nmetadata key, whose value is a dict of key:value pairs containing\r\ninformation appropriate to the use of whatever external store is indicated\r\nby the URL.  This list appears only if the show_multiple_locationsoption is set to true in the Image service\u00e2\u0080\u0099s configuration file.\n\nAs it presents a security risk, this option is disabled by\r\ndefault.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"image_validated\": \"yes\",\r\n  \"container_format\": \"bare\",\r\n  \"min_ram\": 0,\r\n  \"updated_at\": \"2020-02-04T10:58:47Z\",\r\n  \"file\": \"/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67/file\",\r\n  \"owner\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n  \"id\": \"c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n  \"size\": 12716032,\r\n  \"os_distro\": \"linux\",\r\n  \"self\": \"/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n  \"disk_format\": \"qcow2\",\r\n  \"os_hash_algo\": \"sha512\",\r\n  \"direct_url\": \"file:///mnt/vstorage/vols/datastores/glance/c92d820c-<...>\",\r\n  \"hw_disk_bus\": \"virtio\",\r\n  \"schema\": \"/v2/schemas/image\",\r\n  \"status\": \"active\",\r\n  \"tags\": [],\r\n  \"trait:CUSTOM_HCI_122E856B9E9C4D80A0F8C21591B5AFCB\": \"required\",\r\n  \"visibility\": \"public\",\r\n  \"min_disk\": 1,\r\n  \"virtual_size\": null,\r\n  \"name\": \"cirros\",\r\n  \"checksum\": \"443b7623e27ecf03dc9e01ee93f67afe\",\r\n  \"created_at\": \"2020-01-28T12:58:17Z\",\r\n  \"os_hidden\": false,\r\n  \"protected\": false,\r\n  \"os_hash_value\": \"6513f21e44aa3da349f248188a<...>\",\r\n  \"os_type\": \"linux\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-image-details.html"
    },
    {
        "title": "Troubleshooting performance issues",
        "content": "Troubleshooting performance issues\nIn Virtuozzo Hybrid Infrastructure, many performance issues and misconfigurations trigger system alerts, which are displayed in the admin panel. However, some performance issues can only be detected manually by using the command-line interface.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/troubleshooting-performance-issues.html"
    },
    {
        "title": "Enabling integration",
        "content": "Enabling integration\nTo enable integration with CloudBlue Connect, first deploy a CentOS 7 virtual machine in any cloud environment, then install the connector service inside it as follows:\n\nAdd the following repository:\ncat << EOF > /etc/yum.repos.d/hci.repo\r\n[hci-base]\r\nname=Hybrid Infrastructure Base Repo\r\nbaseurl=http://repo.virtuozzo.com/vz-platform/releases/5.4/x86_64/os/\r\npriority=51\r\nenabled=1\r\ngpgcheck=0\r\n\r\nEOF\n\nInstall the cloudblue-connector package:\nyum install <path_to_the_package>/cloudblue-connector-<version>.vl7.noarch.rpm\n\nInstall the Connect SDK:\neasy_install connect-sdk==20.2\n\nIf you want to use flat billing, do the following:\n\nCopy the configuration file example to config.json and open the latter for editing:\ncp /etc/cloudblue-connector/config.json.example /etc/cloudblue-connector/config.jsonvi /etc/cloudblue-connector/config.json{\r\n    \"infraKeystoneEndpoint\": \"https://192.168.1.40:5000/v3\",\r\n    \"infraDomain\": \"Default\",\r\n    \"infraProject\": \"admin\",\r\n    \"infraUser\": \"vstorage-service-user\",\r\n    \"infraPassword\": \"***********\",\r\n    \"apiEndpoint\": \"https://api.connect.cloud.im/public/v1\",\r\n    \"apiKey\": \"ApiKey SU-469-692-689:*****************\",\r\n    \"products\": [\"PRD-063-065-206\",\"PRD-022-814-775\"],\r\n    \"templates\": {\r\n        \"PRD-022-814-775\": {\"grant\": \"TL-699-973-660\", \"revoke\": \"Access to VDC has been revoked\"},\r\n        \"PRD-063-065-206\": {\"grant\": \"TL-101-949-609\", \"revoke\": \"Access to VDC has been revoked\"}\r\n    }\r\n}\r\n\n\nChange the default parameters:\n\nIn \"infraKeystoneEndpoint\", replace the example IP address with the IP address of the Virtuozzo Hybrid Infrastructure cluster that you want to connect to.\nIn \"infraDomain\", \"infraProject\", \"infraUser\", and \"infraPassword\", change the domain, project, and user credentials to the ones of a Virtuozzo Hybrid Infrastructure system administrator.\n\nIn \"apiEndpoint\", specify the API endpoint to interact with the Connect API copied from the vendor portal on the Extensions > General page.\n\nIn \"apiKey\", specify the API key copied from the vendor portal on the Extensions > Tokens page.\n\nIn \"products\", specify product IDs copied from the vendor portal on the Products page.\n\nIn \"templates\", specify template IDs for each product copied from the vendor portal on the Products > product > Embedding page. Click the Templates tab and go to the Activation tile templates section.\n\nRun the command:\ncloudblue-fulfillments\n\nEnable and start the cloudblue-fulfillments service:\nsystemctl enable cloudblue-fulfillmentssystemctl start cloudblue-fulfillments\n\nIf you want to use the pay-as-you-go model, do the following:\n\nCopy the configuration usage example to config-usage.json and open the latter for editing:\ncp /etc/cloudblue-connector/config-usage.json.example /etc/cloudblue-connector/config-usage.jsonvi /etc/cloudblue-connector/config-usage.json{\r\n    \"infraKeystoneEndpoint\": \"https://192.168.1.40:5000/v3\",\r\n    \"infraDomain\": \"Default\",\r\n    \"infraProject\": \"admin\",\r\n    \"infraUser\": \"vstorage-service-user\",\r\n    \"infraPassword\": \"****\",\r\n    \"apiEndpoint\": \"https://api.connect.cloud.im/public/v1\",\r\n    \"apiKey\": \"ApiKey SU-469-692-689:**************************\",\r\n    \"products\": [\"PRD-063-065-206\"],\r\n    \"templates\": {\r\n        \"PRD-263-056-411\": {\"grant\": \"TL-304-029-298\", \"revoke\": \"Access to VDC has been revoked\"},\r\n        \"PRD-063-065-206\": {\"grant\": \"TL-101-949-609\", \"revoke\": \"Access to VDC has been revoked\"}\r\n    }\r\n}\r\n\n\nChange the default parameters:\n\nIn \"infraKeystoneEndpoint\", replace the example IP address with the IP address of the Virtuozzo Hybrid Infrastructure cluster that you want to connect to.\nIn \"infraDomain\", \"infraProject\", \"infraUser\", and \"infraPassword\", change the domain, project, and user credentials to the ones of a Virtuozzo Hybrid Infrastructure system administrator.\n\nIn \"apiEndpoint\", specify the API endpoint to interact with the Connect API copied from the vendor portal on the Extensions > General page.\n\nIn \"apiKey\", specify the API key copied from the vendor portal on the Extensions > Tokens page.\n\nIn \"products\", specify the ID of the product with the pay-as-you-go billing model. Copy the product ID from the vendor portal on the Products page.\n\nIn \"templates\", specify template IDs for each product copied from the vendor portal on the Products > product > Embedding page. Click the Templates tab and go to the Activation tile templates section.\n\nEnable and start the cloudblue-usage service:\nsystemctl enable cloudblue-usagesystemctl start cloudblue-usage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/enabling-integration.html"
    },
    {
        "title": "Creating network bonds",
        "content": "Creating network bonds\nBonding multiple network interfaces is optional but provides the following benefits:\n\nHigh network availability. If one of the interfaces fails, the traffic will be automatically routed through the working interface(s).\nHigher network performance. For example, two bonded Gigabit interfaces will deliver the throughput of about 1.7 Gbit/s or up to 200 MB/s. For a storage node, the required number of network interfaces to bond may depend on the number of disks. For example, an HDD can deliver data at speeds of up to 1 Gbps.\n\nLimitations\n\nA network interface must have at least one IPv4 address.\nYou can only assign an IPv6 address manually. Obtaining an IPv6 address via DHCP is not supported.\nYou cannot bond Ethernet and Infiniband interfaces.\nYou cannot bond network bridges and Infiniband interfaces.\n\nIf you are bonding an Open vSwitch-based bridge used in the compute cluster with another network interface, choose between these two bonding modes:\n\nbalance-tcp, where load balancing is done based on L2-L4 data like the destination MAC address, IP address, and TCP port. This mode requires that Link Aggregation Control Protocol (LACP) be enabled on the physical switch the node is connected to.\nactive-backup, where one network interface is active and all other interfaces are passive. If the active interface fails, a passive one becomes active instead.\n\nTo create a bond\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click Create.\nIn the Create network interface window, select the Bond type and network interfaces to bond, and then click Next.\n\nSelect the bonding mode. For both fault tolerance and good performance, it is recommended to set the balance-xor mode.\n\nSelect a network to assign the bond to, and then specify the network parameters:\n\nSelect Automatically (DHCP) to obtain the IP address, DNS, and routing settings from the DHCP server.\nSelect Automatically (DHCP address only) to obtain only the IP address from the DHCP server.\nSelect Manually, and then specify the IPv4 address and optionally the IPv6 address in CIDR notation by clicking Add.\n\nDynamic IP address allocation will cause network issues as soon as the IP addresses of cluster nodes change. Configure static IP addresses from the start or as soon as possible.\n\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\n\nEnter the desired MTU value in the MTU field. If you leave Auto, the subordinate interface MTU will be used.\n\nSelect the MAC address in the MAC field. Select Auto to automatically choose between the MAC addresses of the subordinate interfaces or select one of them manually.\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra node iface create-bond [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                              [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                              [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                              [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                              [--bonding-opts <bonding_opts>] [--network <network>]\r\n                              [--node <node>] --bond-type <bond-type> --ifaces <ifaces>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--bonding-opts <bonding_opts>\n\nAdditional bonding options\n--bond-type <bond-type>\n\nBond type (balance-rr, active-backup, balance-xor, broadcast, 802.3ad, balance-tlb, balance-alb)\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n--ifaces <ifaces>\n\nA comma-separated list of network interface names, for example, iface1,iface2,\u00e2\u0080\u00a6,iface<N>\n\nFor example, to bond network interfaces eth2 and eth3 into bond0 of the type balance-xor on the node node002, run:# vinfra node iface create-bond --ifaces eth2,eth3 --bond-type balance-xor --dhcp4 --node node002\n\nSee also\n\nChanging network interface parameters\n\nManaging network interfaces\n\nWhat's next\n\nCreating VLAN interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface create-bond [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                              [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                              [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                              [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                              [--bonding-opts <bonding_opts>] [--network <network>]\r\n                              [--node <node>] --bond-type <bond-type> --ifaces <ifaces>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--bonding-opts <bonding_opts>\n\nAdditional bonding options\n--bond-type <bond-type>\n\nBond type (balance-rr, active-backup, balance-xor, broadcast, 802.3ad, balance-tlb, balance-alb)\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n--ifaces <ifaces>\n\nA comma-separated list of network interface names, for example, iface1,iface2,\u00e2\u0080\u00a6,iface<N>\n\nFor example, to bond network interfaces eth2 and eth3 into bond0 of the type balance-xor on the node node002, run:# vinfra node iface create-bond --ifaces eth2,eth3 --bond-type balance-xor --dhcp4 --node node002\n",
                "title": "To create a bond"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click Create.\nIn the Create network interface window, select the Bond type and network interfaces to bond, and then click Next.\n\nSelect the bonding mode. For both fault tolerance and good performance, it is recommended to set the balance-xor mode.\n\n\nSelect a network to assign the bond to, and then specify the network parameters:\n\nSelect Automatically (DHCP) to obtain the IP address, DNS, and routing settings from the DHCP server.\nSelect Automatically (DHCP address only) to obtain only the IP address from the DHCP server.\nSelect Manually, and then specify the IPv4 address and optionally the IPv6 address in CIDR notation by clicking Add.\n\n\nDynamic IP address allocation will cause network issues as soon as the IP addresses of cluster nodes change. Configure static IP addresses from the start or as soon as possible.\n\n\n\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\n\n\nEnter the desired MTU value in the MTU field. If you leave Auto, the subordinate interface MTU will be used.\n\nSelect the MAC address in the MAC field. Select Auto to automatically choose between the MAC addresses of the subordinate interfaces or select one of them manually.\nClick Create.\n\n\n\n\n\n",
                "title": "To create a bond"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-network-bonds.html"
    },
    {
        "title": "Cluster update metrics",
        "content": "Cluster update metrics\nMetrics that are used to generate cluster update alerts are added to the alerting rules in /var/lib/prometheus/alerts/backend.rules. These metrics are described in the table:\n\nMetric\nDescription\n\nLabels\n\nsoftwareupdates_cluster_info\n\nInformation about software updates for the cluster\n\navailable_version\n\nAvailable version for the cluster\nimpact\n\nUpdate impact:\n\nreboot: reboot is required during the update\nmaintenance: maintenance is required during the update\nno_impact:  reboot and maintenance are not required during the update\n\nstate\n\nUpdate state for the cluster\nversion\n\nCurrently installed version for the cluster\n\nsoftwareupdates_cluster_available\n\nUpdate availability for the cluster\n\navailable_version\n\nAvailable version for the cluster\nimpact\n\nUpdate impact:\n\nreboot: reboot is required during the update\nmaintenance: maintenance is required during the update\nno_impact:  reboot and maintenance are not required during the update\n\nversion\n\nCurrently installed version for the cluster\n\nsoftwareupdates_node_uptodate\n\nShows if a specific node is updated to the latest version\n\navailable_version\n\nAvailable version for a node\nimpact\n\nUpdate impact:\n\nreboot: reboot is required during the update\nmaintenance: maintenance is required during the update\nno_impact:  reboot and maintenance are not required during the update\n\nnode\n\nNode ID\nversion\n\nCurrently installed version for a node\n\nsoftwareupdates_node_available\n\nUpdate availability for a specific node\n\navailable_version\n\nAvailable version for a node\nimpact\n\nUpdate impact:\n\nreboot: reboot is required during the update\nmaintenance: maintenance is required during the update\nno_impact:  reboot and maintenance are not required during the update\n\nnode\n\nNode ID\nversion\n\nCurrently installed version for a node\n\nsoftwareupdates_node_info\n\nInformation about software updates for a specific node\n\navailable_version\n\nAvailable version for a node\nimpact\n\nUpdate impact:\n\nreboot: reboot is required during the update\nmaintenance: maintenance is required during the update\nno_impact:  reboot and maintenance are not required during the update\n\nnode\n\nNode ID\nstate\n\nUpdate state for a node\nversion\n\nCurrently installed version for a node\n\nsoftwareupdates_node_state\n\nUpdate state of a specific node\n\nnode\n\nNode ID\nstate\n\nUpdate state of a node\n\nSee also\n\nInfrastructure alerts\n\nCore storage metrics\n\nObject storage metrics\n\nBackup storage metrics\n\nCompute metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/cluster-update-metrics.html"
    },
    {
        "title": "Creating NFS exports",
        "content": "Creating NFS exports\nTo create NFS exports, follow these steps:\n\nCreate the root export.\n\nMount the root export, as described in the Storage User Guide.\n\nDo not mount NFS shares on cluster nodes. It may lead to node freeze.\n\nCreate user exports in the mounted root export.\nMount these user exports the same way you have mounted the root export.\n\nPrerequisites\n\nNFS shares are created, as described in Creating NFS shares.\n\nTo create the root export\n\nAdmin panel\n\nOn the Storage services > NFS > Shares screen, click the name of the desired share. This will open the share screen.\nOn the share screen, click Add export.\n\n In the Add export window, specify root as the export name and / as its path, and then select the Read and write access mode. Then, click Add.\n\nDo not use other names or paths for the root export.\n\nThis will create a directory with a default path that designates the export location inside the share. This path is automatically generated based on the share name and used (alongside the share\u00e2\u0080\u0099s IP address) to mount the export.\n\nDo not give the users access to the root export.\n\nThe root export will be shown in the export list.\n\nCommand-line interface\nUse the following command:vinfra service nfs export create --path <path> --access-type <access-type> --security-types <security-types>\r\n                                 <share-name> <export-name>\n\n--path <path>\n\nPath to the NFS export\n--access-type <access-type>\n\nType of access to the NFS export (none, rw, or ro)\n--security-types <security-types>\n\nTypes of NFS export security (none, sys, krb5, krb5i, or krb5p)\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to create the root export for the share share1, run:# vinfra service nfs export create share1 root --path / --access-type rw --security-types none\nThe created root export will appear in the vinfra service nfs export list output:# vinfra service nfs export list --share-name share1\r\n+---------+-----------------+-------------+\r\n| name    | path            | access_type |\r\n+---------+-----------------+-------------+\r\n| root    | /share1         | rw          |\r\n+---------+-----------------+-------------+\n\nTo create user exports\n\nAdmin panel\n\nIn the mounted root export, create a subdirectory for a user export, for example, export1.\nOn the share screen, click Add export.\n\nIn the Add export window, specify the following:\n\nEnter a user export name and specify /export1 as a path.\nSelect the access mode between Read and write and Read.\n\nIn the Advanced settings section, select the desired root squashing option:\n\nIf you select Disallow access with root UID, you map root users to the anonymous user and group.\nIf you select Disallow access with root UID but allow access to user groups with non-zero GIDs, you map root users to the anonymous user, but allow non-zero groups of root users.\nIf you select Squash all users to anonymous, you map all users to the anonymous user.\nIf you select Allow access with root UID, you allow root users keep administrative access privileges to remote files.\n\nChange the anonymous user and group identifiers. Their default value is -2, which maps to the \"nobody\" user.\n\nClick Add.\nThe user export will appear in the export list.\n\nCommand-line interface\nUse the following command:vinfra service nfs export create --path <path> --access-type <access-type> --security-types <security-types>\r\n                                 [--client <address=ip_addresses:access=access_type:security=security_types>]\r\n                                 [--squash <squash>] [--anonymous-gid <anonymous-gid>] [--anonymous-uid <anonymous-uid>]\r\n                                 <share-name> <export-name>\n\n--path <path>\n\nPath to the NFS export\n--access-type <access-type>\n\nType of access to the NFS export (none, rw, or ro)\n--security-types <security-types>\n\nTypes of NFS export security (none, sys, krb5, krb5i, or krb5p)\n--client <address=ip_addresses:access=access_type:security=security_types>\n\nClient access list of the NFS export\n--squash <squash>\n\nNFS export squash (root_squash, root_id_squash, all_squash, or none)\n--anonymous-gid <anonymous-gid>\n\nAnonymous GID of the NFS export\n--anonymous-uid <anonymous-uid>\n\nAnonymous UID of the NFS export\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to create the user export export1 at /export1, run:# vinfra service nfs export create share1 export1 --path /export1 --access-type rw --security-types none\nThe created NFS exports will appear in the vinfra service nfs export list output:# vinfra service nfs export list --share-name share1\r\n+---------+-----------------+-------------+\r\n| name    | path            | access_type |\r\n+---------+-----------------+-------------+\r\n| export1 | /share1/export1 | rw          |\r\n| root    | /share1         | rw          |\r\n+---------+-----------------+-------------+\n\nWhat's next\n\nManaging file storage\n\nMonitoring file storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs export create --path <path> --access-type <access-type> --security-types <security-types>\r\n                                 <share-name> <export-name>\n\n--path <path>\n\nPath to the NFS export\n--access-type <access-type>\n\nType of access to the NFS export (none, rw, or ro)\n--security-types <security-types>\n\nTypes of NFS export security (none, sys, krb5, krb5i, or krb5p)\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to create the root export for the share share1, run:# vinfra service nfs export create share1 root --path / --access-type rw --security-types none\nThe created root export will appear in the vinfra service nfs export list output:# vinfra service nfs export list --share-name share1\r\n+---------+-----------------+-------------+\r\n| name    | path            | access_type |\r\n+---------+-----------------+-------------+\r\n| root    | /share1         | rw          |\r\n+---------+-----------------+-------------+\n",
                "title": "To create the root export"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs export create --path <path> --access-type <access-type> --security-types <security-types>\r\n                                 [--client <address=ip_addresses:access=access_type:security=security_types>]\r\n                                 [--squash <squash>] [--anonymous-gid <anonymous-gid>] [--anonymous-uid <anonymous-uid>]\r\n                                 <share-name> <export-name>\n\n--path <path>\n\nPath to the NFS export\n--access-type <access-type>\n\nType of access to the NFS export (none, rw, or ro)\n--security-types <security-types>\n\nTypes of NFS export security (none, sys, krb5, krb5i, or krb5p)\n--client <address=ip_addresses:access=access_type:security=security_types>\n\nClient access list of the NFS export\n--squash <squash>\n\nNFS export squash (root_squash, root_id_squash, all_squash, or none)\n--anonymous-gid <anonymous-gid>\n\nAnonymous GID of the NFS export\n--anonymous-uid <anonymous-uid>\n\nAnonymous UID of the NFS export\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to create the user export export1 at /export1, run:# vinfra service nfs export create share1 export1 --path /export1 --access-type rw --security-types none\nThe created NFS exports will appear in the vinfra service nfs export list output:# vinfra service nfs export list --share-name share1\r\n+---------+-----------------+-------------+\r\n| name    | path            | access_type |\r\n+---------+-----------------+-------------+\r\n| export1 | /share1/export1 | rw          |\r\n| root    | /share1         | rw          |\r\n+---------+-----------------+-------------+\n",
                "title": "To create user exports"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Storage services > NFS > Shares screen, click the name of the desired share. This will open the share screen.\nOn the share screen, click Add export.\n\n In the Add export window, specify root as the export name and / as its path, and then select the Read and write access mode. Then, click Add.\n\nDo not use other names or paths for the root export.\n\n\n\n\n\nThis will create a directory with a default path that designates the export location inside the share. This path is automatically generated based on the share name and used (alongside the share\u00e2\u0080\u0099s IP address) to mount the export.\n\nDo not give the users access to the root export.\n\nThe root export will be shown in the export list.\n\n\n",
                "title": "To create the root export"
            },
            {
                "example": "\nAdmin panel\n\nIn the mounted root export, create a subdirectory for a user export, for example, export1.\nOn the share screen, click Add export.\n\nIn the Add export window, specify the following:\n\nEnter a user export name and specify /export1 as a path.\nSelect the access mode between Read and write and Read.\n\nIn the Advanced settings section, select the desired root squashing option:\n\nIf you select Disallow access with root UID, you map root users to the anonymous user and group.\nIf you select Disallow access with root UID but allow access to user groups with non-zero GIDs, you map root users to the anonymous user, but allow non-zero groups of root users.\nIf you select Squash all users to anonymous, you map all users to the anonymous user.\nIf you select Allow access with root UID, you allow root users keep administrative access privileges to remote files.\n\n\n\nChange the anonymous user and group identifiers. Their default value is -2, which maps to the \"nobody\" user.\n\n\n\n\n\n\n\nClick Add.\nThe user export will appear in the export list.\n\n",
                "title": "To create user exports"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-nfs-exports.html"
    },
    {
        "title": "Updating domains",
        "content": "Updating domainsPATCH /v3/domains/{domain_id}\r\n\nChange the name and description of a domain with the specified ID.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=update-domain-detail#update-domain\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ndomain_id\n\npath\nstring\nThe domain ID.\n\ndomain\n\nbody\nobject\nA domain object.\n\ndescription (Optional)\nbody\nstring\nThe description of the domain.\n\nenabled (Optional)\nbody\nstring\n\nIf set to true, domain is created enabled. If set to\r\nfalse, domain is created disabled. The default is true.\nUsers can only authorize against an enabled domain (and any of its\r\nprojects). In addition, users can only authenticate if the domain that owns\r\nthem is also enabled. Disabling a domain prevents both of these things. When you disable a domain, all tokens that are authorized for that domain\r\nbecome invalid. However, if you re-enable the domain, these tokens become\r\nvalid again, providing that they haven\u00e2\u0080\u0099t expired.\n\nname (Optional)\nbody\nstring\nThe new name of the domain.\n\noptions (Optional)\nbody\nobject\nThe resource options for the domain. Available resource options are\r\nimmutable.\n\nExample# curl -ks -X PATCH -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"domain\": {\r\n    \"description\": \"New domain description\",\r\n    \"name\": \"domain1_renamed\"\r\n  }\r\n}' https://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ndomain\n\nbody\nobject\nA domain object.\n\ndescription\n\nbody\nstring\nThe description of the domain.\n\nenabled\n\nbody\nstring\nIf set to true, domain is enabled. If set to\r\nfalse, domain is disabled.\n\nid\n\nbody\nstring\nThe ID of the domain.\n\nlinks\n\nbody\nobject\nThe links to the domain resource.\n\nname\n\nbody\nstring\nThe name of the domain.\n\noptions\n\nbody\nobject\nThe resource options for the role. Available resource options are\r\nimmutable.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n405 - Method Not Allowed\n\nMethod is not valid for this endpoint.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n415 - Unsupported Media Type\n\nThe request entity has a media type which the server or resource does not support.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"domain\": {\r\n    \"description\": \"New domain description\",\r\n    \"links\": {\r\n      \"self\": \"https://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\"\r\n    },\r\n    \"tags\": [],\r\n    \"enabled\": true,\r\n    \"id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"name\": \"domain1_renamed\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-domains.html"
    },
    {
        "title": "Managing S3 user quotas",
        "content": "Managing S3 user quotas\nYou can define quotas for S3 users to limit object storage usage per user. You can apply quotas to a particular S3 user or all S3 users within a domain. It is also possible to set the default quotas that will be applied to all S3 users in the cluster. By default, all S3 user quotas are set to zero, which means \"unlimited\".\nTo set quotas for a particular S3 user\nUse the following command:vinfra service s3 self-service user quotas add [--domain <domain>] [--user <user>] --quotas <quotas>\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--quotas <quotas>\n\nQuota size, in GB\n\nFor example, to set the quota size to 100 GB for the S3 user user1 in the domain domain1, run:# vinfra service s3 self-service user quotas add --domain domain1 --user user1 --quotas 100\nYou can check the applied S3 quotas in the vinfra service s3 self-service user quotas get output:# vinfra service s3 self-service user quotas get --domain domain1 --user user1\r\n+---------------+------------------+\r\n| Field         | Value            |\r\n+---------------+------------------+\r\n| resource_name | fef81edf9cbf754b |\r\n| resource_type | user             |\r\n| size          | 100              |\r\n| units         | GB               |\r\n+---------------+------------------+\nTo remove quotas for a particular S3 user\nUse the following command:vinfra service s3 self-service user quotas remove [--domain <domain>] [--user <user>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n\nFor example, to remove quotas for the S3 user user1 in the domain domain1, run:# vinfra service s3 self-service user quotas remove --domain domain1 --user user1\nTo set quotas for S3 users within a domain\nUse the following command:vinfra service s3 self-service domain quotas add [--domain <domain>] --quotas <quotas>\n\n--domain <domain>\n\nDomain name or ID\n--quotas <quotas>\n\nQuota size, in GB\n\nFor example, to set the quota size to 100 GB for all S3 users in the domain domain1, run:# vinfra service s3 self-service domain quotas add --domain domain1 --quotas 100\nYou can check the applied S3 quotas in the vinfra service s3 self-service domain quotas get output:# vinfra service s3 self-service domain quotas get --domain domain1\r\n+---------------+----------------------------------+\r\n| Field         | Value                            |\r\n+---------------+----------------------------------+\r\n| resource_name | dff4158faaa848ac92b7284fc011b72f |\r\n| resource_type | organization                     |\r\n| size          | 100                              |\r\n| units         | GB                               |\r\n+---------------+----------------------------------+\nTo remove quotas for S3 users within a domain\nUse the following command:vinfra service s3 self-service domain quotas remove [--domain <domain>]\n\n--domain <domain>\n\nDomain name or ID\n\nFor example, to remove quotas for all S3 users in the domain domain1, run:# vinfra service s3 self-service domain quotas remove --domain domain1\nTo set the default S3 user quotas\nUse the following command:vinfra service s3 users default-quotas add --quota-size <quota_size>\n\n--quota-size <quota_size>\n\nQuota size, in GB\n\nFor example, to set the default quota size to 100 GB for all S3 users in the cluster, run:# vinfra service s3 users default-quotas add --quota-size 100\nYou can check the default quotas in the vinfra service s3 users default-quotas get output:# vinfra service s3 users default-quotas get\r\n+---------------+-------+\r\n| Field         | Value |\r\n+---------------+-------+\r\n| resource_type | user  |\r\n| size          | 100   |\r\n| units         | GB    |\r\n+---------------+-------+\nTo remove the default S3 user quotas\nUse the following command:vinfra service s3 users default-quotas remove\nFor example, to remove the default quota size for all S3 users in the cluster, run:# vinfra service s3 users default-quotas remove\nSee also\n\nManaging S3 access keys\n\nManaging S3 user limits",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-s3-user-quotas.html"
    },
    {
        "title": "Creating virtual machines with virtual GPUs",
        "content": "Creating virtual machines with virtual GPUs\nIf you use only one vGPU type in the compute cluster, you need to create a flavor that requests one virtual GPU, and then create virtual machines with this flavor.\nLimitations\n\nVirtual machines with attached vGPUs cannot be suspended and live migrated.\n\nThe default QLX driver for the VNC console and the NVIDIA GPU driver are incompatible\n\nAfter installing the NVIDIA GPU driver inside a virtual machine with an attached vGPU, the VNC console stops working. You can use RDP for a remote connection. Alternatively, for templates that already have the NVIDIA GPU driver installed, you can set the hw_use_vgpu_display property, to disable the integrated QLX driver. For example:# openstack --insecure image set --property hw_use_vgpu_display 007db63f-9b41-4918-b572-2c5eef4c8f4b\n\nPrerequisites\n\nThe compute cluster is reconfigured for vGPU support, as described in Enabling PCI passthrough and vGPU support.\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo create a virtual machine with a vGPU\n\nCreate a flavor with the resources property specifying the number of vGPUs to use. For example, to create the vgpu-flavor flavor with 2 vCPUs and 4 GiB of RAM, run:# openstack --insecure flavor create --ram 4096 --vcpus 2 --property resources:VGPU=1 --public vgpu-flavor\n\nSome drivers may require to hide the hypervisor signature. To do this, add the hide_hypervisor_id property to the flavor:# openstack --insecure flavor set vgpu-flavor --property hide_hypervisor_id=true\n\nCreate a virtual machine specifying the vgpu-flavor flavor. For example, to create the vgpu-vm from the vol2 volume, run:# openstack --insecure server create --volume vol2 --flavor vgpu-flavor vgpu-vm\n\nThe created virtual machine will have a virtual GPU of the type that is configured in the compute cluster.\nSee also\n\nCreating virtual machines with different vGPU types\n\nCreating virtual machines with physical GPUs\n\nCreating virtual machines with SR-IOV network ports\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtual-machines-with-virtual-gpus.html"
    },
    {
        "title": "Provisioning billing metering",
        "content": "Provisioning billing metering\nThe billing metering service collects, stores, and provides usage metrics for resources consumed by end users in their projects. This compute service opens port 8041 and enables two Gnocchi services: gnocchi-api, an HTTP server, and gnocchi-metricd, a metric daemon.\nLimitations\n\nThe metering service will only take into account compute objects created after it has been enabled.\n\nIn the current version of Virtuozzo Hybrid Infrastructure, the installed service cannot be removed.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\n\nTo install the billing metering service\n\nAdmin panel\n\nGo to the Settings > Add-on services screen.\nIn the Billing metering service section, click Install.\n\nCommand-line interface\nRun the following command:# vinfra service compute set --enable-metering\r\n\n\nWhat's next\n\nUsing metering for compute resources",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nRun the following command:# vinfra service compute set --enable-metering\r\n\n",
                "title": "To install the billing metering service"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Settings > Add-on services screen.\nIn the Billing metering service section, click Install.\n\n",
                "title": "To install the billing metering service"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-billing-metering.html"
    },
    {
        "title": "Monitoring the compute cluster",
        "content": "Monitoring the compute cluster\nAfter you create the compute cluster, you can monitor its status and statistics. Additionally, you can monitor separate compute nodes, virtual machines, and load balancers.\nTo view the compute cluster status\nClick the cluster name at the bottom of the left menu. It can be one of the following:\n\nHealthy\n\nAll compute cluster components and nodes operate normally.\nConfiguring\n\nThe compute cluster configuration (the default CPU model for VMs or the number of compute nodes) is changing.\nWarning\n\nThe compute cluster operates normally but some issues have been detected.\nCritical\n\nThe compute cluster has encountered a critical problem and is not operational.\n\nTo view the compute cluster statistics\n\nAdmin panel\nGo to the Compute > Overview screen, which has the following charts:\n\nThe Reserved vCPUs chart displays vCPU reservations in the compute cluster. A vCPU reservation is a guarantee on vCPUs for a service or virtual machine.\n\nThe following statistics are available:\n\nTotal\n\nThe total number of virtual CPUs in the compute cluster. It is a product of the total number of physical CPUs on all compute nodes and the cluster overcommitment ratio.\nSystem\n\nThe number of virtual CPUs reserved for the system and storage services on all nodes in the compute cluster. To learn more about CPU reservations for different services, refer to Server requirements.\nVMs\n\nThe number of virtual CPUs provisioned for all virtual machines in the compute cluster.\nFree\n\nThe number of free virtual CPUs on all nodes in the compute cluster.\nFenced\n\nThe number of virtual CPUs on all fenced nodes in the compute cluster.\nDefault cluster overcommitment ratio\n\nThe ratio of the number of virtual CPUs to physical.\nThe parameter is set in /etc/kolla/nova-compute/nova.conf. You can change it by using the command vinfra service compute set --nova-compute-cpu-allocation-ratio <value> (refer to Changing virtual CPU overcommitment).\n\nA similar chart is available for each individual node in the compute cluster.\n\nThe Reserved RAM chart displays RAM reservations in the compute cluster. A RAM reservation is a guarantee on RAM for a service or virtual machine.\n\nThe following statistics are available:\n\nTotal\n\nThe total amount of RAM on all nodes in the compute cluster. It is a product of the total amount of physical RAM on all compute nodes and the overcommitment ratio.\nSystem\n\nThe amount of RAM reserved for the system and storage services on all nodes in the compute cluster. To learn more about RAM reservations for different services, refer to Server requirements.\nYou can view RAM reservation details for all of the cluster nodes in the vinfra node ram-reservation list output.\n\nVMs\n\nThe amount of RAM provisioned for all virtual machines in the compute cluster.\nFree\n\nThe amount of free RAM on all nodes in the compute cluster.\nFenced\n\nThe amount of RAM on all fenced nodes in the compute cluster.\nDefault cluster overcommitment ratio\n\nThe ratio of the amount of maximum reserved RAM to physical.\nThe parameter is set in /etc/kolla/nova-compute/nova.conf. You can change it by using the command vinfra service compute set --nova-compute-ram-allocation-ratio <value> (refer to Configuring memory for virtual machines).\n\nA similar chart is available for each individual node in the compute cluster.\n\nThe Provisioned storage chart shows usage of storage space by the compute cluster.\n\nThe following statistics are available:\n\nTotal\n\nThe total size of volumes provisioned in the compute cluster.\nUsed\n\nThe amount of storage space actually occupied by data in all volumes provisioned in the compute cluster.\nFree\n\nThe amount of unused space in all volumes provisioned in the compute cluster.\n\nThe VMs status chart shows the total number of virtual machines in the compute cluster and groups them by status.\n\nThe VM\u00a0status can be the following:\n\nRunning\n\nThe number of virtual machines that are up and running.\nIn progress\n\nThe number of virtual machines that are in a transitional state: building, restarting, migrating, etc.\nStopped\n\nThe number of virtual machines that are suspended or powered off.\nError\n\nThe number of virtual machines that have failed. You can reset the state for such VMs to their last stable state.\n\nTo see a full list of virtual machines filtered by the chosen status, click the number next to the status icon.\n\nThe Top VMs chart lists the virtual machines with the highest resource consumption sorted by vCPU, RAM, or Storage in descending order.\n\nTo switch between lists, click the desired resource. To see a full list of virtual machines in the compute cluster, click Show all.\n\nThe Alerts chart lists all of the alerts related to the compute cluster sorted by severity.\n\nAlerts include the following:\n\nCritical\n\nThe compute cluster has encountered a critical problem and is unmanageable. For example, an API service on all of the management nodes has failed or one of the compute agents is down. In this case, contact the technical support team.\nWarning\n\nThe compute cluster is experiencing resource shortage or may become unmanageable. For example, an API service on one of the management nodes has failed or some resource has exceeded 95% of its allocation limit.\nInfo\n\nThe compute cluster is experiencing issues that may lead to resource shortage. For example, some resource has exceeded 80% of its allocation limit.\n\nTo see a full list of alerts, click Show all.\n\nCommand-line interface\nUse the following command:# vinfra service compute stat\r\n+----------+----------------------------------------------+\r\n| Field    | Value                                        |\r\n+----------+----------------------------------------------+\r\n| compute  | block_capacity: 172874997760                 |\r\n|          | block_usage: 22953803776                     |\r\n|          | cpu_allocation_ratio: 8                      |\r\n|          | cpu_usage: 13.3                              |\r\n|          | ram_allocation_ratio: 1.0                    |\r\n|          | vcpus: 7                                     |\r\n|          | vcpus_free: 33                               |\r\n|          | vm_mem_capacity: 35526971392                 |\r\n|          | vm_mem_free: 22105198592                     |\r\n|          | vm_mem_reserved: 13421772800                 |\r\n|          | vm_mem_usage: 10906963968                    |\r\n| datetime | 2022-10-05T13:21:12.447758                   |\r\n| fenced   | physical_cpu_cores: 0                        |\r\n|          | physical_cpu_usage: 0                        |\r\n|          | physical_mem_total: 0                        |\r\n|          | reserved_memory: 0                           |\r\n|          | vcpus: 0                                     |\r\n|          | vm_mem_capacity: 0                           |\r\n| physical | block_capacity: 810773667840                 |\r\n|          | block_free: 713247113216                     |\r\n|          | cpu_cores: 12                                |\r\n|          | cpu_usage: 25.8                              |\r\n|          | mem_total: 75331031040                       |\r\n|          | vcpus_total: 96                              |\r\n| reserved | cpus: 7                                      |\r\n|          | memory: 39804059648                          |\r\n|          | vcpus: 56                                    |\r\n| servers  | count: 5                                     |\r\n|          | error: 0                                     |\r\n|          | in_progress: 0                               |\r\n|          | running: 4                                   |\r\n|          | stopped: 1                                   |\r\n|          | top:                                         |\r\n|          |   disk:                                      |\r\n|          |   - id: f3f522ac-05f7-4849-827d-d787a77edd56 |\r\n|          |     name: k8s2-kvgcdwapwxbh-node-0           |\r\n|          |     size: 6345576448                         |\r\n|          |   - id: f53a6885-7740-4bf7-9765-4c2200b38c2f |\r\n|          |     name: k8s3-dgl3edvjcbf3-node-0           |\r\n|          |     size: 6133764096                         |\r\n|          |   - id: 9a182bc6-54b7-47d9-9553-fcdf712d5a22 |\r\n|          |     name: k8s2-kvgcdwapwxbh-master-0         |\r\n|          |     size: 5385080832                         |\r\n|          |   - id: 38de311b-f46b-4abe-a55b-2c04f677182e |\r\n|          |     name: k8s3-dgl3edvjcbf3-master-0         |\r\n|          |     size: 4925804544                         |\r\n|          |   - id: b5d6bb82-6137-4748-b94a-c1056d4cd8c9 |\r\n|          |     name: vm1                                |\r\n|          |     size: 163577856                          |\r\n|          |   memory:                                    |\r\n|          |   - id: 38de311b-f46b-4abe-a55b-2c04f677182e |\r\n|          |     name: k8s3-dgl3edvjcbf3-master-0         |\r\n|          |     size: 3264253952                         |\r\n|          |   - id: 9a182bc6-54b7-47d9-9553-fcdf712d5a22 |\r\n|          |     name: k8s2-kvgcdwapwxbh-master-0         |\r\n|          |     size: 3132764160                         |\r\n|          |   - id: f53a6885-7740-4bf7-9765-4c2200b38c2f |\r\n|          |     name: k8s3-dgl3edvjcbf3-node-0           |\r\n|          |     size: 2259763200                         |\r\n|          |   - id: f3f522ac-05f7-4849-827d-d787a77edd56 |\r\n|          |     name: k8s2-kvgcdwapwxbh-node-0           |\r\n|          |     size: 2250182656                         |\r\n|          |   - id: b5d6bb82-6137-4748-b94a-c1056d4cd8c9 |\r\n|          |     name: vm1                                |\r\n|          |     size: 0                                  |\r\n|          |   vcpus:                                     |\r\n|          |   - count: 0.55                              |\r\n|          |     id: 38de311b-f46b-4abe-a55b-2c04f677182e |\r\n|          |     name: k8s3-dgl3edvjcbf3-master-0         |\r\n|          |   - count: 0.51                              |\r\n|          |     id: 9a182bc6-54b7-47d9-9553-fcdf712d5a22 |\r\n|          |     name: k8s2-kvgcdwapwxbh-master-0         |\r\n|          |   - count: 0.29                              |\r\n|          |     id: f53a6885-7740-4bf7-9765-4c2200b38c2f |\r\n|          |     name: k8s3-dgl3edvjcbf3-node-0           |\r\n|          |   - count: 0.24                              |\r\n|          |     id: f3f522ac-05f7-4849-827d-d787a77edd56 |\r\n|          |     name: k8s2-kvgcdwapwxbh-node-0           |\r\n|          |   - count: 0                                 |\r\n|          |     id: b5d6bb82-6137-4748-b94a-c1056d4cd8c9 |\r\n|          |     name: vm1                                |\r\n+----------+----------------------------------------------+\n\nTo view more details about the compute cluster\nGo to the Monitoring > Dashboard screen, and then click Grafana dashboard. A separate browser tab will open with preconfigured Grafana dashboards.\nThe Compute service status dashboard shows the status of the compute services and agents on all of the compute nodes. You can sort the displayed services per hostname, service name, and service status.\n\nFor the detailed monitoring of the compute resource allocation, use the Compute resource allocation dashboard. The charts on this dashboard show the usage of vCPUs, memory, storage space per storage policy, and floating IP addresses.  You can view usage statistics for all domains and projects, or filter the data per specific domain or project.\n\nTo monitor the compute API requests, use the Compute service API details dashboard. The charts on this dashboard show the rate of successful and failed requests, as well as the 95th and 99th percentiles of response time, per 10-minute intervals. You can filter the displayed requests per compute service. The most important charts here are those of error request rate and response time. If you see spikes on them, you need to check the status of the corresponding services.\n\nThe RabbitMQ nodes, RabbitMQ messages, and RabbitMQ clients dashboards are intended for troubleshooting the RabbitMQ cluster by the support team. The PostgreSQL overview dashboard shows information about the PostgreSQL database size and replication status, as well as other database details. To see a detailed description for each chart, click the i icon in its left corner.\n\nSee also\n\nManaging the compute cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:# vinfra service compute stat\r\n+----------+----------------------------------------------+\r\n| Field    | Value                                        |\r\n+----------+----------------------------------------------+\r\n| compute  | block_capacity: 172874997760                 |\r\n|          | block_usage: 22953803776                     |\r\n|          | cpu_allocation_ratio: 8                      |\r\n|          | cpu_usage: 13.3                              |\r\n|          | ram_allocation_ratio: 1.0                    |\r\n|          | vcpus: 7                                     |\r\n|          | vcpus_free: 33                               |\r\n|          | vm_mem_capacity: 35526971392                 |\r\n|          | vm_mem_free: 22105198592                     |\r\n|          | vm_mem_reserved: 13421772800                 |\r\n|          | vm_mem_usage: 10906963968                    |\r\n| datetime | 2022-10-05T13:21:12.447758                   |\r\n| fenced   | physical_cpu_cores: 0                        |\r\n|          | physical_cpu_usage: 0                        |\r\n|          | physical_mem_total: 0                        |\r\n|          | reserved_memory: 0                           |\r\n|          | vcpus: 0                                     |\r\n|          | vm_mem_capacity: 0                           |\r\n| physical | block_capacity: 810773667840                 |\r\n|          | block_free: 713247113216                     |\r\n|          | cpu_cores: 12                                |\r\n|          | cpu_usage: 25.8                              |\r\n|          | mem_total: 75331031040                       |\r\n|          | vcpus_total: 96                              |\r\n| reserved | cpus: 7                                      |\r\n|          | memory: 39804059648                          |\r\n|          | vcpus: 56                                    |\r\n| servers  | count: 5                                     |\r\n|          | error: 0                                     |\r\n|          | in_progress: 0                               |\r\n|          | running: 4                                   |\r\n|          | stopped: 1                                   |\r\n|          | top:                                         |\r\n|          |   disk:                                      |\r\n|          |   - id: f3f522ac-05f7-4849-827d-d787a77edd56 |\r\n|          |     name: k8s2-kvgcdwapwxbh-node-0           |\r\n|          |     size: 6345576448                         |\r\n|          |   - id: f53a6885-7740-4bf7-9765-4c2200b38c2f |\r\n|          |     name: k8s3-dgl3edvjcbf3-node-0           |\r\n|          |     size: 6133764096                         |\r\n|          |   - id: 9a182bc6-54b7-47d9-9553-fcdf712d5a22 |\r\n|          |     name: k8s2-kvgcdwapwxbh-master-0         |\r\n|          |     size: 5385080832                         |\r\n|          |   - id: 38de311b-f46b-4abe-a55b-2c04f677182e |\r\n|          |     name: k8s3-dgl3edvjcbf3-master-0         |\r\n|          |     size: 4925804544                         |\r\n|          |   - id: b5d6bb82-6137-4748-b94a-c1056d4cd8c9 |\r\n|          |     name: vm1                                |\r\n|          |     size: 163577856                          |\r\n|          |   memory:                                    |\r\n|          |   - id: 38de311b-f46b-4abe-a55b-2c04f677182e |\r\n|          |     name: k8s3-dgl3edvjcbf3-master-0         |\r\n|          |     size: 3264253952                         |\r\n|          |   - id: 9a182bc6-54b7-47d9-9553-fcdf712d5a22 |\r\n|          |     name: k8s2-kvgcdwapwxbh-master-0         |\r\n|          |     size: 3132764160                         |\r\n|          |   - id: f53a6885-7740-4bf7-9765-4c2200b38c2f |\r\n|          |     name: k8s3-dgl3edvjcbf3-node-0           |\r\n|          |     size: 2259763200                         |\r\n|          |   - id: f3f522ac-05f7-4849-827d-d787a77edd56 |\r\n|          |     name: k8s2-kvgcdwapwxbh-node-0           |\r\n|          |     size: 2250182656                         |\r\n|          |   - id: b5d6bb82-6137-4748-b94a-c1056d4cd8c9 |\r\n|          |     name: vm1                                |\r\n|          |     size: 0                                  |\r\n|          |   vcpus:                                     |\r\n|          |   - count: 0.55                              |\r\n|          |     id: 38de311b-f46b-4abe-a55b-2c04f677182e |\r\n|          |     name: k8s3-dgl3edvjcbf3-master-0         |\r\n|          |   - count: 0.51                              |\r\n|          |     id: 9a182bc6-54b7-47d9-9553-fcdf712d5a22 |\r\n|          |     name: k8s2-kvgcdwapwxbh-master-0         |\r\n|          |   - count: 0.29                              |\r\n|          |     id: f53a6885-7740-4bf7-9765-4c2200b38c2f |\r\n|          |     name: k8s3-dgl3edvjcbf3-node-0           |\r\n|          |   - count: 0.24                              |\r\n|          |     id: f3f522ac-05f7-4849-827d-d787a77edd56 |\r\n|          |     name: k8s2-kvgcdwapwxbh-node-0           |\r\n|          |   - count: 0                                 |\r\n|          |     id: b5d6bb82-6137-4748-b94a-c1056d4cd8c9 |\r\n|          |     name: vm1                                |\r\n+----------+----------------------------------------------+\n",
                "title": "To view the compute cluster statistics"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nGo to the Compute > Overview screen, which has the following charts:\n\n\nThe Reserved vCPUs chart displays vCPU reservations in the compute cluster. A vCPU reservation is a guarantee on vCPUs for a service or virtual machine.\n\nThe following statistics are available:\n\nTotal\n\nThe total number of virtual CPUs in the compute cluster. It is a product of the total number of physical CPUs on all compute nodes and the cluster overcommitment ratio.\nSystem\n\nThe number of virtual CPUs reserved for the system and storage services on all nodes in the compute cluster. To learn more about CPU reservations for different services, refer to Server requirements.\nVMs\n\nThe number of virtual CPUs provisioned for all virtual machines in the compute cluster.\nFree\n\nThe number of free virtual CPUs on all nodes in the compute cluster.\nFenced\n\nThe number of virtual CPUs on all fenced nodes in the compute cluster.\nDefault cluster overcommitment ratio\n\n\nThe ratio of the number of virtual CPUs to physical.\nThe parameter is set in /etc/kolla/nova-compute/nova.conf. You can change it by using the command vinfra service compute set --nova-compute-cpu-allocation-ratio <value> (refer to Changing virtual CPU overcommitment).\n\n\n\n\n\n\nA similar chart is available for each individual node in the compute cluster.\n\n\n\n\nThe Reserved RAM chart displays RAM reservations in the compute cluster. A RAM reservation is a guarantee on RAM for a service or virtual machine.\n\nThe following statistics are available:\n\nTotal\n\nThe total amount of RAM on all nodes in the compute cluster. It is a product of the total amount of physical RAM on all compute nodes and the overcommitment ratio.\nSystem\n\n\nThe amount of RAM reserved for the system and storage services on all nodes in the compute cluster. To learn more about RAM reservations for different services, refer to Server requirements.\nYou can view RAM reservation details for all of the cluster nodes in the vinfra node ram-reservation list output.\n\nVMs\n\nThe amount of RAM provisioned for all virtual machines in the compute cluster.\nFree\n\nThe amount of free RAM on all nodes in the compute cluster.\nFenced\n\nThe amount of RAM on all fenced nodes in the compute cluster.\nDefault cluster overcommitment ratio\n\n\nThe ratio of the amount of maximum reserved RAM to physical.\nThe parameter is set in /etc/kolla/nova-compute/nova.conf. You can change it by using the command vinfra service compute set --nova-compute-ram-allocation-ratio <value> (refer to Configuring memory for virtual machines).\n\n\n\n\n\n\nA similar chart is available for each individual node in the compute cluster.\n\n\n\n\nThe Provisioned storage chart shows usage of storage space by the compute cluster.\n\nThe following statistics are available:\n\nTotal\n\nThe total size of volumes provisioned in the compute cluster.\nUsed\n\nThe amount of storage space actually occupied by data in all volumes provisioned in the compute cluster.\nFree\n\nThe amount of unused space in all volumes provisioned in the compute cluster.\n\n\n\n\n\n\n\n\n\nThe VMs status chart shows the total number of virtual machines in the compute cluster and groups them by status.\n\nThe VM\u00a0status can be the following:\n\nRunning\n\nThe number of virtual machines that are up and running.\nIn progress\n\nThe number of virtual machines that are in a transitional state: building, restarting, migrating, etc.\nStopped\n\nThe number of virtual machines that are suspended or powered off.\nError\n\nThe number of virtual machines that have failed. You can reset the state for such VMs to their last stable state.\n\n\n\n\n\nTo see a full list of virtual machines filtered by the chosen status, click the number next to the status icon.\n\n\n\n\nThe Top VMs chart lists the virtual machines with the highest resource consumption sorted by vCPU, RAM, or Storage in descending order.\n\nTo switch between lists, click the desired resource. To see a full list of virtual machines in the compute cluster, click Show all.\n\n\n\n\n\n\n\n\nThe Alerts chart lists all of the alerts related to the compute cluster sorted by severity.\n\nAlerts include the following:\n\nCritical\n\nThe compute cluster has encountered a critical problem and is unmanageable. For example, an API service on all of the management nodes has failed or one of the compute agents is down. In this case, contact the technical support team.\nWarning\n\nThe compute cluster is experiencing resource shortage or may become unmanageable. For example, an API service on one of the management nodes has failed or some resource has exceeded 95% of its allocation limit.\nInfo\n\nThe compute cluster is experiencing issues that may lead to resource shortage. For example, some resource has exceeded 80% of its allocation limit.\n\nTo see a full list of alerts, click Show all.\n\n\n\n\n",
                "title": "To view the compute cluster statistics"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-the-compute-cluster.html"
    },
    {
        "title": "4.2. Connecting HostBill to BitNinja\u00c2\u00b6",
        "content": "4.2. Connecting HostBill to BitNinja | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n4.2. Connecting HostBill to BitNinja\u00c2\u00b6\nIn order to add the new service, you will need your reseller API key and your reseller e-mail address. You can obtain your API key from your reseller panel by clicking generate API key.\n\nGo to Settings > Apps > Add new App then from applications list select BitNinja. You will need to provide the following information:\n\nName - name of this connection.\nUsername - reseller email address from the BitNinja reseller panel.\nAPI KEY - API Key generated from the BitNinja reseller panel.\n\nVerify the connection by clicking Test Configuration.\nSave the changes.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/hostbill-bitninja/connecting-hostbill.html"
    },
    {
        "title": "Hystax Acura Migration from VMware\u00c2\u00b6",
        "content": "Hystax Acura Migration from VMware | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nNext\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nNext\n\nHystax Acura Migration from VMware\u00c2\u00b6\n\n1. Hystax Acura Overview\n2. Migration Steps\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/index.html"
    },
    {
        "title": "Services chart",
        "content": "Services chart\n\nAdmin panel\nOn the Services chart, you can monitor two types of services:\n\nMetadata services (MDS). The number of all disks with the metadata role. Ensure that at least three MDSes are running at all times.\nChunk services (CS). The number of all disks with the storage role.\n\nTypical statistics may look like this:\n\nThe green color on the chart indicates active services. If some time periods are highlighted in a different color, you can hover over them to check the services status. To see a list of service statuses, refer to Monitoring node disks.\n\nCommand-line interface\nUse the following command:vinfra cluster overview\nFor example, to view the information about the storage services in the cluster cluster1, take a look at these lines from the command output:\r\n+-------------------+-------------------------+\r\n| Field             | Value                   |\r\n+-------------------+-------------------------+\r\n| ...               | ...                     |\r\n| cs                | failed: 0               |\r\n|                   | slow: 0                 |\r\n|                   | total: 5                |\r\n| ...               | ...                     |\r\n| mds               | failed: 0               |\r\n|                   | total: 3                |\r\n+-------------------+-------------------------+\r\n\n\nSee also\n\nI/O activity charts\n\nChunks chart\n\nPhysical space chart\n\nLogical space chart",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/services-chart.html"
    },
    {
        "title": "Managing VPN connections",
        "content": "Managing VPN connections\nWith Virtual Private Network (VPN) as a service, self-service users can extend virtual networks across public networks, such as the Internet. To connect two or more remote endpoints, VPNs use virtual connections tunneled through physical networks. To secure VPN communication, the traffic that flows between remote endpoints is encrypted. The VPN implementation uses the Internet Key Exchange (IKE) and IP Security (IPsec) protocols to establish secure VPN connections and is based on the strongSwan IPsec solution.\nVPN as a service can be used to establish a Site-to-Site VPN connection between a virtual network configured in Virtuozzo Hybrid Infrastructure and any other network with a VPN gateway that uses the IPsec and IKE protocols. With VPN as a service, you can connect the following workloads:\n\nOn-premises workloads with workloads hosted in Virtuozzo Hybrid Infrastructure\nWorkloads hosted in other clouds with workloads hosted in Virtuozzo Hybrid Infrastructure\nWorkloads hosted in different Virtuozzo Hybrid Infrastructure clusters\n\nTo better understand how a VPN works, consider the following example:\n\nIn the cluster 1, the virtual machine VM1 is connected to the virtual network privnet1 (192.168.10.0/24) via the network interface with IP address 192.168.10.10. The network privnet1 is exposed to public networks via the router router1 with the external port 10.10.10.5.\nIn the cluster 2, the virtual machine VM2 is connected to the virtual network privnet2 (192.168.20.0/24) via the network interface with IP address 192.168.20.20. The network privnet2 is exposed to public networks via the router router2 with the external port 10.10.10.4.\nThe VPN tunnel is created between the routers router1 and router2 that serve as VPN gateways, thus allowing mutual connectivity between the networks privnet1 and privnet2.\nThe virtual machines VM1 and VM2 are visible to each other at their private IP addresses. That is, VM1 can access VM2 at 192.168.20.20, and VM2 can access VM1 at 192.168.10.10.\n\nFor key exchange between communicating parties, two IKE versions are available: IKE version 1 (IKEv1) and IKE version 2 (IKEv2). IKEv2 is the latest version of the IKE protocol and it supports connecting multiple remote subnets.\n\nIn the example above:\n\nVPN1 uses the IKEv1 and connects the network network1 with the network3.\nVPN2 uses the IKEv2 and connects the network network2 with the two networks network4 and network5.\n\nLimitations\n\nCurrently, we support only Site-to-Site VPN connections. Point-to-Site VPN connections are not supported.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-vpn-connections.html"
    },
    {
        "title": "Setting operations per second for users via CLI",
        "content": "Setting operations per second for users via CLI\nYou can limit operations rate with the set-limits command and the following parameters: -e specifying the email address, -t ops specifying the limit type, and -L default=, get=, put=, list=, or delete= specifying the limit key:# ostor-s3-admin set-limits -e client@example.com -t ops -L get=3600\r\nops:default=0.00ops/s\r\nops:get=3600.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=0kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-operations-per-second-for-users-via-cli.html"
    },
    {
        "title": "Listing snapshots",
        "content": "Listing snapshotsGET /v3/{project_id}/snapshots\r\n\nLists all volume snapshots, with summary information that the project can access.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=list-accessible-snapshots-detail#list-accessible-snapshots\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nall_tenants (Optional)\nquery\nstring\nShows details for all projects. Admin only.\n\nsort (Optional)\nquery\nstring\nComma-separated list of sort keys and optional\r\nsort directions in the form of <key>[:<direction>]. A valid\r\ndirection is asc (ascending) or desc (descending).\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number\r\nof items up to a limit value. Use the limit parameter to make\r\nan initial limited request and use the ID of the last-seen item\r\nfrom the response as the marker parameter value in a\r\nsubsequent limited request.\n\noffset (Optional)\nquery\ninteger\nUsed in conjunction with limit to return a slice of items. offset\r\nis where to start in the list.\n\nmarker (Optional)\nquery\nstring\nThe ID of the last-seen item. Use the limit\r\nparameter to make an initial limited request and use the ID of the\r\nlast-seen item from the response as the marker parameter value\r\nin a subsequent limited request.\n\nwith_count (Optional)\nquery\nboolean\n\nWhether to show count in API response or not, default is False.\nNew in version 3.45\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/snapshots\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nuser_id\n\nbody\nstring\n\nThe UUID of the user.\nNew in version 3.41\n\nvolume_id\n\nbody\nstring\nIf the snapshot was created from a volume, the\r\nvolume ID.\n\nname\n\nbody\nstring\nThe name of the snapshot.\n\nstatus\n\nbody\nstring\nThe status for the snapshot.\n\ndescription\n\nbody\nstring\nA description for the snapshot.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nmetadata\n\nbody\nobject\nOne or more metadata key and value pairs for the\r\nsnapshot, if any.\n\nid\n\nbody\nstring\nThe snapshot UUID.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\ncount (Optional)\nbody\ninteger\n\nThe total count of requested resource before pagination is applied.\nNew in version 3.45\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nsnapshots_links (Optional)\nbody\narray\nLinks for the snapshot.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\nExample{\r\n  \"snapshots\": [\r\n    {\r\n      \"status\": \"available\",\r\n      \"size\": 2,\r\n      \"metadata\": {},\r\n      \"name\": \"Snapshot-vol1/2020-03-11 05:01:53\",\r\n      \"volume_id\": \"cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n      \"created_at\": \"2020-03-11T14:01:54.381048\",\r\n      \"description\": null,\r\n      \"id\": \"aebe052f-6c13-417a-8ea9-771f40d6667f\",\r\n      \"updated_at\": \"2020-03-11T14:01:56.522040\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-snapshots.html"
    },
    {
        "title": "Compute alerts",
        "content": "Compute alerts\nBased on the metrics described in Compute metrics, the compute alerts are generated and displayed in the admin panel.\nCompute service alerts\n\n Keystone API service is down\n\n<service_name> API service is down.\n\nCheck the status of the vstorage-ui-keystone-admin and vstorage-ui-keystone-publicservices on the management node by running:# systemctl status vstorage-ui-keystone-admin.service\r\n# systemctl status vstorage-ui-keystone-public.service\n\nCheck the service logs at /var/log/vstorage-ui-backend/uwsgi-keystone-admin.log and /var/log/vstorage-ui-backend/uwsgi-keystone-public.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack service API upstream is down\n\nOne or more OpenStack <service_name> API upstreams are down.\n\nEnsure that the  container of the affected compute service is up on the management node. For example, for the nova_api service, run:# docker ps --all | grep nova_api\n\nIf the container is down, start it. For example, for the nova_api service, run:# docker start nova_api\n\nCheck the service log (refer to Viewing cluster logs).\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n All OpenStack service API upstreams are down\n\nAll OpenStack <service_name> API upstreams are down.\n\nEnsure that the  container of the affected compute services are up on the management node. For example, for the nova_api service, run:# docker ps --all | grep nova_api\n\nIf the containers are down, start them. For example, for the nova_api service, run:# docker start nova_api\n\nCheck the service logs (refer to Viewing cluster logs).\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Cinder Scheduler is down\n\nOpenStack Block Storage (Cinder) Scheduler agent is down on host <hostname>.\n\nEnsure that the cinder_scheduler container is up on the specified node by running:# docker ps --all | grep cinder_scheduler\n\nIf the container is down, start it by running:# docker start cinder_scheduler\n\nCheck the service log at /var/log/hci/cinder/cinder-scheduler.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Cinder Volume agent is down\n\nOpenStack Block Storage (Cinder) Volume agent is down on host <hostname>.\n\nEnsure that the cinder_volume container is up on the specified node by running:# docker ps --all | grep cinder_volume\n\nIf the container is down, start it by running:# docker start cinder_volume\n\nCheck the service log at /var/log/hci/cinder/cinder-volume.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Neutron L3 agent is down\n\nOpenStack Networking (Neutron) L3 agent is down on host <hostname>.\n\nEnsure that the neutron_l3_agent container is up on the specified node by running:# docker ps --all | grep neutron_l3_agent\n\nIf the container is down, start it by running:# docker start neutron_l3_agent\n\nCheck the service log at /var/log/hci/neutron/neutron-l3-agent.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Neutron Open vSwitch agent is down\n\nOpenStack Networking (Neutron) Open vSwitch agent is down on host <hostname>.\n\nEnsure that the neutron_openvswitch_agent container is up on the specified node by running:# docker ps --all | grep neutron_openvswitch_agent\n\nIf the container is down, start it by running:# docker start neutron_openvswitch_agent\n\nCheck the service log at /var/log/hci/neutron/neutron-openvswitch-agent.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Neutron Metadata agent is down\n\nOpenStack Networking (Neutron) Metadata agent is down on host <hostname>.\n\nEnsure that the neutron_metadata_agent container is up on the specified node by running:# docker ps --all | grep neutron_metadata_agent\n\nIf the container is down, start it by running:# docker start neutron_metadata_agent\n\nCheck the service log at /var/log/hci/neutron/neutron-metadata-agent.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Neutron DHCP agent is down\n\nOpenStack Networking (Neutron) DHCP agent is down on host <hostname>.\n\nEnsure that the neutron_dhcp_agent container is up on the specified node by running:# docker ps --all | grep neutron_dhcp_agent\n\nIf the container is down, start it by running:# docker start neutron_dhcp_agent\n\nCheck the service log at /var/log/hci/neutron/neutron-dhcp-agent.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Nova Compute is down\n\nOpenStack Compute (Nova) agent is down on host <hostname>.\n\nEnsure that the nova_compute container is up on the specified node by running:# docker ps --all | grep nova_compute\n\nIf the container is down, start it by running:# docker start nova_compute\n\nCheck the service log at /var/log/hci/nova/nova-compute.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Nova Conductor is down\n\nOpenStack Compute (Nova) Conductor agent is down on host <hostname>.\n\nEnsure that the nova_conductor container is up on the specified node by running:# docker ps --all | grep nova_conductor\n\nIf the container is down, start it by running:# docker start nova_conductor\n\nCheck the service log at /var/log/hci/nova/nova-conductor.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Nova Scheduler is down\n\nOpenStack Compute (Nova) Scheduler agent is down on host <hostname>.\n\nEnsure that the nova_scheduler container is up on the specified node by running:# docker ps --all | grep nova_scheduler\n\nIf the container is down, start it by running:# docker start nova_scheduler\n\nCheck the service log at /var/log/hci/nova/nova-scheduler.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Octavia Provisioning Worker v1 is down\n\nOpenStack Loadbalancing (Octavia) provisioning worker version 1 is down on host <hostname>.\n\nEnsure that the octavia_worker container is up on the management node by running:# docker ps --all | grep octavia_worker\n\nIf the container is down, start it by running:# docker start octavia_worker\n\nCheck the service log at /var/log/hci/octavia/octavia-worker.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Octavia Provisioning Worker v2 is down\n\nOpenStack Loadbalancing (Octavia) provisioning worker version 2 is down on host <hostname>.\n\nEnsure that the octavia_worker container is up on the management node by running:# docker ps --all | grep octavia_worker\n\nIf the container is down, start it by running:# docker start octavia_worker\n\nCheck the service log at /var/log/hci/octavia/octavia-worker.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Octavia Housekeeping service is down\n\nOpenStack Loadbalancing (Octavia) housekeeping service is down on host <hostname>.\n\nEnsure that the octavia_housekeeping container is up on the management node by running:# docker ps --all | grep octavia_housekeeping\n\nIf the container is down, start it by running:# docker start octavia_housekeeping\n\nCheck the service log at /var/log/hci/octavia/octavia-housekeeping.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n OpenStack Octavia HealthManager service is down\n\nOpenStack Loadbalancing (Octavia) health manager service is down on host <hostname>.\n\nEnsure that the octavia_health_manager container is up on the management node by running:# docker ps --all | grep octavia_health_manager\n\nIf the container is down, start it by running:# docker start octavia_health_manager\n\nCheck the service log at /var/log/hci/octavia/octavia-health-manager.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n High request error rate for OpenStack API requests detected\n\nRequest error rate more than 5% detected for <object_id> for the last 1 hour. Check <object_id> resource usage.\n\nCheck the status of the affected compute services.\nIf some services are down, bring them up.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\nCompute cluster alerts\n\n Compute cluster has failed\n\nCompute cluster has failed. Unable to manage virtual machines.\n\nGo to the Monitoring > Dashboard screen, and then click Grafana dashboard.\nOpen the Compute service status dashboard and find out the failed service.\nDepending on the service, follow the instructions from the Compute service alerts section.\n\n Cluster is running out of vCPU resources\n\nCluster has reached 80% of the vCPU allocation limit.\n\nThe compute cluster may soon experience the lack of vCPU resources that will lead to inability to accommodate new virtual machines. To avoid this, you can add more compute nodes or return to operation fenced nodes, if any.\n\n Cluster is out of vCPU resources\n\nCluster has reached 95% of the vCPU allocation limit.\n\nThe compute cluster will soon experience the lack of vCPU resources that will lead to inability to accommodate new virtual machines. To avoid this, you can add more compute nodes or return to operation fenced nodes, if any.\n\n Cluster is running out of memory\n\nCluster has reached 80% of the memory allocation limit.\n\nThe compute cluster may soon experience the lack of RAM resources that will lead to inability to accommodate new virtual machines. To avoid this, you can add more compute nodes or return to operation fenced nodes, if any.\n\n Cluster is out of memory\n\nCluster has reached 95% of the memory allocation limit.\n\nThe compute cluster will soon experience the lack of RAM resources that will lead to inability to accommodate new virtual machines. To avoid this, you can add more compute nodes or return to operation fenced nodes, if any.\n\n Virtual machine error\n\nVirtual machine <name> with ID <id> is in the 'Error' state.\n\nExamine the VM history in the History tab on the VM right pane and reset the VM state, as described in Troubleshooting virtual machines.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n Virtual machine state mismatch\n\nState of virtual machine <name> with ID <id> differs in the Nova databases and libvirt configuration.\n\nDo not try to migrate the VM or reset its state. Contact the technical support team.\n\n Volume attachment details mismatch\n\nAttachment details for volume with ID <id> differ in the Nova and libvirt databases.\n\nDo not try to migrate the VM or reset its state. Contact the technical support team.\n\n Virtual network port check failed\n\nNeutron port with ID <port_id> failed <check_type> check. The port type is <device_owner> with owner ID <device_id>.\n\nRun the openstack --insecure port check command specifying the port ID.\nCheck connectivity of the device owner.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n Backup plan failed\n\nBackup plan <plan_name> for compute volumes has three consecutive failures.\n\nCheck the service logs at /var/log/hci/freezer/freezer-scheduler.log and /var/log/hci/cinder/cinder-backup.log.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\nCompute node alerts\n\n Node is running out of vCPU resources\n\nNode <node> with ID <id> has reached 80% of the vCPU allocation limit.\n\nThe compute node may soon experience the lack of vCPU resources that will lead to inability to accommodate new virtual machines. To avoid this, check the distribution of VMs in the compute cluster, and then migrate the VMs from the specified node to less loaded compute nodes.\n\n Node is out of vCPU resources\n\nNode <node> with ID <id> has reached 95% of the vCPU allocation limit.\n\nThe compute node will soon experience the lack of vCPU resources that will lead to inability to accommodate new virtual machines. To avoid this, check the distribution of VMs in the compute cluster, and then migrate the VMs from the specified node to less loaded compute nodes.\n\n Node is running out of memory\n\nNode <node> with ID <id> has reached 80% of the memory allocation limit.\n\nThe compute node may soon experience the lack of RAM resources that will lead to inability to accommodate new virtual machines. To avoid this, check the distribution of VMs in the compute cluster, and then migrate the VMs from the specified node to less loaded compute nodes.\n\n Node is out of memory\n\nNode <node> with ID <id> has reached 95% of the memory allocation limit.\n\nThe compute node will soon experience the lack of RAM resources that will lead to inability to accommodate new virtual machines. To avoid this, check the distribution of VMs in the compute cluster, and then migrate the VMs from the specified node to less loaded compute nodes.\n\n Node had a fenced state for 1 hour\n\nFor the last 2 hours node <node> with ID <id> had a fenced state at least for 1 hour.\n\nDomain quota alerts\n\n Domain is out of vCPU resources\n\nDomain <name> has reached <value_80<95>% of the vCPU allocation limit.\n\nThe domain will soon experience the lack of vCPU resources that will lead to inability to create new virtual machines. To avoid this, add more vCPUs to the domain quota.\n\n Domain is out of vCPU resources\n\nDomain <name> has reached <value_>=95>% of the vCPU allocation limit.\n\nThe domain will soon experience the lack of vCPU resources that will lead to inability to create new virtual machines. To avoid this, add more vCPUs to the domain quota.\n\n Domain is out of memory\n\nDomain <name> has reached <value_80<95>% of the memory allocation limit.\n\nThe domain will soon experience the lack of RAM resources that will lead to inability to create new virtual machines. To avoid this, add more RAM to the domain quota.\n\n Domain is out of memory\n\nDomain <name> has reached <value_>=95>% of the memory allocation limit.\n\nThe domain will soon experience the lack of RAM resources that will lead to inability to create new virtual machines. To avoid this, add more RAM to the domain quota.\n\n Domain is out of storage policy space\n\nDomain <name> has reached <value_80<95>% of the <policy_name> storage policy allocation limit.\n\nThe domain will soon experience the lack of storage policy space that will lead to inability to create new compute volumes with this storage policy. To avoid this, add more storage space to the domain quota.\n\n Domain is out of storage policy space\n\nDomain <name> has reached <value_>=95>% of the <policy_name> storage policy allocation limit.\n\nThe domain will soon experience the lack of storage policy space that will lead to inability to create new compute volumes with this storage policy. To avoid this, add more storage space to the domain quota.\n\nProject quota alerts\n\n Project is out of vCPU resources\n\nProject <name> has reached 95% of the vCPU allocation limit.\n\nThe project will soon experience the lack of vCPU resources that will lead to inability to create new virtual machines. To avoid this, add more vCPUs to the project quota.\n\n Project is out of memory\n\nProject <name> has reached 95% of the memory allocation limit.\n\nThe project will soon experience the lack of RAM resources that will lead to inability to create new virtual machines. To avoid this, add more RAM to the project quota.\n\n Project is out of floating IP addresses\n\nProject <name> has reached 95% of the floating IP address allocation limit.\n\nThe project will soon experience the lack of floating IP addresses that will lead to inability to assign them to virtual machines. To avoid this, add more floating IPs to the project quota.\n\n Network is out of IP addresses\n\nNetwork <name> with ID <id> in project <name> has reached 95% of the IP address allocation limit.\n\nThe network will soon experience the lack of IP addresses that will lead to inability to connect new virtual machines to this network. To avoid this, add more allocation pools to the network.\n\n Project is out of storage policy space\n\nProject <name> has reached 95% of the <policy_name> storage policy allocation limit.\n\nThe project will soon experience the lack of storage policy space that will lead to inability to create new compute volumes with this storage policy. To avoid this, add more storage space to the project quota.\n\nOther alerts\n\n Libvirt service is down\n\nLibvirt service is down on node <node> with ID <id>. Check the service state and start it. If the service cannot start, contact the technical support.\n\nStart the libvirtd service on the specified node by running:# systemctl start libvirtd.service\n\n Docker service is down\n\nDocker service is down on host <hostname>.\n\nStart the Docker service on the specified node by running:# systemctl start docker.service\n\n RabbitMQ node is down\n\nOne or more nodes in the Rabbitmq cluster is down.\n\nContact the technical support team.\n\n RabbitMQ split brain detected\n\nRabbitMQ cluster has experienced a split brain due to a network partition.\n\nContact the technical support team.\n\n PostgreSQL database size is greater than 30 GB\n\nPostgreSQL database \"<name>\" on node \"<hostname>\" is greater than 30 GB in size. Verify that deleted entries are archived or contact the technical support.\n\n PostgreSQL database uses more than 50% of node root partition\n\nPostgreSQL databases on node \"<hostname>\" with ID \"<id>\" use more than 50% of node root partition. Verify that deleted entries are archived or contact the technical support.\n\n Kafka SSL CA certificate will expire in less than 30 days\n\nKafka SSL CA certificate will expire in <number> days. Please renew the certificate.\n\n Kafka SSL CA certificate has expired\n\nKafka SSL CA certificate has expired. Please renew the certificate.\n\n Kafka SSL client certificate will expire in less than 30 days\n\nKafka SSL client certificate will expire in <number> days. Please renew the certificate.\n\n Kafka SSL client certificate has expired\n\nKafka SSL client certificate has expired. Please renew the certificate.\n\nWhat's next\n\nGetting technical support\n\nSee also\n\nInfrastructure alerts\n\nCore storage alerts\n\nBackup storage alerts\n\nObject storage alerts\n\nBlock storage alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/compute-alerts.html"
    },
    {
        "title": "Changing the storage policy for volumes",
        "content": "Changing the storage policy for volumes\nIf you use redundancy by replication for a compute volume, you can update the chosen redundancy scheme by changing the storage policy. With redundancy by erasure coding, however, changing the redundancy scheme applied to the volume is disabled. The storage policy can be changed for volumes attached to both running and stopped virtual machines.\nLimitations\n\nYou cannot change the volume redundancy type. And thus, you can apply another storage policy only within the same redundancy type. For example, the storage policy with 3 replicas can only be changed to the storage policy with 2 replicas or 1 replica (no redundancy).\nChanging the storage policy with the erasure coding redundancy type is disabled.\n\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nA volume is created, as described in Creating and deleting volumes.\n\nTo change the storage policy of a volume\n\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\nClick the pencil icon in the Storage policy field.\nSelect a new storage policy, and then click the tick icon. You can choose only between storage policies with the replication redundancy type.\n\nCommand-line interface\nUse the following command:vinfra service compute volume set --storage-policy <storage_policy> <volume>\r\n\n\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to change the storage policy of the volume myvolume to mystorpolicy, run:# vinfra service compute volume set myvolume --storage-policy mystorpolicy\r\n+--------------------------------+------------------------------------------+\r\n| Field                          | Value                                    |\r\n+--------------------------------+------------------------------------------+\r\n| attachments                    | []                                       |\r\n| availability_zone              | nova                                     |\r\n| bootable                       | False                                    |\r\n| consistencygroup_id            |                                          |\r\n| created_at                     | 2018-09-12T12:30:12.665916               |\r\n| description                    |                                          |\r\n| encrypted                      | False                                    |\r\n| id                             | c9c0e9e7-ce7a-4566-99d5-d7e40f2987ab     |\r\n| imageRef                       |                                          |\r\n| migration_status               |                                          |\r\n| multiattach                    | False                                    |\r\n| name                           | myvolume                                 |\r\n| network_install                | False                                    |\r\n| os-vol-host-attr:host          | node001.vstoragedomain@vstorage#vstorage |\r\n| os-vol-mig-status-attr:migstat |                                          |\r\n| os-vol-mig-status-attr:name_id |                                          |\r\n| project_id                     | 72a5db3a033c403a86756021e601ef34         |\r\n| replication_status             |                                          |\r\n| size                           | 8                                        |\r\n| snapshot_id                    |                                          |\r\n| source_volid                   |                                          |\r\n| status                         | available                                |\r\n| storage_policy_name            | mystorpolicy                             |\r\n| updated_at                     | 2018-09-12T12:55:29.298717               |\r\n| user_id                        | 98bf389983c24c07af9677b931783143         |\r\n| volume_image_metadata          |                                          |\r\n+--------------------------------+------------------------------------------+\r\n\n\nSee also\n\nAttaching and detaching volumes\n\nResizing volumes\n\nCloning volumes\n\nManaging volume snapshots",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume set --storage-policy <storage_policy> <volume>\r\n\n\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to change the storage policy of the volume myvolume to mystorpolicy, run:# vinfra service compute volume set myvolume --storage-policy mystorpolicy\r\n+--------------------------------+------------------------------------------+\r\n| Field                          | Value                                    |\r\n+--------------------------------+------------------------------------------+\r\n| attachments                    | []                                       |\r\n| availability_zone              | nova                                     |\r\n| bootable                       | False                                    |\r\n| consistencygroup_id            |                                          |\r\n| created_at                     | 2018-09-12T12:30:12.665916               |\r\n| description                    |                                          |\r\n| encrypted                      | False                                    |\r\n| id                             | c9c0e9e7-ce7a-4566-99d5-d7e40f2987ab     |\r\n| imageRef                       |                                          |\r\n| migration_status               |                                          |\r\n| multiattach                    | False                                    |\r\n| name                           | myvolume                                 |\r\n| network_install                | False                                    |\r\n| os-vol-host-attr:host          | node001.vstoragedomain@vstorage#vstorage |\r\n| os-vol-mig-status-attr:migstat |                                          |\r\n| os-vol-mig-status-attr:name_id |                                          |\r\n| project_id                     | 72a5db3a033c403a86756021e601ef34         |\r\n| replication_status             |                                          |\r\n| size                           | 8                                        |\r\n| snapshot_id                    |                                          |\r\n| source_volid                   |                                          |\r\n| status                         | available                                |\r\n| storage_policy_name            | mystorpolicy                             |\r\n| updated_at                     | 2018-09-12T12:55:29.298717               |\r\n| user_id                        | 98bf389983c24c07af9677b931783143         |\r\n| volume_image_metadata          |                                          |\r\n+--------------------------------+------------------------------------------+\r\n\n",
                "title": "To change the storage policy of a volume"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\nClick the pencil icon in the Storage policy field.\nSelect a new storage policy, and then click the tick icon. You can choose only between storage policies with the replication redundancy type.\n\n",
                "title": "To change the storage policy of a volume"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-volume-storage-policy.html"
    },
    {
        "title": "Managing files and folders",
        "content": "Managing files and folders\nOnce you have a bucket, you can start populating it with data.\nPrerequisites\n\nA bucket is created, as described in Managing buckets.\n\nTo create folders in a bucket\n\nGo to the S3 > Buckets screen, and click the bucket name.\nOn the bucket screen, click Create folder.\nIn the Create folder window, specify a name for the folder, and then click Create.\n\nTo upload files in a bucket\n\nGo to the S3 > Buckets screen, click the bucket name and optionally the folder name.\nOn the bucket or folder screen, drag and drop files to upload, or click Upload files.\nIn the Upload files window, browse files to upload.\n\nTo download files from a bucket\n\nGo to the S3 > Buckets screen, click the bucket name and optionally the folder name.\nOn the bucket or folder screen, click the required file.\nIn the file right pane, click Dowload.\n\nTo delete a folder or a file\n\nGo to the S3 > Buckets screen, click the bucket name.\nOn the bucket, click the required file or folder to delete.\nIn the file or folder right pane, click Delete.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-files-and-folders.html"
    },
    {
        "title": "Getting Kubernetes cluster configuration data",
        "content": "Getting Kubernetes cluster configuration data\nTo get the configuration data of a Kubernetes cluster, run the following vinfra command:# vinfra --vinfra-domain <domain_name> \\\r\n         --vinfra-project <project_name> \\\r\n         --vinfra-username <username> \\\r\n         --vinfra-password <password> \\\r\n         service compute k8saas config <k8s_cluster_name>\r\n\nSample output:apiVersion: v1\r\nclusters:\r\n- cluster:\r\n    certificate-authority-data: <...>\r\n    server: https://10.94.129.74:6443\r\n  name: k8s1\r\ncontexts:\r\n- context:\r\n    cluster: k8s1\r\n    user: admin\r\n  name: default\r\ncurrent-context: default\r\nkind: Config\r\npreferences: {}\r\nusers:\r\n- name: admin\r\n  user:\r\n    client-certificate-data: <...>\r\n    client-key-data: <...>\r\n    token: <...>",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/getting-kubernetes-cluster-configuration-data.html"
    },
    {
        "title": "Managing compute backup quotas",
        "content": "Managing compute backup quotas\nBy using the vinfra command-line tool, you can limit storage space provisioned for compute backups per domain and per project.\nTo set compute backup quotas for a domain\nUse the following command:vinfra service compute quotas update [--volumes-backups <volumes-backups-size>] <domain_id>\n\n--volumes-backups <volumes-backups-size>\n\nVolume backup size. To specify the size, use the following units: M or MiB for mebibytes, G or GiB for gibibytes, T or TiB for tebibytes, P or PiB for pebibytes, and E or EiB for exbibytes.\n<domain_id>\n\nDomain ID\n\nFor example, to update quotas for the domain with the ID 0ed0dac39ba14e89b7d2b8cb7d5337f7 to 200 GiB of the volume backup size, run:# vinfra service compute quotas update --volumes-backups 200G 0ed0dac39ba14e89b7d2b8cb7d5337f7\nYou can view the updated quotas in the vinfra service compute quotas show output:# vinfra service compute quotas show 0ed0dac39ba14e89b7d2b8cb7d5337f7\r\n+----------------------------------------+----------+\r\n| Field                                  | Value    |\r\n+----------------------------------------+----------+\r\n| compute.cores.limit                    | -1       |\r\n| compute.ram.limit                      | -1       |\r\n| compute.ram_quota.limit                | -1       |\r\n| storage.gigabytes.default.limit        | -1       |\r\n| storage.storage_policies.default.limit | -1       |\r\n| storage.volumes_backups.limit          | 200.0GiB |\r\n+----------------------------------------+----------+\nTo remove compute backup quotas for a domain\nUse the following command:vinfra service compute quotas update [--volumes-backups <volumes-backups-size>] <domain_id>\n\n--volumes-backups <volumes-backups-size>\n\nVolume backup size. Specify -1 to set the quota to the unlimited value.\n<domain_id>\n\nDomain ID\n\nFor example, to remove compute backup quotas for the domain with the ID 0ed0dac39ba14e89b7d2b8cb7d5337f7, run:# vinfra service compute quotas update --volumes-backups -1 0ed0dac39ba14e89b7d2b8cb7d5337f7\nTo set compute backup quotas for a project\nUse the following command:vinfra service compute quotas update [--volumes-backups <volumes-backups-size>] <project-id>\r\n\n\n--volumes-backups <volumes-backups-size>\n\nVolume backup size. To specify the size, use the following units: M or MiB for mebibytes, G or GiB for gibibytes, T or TiB for tebibytes, P or PiB for pebibytes, and E or EiB for exbibytes.\n<project-id>\n\nProject ID\n\nFor example, to update quotas for the project with the ID 6ef6f48f01b640ccb8ff53117b830fa3 to 100 GiB of the volume backup size, run:# vinfra service compute quotas update --volumes-backups 100G 6ef6f48f01b640ccb8ff53117b830fa3\nYou can view the updated quotas in the vinfra service compute quotas show output:# vinfra service compute quotas show 79830e3c64c74ded9bac6bffde5d26e4\r\n+----------------------------------------+----------+\r\n| Field                                  | Value    |\r\n+----------------------------------------+----------+\r\n| compute.cores.limit                    | -1       |\r\n| compute.ram.limit                      | -1       |\r\n| compute.ram_quota.limit                | -1       |\r\n| network.floatingip.limit               | -1       |\r\n| network.ipsec_site_connection.limit    | -1       |\r\n| storage.gigabytes.default.limit        | -1       |\r\n| storage.storage_policies.default.limit | -1       |\r\n| storage.volumes_backups.limit          | 100.0GiB |\r\n+----------------------------------------+----------+\nTo remove compute backup quotas for a project\nUse the following command:vinfra service compute quotas update [--volumes-backups <volumes-backups-size>] <project-id>\r\n\n\n--volumes-backups <volumes-backups-size>\n\nVolume backup size. Specify -1 to set the quota to the unlimited value.\n<project-id>\n\nProject ID\n\nFor example, to remove compute backup quotas for the project with the ID 6ef6f48f01b640ccb8ff53117b830fa3, run:# vinfra service compute quotas update --volumes-backups -1 6ef6f48f01b640ccb8ff53117b830fa3\nSee also\n\nCreating backup plans\n\nManaging volumes in backup plans\n\nEditing and deleting backup plans\n\nCreating and deleting backups manually",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-compute-backup-quotas.html"
    },
    {
        "title": "Managing object storage",
        "content": "Managing object storage\nThis section outlines common administrator's tasks for S3 clusters, users, and buckets. It also provides the best practices for using S3 in Virtuozzo Hybrid Infrastructure and lists the supported Amazon S3 features. In addition, the section explains how to configure S3 geo-replication or cross-region replication between datacenters.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-object-storage.html"
    },
    {
        "title": "Configuration",
        "content": "Configuration\nIn addition, you need to create Virtuozzo Hybrid Infrastructure directories to modify the default functionality.\nChange to the document root directory of your WHMCS server (for example, /srv/http) and create the following directories in it:\n\nwhmcs/includes/staas_scripts\n\nwhmcs/admin/staas_scripts\n\nChange to the directory whmcs/includes/staas_scripts.\nThe first file you need to create includes the S3 configuration. Create a configuration file S3_getConfig.php with the following contents, replacing variables as follows:\n\ns3_key with your S3AcessKeyId,\ns3_secret with your S3SecretAccessKey,\ns3_gateway with your configured S3 gateway address, and\nwhmcs_username with your WHMCS admin username.\n<?php\r\n\r\n// Return array with default configuration.\r\nif (!function_exists('S3_getConfig')) {\r\n    function S3_getConfig() {\r\n\r\n        // s3 login.\r\n        $vars['s3_key'] = \"939e2ac6916b57082P9O\";\r\n        $vars['s3_secret'] = \"tVYF3kZD9zcTtl6q6QDTHaZKM2nuq4xVcl8ikJpd\";\r\n\r\n        // s3 gateway.\r\n        $vars['s3_gateway'] = \"http://s3.example.com\";\r\n\r\n        // whmcs login.\r\n        $vars['whmcs_username'] = \"admin\";\r\n\r\n        // Return config array.\r\n        return $vars;\r\n    }\r\n}\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/configuration.html"
    },
    {
        "title": "Querying bucket limits via REST API",
        "content": "Querying bucket limits via REST API\nYou can display the current limits with the ostor-limits service and parameter bucket specifying the bucket name:# s3_curl GET \"http://s3.example.com/?ostor-limits&bucket=client\"\r\n{\r\n    \"ops:default\": \"0.00\",\r\n    \"ops:get\": \"3600.00\",\r\n    \"ops:put\": \"0.00\",\r\n    \"ops:list\": \"0.00\",\r\n    \"ops:delete\": \"0.00\",\r\n    \"bandwidth:out\": \"100\"\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-bucket-limits-via-rest-api.html"
    },
    {
        "title": "Managing S3 users via CLI",
        "content": "Managing S3 users via CLI\nThe concept of an S3 user is one of the base concepts of object storage along with those of an object and a bucket (a container for storing objects). The Amazon S3 protocol uses a permission model based on access control lists (ACLs), where each bucket and each object are assigned an ACL that lists all users with access to the given resource and the type of this access (read, write, read ACL, or write ACL). The list of users includes the entity owner assigned to every object and bucket at creation. The entity owner has extra rights compared to other users. For example, the bucket owner is the only one who can delete that bucket.\nUser model and access policies implemented in Virtuozzo Hybrid Infrastructure comply with the Amazon S3 user model and access policies.\nUser management scenarios in Virtuozzo Hybrid Infrastructure are largely based on the Amazon Web Services user management and include the following operations: create, query, and delete users, as well as generate and revoke user access key pairs.\nYou can manage users with the ostor-s3-admin tool.\nTo do it via CLI, you will need to know the ID of the volume that they are in. You can obtain it with the ostor-ctl get-config command. For example:# ostor-ctl get-config -n 10.94.97.195\r\nVOL_ID             TYPE     STATE\r\n0100000000000002   OBJ      READY\r\n...\r\n\n\r\n            As ostor-s3-admin commands are assumed to be issued by object storage administrators, they do not include any authentication or authorization checks.\r\n        ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-users-via-cli.html"
    },
    {
        "title": "Enabling S3 cross-region replication",
        "content": "Enabling S3 cross-region replication\nCross-region replication (CRR) enables automatic, asynchronous copying of objects across S3 buckets in different regions. Buckets that are configured for CRR can be owned by the same user. Objects may be replicated to a single destination bucket or multiple destination buckets.\nTo enable CRR, you need to add replication configuration to your source bucket. The minimum configuration must provide the destination buckets where you want to replicate objects and a user with the role that enables replicating objects on your behalf.\nLimitations\n\nCRR only supports copying new S3 objects after it is enabled.\n\nPrerequisites\n\nS3 clusters are created, as described in Creating the S3 cluster.\n\nTo set up CRR replication\n\nCreate two or more S3 buckets, one source bucket and one or multiple destination buckets. You can also use buckets that already exist in the S3 cluster. For example, to create the source and destination buckets, use:\r\naws s3api create-bucket --bucket source --endpoint-url http://s3.ostor --profile ostor\r\naws s3api create-bucket --bucket destination --endpoint-url http://s3.ostor --profile ostor\n\nEnable versioning for these buckets. For example:aws s3api  put-bucket-versioning --bucket source --endpoint-url http://s3.ostor --profile ostor \\\r\n--versioning-configuration 'Status=Enabled'\r\naws s3api  put-bucket-versioning --bucket destination --endpoint-url http://s3.ostor --profile ostor \\\r\n--versioning-configuration 'Status=Enabled'\n\nCreate a replication configuration file. For example, the replication.conf file may look as follows:<?xml version=\"1.0\"?>\r\n<ReplicationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\r\n  <Rule>\r\n    <Status>Enabled</Status>\r\n    <Filter/>\r\n    <DeleteMarkerReplication>\r\n      <Status>Disabled</Status>\r\n    </DeleteMarkerReplication>\r\n    <Destination>\r\n      <Bucket>arn:aws:s3:::destination</Bucket>\r\n    </Destination>\r\n    <Priority>1</Priority>\r\n    <ID>rep-rule</ID>\r\n  </Rule>\r\n  <Role>arn:aws:iam::ccb13f7bc586ace0:role/service-role/s3crr_role</Role>\r\n</ReplicationConfiguration>\nwhere:\n\nRule\n\nSpecifies which objects to replicate and where to store the replicas.\nDeleteMarkerReplication\n\nSpecifies whether to replicate delete markers. If the Filter\u00a0element is specified, you must also include the DeleteMarkerReplication\u00a0element.\nDestination\n\nA container for information about the replication destination and its configuration.\nPriority\n\nIndicates which rule has precedence whenever two or more replication rules conflict.\nBucket\n\nThe name of the bucket where you want to store the results.\nStatus\n\nSpecifies whether the rule is enabled. Valid values\u00a0are Enabled or Disabled.\nID\n\nA unique identifier for the rule. The value must be up to 255 characters long.\nRole\n\nThe ID of the user that is used to replicate objects on your behalf. In the example above, it is ccb13f7bc586ace0.\n\nConfigure the source bucket for CRR by specifying the replication configuration file. For example:aws s3api put-bucket-replication --bucket source --endpoint-url http://s3.ostor --profile ostor \\\r\n--replication-configuration file://replication.conf\n\nSee also\n\nEnabling S3 geo-replication",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-s3-cross-region-replication.html"
    },
    {
        "title": "Creating projects",
        "content": "Creating projectsPOST /v3/projects\r\n\nCreate a project with the specified name.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=create-project-detail#create-project\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject\n\nbody\nobject\nA project object.\n\nname\n\nbody\nstring\nThe unique name of the project within the\r\nowning domain.\n\nis_domain (Optional)\nbody\nboolean\n\nIndicates whether the project also acts as a domain. If set to true,\r\nthis project acts as both a project and domain. As a domain, the project\r\nprovides a name space in which you can create users, groups, and other\r\nprojects. If set to false, this project behaves as a regular project\r\nthat contains only resources. Default is false. You cannot update\r\nthis parameter after you create the project.\nNew in version 3.6\n\ndescription (Optional)\nbody\nstring\nThe description of the project.\n\ndomain_id (Optional)\nbody\nstring\n\nThe ID of the domain for the project.\nFor projects acting as a domain, the domain_id must not be specified,\r\nit will be generated by the Identity service implementation.\nFor regular projects (i.e. those not acing as a domain), if domain_id\r\nis not specified, but parent_id is specified, then the domain ID of the\r\nparent will be used. If neither domain_id or parent_id is\r\nspecified, the Identity service implementation will default to the domain\r\nto which the client\u00e2\u0080\u0099s token is scoped. If both domain_id and\r\nparent_id are specified, and they do not indicate the same domain, an\r\nBad Request (400) will be returned.\n\nenabled (Optional)\nbody\nboolean\nIf set to true, project is enabled. If set to\r\nfalse, project is disabled. The default is true.\n\nparent_id (Optional)\nbody\nstring\n\nThe ID of the parent of the project.\nIf specified on project creation, this places the project within a\r\nhierarchy and implicitly defines the owning domain, which will be the\r\nsame domain as the parent specified. If parent_id is\r\nnot specified and is_domain is false, then the project will use its\r\nowning domain as its parent. If is_domain is true (i.e. the project\r\nis acting as a domain), then parent_id must not specified (or if it is,\r\nit must be null) since domains have no parents.\nparent_id is immutable, and can\u00e2\u0080\u0099t be updated after the project is\r\ncreated - hence a project cannot be moved within the hierarchy.\nNew in version 3.4\n\ntags (Optional)\nbody\narray\nA list of simple strings assigned to a project.\r\nTags can be used to classify projects into groups.\n\noptions (Optional)\nbody\nobject\nThe resource options for the project. Available resource options are\r\nimmutable.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"project\": {\r\n        \"description\": \"Project description\",\r\n        \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n        \"name\": \"project1\"\r\n    }\r\n}' https://<node_IP_addr>:5000/v3/projects\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nproject\n\nbody\nobject\nA project object.\n\nname\n\nbody\nstring\nThe unique name of the project within the\r\nowning domain.\n\nis_domain\n\nbody\nboolean\n\nIndicates whether the project also acts as a domain. If set to true,\r\nthis project acts as both a project and domain. As a domain, the project\r\nprovides a name space in which you can create users, groups, and other\r\nprojects. If set to false, this project behaves as a regular project\r\nthat contains only resources.\nNew in version 3.6\n\ndescription\n\nbody\nstring\nThe description of the project.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain for the project.\n\nenabled\n\nbody\nboolean\nIf set to true, project is enabled. If set to\r\nfalse, project is disabled.\n\nid\n\nbody\nstring\nThe ID for the project.\n\nlinks\n\nbody\nobject\nThe link to the project resource.\n\nparent_id\n\nbody\nstring\n\nThe ID of the parent for the project.\nNew in version 3.4\n\noptions\n\nbody\nobject\nThe resource options for the project. Available resource options are\r\nimmutable.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"project\": {\r\n    \"is_domain\": false,\r\n    \"description\": \"Project description\",\r\n    \"links\": {\r\n      \"self\": \"https://<node_IP_addr>:5000/v3/projects/ec35eb7ceb594ad696839fc867817e4c\"\r\n    },\r\n    \"tags\": [],\r\n    \"enabled\": true,\r\n    \"id\": \"ec35eb7ceb594ad696839fc867817e4c\",\r\n    \"parent_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"name\": \"project1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-projects.html"
    },
    {
        "title": "Deploying virtual machines with load generators",
        "content": "Deploying virtual machines with load generators\nYou can deploy virtual machines with load generators in the compute cluster of Virtuozzo Hybrid Infrastructure by using the prebuilt images.\nPrerequisites\n\nKnowledge of the requirements listed in Benchmarking requirements.\n\nTo deploy VMs with load generators\n\nDownload and extract the images of the test VM templates:# wget https://docs.virtuozzo.com/fio/fio-test-images.tar.gz\r\n# tar xvzf fio-test-images.tar.gz\n\nCreate templates from the extracted images:# vinfra service compute image create --file Centos7-fio-test-sys.qcow --os-distro centos7 Centos7-fio-test-sys\r\n# vinfra service compute image create --file Centos7-fio-test-blank.qcow Centos7-fio-test-blank\n\nDeploy test VMs from the templates:# vinfra service compute server create FIO-Centos7 --count <N> --network id=<net> \\\r\n--volume source=image,id=Centos7-fio-test-sys,size=10,boot-index=0 \\\r\n--volume source=image,id=Centos7-fio-test-blank,size=64,boot-index=1 --flavor large\nWhere:\n\n--count <N> is the number of nodes in your compute cluster, for example, --count 5. We recommend creating VMs on a clean cluster, so that each node will have one VM. If you want to test a single VM, use --count 1.\n--network id=<net> is a network accessible by the host or virtual environment that you will run the tests from, for example, public.\n\nAs the result, you will have a set number of identical virtual machines with the following characteristics:\n\n4 vCPUs and 8 GiB RAM (the flavor large). If you want to use another flavor, make sure to update the fio scripts and other job profiles accordingly, as described in Setting up the benchmark for NFS and iSCSI.\nA 10 GiB system disk with the CentOS 7 operating system\nA 64 GiB ext4 disk for tests\nThe network specified by the --network option\nLogin: root, password: CDEkOA%rXfd%wWnOHDXm\n\nWhat's next\n\nCreating the target storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/deploying-load-generator-vms.html"
    },
    {
        "title": "3.3. Creating BitNinja Product and Service\u00c2\u00b6",
        "content": "3.3. Creating BitNinja Product and Service | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n3.3. Creating BitNinja Product and Service\u00c2\u00b6\nIn order to create the new Product/Service you will need to first get your API Key from reseller.bitninja.io. Login with your user account generate the Key. This API Key will be used in the next step along with your reseller e-mail account.\n\nIn order to add a new product go to  Setup (spanner icon) > System Settings > Servers > Create a new Server:\n\nModule - Choose the BitNinja Module\nHostname - api.bitninja.io\nUsername - the e-mail account used to\n\nTo add a new Product Group go to Setup (spanner icon) > System Settings > Products/Services > Create new Group:\n\nNow create each one or more Products by going to Setup (spanner icon) > System Settings > Products/Services > Create new Product:\n\nFill in the Details information for your product.\n\nAdd Pricing\n\nAlso configure the Module Settings to define at what point the product is setup.\n\nNow your new service will be available on the service portal for the end-users\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/whmcs-bitninja/creating-bitninja-product.html"
    },
    {
        "title": "Creating Kubernetes clusters",
        "content": "Creating Kubernetes clustersPOST /v1/clusters\r\n\nCreate a new Kubernetes cluster based on a cluster template. Refer to Creating Kubernetes cluster templates for more information.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=create-new-cluster-detail#create-new-cluster\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nname\n\nbody\nstring\nName of the resource.\n\ndiscovery_url\n\nbody\nstring\n\nThe custom discovery URL for node discovery. This is used by the COE to\r\ndiscover the servers that have been created to host the containers. The\r\nactual discovery mechanism varies with the COE. In some cases, Magnum fills\r\nin the server info in the discovery service. In other cases, if the\r\ndiscovery_url is not specified, Magnum will use the public discovery\r\nservice at:https://discovery.etcd.io\r\n\nIn this case, Magnum will generate a unique URL here for each bay and\r\nstore the info for the servers.\n\nmaster_count\n\nbody\ninteger\nThe number of servers that will serve as master for the bay/cluster. The\r\ndefault is 1. Set to more than 1 master to enable High Availability. If\r\nthe option master-lb-enabled is specified in the baymodel/cluster\r\ntemplate, the master servers will be placed in a load balancer pool.\n\ncluster_template_id\n\nbody\nUUID\nThe UUID of the cluster template.\n\nnode_count\n\nbody\ninteger\nThe number of servers that will serve as node in the bay/cluster. The\r\ndefault is 1.\n\nkeypair\n\nbody\nstring\nThe name of the SSH keypair to configure in the bay/cluster servers\r\nfor ssh access. Users will need the key to be able to ssh to the servers in\r\nthe bay/cluster. The login name is specific to the bay/cluster driver, for\r\nexample with fedora-atomic image, default login name is fedora.\n\ncreate_timeout\n\nbody\ninteger\nThe timeout for cluster creation in minutes. The value expected is a\r\npositive integer and the default is 60 minutes. If the timeout is reached\r\nduring cluster creation process, the operation will be aborted and the\r\ncluster status will be set to CREATE_FAILED.\n\nmaster_flavor_id (Optional)\nbody\nstring\nThe flavor of the master node for this baymodel/cluster template.\n\nlabels (Optional)\nbody\narray\nArbitrary labels in the form of key=value pairs. The accepted keys and\r\nvalid values are defined in the bay/cluster drivers. They are used as a way\r\nto pass additional parameters that are specific to a bay/cluster driver.\n\nflavor_id\n\nbody\nstring\nThe nova flavor ID or name for booting the node servers. The default is\r\nm1.small.\n\nfixed_subnet (Optional)\nbody\nstring\nFixed subnet that are using to allocate network address for nodes in\r\nbay/cluster.\n\nfixed_network (Optional)\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to\r\nthe internal network for the bay/cluster.\n\nfloating_ip_enabled (Optional)\nbody\nboolean\nWhether enable or not using the floating IP of cloud provider. Some\r\ncloud providers used floating IP, some used public IP, thus Magnum\r\nprovide this option for specifying the choice of using floating IP.\r\nIf it\u00e2\u0080\u0099s not set, the value of floating_ip_enabled in template\r\nwill be used.\n\nExample# curl -ks -X POST -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"name\": \"kub1\",\r\n  \"master_count\": 2,\r\n  \"master_flavor_id\": \"medium\",\r\n  \"node_count\": 2,\r\n  \"flavor_id\": \"small\",\r\n  \"keypair\": \"key1\",\r\n  \"docker_volume_size\": 10,\r\n  \"cluster_template_id\": \"b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n  \"create_timeout\": 60\r\n}' https://<node_IP_addr>:9513/v1/clusters\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nuuid\n\nbody\nUUID\nThe UUID of the cluster.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"uuid\": \"ea9182cc-26ef-4087-bdd7-097cc99672ea\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-kubernetes-clusters.html"
    },
    {
        "title": "Disabling geo-replication",
        "content": "Disabling geo-replication\nPrerequisites\n\nGeo-replication is enabled, as described in Enabling geo-replication.\n\nTo disable geo-replication\n\nAdmin panel\n\nOn the primary cluster, go to Storage services > Backup storage > Geo-replication, and then click Disable replication. \nClick Disable in the confirmation window.\nOn the primary cluster, go to Storage services > Backup storage > Registrations, and then delete Geo-replication registration.\n\nOn the secondary cluster, do one of the following:\n\nIf you plan to use this backup storage, cancel geo-replication for it by running:# vinfra service backup geo-replication secondary cancel\n\nIf you do not need this backup storage, reinstall Virtuozzo Hybrid Infrastructure on each node from scratch.\n\nCommand-line interface\n\nDisable geo-replication on the primary cluster by running vinfra service backup geo-replication primary disable. For example:# vinfra service backup geo-replication primary disable\n\nDelete Geo-replication registration on the primary cluster by running vinfra service backup registration delete. For example:# vinfra service backup registration delete --username account@example.com --stdin \"Geo-replication registration\"\n\nCancel geo-replication on the secondary cluster by running vinfra service backup geo-replication secondary cancel. For example:# vinfra service backup geo-replication secondary cancel\n\nDestroy the secondary cluster to delete the backup data that has been replicated from the primary cluster. For example:# vinfra service backup cluster release\n\nWhat's next\n\nReleasing nodes from backup storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nDisable geo-replication on the primary cluster by running vinfra service backup geo-replication primary disable. For example:# vinfra service backup geo-replication primary disable\n\n\nDelete Geo-replication registration on the primary cluster by running vinfra service backup registration delete. For example:# vinfra service backup registration delete --username account@example.com --stdin \"Geo-replication registration\"\n\n\nCancel geo-replication on the secondary cluster by running vinfra service backup geo-replication secondary cancel. For example:# vinfra service backup geo-replication secondary cancel\n\n\nDestroy the secondary cluster to delete the backup data that has been replicated from the primary cluster. For example:# vinfra service backup cluster release\n\n\n",
                "title": "To disable geo-replication"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the primary cluster, go to Storage services > Backup storage > Geo-replication, and then click Disable replication. \nClick Disable in the confirmation window.\nOn the primary cluster, go to Storage services > Backup storage > Registrations, and then delete Geo-replication registration.\n\nOn the secondary cluster, do one of the following:\n\n\nIf you plan to use this backup storage, cancel geo-replication for it by running:# vinfra service backup geo-replication secondary cancel\n\nIf you do not need this backup storage, reinstall Virtuozzo Hybrid Infrastructure on each node from scratch.\n\n\n\n",
                "title": "To disable geo-replication"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/disabling-geo-replication.html"
    },
    {
        "title": "Creating the S3 cluster",
        "content": "Creating the S3 cluster\nLimitations\n\nAfter the S3 cluster deployment, you can change only the replication redundancy scheme for data. Changing the encoding redundancy scheme for data is disabled, because it may decrease cluster performance. Re-encoding demands a significant amount of cluster resources for a long period of time. If you still want to change the redundancy scheme for data, contact the technical support team.\n\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nThe storage cluster has at least one disk with the Storage role.\nEnsure that each node to join the object storage cluster has the TCP port 443 (HTTPS) or TCP port 80 (HTTP) open for outgoing and incoming Internet connections.\n\nTo set up object storage services on cluster nodes\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the OSTOR private and S3 public traffic types are added to the networks you intend to use.\nOpen the Storage services > S3 screen, and then click Create S3 storage.\nOn the Nodes step, select nodes to add to the S3 storage, and then click Next. To create highly available S3 storage, select at least three nodes.\n\nOn the Storage policies step, define storage policies for S3 data and metadata:\n\nIn the Data storage policy section, select the desired tier, failure domain, and data redundancy mode for storing S3 data. To benefit from high availability, select a mode other than No redundancy and a failure domain other than Disk.\n\nIn the Metadata storage policy section, select the desired tier for storing S3 metadata, which includes NS and OS journals. It is highly recommended to place metadata on a faster storage tier than is used for data, to improve the service performance.\n\nOn the DNS step, specify an external DNS name for the S3 storage. For example, s3storage.example.com. End users will use this DNS name and the TCP port 443 (HTTPS) or TCP port 80 (HTTP) to access the S3 data. Then, click Next.\n\nDNS load balancing can be used for test purposes only. For production, use an external load balancer.\n\nOn the Protocol step, select an S3 endpoint protocol: HTTP, HTTPS, or both.\n\nIt is recommended to use only HTTPS for production deployments.\n\nIf you selected the HTTPS protocol, do one of the following: \n\nSelect Upload a certificate, specify the prepared SSL certificate, and then specify the SSL key or passphrase (for PKCS#12 files).\nYou need to acquire a key and a trusted wildcard SSL certificate for endpoint\u00e2\u0080\u0099s bottom-level domain. For example, the endpoint s3storage.example.com would need a wildcard certificate for *.s3storage.example.com with the subject alternative name s3storage.example.com.\nIf you acquired an SSL certificate from an intermediate certificate authority (CA)\n\nYou should have an end-user certificate along with a CA bundle that contains the root and intermediate certificates. To be able to use these certificates, you need to merge them into a chain first. A certificate chain includes the end-user certificate, the certificates of intermediate CAs, and the certificate of a trusted root CA. In this case, an SSL certificate can only be trusted if every certificate in the chain is properly issued and valid.\nFor example, if you have an end-user certificate, two intermediate CA certificates, and a root CA certificate, create a new certificate file and add all certificates to it in the following order:# End-user certificate issued by the intermediate CA 1\r\n-----BEGIN CERTIFICATE-----\r\nMIICiDCCAg2gAwIBAgIQNfwmXNmET8k9Jj1X<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 1 certificate issued by the intermediate CA 2\r\n-----BEGIN CERTIFICATE-----\r\nMIIEIDCCAwigAwIBAgIQNE7VVyDV7exJ9ON9<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 2 certificate issued by the root CA\r\n-----BEGIN CERTIFICATE-----\r\nMIIC8jCCAdqgAwIBAgICZngwDQYJKoZIhvcN<...>\r\n-----END CERTIFICATE-----\r\n# Root CA certificate\r\n-----BEGIN CERTIFICATE-----\r\nMIIDODCCAiCgAwIBAgIGIAYFFnACMA0GCSqG<...>\r\n-----END CERTIFICATE-----\r\n\n\nSelect Generate a certificate, to get a self-signed certificate for HTTPS evaluation purposes.\n\nS3 geo-replication requires a certificate from a trusted authority. It does not work with self-signed certificates.\nTo access the data in the S3 cluster via a browser, add the self-signed certificate to browser\u00e2\u0080\u0099s exceptions.\n\nThen, click Next.\n\nOn the Summary step, review the configuration, and then click Create.\n\nTo check if the S3 storage is successfully deployed and can be accessed by users, visit https://<S3_DNS_name> or http://<S3_DNS_name> in your browser. You should receive the following XML response:<Error>\r\n<Code>AccessDenied</Code>\r\n<Message/>\r\n</Error>\r\n\nTo start using the S3 storage, you will also need to create at least one S3 user.\n\nCommand-line interface\nUse the following command:vinfra service s3 cluster create [--tier {0,1,2,3}] [--failure-domain {0,1,2,3,4}]\r\n                                 [--replicas <norm> | --encoding <M>+<N>] [--metadata-tier {0,1,2,3}]\r\n                                 [--self-signed | --no-ssl | --cert-file <cert_file>]\r\n                                 [--insecure] [--key-file <key_file>] [--password]\r\n                                 --nodes <nodes> --s3gw-domain <domain> --s3gw-count <s3gw_count>\r\n                                 --os-count <os_count> --ns-count <ns_count>\n\n--tier {0,1,2,3}\n\nStorage tier (default: 0)\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain (default: 0)\n--replicas <norm>\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain (default: 1)\n\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: the number of data blocks\nN: the number of parity blocks\n\n--metadata-tier {0,1,2,3}\n\nStorage tier\n--self-signed\n\n        Generate a new self-signed certificate (default)\n--no-ssl\n\nDo not generate a self-signed certificate\n--cert-file <cert_file>\n\nPath to a file with the new certificate\n--insecure\n\nAllow insecure connections in addition to secure ones (only used with the --cert-file and --self-signed options)\n--key-file <key_file>\n\nPath to a file with the private key (only used with the --cert-file option)\n--password\n\nRead certificate password from stdin (only used with the --cert-file option)\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--s3gw-domain <domain>\n\nDNS name S3 endpoint\n--s3gw-count <s3gw_count>\n\nNumber of S3 gateways\n--os-count <os_count>\n\n  Amount of OS services in S3 cluster\n--ns-count <ns_count>\n\n  Amount of NS services in S3 cluster\n\nIncreasing the number of gateways, NS, and OS services also increases the resource requirements. To learn more about CPU and RAM reservations for the S3 services, refer to General requirements.\n\nFor example, to create the S3 cluster from nodes node001 and node002 with a self-signed certificate, run:# vinfra service s3 cluster create --nodes node001,node002 --tier 0 --failure-domain 1 --encoding 1+2 \\\r\n--metadata-tier 1 --self-signed --s3gw-domain dns.example.com\nThis command also specifies the tier, failure domain, redundancy mode, and domain name.\nYou can view the S3 storage details in the vinfra service s3 show output:# vinfra service s3 show\r\n+-----------------+--------------------------------------------+\r\n| Field           | Value                                      |\r\n+-----------------+--------------------------------------------+\r\n| failure_domain  | 1                                          |\r\n| id              | 0100000000000002                           |\r\n| metadata_policy | failure_domain: 1                          |\r\n|                 | redundancy:                                |\r\n|                 |   m: 1                                     |\r\n|                 |   n: 2                                     |\r\n|                 |   type: raid6                              |\r\n|                 | tier: 1                                    |\r\n| name            | cluster1                                   |\r\n| nodes           | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                 | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n| np              |                                            |\r\n| nusers          | 0                                          |\r\n| protocol        | scheme: https                              |\r\n| redundancy      | m: 1                                       |\r\n|                 | n: 2                                       |\r\n|                 | type: raid6                                |\r\n| s3gw_domain     | dns.example.com                            |\r\n| tier            | 0                                          |\r\n+-----------------+--------------------------------------------+\n\nWhat's next\n\nEnabling S3 access for the self service\n\nCreating S3 users",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 cluster create [--tier {0,1,2,3}] [--failure-domain {0,1,2,3,4}]\r\n                                 [--replicas <norm> | --encoding <M>+<N>] [--metadata-tier {0,1,2,3}]\r\n                                 [--self-signed | --no-ssl | --cert-file <cert_file>]\r\n                                 [--insecure] [--key-file <key_file>] [--password]\r\n                                 --nodes <nodes> --s3gw-domain <domain> --s3gw-count <s3gw_count>\r\n                                 --os-count <os_count> --ns-count <ns_count>\n\n--tier {0,1,2,3}\n\nStorage tier (default: 0)\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain (default: 0)\n--replicas <norm>\n\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain (default: 1)\n\n\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: the number of data blocks\nN: the number of parity blocks\n\n\n--metadata-tier {0,1,2,3}\n\nStorage tier\n--self-signed\n\n        Generate a new self-signed certificate (default)\n--no-ssl\n\nDo not generate a self-signed certificate\n--cert-file <cert_file>\n\nPath to a file with the new certificate\n--insecure\n\nAllow insecure connections in addition to secure ones (only used with the --cert-file and --self-signed options)\n--key-file <key_file>\n\nPath to a file with the private key (only used with the --cert-file option)\n--password\n\nRead certificate password from stdin (only used with the --cert-file option)\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--s3gw-domain <domain>\n\nDNS name S3 endpoint\n--s3gw-count <s3gw_count>\n\nNumber of S3 gateways\n--os-count <os_count>\n\n  Amount of OS services in S3 cluster\n--ns-count <ns_count>\n\n  Amount of NS services in S3 cluster\n\n\nIncreasing the number of gateways, NS, and OS services also increases the resource requirements. To learn more about CPU and RAM reservations for the S3 services, refer to General requirements.\n\nFor example, to create the S3 cluster from nodes node001 and node002 with a self-signed certificate, run:# vinfra service s3 cluster create --nodes node001,node002 --tier 0 --failure-domain 1 --encoding 1+2 \\\r\n--metadata-tier 1 --self-signed --s3gw-domain dns.example.com\nThis command also specifies the tier, failure domain, redundancy mode, and domain name.\nYou can view the S3 storage details in the vinfra service s3 show output:# vinfra service s3 show\r\n+-----------------+--------------------------------------------+\r\n| Field           | Value                                      |\r\n+-----------------+--------------------------------------------+\r\n| failure_domain  | 1                                          |\r\n| id              | 0100000000000002                           |\r\n| metadata_policy | failure_domain: 1                          |\r\n|                 | redundancy:                                |\r\n|                 |   m: 1                                     |\r\n|                 |   n: 2                                     |\r\n|                 |   type: raid6                              |\r\n|                 | tier: 1                                    |\r\n| name            | cluster1                                   |\r\n| nodes           | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                 | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n| np              |                                            |\r\n| nusers          | 0                                          |\r\n| protocol        | scheme: https                              |\r\n| redundancy      | m: 1                                       |\r\n|                 | n: 2                                       |\r\n|                 | type: raid6                                |\r\n| s3gw_domain     | dns.example.com                            |\r\n| tier            | 0                                          |\r\n+-----------------+--------------------------------------------+\n",
                "title": "To set up object storage services on cluster nodes"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the OSTOR private and S3 public traffic types are added to the networks you intend to use.\nOpen the Storage services > S3 screen, and then click Create S3 storage.\nOn the Nodes step, select nodes to add to the S3 storage, and then click Next. To create highly available S3 storage, select at least three nodes.\n\nOn the Storage policies step, define storage policies for S3 data and metadata:\n\n\nIn the Data storage policy section, select the desired tier, failure domain, and data redundancy mode for storing S3 data. To benefit from high availability, select a mode other than No redundancy and a failure domain other than Disk.\n\n\n\n\n\n\nIn the Metadata storage policy section, select the desired tier for storing S3 metadata, which includes NS and OS journals. It is highly recommended to place metadata on a faster storage tier than is used for data, to improve the service performance.\n\n\n\n\n\n\n\n\nOn the DNS step, specify an external DNS name for the S3 storage. For example, s3storage.example.com. End users will use this DNS name and the TCP port 443 (HTTPS) or TCP port 80 (HTTP) to access the S3 data. Then, click Next.\n\nDNS load balancing can be used for test purposes only. For production, use an external load balancer.\n\n\n\nOn the Protocol step, select an S3 endpoint protocol: HTTP, HTTPS, or both.\n\nIt is recommended to use only HTTPS for production deployments.\n\n\n\n\n\nIf you selected the HTTPS protocol, do one of the following: \n\n\nSelect Upload a certificate, specify the prepared SSL certificate, and then specify the SSL key or passphrase (for PKCS#12 files).\nYou need to acquire a key and a trusted wildcard SSL certificate for endpoint\u00e2\u0080\u0099s bottom-level domain. For example, the endpoint s3storage.example.com would need a wildcard certificate for *.s3storage.example.com with the subject alternative name s3storage.example.com.\nIf you acquired an SSL certificate from an intermediate certificate authority (CA)\n\nYou should have an end-user certificate along with a CA bundle that contains the root and intermediate certificates. To be able to use these certificates, you need to merge them into a chain first. A certificate chain includes the end-user certificate, the certificates of intermediate CAs, and the certificate of a trusted root CA. In this case, an SSL certificate can only be trusted if every certificate in the chain is properly issued and valid.\nFor example, if you have an end-user certificate, two intermediate CA certificates, and a root CA certificate, create a new certificate file and add all certificates to it in the following order:# End-user certificate issued by the intermediate CA 1\r\n-----BEGIN CERTIFICATE-----\r\nMIICiDCCAg2gAwIBAgIQNfwmXNmET8k9Jj1X<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 1 certificate issued by the intermediate CA 2\r\n-----BEGIN CERTIFICATE-----\r\nMIIEIDCCAwigAwIBAgIQNE7VVyDV7exJ9ON9<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 2 certificate issued by the root CA\r\n-----BEGIN CERTIFICATE-----\r\nMIIC8jCCAdqgAwIBAgICZngwDQYJKoZIhvcN<...>\r\n-----END CERTIFICATE-----\r\n# Root CA certificate\r\n-----BEGIN CERTIFICATE-----\r\nMIIDODCCAiCgAwIBAgIGIAYFFnACMA0GCSqG<...>\r\n-----END CERTIFICATE-----\r\n\n\n\n\n\nSelect Generate a certificate, to get a self-signed certificate for HTTPS evaluation purposes.\n\n\nS3 geo-replication requires a certificate from a trusted authority. It does not work with self-signed certificates.\nTo access the data in the S3 cluster via a browser, add the self-signed certificate to browser\u00e2\u0080\u0099s exceptions.\n\n\n\n\nThen, click Next.\n\nOn the Summary step, review the configuration, and then click Create.\n\nTo check if the S3 storage is successfully deployed and can be accessed by users, visit https://<S3_DNS_name> or http://<S3_DNS_name> in your browser. You should receive the following XML response:<Error>\r\n<Code>AccessDenied</Code>\r\n<Message/>\r\n</Error>\r\n\nTo start using the S3 storage, you will also need to create at least one S3 user.\n",
                "title": "To set up object storage services on cluster nodes"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-the-s3-cluster.html"
    },
    {
        "title": "Preparing boot media for virtual machines",
        "content": "Preparing boot media for virtual machines\nBefore creating a virtual machine, you need to prepare a source with a guest operating system, to boot the VM from it. You can use the following media:\n\nAn ISO image is a typical OS distribution that needs to be installed on disk. You can upload an ISO image to the compute cluster.\nA template is a ready boot volume in the QCOW2 (rarely RAW or IMG) format with an installed operating system and applications. Many OS vendors offer templates of their operating systems under the name \u00e2\u0080\u009ccloud images\u00e2\u0080\u009d. You can upload a cloud image from the OS official repository or prepare your own template in the compute cluster.\nA boot volume with an installed operating system and applications. You can prepare a boot volume in the compute cluster.\n\nPrerequisites\n\nKnowledge of the supported guest operating systems listed in Supported guest operating systems. \r\n\t\t",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-boot-media-for-vms.html"
    },
    {
        "title": "Limit management",
        "content": "Limit management\nThis section describes operation rate limits and outgoing bandwidth limits that can be defined for S3 users and buckets.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/limit-management.html"
    },
    {
        "title": "Managing notifications",
        "content": "Managing notifications\nThe notification center stores and shows notifications about recent tasks of the current user in the management panel. Notifications are displayed only for tasks performed during the current user session and cleared out when the user logs out.\nA user is informed about each task by a pop-up notification in the bottom right corner of the screen. The same notification also appears in the notification center. After the pop-up window is closed, the notification is available in the notification center.\nThe following table describes all of the supported notification types:\n\nNotification type\nIcon\nDescription\nRetention period of a pop-up window\nRetention period in the notification center\n\nInfo\n\nNotifications about a task launch\n3 seconds\n10 minutes\n\nSuccess\n\nNotifications about successfully completed tasks\n3 seconds\n10 minutes\n\nError\n\nNotifications about failed tasks\n10 seconds\n50 minutes\n\nIn progress\n\nLong-running tasks, such as image upload or problem report creation\nTask time\nTask time\n\nTo view notifications\n\nOn any screen, click the bell icon in the top right corner. Next to the bell icon, you can see the notification counter, or the loading sign if you have a running task.\nTo view notifications of a particular type, click All types, and then select the notification type you wish to be displayed in the notification center.\n\nTo clear notifications\n\nOn any screen, click the bell icon in the top right corner.\nTo clear only one notification, click the cross icon next to it.\nTo clear all of the notifications, click Clear all above the notification list.\n\nTo configure pop-up notifications\n\nOn any screen, click the bell icon in the top right corner.\n\nClick the cogwheel icon, and then clear notification types that you do not wish to be shown in a pop-up window. Only the selected notification types will appear as pop-up messages.\n\nTo mute pop-up notifications\n\nOn any screen, click the bell icon in the top right corner.\n\nClick the cogwheel icon, and then turn on the Do not disturb mode.\n\nThe bell icon will be greyed out, and the notification counter will disappear. While this mode is on, pop-up notifications are disabled. However, all notifications are still available in the notification center.\nTo unmute pop-up notifications\n\nOn any screen, click the greyed out bell icon in the top right corner.\n\nClick Turn off, to turn off the Do not disturb mode.\n\nSee also\n\nSending email notifications\n\nViewing alerts\n\nViewing audit log",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-notifications.html"
    },
    {
        "title": "Restoring management database from backup",
        "content": "Restoring management database from backup\nYou can restore a management node database from backup on the same management node or any node in the storage cluster.\nLimitations\n\nIf management node high availability is enabled, you cannot restore database backups by using the script. In this case, contact the technical support team.\nThe vstorage-ui-backend service must be running on a single node in the storage cluster. If the management node database is restored on a different node, the previous management node must be re-deployed.\n\nPrerequisites\n\nThe management database is backed up automatically or manually, as described in Backing up management database.\n\nTo restore a management node database from backup\nRun the following script on the node where the MN database will be restored:/usr/libexec/vstorage-ui-backend/bin/restore-management-node.sh -x <public_net_iface> -i <private_net_iface> \\\r\n-f /mnt/vstorage/webcp/backup/<backup_file>\r\n\nwhere\n\nThe <public_net_iface> and <private_net_iface> are interfaces assigned the public and private networks. If required, you can specify the same network interface in both parameters.\nThe -f option specifies the path to the backup file. If omitted, the management node database will be restored from the latest backup.\n\nFor example, if the network interface eth0 is connected to the Public network, the network interface eth1 is connected to the Private network, and you want to restore the management node database from the backup backup-20211026000001.tar, run:# /usr/libexec/vstorage-ui-backend/bin/restore-management-node.sh -x eth0 -i eth1 \\\r\n-f /mnt/vstorage/webcp/backup/backup-20211026000001.tar\nTo access the admin panel, use the public IP address of the node with the restored MN database.\nSee also\n\nRestoring management database with the compute cluster",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/restoring-management-database.html"
    },
    {
        "title": "Managing admin panel users",
        "content": "Managing admin panel users\nDuring the primary node deployment, the unique Default domain is created along with the default user account and project:\n\nThe default administrator account is created with the unique Superuser permission. The user name for this account is admin and the password is specified during the primary node deployment. This account cannot be deleted or disabled and its permissions cannot be changed. Other than that, admin does not differ from a user who is assigned the System administrator role.\nThe default admin project is a bootstrap project for initializing the compute cloud. It cannot be deleted or renamed.\n\nThe Default domain with system users and projects is used by the system for different services. System entities are marked with the System tag and cannot be modified or deleted. \nDue to security concerns, you might want to create other system administrators with different permissions to manage the infrastructure. For example, you can create system administrators that are able to monitor the cluster performance and parameters, but cannot change any settings. \nOther users such as domain administrators and project members have access only to the self-service panel and are required to provision multitenant compute resources.\nLimitations\n\nSystem administrators can be created only within the Default domain.\n\nTo create a system administrator\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the Default domain.\nGo to the Domain users tab, and then click Create user.\n\nIn the Create user window, specify the user name, password, and, if required, a user email address and description. The user name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nSelect the System administrator role.\n\nSelect the permissions to be granted to the user account from the System permission set section:\n\nFull (System administrator): has all permissions and can perform all management operations, including creating projects and managing other users.\nCompute: can create and manage the compute cluster.\nISCSI: can create and manage iSCSI targets, LUNs, and CHAP users.\nS3: can create and manage the S3 cluster.\nABGW: can create and manage the Backup Gateway cluster.\nNFS: can create and manage NFS shares and exports.\nCluster: can create the storage cluster, join nodes to it, and manage (assign and release) disks.\nNetwork: can modify networks and traffic types.\nUpdate: can install updates.\nSSH: can add and remove SSH keys for cluster nodes access.\n\nThe view permission is always enabled.\n\nEnable the full Domain permissions set to allow the user to manage virtual objects in all projects within the Default domain and other users in the self-service panel.\n\nEnable Image uploading to allow the user to upload images.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra domain user create [--email <email>] [--description <description>]\r\n                          [--system-permissions <system_permissions>]\r\n                          [--enable | --disable] --domain <domain> <name>\r\n\n\n--email <email>\n\nUser email\n--description <description>\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--system-permissions <system_permissions>\n\nA comma-separated list of system permissions. View the list of available system permissions using vinfra domain user list-available-roles | grep system.\n--enable\n\nEnable user\n--disable\n\nDisable user\n--domain <domain>\n\nDomain name or ID\n<name>\n\nUser name\n\nFor example, to create a system administrator account called mysysadmin within the domain Default, to manage the compute cluster, run:# vinfra domain user create mysysadmin --domain Default --system-permissions compute\r\n\nSpecify the user password when prompted.\nThe created system administrator will appear in the vinfra domain user list output:# vinfra domain user list --domain Default\r\n+----------------------------------+-----------------------+-------+---------+-------------+--------------------+-------------------+\r\n| id                               | name                  | email | enabled | description | domain_permissions | assigned_projects |\r\n+----------------------------------+-----------------------+-------+---------+-------------+--------------------+-------------------+\r\n| 1d207818a205433fabb85d68ff8bd45a | nova                  |       | True    |             | []                 | []                |\r\n| 1eb4cd6272d84d0a824877a8afe16269 | heat                  |       | True    |             | []                 | []                |\r\n| 4ae74e324e7241139e1357c9ce65f0b1 | backup-service-user   |       | False   |             | []                 | []                |\r\n| 4e7db09ec1794aff92cbac0a70159478 | gnocchi               |       | True    |             | []                 | []                |\r\n| 8d54115532ee421a8551ab32910998ad | octavia               |       | True    |             | []                 | []                |\r\n| 8fd6757e10494c399cd8445dd8c83c87 | barbican              |       | True    |             | []                 | []                |\r\n| 9e462afe59a742049970bdbb902569d1 | neutron               |       | True    |             | []                 | []                |\r\n| a2c7eda0ea5a45749d0af7742ace85b0 | glance                |       | True    |             | []                 | []                |\r\n| a91aa030575c474f9753abda3bf7afa0 | cinder                |       | True    |             | []                 | []                |\r\n| c727a901a6444ee1a8ad31e3d5b53b3a | admin                 |       | True    |             | []                 | []                |\r\n| ca92d0b41f354a6882f24e0eb101b4ea | vstorage-service-user |       | True    |             | []                 | []                |\r\n| e03bf89a89ef4a018dbf5aae107beed8 | mysysadmin            |       | True    |             | []                 | []                |\r\n| ed4b3f0b6e61470ba0b79662671679f6 | ceilometer            |       | True    |             | []                 | []                |\r\n| f62f123df20c4b388fefebf058fb185c | placement             |       | True    |             | []                 | []                |\r\n+----------------------------------+-----------------------+-------+---------+-------------+--------------------+-------------------+\r\n\n\nTo change the password\n\nAdmin panel\n\n In the top right corner of the admin panel, click the user icon, and then click Change password.\nIn the Change password window, enter the current password and enter a new password twice.\nClick Save.\n\nCommand-line interface\n\nFor the default administrator account, use the following command:vinfra cluster user change-password\nWhen prompted, enter the current and a new password, and then repeat the new password for confirmation.\n\nFor other accounts, us the following command:vinfra domain user set [--password] --domain <domain> <user>\r\n\n\n--password\n\nRequest the password from stdin\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to change the password for the system administrator mysysadmin, run:# vinfra domain user set mysysadmin --domain Default --password\nWhen prompted, enter a new password, which will replace the old one.\n\nSee also\n\nResetting the admin user password\n\nManaging domain groups\n\nManaging self-service users\n\nUnlocking user accounts",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user create [--email <email>] [--description <description>]\r\n                          [--system-permissions <system_permissions>]\r\n                          [--enable | --disable] --domain <domain> <name>\r\n\n\n--email <email>\n\nUser email\n--description <description>\n\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--system-permissions <system_permissions>\n\nA comma-separated list of system permissions. View the list of available system permissions using vinfra domain user list-available-roles | grep system.\n--enable\n\nEnable user\n--disable\n\nDisable user\n--domain <domain>\n\nDomain name or ID\n<name>\n\nUser name\n\nFor example, to create a system administrator account called mysysadmin within the domain Default, to manage the compute cluster, run:# vinfra domain user create mysysadmin --domain Default --system-permissions compute\r\n\nSpecify the user password when prompted.\nThe created system administrator will appear in the vinfra domain user list output:# vinfra domain user list --domain Default\r\n+----------------------------------+-----------------------+-------+---------+-------------+--------------------+-------------------+\r\n| id                               | name                  | email | enabled | description | domain_permissions | assigned_projects |\r\n+----------------------------------+-----------------------+-------+---------+-------------+--------------------+-------------------+\r\n| 1d207818a205433fabb85d68ff8bd45a | nova                  |       | True    |             | []                 | []                |\r\n| 1eb4cd6272d84d0a824877a8afe16269 | heat                  |       | True    |             | []                 | []                |\r\n| 4ae74e324e7241139e1357c9ce65f0b1 | backup-service-user   |       | False   |             | []                 | []                |\r\n| 4e7db09ec1794aff92cbac0a70159478 | gnocchi               |       | True    |             | []                 | []                |\r\n| 8d54115532ee421a8551ab32910998ad | octavia               |       | True    |             | []                 | []                |\r\n| 8fd6757e10494c399cd8445dd8c83c87 | barbican              |       | True    |             | []                 | []                |\r\n| 9e462afe59a742049970bdbb902569d1 | neutron               |       | True    |             | []                 | []                |\r\n| a2c7eda0ea5a45749d0af7742ace85b0 | glance                |       | True    |             | []                 | []                |\r\n| a91aa030575c474f9753abda3bf7afa0 | cinder                |       | True    |             | []                 | []                |\r\n| c727a901a6444ee1a8ad31e3d5b53b3a | admin                 |       | True    |             | []                 | []                |\r\n| ca92d0b41f354a6882f24e0eb101b4ea | vstorage-service-user |       | True    |             | []                 | []                |\r\n| e03bf89a89ef4a018dbf5aae107beed8 | mysysadmin            |       | True    |             | []                 | []                |\r\n| ed4b3f0b6e61470ba0b79662671679f6 | ceilometer            |       | True    |             | []                 | []                |\r\n| f62f123df20c4b388fefebf058fb185c | placement             |       | True    |             | []                 | []                |\r\n+----------------------------------+-----------------------+-------+---------+-------------+--------------------+-------------------+\r\n\n",
                "title": "To create a system administrator"
            },
            {
                "example": "\nCommand-line interface\n\n\nFor the default administrator account, use the following command:vinfra cluster user change-password\nWhen prompted, enter the current and a new password, and then repeat the new password for confirmation.\n\n\nFor other accounts, us the following command:vinfra domain user set [--password] --domain <domain> <user>\r\n\n\n--password\n\nRequest the password from stdin\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to change the password for the system administrator mysysadmin, run:# vinfra domain user set mysysadmin --domain Default --password\nWhen prompted, enter a new password, which will replace the old one.\n\n\n",
                "title": "To change the password"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the Default domain.\nGo to the Domain users tab, and then click Create user.\n\nIn the Create user window, specify the user name, password, and, if required, a user email address and description. The user name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\nSelect the System administrator role.\n\nSelect the permissions to be granted to the user account from the System permission set section:\n\nFull (System administrator): has all permissions and can perform all management operations, including creating projects and managing other users.\nCompute: can create and manage the compute cluster.\nISCSI: can create and manage iSCSI targets, LUNs, and CHAP users.\nS3: can create and manage the S3 cluster.\nABGW: can create and manage the Backup Gateway cluster.\nNFS: can create and manage NFS shares and exports.\nCluster: can create the storage cluster, join nodes to it, and manage (assign and release) disks.\nNetwork: can modify networks and traffic types.\nUpdate: can install updates.\nSSH: can add and remove SSH keys for cluster nodes access.\n\n\nThe view permission is always enabled.\n\n\n\nEnable the full Domain permissions set to allow the user to manage virtual objects in all projects within the Default domain and other users in the self-service panel.\n\n\nEnable Image uploading to allow the user to upload images.\n\nClick Create.\n\n\n\n\n\n",
                "title": "To create a system administrator"
            },
            {
                "example": "\nAdmin panel\n\n In the top right corner of the admin panel, click the user icon, and then click Change password.\nIn the Change password window, enter the current password and enter a new password twice.\nClick Save.\n\n",
                "title": "To change the password"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-admin-panel-users.html"
    },
    {
        "title": "Aggregating provisioned memory",
        "content": "Aggregating provisioned memoryPOST /v1/aggregates?details=False&needed_overlap=0.0&start={start_date}&stop={stop_date}\r\n\nAggregate the amount of provisioned memory per project for a specific period of time.\n\nIf the start or stop date is not specified, the missing value will be set to the first or last timestamp common across the time series.\n\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\noperation\n\nbody\nstring\nOperations to apply to the time series. For aggregation across metrics, use the following syntax: aggregate <aggregation_method> ((metric <metric_id> <aggregation_method>), ...). Supported aggregation methods are: mean, median, std, min, max, sum, var, count.\n\nsearch\n\nbody\nstring\nA query to filter resources. The syntax includes an attribute, operator, and value. For example, the query id=90d58eea-70d7-4294-a49a-170dcdf44c3c will filter a resource with the specified ID. You can use more complex queries, for example, not (flavor_id!=\u00e2\u0080\u009d1\u00e2\u0080\u009d and memory>=24). Use \u00e2\u0080\u009c\u00e2\u0080\u009d to interpret data as a string. Supported operators are: not, and, \u00e2\u0088\u00a7 or, \u00e2\u0088\u00a8, >=, <=, !=, >, <, =, ==, eq, ne, lt, gt, ge, le, in, like, \u00e2\u0089\u00a0, \u00e2\u0089\u00a5, \u00e2\u0089\u00a4, like, in.\n\nresource_type\n\nbody\nstring\n\nA resource type that a metric is associated with. For example, these metrics are bound to:\n\nvCPU and RAM metrics\u00e2\u0080\u0094the instance resource type\nStorage metrics\u00e2\u0080\u0094the volume resource type\nFloating IP addresses\u00e2\u0080\u0094the network resource type\nLoad balancers\u00e2\u0080\u0094the loadbalancer resource type\nKubernetes clusters\u00e2\u0080\u0094the coe_cluster resource type\n\nExample\nAggregate the amount of provisioned memory for the project with the ID 75521ab61d1f4e9090aac5836c219492 from 12:00 PM July 18, 2021, to 12:00 PM July 19, 2021.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"operations\":\"(aggregate sum (metric memory mean))\",\r\n    \"search\":\"project_id=75521ab61d1f4e9090aac5836c219492\",\r\n    \"resource_type\":\"instance\"\r\n}' https://<node_IP_addr>:8041/v1/aggregates?details=False&needed_overlap=0.0&\\\r\nstart=2021-07-18T12:00:00&stop=2021-07-19T12:00:00\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nmeasures\n\nbody\nstring\nA list of measures for a metric.\n\naggregated\n\nbody\narray\nA number of aggregates, each consisting of a timestamp, granularity, and value.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"measures\": {\r\n    \"aggregated\": [\r\n      [\r\n        \"2021-07-18T12:00:00+00:00\",\r\n        300.0,\r\n        12288.0\r\n      ],\r\n      <...>\r\n      [\r\n        \"2021-07-19T11:00:00+00:00\",\r\n        300.0,\r\n        12288.0\r\n      ] \r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/aggregating-provisioned-memory.html"
    },
    {
        "title": "4.1. Activating Module HostBill\u00c2\u00b6",
        "content": "4.1. Activating Module HostBill | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n4.1. Activating Module HostBill\u00c2\u00b6\nThe module is included with the \u00e2\u0080\u009cAll Inclusive\u00e2\u0080\u009d HostBill License. If this is the case you can download it from your client portal. Alternatively, you can purchase the module from HostBill\u00e2\u0080\u0099s market place (one-time fee $99).\nAfter downloading the module, extract the module in the main HostBill directory then go to Settings > Modules > Hosting Modules and activate the BitNinja module.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/hostbill-bitninja/activating-module.html"
    },
    {
        "title": "Configuring compute parameters",
        "content": "Configuring compute parameters\nAfter deploying the compute cluster, you may want to configure the OpenStack command-line client, custom parameters in the OpenStack configuration files, default quotas for projects, RAM and CPU reservations for virtual machines, and other features.\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-compute-parameters.html"
    },
    {
        "title": "Configuration examples",
        "content": "Configuration examples\n\nBackups and cold storage. The aim is to maximize performance of sequential workloads. CPU, RAM, and network latency are not as important as the number of HDDs and their IOPS capabilities. Use erasure coding to decrease overall cost.\nHot storage and compute. The aim is to minimize latency. Use NVMe disks, an RDMA network, fast CPU and RAM, and replication for better performance.\nDatabases. The aim is to maximize performance of random workloads. Use NVMe or fast SSD disks, an RDMA network, and consider using no redundancy if an application has built-in replication capabilities.\n\nSee also\n\nStorage cluster best practices\n\nLimiting performance\n\nTroubleshooting performance issues",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuration-examples.html"
    },
    {
        "title": "Troubleshooting node disks",
        "content": "Troubleshooting node disks\nThe S.M.A.R.T. status of all disks is monitored by the smartctl tool installed along with Virtuozzo Hybrid Infrastructure. Run every 10 minutes, the tool polls all disks attached to nodes, including journaling SSDs and system disks, and reports the results to the management node. The tool checks disk health according to S.M.A.R.T. attributes. If it finds a disk in the pre-failure condition, it generates an alert. The pre-failure condition means that at least one of these S.M.A.R.T. attributes is not zero:\n\nReallocated Sector Count\nReallocated Event Count\nCurrent Pending Sector Count\nUncorrectable Sector Count\n\nAdditionally, slow disk and CS analyzers calculate disk health according to the average I/O latency over time. When the disk I/O latency reaches the predefined threshold, the disk health is considered to be 0%. In this case, an alert is generated and the disk is marked as unresponsive.\nLimitations\n\nFor the S.M.A.R.T. tool to work, the S.M.A.R.T. functionality must be enabled in the node\u00e2\u0080\u0099s BIOS.\n\nPrerequisites\n\nA clear understanding of how disk health is calculated, described in Calculating disk health.\n\nTo troubleshoot an unresponsive disk\n\nGo to the Infrastructure > Nodes screen and click the name of a node that hosts an unresponsive storage disk.\nOn the Disks tab, click the storage disk, and then go to the Service tab, to view the warning message.\nCheck the disk connectivity, S.M.A.R.T. status, and dmesg output on the node.\n\nAfter fixing the issue, click Mark as healthy to change the disk status to Healthy. If however the problem persists, it is recommended to replace the disk before its failure. If you recover such a disk, it may decrease the cluster performance and increase I/O latency.\nTo troubleshoot a failed disk\n\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the name of a node that hosts a failed service.\nOn the Disks tab, click the failed disk, and then go to the Service tab, to view the error message.\nClick Get diagnostic information to investigate the smartctl and dmesg outputs.\n\nCommand-line interface\n\nFind out the device name of a failed disk on the node from the vinfra node disk list output:# vinfra node disk list --node node003\r\n+-------------+---------+------+--------+-------------+----------+----------+---------------+------------+----------------+\r\n| id          | device  | type | role   | disk_status | used     | size     | physical_size | service_id | service_status |\r\n+-------------+---------+------+--------+-------------+----------+----------+---------------+------------+----------------+\r\n| 36972905<\u00e2\u0080\u00a6> | nvme1n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1090       | failed         |\r\n| B9F2C34F<\u00e2\u0080\u00a6> | nvme0n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1091       | active         |\r\n| A8E05CCA<\u00e2\u0080\u00a6> | nvme2n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1086       | active         |\r\n| D6E421E0<\u00e2\u0080\u00a6> | nvme3n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1087       | active         |\r\n| md126       | md126   | ssd  | system | ok          | 364.2MiB | 989.9MiB | 1022.0MiB     |            |                |\r\n| md127       | md127   | ssd  | system | ok          | 104.4GiB | 187.1GiB | 190.2GiB      |            |                |\r\n+-------------+---------+------+--------+-------------+----------+----------+---------------+------------+----------------+\r\n\nOn the node node003, the storage disc nvme1n1 is reported as failed.\n\nInvestigate the smartctl and dmesg outputs for the failed disk. For example:# vinfra node disk show diagnostic-info --node node003 nvme1n1 -f yaml\r\n- command: smartctl --all /dev/nvme1n1\r\n  stdout: 'smartctl 7.1 2020-06-20 r5066 [x86_64-linux-3.10.0-1160.41.1.vz7.183.5]\r\n    (local build)\r\n  Copyright (C) 2002-19, Bruce Allen, Christian Franke, www.smartmontools.org\r\n\r\n  === START OF INFORMATION SECTION ===\r\n  Model Number:                       INTEL SSDPE2KX020T8\r\n  Serial Number:                      PHLJ9500032H2P0BGN\r\n  Firmware Version:                   VDV10131\r\n  PCI Vendor/Subsystem ID:            0x8086\r\n  IEEE OUI Identifier:                0x5cd2e4\r\n  Total NVM Capacity:                 2,000,398,934,016 [2.00 TB]\r\n  Unallocated NVM Capacity:           0\r\n  Controller ID:                      0\r\n  Number of Namespaces:               1\r\n  Namespace 1 Size/Capacity:          2,000,398,934,016 [2.00 TB]\r\n  Namespace 1 Formatted LBA Size:     512\r\n  Namespace 1 IEEE EUI-64:            5cd2e4 75b0070100\r\n  Local Time is:                      Fri Nov 26 13:32:44 2021 EET\r\n  Firmware Updates (0x02):            1 Slot\r\n  Optional Admin Commands (0x000e):   Format Frmw_DL NS_Mngmt\r\n  Optional NVM Commands (0x0006):     Wr_Unc DS_Mngmt\r\n  Maximum Data Transfer Size:         32 Pages\r\n  Warning  Comp. Temp. Threshold:     70 Celsius\r\n  Critical Comp. Temp. Threshold:     80 Celsius\r\n\r\n  Supported Power States\r\n  St Op     Max   Active     Idle   RL RT WL WT  Ent_Lat  Ex_Lat\r\n   0 +    25.00W       -        -    0  0  0  0        0       0\r\n\r\n  Supported LBA Sizes (NSID 0x1)\r\n  Id Fmt  Data  Metadt  Rel_Perf\r\n   0 +     512       0         2\r\n   1 -    4096       0         0\r\n\r\n  === START OF SMART DATA SECTION ===\r\n  SMART overall-health self-assessment test result: PASSED\r\n\r\n  SMART/Health Information (NVMe Log 0x02)\r\n  Critical Warning:                   0x00\r\n  Temperature:                        34 Celsius\r\n  Available Spare:                    99%\r\n  Available Spare Threshold:          10%\r\n  Percentage Used:                    5%\r\n  Data Units Read:                    550,835,698 [282 TB]\r\n  Data Units Written:                 720,479,182 [368 TB]\r\n  Host Read Commands:                 10,050,305,459\r\n  Host Write Commands:                20,760,365,218\r\n  Controller Busy Time:               1,968\r\n  Power Cycles:                       20\r\n  Power On Hours:                     13,405\r\n  Unsafe Shutdowns:                   16\r\n  Media and Data Integrity Errors:    0\r\n  Error Information Log Entries:      0\r\n  Warning  Comp. Temperature Time:    0\r\n  Critical Comp. Temperature Time:    0\r\n\r\n  Error Information (NVMe Log 0x01, max 64 entries)\r\n  No Errors Logged\r\n  '\r\n- command: dmesg --ctime --kernel --level=emerg,alert,crit,err,warn --facility=kern\r\n    | grep 'nvme1n1'\r\n  stdout: ''\n\nIf you cannot fix the problem, contact the technical support team, as described in Getting technical support.\nWhat's next\n\nReplacing node disks",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nFind out the device name of a failed disk on the node from the vinfra node disk list output:# vinfra node disk list --node node003\r\n+-------------+---------+------+--------+-------------+----------+----------+---------------+------------+----------------+\r\n| id          | device  | type | role   | disk_status | used     | size     | physical_size | service_id | service_status |\r\n+-------------+---------+------+--------+-------------+----------+----------+---------------+------------+----------------+\r\n| 36972905<\u00e2\u0080\u00a6> | nvme1n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1090       | failed         |\r\n| B9F2C34F<\u00e2\u0080\u00a6> | nvme0n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1091       | active         |\r\n| A8E05CCA<\u00e2\u0080\u00a6> | nvme2n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1086       | active         |\r\n| D6E421E0<\u00e2\u0080\u00a6> | nvme3n1 | ssd  | cs     | ok          | 1.5TiB   | 1.8TiB   | 1.8TiB        | 1087       | active         |\r\n| md126       | md126   | ssd  | system | ok          | 364.2MiB | 989.9MiB | 1022.0MiB     |            |                |\r\n| md127       | md127   | ssd  | system | ok          | 104.4GiB | 187.1GiB | 190.2GiB      |            |                |\r\n+-------------+---------+------+--------+-------------+----------+----------+---------------+------------+----------------+\r\n\nOn the node node003, the storage disc nvme1n1 is reported as failed.\n\n\nInvestigate the smartctl and dmesg outputs for the failed disk. For example:# vinfra node disk show diagnostic-info --node node003 nvme1n1 -f yaml\r\n- command: smartctl --all /dev/nvme1n1\r\n  stdout: 'smartctl 7.1 2020-06-20 r5066 [x86_64-linux-3.10.0-1160.41.1.vz7.183.5]\r\n    (local build)\r\n  Copyright (C) 2002-19, Bruce Allen, Christian Franke, www.smartmontools.org\r\n\r\n  === START OF INFORMATION SECTION ===\r\n  Model Number:                       INTEL SSDPE2KX020T8\r\n  Serial Number:                      PHLJ9500032H2P0BGN\r\n  Firmware Version:                   VDV10131\r\n  PCI Vendor/Subsystem ID:            0x8086\r\n  IEEE OUI Identifier:                0x5cd2e4\r\n  Total NVM Capacity:                 2,000,398,934,016 [2.00 TB]\r\n  Unallocated NVM Capacity:           0\r\n  Controller ID:                      0\r\n  Number of Namespaces:               1\r\n  Namespace 1 Size/Capacity:          2,000,398,934,016 [2.00 TB]\r\n  Namespace 1 Formatted LBA Size:     512\r\n  Namespace 1 IEEE EUI-64:            5cd2e4 75b0070100\r\n  Local Time is:                      Fri Nov 26 13:32:44 2021 EET\r\n  Firmware Updates (0x02):            1 Slot\r\n  Optional Admin Commands (0x000e):   Format Frmw_DL NS_Mngmt\r\n  Optional NVM Commands (0x0006):     Wr_Unc DS_Mngmt\r\n  Maximum Data Transfer Size:         32 Pages\r\n  Warning  Comp. Temp. Threshold:     70 Celsius\r\n  Critical Comp. Temp. Threshold:     80 Celsius\r\n\r\n  Supported Power States\r\n  St Op     Max   Active     Idle   RL RT WL WT  Ent_Lat  Ex_Lat\r\n   0 +    25.00W       -        -    0  0  0  0        0       0\r\n\r\n  Supported LBA Sizes (NSID 0x1)\r\n  Id Fmt  Data  Metadt  Rel_Perf\r\n   0 +     512       0         2\r\n   1 -    4096       0         0\r\n\r\n  === START OF SMART DATA SECTION ===\r\n  SMART overall-health self-assessment test result: PASSED\r\n\r\n  SMART/Health Information (NVMe Log 0x02)\r\n  Critical Warning:                   0x00\r\n  Temperature:                        34 Celsius\r\n  Available Spare:                    99%\r\n  Available Spare Threshold:          10%\r\n  Percentage Used:                    5%\r\n  Data Units Read:                    550,835,698 [282 TB]\r\n  Data Units Written:                 720,479,182 [368 TB]\r\n  Host Read Commands:                 10,050,305,459\r\n  Host Write Commands:                20,760,365,218\r\n  Controller Busy Time:               1,968\r\n  Power Cycles:                       20\r\n  Power On Hours:                     13,405\r\n  Unsafe Shutdowns:                   16\r\n  Media and Data Integrity Errors:    0\r\n  Error Information Log Entries:      0\r\n  Warning  Comp. Temperature Time:    0\r\n  Critical Comp. Temperature Time:    0\r\n\r\n  Error Information (NVMe Log 0x01, max 64 entries)\r\n  No Errors Logged\r\n  '\r\n- command: dmesg --ctime --kernel --level=emerg,alert,crit,err,warn --facility=kern\r\n    | grep 'nvme1n1'\r\n  stdout: ''\n\n\n",
                "title": "To troubleshoot a failed disk"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the name of a node that hosts a failed service.\nOn the Disks tab, click the failed disk, and then go to the Service tab, to view the error message.\nClick Get diagnostic information to investigate the smartctl and dmesg outputs.\n\n",
                "title": "To troubleshoot a failed disk"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/troubleshooting-node-disks.html"
    },
    {
        "title": "Accessing cluster information objects via SNMP",
        "content": "Accessing cluster information objects via SNMP\nYou can access cluster information objects with SNMP tools of your choice, for example, the free Net-SNMP suite for Linux.\nPrerequisites\n\nThe SNMP access is enabled, as described in Enabling SNMP access.\n\nTo obtain storage cluster information on the management node\nPlace the MIB file in /usr/share/snmp/mibs and run the snmpwalk command. For example:# snmpwalk  -M /usr/share/snmp/mibs -m VSTORAGE-MIB -v 2c -c public localhost:161 VSTORAGE-MIB:cluster\r\n\nTypical output may look like the following:VSTORAGE-MIB::clusterName.0 = STRING: \"cluster1\"VSTORAGE-MIB::healthStatus.0 = STRING: \"healthy\"VSTORAGE-MIB::usedLogicalSpace.0 = Counter64: 173732322VSTORAGE-MIB::totalLogicalSpace.0 = Counter64: 1337665179648VSTORAGE-MIB::freeLogicalSpace.0 = Counter64: 1318963253248VSTORAGE-MIB::licenseStatus.0 = STRING: \"unknown\"VSTORAGE-MIB::licenseCapacity.0 = Counter64: 1099511627776VSTORAGE-MIB::licenseExpirationStatus.0 = STRING: \"None\"VSTORAGE-MIB::ioReadOpS.0 = Counter64: 0VSTORAGE-MIB::ioWriteOpS.0 = Counter64: 0VSTORAGE-MIB::ioReads.0 = Counter64: 0VSTORAGE-MIB::ioWrites.0 = Counter64: 0VSTORAGE-MIB::csActive.0 = Counter64: 11VSTORAGE-MIB::csTotal.0 = Counter64: 11VSTORAGE-MIB::mdsAvail.0 = Counter64: 4VSTORAGE-MIB::mdsTotal.0 = Counter64: 4<...>\r\n\nSee also\n\nCluster objects and traps\n\nListening to SNMP traps\n\nMonitoring the cluster with Zabbix",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/accessing-cluster-information-objects-via-snmp.html"
    },
    {
        "title": "4.1. Backing Up Virtual Machines\u00c2\u00b6",
        "content": "4.1. Backing Up Virtual Machines | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n4.1. Backing Up Virtual Machines\u00c2\u00b6\nTo backup virtual machines, you will need to:\n\nRemove VMware Tools and install Virtuozzo Guest Tools in the virtual machines.\nCreate a protection plan with the Backup module enabled. It is a set of rules that specify how the given data will be protected on a given machine. A protection plan can be applied to multiple machines at the time of its creation, or later.\n\nTo create the first protection plan with the Backup module enabled, select the machines that you want to back up and click Protect.\nThe software will display protection plans that are applied to the machine. If the machine does not have any plans assigned to it, you will see the default protection plan that can be applied. You can adjust the settings as needed and apply this plan or create a new one.\nTo create a new plan:\n\nClick Create plan. Enable the Backup module and unroll the settings.\n\n(Optional) To modify the protection plan name, click the default name.\n(Optional) To modify the Backup module parameters, click the corresponding setting of the protection plan panel.\n(Optional) To modify the backup options, click Change next to them.\nClick Create.\n\nTo apply an existing protection plan:\n\nSelect the machines that you want to back up and click Protect. If a common protection plan is already applied to the selected machines, click Add plan. The software will display the previously created protection plans.\n\nSelect a protection plan to apply.\nClick Apply and wait until the backup procedure is complete.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/migrating-virtual-machines/backing-up-virtual-machines.html"
    },
    {
        "title": "Changing the TLS configuration for S3",
        "content": "Changing the TLS configuration for S3\nTo filter connections to the object storage service, an administrator can configure allowed TLS protocol versions and ciphers. By default, only TLS protocol version 1.2 is accepted for connections to the S3 cluster. Moreover, only the following ciphers are allowed:\n\nECDHE-ECDSA-AES128-GCM-SHA256\nECDHE-RSA-AES128-GCM-SHA256\nDHE-RSA-AES128-GCM-SHA256\nECDHE-ECDSA-AES256-GCM-SHA384\nECDHE-RSA-AES256-GCM-SHA384\nECDHE-RSA-AES128-SHA256\nDHE-RSA-AES128-SHA256\nAES128-GCM-SHA256\n\nThese options are automatically applied to all S3 clusters running Virtuozzo Hybrid Infrastructure 6.2, even if a cluster was created in an earlier version.\n\nAfter changing the allowed TLS ciphers, you may need to regenerate certificates.\n\nIf a client has none of the specified ciphers, the connection will fail and the client will not be able to reach the service. \n\nPrerequisites\n\nThe S3 cluster is created, as described in Creating the S3 cluster.\n\nTo accept connections to object storage with TLS 1.0 and 1.1 protocols\n\nSpecify the required TLS protocols, space-separated, in the OSTOR_S3_GW_CUSTOM_SSL_PROTOCOLS parameter in the configuration file /usr/libexec/vstorage-ui-backend/etc/backend.cfg on each management node. For more details on this parameter, refer to the nginx documentation. For example, to enable TLS 1.1 used in earlier versions,  specify:OSTOR_S3_GW_CUSTOM_SSL_PROTOCOLS = 'TLSv1.1 TLSv1.2'\n\nRestart the backend service:# systemctl restart vstorage-ui-backend\n\nIn the admin panel, go to the Storage services > S3 > Nodes screen, click Protocol settings, and then click Done to apply your changes.\n\nTo accept customer ciphers in object storage\n\nSpecify the required ciphers, separated by colons, in the OSTOR_S3_GW_CUSTOM_SSL_CIPHERS parameter in the configuration file /usr/libexec/vstorage-ui-backend/etc/backend.cfg on each management node. For more details on this parameter, refer to the nginx documentation. For example, to enable ciphers used in earlier versions, specify the following:OSTOR_S3_GW_CUSTOM_SSL_CIPHERS = 'HIGH:!3DES:!RC4:!aNULL:!MD5:!kEDH'\n\nRestart the backend service:# systemctl restart vstorage-ui-backend\n\nIn the admin panel, go to the Storage services > S3 > Nodes screen, click Protocol settings, and then click Done to apply your changes.\n\nSee also\n\nSupported Amazon S3 features\n\nManaging S3 users\n\nManaging S3 buckets\n\nMonitoring object storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-tls-configuration-for-s3.html"
    },
    {
        "title": "Changing the default load balancer image",
        "content": "Changing the default load balancer image\nBy default, a load balancer is created by using the amphora image that is automatically added to the compute cluster when you enable the load balancing service. You can change the default image by creating a new one via the vinfra tool.\nTo change the default load balancer image\n\nAdd a new amphora image to the compute cluster and specify a tag for it. For example, to create the myamphora image from the myamphora.qcow2 file with the custom_amphora tag, run:# vinfra service compute image create myamphora --file myamphora.qcow2 --tags custom_amphora\r\n\n\nReconfigure the load balancing service to use the new image by default. For example, to use the image with the custom_amphora tag, run:# vinfra service compute lbaas configure --amp-image-tag custom_amphora\n\nOnce the load balancing service is reconfigured, new load balancers will be created from the myamphora image.\nSee also\n\nManaging balancing pools\n\nChanging load balancer resources\n\nCreating custom load balancer flavors",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-the-default-load-balancer-image.html"
    },
    {
        "title": "Provisioning object storage space",
        "content": "Provisioning object storage space\nObject storage space is provisioned via S3 buckets created in the S3 cluster.\nLimitations\n\nOnly one S3 cluster can be created on top of the storage cluster.\n\nAll components of the S3 cluster should run on multiple nodes for high availability. Name server and object server components in the S3 cluster are automatically balanced and migrated between S3 nodes. S3 gateways are not automatically migrated; their high availability is based on load balancing.\nWe recommend using an external load balancer to balance traffic between S3 nodes with gateways. The external load balancer must support session persistence (also called sticky sessions) based on the source IP address and SSL certificate management.\nDNS load balancing can be used for test purposes only. For production, use an external load balancer.\n\nPrerequisites\n\nA clear understanding of object storage, which is explained in About object storage.\nYour hardware meets the requirements listed in Object storage requirements.\nYour infrastructure networks are set up, as described in Setting up networks for object storage.\nThe storage cluster is created by following the instructions in Deploying the storage cluster.\nDomains, projects, and users are created, as described in Configuring multitenancy.\nYou have access to the self-service panel configured, as outlined in Providing access to the self-service portal.\nThe nodes that will run the S3 services are available in Virtuozzo Hybrid Infrastructure.\n\nProvisioning overview\n\nCreate the S3 cluster.\nTo manage S3 resources in the self-service panel, enable S3 access for the self service, log in there at http://<admin_panel_IP_address>:8800 as a self-service user, and then proceed to create S3 buckets, as described in Managing S3 resources in the Self-Service Guide.\nTo manage S3 resources in the legacy user panel or by using a third-party application (such as Cyberduck and Mountain Duck), add S3 users, and then proceed to create S3 buckets, as described in Accessing S3 buckets in the Storage User\u00e2\u0080\u0099s Guide.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-object-storage.html"
    },
    {
        "title": "Managing virtual machines in placements",
        "content": "Managing virtual machines in placements\nA virtual machine is assigned a placement when it is created from an image or flavor with the placement assigned. A VM can also inherit a placement from a volume created with an assigned image. However, a VM does not inherit the placement and changes to it from the node. For example, if you assign a placement to a node with existing VMs, only the node will have the placement. The VMs will not inherit the same placement. Likewise, if you have a node and VMs on it assigned to the same placement, and you delete such a node from a placement, only the node will change the placement. The VMs on it will still keep the original placement.\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\nPlacements for compute nodes are created, as described in Creating placements.\nThe node and VMs hosted on it have the same placement configuration.\n\nTo edit the VM placement\nUse the following command:vinfra service compute server set [--no-placements |--placement placement] <server>\r\n\n\n--no-placements\n\nClean up placements from the virtual machine.\n--placement placement\n\nPlacement name or ID to add the virtual machine to. Specify this option multiple times to add the virtual machine to multiple placements.\n<server>\n\nVirtual machine ID or name\n\nFor example, to remove all placement assignments from the virtual machine myvm, run:# vinfra service compute server set myvm --no-placements\r\n\nSee also\n\nMigrating virtual machines\n\nTroubleshooting virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-vms-in-placements.html"
    },
    {
        "title": "Managing infrastructure nodes",
        "content": "Managing infrastructure nodes\nThis section describes how to manage network interfaces and change their parameters, as well as connect remote iSCSI devices. ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-infrastructure-nodes.html"
    },
    {
        "title": "Deleting user quotas via CLI",
        "content": "Deleting user quotas via CLI\nYou can delete the current quotas per user with the rm-quotas command and the following parameters: -e specifying the email address or -i specifying the user ID:# ostor-s3-admin rm-quotas -e user@example.com -V 0100000000000002\r\nsuccessfully removed quotas# ostor-s3-admin rm-quotas -i fa153230721eed05 -V 0100000000000002\r\nsuccessfully removed quotas",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-user-quotas-via-cli.html"
    },
    {
        "title": "Deleting user quotas via REST API",
        "content": "Deleting user quotas via REST API\nYou can delete the current quotas per user with the ostor-quotas service and parameter emailAddress specifying the email address:# s3_curl DELETE \"http://s3.example.com/?ostor-quotas&emailAddress=user@example.com\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-user-quotas-via-rest-api.html"
    },
    {
        "title": "Providing access to the self-service portal",
        "content": "Providing access to the self-service portal\nThe self-service panel is a web-based control panel that allows end users to manage compute and S3 resources in isolated administrative environments.\nLimitations\n\nThe default system administrator cannot log in to the self-service portal.\n\nPrerequisites\n\nThe storage cluster is created, as described in Deploying the storage cluster.\nSelf-service projects and users are created, as described in Configuring multitenancy.\n\nTo be able to access the self-service panel\n\nAdmin panel\nOpen TCP port 8800 on the management node by doing the following:\n\nOn the Infrastructure > Networks screen, click Edit.\nAdd the Self-service panel traffic type to your public network by selecting the corresponding check box.\nClick Save to apply changes.\n\nYou can now access the self-service panel at http://<admin_panel_IP_address>:8800. Use the domain name and user credentials to log in. If high availability for the management node is enabled, log in into the self-service panel by using the virtual address for the admin panel: http://<admin_panel_virtual_IP_address>:8800. You can also use the link in the Panel URLs field on the Settings > System settings > Self-service portal screen.\n\nCommand-line interface\nOpen TCP port 8800 on the management node by adding the Self-service panel traffic type to your public network. For example, run:# vinfra cluster network set Public --add-traffic-types \"Self-service panel\"\nYou can now access the self-service panel at http://<admin_panel_IP_address>:8800. Use the domain name and user credentials to log in. If high availability for the management node is enabled, log in into the self-service panel by using the virtual address for the admin panel: http://<admin_panel_virtual_IP_address>:8800.\n\nSee also\n\nConfiguring the self-service panel\n\nWhat's next\n\nProvisioning compute resources\n\nProvisioning object storage space",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nOpen TCP port 8800 on the management node by adding the Self-service panel traffic type to your public network. For example, run:# vinfra cluster network set Public --add-traffic-types \"Self-service panel\"\nYou can now access the self-service panel at http://<admin_panel_IP_address>:8800. Use the domain name and user credentials to log in. If high availability for the management node is enabled, log in into the self-service panel by using the virtual address for the admin panel: http://<admin_panel_virtual_IP_address>:8800.\n",
                "title": "To be able to access the self-service panel"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nOpen TCP port 8800 on the management node by doing the following:\n\nOn the Infrastructure > Networks screen, click Edit.\nAdd the Self-service panel traffic type to your public network by selecting the corresponding check box.\nClick Save to apply changes.\n\nYou can now access the self-service panel at http://<admin_panel_IP_address>:8800. Use the domain name and user credentials to log in. If high availability for the management node is enabled, log in into the self-service panel by using the virtual address for the admin panel: http://<admin_panel_virtual_IP_address>:8800. You can also use the link in the Panel URLs field on the Settings > System settings > Self-service portal screen.\n\n\n\n\n",
                "title": "To be able to access the self-service panel"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/providing-access-to-the-self-service-portal.html"
    },
    {
        "title": "\u00d0\u00a1luster rebuilding",
        "content": "\u00d0\u00a1luster rebuilding\nThe storage cluster is self-healing. If a node or disk fails, a cluster will automatically try to restore the lost data, that is,  rebuild itself.\nRebuilding prerequisites\nFor a cluster to be able to rebuild itself, it must have at least:\n\nAs many healthy nodes as required by the redundancy mode\n\nConsider the following example. In a cluster that works in the 5+2 erasure coding mode and has seven nodes (that is,  the minimum), each replica of user data is distributed to each of the 5+2 nodes for redundancy. If one or two nodes fail, the user data will not be lost, but the cluster will become degraded and will not be able to rebuild itself until at least seven nodes are healthy again (until you add the missing nodes). For comparison, in a cluster that works in the 5+2 erasure coding mode and has ten nodes, each replica of user data is distributed to the random 5+2 nodes out of ten, to even out the load on CSes. If up to three nodes fail, such a cluster will still have enough nodes to rebuild itself.\n\nEnough free space to accommodate as much data as any one node can store\n\nConsider the following example. In a cluster that has ten 10 TB nodes, at least 1 TB on each node should be kept free, so if a node fails, its 9 TB of data can be rebuilt on the remaining nine nodes. If, however, a cluster has ten 10 TB nodes and one 20 TB node, each smaller node should have at least 2 TB free in case the largest node fails (while the largest node should have 1 TB free).\n\nRebuilding process\nThe rebuilding process consists of several steps. Every CS sends a heartbeat message to an MDS every 5 seconds. If a heartbeat is not sent, the CS is considered inactive and the MDS informs all cluster components that they stop requesting operations on its data. If no heartbeats are received from a CS for 15 minutes, the MDS considers that CS offline and starts cluster rebuilding. In the process, the MDS finds CSes that do not have replicas of the lost data and restores the data\u00e2\u0080\u0094one replica at a time\u00e2\u0080\u0094as follows:\n\nIf replication is used, the existing replicas of a degraded chunk are locked (to make sure all replicas remain identical) and one is copied to the new CS. If at this time a client needs to read some data that has not been rebuilt yet, it reads any remaining replica of that data.\nIf erasure coding is used, the new CS requests almost all of the remaining data pieces to rebuild the missing ones. If at this time a client needs to read some data that has not yet been rebuilt, that data is rebuilt out of turn and then read.\n\nSelf-healing requires more network traffic and CPU resources if replication is used. On the other hand, rebuilding with erasure coding is slower.\n\nIf a node or disk goes offline during maintenance, cluster self-healing is delayed, to save cluster resources. The default delay is 30 minutes. You can adjust it by setting the mds.wd.offline_tout_mnt parameter, in milliseconds, with the vstorage -c <cluster_name> set-config command.\n\nRecommendations for cluster rebuilding \nTwo recommendations that help smooth out rebuilding overhead:\n\nTo simplify rebuilding, keep uniform disk counts and capacity sizes on all nodes.\nRebuilding places additional load on the network, and increases the latency of read and write operations. The more network bandwidth the cluster has, the faster rebuilding will be completed and bandwidth freed up.\n\nSee also\n\nData redundancy\n\nStorage policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/cluster-rebuilding.html"
    },
    {
        "title": "Creating a kickstart file",
        "content": "Creating a kickstart file\nVirtuozzo Hybrid Infrastructure uses the same kickstart file syntax as Red Hat Enterprise Linux.\nThe following sections describe the options and scripts you will need to include in your kickstart file, and provide an example you can start from.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-a-kickstart-file.html"
    },
    {
        "title": "Integration methods",
        "content": "Integration methods\nVirtuozzo Hybrid Infrastructure provides an orchestration representational state transfer (REST) API as well as an Amazon S3 compatible REST API.\nWith the orchestration API, you can manage users and buckets, configure user and bucket limits, and collect usage statistics. You can use the orchestration API by means of a single CLI tool shipped with Virtuozzo Hybrid Infrastructure.\nThe Amazon S3 compatible REST API also enables you to manage users and buckets, configure user and bucket limits, and collect usage statistics. The user model and access policies comply with those of Amazon S3.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/integration-methods.html"
    },
    {
        "title": "Editing and deleting identity providers",
        "content": "Editing and deleting identity providers\nFor an existing identity provider, you can change the configuration and grant type. You also can enable or disable an identity provider, thus allowing or prohibiting login for its federated users in the management panel. After deleting an identity provider, all of its federated users are removed along with it.\nPrerequisites\n\nIdentity providers are added to the admin panel, as described in Adding  identity providers.\n\nTo edit an identity provider\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Edit.\nMake the required changes, and then click Save.\n\nAfter modifying the identity provider parameters, all of its federated users will be logged out of the management panel.\n\nCommand-line interface\nUse the following command:vinfra domain idp set [--issuer <issuer>] [--scope <issuer>] [--metadata-url <metadata-url>]\r\n                      [--client-id <client-id>] [--client-secret <client-secret>]\r\n                      [--mapping <path>] [--verify-ssl | --dont-verify-ssl] [--request-timeout <seconds>]\r\n                      [--name <name>] --domain <domain> <idp>\n\n--issuer <issuer>\n\nIdentity provider issuer\n--scope <scope>\n\nScope that define what user identity data will be shared by the identity provider during authentication\n--metadata-url <metadata-url>\n\nMetadata URL of the identity provider's discovery endpoint\n--client-id <client-id>\n\nClient ID to access the identity provider\n--client-secret <client-secret>\n\nClient secret to access the identity provider\n--mapping <path>\n\nPath to the mapping configuration file.\nA mapping file may look as follows:# cat mapping.json\r\n[\r\n    {\r\n        \"local\": [\r\n            {\r\n                \"user\": {\r\n                    \"name\": \"{0}\"\r\n                },\r\n                \"group\": {\r\n                    \"name\":\"users\"\r\n                }\r\n            }\r\n        ],\r\n        \"remote\": [{\"type\": \"email\"}]\r\n    }\r\n]\nIn this example, all users that have the attribute email will be mapped to the group users within the default domain. For details on creating a mapping file, refer to the OpenStack documentation.\n\n--verify-ssl\n\nEnable identity provider endpoints SSL verification\n--dont-verify-ssl\n\nDisable identity provider endpoints SSL verification\n--request-timeout <seconds>\n\nIdentity provider API request timeout (default: 5)\n--name <name>\n\nA new name for the identity provider\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to change the mapping rules of the identity provider My ADFS within the mydomain domain by using the mapping file new_mapping.json, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --mapping new_mapping.json\nAfter modifying the identity provider parameters, all of its federated users will be logged out of the management panel.\n\nTo change the grant type\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Edit.\nIn the Grant types section, choose between Implicit Flow and Authorization Code Flow, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra domain idp set --response-type <response-type> --domain <domain> <idp>\n\n--response-type <response-type>\n\nResponse type to be used in the authorization flow: \n\ncode: use the Authorization Code Flow\nid_token: use the Implicit Flow\n\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to change the grant type of the identity provider My ADFS within the mydomain domain to the Authorization Code Flow, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --response-type code\nTo change the grant type to the Implicit Flow, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --response-type id_token\n\nTo enable or disable an identity provider\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Enable or Disable.\n\nCommand-line interface\nUse the following command:vinfra domain idp set [--enable] [--disable] --domain <domain> <idp>\n\n--enable\n\nEnable identity provider\n--disable\n\nDisable identity provider\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to disable the identity provider My ADFS within the mydomain, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --disable\n\nTo delete an identity provider\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra domain idp delete --domain <domain> <idp>\n\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to delete the identity provider My ADFS within the mydomain, run:# vinfra domain idp delete \"My ADFS\" --domain mydomain\n\nSee also\n\nSigning in through identity providers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain idp set [--issuer <issuer>] [--scope <issuer>] [--metadata-url <metadata-url>]\r\n                      [--client-id <client-id>] [--client-secret <client-secret>]\r\n                      [--mapping <path>] [--verify-ssl | --dont-verify-ssl] [--request-timeout <seconds>]\r\n                      [--name <name>] --domain <domain> <idp>\n\n--issuer <issuer>\n\nIdentity provider issuer\n--scope <scope>\n\nScope that define what user identity data will be shared by the identity provider during authentication\n--metadata-url <metadata-url>\n\nMetadata URL of the identity provider's discovery endpoint\n--client-id <client-id>\n\nClient ID to access the identity provider\n--client-secret <client-secret>\n\nClient secret to access the identity provider\n--mapping <path>\n\n\nPath to the mapping configuration file.\nA mapping file may look as follows:# cat mapping.json\r\n[\r\n    {\r\n        \"local\": [\r\n            {\r\n                \"user\": {\r\n                    \"name\": \"{0}\"\r\n                },\r\n                \"group\": {\r\n                    \"name\":\"users\"\r\n                }\r\n            }\r\n        ],\r\n        \"remote\": [{\"type\": \"email\"}]\r\n    }\r\n]\nIn this example, all users that have the attribute email will be mapped to the group users within the default domain. For details on creating a mapping file, refer to the OpenStack documentation.\n\n--verify-ssl\n\nEnable identity provider endpoints SSL verification\n--dont-verify-ssl\n\nDisable identity provider endpoints SSL verification\n--request-timeout <seconds>\n\nIdentity provider API request timeout (default: 5)\n--name <name>\n\nA new name for the identity provider\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to change the mapping rules of the identity provider My ADFS within the mydomain domain by using the mapping file new_mapping.json, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --mapping new_mapping.json\nAfter modifying the identity provider parameters, all of its federated users will be logged out of the management panel.\n",
                "title": "To edit an identity provider"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain idp set --response-type <response-type> --domain <domain> <idp>\n\n--response-type <response-type>\n\n\nResponse type to be used in the authorization flow: \n\ncode: use the Authorization Code Flow\nid_token: use the Implicit Flow\n\n\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to change the grant type of the identity provider My ADFS within the mydomain domain to the Authorization Code Flow, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --response-type code\nTo change the grant type to the Implicit Flow, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --response-type id_token\n",
                "title": "To change the grant type"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain idp set [--enable] [--disable] --domain <domain> <idp>\n\n--enable\n\nEnable identity provider\n--disable\n\nDisable identity provider\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to disable the identity provider My ADFS within the mydomain, run:# vinfra domain idp set \"My ADFS\" --domain mydomain --disable\n",
                "title": "To enable or disable an identity provider"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain idp delete --domain <domain> <idp>\n\n--domain <domain>\n\nDomain name or ID\n<idp>\n\nIdentity provider name or ID\n\nFor example, to delete the identity provider My ADFS within the mydomain, run:# vinfra domain idp delete \"My ADFS\" --domain mydomain\n",
                "title": "To delete an identity provider"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Edit.\nMake the required changes, and then click Save.\n\nAfter modifying the identity provider parameters, all of its federated users will be logged out of the management panel.\n",
                "title": "To edit an identity provider"
            },
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Edit.\nIn the Grant types section, choose between Implicit Flow and Authorization Code Flow, and then click Save.\n\n",
                "title": "To change the grant type"
            },
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Enable or Disable.\n\n",
                "title": "To enable or disable an identity provider"
            },
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, click the ellipsis icon next to the identity provider, and then click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete an identity provider"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/editing-and-deleting-identity-providers.html"
    },
    {
        "title": "Managing users and projects",
        "content": "Managing users and projects\nIn the self-service panel, a domain administrator can manage users and their assignment to projects within a domain. If granted the required permission, a domain administrator can also manage projects and their quotas.\nLimitations\n\nOnly domain administrators can manage users and projects.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-users-and-projects.html"
    },
    {
        "title": "Listing S3 users via REST API",
        "content": "Listing S3 users via REST API\nYou can list information about all users by sending a GET request to the ostor-users service. Additional rows may list S3 access key pairs associated with each user. For example:# s3_curl GET \"http://s3.example.com/?ostor-users\"\r\n[\r\n    {\r\n        \"UserEmail\": \"user@example.com\",\r\n        \"UserId\": \"a14040e0b2ef8b28\",\r\n        \"State\": \"enabled\",\r\n        \"OwnerId\": \"0000000000000000\"\r\n    },\r\n    {\r\n        \"UserEmail\": \"user@example.com\",\r\n        \"UserId\": \"ca55631f9f3d59dc\",\r\n        \"State\": \"enabled\",\r\n        \"OwnerId\": \"0000000000000000\"\r\n    }\r\n]\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/listing-s3-users-via-rest-api.html"
    },
    {
        "title": "Restoring virtual machines from backups",
        "content": "Restoring virtual machines from backups\nDuring the restore process, a new virtual machine is deployed and the existing VM is not overwritten. You can restore a VM from a backup of a boot volume only.\nPrerequisites\n\nA volume backup is created automatically, as described in Creating backup plans, or manually,  as described in Creating and deleting backups manually.\n\nTo restore a virtual machine\n\nOn the Recovery points screen, click the recovery point from which you want to restore a VM.\nOn the right pane, click Restore virtual machine.\n\nIn the Restore virtual machine window, the boot volume will be defined automatically and will be restored from the selected recovery point. Specify all other VM parameters, as described in Creating virtual machines.\n\nClick Deploy.\n\nThe new virtual machine will appear on the Virtual machines screen.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/restoring-virtual-machines-from-backups.html"
    },
    {
        "title": "Showing VPN service details",
        "content": "Showing VPN service detailsGET /v2.0/vpn/vpnservices/{service_id}\nShows details for a VPN service.\nIf the user does not have administrative rights and the VPN service does not belong to the user, the operation returns the 403 - Forbidden response code.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-vpn-service-details-detail#show-vpn-service-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nservice_id\n\npath\nstring\nThe ID of the VPN service.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/vpnservices/d6116b75-db78-4d07-9911-226b4655838a\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvpnservice\n\nbody\nobject\nA vpnservice object.\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec VPN service is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nexternal_v4_ip\n\nbody\nstring\nThe read-only external (public) IPv4 address that is used for the VPN service. The VPN plugin sets this address if an IPv4 interface is available.\n\nexternal_v6_ip\n\nbody\nstring\nThe read-only external (public) IPv6 address that is used for the VPN service. The VPN plugin sets this address if an IPv6 interface is available.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\nsubnet_id (Optional)\nbody\nstring\nIf you specify only a subnet UUID, the networking service allocates an available IP from that subnet to the port. If you specify both a subnet UUID and an IP address, the networking service tries to allocate the address to the port.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nflavor_id\n\nbody\nstring\nThe ID of the flavor.\n\nid\n\nbody\nstring\nThe ID of the VPN service.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"vpnservice\": {\r\n    \"id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n    \"name\": \"vpnservice\",\r\n    \"description\": \"\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"subnet_id\": null,\r\n    \"router_id\": \"923f2578-079e-40f1-b0a9-23c2b48dbdcd\",\r\n    \"flavor_id\": null,\r\n    \"admin_state_up\": true,\r\n    \"external_v4_ip\": \"10.136.18.148\",\r\n    \"external_v6_ip\": null,\r\n    \"status\": \"PENDING_CREATE\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-vpn-service-details.html"
    },
    {
        "title": "Creating and importing SSH keys",
        "content": "Creating and importing SSH keysPOST /os-keypairs\r\n\nGenerates or imports a key pair.\nSource: https://docs.openstack.org/api-ref/compute/index.html?expanded=create-or-import-keypair-detail#create-or-import-keypair\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nkeypairs\n\nbody\narray\nArray of keypair objects\n\nkeypair\n\nbody\nobject\nThe keypair object.\n\nname\n\nbody\nstring\nA name for the key pair which will be used to reference it later.\n\npublic_key (Optional)\nbody\nstring\nThe public ssh key to import. If you omit this value, a key pair is\r\ngenerated for you.\n\nuser_id (Optional)\nbody\nstring\n\nThe user ID for a key pair. This allows administrative users to\r\nupload keys for other users than themselves.\nNew in version 2.10\n\ntype (Optional)\nbody\nstring\n\nThe type of the key pair. Allowed values are ssh or x509.\nNew in version 2.2\n\nExample\nGenerate a key pair:# curl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"keypair\": {\r\n        \"name\": \"key2\"\r\n    }                \r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-keypairs\r\n\nImport a public key pair with an optional description in VSTOR-KEY-DESC:# curl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"keypair\": {\r\n        \"name\": \"key3\",\r\n        \"public_key\": \"ssh-rsa AAAA<...> VSTOR-KEY-DESC:Key3 description\"\r\n    }\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-keypairs\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nkeypairs\n\nbody\narray\nArray of keypair objects\n\nkeypair\n\nbody\nobject\nThe keypair object.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nname\n\nbody\nstring\nA name for the key pair which will be used to reference it later.\n\npublic_key\n\nbody\nstring\nThe key pair public key.\n\nfingerprint\n\nbody\nstring\nThe fingerprint for the key pair.\n\nuser_id\n\nbody\nstring\nThe user ID for a key pair.\n\nprivate_key (Optional)\nbody\nstring\nIf you do not provide a public key on create, a new key pair will\r\nbe built for you, and the private key will be returned during the\r\ninitial create call. Make sure to save this, as there is no way to\r\nget this private key again in the future.\n\ntype\n\nbody\nstring\n\nThe type of the key pair. Allowed values are ssh or x509.\nNew in version 2.2\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample\nGenerate a key pair:{\r\n  \"keypair\": {\r\n    \"public_key\": \"ssh-rsa AAAA<...> Generated-by-Nova\",\r\n    \"private_key\": \"-----BEGIN RSA PRIVATE KEY-----\\nMII<...>\\n-----END RSA PRIVATE KEY-----\\n\",\r\n    \"user_id\": \"eb481bff7b7c4ec6a686646957d8064b\",\r\n    \"name\": \"key2\",\r\n    \"created_at\": \"2020-02-12T09:23:35.524428\",\r\n    \"fingerprint\": \"dd:91:ef:1a:05:0b:17:57:bd:46:cb:69:53:63:62:f4\",\r\n    \"type\": \"ssh\"\r\n  }\r\n}\nImport a public key pair:{\r\n  \"keypair\": {\r\n    \"public_key\": \"ssh-rsa AAAA<...>\",\r\n    \"user_id\": \"eb481bff7b7c4ec6a686646957d8064b\",\r\n    \"name\": \"key3\",\r\n    \"created_at\": \"2020-02-12T09:22:57.508566\",\r\n    \"fingerprint\": \"1e:2c:9b:56:79:4b:45:77:f9:ca:7a:98:2c:b0:d5:3c\",\r\n    \"type\": \"ssh\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-and-importing-ssh-keys.html"
    },
    {
        "title": "Object storage alerts",
        "content": "Object storage alerts\nBased on the metrics described in Object storage metrics, the object storage alerts are generated and displayed in the admin panel.\nS3 Gateway alerts\n\n S3 cluster has unavailable S3 Gateway services\n\nSome S3 Gateway services are not running on <node>. Check the service status in the command-line interface.\n\n S3 Gateway service has high GET request latency\n\nS3 Gateway service (<service_id>) on <node> has the median GET request latency higher than 1 second\n\n S3 Gateway service has critically high GET request latency\n\nS3 Gateway service (<service_id>) on <node> has the median GET request latency higher than 5 seconds.\n\n S3 Gateway service has high cancel request rate\n\nS3 Gateway service (<service_id>) on <node> has the cancel request rate higher than 5%. It may be caused by connectivity issues, requests timeouts, or a small limit for pending requests.\n\n S3 Gateway service has critically high cancel request rate\n\nS3 Gateway service (<service_id>) on <node> has the cancel request rate higher than 30%. It may be caused by connectivity issues, requests timeouts, or a small limit for pending requests.\n\n S3 Gateway service has high CPU usage\n\nS3 Gateway service (<service_id>) on <node> has CPU usage higher than 75%. The service may be overloaded.\n\n S3 Gateway service has critically high CPU usage\n\nS3 Gateway service (<service_id>) on <node> has CPU usage higher than 90%. The service may be overloaded.\n\n S3 Gateway service has too many failed requests\n\nS3 Gateway service (<service_id>) on <node> has a lot of failed requests with a server error (5XX status code).\n\nS3 Object service alerts\n\n S3 cluster has unavailable object services\n\nSome Object services are not running on <node>. Check the service status in the command-line interface.\n\n Object service has high request latency\n\nObject service (<service_id>) on <node> has the median request latency higher than 1 second.\n\n Object service has critically high request latency\n\nObject service (<service_id>) on <node> has the median request latency higher than 5 seconds.\n\n Object service has high commit latency\n\nObject service (<service_id>) on <node> has the median commit latency higher than 1 second. Check the storage performance.\n\n Object service has critically high commit latency\n\nObject service (<service_id>) on <node> has the median commit latency higher than 10 seconds. Check the storage performance.\n\nS3 Name service alerts\n\n S3 cluster has unavailable name services\n\nSome Name services are not running on <node>. Check the service status in the command-line interface.\n\n Name service has high request latency\n\nName service (<service_id>) on <node> has the median request latency higher than 1 second.\n\n Name service has critically high request latency\n\nName service (<service_id>) on <node> has the median request latency higher than 5 seconds.\n\n Name service has high commit latency\n\nName service (<service_id>) on <node> has the median commit latency higher than 1 second. Check the storage performance.\n\n Name service has critically high commit latency\n\nName service (<service_id>) on <node> has the median commit latency higher than 10 seconds. Check the storage performance.\n\nOSTOR agent alerts\n\n Object storage agent is frozen for a long time\n\nObject storage agent on <node> has the event loop inactive for more than 1 minute.\n\n Object storage agent is offline\n\nObject storage agent is offline on <node>.\n\n Object storage agent is not connected to configuration service\n\nObject storage agent failed to connect to the configuration service on <node>.\n\nFile service alerts\n\n NFS service has unavailable FS services\n\nSome File services are not running on <node>. Check the service status in the command-line interface.\n\n NFS service failed to start\n\nObject storage agent failed to start <service_name>(<service_id>) on <node>.\n\n FS failed to start\n\nObject storage agent failed to start file service on <node>.\n\n NFS service is experiencing some network problems\n\nNFS service <service_name>, <service_id> on <hostname> has some RPC errors. Check your network configuration.\n\n NFS service is experiencing many network problems\n\nNFS service <service_name>, <service_id> on <hostname> has many RPC errors. Check your network configuration.\n\nNDS service alerts\n\n S3 NDS service has high notification processing error rate\n\nS3 NDS service (<service_id>) on <node> has the notification processing error rate higher than 5%. It may be caused by connectivity issues, requests timeouts, or an S3 topics misconfiguration.\n\n S3 NDS service has critically high notification processing error rate\n\nS3 NDS service (<service_id>) on <node> has the notification processing error rate higher than 15%. It may be caused by connectivity issues, requests timeouts, or an S3 topics misconfiguration.\n\n S3 NDS service has high notification deletion error rate\n\nS3 NDS service (<service_id>) on <node> has the notification deletion error rate higher than 5%. It may be caused by a storage misconfiguration, storage performance degradation, or other storage issues.\n\n S3 NDS service has high notification repetition rate\n\nS3 NDS service (<service_id>) on <node> has the notification repetition rate higher than 5%. It may be caused by a storage misconfiguration or other storage issues.\n\n S3 NDS service has too many staged unprocessed notifications\n\nS3 NDS service (<service_id>) on <node> has a lot of unprocessed notifications staged on the storage. It may be caused by connectivity or storage issues.\n\n S3 NDS service has too many messages in simultaneous processing\n\nS3 NDS service (<service_id>) on <node> has a lot of notifications in simultaneous processing on the endpoint. It may be caused by connectivity issues or an S3 topics misconfiguration.\n\nOther S3 cluster alerts\n\n S3 cluster misconfiguration\n\nThe S3 cluster configuration is not highly available. If one S3 node fails, the entire S3 cluster may become non-operational.\n\n Redundancy warning\n\nS3 is set to failure domain \u00e2\u0080\u009cdisk\u00e2\u0080\u009d even though <number_of_nodes> nodes are available. It is recommended to set the failure domain to \u00e2\u0080\u009chost\u00e2\u0080\u009d so that S3 can survive host failures in addition to disk failures.\n\n S3 service is frozen for a long time\n\nS3 service (<service_name>, <service_id>) on <node> has the event loop inactive for more than 1 minute.\n\n S3 service failed to start\n\nObject storage agent failed to start <service_name>(<service_id>) on <node>.\n\n S3 cluster has unavailable Geo-replication services\n\nSome Geo-replication services are not running on <node>. Check the service status in the command-line interface.\n\n S3 cluster has too many open file descriptors\n\nThere are more than 9000 open file descriptors on <node>. Please contact the technical support.\n\n S3 service is experiencing some network problems\n\nS3 service <service_name>, <service_id> on <hostname> has some RPC errors. Check your network configuration.\n\n S3 service is experiencing many network problems\n\nS3 service <service_name>, <service_id> on <hostname> has many RPC errors. Check your network configuration.\n\nWhat's next\n\nGetting technical support\n\nSee also\n\nInfrastructure alerts\n\nCore storage alerts\n\nBackup storage alerts\n\nBlock storage alerts\n\nCompute alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/s3-alerts.html"
    },
    {
        "title": "Creating the target storage",
        "content": "Creating the target storage\nIn the test cluster, create iSCSI, NFS, or S3 services that will serve as the target storage.\nPrerequisites\n\nKnowledge of the requirements listed in Benchmarking requirements.\n\nTo create iSCSI, NFS, or S3 services\n\nFor iSCSI targets, refer to Provisioning block storage space.\nFor NFS shares, refer to Provisioning file storage space.\nFor the S3 cluster, refer to Provisioning object storage space.\n\nFor iSCSI and NFS, the recommended storage size is at least 3x the amount of available RAM.\n\nWhat's next\n\nSetting up the benchmark for NFS and iSCSI\n\nSetting up the benchmark for S3",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-target-storage.html"
    },
    {
        "title": "14. Connecting Virtual Desktop Using Leostream\u00c2\u00b6",
        "content": "14. Connecting Virtual Desktop Using Leostream | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n14. Connecting Virtual Desktop Using Leostream\u00c2\u00b6\nBefore attempting to connect to one of your virtual machines using Leostream, ensure that you are able to connect to the VM directly. For example, ensure that you can establish an RDP connection to the desktop from another VM on the same network.\nYou can connect to the virtual desktop using either the HTML5 client available in the Leostream Gateway or using a client-based protocol launched by either the Leostream Web client or the Leostream Connect client. This example uses the Leostream Connect client, which is available on the Leostream Downloads page. Consult the Leostream Installation Guide for information on installing Leostream Connect.\nAfter installing and launching the client, provide the FQDN or IP of your Leostream Gateway (if your Leostream Gateway is actively forwarding to your Connection Broker, as done in this example) or enter your Connection Broker FQDN or IP. Click the Test button to ensure that the client can communicate with the Connection Broker, as shown in the following figure.\n\nNow, go to the Login dialog and enter the username and password of an Active Directory user, for example:\n\nIf the user\u00e2\u0080\u0099s policy offers a single desktop, the desktop connection launches automatically, for example:\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/connecting-virtual-desktop.html"
    },
    {
        "title": "Setting up a PXE server",
        "content": "Setting up a PXE server\nYou will need to install and configure the following components:\n\nTFTP server. This is a machine that allows your servers to boot and install Virtuozzo Hybrid Infrastructure over the network. Any machine that can run Linux and is accessible over network can be a TFTP server.\nDHCP server. This is a standard DHCP machine serving TCP/IP settings to computers on your network.\n\nHTTP server. This is a machine serving Virtuozzo Hybrid Infrastructure installation files over a network.\nYou can also share Virtuozzo Hybrid Infrastructure distribution over a network via FTP (for example, with vsftpd) or NFS.\n\nTo install PXE components\nRun the following command:# yum install tftp-server syslinux httpd dhcp\r\n\nYou can also use servers that already exist in your infrastructure. For example, skip httpd and dhcp if you already have the HTTP and DHCP servers.\nTo set up the TFTP server\nFollow this instruction to configure the TFTP server for BIOS-based systems. For information on configuring it for EFI-based systems, refer to the Red Hat Enterprise Linux Installation Guide.\n\nOn the server, open the /etc/xinetd.d/tftp file, and edit it as follows:service tftp{disable         = nosocket_type     = dgramprotocol        = udpwait            = yesuser            = rootserver          = /usr/sbin/in.tftpdserver_args     = -v -s /tftpbootper_source      = 11cps             = 100 2flags           = IPv4}\nOnce you are done, save the file.\n\nCreate the /tftpboot directory and copy the following files to it: vmlinuz, initrd.img, menu.c32, pxelinux.0.\nThese files are necessary to start installation. You can find the first two in the /images/pxeboot directory of the Virtuozzo Hybrid Infrastructure distribution. The last two files are located in the syslinux directory (usually /usr/share/syslinux or /usr/lib/syslinux).\n\nCreate the /tftpboot/pxelinux.cfg directory and make the default file in it.# mkdir /tftpboot/pxelinux.cfg\r\n# touch /tftpboot/pxelinux.cfg/default\n\nAdd the following lines to default:default menu.c32\r\nprompt 0timeout 100ontimeout INSTALLmenu title Boot Menulabel INSTALL        menu label Install        kernel vmlinuz        append initrd=initrd.img ip=dhcp\r\n\nFor detailed information on parameters you can specify in this file, refer to the documentation for syslinux.\n\nRestart the xinetd service:# /etc/init.d/xinetd restart\r\n\n\nIf necessary, configure the firewall to allow access to the TFTP server (on port 69 by default).\nWhen running the TFTP server, you might get the \u00e2\u0080\u009cPermission denied\u00e2\u0080\u009d error. In this case, you may try to fix the problem by running the following command: # restorecon -Rv /tftboot/.\n\nTo set up the DHCP server\nAdd the following strings to the dhcpd.conf file, which is usually located in the /etc or /etc/dhcp directory:next-server <PXE_server_IP_address>;filename \"/pxelinux.0\";\r\n\nTo configure a DHCP server for installation on EFI-based systems, specify filename \"/bootx64.efi\" instead of filename \"/pxelinux.0\" in the dhcpd.conf file, where /bootx64.efi is the directory to which you copied the EFI boot images when setting up the TFTP server.\nTo make the  distribution files available on the HTTP server\n\nSet up an HTTP server (or configure the one you already have).\nCopy the contents of the distribution image to a directory on the HTTP server (for example, /var/www/html/distrib).\n\nOn the PXE server, specify the path to the  installation files in the append line of the /tftpboot/pxelinux.cfg/default file.\nFor EFI-based systems, the file you need to edit has the name of /tftpboot/pxelinux.cfg/efidefault or /tftpboot/pxelinux.cfg/<PXE_server_IP_address>.\nAssuming that the HTTP server is at 198.123.123.198, the installation files are in /var/www/html/distrib/, and DocumentRoot is set to /var/www/html, the default file may look like this:default menu.c32prompt 0timeout 100ontimeout INSTALLmenu title Boot Menulabel INSTALL        menu label Install        kernel vmlinuz        append initrd=initrd.img ip=dhcp inst.repo=http://198.123.123.198/distrib\n\nWhat's next\n\nInstalling in the attended mode\n\nInstalling in the unattended mode",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-a-pxe-server.html"
    },
    {
        "title": "Managing images",
        "content": "Managing images\nImages  stored in the compute cluster can be downloaded to a client's machine, edited, and removed.\nTo protect images with third-party software licenses, system administrators can disallow image download for self-service users. In this case, VM volumes created from such images will inherit this property and once converted back to images can only be downloaded by system administrators.\nLimitations\n\nImages are stored according to the default storage policy.\nWhen you install the load balancer or Kubernetes service, special images appear in the compute cluster, which are used by the system for creating service VMs. Such images are marked with the System tag and cannot be modified or deleted in the admin panel.\n\nPrerequisites\n\nImages are added to the compute cluster, as described in Uploading images for virtual machines.\n\nTo download an image\n\nAdmin panel\n\nGo to the Compute > Virtual machines > Images tab, and then click the ellipsis button next to the required image.\nClick Download image.\n\nThe image will be downloaded to the your machine.\n\nCommand-line interface\nUse the following command:vinfra service compute image save [--file <filename>] <image>\r\n\n\n--file <filename>\n\nFile to save the image to (default: stdout)\n<image>\n\nImage ID or name\n\nFor example, to download the image cirros to the local disk as cirros.qcow2, run:# vinfra service compute image save cirros --file cirros.qcow2\n\nTo edit an image\n\nAdmin panel\n\nGo to the Compute > Virtual machines > Images tab, and then click the required image.\nOn the image right pane, click the pencil icon next to a parameter you need to change. You can change the image name, OS type, and network access. For templates, you can also edit the minimum volume size.\n\nCommand-line interface\nUse the following command:vinfra service compute image set [--min-disk <size-gb>] [--min-ram <size-mb>] [--os-distro <os-distro>]\r\n                                 [--protected | --unprotected] [--public] [--private] [--name <name>] <image>\r\n\n\n--min-disk <size-gb>\n\nMinimum disk size required to boot from image, in gigabytes\n--min-ram <size-mb>\n\nMinimum RAM size required to boot from image, in megabytes\n--os-distro <os-distro>\n\nOS distribution. To list available distributions, run vinfra service compute cluster show.\n--protected\n\nProtect image from deletion.\n--unprotected\n\nAllow image to be deleted.\n--public\n\nMake image accessible to all users.\n--private\n\nMake image accessible only to the owners.\n--name <name>\n\nImage name\n<image>\n\nImage ID or name\n\nFor example, to make the image cirros accessible to all users and set the minimum RAM size for it to 1 GB, run:# vinfra service compute image set cirros --public --min-ram 1\n\nTo manage image restrictions\nUse the following command:vinfra service compute image set [--restricted| --unrestricted] <image>\n\n--restricted\n\nMake image download restricted\n--unrestricted\n\nAllow image to be downloaded\n\nFor example, to disallow the image cirros to be downloaded by self-service users, run:# vinfra service compute image set cirros --restricted\nTo remove an image\n\nAdmin panel\n\nGo to the Compute > Virtual machines > Images tab, and then click the ellipsis button next to the required image.\nClick Delete.\n\nCommand-line interface\nUse the following command:vinfra service compute image delete <image>\r\n\n\n<image>\n\nImage ID or name\n\nFor example, to delete the image cirros, run:# vinfra service compute image delete cirros\r\n",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute image save [--file <filename>] <image>\r\n\n\n--file <filename>\n\nFile to save the image to (default: stdout)\n<image>\n\nImage ID or name\n\nFor example, to download the image cirros to the local disk as cirros.qcow2, run:# vinfra service compute image save cirros --file cirros.qcow2\n",
                "title": "To download an image"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute image set [--min-disk <size-gb>] [--min-ram <size-mb>] [--os-distro <os-distro>]\r\n                                 [--protected | --unprotected] [--public] [--private] [--name <name>] <image>\r\n\n\n--min-disk <size-gb>\n\nMinimum disk size required to boot from image, in gigabytes\n--min-ram <size-mb>\n\nMinimum RAM size required to boot from image, in megabytes\n--os-distro <os-distro>\n\nOS distribution. To list available distributions, run vinfra service compute cluster show.\n--protected\n\nProtect image from deletion.\n--unprotected\n\nAllow image to be deleted.\n--public\n\nMake image accessible to all users.\n--private\n\nMake image accessible only to the owners.\n--name <name>\n\nImage name\n<image>\n\nImage ID or name\n\nFor example, to make the image cirros accessible to all users and set the minimum RAM size for it to 1 GB, run:# vinfra service compute image set cirros --public --min-ram 1\n",
                "title": "To edit an image"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute image delete <image>\r\n\n\n<image>\n\nImage ID or name\n\nFor example, to delete the image cirros, run:# vinfra service compute image delete cirros\r\n\n",
                "title": "To remove an image"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Virtual machines > Images tab, and then click the ellipsis button next to the required image.\nClick Download image.\n\nThe image will be downloaded to the your machine.\n",
                "title": "To download an image"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Virtual machines > Images tab, and then click the required image.\nOn the image right pane, click the pencil icon next to a parameter you need to change. You can change the image name, OS type, and network access. For templates, you can also edit the minimum volume size.\n\n",
                "title": "To edit an image"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Virtual machines > Images tab, and then click the ellipsis button next to the required image.\nClick Delete.\n\n",
                "title": "To remove an image"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-images.html"
    },
    {
        "title": "Getting technical support",
        "content": "Getting technical support\nIf you need technical support, you can send a problem report to and contact the technical support team. When generated, a problem report is assigned an ID. Make sure to mention this ID in the support ticket. \nIn the case of connection problems with the report server or if the report is too large to send via email, you can find the report in the /var/cache/problem-reports/ directory on the management node.\nTo generate and send a problem report\n\nAdmin panel\n\nOn any screen, click the user icon in the top right corner, and then select Report a problem.\n\nEnter your contact email and describe the problem, and then click Generate and send. The report status will be shown in the bottom right corner.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nYou can hide the pop-up window without interrupting the report generation. The report ID will be available in the notification center.\n\nCommand-line interface\nUse the following command:vinfra cluster problem-report [--email <email>] [--description <description>] [--send]\r\n\n\n--email <email>\n\nContact email address\n--description <description>\n\nProblem description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--send\n\nGenerate the problem report archive and send it to the technical support team\n\nFor example, to send a problem report with the description \u00e2\u0080\u009cTest report\u00e2\u0080\u009d to the technical support team and use test@example.com as a reply-to address, run:# vinfra cluster problem-report --email test@example.com --description \"Test report\" --send\r\n+---------+--------------------------------------+\r\n| Field   | Value                                |\r\n+---------+--------------------------------------+\r\n| task_id | 8bcfb92f-f02b-4de8-8e44-3426047630e3 |\r\n+---------+--------------------------------------+\r\n# vinfra task show 8bcfb92f-f02b-4de8-8e44-3426047630e3\r\n+---------+-------------------------------------------------------------+\r\n| Field   | Value                                                       |\r\n+---------+-------------------------------------------------------------+\r\n| details |                                                             |\r\n| name    | backend.presentation.reports.tasks.ReportProblemTask        |\r\n| result  | id: '1001923113'                                            |\r\n|         | path: /var/cache/problem-reports/report-<...>.391329.tar.gz |\r\n| state   | success                                                     |\r\n| task_id | 8bcfb92f-f02b-4de8-8e44-3426047630e3                        |\r\n+---------+-------------------------------------------------------------+\r\n\nNote the problem report ID in the task details. You will need to mention it in the support ticket.\n\nTo contact the technical support team\nVisit the support page at https://www.virtuozzo.com/support/.\nSee also\n\nManaging notifications",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster problem-report [--email <email>] [--description <description>] [--send]\r\n\n\n--email <email>\n\nContact email address\n--description <description>\n\n\nProblem description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--send\n\nGenerate the problem report archive and send it to the technical support team\n\nFor example, to send a problem report with the description \u00e2\u0080\u009cTest report\u00e2\u0080\u009d to the technical support team and use test@example.com as a reply-to address, run:# vinfra cluster problem-report --email test@example.com --description \"Test report\" --send\r\n+---------+--------------------------------------+\r\n| Field   | Value                                |\r\n+---------+--------------------------------------+\r\n| task_id | 8bcfb92f-f02b-4de8-8e44-3426047630e3 |\r\n+---------+--------------------------------------+\r\n# vinfra task show 8bcfb92f-f02b-4de8-8e44-3426047630e3\r\n+---------+-------------------------------------------------------------+\r\n| Field   | Value                                                       |\r\n+---------+-------------------------------------------------------------+\r\n| details |                                                             |\r\n| name    | backend.presentation.reports.tasks.ReportProblemTask        |\r\n| result  | id: '1001923113'                                            |\r\n|         | path: /var/cache/problem-reports/report-<...>.391329.tar.gz |\r\n| state   | success                                                     |\r\n| task_id | 8bcfb92f-f02b-4de8-8e44-3426047630e3                        |\r\n+---------+-------------------------------------------------------------+\r\n\nNote the problem report ID in the task details. You will need to mention it in the support ticket.\n",
                "title": "To generate and send a problem report"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOn any screen, click the user icon in the top right corner, and then select Report a problem.\n\n\n\n\n\n\nEnter your contact email and describe the problem, and then click Generate and send. The report status will be shown in the bottom right corner.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n\n\n\n\nYou can hide the pop-up window without interrupting the report generation. The report ID will be available in the notification center.\n",
                "title": "To generate and send a problem report"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/getting-technical-support.html"
    },
    {
        "title": "Sample object storage",
        "content": "Sample object storage\nThis section shows a sample object storage deployed on top of a storage cluster of five nodes that run various services. The final setup is shown in the figure below.\n\nSee also\n\nObject storage architecture",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/sample-s3-storage.html"
    },
    {
        "title": "Importing registrations to the secondary cluster",
        "content": "Importing registrations to the secondary cluster\nAfter geo-replication is enabled, new registrations that you add to the primary cluster are not automatically replicated to the secondary cluster. You need to import such registrations manually.\nPrerequisites\n\nGeo-replication is enabled, as described in Enabling geo-replication.\nOne or more registrations are added to the primary cluster, as explained in Adding registrations.\n\nTo import a registration to the secondary cluster\n\nOn the primary cluster, find out the registration ID in the uuid field. For example:# vstorage-abgw-register list\r\n[\r\n    {\r\n        \"uuid\": \"68ae9bd1-ae34-4ff2-938b-cd576d9610a5\",\r\n        \"type\": \"ABC\",\r\n        \"description\": \"registration1\",\r\n        ...\r\n    },\r\n    ...\r\n]\n\nExport the registration to a configuration file specifying the registration ID and the file name. For example:# vstorage-abgw-register export -R \"68ae9bd1-ae34-4ff2-938b-cd576d9610a5\" -f registration1.txt\n\nMove the configuration file from the primary cluster to the secondary cluster using the standard Linux command-line tool. For example, by using scp:# scp registration1.txt <secondary_cluster_IP_address>:/root/registration1.txt\n\nOn the secondary cluster, import the registration from the configuration file specifying the registration ID and the file name. For example:# vstorage-abgw-register import -R \"68ae9bd1-ae34-4ff2-938b-cd576d9610a5\" -f registration1.txt\n\nList all registrations to check that the registration is successfully imported. For example:# vstorage-abgw-register list\r\n[\r\n    {\r\n        \"uuid\": \"68ae9bd1-ae34-4ff2-938b-cd576d9610a5\",\r\n        \"type\": \"ABC\",\r\n        \"description\": \"registration1\",\r\n        ...\r\n    },\r\n    ...\r\n]\n\nRestart the Backup Gateway services on each node of the secondary backup storage cluster:# systemctl restart vstorage-abgw.service\n\nSee also\n\nPerforming a failover\n\nDisabling geo-replication",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/importing-registrations-to-the-secondary-cluster.html"
    },
    {
        "title": "Setting the default QoS policy",
        "content": "Setting the default QoS policy\nYou can set the default QoS policy to a project. It will be automatically assigned to all new networks that you create within the project. Existing networks within the project will not inherit the default QoS policy, you will need to explicitly assign the policy to them.\nLimitations\n\nEach project can have only one default QoS policy. If you want to change the default policy, unset the old default policy first.\n\nPrerequisites\n\nA QoS policy is created, as described in Creating QoS policies.\n\nTo set a QoS policy as default to a project\nUse the --default option with the openstack network qos policy set command. For example:# openstack --insecure network qos policy set --default policy1\nTo unset the default policy from a project\nUse the --no-default option with the openstack network qos policy set command. For example:# openstack --insecure network qos policy set --no-default policy1\nSee also\n\nAssigning QoS policies\n\nModifying QoS policy rules",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-the-default-qos-policy.html"
    },
    {
        "title": "Managing project assignment to domain groups",
        "content": "Managing project assignment to domain groups\nOnce you create a domain group with the role Project member, you can assign projects to it. Projects that you assign to a domain group will be automatically assigned to all of the domain group users.\nPrerequisites\n\nDomain groups are created, as described in Creating domain groups.\nProjects are created, as described in Configuring multitenancy.\n\nTo manage projects of a domain group\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a domain group.\nGo to the Domain groups tab, click the ellipsis icon next to the group with the Project member role, and then click Manage projects.\nIn the Manage projects window, select projects to assign to the group or to unassign from the group, and then click Assign.\n\nCommand-line interface\nUse the following command:vinfra domain group set [--assign <project> <role>] [--unassign <project>] --domain <domain> <group>\r\n\n\n--assign <project> <role>\n\nAssign a group to a project with one or more permission sets. Specify this option multiple times to assign the group to multiple projects.\n\n<project>: project ID or name\n<role>: group role in the project (project_admin)\n\n--unassign <project>\n\nUnassign a group from a project. Specify this option multiple times to unassign the group from multiple projects.\n\n<project>: project ID or name\n\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n\nFor example, to assign the group myusers within the domain mydomain to the project myproject as a project administrator, run:# vinfra domain group set myusers --domain mydomain --assign myproject project_admin\n\nSee also\n\nManaging user assignment to domain groups\n\nEditing and deleting domain groups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain group set [--assign <project> <role>] [--unassign <project>] --domain <domain> <group>\r\n\n\n--assign <project> <role>\n\n\nAssign a group to a project with one or more permission sets. Specify this option multiple times to assign the group to multiple projects.\n\n<project>: project ID or name\n<role>: group role in the project (project_admin)\n\n\n--unassign <project>\n\n\nUnassign a group from a project. Specify this option multiple times to unassign the group from multiple projects.\n\n<project>: project ID or name\n\n\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n\nFor example, to assign the group myusers within the domain mydomain to the project myproject as a project administrator, run:# vinfra domain group set myusers --domain mydomain --assign myproject project_admin\n",
                "title": "To manage projects of a domain group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a domain group.\nGo to the Domain groups tab, click the ellipsis icon next to the group with the Project member role, and then click Manage projects.\nIn the Manage projects window, select projects to assign to the group or to unassign from the group, and then click Assign.\n\n",
                "title": "To manage projects of a domain group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-project-assignment-to-domain-groups.html"
    },
    {
        "title": "Installing Virtuozzo Hybrid Infrastructure",
        "content": "Installing Virtuozzo Hybrid Infrastructure\n\nThe time needs to be synchronized via NTP on all nodes in the same cluster. Make sure that the nodes can access the NTP server.\n\nTo install Virtuozzo Hybrid Infrastructure, do the following:\n\nObtain the distribution ISO image. To do that, visit the product page and submit a request for the trial version.\n\nPrepare the bootable media using the distribution ISO image (mount it to an IPMI virtual drive, create a bootable USB drive, or set up a PXE server).\nBoot the server from the chosen media.\nOn the Welcome screen, choose Install Virtuozzo Hybrid Infrastructure.\nOn step 1, carefully read the End-User License Agreement. Accept it by selecting the I accept the End-User License Agreement check box, and then click Next.\nOn step 2, configure a static IP address for the network interface and provide a host name: either a fully qualified domain name (<hostname>.<domainname>) or a short name (<hostname>). A dynamic IP is not recommended as it might cause issues with reaching the nodes. Check that the network settings are correct.\nOn step 3, choose your time zone. Date and time will be set via NTP. You will need an Internet connection for synchronization to complete.\nOn step 4, specify what type of node you are installing. First, deploy one primary node. Then, deploy as many secondary nodes as you need.If you chose to deploy the primary node, select two network interfaces: for internal management and configuration and for access to the admin panel. Also create and confirm a password for the superadmin account of the admin panel. This node will be the management node.If you chose to deploy a secondary node, provide the IP address of the management node and the token. Both are obtained from the admin panel. Log in to the admin panel on port 8888. The panel\u00e2\u0080\u0099s IP address is shown in the console after deploying the primary node. Enter the default username admin and the superadmin account password. In the admin panel, open Infrastructure > Nodes, and then click Connect node, to invoke a screen with the management node address and the token.The node may appear on the Infrastructure > Nodes screen with the Unassigned status as soon as the token is validated. However, you will be able to join it to the storage cluster only after the installation is complete.\nOn step 5, choose a disk for the operating system. This disk will have the supplementary role System, although you will still be able to set it up for data storage in the admin panel. You can also create software RAID1 for the system disk, to ensure its high performance and availability.\nOn step 6, enter and confirm the password for the root account, and then click Start installation.\n\nOnce the installation is complete, the node will reboot automatically. The admin panel IP address will be shown in the welcome prompt.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/installing-infrastructure.html"
    },
    {
        "title": "Creating S3 buckets on Mounted S3 Storage",
        "content": "Creating S3 buckets on Mounted S3 Storage\nWindows and macOS, operating systems supported by Mountain Duck, treat buckets as folders in case the S3 storage is mounted as a disk drive. In both operating systems, the default folder name contains spaces. This violates bucket naming conventions (refer to S3 bucket and key naming policies), therefore you cannot create a new bucket directly on the mounted S3 storage. To create a bucket on a mounted S3 storage, create a folder with a name complying with DNS naming conventions elsewhere and copy it to the root of the mounted S3 storage.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/creating-s3-buckets-on-mounted-s3-storage.html"
    },
    {
        "title": "Editing and deleting backup plans",
        "content": "Editing and deleting backup plans\nYou can edit a backup plan's name and description, change its schedule, and delete it when it is no longer needed.\nPrerequisites\n\nA backup plan is created, as described in Creating backup plans.\n\nTo edit a backup plan\n\nOn the Backup plans screen, click the required backup plan.\nOn the plan right pane, click Edit.\n\nIn the Edit backup plan window, make the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nTo delete a backup plan\n\nOn the Backup plans tab, click the required backup plan.\nOn the plan right pane, click Delete.\nIf the backup plan has recovery points, you can delete them along with the backup plan. To do this, select Delete recovery points.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/editing-and-deleting-backup-plans.html"
    },
    {
        "title": "Authenticating NFS share users via Kerberos",
        "content": "Authenticating NFS share users via Kerberos\n\nThis feature is experimental and not intended for use in production environments.\n\nUser authentication via Kerberos includes these steps:\n\nEnabling Kerberos authentication in the NFS settings.\nCreating principals with their key tables (keytabs) for the Kerberos client and for an NFS share  on the Kerberos server.\nSetting up a Kerberos client on a host that the NFS share will be mounted to.\nEnabling user authentication for the NFS share.\nMounting the NFS share to the host with the Kerberos client.\n\nPrerequisites\n\nNFS shares are created and stopped, as described in Creating NFS shares and Managing NFS shares.\nThe share\u00e2\u0080\u0099s IP address is assigned a forward and reverse resolvable FQDN (fully qualified domain name).\n\nTo enable Kerberos authentication\n\nAdmin panel\n\nGo to the Storage services > NFS > Settings tab and then switch to the Kerberos screen.\n\nSpecify the following Kerberos information:\n\nIn Realm, specify your DNS name in uppercase letters.\nIn KDC service, specify the DNS name or IP address of the host running the realm\u00e2\u0080\u0099s Key Distribution Center (KDC) service.\n\nIn KDC admin service, specify the DNS name or IP address of the host running the realm\u00e2\u0080\u0099s KDC administration service.\n\nThe KDC and its administration service usually run on the same host.\n\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra service nfs kerberos settings set --realm <realm> --kdc-service <kdc-service>\r\n                                         --kdc-admin-service <kdc-admin-service>\n\n--realm <realm>\n\nRealm name in uppercase letters\n--kdc-service <kdc-service>\n\nDNS name or IP address of the KDC service\n--kdc-admin-service <kdc-admin-service>\n\nDNS name or IP address of the KDC administration service\n\nFor example, to enable Kerberos authentication, run:# vinfra service nfs kerberos settings set --realm EXAMPLE.COM --kdc-service 10.136.10.10 \\\r\n--kdc-admin-service 10.136.10.10\n\nTo create a keytab file for a principal\n\nOn the Kerberos server, log in as administrator to the Kerberos database administration program.\n\nAdd principals for the Kerberos client and for the NFS share by using the command addprinc -randkey nfs/<FQDN>@<realm>. For example, if the client's domain name is krb-client.example.com and the share's domain name share1.example.com, run:# addprinc -randkey nfs/krb-client.example.com@EXAMPLE.COM\r\n# addprinc -randkey nfs/share1.example.com@EXAMPLE.COM\n\nGenerate keytabs for the created principals and save them to a directory you can upload from. For example:# ktadd -k /tmp/krb-client.keytab nfs/krb-client.example.com@EXAMPLE.COM\r\n# ktadd -k /tmp/share.keytab nfs/share1.example.com@EXAMPLE.COM\r\n\n\nEach share and client must have their own principal and keytab.\n\nTo set up the Kerberos client\n\nOn a host that an NFS share will be mounted to, install the required packages. For example, on a CentOS server, run:# yum install krb5-workstation krb5-libs \u00e2\u0080\u0093y\n\nConfigure firewalld and selinux, if needed. For details, refer to your OS manual, such as Securing services in the Red Hat Enterprise Linux Security Guide.\n\nCopy the krb5.conf configuration file and the krb-client.keytab keytab file from the Kerberos server to the client host.\nEnsure that the client host can reach the  Kerberos server and NFS share via their domain names. Also, the client host must have the domain name specified during the principal configuration on the Kerberos server.\n\nStart the client service:# systemctl start nfs-client\n\nTo enable user authentication for an NFS share\n\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab, and then click the line with a share.\nIf the share is running, stop it by clicking Stop on the right pane.\nClick Authentication on the right pane.\nIn the Authentication window, enable user authentication, upload the corresponding keytab file, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra service nfs share set [--krb-keytab <krb-keytab>] [--krb-auth <krb-auth>] <name>\n\n--krb-keytab <krb-keytab>\n\nKerberos keytab file\n--krb-auth <krb-auth>\n\nWhether or not Kerberos authentication is enabled (true or false)\n<name>\n\nNFS share name\n\nFor example, to enable authentication for the share share1 with the keytab file /tmp/krb5.keytab, run:# vinfra service nfs share set share1 --krb-auth true --krb-keytab share1.keytab\n\nTo mount an NFS share with enabled Kerberos authentication\nSpecify the sec=krb5 option with the mount command. For example, to mount share1 with the share1.example.com domain name, run:# mkdir /mnt/share\r\n# mount -t nfs4 -o sec=krb5 share1.example.com:/share1 /mnt/share/\nSee also\n\nManaging NFS shares\n\nWhat's next\n\nAuthorizing NFS export users via LDAP",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs kerberos settings set --realm <realm> --kdc-service <kdc-service>\r\n                                         --kdc-admin-service <kdc-admin-service>\n\n--realm <realm>\n\nRealm name in uppercase letters\n--kdc-service <kdc-service>\n\nDNS name or IP address of the KDC service\n--kdc-admin-service <kdc-admin-service>\n\nDNS name or IP address of the KDC administration service\n\nFor example, to enable Kerberos authentication, run:# vinfra service nfs kerberos settings set --realm EXAMPLE.COM --kdc-service 10.136.10.10 \\\r\n--kdc-admin-service 10.136.10.10\n",
                "title": "To enable Kerberos authentication"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs share set [--krb-keytab <krb-keytab>] [--krb-auth <krb-auth>] <name>\n\n--krb-keytab <krb-keytab>\n\nKerberos keytab file\n--krb-auth <krb-auth>\n\nWhether or not Kerberos authentication is enabled (true or false)\n<name>\n\nNFS share name\n\nFor example, to enable authentication for the share share1 with the keytab file /tmp/krb5.keytab, run:# vinfra service nfs share set share1 --krb-auth true --krb-keytab share1.keytab\n",
                "title": "To enable user authentication for an NFS share"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Settings tab and then switch to the Kerberos screen.\n\nSpecify the following Kerberos information:\n\nIn Realm, specify your DNS name in uppercase letters.\nIn KDC service, specify the DNS name or IP address of the host running the realm\u00e2\u0080\u0099s Key Distribution Center (KDC) service.\n\nIn KDC admin service, specify the DNS name or IP address of the host running the realm\u00e2\u0080\u0099s KDC administration service.\n\nThe KDC and its administration service usually run on the same host.\n\n\n\n\n\n\n\n\nClick Save to apply your changes.\n\n",
                "title": "To enable Kerberos authentication"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab, and then click the line with a share.\nIf the share is running, stop it by clicking Stop on the right pane.\nClick Authentication on the right pane.\nIn the Authentication window, enable user authentication, upload the corresponding keytab file, and then click Save.\n\n",
                "title": "To enable user authentication for an NFS share"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/authenticating-nfs-users-via-kerberos.html"
    },
    {
        "title": "Editing user credentials and permissions",
        "content": "Editing user credentials and permissions\nIf required, self-service users can change the password of their account. Additionally, domain administrators are able to edit credentials and permissions of other domain administrators and project members.\nPrerequisites\n\nA domain administrator must have the Image uploading and Project and quota management permissions granted, to be able to configure these permissions for other users.\n\nTo change the password\n\nIn the top right corner of the self-service panel, click the user icon, and then click Change password.\nIn the Change password window, enter the current password and enter a new password twice.\nClick Save.\n\nTo edit a user\n\nSelect the domain in the drop-down list in the top right corner.\nOn the Users screen, click the ellipsis icon next to the user, and then click Edit.\nMake the required changes, and then click Save.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/editing-user-credentials-and-permissions.html"
    },
    {
        "title": "Managing balancing pools",
        "content": "Managing balancing pools\nTo see a list of balancing pools in a load balancer, click its name.\n\nYou can open the pool right pane to monitor its performance and health on the Overview tab, see its parameters on the Properties tab, manage its members on the Members tab, and configure its allowed IP ranges on the CIDRs tab.\nLimitations\n\nThe forwarding rule and protocol cannot be changed after the load balancer pool is added.\n\nPrerequisites\n\nAll VMs that will be added in balancing pools have fixed IP addresses.\n\nTo add another balancing pool to a load balancer\n\nOn the screen with balancing pools, click Create balancing pool.\n\nIn the Forwarding rule section, select a forwarding rule from the load balancer to the backend protocol:\n\nWith the HTTPS -> HTTPS rule\n\nSpecify ports for incoming and destination connections.\nEnsure that all virtual machines have the same SSL certificate (or a certificate chain).\n\nEnable the PROXY protocol version 1 to add a human-readable header with connection information (the source IP address, destination IP address, and port numbers) as a part of the request header.\n\nWith the HTTPS -> HTTP rule\n\nSpecify ports for incoming and destination connections.\nUpload an SSL certificate (or a certificate chain) in the PEM format and a private key in the PEM format.\n\nChoose HTTP headers to insert into the request.\n\nEnable the TLS encryption to re-encrypt traffic from the load balancer to its members.\n\nEnable the PROXY protocol version 1 to add a human-readable header with connection information (the source IP address, destination IP address, and port numbers) as a part of the request header.\n\nWith the HTTP -> HTTP rule\n\nSpecify ports for incoming and destination connections.\n\nChoose HTTP headers to insert into the request.\n\nEnable the TLS encryption to re-encrypt traffic from the load balancer to its members.\n\nEnable the PROXY protocol version 1 to add a human-readable header with connection information (source IP address, destination IP address, and port numbers) as a part of the request header.\n\nWith the TCP -> TCP rule\n\nSpecify ports for incoming and destination connections.\n\nEnable the TLS encryption to re-encrypt traffic from the load balancer to its members.\n\nWith the UDP -> UDP rule\n\nSpecify ports for incoming and destination connections.\n\nIn the Balancing settings section, do the following:\n\nSelect the balancing algorithm:\n\nLeast connections. Requests will be forwarded to the VM with the least number of active connections.\nRound robin. All VMs will receive requests in the round-robin manner.\nSource IP. Requests from a unique source IP address will be directed to the same VM.\n\nSelect Sticky session to enable session persistence. The load balancer will generate a cookie that will be inserted into each response. The cookie will be used to send future requests to the same VM.\n\nThis option is not available in the SSL passthrough mode.\n\nIn the Members section, add members, that is, virtual machines, to the balancing pool by clicking Add. Each VM can be included to multiple balancing pools. In the Add members window that opens, select the desired VMs, and then click Add.\n\nYou can select only between VMs that are connected to the chosen network.\n\nIn the Allowed CIDRs section, specify IP address ranges in the CIDR format that will be allowed to interact with the balancing pool. This will limit incoming traffic to the specified IP addresses, any other incoming traffic will be rejected. For example:\n\nTo limit traffic from the IP address 10.10.10.10, add the /32 suffix: 10.10.10.10/32.\nTo limit traffic from the subnet range 10.10.10.0\u00e2\u0080\u009310.10.10.255, add the /24 suffix: 10.10.10.10/24.\nTo limit traffic from the subnet range 10.10.0.0 - 10.10.255.255, add the /16 suffix: 10.10.10.10/16.\n\nIn the Health monitor section, select the protocol that will be used for monitoring members availability:\n\nHTTP/HTTPS. The HTTP/HTTPS method GET will be used to check for the response status code 200. Additionally, specify the URL path to the health monitor.\nTCP/UDP. The health monitor will check the TCP/UDP connection on the backend port.\nPING. The health monitor will check members\u00e2\u0080\u0099 IP addresses.\n\nBy default, the health monitor removes a member from a balancing pool if it fails three consecutive health checks of five-second intervals. When a member returns to operation and responds successfully to three consecutive health checks, it is added to the pool again. You can manually set the health monitor parameters, such as the interval after which VM health is checked, the time after which the monitor times out, healthy and unhealthy thresholds. To change the default parameters, click Edit parameters, enter the desired values, and then click Save.\n\n\r\n                                Click Create.\r\n                     \n\nThe newly added pool will appear in the list of balancing pools.\nTo edit a balancing pool\n\nOn the screen with balancing pools, click the required balancing pool.\n\nOn the right pane, click one of the following:\n\nTo edit the balancing settings such as the HTTP headers, TLS encryption, balancing algorithm, and session persistence, click Edit.\nTo add or remove IP ranges that are allowed to interact with the balancing pool, click Edit allowed CIDRs.\nTo edit the health monitor parameters, click Edit health monitor.\n\nTo add more members to a balancing pool\n\nOn the screen with balancing pools, click the required balancing pool.\nOn the right pane, click + Add members.\nIn the Add members window, select virtual machines to be added to the balancing pool, and then click Add.\n\nTo remove a balancing pool\n\nClick the ellipsis icon next to the required balancing pool, and then click Delete.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-balancing-pools.html"
    },
    {
        "title": "Showing IPsec policy details",
        "content": "Showing IPsec policy detailsGET /v2.0/vpn/ipsecpolicies/{ipsecpolicy_id}\nShows details for an IPsec policy.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-ipsec-policy-detail#show-ipsec-policy\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicy_id\n\npath\nstring\nThe ID of the IPsec policy.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ipsecpolicies/805ab779-e91c-42db-b6b9-591156d9634e\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicies\n\nbody\narray\nA list of ipsecpolicy objects.\n\nipsecpolicy\n\nbody\nobject\nAn ipsecpolicy object.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencapsulation_mode (Optional)\nbody\nstring\nThe encapsulation mode. A valid value is tunnel or transport. Default is tunnel.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\ntransform_protocol (Optional)\nbody\nstring\nThe transform protocol. A valid value is ESP, AH, or AH- ESP. Default is ESP.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IPsec policy.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"ipsecpolicy\": {\r\n    \"id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"ipsecpolicy1\",\r\n    \"description\": \"\",\r\n    \"transform_protocol\": \"esp\",\r\n    \"auth_algorithm\": \"sha1\",\r\n    \"encryption_algorithm\": \"aes-128\",\r\n    \"encapsulation_mode\": \"tunnel\",\r\n    \"lifetime\": {\r\n      \"units\": \"seconds\",\r\n      \"value\": 7200\r\n    },\r\n    \"pfs\": \"group5\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-ipsec-policy-details.html"
    },
    {
        "title": "Listing traits",
        "content": "Listing traitsGET /traits/detail\r\n\nReturns a list of trait strings. This custom API call is only supported in Virtuozzo Hybrid Infrastructure.\nSource: https://docs.openstack.org/api-ref/placement/?expanded=list-traits-detail#list-traits\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nname (Optional)\nquery\nstring\n\nA string to filter traits. The following options are available:\n\nstartswith operator filters the traits whose name begins with a\r\nspecific prefix, e.g. name=startswith:CUSTOM\nin operator filters the traits whose name is in the specified list, e.g.\r\nname=in:HW_CPU_X86_AVX,HW_CPU_X86_SSE,HW_CPU_X86_INVALID_FEATURE\n\nassociated (Optional)\nquery\nstring\nIf this parameter has a true value, the returned traits will be those that are associated with at least one resource provider. Available values for the parameter are true and false.\n\nExamplecurl -ks -H 'Content-Type: application/json' -H 'OpenStack-API-Version: placement 1.32' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8780/traits/detail?name=startswith:CUSTOM_HCI\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ntraits\n\nbody\narray\nA list of traits.\n\ntrait\n\nbody\narray\nA list of trait details.\n\nname\n\nbody\nstring\nThe name of a trait.\n\ndisplay_name\n\nbody\nstring\nA human-readable trait name to be displayed in the admin panel.\n\ndescription\n\nbody\nstring\nA human-readable trait description to be displayed in the admin panel.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"traits\": [\r\n    {\r\n      \"display_name\": \"placement1\",\r\n      \"description\": \"Sample placement\",\r\n      \"name\": \"CUSTOM_HCI_E3A45A6A4B614263893D72015BFB1A5F\"\r\n    },\r\n    {\r\n      \"display_name\": \"placement2\",\r\n      \"description\": \"Sample placement #2\",\r\n      \"name\": \"CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-traits.html"
    },
    {
        "title": "Attaching host devices to virtual machines",
        "content": "Attaching host devices to virtual machines\nBy attaching various devices from compute nodes to virtual machines, you can reduce VM network latency or accelerate visualization inside a guest operating system. The following PCI devices are supported:\n\nGraphics cards. With GPU passthrough, you can give an entire physical GPU to a single virtual machine, while vGPU enables dividing up video RAM of a physical GPU between multiple virtual machines. You can use both capabilities, GPU passthough and vGPU, on the same node.\nNetwork adapters with Single Root I/O Virtualization (SR-IOV) capabilities. The SR-IOV technology enables splitting a single physical adapter (physical function) into several virtual adapters (virtual functions). Each virtual function appears as a separate PCI device that can be attached to multiple virtual machines.\nHost bus adapters. To attach HBA devices to virtual machines, use the steps described for GPU passthrough.\n\nLimitations\n\nPCI device passthrough and GPU virtualization is only available on servers that support Input/Output Memory Management Unit (IOMMU). For a list of IOMMU-supporting hardware, refer to this article.\nvGPU is supported for NVIDIA GPU cards.\n\nProcedure overview\n\nPrepare compute nodes depending on a host device you are going to pass through or virtualize.\nReconfigure the compute cluster to enable PCI passthrough or vGPU support.\nCreate virtual machines with attached PCI or vGPU devices.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/attaching-host-devices-to-vms.html"
    },
    {
        "title": "Setting buckets limits in WHMCS",
        "content": "Setting buckets limits in WHMCS\nYou can limit operations rate with the ostor-limits service and the following parameters: bucket specifying the bucket name, default=, get=, put=, list=, delete= specifying the limit value.\nSimilarly, you can limit outgoing bandwidth of a response with the ostor-limits service and the following parameters: bucket specifying the bucket name, out= specifying the limit value. WHMCS configures the bucket limits in S3 cluster when you click the Set button. Create a file S3_setLimitsForBucket.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Set s3 bucket limits.\r\nfunction S3_setLimitsForBucket($vars) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Set only if value specified.\r\n    if (!empty($vars['ops-value'])) {\r\n\r\n        // Set s3 bucket limits (ops).\r\n        S3_requestCurl(\r\n            $s3_config['s3_key'],\r\n            $s3_config['s3_secret'],\r\n            $s3_config['s3_gateway'],\r\n                \"/?ostor-limits&bucket=\" . $vars['bucket'] .\r\n                \"&limit-type=ops&limit-resource=\" . $vars['ops-name'] .\r\n                    '&limit-value=' . $vars['ops-value'],\r\n            \"PUT\"\r\n        );\r\n    }\r\n\r\n    // Set only if value specified.\r\n    if (!empty($vars['bandwidth-value'])) {\r\n\r\n        // Set s3 bucket limits (bandwidth).\r\n        S3_requestCurl(\r\n            $s3_config['s3_key'],\r\n            $s3_config['s3_secret'],\r\n            $s3_config['s3_gateway'],\r\n                \"/?ostor-limits&bucket=\" . $vars['bucket'] .\r\n                \"&limit-type=bandwidth&limit-resource=\" . $vars['bandwidth-name'] .\r\n                    '&limit-value=' . $vars['bandwidth-value'],\r\n            \"PUT\"\r\n        );\r\n    }\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_setLimitsForBucket($_GET);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-buckets-limits-in-whmcs.html"
    },
    {
        "title": "Creating volumes",
        "content": "Creating volumesPOST /v3/{project_id}/volumes\r\n\nCreate a volume.\nTo clone a volume, pass its ID in source_volid. To create a volume from a snapshot, pass its ID in snapshot_id.\nTo create a bootable volume, include the UUID of the image from\r\nwhich you want to create the volume in the imageRef attribute\r\nin the request body.\nPrecondition: You must have enough volume storage quota remaining to create a volume of size requested.\nAsynchronous postconditions:\n\nWith correct permissions, you can see the volume status as\r\navailable through API calls.\nWith correct access, you can see the created volume in the storage\r\nsystem that OpenStack Block Storage manages.\n\nTroubleshooting:\n\nIf volume status remains creating or another error\r\nstatus, the request has failed. Ensure you meet the preconditions\r\nthen investigate the storage back end.\nVolume is not created in the storage system that OpenStack Block\r\nStorage manages.\nThe storage node needs enough free storage space to match the size\r\nof the volume creation request.\n\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=create-a-volume-detail#create-a-volume\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nvolume\n\nbody\nobject\nA volume object.\n\nname (Optional)\nbody\nstring\nThe volume name.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\navailability_zone (Optional)\nbody\nstring\nThe name of the availability zone.\n\ndescription (Optional)\nbody\nstring\nThe volume description.\n\nmultiattach (Optional)\nbody\nboolean\nTo enable this volume to attach to more than one\r\nserver, set this value to true. Default is false.\r\nNote that support for multiattach volumes depends on the volume\r\ntype being used.\n\nsource_volid (Optional)\nbody\nstring\nThe UUID of the source volume. The API creates a new volume with the same\r\nsize as the source volume unless a larger size is requested.\n\nsnapshot_id (Optional)\nbody\nstring\nTo create a volume from an existing snapshot,\r\nspecify the UUID of the volume snapshot. The volume is created in\r\nsame availability zone and with same size as the snapshot.\n\nbackup_id (Optional)\nbody\nstring\n\nThe UUID of the backup.\nNew in version 3.47\n\nimageRef (Optional)\nbody\nstring\nThe UUID of the image from which you want to\r\ncreate the volume. Required to create a bootable volume.\n\nvolume_type (Optional)\nbody\nstring\nThe volume type (either name or ID). To create an environment with\r\nmultiple-storage back ends, you must specify a volume type. Block\r\nStorage volume back ends are spawned as children to cinder-\r\nvolume, and they are keyed from a unique queue. They are named\r\ncinder- volume.HOST.BACKEND. For example, cinder-\r\nvolume.ubuntu.lvmdriver. When a volume is created, the scheduler\r\nchooses an appropriate back end to handle the request based on the\r\nvolume type.  Default is None.  For information about how to\r\nuse volume types to create multiple- storage back ends, see\r\nConfigure multiple-storage back ends.\n\nmetadata (Optional)\nbody\nobject\nOne or more metadata key and value pairs to be associated\r\nwith the new volume.\n\nconsistencygroup_id\n\nbody\nstring\nThe UUID of the consistency group.\n\nOS-SCH-HNT:scheduler_hints (Optional)\nbody\nobject\nThe dictionary of data to send to the scheduler.\n\nExample\nCreate a 1 GiB volume vol2 with the policy policy1:# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"volume\": {\r\n    \"size\": 1,\r\n    \"description\": \"Volume 2\",\r\n    \"name\": \"vol2\",\r\n    \"volume_type\": \"policy1\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvolume\n\nbody\nobject\nA volume object.\n\nmigration_status (Optional)\nbody\nstring\nThe volume migration status. Admin only.\n\nattachments\n\nbody\narray\n\nInstance attachment information.  If this volume\r\nis attached to a server instance, the attachments list includes\r\nthe UUID of the attached server, an attachment UUID, the name of\r\nthe attached host, if any, the volume UUID, the device, and the\r\ndevice UUID.  Otherwise, this list is empty. For example:\n\n[\r\n  {\r\n    'server_id': '6c8cf6e0-4c8f-442f-9196-9679737feec6',\r\n    'attachment_id': '3dafcac4-1cb9-4b60-a227-d729baa10cf6',\r\n    'attached_at': '2019-09-30T19:30:34.000000',\r\n    'host_name': null,\r\n    'volume_id': '5d95d5ee-4bdd-4452-b9d7-d44ca10d3d53',\r\n    'device': '/dev/vda',\r\n    'id': '5d95d5ee-4bdd-4452-b9d7-d44ca10d3d53'\r\n  }\r\n]\r\n\n\nid\n\nbody\nstring\nThe UUID of the volume.\n\nlinks\n\nbody\narray\nThe volume links.\n\nname\n\nbody\nstring\nThe volume name.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\nbootable\n\nbody\nstring\nEnables or disables the bootable attribute. You\r\ncan boot an instance from a bootable volume.\n\nstatus\n\nbody\nstring\nThe volume status.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\navailability_zone (Optional)\nbody\nstring\nThe name of the availability zone.\n\ndescription\n\nbody\nstring\nThe volume description.\n\nmultiattach\n\nbody\nboolean\nIf true, this volume can attach to more than one\r\ninstance.\n\nsource_volid (Optional)\nbody\nstring\nThe UUID of the source volume. The API creates a new volume with the same\r\nsize as the source volume unless a larger size is requested.\n\nvolume_type\n\nbody\nstring\nThe associated volume type name for the volume.\n\nencrypted\n\nbody\nboolean\nIf true, this volume is encrypted.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nreplication_status\n\nbody\nstring\nThe volume replication status.\n\nsnapshot_id (Optional)\nbody\nstring\nTo create a volume from an existing snapshot,\r\nspecify the UUID of the volume snapshot. The volume is created in\r\nsame availability zone and with same size as the snapshot.\n\nuser_id\n\nbody\nstring\nThe UUID of the user.\n\nmetadata\n\nbody\nobject\nA metadata object. Contains one or more\r\nmetadata key and value pairs that are associated with the volume.\n\ngroup_id (Optional)\nbody\nstring\nThe ID of the group.\n\nconsistencygroup_id\n\nbody\nstring\nThe UUID of the consistency group.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nExample{\r\n  \"volume\": {\r\n    \"status\": \"creating\",\r\n    \"migration_status\": null,\r\n    \"user_id\": \"eb481bff7b7c4ec6a686646957d8064b\",\r\n    \"attachments\": [],\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8776/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"availability_zone\": \"nova\",\r\n    \"bootable\": \"false\",\r\n    \"encrypted\": false,\r\n    \"created_at\": \"2020-03-11T12:15:14.476003\",\r\n    \"description\": \"Volume 2\",\r\n    \"updated_at\": null,\r\n    \"volume_type\": \"policy1\",\r\n    \"name\": \"vol2\",\r\n    \"replication_status\": null,\r\n    \"consistencygroup_id\": null,\r\n    \"source_volid\": null,\r\n    \"snapshot_id\": null,\r\n    \"multiattach\": false,\r\n    \"metadata\": {},\r\n    \"id\": \"de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n    \"size\": 1\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-volumes.html"
    },
    {
        "title": "Creating outbound firewall rules",
        "content": "Creating outbound firewall rules\nTo create custom outbound firewall rules\nUse the following command:vinfra cluster network set --add-outbound-allow-list <rules> <network>\n\n--add-outbound-allow-list <rules>\n\nA comma-separated list of allow rules in the format: <address>:<protocol>:<port>:<description>, where:\n\n<address> is a single IP address (10.10.10.10), address range (10.10.10.0-10.10.10.10), or subnet CIDR (10.10.10.0/32)\n<protocol> can be udp, tcp, or any\n<port> is an integer value (22) or a range (20-22)\n<description> usually contains the name of the service that uses the specified port\n\n<network>\n\nNetwork ID or name\n\nThe cases when you need to create an additional rule are the following:\n\nIf you connect a remote iSCSI device to your cluster node, manually add a rule specifying the port number used for connecting this iSCSI device. For example:# vinfra cluster network set Public --add-outbound-allow-list \"0.0.0.0:tcp:3260:Remote iSCSI\"\n\nIf you plan to change the network configuration and IP address assignment of your cluster nodes by using network migration, manually add a rule specifying TCP and UDP ports 60000\u00e2\u0080\u009360100. For example:# vinfra cluster network set Public --add-outbound-allow-list \\\r\n\"0.0.0.0:tcp:60000-60100:Network migration\",\"0.0.0.0:udp:60000-60100:Network migration\"\n\nIf you plan to reassign an exclusive traffic type from one network to another, manually add rules specifying TCP and UDP ports 60000\u00e2\u0080\u009360100 for both networks. For example:# vinfra cluster network set Public --add-outbound-allow-list \\\r\n\"0.0.0.0:tcp:60000-60100:Network migration\",\"0.0.0.0:udp:60000-60100:Network migration\"\r\n# vinfra cluster network set MyNet --add-outbound-allow-list \\\r\n\"0.0.0.0:tcp:60000-60100:Network migration\",\"0.0.0.0:udp:60000-60100:Network migration\"\n\nIf you enable user authentication in an NFS share with Kerberos V5, manually add rules specifying TCP ports 88 and 749, UDP port 88, and the Kerberos server IP address. For example, if the IP address of the Kerberos server is 10.128.168.20, run:# vinfra cluster network set Public --add-outbound-allow-list \\\r\n\"10.128.168.20:tcp:88:Kerberos\",\"10.128.168.20:tcp:749:Kerberos\",\\\r\n\"10.128.168.20:udp:88:Kerberos\"\n\nIf you configure a custom port for a particular service, manually add a rule specifying the used port number. For example: # vinfra cluster network set Public --add-outbound-allow-list \"0.0.0.0:udp:161:Zabbix\"\n\nWhat's next\n\nRemoving outbound firewall rules",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-outbound-firewall-rules.html"
    },
    {
        "title": "Deleting IPsec connections",
        "content": "Deleting IPsec connectionsDELETE /v2.0/vpn/ipsec-site-connections/{connection_id}\nDelete an IPsec connection.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=remove-ipsec-connection-detail#remove-ipsec-connection\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nconnection_id\n\npath\nstring\nThe ID of the IPsec site-to-site connection.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ipsec-site-connections/324dc68b-bdee-4a78-9d14-3484d8ee97a9\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-ipsec-connections.html"
    },
    {
        "title": "Deleting virtual networks",
        "content": "Deleting virtual networksDELETE /v2.0/networks/{network_id}\r\n\nDelete a network with the specified ID and its associated resources.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=delete-network-detail#delete-network\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nnetwork_id\n\npath\nstring\nThe ID of the network.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/networks/ee3c3486-2ccc-457a-9b66-b974e164f358\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n412 - Precondition Failed\n\nThe server does not meet one of the preconditions that the requester put on the request header fields.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-virtual-networks.html"
    },
    {
        "title": "Managing high availability configuration",
        "content": "Managing high availability configuration\nOnce the management node high availability (HA) is created, it includes three nodes and protects your infrastructure from a failure of one management node. Additionally, you can expand the HA configuration up to five nodes, to  keep your cluster operational even if two management nodes fail simultaneously.\n\nThough it is possible to have four nodes in the management node HA, such a configuration should be considered intermediary, as it is highly recommended to have an odd number of nodes included.\n\nThe HA node that is used by the backend services is called Primary. After creating the HA configuration, the current management node usually becomes the primary one. You can change the primary node by promoting another node in the HA configuration to primary. When the primary node changes, the backend services move from the current management node to the selected HA node. During this operation, which may take up to five minutes, the admin and self-service panels, as well as the compute API, are unavailable.\nDepending on the number of nodes, management of the HA configuration may differ:\n\nWith a three-node configuration, that is, with the minimum number of nodes, removing a node from the HA configuration is not possible without destroying the management node HA. If one of the HA nodes fails, you need to replace it with a healthy one.\nWith a five-node configuration, you can remove up to two nodes without destroying the management node HA. If one of the HA nodes fails, you can either replace it with a healthy one in one iteration, or you can remove the failed node, and then add another one instead.\n\nWhen replacing a node in the HA configuration, you need to consider its role in the compute cluster:\n\nA node that is added to the compute cluster and used to host virtual machines has the Worker role. In the vinfra command-line tool, this role is called compute.\nA management node or a node that is included into the HA configuration has the Controller role. Such nodes are automatically added to the compute cluster, but they are not used to host VMs.\nA node that is not added to the compute cluster is called a storage node.\n\nThe replacement option depends on the Worker role, that is, whether a node belongs to the compute cluster. Worker nodes can only be replaced with other nodes from the compute cluster. Non-worker nodes have two options, they can be replaced with both compute and storage nodes. The figure below shows all possible replacement options in the five-node HA configuration.\n\nDestroying the HA configuration is required for network migration that enables changing network configuration.\nLimitations\n\nThe primary node cannot be replaced in the HA configuration.\nIf one or more management nodes enter the maintenance mode, a failure of another management node may affect high availability of the cluster.\nWhile the management node HA is being destroyed, management of the compute cluster may be unavailable.\n\nPrerequisites\n\nA clear understanding of the limitations listed in High availability and the compute cluster.\nThe HA configuration is created, as described in Enabling management node high availability.\n\nTo add nodes to the HA configuration\n\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nIn the High availability nodes section, click Options, and then click Add node.\nIn the Add node window, select one or two nodes to be added to the HA configuration, and then click Add.\n\nCommand-line interface\nUse the following command:vinfra cluster ha node add --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n\nFor example, to add the nodes node001 and node002 to the HA configuration, run:# vinfra cluster ha node add --nodes node001,node002\n\nTo change the primary node in the HA configuration\n\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nClick the ellipsis icon next to the node that you wish to make primary in the HA configuration, and then click Promote to primary node.\nIn the confirmation window, click Promote.\n\nDuring this operation, you will be logged out of the system due to migration of the backend services to the selected node.\n\nCommand-line interface\nUse the following command:vinfra cluster ha switch-primary <node> \n\n<node>\n\nName or ID of the new primary node\n\nFor example, to promote the node node001 to primary, run:# vinfra cluster ha switch-primary node001\n\nTo replace nodes in the HA configuration\n\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nClick the ellipsis icon next to the node that you wish to replace in the HA configuration, and then click Replace.\nIn the Replace node window, select the node that will be added into the HA configuration instead of the removed node, and then click Replace.\n\nOnce an offline node is removed from the high availability configuration, it will remain so after becoming available again.\n\nCommand-line interface\nUse the following command:vinfra cluster ha update [--virtual-ip <network:ip>] [--nodes <nodes>] [--force]\r\n\n\n--virtual-ip <network:ip>\n\nHA configuration mapping in the format:\n\nnetwork: network to include in the HA configuration (must include at least one of these traffic types: Internal management, Admin panel, Self-service panel, or Compute API).\nip: virtual IP address that will be used in the HA configuration.\n\nSpecify this option multiple times to create a HA configuration for multiple networks.\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--force\n\nSkip checks for minimal hardware requirements\n\nFor example, to update the management node HA configuration, that is, include the nodes node001, node002, and node005, run:# vinfra cluster ha update --nodes node001,node002,node005\n\nTo remove nodes from the HA configuration\n\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nClick the ellipsis icon next to the node that you wish to remove from the HA configuration, and then click Remove.\nIn the confirmation window, click Remove.\n\nCommand-line interface\nUse the following command:vinfra cluster ha node remove [--force] <node>\r\n\n\n--force\n\nSkip the compute cluster state and forcibly remove the node(s). This option is required when removing multiple nodes or offline nodes.\n<node>\n\nNode ID(s) or hostname(s) to be removed. Note that the HA configuration must have at least 3 nodes to be operational.\n\nFor example, to remove the nodes node002 and node005 from the HA configuration, run:# vinfra cluster ha node remove node002 node005 --force\n\nTo destroy the HA configuration\n\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nIn the High availability nodes section, click Options, and then click Destroy HA configuration.\nIn the confirmation window, click Destroy.\n\nOnce the high availability configuration is destroyed, you can log in to the admin panel at the IP address of the management node and on the same port 8888.\n\nCommand-line interface\nUse the following command:vinfra cluster ha delete\r\n\n\nSee also\n\nChanging network configuration",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster ha node add --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n\nFor example, to add the nodes node001 and node002 to the HA configuration, run:# vinfra cluster ha node add --nodes node001,node002\n",
                "title": "To add nodes to the HA configuration"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster ha switch-primary <node> \n\n<node>\n\n\nName or ID of the new primary node\n\n\nFor example, to promote the node node001 to primary, run:# vinfra cluster ha switch-primary node001\n",
                "title": "To change the primary node in the HA configuration"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster ha update [--virtual-ip <network:ip>] [--nodes <nodes>] [--force]\r\n\n\n--virtual-ip <network:ip>\n\n\nHA configuration mapping in the format:\n\nnetwork: network to include in the HA configuration (must include at least one of these traffic types: Internal management, Admin panel, Self-service panel, or Compute API).\nip: virtual IP address that will be used in the HA configuration.\n\nSpecify this option multiple times to create a HA configuration for multiple networks.\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--force\n\nSkip checks for minimal hardware requirements\n\nFor example, to update the management node HA configuration, that is, include the nodes node001, node002, and node005, run:# vinfra cluster ha update --nodes node001,node002,node005\n",
                "title": "To replace nodes in the HA configuration"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster ha node remove [--force] <node>\r\n\n\n--force\n\nSkip the compute cluster state and forcibly remove the node(s). This option is required when removing multiple nodes or offline nodes.\n<node>\n\nNode ID(s) or hostname(s) to be removed. Note that the HA configuration must have at least 3 nodes to be operational.\n\nFor example, to remove the nodes node002 and node005 from the HA configuration, run:# vinfra cluster ha node remove node002 node005 --force\n",
                "title": "To remove nodes from the HA configuration"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster ha delete\r\n\n",
                "title": "To destroy the HA configuration"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nIn the High availability nodes section, click Options, and then click Add node.\nIn the Add node window, select one or two nodes to be added to the HA configuration, and then click Add.\n\n",
                "title": "To add nodes to the HA configuration"
            },
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nClick the ellipsis icon next to the node that you wish to make primary in the HA configuration, and then click Promote to primary node.\nIn the confirmation window, click Promote.\n\nDuring this operation, you will be logged out of the system due to migration of the backend services to the selected node.\n",
                "title": "To change the primary node in the HA configuration"
            },
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nClick the ellipsis icon next to the node that you wish to replace in the HA configuration, and then click Replace.\nIn the Replace node window, select the node that will be added into the HA configuration instead of the removed node, and then click Replace.\n\nOnce an offline node is removed from the high availability configuration, it will remain so after becoming available again.\n",
                "title": "To replace nodes in the HA configuration"
            },
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nClick the ellipsis icon next to the node that you wish to remove from the HA configuration, and then click Remove.\nIn the confirmation window, click Remove.\n\n",
                "title": "To remove nodes from the HA configuration"
            },
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Management node high availability.\nIn the High availability nodes section, click Options, and then click Destroy HA configuration.\nIn the confirmation window, click Destroy.\n\nOnce the high availability configuration is destroyed, you can log in to the admin panel at the IP address of the management node and on the same port 8888.\n",
                "title": "To destroy the HA configuration"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-ha-configuration.html"
    },
    {
        "title": "5. Installing Leostream in Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "5. Installing Leostream in Virtuozzo Hybrid Infrastructure | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nThe Leostream Connection Broker must be installed in a location where it has network access to the Leostream Agents installed on your VDI instances. The following procedure covers installing a single instance of the Leostream Connection Broker and Leostream Gateway. For information on creating clusters of Connection Brokers for large-scale production environments, see the Leostream Scalability Guide.\n\nIn this chapter:\n\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/installing-leostream/index.html"
    },
    {
        "title": "Creating virtual machines",
        "content": "Creating virtual machines\nLimitations\n\nVirtual machines are created with the host CPU model, by default. Having compute nodes with different CPUs may lead to live migration issues. To avoid them, you can manually set the CPU model for all new VMs, as described in Setting virtual machine CPU model. Alternatively, you can create a placement for each group of compute nodes with the same CPU model by using the instructions in Managing placements for compute nodes.\n\nUEFI boot is not supported for CentOS 7.x virtual machines with less than 1 GiB of RAM.\n\nPrerequisites\n\nYou have a guest OS source prepared, as described in Preparing boot media for virtual machines.\nOne or more compute networks are created automatically during the compute cluster deployment or manually by using the instructions in Creating physical compute networks and Creating virtual compute networks.\n\nCustom security groups are configured, as instructed in Managing security groups.\n\nYou have a custom flavor created, as described in Creating custom flavors for virtual machines. You can also use preconfigured flavors.\n\nAn SSH key is added to the compute cluster, as outlined in Adding SSH keys for virtual machines. You can specify an SSH key only when creating VMs from a template or boot volume.\n\nA custom storage policy is created for volumes, as described in Managing storage policies.\n\nTo create a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click Create virtual machine. A window will open where you will need to specify the VM parameters.\n\nSpecify a name for the new VM.\n\nSelect the VM boot media:\n\nIf you have an ISO image or a template\n\nSelect Image in the Deploy from section, and then click Specify in the Image section.\n\nIn the Images window, select the ISO image or template, and then click Done.\n\nIf you have a compute boot volume\n\nSelect Volume in the Deploy from section, and then click Specify in the Volumes section.\nIn the Volumes window, click Attach.\n\nIn the Attach volume window, find and select the volume, and then click Attach.\n\nIf you attach more than one volume, the first attached volume becomes the boot volume, by default. To select another volume as bootable, place it first in the list by clicking the up arrow button next to it.\n\nIf you select an image or volume with an assigned placement, the created VM will also inherit this placement.\n\nAfter selecting the boot media, volumes required for this media to boot will be automatically added to the Volumes section.\n\nConfigure the VM disks:\n\nIn the Volumes window, make sure the default boot volume is large enough to accommodate the guest OS. Otherwise, click the ellipsis icon next to it, and then Edit. Change the volume size and click Save.\n\nAdd more disks to the VM by creating or attaching volumes. To do this, click the pencil icon in the Volumes section, and then Add or Attach in the Volumes window.\n\nSelect volumes that will be removed during the VM deletion. To do this, click the pencil icon in the Volumes section, click the ellipsis icon next to the needed volume, and then Edit. Enable Delete on termination and click Save.\nWhen you finish configuring the VM disks, click Done.\n\nChoose the amount of RAM and CPU resources that will be allocated to the VM in the Flavor section. In the Flavor window, select a flavor, and then click Done.\n\nWhen choosing a flavor for a VM, ensure it satisfies the hardware requirements of the guest OS.\n\nTo select a flavor with an assigned placement, you can filter flavors by placement. The VM created from such a flavor will also inherit this placement.\n\nAdd network interfaces to the VM in the Networks section:\n\nIn the Network interfaces window, click Add to attach a network interface.\n\nIn the Add network interface window, select a compute network to connect to, and then specify MAC address, IPv4 and/or IPv6 addresses, and security groups. By default, MAC and primary IP addresses are assigned automatically. To specify them manually, clear the Assign automatically check boxes, and enter the desired addresses. Optionally, assign additional IP addresses to the network interface in the Secondary IP addresses section. Note that a secondary IPv6 address is not available for an IPv6 subnet that works in the SLAAC or DHCPv6 stateless mode.\n\nSecondary IP addresses, unlike the primary one, will not be automatically assigned to the network interface inside the virtual machine guest OS. You should assign them manually.\n\nIf you selected a network with enabled IP address management\n\nIn this case, spoofing protection is enabled and the default security group is selected by default. This security group allows all incoming and outgoing traffic on all the VM ports. If required, you can select another security group or multiple security groups.\nTo disable spoofing protection, clear all of the check boxes and turn off the toggle switch. Security groups cannot be configured with disabled spoofing protection.\n\nIf you selected a network with disabled IP address management\nIn this case, spoofing protection is disabled by default and cannot be enabled. Security groups cannot be configured for such a network.\n\nAfter specifying the network interface parameters, click Add. The network interface will appear in the Network interfaces list.\n\nIf required, edit IP addresses and security groups of newly added network interfaces. To do this, click the ellipsis icon, click Edit, and then set the parameters.\n\nWhen you finish configuring the VM network interfaces, click Done.\n\nIf you have chosen to boot from a template or volume, which has cloud-init and OpenSSH installed:\n\nAs cloud images have no default password, you can access VMs deployed from them only by using the key authentication method with SSH.\n\nAdd an SSH key to the VM, to be able to access it via SSH without a password. \n\nIn the Select an SSH key window, select an SSH key  and then click Done.\n\nAdd user data to customize the VM after launch, for example, change a user password. \n\nWrite a cloud-config or shell script in the Customization script field or browse a file on your local server to load the script from.\n\nTo inject a script in a Windows VM, refer to the Cloudbase-Init documentation. For example, you can set a new password for the account using the following script:#ps1\r\nnet user <username> <new_password>\r\n\n\nEnable CPU and RAM hot plug for the VM in Advanced options, to be able to change its flavor when the VM is running. You can also enable hot plug after the VM is created.\n\nIf you have chosen to boot from an ISO image, enable UEFI boot in Advanced options, to be able to boot the VM in the UEFI mode. This option cannot be configured after the VM is created.\n\nYou cannot configure UEFI boot if you have selected a template as the VM boot media. If your template has UEFI boot enabled, the option is automatically enabled for the VM, and vice versa.\n\nAfter configuring all of the VM parameters, click Deploy to create and boot the VM.\n\nIf you are deploying the VM from an ISO image, you need to install the guest OS inside the VM by using the built-in VNC console. For VMs with UEFI boot enabled, open the VNC console, and then press any key to boot from the chosen ISO image. Virtual machines created from a template or a boot volume already have a preinstalled guest OS.\n\nCommand-line interface\nUse the following command:vinfra service compute server create [--description <description>]\r\n                                     [--metadata <metadata>]\r\n                                     [--user-data <user-data>]\r\n                                     [--key-name <key-name>]\r\n                                     [--config-drive] [--count <count>]\r\n                                     [--ha-enabled {true,false}]\r\n                                     [--placements <placements>]\r\n                                     [--allow-live-resize] [--uefi]\r\n                                     --network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\r\n                                     --volume <source=source\r\n                                     [,key=value,\u00e2\u0080\u00a6]>\r\n                                     --flavor <flavor> <server-name>\r\n\n\n--description <description>\n\nVirtual machine description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--metadata <metadata>\n\nVirtual machine metadata\n--user-data <user-data>\n\nUser data file\n--key-name <key-name>\n\nKey pair to inject\n--config-drive\n\nUse an ephemeral drive\n--count <count>\n\nIf count is specified and greater than 1, the name argument is treated as a naming pattern.\n--ha-enabled {true,false}\n\nEnable or disable HA for the virtual machine.\n--placements <placements>\n\nNames or IDs of placements to add the virtual machine to.\n--allow-live-resize\n\nAllow online resize for the virtual machine.\n--uefi\n\nAllow UEFI boot for the virtual machine. This option can be used for VMs created from ISO images.\n--network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\n\nCreate a virtual machine with a specified network. Specify this option multiple times to create multiple networks.\n\nid: attach network interface to a specified network (ID or name)\ncomma-separated key=value pairs with keys (optional):mac: MAC address for network interfacefixed-ip: fixed IP address or None to automatically allocate an IP address. This option can be used multiple times.spoofing-protection-enable: enable spoofing protection for network interfacespoofing-protection-disable: disable spoofing protection for network interfacesecurity-group: security group ID or name. This option can be used multiple times.no-security-group: do not use a security group\n\n--volume <source=source[,key=value,\u00e2\u0080\u00a6]>\n\nCreate a virtual machine with a specified volume. Specify this option multiple times to create multiple volumes.\n\nsource: source type (volume, image, snapshot, or blank)\ncomma-separated key=value pairs with keys (optional):id: resource ID or name for the specified source type (required for source types volume, image, and snapshot)size: block device size, in gigabytes (required for source types image and blank)boot-index: block device boot index (required for multiple volumes with source type volume)bus: block device controller type (ide, usb, virtio, scsi, or sata) (optional)type: block device type (disk or cdrom) (optional)rm: remove block device on virtual machine termination (yes or no) (optional)storage-policy: block device storage policy\n\n--flavor <flavor>\n\nFlavor ID or name\n<server-name>\n\nA new name for the virtual machine\n\nFor example, to create a virtual machine myvm based on the image cirros and the flavor tiny, connect it to the virtual network private with the fixed IP address 192.168.128.100, run:# vinfra service compute server create myvm --network id=private,fixed-ip=192.168.128.100 \\\r\n--volume source=image,id=cirros,size=1 --flavor tiny\r\n+--------------+--------------------------------------+\r\n| Field        | Value                                |\r\n+--------------+--------------------------------------+\r\n| config_drive |                                      |\r\n| created      | 2019-05-29T11:24:04Z                 |\r\n| description  |                                      |\r\n| flavor       | disk: 0                              |\r\n|              | ephemeral: 0                         |\r\n|              | extra_specs: {}                      |\r\n|              | original_name: tiny                  |\r\n|              | ram: 512                             |\r\n|              | swap: 0                              |\r\n|              | vcpus: 1                             |\r\n| ha_enabled   | True                                 |\r\n| host         |                                      |\r\n| id           | 8cd29296-8bee-4efb-828d-0e522d816c6e |\r\n| key_name     |                                      |\r\n| metadata     | {}                                   |\r\n| name         | myvm                                 |\r\n| networks     | []                                   |\r\n| power_state  | NOSTATE                              |\r\n| project_id   | b4267de6fd0c442da99542cd20f5932c     |\r\n| status       | BUILD                                |\r\n| task_state   | scheduling                           |\r\n| updated      | 2019-05-29T11:24:21Z                 |\r\n| user_data    |                                      |\r\n| vm_state     | building                             |\r\n| volumes      | []                                   |\r\n+--------------+--------------------------------------+\r\n\nThe new virtual machine will appear in the vinfra service compute server list output:# vinfra service compute server list\r\n+-------------+------+--------+------------------------+---------------------------+\r\n| id          | name | status | host                   | networks                  |\r\n+-------------+------+--------+------------------------+---------------------------+\r\n| 8cd29296<\u00e2\u0080\u00a6> | myvm | ACTIVE | node002.vstoragedomain | - private=192.168.128.100 |\r\n+-------------+------+--------+------------------------+---------------------------+\n\nSee also\n\nCreating virtIO disks for virtual machines\n\nAttaching host devices to virtual machines\n\nManaging virtual machine power state\n\nMonitoring virtual machines\n\nTroubleshooting virtual machines\n\nWhat's next\n\nConnecting to virtual machines\n\nManaging guest tools",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server create [--description <description>]\r\n                                     [--metadata <metadata>]\r\n                                     [--user-data <user-data>]\r\n                                     [--key-name <key-name>]\r\n                                     [--config-drive] [--count <count>]\r\n                                     [--ha-enabled {true,false}]\r\n                                     [--placements <placements>]\r\n                                     [--allow-live-resize] [--uefi]\r\n                                     --network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\r\n                                     --volume <source=source\r\n                                     [,key=value,\u00e2\u0080\u00a6]>\r\n                                     --flavor <flavor> <server-name>\r\n\n\n--description <description>\n\n\nVirtual machine description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--metadata <metadata>\n\nVirtual machine metadata\n--user-data <user-data>\n\nUser data file\n--key-name <key-name>\n\nKey pair to inject\n--config-drive\n\nUse an ephemeral drive\n--count <count>\n\nIf count is specified and greater than 1, the name argument is treated as a naming pattern.\n--ha-enabled {true,false}\n\nEnable or disable HA for the virtual machine.\n--placements <placements>\n\nNames or IDs of placements to add the virtual machine to.\n--allow-live-resize\n\nAllow online resize for the virtual machine.\n--uefi\n\nAllow UEFI boot for the virtual machine. This option can be used for VMs created from ISO images.\n--network id|<id=id[,key=value,\u00e2\u0080\u00a6]>\n\n\nCreate a virtual machine with a specified network. Specify this option multiple times to create multiple networks.\n\nid: attach network interface to a specified network (ID or name)\ncomma-separated key=value pairs with keys (optional):mac: MAC address for network interfacefixed-ip: fixed IP address or None to automatically allocate an IP address. This option can be used multiple times.spoofing-protection-enable: enable spoofing protection for network interfacespoofing-protection-disable: disable spoofing protection for network interfacesecurity-group: security group ID or name. This option can be used multiple times.no-security-group: do not use a security group\n\n\n--volume <source=source[,key=value,\u00e2\u0080\u00a6]>\n\n\nCreate a virtual machine with a specified volume. Specify this option multiple times to create multiple volumes.\n\nsource: source type (volume, image, snapshot, or blank)\ncomma-separated key=value pairs with keys (optional):id: resource ID or name for the specified source type (required for source types volume, image, and snapshot)size: block device size, in gigabytes (required for source types image and blank)boot-index: block device boot index (required for multiple volumes with source type volume)bus: block device controller type (ide, usb, virtio, scsi, or sata) (optional)type: block device type (disk or cdrom) (optional)rm: remove block device on virtual machine termination (yes or no) (optional)storage-policy: block device storage policy\n\n\n--flavor <flavor>\n\nFlavor ID or name\n<server-name>\n\nA new name for the virtual machine\n\nFor example, to create a virtual machine myvm based on the image cirros and the flavor tiny, connect it to the virtual network private with the fixed IP address 192.168.128.100, run:# vinfra service compute server create myvm --network id=private,fixed-ip=192.168.128.100 \\\r\n--volume source=image,id=cirros,size=1 --flavor tiny\r\n+--------------+--------------------------------------+\r\n| Field        | Value                                |\r\n+--------------+--------------------------------------+\r\n| config_drive |                                      |\r\n| created      | 2019-05-29T11:24:04Z                 |\r\n| description  |                                      |\r\n| flavor       | disk: 0                              |\r\n|              | ephemeral: 0                         |\r\n|              | extra_specs: {}                      |\r\n|              | original_name: tiny                  |\r\n|              | ram: 512                             |\r\n|              | swap: 0                              |\r\n|              | vcpus: 1                             |\r\n| ha_enabled   | True                                 |\r\n| host         |                                      |\r\n| id           | 8cd29296-8bee-4efb-828d-0e522d816c6e |\r\n| key_name     |                                      |\r\n| metadata     | {}                                   |\r\n| name         | myvm                                 |\r\n| networks     | []                                   |\r\n| power_state  | NOSTATE                              |\r\n| project_id   | b4267de6fd0c442da99542cd20f5932c     |\r\n| status       | BUILD                                |\r\n| task_state   | scheduling                           |\r\n| updated      | 2019-05-29T11:24:21Z                 |\r\n| user_data    |                                      |\r\n| vm_state     | building                             |\r\n| volumes      | []                                   |\r\n+--------------+--------------------------------------+\r\n\nThe new virtual machine will appear in the vinfra service compute server list output:# vinfra service compute server list\r\n+-------------+------+--------+------------------------+---------------------------+\r\n| id          | name | status | host                   | networks                  |\r\n+-------------+------+--------+------------------------+---------------------------+\r\n| 8cd29296<\u00e2\u0080\u00a6> | myvm | ACTIVE | node002.vstoragedomain | - private=192.168.128.100 |\r\n+-------------+------+--------+------------------------+---------------------------+\n",
                "title": "To create a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOn the Compute > Virtual machines > Virtual machines tab, click Create virtual machine. A window will open where you will need to specify the VM parameters.\n\nSpecify a name for the new VM.\n\nSelect the VM boot media:\n\n\nIf you have an ISO image or a template\n\n\nSelect Image in the Deploy from section, and then click Specify in the Image section.\n\nIn the Images window, select the ISO image or template, and then click Done.\n\n\n\n\n\n\n\n\n\n\nIf you have a compute boot volume\n\n\nSelect Volume in the Deploy from section, and then click Specify in the Volumes section.\nIn the Volumes window, click Attach.\n\nIn the Attach volume window, find and select the volume, and then click Attach.\n\n\n\n\nIf you attach more than one volume, the first attached volume becomes the boot volume, by default. To select another volume as bootable, place it first in the list by clicking the up arrow button next to it.\n\n\n\n\n\n\n\nIf you select an image or volume with an assigned placement, the created VM will also inherit this placement.\n\nAfter selecting the boot media, volumes required for this media to boot will be automatically added to the Volumes section.\n\n\nConfigure the VM disks:\n\nIn the Volumes window, make sure the default boot volume is large enough to accommodate the guest OS. Otherwise, click the ellipsis icon next to it, and then Edit. Change the volume size and click Save.\n\nAdd more disks to the VM by creating or attaching volumes. To do this, click the pencil icon in the Volumes section, and then Add or Attach in the Volumes window.\n\nSelect volumes that will be removed during the VM deletion. To do this, click the pencil icon in the Volumes section, click the ellipsis icon next to the needed volume, and then Edit. Enable Delete on termination and click Save.\nWhen you finish configuring the VM disks, click Done.\n\n\n\nChoose the amount of RAM and CPU resources that will be allocated to the VM in the Flavor section. In the Flavor window, select a flavor, and then click Done.\n\nWhen choosing a flavor for a VM, ensure it satisfies the hardware requirements of the guest OS.\n\n\nTo select a flavor with an assigned placement, you can filter flavors by placement. The VM created from such a flavor will also inherit this placement.\n\n\n\n\n\n\n\nAdd network interfaces to the VM in the Networks section:\n\nIn the Network interfaces window, click Add to attach a network interface.\n\nIn the Add network interface window, select a compute network to connect to, and then specify MAC address, IPv4 and/or IPv6 addresses, and security groups. By default, MAC and primary IP addresses are assigned automatically. To specify them manually, clear the Assign automatically check boxes, and enter the desired addresses. Optionally, assign additional IP addresses to the network interface in the Secondary IP addresses section. Note that a secondary IPv6 address is not available for an IPv6 subnet that works in the SLAAC or DHCPv6 stateless mode.\n\nSecondary IP addresses, unlike the primary one, will not be automatically assigned to the network interface inside the virtual machine guest OS. You should assign them manually.\n\n\n\nIf you selected a network with enabled IP address management\n\nIn this case, spoofing protection is enabled and the default security group is selected by default. This security group allows all incoming and outgoing traffic on all the VM ports. If required, you can select another security group or multiple security groups.\nTo disable spoofing protection, clear all of the check boxes and turn off the toggle switch. Security groups cannot be configured with disabled spoofing protection.\n\n\n\n\nIf you selected a network with disabled IP address management\nIn this case, spoofing protection is disabled by default and cannot be enabled. Security groups cannot be configured for such a network.\n\n\n\n\n\n\n\nAfter specifying the network interface parameters, click Add. The network interface will appear in the Network interfaces list.\n\n\nIf required, edit IP addresses and security groups of newly added network interfaces. To do this, click the ellipsis icon, click Edit, and then set the parameters.\n\nWhen you finish configuring the VM network interfaces, click Done.\n\n\n\nIf you have chosen to boot from a template or volume, which has cloud-init and OpenSSH installed:\n\nAs cloud images have no default password, you can access VMs deployed from them only by using the key authentication method with SSH.\n\n\n\nAdd an SSH key to the VM, to be able to access it via SSH without a password. \n\nIn the Select an SSH key window, select an SSH key  and then click Done.\n\n\n\n\n\n\n\n\nAdd user data to customize the VM after launch, for example, change a user password. \n\nWrite a cloud-config or shell script in the Customization script field or browse a file on your local server to load the script from.\n\n\n\n\nTo inject a script in a Windows VM, refer to the Cloudbase-Init documentation. For example, you can set a new password for the account using the following script:#ps1\r\nnet user <username> <new_password>\r\n\n\n\n\n\n\n\nEnable CPU and RAM hot plug for the VM in Advanced options, to be able to change its flavor when the VM is running. You can also enable hot plug after the VM is created.\n\n\nIf you have chosen to boot from an ISO image, enable UEFI boot in Advanced options, to be able to boot the VM in the UEFI mode. This option cannot be configured after the VM is created.\n\nYou cannot configure UEFI boot if you have selected a template as the VM boot media. If your template has UEFI boot enabled, the option is automatically enabled for the VM, and vice versa.\n\n\nAfter configuring all of the VM parameters, click Deploy to create and boot the VM.\n\nIf you are deploying the VM from an ISO image, you need to install the guest OS inside the VM by using the built-in VNC console. For VMs with UEFI boot enabled, open the VNC console, and then press any key to boot from the chosen ISO image. Virtual machines created from a template or a boot volume already have a preinstalled guest OS.\n",
                "title": "To create a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtual-machines.html"
    },
    {
        "title": "Configuring the default CORS behavior",
        "content": "Configuring the default CORS behavior\nCross-origin resource sharing (CORS) is a protocol that defines how resources from different origins interact. By default, the CORS behavior is configured to allow access from all origins and applies to all buckets with no CORS policy specified.\nTo check the CORS settings, use the ostor-ctl get-settings command:# ostor-ctl get-settings\r\n NS.bkup_hour=-24\r\n OS.bkup_hour=-24\r\n OS.max_count=100\r\n OS.max_size=1000\r\n cfg.autosplit.enabled=1\r\n cfg.autosplit.max_active=1\r\n gen.lj.max_size_mb=2048\r\n gen.lj.min_size_mb=16\r\n gen.paxos.cache_size=0\r\n gen.paxos.lease_tout=5000\r\n gen.rj.mismatch_abort=1\r\n gen.rj.obj_type_dump=0\r\n hostd.automaintenance.enabled=0\r\n hostd.automaintenance.threshold=10\r\n ostor.default_cors.enabled=1\nFor security reasons, you may want to change the default CORS behavior to disable all cross-origin requests unless a CORS policy is specified for a bucket. To do this, use the ostor-ctl put-settings command and specify ostor.default_cors.enabled=0:# ostor-ctl put-settings ostor.default_cors.enabled=0\nSee also\n\nSupported Amazon S3 features\n\nManaging S3 buckets\n\nConfiguring the S3 storage usage limit",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-default-cors-behavior.html"
    },
    {
        "title": "Using network policies in Kubernetes",
        "content": "Using network policies in Kubernetes\n\nThis feature is experimental and not intended for use in production environments.\n\nNetwork policies are used to control network traffic in a Kubernetes cluster. By default, all outbound and inbound connections are allowed for a pod. You can provide network isolation for your pods by using network policies.\nA network policy applies to a pod or a group of pods and sets a list of allowed targets for its ingress and egress rules. These targets can be one of the following:\n\nSpecific pods (pods matching a label are allowed)\nSpecific namespaces (all pods in the namespace are allowed)\nIP address blocks (endpoints with an IP address in the block are allowed) \n\nIf you want to isolate a pod for outbound connections, you need to create a network policy that selects this pod and has Egress in its policyTypes. Similarly, to isolate a pod for inbound connections, a network policy should select this pod and have Ingress in its policyTypes. In this case, the only allowed connections to and from the pod will be those allowed by the ingress and egress lists. Note that traffic to and from the node where a pod is running is always allowed, as well as reply traffic for allowed connections.\nNetwork policies are additive, so you can have multiple policies for a pod. Allowed connections to and from the pod will be the sum of the allow rules in the applicable policies. If the allow rules are not specified, all of the connections will be blocked.\nTo allow a connection from one pod to another, both of these pods must have respective egress and ingress policies allowing each other. If either side does not allow the connection, it will not happen.\nTo ensure that your Kubernetes cluster is protected from accidental network exposure, you can create a default deny all policy, and then add specific allow policies for the required traffic flows.\nLimitations\n\nThe default network plugin does not support network policies.\n\nPrerequisites\n\nA Kubernetes cluster is created with the Cilium network plugin. To do this, you need to use Kubernetes version 1.29.3 and specify the network_driver=cilium label in the Labels section, as described in Creating and deleting Kubernetes clusters.\n\nTo create a default deny all network policy\nUse the following default-deny-all.yaml file:apiVersion: networking.k8s.io/v1\r\nkind: NetworkPolicy\r\nmetadata:\r\n  name: default-deny-all\r\nspec:\r\n  podSelector: {}\r\n  policyTypes:\r\n    - Ingress\r\n    - Egress\nThis manifest specifies the network policy default-deny-all that applies to all pods in the namespace and prevents all ingress and egress traffic.\nTo create a default allow all network policy for a pod\nUse the following allow-all-demo.yaml file:apiVersion: networking.k8s.io/v1\r\nkind: NetworkPolicy\r\nmetadata:\r\n  name: allow-all-demo\r\nspec:\r\n  podSelector:\r\n    matchLabels:\r\n      app: demo\r\n  policyTypes:\r\n    - Ingress\r\n    - Egress\r\n  ingress:\r\n    - {}\r\n  egress:\r\n    - {}\r\n\nThis manifest specifies the network policy allow-all-demo that applies to all pods labeled app=demo and allows all ingress and egress traffic.\nTo create a pod-based network policy\nUse the following pod-based-policy.yaml file that defines the NetworkPolicy object:apiVersion: networking.k8s.io/v1\r\nkind: NetworkPolicy\r\nmetadata:\r\n  name: pod-based-policy\r\n  namespace: default\r\nspec:\r\n  podSelector:\r\n    matchLabels:\r\n      app: pod1\r\n  policyTypes:\r\n    - Ingress\r\n    - Egress\r\n  ingress:\r\n    - from:\r\n      - podSelector:\r\n          matchLabels:\r\n            app: pod2\r\n  egress:\r\n    - to:\r\n      - podSelector:\r\n          matchLabels:\r\n            app: pod2\nThis manifest specifies the network policy pod-based-policy that applies to all pods labeled app=pod1 and allows ingress and egress traffic from all pods with the label app=pod2.\nTo create a namespace-based network policy\nUse the following namespace-based-policy.yaml file that defines the NetworkPolicy object:apiVersion: networking.k8s.io/v1\r\nkind: NetworkPolicy\r\nmetadata:\r\n  name: namespace-based-policy\r\n  namespace: default\r\nspec:\r\n  podSelector:\r\n    matchLabels:\r\n      app: pod1\r\n  policyTypes:\r\n    - Ingress\r\n    - Egress\r\n  ingress:\r\n    - from:\r\n      - namespaceSelector:\r\n          matchLabels:\r\n            kubernetes.io/metadata.name: demo-namespace\r\n  egress:\r\n    - to:\r\n      - namespaceSelector:\r\n          matchLabels:\r\n            kubernetes.io/metadata.name: demo-namespace\nThis manifest specifies the network policy namespace-based-policy that applies to all pods labeled app=pod1 and allows ingress and egress traffic from all pods running in the namespace demo-namespace.\nTo create an IP-based network policy\nUse the following ip-based-policy.yaml file that defines the NetworkPolicy object:apiVersion: networking.k8s.io/v1\r\nkind: NetworkPolicy\r\nmetadata:\r\n  name: ip-based-policy\r\n  namespace: default\r\nspec:\r\n  podSelector:\r\n    matchLabels:\r\n      app: pod1\r\n  policyTypes:\r\n    - Ingress\r\n    - Egress\r\n  ingress:\r\n    - from:\r\n      - ipBlock:\r\n          cidr: 10.10.10.0/24\r\n  egress:\r\n    - to:\r\n      - ipBlock:\r\n          cidr: 10.10.10.0/24\nThis manifest specifies the network policy ip-based-policy that applies to all pods labeled app=pod1 and allows ingress and egress traffic from the subnet 10.10.10.0/24.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/using-network-policies-in-kubernetes.html"
    },
    {
        "title": "DELETE service replication",
        "content": "DELETE service replication\nDescription\nDeletes replication configuration for the specified bucket.\nRequests\nSyntaxDELETE /?replication HTTP/1.1\r\nHost: <bucket>.<host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nDELETE service replication parameters\n\nParameter\t\nDescription\t\nRequired\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes\n\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nExamples\nSample request\nDeletes replication configuration of the bucket\u00a0test.DELETE/?replication HTTP/1.1\r\nHost: test.s3.example.com\r\nDate: Tu, 18 Jan 2021 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample responseHTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Tu, 21 Jan 2021 14:08:56 GMT",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/delete-service-replication.html"
    },
    {
        "title": "Rescuing virtual machines",
        "content": "Rescuing virtual machines\nIf a VM experiences boot problems, you can send it to the rescue mode to access its boot volume. When a VM in the \u00e2\u0080\u009cActive\u00e2\u0080\u009d state is sent to the rescue mode, it is shut down softly first. Once the VM is in the rescue mode, you can connect to it via SSH or via the console. Its previous boot disk is now attached as a secondary one. You can mount the disk and repair it.\nLimitations\n\nThe rescue mode can use ISO images for booting both Linux and Windows virtual machines and QCOW2 images (templates) for booting Linux VMs. For instructions on making templates, refer to Preparing templates.\nYou can send a VM to the rescue mode only if its current status is \u00e2\u0080\u009cActive\u00e2\u0080\u009d or \u00e2\u0080\u009cShut down\u00e2\u0080\u009d.\nThere are only three actions available for the VM in the rescue mode: Console, Exit rescue mode, and Delete.\nIf a rescue image has cloud-init installed, then the VM booted from it can be accessed with the same SSH key that was used for its creation.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo put a virtual machine to the rescue mode\n\nOn the Virtual machines screen, click the required VM on the list.\nOn the VM right pane, click the ellipsis button on the toolbar. Then, click Enter rescue mode.\n\nIn the Enter rescue mode window, select an image to rescue the VM with. By default, the initial image used for creating the VM is selected. Click Enter.\n\nThe machine status changes to \u00e2\u0080\u009cRescue\u00e2\u0080\u009d. \n\nTo return a virtual machine to normal operation\n\nOn the Virtual machines screen, click the required VM on the list.\nOn the VM right pane, click Exit rescue mode.\nIn the Exit rescue mode window, click Exit. The VM will be automatically rebooted.\n\nThe VM status changes to \u00e2\u0080\u009cActive\u00e2\u0080\u009d and it boots from the original root disk.\n\nIf the VM status changes to \u00e2\u0080\u009cError\u00e2\u0080\u009d when exiting the rescue mode, you can reset its status with the Reset state action. The VM should then return to the \u00e2\u0080\u009cRescue\u00e2\u0080\u009d status again.\n\nTo exit the rescue mode for a Windows VM\nThere might be an issue of exiting the rescue mode for a Windows VM. If in the rescue mode you set the original system disk online, its ID becomes the same as that of the rescue disk. Then, when you try to exit the rescue mode, the boot loader cannot find the proper boot disk. To resolve the ID conflict, follow the steps:\n\nWith the VM in the rescue mode, open the Disk Management window and note the numbers of the original system disk (offline) and the rescue disk (online). Set the original system disk to Online.\n\nTo edit the boot configuration, enter the following command in the Command Prompt window:> bcdedit /store <the original system disk name>:\\boot\\bcd\r\n\n\nReview the output and check that the rescue disk is the target for objects in the output (partition=<the rescue disk name>).\nIf the objects do not point to drive C, fix it with the following commands:> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {default} osdevice partition=<the rescue disk name>:\r\n> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {default} device partition=<the rescue disk name>:\r\n> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {bootmgr} device partition=<the rescue disk name>:\r\n> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {memdiag} device partition=<the rescue disk name>:\r\n\n\nTo view the available disks, enter the following commands in the command line:> DISKPART\r\n> LIST DISK\r\n\nMatch the disk number and name to those displayed in the Disk Management window.\n\nTo get the ID of the rescue disk, run the following commands:> SELECT DISK <the rescue disk number>\r\n> UNIQUEID DISK\r\n\nRecord the disk ID, you will need it later.\n\nChange this ID by using the following command:> UNIQUEID DISK id=<any hex value of 8 characters>\r\n\nMake sure that the value has changed with the UNIQUEID DISK command.\n\nAssign the ID that you recorded previusly to the original system disk:> SELECT DISK <the original system disk number>\r\n> UNIQUEID DISK id=<the recorded disk ID>\r\n\nMake sure that the value has changed with the UNIQUEID DISK command.\n\nYou should now be able to exit the rescue mode.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/rescuing-virtual-machines.html"
    },
    {
        "title": "Managing Kubernetes clusters",
        "content": "Managing Kubernetes clusters",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-kubernetes-clusters.html"
    },
    {
        "title": "Creating assets",
        "content": "Creating assets\nAn asset represents a product instance provisioned to a customer. In this case, it is a customer project with defined quotas in Virtuozzo Hybrid Infrastructure. \nYou can create an asset for testing purposes as follows:\n\nIn the vendor portal, go to the Assets page and click + Create asset.\nIn Create Asset \u00e2\u0080\u0094 Step 1 Introduction, read about assets and click Next.\n\nIn Create Asset \u00e2\u0080\u0094 Step 2 Product, select a product  and click Next.\n\nIn Create Asset \u00e2\u0080\u0094 Step 3 Marketplace, select a marketplace available for the provider and click Next.\n\nIn Create Asset \u00e2\u0080\u0094 Step 4 Tiers, select the tier configuration depending on the tier model of your marketplace and click Next.\n\n(Optional, appears only if you have chosen T1+T2 reseller tiers model) In Create Asset \u00e2\u0080\u0094 Step 5 T2 Account, choose a T2 reseller account from the drop-down list or create a new one by clicking New. Then click Next.\nIn Create Asset \u00e2\u0080\u0094 Step 6 T1 Account, choose a T1 reseller account from the drop-down list or create a new one by clicking New. Then click Next.\nIn Create Asset \u00e2\u0080\u0094 Step 7 Customer, choose a customer from the drop-down list or create a new one by clicking New. Then click Next.\n\nIn Create Asset \u00e2\u0080\u0094 Step 8 Asset Items, click + Add Items. \nIn a window that opens, select all items that represent compute resources in Virtuozzo Hybrid Infrastructure and click Select. \n\nFor the reservation model, change the quantity for items you need. For the pay-as-you-go model, the item quantity cannot be defined. Then click Next.\n\nIf you are not going to use all of the items, you can exclude unnecessary ones from the asset later by setting their quantity to 0.\n\nIn Create Asset \u00e2\u0080\u0094 Step 9 Attributes, leave the default external ID and UUID, and click Next.\n\nIn Create Asset \u00e2\u0080\u0094 Step 10 Parameters, specify the project name and user credentials for a project and user that will be created in Virtuozzo Hybrid Infrastructure. Then click Create.\n\nIn Create Asset \u00e2\u0080\u0094 Step 11 Summary, review the created objects and their current statuses. Click Close to return to the list of assets.\n\nAfter the asset is created, its status is changed to Active. You can view the asset details by clicking its ID. The asset page also provides the link to the VDC login page. The Requests tab contains all requests associated with this asset.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/creating-assets.html"
    },
    {
        "title": "Querying default quotas via REST API",
        "content": "Querying default quotas via REST API\nYou can display the default quotas for all users or buckets with the ostor-quotas service and the following parameters: default specifying user for users or bucket for buckets:# s3_curl GET \"http://s3.example.com/?ostor-quotas&default=user\"\r\n{\r\n    \"version\": \"1\",\r\n    \"type\": \"user\",\r\n    \"size\": \"1024\"\r\n}# s3_curl GET \"http://s3.example.com/?ostor-quotas&default=bucket\"\r\n{\r\n    \"version\": \"1\",\r\n    \"type\": \"bucket\",\r\n    \"size\": \"256\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-default-quotas-via-rest-api.html"
    },
    {
        "title": "Includes",
        "content": "Includes\nShared functions required by API operations are provided in a number of standalone PHP include files. The first file returns the client information (for example, email address) which further S3 API user management requests need for various operations. Create a file S3_getClient.php with the following contents:<?php\r\n\r\n// API request to get whmcs client information.\r\nif (!function_exists('S3_getClient')) {\r\n    function S3_getClient($userid, $whmcs_username) {\r\n\r\n        // Get client details for user email.\r\n        $command = 'GetClientsDetails';\r\n        $data = array(\r\n            'clientid' => $userid,\r\n        );\r\n        $results = localAPI($command, $data, $whmcs_username);\r\n\r\n        // Return client information.\r\n     return $results;\r\n    }\r\n}\r\n\r\n?>\r\n\nThe next file adds notes to the client in WHMCS with the S3 access key pairs whenever a new user or access key pair is created. Create a file S3_addClientNote.php with the following contents:<?php\r\n\r\n// API request to add note to client in whmcs.\r\nif (!function_exists('S3_addClientNote')) {\r\n    function S3_addClientNote(\r\n        $userid,\r\n        $whmcs_username,\r\n        $s3_client_userid,\r\n        $s3_client_key,\r\n        $s3_client_secret\r\n    ) {\r\n\r\n        // Add note only for non-empty users.\r\n        if (!empty($s3_client_userid)) {\r\n\r\n            // Add note with the s3 access key and s3 secret.\r\n            $command = 'AddClientNote';\r\n            $data = array(\r\n                'userid' => $userid,\r\n                'notes' =>\r\n                    \"UserId: \" . $s3_client_userid . \"\\n\" .\r\n                    \"AWSAccessKeyId: \" . $s3_client_key . \"\\n\" .\r\n                    \"AWSSecretAccessKey: \" . $s3_client_secret,\r\n            );\r\n            localAPI($command, $data, $whmcs_username);\r\n        }\r\n    }\r\n}\r\n\r\n?>\r\n\nThe next file removes notes from the client in WHMCS with the S3 access key pairs whenever a user or access key pair is removed. Create a file S3_delClientNote.php with the following contents:<?php\r\n\r\n// whmcs database access.\r\nuse WHMCS\\Database\\Capsule;\r\n\r\n// API request to remove note from client in whmcs.\r\nif (!function_exists('S3_delClientNote')) {\r\n    function S3_delClientNote(\r\n        $userid,\r\n        $whmcs_username,\r\n        $s3_client_userid,\r\n        $s3_client_key\r\n    ) {\r\n\r\n        // Delete notes in database.\r\n        $db = Capsule::connection()->getPdo();\r\n        $db->exec('\r\n            DELETE FROM\r\n              tblnotes\r\n            WHERE\r\n              userid = ' . $userid . '\r\n            AND\r\n              note LIKE \"%' . $s3_client_userid . '%\"\r\n            AND\r\n              note LIKE \"%' . $s3_client_key . '%\"'\r\n        );\r\n    }\r\n}\r\n\r\n?>\r\n\nThe last file is the cURL library for sending GET, PUT, POST, and DELETE requests. Create a file S3_requestCurl.php with the following contents:<?php\r\n\r\n// API request to s3 gateway.\r\nif (!function_exists('S3_requestCurl')) {\r\n    function S3_requestCurl($s3_key, $s3_secret, $s3_gateway, $s3_query, $method) {\r\n\r\n        // Prepare signature.\r\n        $s3_host  = parse_url($s3_gateway, PHP_URL_HOST);\r\n        $s3_date  = date(DATE_RFC2822);\r\n\r\n        // Generate signature.\r\n        $s3_signature = hash_hmac('sha1', $method . \"\\n\\n\\n\" . $s3_date . \"\\n\" .\r\n            current(explode('&', $s3_query)), $s3_secret, true);\r\n        $s3_signature = base64_encode($s3_signature);\r\n\r\n        // Curl init.\r\n        $s3_curl = curl_init($s3_gateway . $s3_query);\r\n\r\n        // Curl options.\r\n        switch ($method) {\r\n            case \"PUT\":\r\n                curl_setopt($s3_curl, CURLOPT_PUT, 1);\r\n                break;\r\n            case \"POST\":\r\n                curl_setopt($s3_curl, CURLOPT_POST, 1);\r\n                break;\r\n            case \"DELETE\":\r\n                curl_setopt($s3_curl, CURLOPT_CUSTOMREQUEST, \"DELETE\");\r\n                break;\r\n        }\r\n        curl_setopt($s3_curl, CURLOPT_RETURNTRANSFER, true);\r\n        curl_setopt($s3_curl, CURLOPT_URL, $s3_gateway . $s3_query);\r\n        curl_setopt($s3_curl, CURLOPT_HTTPHEADER, array(\r\n            'Host: ' . $s3_host,\r\n            'Date: ' . $s3_date,\r\n            'Authorization: AWS ' . $s3_key . ':' . $s3_signature,\r\n            'Content-Type:',\r\n            'Expect:',\r\n        ));\r\n\r\n        // Call.\r\n        $response = curl_exec($s3_curl);\r\n        $response = json_decode($response, true);\r\n\r\n        // Curl deinit.\r\n        curl_close($s3_curl);\r\n\r\n        // Return response.\r\n        return $response;\r\n    }\r\n}\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/includes.html"
    },
    {
        "title": "Object storage architecture",
        "content": "Object storage architecture\nThe object storage infrastructure consists of the following entities: object servers (OS), name servers (NS), S3 gateways (GW), and the block-level backend. These entities run as services on the Virtuozzo Hybrid Infrastructure nodes. Each service should be deployed on multiple Virtuozzo Hybrid Infrastructure nodes for high availability.\nThe NS and OS services are highly available: the system automatically keeps them online if at least one machine in the S3 cluster is up and running. If an NS or OS service fails, the whole S3 cluster cannot operate normally.\nBy default, each S3 node runs 4 S3 gateways and can run up to 10 NS and 10 OS instances, but the entire S3 cluster cannot host more than 24 OS and 16 NS instances. For example:\n\nA single-node S3 cluster hosts 4 GW, 10 OS, and 10 NS services.\nA two-node S3 cluster hosts 8 GW, 20 OS, and 16 NS services.\nA three-node S3 cluster hosts 12 GW, 24 OS, and 16 NS services.\n\nThe number of OS and NS services is defined during the initial S3 cluster setup. Adding more nodes to the S3 cluster does not affect it.\n\nAn object server stores actual object data received from an S3 gateway. The data is packed into special containers to achieve high performance. The containers are redundant, which means you can specify the redundancy mode while configuring object storage. An object server also stores its own data in block storage with built-in high availability.\nA name server stores object metadata received from an S3 gateway. Metadata includes object name, size, ACL (access control list), location, owner, and similar. A name server (NS) also stores its own data in block storage with built-in high availability.\nAn S3 gateway is a data proxy between object storage services and end users. It receives and handles Amazon S3 protocol requests, and S3 user authentication and ACL checks. The S3 gateway uses the NGINX web server for external connections and has no data of its own (that is,  it is stateless).\nThe block-level backend is block storage with high availability of services and data. Since all object storage services run on hosts, no virtual environments (and hence licenses) are required for object storage.\n\nSee also\n\nSample object storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/s3-storage-architecture.html"
    },
    {
        "title": "Updating registration certificates",
        "content": "Updating registration certificates\nWhen you register backup storage in Acronis Cyber Protect Cloud or Acronis Cyber Protect, they exchange certificates that are valid for three years. One and a half months before expiration, you will be alerted about the expiring certificate in the admin panel. \nPrerequisites\n\nThe backup storage cluster is created and registered in the Cloud Management Panel, as described in Provisioning Acronis Backup Storage space.\nOne or more registrations are added for the backup storage, as explained in Adding registrations.\nEnsure that two-factor authentication (2FA) is disabled for your partner account. You can also disable it for a specific user within a 2FA-enabled tenant, as described in the Acronis Cyber Protect Cloud documentation, and specify the user credentials.\n\nIf you have enabled login control for the Acronis Cyber Protect Cloud web interface, ensure that the public IP address of your backup storage cluster is specified among the allowed IP addresses, as instructed in the Acronis Cyber Protect Cloud documentation.\n\nTo update the registration certificate\n\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Registrations tab. \nSelect a backup storage registration, and then click Update certificate.\nSpecify the credentials of a partner account in the cloud or of an organization administrator on the local management server.\nClick Update.\n\nThe backup storage service will be automatically restarted and the new certificate will be loaded in five minutes.\n\nCommand-line interface\nUse the following command:vinfra service backup registration renew-certificates --username <username> [--server-cert-only]\r\n                                                      [--stdin] <registration>\n\n--stdin\n\nUse for setting registration password from stdin.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server\n--server-cert-only\n\nUpdate only the server certificate\n<registration>\n\nRegistration ID or name\n\nFor example, to update certificates for the backup storage registration registration1, run:# vinfra service backup registration renew-certificates --username account@example.com \\\r\n--stdin registration1\nSpecify the registration password when prompted.\nThe backup storage service will be automatically restarted and the new certificate will be loaded in five minutes.\n\nSee also\n\nDeleting registrations",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup registration renew-certificates --username <username> [--server-cert-only]\r\n                                                      [--stdin] <registration>\n\n--stdin\n\nUse for setting registration password from stdin.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server\n--server-cert-only\n\nUpdate only the server certificate\n<registration>\n\nRegistration ID or name\n\nFor example, to update certificates for the backup storage registration registration1, run:# vinfra service backup registration renew-certificates --username account@example.com \\\r\n--stdin registration1\nSpecify the registration password when prompted.\nThe backup storage service will be automatically restarted and the new certificate will be loaded in five minutes.\n",
                "title": "To update the registration certificate"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Registrations tab. \nSelect a backup storage registration, and then click Update certificate.\nSpecify the credentials of a partner account in the cloud or of an organization administrator on the local management server.\nClick Update.\n\nThe backup storage service will be automatically restarted and the new certificate will be loaded in five minutes.\n",
                "title": "To update the registration certificate"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/updating-registration-certificates.html"
    },
    {
        "title": "3. SECaaS Service Offering with WHMCS BitNinja Module\u00c2\u00b6",
        "content": "3. SECaaS Service Offering with WHMCS BitNinja Module | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n3. SECaaS Service Offering with WHMCS BitNinja Module\u00c2\u00b6\n\nIn this chapter:\n\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/whmcs-bitninja/index.html"
    },
    {
        "title": "Fencing compute nodes",
        "content": "Fencing compute nodes\nA compute node might fail due to a kernel crash, power outage, or might become unreachable over the network. A failed node is automatically fenced from scheduling new virtual machines on it. That is, this node is isolated from the compute cluster, and new VMs are created on other compute nodes. Once a failed node becomes available again, the system runs a health check, and if successful, automatically tries to return the node to operation. If a node cannot be unfenced within 30 minutes after a crash or fails three times within an hour, you need to check its hardware, and then return it to operation manually.\nIn case there is an ongoing VM evacuation when the node is back to operation, the process continues for those VMs already scheduled for evacuation. The remaining VMs are retained on the node.\nIf you experience problems launching VMs on a particular node, you can fence this node manually for troubleshooting. Such nodes need to be returned to operation manually\nLimitations\n\nWith a three-node configuration, the compute cluster can survive a failure of only one node. Having at least five nodes will keep the compute cluster operational even if two compute nodes fail simultaneously.\nCompute nodes that are in maintenance cannot be fenced.\nCompute nodes with the single Controller role cannot be fenced.\nIf a compute node was fenced and then placed into the maintenance mode, it will return to the \"Fenced\" state after exiting maintenance.\nFenced nodes cannot be released from the compute cluster.\n\nPrerequisites\n\nBefore fencing a node, ensure it has no running virtual machines. You can either stop such VMs or migrate them live to other nodes.\n\nTo fence a compute node\n\nAdmin panel\n\nGo to the Compute > Nodes screen, and then click a node.\nOn the node right pane, click Fence.\n\nIn the Fence node window, optionally specify the fencing reason, and then click Fence.\n\nA fencing reason should not contain any personally identifiable information or sensitive business data.\n\nOnce, the node is fenced, you can check the fencing reason in its details. If the node hosts stopped virtual machines, you can move them to healthy nodes by clicking Evacuate on the VM right pane.\n\nCommand-line interface\nUse the following command:vinfra service compute node fence [--reason <reason>] <node>\r\n\n\n--reason <reason>\n\nThe reason for disabling the compute node\n\nA fencing reason should not contain any personally identifiable information or sensitive business data.\n\n<node>\n\nNode ID or hostname\n\nFor example, to fence the node node003.vstoragedomain, run:# vinfra service compute node fence node003.vstoragedomain\r\n\nYou can check that the node is successfully fenced in the vinfra service compute node list output:# vinfra service compute node list\r\n+--------------------------------------+------------------------+----------+--------------+\r\n| id                                   | host                   | state    | roles        |\r\n+--------------------------------------+------------------------+----------+--------------+\r\n| 52565ca3-5893-8f6b-62ce-2f07b175b549 | node001.vstoragedomain | healthy  | - controller |\r\n|                                      |                        |          | - compute    |\r\n| 578ccd91-dd8d-50b0-e3a2-f6ccb5959159 | node002.vstoragedomain | healthy  | - compute    |\r\n| 3ccf40b2-9437-b393-f02b-5282b188a4b3 | node003.vstoragedomain | disabled | - compute    |\r\n+--------------------------------------+------------------------+----------+--------------+\nIn the command-line output, the fenced node has the disabled state.\n\nTo return a fenced node back to operation\n\nAdmin panel\n\nGo to the Compute > Nodes screen, and then click a fenced node.\nOn the node right pane, click Return to operation.\nIn the confirmation window, click Return.\n\nCommand-line interface\nUse the following command:vinfra service compute node unfence <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to return the node node003.vstoragedomain to operation, run:# vinfra service compute node unfence node003.vstoragedomain\r\n\n\nSee also\n\nConfiguring virtual machine high availability\n\nManaging placements for compute nodes\n\nMonitoring compute nodes\n\nReleasing nodes from the compute cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute node fence [--reason <reason>] <node>\r\n\n\n--reason <reason>\n\n\nThe reason for disabling the compute node\n\nA fencing reason should not contain any personally identifiable information or sensitive business data.\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to fence the node node003.vstoragedomain, run:# vinfra service compute node fence node003.vstoragedomain\r\n\nYou can check that the node is successfully fenced in the vinfra service compute node list output:# vinfra service compute node list\r\n+--------------------------------------+------------------------+----------+--------------+\r\n| id                                   | host                   | state    | roles        |\r\n+--------------------------------------+------------------------+----------+--------------+\r\n| 52565ca3-5893-8f6b-62ce-2f07b175b549 | node001.vstoragedomain | healthy  | - controller |\r\n|                                      |                        |          | - compute    |\r\n| 578ccd91-dd8d-50b0-e3a2-f6ccb5959159 | node002.vstoragedomain | healthy  | - compute    |\r\n| 3ccf40b2-9437-b393-f02b-5282b188a4b3 | node003.vstoragedomain | disabled | - compute    |\r\n+--------------------------------------+------------------------+----------+--------------+\nIn the command-line output, the fenced node has the disabled state.\n",
                "title": "To fence a compute node"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute node unfence <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to return the node node003.vstoragedomain to operation, run:# vinfra service compute node unfence node003.vstoragedomain\r\n\n",
                "title": "To return a fenced node back to operation"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Nodes screen, and then click a node.\nOn the node right pane, click Fence.\n\nIn the Fence node window, optionally specify the fencing reason, and then click Fence.\n\nA fencing reason should not contain any personally identifiable information or sensitive business data.\n\n\n\nOnce, the node is fenced, you can check the fencing reason in its details. If the node hosts stopped virtual machines, you can move them to healthy nodes by clicking Evacuate on the VM right pane.\n",
                "title": "To fence a compute node"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Nodes screen, and then click a fenced node.\nOn the node right pane, click Return to operation.\nIn the confirmation window, click Return.\n\n",
                "title": "To return a fenced node back to operation"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/fencing-compute-nodes.html"
    },
    {
        "title": "Default outbound firewall rules",
        "content": "Default outbound firewall rules\nAll networks in the cluster have the default outbound allow rules, which are specified in the format: <address>:<protocol>:<port>:<description>. These rules are the following:\n\n0.0.0.0:udp:500:IKE\n\nTraffic encryption\n0.0.0.0:udp:4500:IKE\n\nTraffic encryption\n0.0.0.0:tcp:8888:Admin panel\n\nUsed by the cluster API\n0.0.0.0:tcp:80:HTTP\n\nConnection to the update repository and the S3 backend when configured to serve HTTP requests\n0.0.0.0:tcp:443:HTTPS\n\nCommunication with Acronis Cyber Protect Cloud and the S3 services\n0.0.0.0:udp:53:DNS\n\nDNS name resolution\n0.0.0.0:tcp:53:DNS\n\nDNS name resolution\n0.0.0.0:udp:123:NTP\n\nTime syncronization\n0.0.0.0:tcp:8443:ABGW registration\n\nData control for the Acronis Cyber Protect agents and Management server\n0.0.0.0:tcp:44445:ABGW Geo-replication\n\nBackup data replication between clusters\n0.0.0.0:tcp:9877:Acronis Cyber Protect\n\nRegistration with Acronis Cyber Protect Management server in on-premise installations\n0.0.0.0:tcp:5900-6079:VM VNC Legacy\n\nLegacy ports for VNC console access to virtual machines\n0.0.0.0:udp:4789:VXLAN\n\nNetwork traffic between virtual machines in private virtual networks\n0.0.0.0:tcp:15900-16900:VM VNC\n\nVNC console access to virtual machines in the compute cluster\n0.0.0.0:tcp:7050:KA license\n\nConnection to the Key Authentication (KA) licensing server\n0.0.0.0:tcp:5224:KA report\n\nSending reports to the KA server\n0.0.0.0:udp:2049:NFS\n\nData exchange with the NFS access point\n0.0.0.0:tcp:2049:NFS\n\nData exchange with the NFS access point\n0.0.0.0:tcp:111:NFS Rpcbind\n\nRPC request mapping from NFS clients to the correct port\n0.0.0.0:any:0:Allow all\n\nAllows all outbound traffic\n\nSee also\n\nCreating outbound firewall rules\n\nRestoring default outbound firewall rules",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/default-outbound-firewall-rules.html"
    },
    {
        "title": "Revoking S3 access keys in WHMCS",
        "content": "Revoking S3 access keys in WHMCS\nYou can revoke the specified access key pair of the specified user with the ostor-users service and the following parameters: emailAddress specifying the user email address, revokeKey specifying the access key in the key pair. WHMCS removes the key pair when you click Revoke Access Key. Create a file S3_revokeAccessKey.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_delClientNote.php');\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Revoke s3 access key pair.\r\nfunction S3_revokeAccessKey($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Get first s3 access key.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'],\r\n        \"GET\"\r\n    );\r\n\r\n    // Revoke s3 access key.\r\n    S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n            \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'] .\r\n            \"&revokeKey=\" . $s3_client['AWSAccessKeys']['0']['AWSAccessKeyId'],\r\n        \"POST\"\r\n    );\r\n\r\n    // Delete note with the s3 access key and s3 secret.\r\n    S3_delClientNote(\r\n        $s3_whmcs['userid'],\r\n        $s3_config['whmcs_username'],\r\n        $s3_client['UserId'],\r\n        $s3_client['AWSAccessKeys']['0']['AWSAccessKeyId']\r\n    );\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_revokeAccessKey($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/revoking-s3-access-keys-in-whmcs.html"
    },
    {
        "title": "Showing backup plan details",
        "content": "Showing backup plan detailsGET /v2/{project_id}/jobs/{job_id}\nShows details for a backup plan.\nSource: https://docs.openstack.org/api-ref/backup/v2/index.html#show-jobs-v2\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\njob_id\n\npath\nstring\nThe job UUID.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8736/v2/3046fb2c2a314a0fbb32607caa1e5277/jobs/e632eb1884e0468c8a41e656942df500\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\njob_id\n\nbody\nstring\nThe job UUID.\n\njob_id_hash\n\nbody\nstring\nThe job ID hash.\n\nuser_id\n\nbody\nstring\nThe user UUID.\n\nproject_id\n\nbody\nstring\nThe UUID of the project.\n\nname\n\nbody\nstring\nThe name of the job.\n\ndescription\n\nbody\nstring\nThe description of the job.\n\nclient_id\n\nbody\nstring\nThe client UUID.\n\njob_schedule\n\nbody\ndict\nThe schedule information of the job.\n\njob_actions\n\nbody\nlist\nA list of actions that carry out the backup/restore job.\n\nstatus\n\nbody\nstring\nThe job status.\n\ndisabled\n\nbody\nboolean\nIf set to true, the job is disabled. If set to false, the job is enabled.\n\nstarted_at\n\nbody\nstring\n\nThe date and time when the job started.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nended_at\n\nbody\nstring\n\nThe date and time when the job ended.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"created_at\": \"2024-05-09T09:51:10.785289\",\r\n  \"updated_at\": \"2024-05-09T09:52:58.261715\",\r\n  \"job_id\": \"e632eb1884e0468c8a41e656942df500\",\r\n  \"job_id_hash\": \"d91e52f5117e95d8cf094071a7923289951a433c\",\r\n  \"project_id\": \"3046fb2c2a314a0fbb32607caa1e5277\",\r\n  \"user_id\": \"d1899d7f32d64b1bb95e262e7a6a4bc2\",\r\n  \"job_schedule\": {\r\n    \"schedule_day_of_week\": \"0,1,2,3,4,5,6\",\r\n    \"schedule_month\": \"1,2,3,4,5,6,7,8,9,10,11,12\",\r\n    \"schedule_day\": \"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31\",\r\n    \"schedule_minute\": \"00\",\r\n    \"schedule_hour\": \"13\"\r\n  },\r\n  \"client_id\": \"hci\",\r\n  \"session_id\": \"\",\r\n  \"session_tag\": 0,\r\n  \"name\": \"myplan\",\r\n  \"description\": \"My new plan\",\r\n  \"job_actions\": [\r\n    {\r\n      \"freezer_action\": {\r\n        \"action\": \"backup\",\r\n        \"mode\": \"hci-volumes\",\r\n        \"recovery_points_rotation\": 7\r\n      },\r\n      \"user_id\": \"d1899d7f32d64b1bb95e262e7a6a4bc2\",\r\n      \"project_id\": \"3046fb2c2a314a0fbb32607caa1e5277\",\r\n      \"action_id\": \"b9dc9e548b914b80a06d752342828371\"\r\n    }\r\n  ],\r\n  \"status\": \"scheduled\",\r\n  \"disabled\": false,\r\n  \"started_at\": null,\r\n  \"ended_at\": null\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-backup-plan-details.html"
    },
    {
        "title": "Managing virtual networks",
        "content": "Managing virtual networks\nLimitations\n\nYou can delete a compute network only if no VMs are connected to it.\n\nTo add a new virtual network\n\n\r\n                On the Networks screen, click Create virtual network.\r\n            \n\r\n                On the Network configuration step, do the following:\r\n            Enable or disable IP address management:With IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.With IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.In any case, you will be able to manually assign static IP addresses from inside the VMs.Specify a name, and then click Next.\n\nIf you enabled IP address management, you will move on to the IP address management step, where you can add an IPv4 subnet:\n\nIn the Subnets section, click Add and select IPv4 subnet.\nIn the Add IPv4 subnet window, specify the network\u00e2\u0080\u0099s IPv4 address range and, optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\nEnable or disable the built-in DHCP server:\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\nOn the Summary step, review the configuration, and then click Create virtual network.\n\nTo edit parameters of a virtual network\n\nOn the Networks screen, click the required network. \nOn the network right pane, click the pencil icon next to the network name or IPv4 subnet.\n Make changes and save them.\n\nTo delete a compute network\nClick the ellipsis icon next to the required network, and then click Delete. To remove multiple compute networks at once, select them, and then click Delete. ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-virtual-networks.html"
    },
    {
        "title": "Unlocking user accounts",
        "content": "Unlocking user accounts\nA user account is locked after a number of successive failed login attempts from the same IP address in the admin or self-service panel:\n\n10 failed attempts per hour\n50 failed attempts per day\n100 failed attempts per month\n300 failed attempts per year\n\nA successful login resets the counter. A locked user account is unlocked automatically after the lock expires or can be unlocked manually by a system administrator.\nTo unlock a user\n\nFind the name or ID of a locked user within the domain by using the vinfra tool. For example:# vinfra domain user list --domain domain1 --long\r\n+---------------+--------+-------+-------------------------------------------------+----------------+--------------------+------+\r\n| id            | name   | <...> | locked_ips                                      | role           | system_permissions | tags |\r\n+---------------+--------+-------+-------------------------------------------------+----------------+--------------------+------+\r\n| 646f5793<...> | admin1 | <...> | []                                              | domain_admin   | []                 | []   |\r\n|               |        |       |                                                 |                |                    |      |\r\n| 899bc00d<...> | user2  | <...> | - ip: 10.35.15.27                               | project_member | []                 | []   |\r\n|               |        |       |   lock_expired_at: '2022-09-27T13:17:21.499275' |                |                    |      |\r\n| f0b9c6d0<...> | user1  | <...> | []                                              | project_member | []                 | []   |\r\n|               |        |       |                                                 |                |                    |      |\r\n+---------------+--------+-------+-------------------------------------------------+----------------+--------------------+------+\nIn this command output, the locked user is user2, the locked IP address is 10.35.15.27, and the lock will expire at 13:17 on September 27, 2022.\n\nUnlock the user account by specifying its name or ID. For example:# vinfra domain user unlock --domain domain1 user2\n\nSee also\n\nManaging admin panel users\n\nManaging self-service users",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/unlocking-user-accounts.html"
    },
    {
        "title": "GET service ostor-users",
        "content": "GET service ostor-users\nDescription\nLists information about all users and their space usage, or the user specified by either email or ID.\nRequests\nSyntaxGET /?ostor-users HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-users&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-users&id=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-users&space HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nGET service ostor-users parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nNo*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nNo*\n\nspace\n\nShow space usage.\nType: flag.\nDefault value: none.\n\nNo\n\n* Only one of the required parameters can be set in a single request.\nIf neither emailAddress nor id are set, the response is information about all users, otherwise the response is information about the user with the specified email or ID.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nA JSON dictionary with user information in the following format:{\r\n\"UserEmail\" : \"<email>\"\r\n\"UserId\" : \"<id>\",\r\n\"AWSAccessKeys : [\r\n{\r\n\"AWSAccessKeyId\" : \"<access_key>\",\r\n\"AWSSecretAccessKey\" : \"<secret_key>\"\r\n}]\r\n}\r\n{\r\n\"UserEmail\": \"<email>\",\r\n\"UserId\": \"<id>\",\r\n\"State\": \"<state>\",\r\n\"OwnerId\": \"<id>\",\r\n\"Flags\": [\"<flag>\"],\r\n\"AWSAccessKeys\": [\r\n{\r\n\"AWSAccessKeyId\": \"<access_key>\",\r\n\"AWSSecretAccessKey\": \"<secret_key>\"\r\n}],\r\n\"AccountCount\": \"<count>\",\r\n\"Accounts\": [\r\n{\r\n\"Name\": \"<name>\",\r\n\"AWSAccessKeys\": [\r\n{\r\n\"AWSAccessKeyId\": \"<access_key>\",\r\n\"AWSSecretAccessKey\": \"<secret_key>\"}]\r\n}]\r\n}\nErrors\nReturns Error Code 400 if more than one parameter is set.\nExamples\nSample request #1\nReturns information about all users.\r\nGET /?ostor-users HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 24 Mar 2021 17:01:11 +0200\r\nAuthorization: <authorization_string>\nSample response #1\r\nHTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nx-amz-req-time-micros: 921\r\nx-amz-request-id: 8000000000000016000060d778c73410\r\nDate: Wed, 24 Mar 2021 15:01:11 GMT\r\nConnection:keep-alive\r\nContent-type : application/json{\r\n  \"Users\": [\r\n    {\r\n      \"UserEmail\": \"user1@email.com\",\r\n      \"UserId\": \"b09693b73b3c7686\",\r\n      \"State\": \"disabled\",\r\n      \"OwnerId\": \"0000000000000000\",\r\n      \"Flags\": [\r\n        \"disabled\"\r\n      ]\r\n    },\r\n    {\r\n      \"UserEmail\": \"user2@email.com\",\r\n      \"UserId\": \"bc6265392b818465\",\r\n      \"State\": \"enabled\",\r\n      \"OwnerId\": \"0000000000000000\",\r\n      \"Flags\": []\r\n    },\r\n    {\r\n      \"UserEmail\": \"user@example.com\",\r\n      \"UserId\": \"f373d5175d1f3b63\",\r\n      \"State\": \"enabled\",\r\n      \"OwnerId\": \"0000000000000000\",\r\n      \"Flags\": [\r\n        \"system\"\r\n      ]\r\n    }\r\n  ]\r\n}\r\n\nSample request #2\nReturns information about the user with the ID b09693b73b3c7686.GET /?ostor-users&id=b09693b73b3c7686 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 24 Mar 2021 17:02:25 +0200\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 200 OK\r\nServer: nginx\r\nContent-Type: application/json\r\nTransfer-Encoding: chunked\r\nConnection: keep-alive\r\nDate: Wed, 24 Mar 2021 15:01:11 GMT\r\nx-amz-req-time-micros: 983\r\nx-amz-request-id: 8000000000000016000060d77d2db664\r\n{\r\n  \"UserEmail\": \"user@email.com\",\r\n  \"UserId\": \"b09693b73b3c7686\",\r\n  \"State\": \"disabled\",\r\n  \"OwnerId\": \"0000000000000000\",\r\n  \"Flags\": [\r\n    \"disabled\"\r\n  ],\r\n  \"AWSAccessKeys\": [\r\n    {\r\n      \"AWSAccessKeyId\": \"b09693b73b3c7686FIGH\",\r\n      \"AWSSecretAccessKey\": \"jO2p4JBN1tWc4FEGxwZ8qW2jPCJBYp8RJ4KgBcZP\"\r\n    }\r\n  ],\r\n  \"AccountCount\": \"3\",\r\n  \"Accounts\": [\r\n    {\r\n      \"Name\": \"account1\",\r\n      \"AWSAccessKeys\": [\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c768613NV\",\r\n          \"AWSSecretAccessKey\": \"CBUpFmnpUGlXskTivgDQu4qjYksWpceGZeH6Qyct\"\r\n        }\r\n      ]\r\n    },\r\n    {\r\n      \"Name\": \"account2\",\r\n      \"AWSAccessKeys\": [\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c7686LCZ5\",\r\n          \"AWSSecretAccessKey\": \"xLpUDFJMFMO5rR9acAbUDplrPqIO6fneKNFjEB5c\"\r\n        },\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c76866NI2\",\r\n          \"AWSSecretAccessKey\": \"ajowU8pWSGW5ZJhA7AR9OjTrt11HmHPCJsMd247W\"\r\n        }\r\n      ]\r\n    },\r\n    {\r\n      \"Name\": \"account3\",\r\n      \"AWSAccessKeys\": [\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c7686OVV1\",\r\n          \"AWSSecretAccessKey\": \"EOT652BDvByLwy2qPt0VsQ6s3I0pTrfPXKDw9i75\"\r\n        },\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c7686Z8BU\",\r\n          \"AWSSecretAccessKey\": \"m8PgWFLXPeJVSWojCE3DxWDoRk80g7CMyB7xK3Hd\"\r\n        }\r\n      ]\r\n    }\r\n  ]\r\n}\r\n\nSample request #3\nReturns information about space usage.\r\nGET /?ostor-users&space HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 23 Oct 2023 13:11:45 +0200\r\nAuthorization: <authorization_string>\nSample response #3\r\nHTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nx-amz-req-time-micros: 921\r\nx-amz-request-id: 8000000000000016000060d778c73410\r\nDate: Wed, 23 Oct 2023 13:15:04 GMT\r\nConnection:keep-alive\r\nContent-type : application/json{\r\n  \"Users\": [\r\n    {\r\n      \"UserEmail\": \"user2@email.com\",\r\n      \"UserId\": \"bc6265392b818465\",\r\n      \"State\": \"enabled\",\r\n      \"OwnerId\": \"0000000000000000\",\r\n      \"SpaceStat\":\r\n        {\r\n          \"LastTs\": 471425,\r\n          \"SizeCurr\": 9323413504,\r\n          \"SizeHMax\": 9323413504,\r\n          \"SizeHInt\": 2414764097536\r\n        },\r\n      \"Flags\": []\r\n    },\r\n    {\r\n      \"UserEmail\": \"user@example.com\",\r\n      \"UserId\": \"f373d5175d1f3b63\",\r\n      \"State\": \"enabled\",\r\n      \"OwnerId\": \"0000000000000000\",\r\n      \"SpaceStat\":\r\n        {\r\n          \"LastTs\": 0,\r\n          \"SizeCurr\": 0,\r\n          \"SizeHMax\": 0,\r\n          \"SizeHInt\": 0\r\n        },\r\n      \"Flags\": [\r\n        \"system\"\r\n      ]\r\n    }\r\n  ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/get-service-ostor-users.html"
    },
    {
        "title": "Managing volumes in backup plans",
        "content": "Managing volumes in backup plans\nYou can manage compute volumes that you want to back up by adding them to or removing them from your backup plans. After removing a volume from a backup plan, all backups that have been already created remain intact.\nPrerequisites\n\nA backup plan is created, as described in Creating backup plans.\n\nTo add volumes to a backup plan\n\nOn the Backup plans screen, click the required backup plan.\nOn the plan right pane, navigate to the Volumes to back up tab. All the compute volumes included in the backup plan will be shown here.\nClick Manage above the list of volumes.\nIn the Manage volumes window, select volumes that you want to back up, and then click Save.\n\nTo remove volumes from a backup plan\n\nOn the Backup plans screen, click the required backup plan.\nOn the plan right pane, navigate to the Volumes to back up tab. All the compute volumes included in the backup plan will be shown here.\nClick Manage above the list of volumes.\nIn the Manage volumes window, remove the selection from volumes that you do not want to back up. To see only the volumes assigned to the backup plan, select Show only selected items next to the Search field. Then, click Save.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-volumes-in-backup-plans.html"
    },
    {
        "title": "Managing snapshots",
        "content": "Managing snapshots",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-snapshots.html"
    },
    {
        "title": "Configuring network interfaces of virtual machines",
        "content": "Configuring network interfaces of virtual machines\nYou can add new network interfaces to your virtual machines, edit IP addresses and security groups for the existing interfaces, and remove network interfaces by detaching them.\nLimitations\n\nYou cannot manage network interfaces of shelved VMs.\nA VM that is connected to a dual-stack network always receives an IPv6 address, if the IPv6 subnet is in the SLAAC or DHCPv6 stateless mode.\n\nTo attach a network interface to a virtual machine\n\nOn the Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click Add to attach a network interface.\n\nIn the Add network interface window, select a compute network to connect to, and then specify MAC address, IPv4 and/or IPv6 addresses, and security groups. By default, MAC and primary IP addresses are assigned automatically. To specify them manually, clear the Assign automatically check boxes, and enter the desired addresses. Optionally, assign additional IP addresses to the network interface in the Secondary IP addresses section. Note that a secondary IPv6 address is not available for an IPv6 subnet that works in the SLAAC or DHCPv6 stateless mode.\n\nSecondary IP addresses, unlike the primary one, will not be automatically assigned to the network interface inside the virtual machine guest OS. You should assign them manually.\n\nIf you selected a virtual network with enabled IP address management\n\nIn this case, spoofing protection is enabled and the default security group is selected by default. This security group allows all incoming and outgoing traffic on all the VM ports. If required, you can select another security group or multiple security groups.\nTo disable spoofing protection, clear all of the check boxes and turn off the toggle switch. Security groups cannot be configured with disabled spoofing protection.\n\nIf you selected a virtual network with disabled IP address management\nIn this case, spoofing protection is disabled by default and cannot be enabled. Security groups cannot be configured for such a network.\n\nIf you selected a shared physical network\n\nIn this case, spoofing protection cannot be configured by a self-service user. If you want to enable or disable spoofing protection, contact your system administrator.\r\n                        \n\nAfter specifying the network interface parameters, click Add.\n\nClick Done to finish editing VM network interfaces and save your changes.\n\nTo edit a network interface of a virtual machine\n\nOn the Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click the ellipsis button next to the interface you want to edit, and then click Edit.\n\nIn the Edit network interface window, modify the network interface parameters as follows:\n\nChange the primary IP address. To update the address inside the VM guest OS, restart the network interface.\nAdd or remove secondary IP addresses.\nModify security groups assigned to the VM.\n\nAfter updating the required parameters, click Save.\n\nClick Done to finish editing VM network interfaces and save your changes.\n\nTo detach a network interface from a virtual machine\n\nOn the Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click the ellipsis button next to the interface you want to detach, and then click Remove.\nClick Done to finish editing VM network interfaces and save your changes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/configuring-vm-network-interfaces.html"
    },
    {
        "title": "Updating backup plans",
        "content": "Updating backup plansPATCH /v2/{project_id}/jobs/{job_id}\nUpdate backup settings in a backup plan.\nSource: https://docs.openstack.org/api-ref/backup/v2/index.html#updates-jobs-v2\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\njob_id\n\npath\nstring\nThe job UUID.\n\nname\n\nbody\nstring\nThe name of the job.\n\ndescription\n\nbody\nstring\nThe description of the job.\n\njob_schedule\n\nbody\ndict\nThe schedule information of the job.\n\njob_actions\n\nbody\nlist\nA list of actions that carry out the backup/restore job.\n\nExample# curl -ks -X PATCH -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"job_schedule\": {\r\n        \"schedule_day_of_week\": \"0,1,2,3,4,5,6\",\r\n        \"schedule_month\": \"1,2,3,4,5,6,7,8,9,10,11,12\",\r\n        \"schedule_day\": \"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31\",\r\n        \"schedule_minute\": \"00\",\r\n        \"schedule_hour\": \"14\"\r\n    }\r\n}' https://<node_IP_addr>:8736/v2/3046fb2c2a314a0fbb32607caa1e5277/jobs/e632eb1884e0468c8a41e656942df500\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\njob_id\n\nbody\nstring\nThe job UUID.\n\nversion\n\nbody\ninteger\nThe job version.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"job_id\": \"e632eb1884e0468c8a41e656942df500\",\r\n  \"version\": 0\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-backup-plans.html"
    },
    {
        "title": "Disk requirements",
        "content": "Disk requirements\nDisk types and roles\n\nUsing SATA HDDs with one SSD for caching is more cost effective than using only SAS HDDs without such an SSD.\nUsing NVMe or SAS SSDs for write caching improves random I/O performance and is highly recommended for all workloads with heavy random access (for example, iSCSI volumes). In turn, SATA disks are best suited for SSD-only configurations but not write caching.\nRunning metadata services on SSDs improves cluster performance. To also minimize CAPEX, the same SSDs can be used for write caching.\nUsing shingled magnetic recording (SMR) HDDs is available only for storage purposes and only if the node has an SSD disk for cache.\nIf capacity is the main goal and you need to store infrequently accessed data, select SATA disks over SAS ones. If performance is the main goal, select NVMe or SAS disks over SATA ones.\nDisk block size (for example, 512b or 4K) is not important and has no effect on performance.\nThe maximum supported physical partition size is 254 TiB.\n\nDisk capacity\n\nThe system disk must have at least 100 GB of space.\nIt is possible to use disks of different size in the same cluster. However, keep in mind that, given the same IOPS, smaller disks will offer higher performance per terabyte of data compared to bigger disks. It is recommended to group disks with the same IOPS per terabyte in the same tier.\nThe capacity of HDD and SSD is measured and specified with decimal, not binary prefixes, so \u00e2\u0080\u009cTB\u00e2\u0080\u009d in disk specifications usually means \u00e2\u0080\u009cterabyte.\u00e2\u0080\u009d The operating system, however, displays a drive capacity using binary prefixes meaning that \u00e2\u0080\u009cTB\u00e2\u0080\u009d is \u00e2\u0080\u009ctebibyte\u00e2\u0080\u009d which is a noticeably larger number. As a result, disks may show a capacity smaller than the one marketed by the vendor. For example, a disk with 6 TB in specifications may be shown to have 5.45 TB of actual disk space in Virtuozzo Hybrid Infrastructure. 5 percent of disk space is reserved for emergency needs. Therefore, if you add a 6 TB disk to a cluster, the available physical space should increase by about 5.2 TB.\nPerformance of SSD disks may depend on their size. Lower-capacity drives (100 to 400 GB) may perform much slower (sometimes up to ten times slower) than higher-capacity ones (1.9 to 3.8 TB). Check the drive performance and endurance specifications before purchasing hardware.\nThin provisioning is always enabled for all data and cannot be configured otherwise.\n\nConsumer-grade SSD drives\n\nConsumer-grade SSD drives can withstand a very low number of rewrites. SSD drives intended for storage clusters must offer at least 1 DWPD endurance (10 DWPD is recommended). The higher the endurance, the less often SSDs will need to be replaced, and this will improve TCO.\nConsumer-grade SSD drives usually have unstable performance and are not suited to withstand sustainable enterprise workloads. For this reason, pay attention to sustainable load tests when choosing SSDs.\nMany consumer-grade SSD drives can ignore disk flushes and falsely report to operating systems that data was written while it, in fact, was not. Examples of such drives include OCZ Vertex 3, Intel 520, Intel X25-E, and Intel X-25-M G2. These drives are known to be unsafe in terms of data commits, they should not be used with databases, and they may easily corrupt the file system in case of a power failure. It is recommended to use enterprise-grade SSD drives with power loss protection, as described in Protecting data during a power outage.\n\nRAID and HBA controllers\n\nCreate hardware or software RAID1 volumes for system disks by using RAID or HBA controllers, respectively, to ensure its high performance and availability.\nUse HBA controllers, as they are less expensive and easier to manage than RAID controllers.\nDisable all RAID controller caches for SSD drives. Modern SSDs have good performance that can be reduced by a RAID controller\u00e2\u0080\u0099s write and read cache. It is recommended to disable caching for SSD drives and leave it enabled only for HDD drives.\nIf you use RAID controllers, do not create RAID volumes from HDDs intended for storage. Each storage HDD needs to be recognized by Virtuozzo Hybrid Infrastructure as a separate device.\nIf you use RAID controllers with caching, equip them with backup battery units (BBUs), to protect against cache loss during power outages.\n\nSee also\n\nHardware recommendations\n\nServer requirements\n\nNetwork requirements and recommendations\n\nAdmin panel requirements",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/disk-requirements.html"
    },
    {
        "title": "11.2. Integration with Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "11.2. Integration with Virtuozzo Hybrid Infrastructure | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n11.2. Integration with Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nTo integrate with Virtuozzo Hybrid Infrastructure, you create an OpenStack center in Leostream for each project you want to manage in your Connection Broker.\n\nImportant\nLeostream defines centers as the external systems that inform the Connection Broker about desktops and other resources that are available for assignment to end users.\n\nLeostream uses the OpenStack APIs to inventory the instances and images in your Virtuozzo Hybrid Infrastructure project.\nTo integrate with Virtuozzo Hybrid Infrastructure:\n\nGo to the Setup > Centers page.\nClick the Add Center link.\nIn the Add Center form, select OpenStack from the Type drop-down menu (the Leostream license controls if OpenStack is available as a center).\nEnter the name for the center in the Name edit field.\nIn the Auth URL: VHI OS_AUTH_URL e.g. https://virtuozzo.admin.panel.ip:5000/v3.\nEnter the default Virtuozzo Hybrid Infrastructure region (VHI region = RegionOne) in the Region edit field.\nEnter the domain you created for your project in the Project Domain edit field.\nEnter the name of the project you created in the Project edit field.\nEnter the domain, username, and password of the user you created in the previous steps into the User Domain, Username and Password edit fields, respectively.\nClick Save to create the center. The following figure shows an example of a saved OpenStack center for Virtuozzo Hybrid Infrastructure.\n\nThe instances in the Virtuozzo Hybrid Infrastructure project appear in the Resources > Desktops page. The Connection Broker inventories all images and displays them on the Resources > Images page, for example.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-external-systems/integration-with-vhi.html"
    },
    {
        "title": "Benchmarking and performance",
        "content": "Benchmarking and performance\nThis section describes how to set up the storage cluster of Virtuozzo Hybrid Infrastructure, to run performance benchmarks for the network, storage disks, and virtual machines, as well as for the NFS, iSCSI, and S3 protocols. It also explains how to identify and troubleshoot typical performance issues in Virtuozzo Hybrid Infrastructure.\nWe recommend benchmarking the infrastructure to ensure that the measured performance matches your expectations. Benchmarking is impossible while the system is used for production workloads, as benchmarks will yield unreliable results and might disrupt user activities or significantly decrease performance. You can perform the benchmarks immediately as soon as the cluster is deployed and configured. At this stage, most performance issues and misconfigurations can be detected and prevented. The information obtained with benchmarking only measures actual performance and may be not sufficient to highlight performance issues. This information helps to understand if performance is up to expectations, and can be used for comparison with monitoring tools during normal cluster activity.\nThe specifics of every permutation of network environment, hardware platform, and workload cannot be covered in every detail. This section offers generic instructions on setting up a test environment, so your mileage may vary.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/benchmarking-and-performance.html"
    },
    {
        "title": "Supported Amazon S3 object expiration actions",
        "content": "Supported Amazon S3 object expiration actions\nThe Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 object lifecycle only supports object expiration by prefix. Deleting objects by tag is not available.\nThe following S3 object expiration actions are currently supported:\n\nExpiration\n\nDeletes objects by age or by date. In case of versioning, inserts a delete marker, which becomes the latest version of an object. Delete markers are not removed.\nNonCurrentVersionExpiration\n\nDeletes an object version after it has become non-current for the specified number of days.\nAbortIncompleteMultipartUpload\n\nAborts a multipart upload that has not completed during the specified number of days.\nExpiredObjectDeleteMarker\n\nDeletes a delete marker as soon as there are no other versions of an object.\n\nSee also\n\nSupported Amazon S3 REST operations\n\nSupported Amazon request headers\n\nSupported Amazon response headers\n\nSupported Amazon error response headers\n\nSupported authentication schemes\n\nAmazon S3 features supported by bucket policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-object-expiration-actions.html"
    },
    {
        "title": "Requirements",
        "content": "Requirements\nAny operation or management request must be authenticated with a signed request via Signature Version 2 or 4 of the Amazon S3 protocol of the corresponding S3 system user. To authenticate API requests, you need to create a system user. First, obtain the volume ID with the ostor-ctl get-config command. For example:# ostor-ctl get-config -n 10.94.97.195\r\nVOL_ID             TYPE     STATE\r\n0100000000000002   OBJ      READY\r\n...\r\n\nThen, create a system user on any storage node in the cluster with the ostor-s3-admin create-user -S -e <email> command. For example:# ostor-s3-admin create-user -S -e user@example.com -V 0100000000000002\r\nUserEmail:user@example.com\r\nUserId:a14040e0b2ef8b28\r\nKeyPair[0]:S3AccessKeyId:a14040e0b2ef8b28FZZ8\r\nKeyPair[0]:S3SecretAccessKey:dbwTnQTW602aAAdq8DQVFzB6yrTCFTNiGB8C8RFA\r\nFlags:system\r\n\nWith this user, you can now authenticate further API requests for managing the S3 cluster. You can create multiple system accounts for different types of management operations.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/requirements.html"
    },
    {
        "title": "Creating virtual subnets",
        "content": "Creating virtual subnetsPOST /v2.0/subnets\r\n\nCreate a subnet in a network.\nOpenStack Networking does not try to derive the correct IP version\r\nfrom the CIDR. If you do not specify the gateway_ip attribute,\r\nOpenStack Networking allocates an address from the CIDR for the\r\ngateway for the subnet.\nTo specify a subnet without a gateway, set the gateway_ip\r\nattribute to null in the request body. If you do not specify\r\nthe allocation_pools attribute, OpenStack Networking\r\nautomatically allocates pools for covering all IP addresses in the\r\nCIDR, excluding the address reserved for the subnet gateway.\r\nOtherwise, you can explicitly specify allocation pools as shown in\r\nthe following example.\nWhen you specify both the allocation_pools and gateway_ip\r\nattributes, you must ensure that the gateway IP does not overlap\r\nwith the allocation pools; otherwise, the call returns the\r\nConflict (409) response code.\nA subnet can have one or more name servers and host routes. Hosts\r\nin this subnet use the name servers. Devices with IP addresses from\r\nthis subnet, not including the local subnet route, use the host\r\nroutes.\nSpecify the ipv6_ra_mode and ipv6_address_mode attributes\r\nto create subnets that support IPv6 configurations, such as\r\nstateless address autoconfiguration (SLAAC), DHCPv6 stateful, and\r\nDHCPv6 stateless configurations.\nA subnet can optionally be associated with a network segment when\r\nit is created by specifying the segment_id of a valid segment\r\non the specified network. A network with subnets associated in this\r\nway is called a routed network. On any given network, all of the\r\nsubnets must be associated with segments or none of them can be.\r\nNeutron enforces this invariant. Currently, routed networks are\r\nonly supported for provider networks.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-subnet-detail#create-subnet\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nsubnet\n\nbody\nobject\nA subnet object.\n\ntenant_id (Optional)\nbody\nstring\nThe ID of the project that owns the resource.\r\nOnly administrative and users with advsvc role can specify\r\na project ID other than their own.\r\nYou cannot change this value through authorization policies.\n\nproject_id (Optional)\nbody\nstring\nThe ID of the project that owns the resource.\r\nOnly administrative and users with advsvc role can specify\r\na project ID other than their own.\r\nYou cannot change this value through authorization policies.\n\nname (Optional)\nbody\nstring\nHuman-readable name of the resource. Default is an empty string.\n\nenable_dhcp (Optional)\nbody\nboolean\nIndicates whether dhcp is enabled or disabled\r\nfor the subnet. Default is true.\n\nnetwork_id\n\nbody\nstring\nThe ID of the network to which the subnet belongs.\n\ndns_nameservers (Optional)\nbody\narray\nList of dns name servers associated with the subnet. Default is an\r\nempty list.\n\nallocation_pools (Optional)\nbody\narray\nAllocation pools with start and end IP addresses\r\nfor this subnet. If allocation_pools are not specified, OpenStack\r\nNetworking automatically allocates pools for covering all IP addresses\r\nin the CIDR, excluding the address reserved for the subnet gateway by\r\ndefault.\n\nhost_routes (Optional)\nbody\narray\nAdditional routes for the subnet. A list of dictionaries with\r\ndestination and nexthop parameters. Default value is\r\nan empty list.\n\nip_version\n\nbody\ninteger\nThe IP protocol version. Value is 4 or 6.\n\ngateway_ip (Optional)\nbody\nstring\nGateway IP of this subnet. If the value is null that implies no\r\ngateway is associated with the subnet. If the gateway_ip is not\r\nspecified, OpenStack Networking allocates an address from the CIDR\r\nfor the gateway for the subnet by default.\n\ncidr\n\nbody\nstring\nThe CIDR of the subnet.\n\nprefixlen (Optional)\nbody\ninteger\nThe prefix length to use for subnet allocation from a subnet pool.\r\nIf not specified, the default_prefixlen value of the subnet pool\r\nwill be used.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the subnet.\r\nDefault is an empty string.\n\nipv6_address_mode (Optional)\nbody\nstring\nThe IPv6 address modes specifies mechanisms for assigning IP addresses.\r\nValue is slaac, dhcpv6-stateful, dhcpv6-stateless.\n\nipv6_ra_mode (Optional)\nbody\nstring\nThe IPv6 router advertisement specifies whether the networking service\r\nshould transmit ICMPv6 packets, for a subnet. Value is slaac,\r\ndhcpv6-stateful, dhcpv6-stateless.\n\nsegment_id (Optional)\nbody\nstring\nThe ID of a network segment the subnet is associated with.\r\nIt is available when segment extension is enabled.\n\nsubnetpool_id (Optional)\nbody\nstring\nThe ID of the subnet pool associated with the subnet.\n\nuse_default_subnetpool (Optional)\nbody\nboolean\nWhether to allocate this subnet from the default subnet pool.\n\nservice_types (Optional)\nbody\narray\nThe service types associated with the subnet.\n\ndns_publish_fixed_ip (Optional)\nbody\nboolean\nWhether to publish DNS records for IPs from this subnet. Default\r\nis false.\n\nExample 1\nCreate a subnet with enabled DHCP, an allocation pool, a gateway, a DNS. Attach it to a private network with the specified ID:# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d'\r\n{                                    \r\n  \"subnet\": {\r\n    \"enable_dhcp\": true,\r\n    \"network_id\": \"c5252a20-9206-4b8e-9a0f-45bd22ee7bc8\",\r\n    \"dns_nameservers\": [\r\n      \"10.30.0.27\",\r\n      \"10.30.0.28\"\r\n    ],\r\n    \"allocation_pools\": [\r\n      {\r\n        \"start\": \"192.168.10.2\",\r\n        \"end\": \"192.168.10.254\"\r\n      }\r\n    ],\r\n    \"ip_version\": 4,\r\n    \"gateway_ip\": \"192.168.10.1\",\r\n    \"cidr\": \"192.168.10.0/24\"\r\n  }\r\n}' https://<node_IP_addr>:9696/v2.0/subnets\r\n\nExample 2\nCreate a subnet with enabled DHCP, an allocation pool, a gateway, a DNS. Attach it to a public network with the specified ID:# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"subnet\": {\r\n    \"enable_dhcp\": true,\r\n    \"network_id\": \"c5a5d68e-55cd-40b8-a272-3768cbb86bd1\",\r\n    \"dns_nameservers\": [\r\n      \"10.30.0.27\",\r\n      \"10.30.0.28\"\r\n    ],\r\n    \"allocation_pools\": [\r\n      {\r\n        \"start\": \"10.94.139.168\",\r\n        \"end\": \"10.94.139.175\"\r\n      }\r\n    ],\r\n    \"ip_version\": 4,\r\n    \"gateway_ip\": \"10.94.0.1\",\r\n    \"cidr\": \"10.94.0.0/16\"\r\n  }\r\n}' https://<node_IP_addr>:9696/v2.0/subnets\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nsubnet\n\nbody\nobject\nA subnet object.\n\nid\n\nbody\nstring\nThe ID of the subnet.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\nenable_dhcp\n\nbody\nboolean\nIndicates whether dhcp is enabled or disabled\r\nfor the subnet.\n\nnetwork_id\n\nbody\nstring\nThe ID of the network to which the subnet belongs.\n\ndns_nameservers\n\nbody\narray\nList of dns name servers associated with the subnet.\n\nallocation_pools\n\nbody\narray\nAllocation pools with start and end IP addresses\r\nfor this subnet.\n\nhost_routes\n\nbody\narray\nAdditional routes for the subnet. A list of dictionaries with\r\ndestination and nexthop parameters.\n\nip_version\n\nbody\ninteger\nThe IP protocol version. Value is 4 or 6.\n\ngateway_ip\n\nbody\nstring\nGateway IP of this subnet. If the value is null that implies no\r\ngateway is associated with the subnet.\n\ncidr\n\nbody\nstring\nThe CIDR of the subnet.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndescription\n\nbody\nstring\nA human-readable description for the subnet.\n\nipv6_address_mode\n\nbody\nstring\nThe IPv6 address modes specifies mechanisms for assigning IP addresses.\r\nValue is slaac, dhcpv6-stateful, dhcpv6-stateless or null.\n\nipv6_ra_mode\n\nbody\nstring\nThe IPv6 router advertisement specifies whether the networking service\r\nshould transmit ICMPv6 packets, for a subnet. Value is slaac,\r\ndhcpv6-stateful, dhcpv6-stateless or null.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the subnet.\n\nsegment_id\n\nbody\nstring\nThe ID of a network segment the subnet is associated with.\r\nIt is available when segment extension is enabled.\n\nsubnetpool_id\n\nbody\nstring\nThe ID of the subnet pool associated with the subnet.\n\nservice_types\n\nbody\narray\nThe service types associated with the subnet.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\ndns_publish_fixed_ip\n\nbody\nboolean\nWhether to publish DNS records for IPs from this subnet.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample 1\nSubnet for a private network:{\r\n  \"subnet\": {\r\n    \"service_types\": [],\r\n    \"description\": \"\",\r\n    \"enable_dhcp\": true,\r\n    \"tags\": [],\r\n    \"network_id\": \"c5252a20-9206-4b8e-9a0f-45bd22ee7bc8\",\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-02-14T13:42:56Z\",\r\n    \"dns_nameservers\": [\r\n      \"10.30.0.27\",\r\n      \"10.30.0.28\"\r\n    ],\r\n    \"updated_at\": \"2020-02-14T13:42:56Z\",\r\n    \"gateway_ip\": \"192.168.10.1\",\r\n    \"ipv6_ra_mode\": null,\r\n    \"allocation_pools\": [\r\n      {\r\n        \"start\": \"192.168.10.2\",\r\n        \"end\": \"192.168.10.254\"\r\n      }\r\n    ],\r\n    \"host_routes\": [],\r\n    \"revision_number\": 0,\r\n    \"ip_version\": 4,\r\n    \"ipv6_address_mode\": null,\r\n    \"cidr\": \"192.168.10.0/24\",\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"id\": \"aa29d149-b2a4-45a0-8066-dc63fa9c9b77\",\r\n    \"subnetpool_id\": null,\r\n    \"name\": \"\"\r\n  }\r\n}\nExample 2\nSubnet for a public network:{\r\n  \"subnet\": {\r\n    \"service_types\": [],\r\n    \"description\": \"\",\r\n    \"enable_dhcp\": true,\r\n    \"tags\": [],\r\n    \"network_id\": \"c5a5d68e-55cdl-40b8-a272-3768cbb86bd1\",\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-02-17T11:30:30Z\",\r\n    \"dns_nameservers\": [\r\n      \"10.30.0.27\",\r\n      \"10.30.0.28\"\r\n    ],\r\n    \"updated_at\": \"2020-02-17T11:30:30Z\",\r\n    \"gateway_ip\": \"10.94.0.1\",\r\n    \"ipv6_ra_mode\": null,\r\n    \"allocation_pools\": [\r\n      {\r\n        \"start\": \"10.94.139.168\",\r\n        \"end\": \"10.94.139.175\"\r\n      }\r\n    ],\r\n    \"host_routes\": [],\r\n    \"revision_number\": 0,\r\n    \"ip_version\": 4,\r\n    \"ipv6_address_mode\": null,\r\n    \"cidr\": \"10.94.0.0/16\",\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"id\": \"5fc296ab-6f00-41ab-914d-0aea9c8da34f\",\r\n    \"subnetpool_id\": null,\r\n    \"name\": \"\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-virtual-subnets.html"
    },
    {
        "title": "Creating traits",
        "content": "Creating traitsPUT /traits/{name}\r\n\nInsert a new custom trait. If the trait already exists, 204 is returned. This API call requires custom parameters that are only supported in Virtuozzo Hybrid Infrastructure.\nThere are two kinds of traits: the standard traits and the custom traits.\r\nThe standard traits are interoperable across different OpenStack cloud\r\ndeployments. The definition of standard traits comes from the os-traits\r\nlibrary. The standard traits are read-only in the placement API which means\r\nthat the user cannot modify any standard traits through API.\r\nThe custom traits are used by admin users to manage the non-standard\r\nqualitative information of resource providers.\nA custom trait name for Virtuozzo Hybrid Infrastructure looks like CUSTOM_HCI_<UUID>, where the <UUID> must be generated using Python\u00e2\u0080\u0099s uuid4() function as follows:>>> str(uuid.uuid4()).upper().replace('-', '')\r\n'E4A64BAA4BE84887ADE712ABB9B5882A'\r\n\nSo a complete name would beCUSTOM_HCI_E4A64BAA4BE84887ADE712ABB9B5882A\r\n\nSource: https://docs.openstack.org/api-ref/placement/?expanded=update-traits-detail#update-traits\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nname\n\npath\nstring\nThe name of a trait.\n\ndisplay_name\n\nbody\nstring\nA human-readable trait name to be displayed in the admin panel.\n\ndescription\n\nbody\nstring\nA human-readable trait description to be displayed in the admin panel.\n\nExamplecurl -ks -X PUT -H 'Content-Type: application/json' -H 'OpenStack-API-Version: placement 1.32' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"display_name\": \"placement2\",\r\n    \"description\": \"Sample placement #2\"\r\n}' https://<node_IP_addr>:8780/traits/CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-traits.html"
    },
    {
        "title": "Deleting Kubernetes cluster templates",
        "content": "Deleting Kubernetes cluster templatesDELETE /v1/clustertemplates/{clustertemplate_ident}\r\n\nDelete a cluster template.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=delete-a-cluster-template-detail#delete-a-cluster-template\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nclustertemplate_ident\n\npath\nstring\nThe UUID or name of cluster templates in Magnum.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9513/v1/clustertemplates/bccf828b-7366-4ed9-954c-7f23b9779cbd\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-kubernetes-cluster-templates.html"
    },
    {
        "title": "Amazon S3 features supported by bucket policies",
        "content": "Amazon S3 features supported by bucket policies\nThe Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 bucket policies supports the following S3 actions, condition keys, and condition comparators:\n\nSupported S3 actions\nObject actions\n\ns3:AbortMultipartUpload\ns3:DeleteObject\ns3:DeleteObjectVersion\ns3:GetObject\ns3:GetObject\ns3:GetObjectAcl\ns3:GetObjectVersion\ns3:GetObjectVersionAcl\ns3:ListMultipartUploadParts\ns3:PutObject\ns3:PutObjectAcl\ns3:PutObjectVersionAcl\n\nBucket actions\n\ns3:CreateBucket\ns3:DeleteBucket\ns3:ListBucket\ns3:ListBucketMultipartUploads\ns3:ListBucketVersions\n\nBucket subresource actions\n\ns3:DeleteBucketPolicy\ns3:DeleteBucketWebsite\ns3:GetBucketAcl\ns3:GetBucketCORS\ns3:GetBucketLocation\ns3:GetBucketLogging\ns3:GetBucketNotification\ns3:GetBucketPolicy\ns3:GetBucketVersioning\ns3:GetBucketWebsite\ns3:GetLifecycleConfiguration\ns3:GetReplicationConfiguration\ns3:PutBucketAcl\ns3:PutBucketCORS\ns3:PutBucketLogging\ns3:PutBucketNotification\ns3:PutBucketPolicy\ns3:PutBucketRequestPayment\ns3:PutBucketVersioning\ns3:PutBucketWebsite\ns3:PutLifecycleConfiguration\ns3:PutReplicationConfiguration\n\nSupported condition keys\n\ns3:x-amz-storage-class\ns3:x-amz-acl\ns3:x-amz-grant-full-control\ns3:x-amz-grant-read\ns3:x-amz-grant-read-acp\ns3:x-amz-grant-write\ns3:x-amz-grant-write-acp\ns3:x-amz-copy-source\ns3:TlsVersion\ns3:x-amz-content-sha256\ns3:signatureversion\ns3:signatureAge\ns3:authType\ns3:x-amz-website-redirect-location\ns3:object-lock-mode\ns3:object-lock-retain-until-date\ns3:object-lock-legal-hold\ns3:object-lock-remaining-retention-days\ns3:prefix\ns3:versionid\ns3:max-keys\ns3:locationconstraint\naws:SourceIp\n\nSupported condition comparators\n\nStringNotEquals\nStringEqualsIgnoreCase\nStringNotEqualsIgnoreCase\nStringLike\nStringNotLike\nNumericEquals\nNumericNotEquals\nNumericLessThan\nNumericLessThanEquals\nNumericGreaterThan\nNumericGreaterThanEquals\nDateEquals\nDateNotEquals\nDateLessThan\nDateLessThanEquals\nDateGreaterThan\nDateGreaterThanEquals\nBinaryEquals\nIpAddress\nNotIpAddress\n\nSee also\n\nSupported Amazon S3 REST operations\n\nSupported Amazon request headers\n\nSupported Amazon response headers\n\nSupported Amazon error response headers\n\nSupported authentication schemes\n\nSupported Amazon S3 object expiration actions",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-features-by-bucket-policies.html"
    },
    {
        "title": "Supported storage types",
        "content": "Supported storage types\nYour service provider can configure Virtuozzo Hybrid Infrastructure to keep your data in three storage types:\n\nS3 object storage for storing an unlimited number of objects (files).\niSCSI block storage for virtualization, databases, and other needs.\nNFS shares for storing an unlimited number of files via a distributed filesystem.\n\nThe following sections describe the ways to access data in Virtuozzo Hybrid Infrastructure in detail.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/supported-storage-types.html"
    },
    {
        "title": "13.3. Assigning Policies to Users\u00c2\u00b6",
        "content": "13.3. Assigning Policies to Users | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n13.3. Assigning Policies to Users\u00c2\u00b6\nWhen a user logs in to the Connection Broker, the Connection Broker searches the authentication servers you defined on the Setup > Authentication Servers page for a user that matches the credentials provided by the user.\nThe Connection Broker then looks on the Configuration > Assignments page for the assignment rules associated with the user\u00e2\u0080\u0099s authentication server. For example, if the Connection Broker authenticated the user in the VDI.VZ domain defined on the Setup > Authentication Servers page, the Connection Broker would look in the VDI.VZ assignment rules.\nTo assign policies to users in a particular authentication server, click the Edit link associated with that authentication server on the Configuration > Assignments tab. The Edit Assignment form for this authentication server appears, for example as shown in the following figure.\n\nBy default, the Connection Broker matches the selection in the Group drop-down menu to the user\u00e2\u0080\u0099s memberOf attribute in Active Directory.\n\nNote\nIf you modified your groups in Active Directory after you last signed into your Connection Broker, you must sign out and sign back in to have your Connection Broker reflect the authentication server changes.\n\nTo assign policies based on the user\u00e2\u0080\u0099s memberOf attribute:\n\nSelect the group from the Group drop-down menu.\nIf you are using locations, select a location from the Client Location drop-down menu.\nAssign a role to this group and client location pair by selecting an item from the User Role drop-down menu.\n\nIn Leostream, roles are permissions that control the actions an end user can take on their desktop and the level of access the user has to the Connection Broker Administrator Web interface. A location is a group of clients defined by attributes such as manufacturer, device type, OS version, IP address, etc. For more information on building roles and locations, see Chapters 10 and 13 in the Connection Broker Administrator\u00e2\u0080\u0099s Guide.\n\nAssign a policy to this group and client location pair by selecting an item from the User Policy drop-down menu.\n\nLeostream supports various different multi-factor authentication systems. If you require MFA, visit the Support Documents tab on the Leostream Documentation page for more information.\n\nIf you edit the Default policy, you can leave your Assignments table at its default values and proceed with the example.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/offering-vhi-desktops/assigning-policies.html"
    },
    {
        "title": "Updating resource provider traits",
        "content": "Updating resource provider traitsPUT /resource_providers/{uuid}/traits\r\n\nAssociate traits with a resource provider with the specified ID.\nAll the associated traits will be replaced by the traits specified in the request body. For this reason, make sure to pass all of resource provider\u00e2\u0080\u0099s standard traits (refer to Listing resource provider traits) and only add or remove the custom traits you need.\nIn addition, you must pass resource provider\u00e2\u0080\u0099s current resource_provider_generation value in the request.\nSource: https://docs.openstack.org/api-ref/placement/?expanded=update-resource-provider-traits-detail#update-resource-provider-traits\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ntraits\n\nbody\narray\nA list of traits.\n\nresource_provider_generation\n\nbody\ninteger\nA consistent view marker that assists with the management of concurrent resource provider updates.\n\nuuid\n\npath\nstring\nThe UUID of a resource provider.\n\nExamplecurl -ks -X PUT -H 'Content-Type: application/json' -H 'OpenStack-API-Version: placement 1.32' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{                        \r\n  \"traits\": [\r\n    \"COMPUTE_DEVICE_TAGGING\",\r\n    \"COMPUTE_TRUSTED_CERTS\",\r\n    \"COMPUTE_VOLUME_EXTEND\",\r\n    \"COMPUTE_NET_ATTACH_INTERFACE_WITH_TAG\",\r\n    \"COMPUTE_NET_ATTACH_INTERFACE\",\r\n    \"COMPUTE_VOLUME_ATTACH_WITH_TAG\",\r\n    \"COMPUTE_VOLUME_MULTI_ATTACH\",\r\n    \"CUSTOM_HCI_E3A45A6A4B614263893D72015BFB1A5F\"\r\n  ],\r\n  \"resource_provider_generation\": 546\r\n}' https://<node_IP_addr>:8780/resource_providers/34233b75-4022-4539-9e3f-305e9f9f1f18/traits\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ntraits\n\nbody\narray\nA list of traits.\n\nresource_provider_generation\n\nbody\ninteger\nA consistent view marker that assists with the management of concurrent resource provider updates.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"traits\": [\r\n    \"COMPUTE_DEVICE_TAGGING\",\r\n    \"COMPUTE_TRUSTED_CERTS\",\r\n    \"COMPUTE_VOLUME_EXTEND\",\r\n    \"COMPUTE_NET_ATTACH_INTERFACE_WITH_TAG\",\r\n    \"COMPUTE_NET_ATTACH_INTERFACE\",\r\n    \"COMPUTE_VOLUME_ATTACH_WITH_TAG\",\r\n    \"COMPUTE_VOLUME_MULTI_ATTACH\",\r\n    \"CUSTOM_HCI_E3A45A6A4B614263893D72015BFB1A5F\"\r\n  ],\r\n  \"resource_provider_generation\": 547\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-resource-provider-traits.html"
    },
    {
        "title": "Preparing templates",
        "content": "Preparing templates\nYou may need to create a template in these cases:\n\nTo rescue a virtual machine\nTo create a VM accessible via SSH\nTo create a VM customizable with user data\n\nPreparation overview\n\nInstall cloud-init and OpenSSH Server in the virtual machine.\n\nEnable logging for virtual machines that will be created from the template.\n\nConvert the VM boot volume to the template.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-templates.html"
    },
    {
        "title": "High availability",
        "content": "High availability\nHigh availability (HA) keeps Virtuozzo Hybrid Infrastructure services operational even if the node they are located on fails. In such cases, services from a failed node are relocated to healthy nodes, according to the Raft consensus algorithm. High availability is ensured by:\n\nMetadata redundancy. For a storage cluster to function, not all but just the majority of metadata servers must be up. By setting up multiple metadata servers in the cluster, you will make sure that if an metadata server fails, other metadata servers will continue controlling the cluster.\nThe required number of metadata servers is deployed automatically, based on recommended hardware configurations.\n\nData redundancy. Copies of each piece of data are stored across different failure domains, to ensure that the data is available even if some of the failure domains are inaccessible. For more information, refer to Data redundancy.\nMonitoring of node health.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/high-availability.html"
    },
    {
        "title": "Managing S3 user limits",
        "content": "Managing S3 user limits\nYou can define limits for S3 users to limit operations per second and outgoing bandwidth of a response per user. You can apply limits to a particular S3 user or all S3 users within a domain. By default, all S3 user limits are set to zero, which means \"unlimited\".\nTo set limits for a particular S3 user\nUse the following command:vinfra service s3 self-service user limits add [--domain <domain>] [--user <user>]\r\n                                               --limit-type <limit_type> --limits <limits>\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--limit-type <limit_type>\n\nLimit type: operations per second (ops), in ops/s, or outgoing bandwidth (bandwidth), in kb/s\n--limits <limits>\n\nLimits expressions:\n\nOperations per second: { default=<value> | put=<value> | get=<value> | list=<value> | delete=<value> }\nBandwidth: { out=<value> }\n\nFor example, to limit GET operations to 500 ops/s and PUT operations to 200 ops/s for the S3 user user1 in the domain domain1, run:# vinfra service s3 self-service user limits add --domain domain1 --user user1 --limit-type ops --limits get=500,put=200\nYou can check the applied S3 limits in the vinfra service s3 self-service user limits get output:# vinfra service s3 self-service user limits get --domain domain1 --user user1\r\n+---------------+-------------------+\r\n| Field         | Value             |\r\n+---------------+-------------------+\r\n| bandwidth     | - name: out       |\r\n|               |   unit: kbs/s     |\r\n|               |   value: '0'      |\r\n| ops           | - name: default   |\r\n|               |   unit: ops/s     |\r\n|               |   value: '0.00'   |\r\n|               | - name: get       |\r\n|               |   unit: ops/s     |\r\n|               |   value: '500.00' |\r\n|               | - name: put       |\r\n|               |   unit: ops/s     |\r\n|               |   value: '200.00' |\r\n|               | - name: list      |\r\n|               |   unit: ops/s     |\r\n|               |   value: '0.00'   |\r\n|               | - name: delete    |\r\n|               |   unit: ops/s     |\r\n|               |   value: '0.00'   |\r\n| resource_name | fef81edf9cbf754b  |\r\n| resource_type | user              |\r\n+---------------+-------------------+\nTo remove limits for a particular S3 user\nUse the following command:vinfra service s3 self-service user limits remove [--domain <domain>] [--user <user] --limit-type <limit_type>\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--limit-type <limit_type>\n\nLimit type: operations per second (ops) or outgoing bandwidth (bandwidth)\n\nFor example, to remove bandwidth limits for the S3 user user1 in the domain domain1, run:# vinfra service s3 self-service user limits remove --domain domain1 --user user1 --limit-type bandwidth\nTo set limits for S3 users within a domain\nUse the following command:vinfra service s3 self-service domain limits add [--domain <domain>] --limit-type <limit_type> --limits <limits>\n\n--domain <domain>\n\nDomain name or ID\n--limit-type <limit_type>\n\nLimit type: operations per second (ops), in ops/s, or outgoing bandwidth (bandwidth), in kb/s\n--limits <limits>\n\nLimits expressions:\n\nOperations per second: { default=<value> | put=<value> | get=<value> | list=<value> | delete=<value> }\nBandwidth: { out=<value> }\n\nFor example, to limit all operations to 500 ops/s for all S3 users in the domain domain1, run:# vinfra service s3 self-service domain limits add --domain domain1 --limit-type ops --limits default=500\nYou can check the applied S3 limits in the vinfra service s3 self-service domain limits get output:# vinfra service s3 self-service domain limits get --domain domain1\r\n+---------------+----------------------------------+\r\n| Field         | Value                            |\r\n+---------------+----------------------------------+\r\n| bandwidth     | - name: out                      |\r\n|               |   unit: kbs/s                    |\r\n|               |   value: '0'                     |\r\n| ops           | - name: default                  |\r\n|               |   unit: ops/s                    |\r\n|               |   value: '500.00'                |\r\n|               | - name: get                      |\r\n|               |   unit: ops/s                    |\r\n|               |   value: '500.00'                |\r\n|               | - name: put                      |\r\n|               |   unit: ops/s                    |\r\n|               |   value: '500.00'                |\r\n|               | - name: list                     |\r\n|               |   unit: ops/s                    |\r\n|               |   value: '500.00'                |\r\n|               | - name: delete                   |\r\n|               |   unit: ops/s                    |\r\n|               |   value: '500.00'                |\r\n| resource_name | dff4158faaa848ac92b7284fc011b72f |\r\n| resource_type | organization                     |\r\n+---------------+----------------------------------+\nTo remove limits for S3 users within a domain\nUse the following command:vinfra service s3 self-service domain limits remove [--domain <domain] --limit-type <limit_type>\n\n--domain <domain>\n\nDomain name or ID\n--limit-type <limit_type>\n\nLimit type: operations per second (ops), in ops/s, or outgoing bandwidth (bandwidth), in kb/s\n\nFor example, to remove bandwidth limits for all S3 users in the domain domain1, run:# vinfra service s3 self-service domain limits remove --domain domain1 --limit-type bandwidth\nSee also\n\nManaging S3 access keys\n\nManaging S3 user quotas",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-s3-user-limits.html"
    },
    {
        "title": "Deleting virtual router interfaces",
        "content": "Deleting virtual router interfacesPUT /v2.0/routers/{router_id}/remove_router_interface\r\n\nDelete an internal interface with the specified ID from a virtual router.\nThis operation deletes an internal router interface, which detaches\r\na subnet from the router. If this subnet ID is the last subnet on\r\nthe port, this operation deletes the port itself. You must specify\r\neither a subnet ID or port ID in the request body; the\r\noperation uses this value to identify which router interface to\r\ndeletes.\nYou can also specify both a subnet ID and port ID. If you\r\nspecify both IDs, the subnet ID must correspond to the subnet\r\nID of the first IP address on the port. Otherwise, this operation\r\nreturns the Conflict (409) response code with information about\r\nthe affected router and interface.\nIf you try to delete the router interface for subnets that are used\r\nby one or more routes, this operation returns the Conflict (409)\r\nresponse. In this case, you first need to delete such routes from\r\nthe router.\nIf the router or the subnet and port do not exist or are not\r\nvisible to you, this operation returns the Not Found (404)\r\nresponse code. As a consequence of this operation, the operation\r\nremoves the port connecting the router with the subnet from the\r\nsubnet for the network.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=remove-interface-from-router-detail#remove-interface-from-router\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nsubnet_id (Optional)\nbody\nstring\nThe ID of the subnet.\r\nOne of subnet_id or port_id must be specified.\n\nport_id (Optional)\nbody\nstring\nThe ID of the port.\r\nOne of subnet_id or port_id must be specified.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{                                                        \r\n    \"subnet_id\": \"112f9b9c-7be2-41c9-8c31-903b263353e7\"\r\n}' https://<node_IP_addr>:9696/v2.0/routers/ce996632-45a2-4c6b-a951-a624eba74621/remove_router_interface\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nid\n\nbody\nstring\nThe ID of the resource.\n\nsubnet_id\n\nbody\nstring\nThe ID of the subnet which the router interface belongs to.\n\nsubnet_ids\n\nbody\narray\nA list of the ID of the subnet which the router interface belongs to.\r\nThe list contains only one member.\n\nnetwork_id\n\nbody\nstring\nThe ID of the attached network.\n\nport_id\n\nbody\nstring\nThe ID of the port which represents the router interface.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"network_id\": \"c4e2f31b-fe3b-402b-ac1b-b182693f72f7\",\r\n  \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n  \"subnet_id\": \"112f9b9c-7be2-41c9-8c31-903b263353e7\",\r\n  \"subnet_ids\": [\r\n    \"112f9b9c-7be2-41c9-8c31-903b263353e7\"\r\n  ],\r\n  \"port_id\": \"5374d25d-edfe-40dd-ae1e-bef883d8e72d\",\r\n  \"id\": \"ce996632-45a2-4c6b-a951-a624eba74621\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-virtual-router-interfaces.html"
    },
    {
        "title": "Benchmarking virtual machines",
        "content": "Benchmarking virtual machines\nBesides generic benchmark best practices, consider the following while running tests on virtual machines:\n\nUsing a high number of threads or a deep queue can improve results, as virtual machine I/O tends to have more latency compared to tests running on a host.\nUsing test sets with a size comparable to the size of a virtual disk, or running the same test several times, can significantly impact test results on thin disks. With each repetition a virtual disk becomes \u00e2\u0080\u009cthicker,\u00e2\u0080\u009d which leads to higher performance of subsequent tests.\nUsing snapshots is generally not recommended if the goal is to maximize performance. The system needs to synchronize data of a live volume and its snapshot, which adds an I/O overhead that lowers the disk performance. The impact of snapshots, however, may be reduced by using larger test sets.\n\nSee also\n\nStorage cluster best practices\n\nConfiguration examples\n\nBenchmarking disks\n\nBenchmarking the network\n\nBenchmarking NFS, iSCSI, and S3",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/benchmarking-virtual-machines.html"
    },
    {
        "title": "Creating and deleting volumes",
        "content": "Creating and deleting volumes\nLimitations\n\nA volume is removed along with all of its snapshots.\n\nTo create a volume\n\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click Create volume.\n\nIn the Create volume window, specify a volume name and size in gigabytes, select a storage policy, and then click Create.\n\nCommand-line interface\nUse the following command:vinfra service compute volume create [--description <description>]\r\n                                     [--network-install <network_install>]\r\n                                     [--image <image>]\r\n                                     [--snapshot <snapshot>]\r\n                                     --storage-policy <storage_policy>\r\n                                     --size <size-gb> <volume-name>\r\n\n\n--description <description>\n\nVolume description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--network-install <network_install>\n\nPerform network installation (true or false).\n--image <image>\n\nSource compute image ID or name\n--snapshot <snapshot>\n\nSource compute volume snapshot ID or name\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n--size <size-gb>\n\nVolume size, in gigabytes\n<volume-name>\n\nVolume name\n\nFor example, to create a volume myvolume sized 8 GB and with the default storage policy, run:# vinfra service compute volume create myvolume --storage-policy default --size 8\r\n+--------------------------------+--------------------------------------+\r\n| Field                          | Value                                |\r\n+--------------------------------+--------------------------------------+\r\n| attachments                    | []                                   |\r\n| availability_zone              | nova                                 |\r\n| bootable                       | False                                |\r\n| consistencygroup_id            |                                      |\r\n| created_at                     | 2018-09-12T12:30:12.665916           |\r\n| description                    |                                      |\r\n| encrypted                      | False                                |\r\n| id                             | c9c0e9e7-ce7a-4566-99d5-d7e40f2987ab |\r\n| imageRef                       |                                      |\r\n| migration_status               |                                      |\r\n| multiattach                    | False                                |\r\n| name                           | myvolume                             |\r\n| network_install                | False                                |\r\n| os-vol-host-attr:host          |                                      |\r\n| os-vol-mig-status-attr:migstat |                                      |\r\n| os-vol-mig-status-attr:name_id |                                      |\r\n| project_id                     | 72a5db3a033c403a86756021e601ef34     |\r\n| replication_status             |                                      |\r\n| size                           | 8                                    |\r\n| snapshot_id                    |                                      |\r\n| source_volid                   |                                      |\r\n| status                         | creating                             |\r\n| storage_policy_name            | default                              |\r\n| updated_at                     |                                      |\r\n| user_id                        | 98bf389983c24c07af9677b931783143     |\r\n| volume_image_metadata          |                                      |\r\n+--------------------------------+--------------------------------------+\r\n\nThe new volume will appear in the vinfra service compute volume list output:# vinfra service compute volume list -c id -c name -c size -c status\r\n+--------------------------------------+----------+------+-----------+\r\n| id                                   | name     | size | status    |\r\n+--------------------------------------+----------+------+-----------+\r\n| c9c0e9e7-ce7a-4566-99d5-d7e40f2987ab | myvolume |    8 | available |\r\n+--------------------------------------+----------+------+-----------+\r\n\n\nTo remove a volume\n\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, check the status of the volume you want to remove.\n If the status is \"In use\", click the volume, and then click Force detach.\nIf the status is \"Available\", click the volume, and then click Delete. \n\nCommand-line interface\nUse the following command:vinfra service compute volume delete <volume>\r\n\n\n<volume>\n\nVolume ID or name\n\nFor example, to delete the volume myvolume2, run:# vinfra service compute volume delete myvolume2\r\nOperation successful\r\n\n\nSee also\n\nResizing volumes\n\nChanging the storage policy for volumes\n\nCloning volumes\n\nManaging volume snapshots\n\nWhat's next\n\nAttaching and detaching volumes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume create [--description <description>]\r\n                                     [--network-install <network_install>]\r\n                                     [--image <image>]\r\n                                     [--snapshot <snapshot>]\r\n                                     --storage-policy <storage_policy>\r\n                                     --size <size-gb> <volume-name>\r\n\n\n--description <description>\n\n\nVolume description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--network-install <network_install>\n\nPerform network installation (true or false).\n--image <image>\n\nSource compute image ID or name\n--snapshot <snapshot>\n\nSource compute volume snapshot ID or name\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n--size <size-gb>\n\nVolume size, in gigabytes\n<volume-name>\n\nVolume name\n\nFor example, to create a volume myvolume sized 8 GB and with the default storage policy, run:# vinfra service compute volume create myvolume --storage-policy default --size 8\r\n+--------------------------------+--------------------------------------+\r\n| Field                          | Value                                |\r\n+--------------------------------+--------------------------------------+\r\n| attachments                    | []                                   |\r\n| availability_zone              | nova                                 |\r\n| bootable                       | False                                |\r\n| consistencygroup_id            |                                      |\r\n| created_at                     | 2018-09-12T12:30:12.665916           |\r\n| description                    |                                      |\r\n| encrypted                      | False                                |\r\n| id                             | c9c0e9e7-ce7a-4566-99d5-d7e40f2987ab |\r\n| imageRef                       |                                      |\r\n| migration_status               |                                      |\r\n| multiattach                    | False                                |\r\n| name                           | myvolume                             |\r\n| network_install                | False                                |\r\n| os-vol-host-attr:host          |                                      |\r\n| os-vol-mig-status-attr:migstat |                                      |\r\n| os-vol-mig-status-attr:name_id |                                      |\r\n| project_id                     | 72a5db3a033c403a86756021e601ef34     |\r\n| replication_status             |                                      |\r\n| size                           | 8                                    |\r\n| snapshot_id                    |                                      |\r\n| source_volid                   |                                      |\r\n| status                         | creating                             |\r\n| storage_policy_name            | default                              |\r\n| updated_at                     |                                      |\r\n| user_id                        | 98bf389983c24c07af9677b931783143     |\r\n| volume_image_metadata          |                                      |\r\n+--------------------------------+--------------------------------------+\r\n\nThe new volume will appear in the vinfra service compute volume list output:# vinfra service compute volume list -c id -c name -c size -c status\r\n+--------------------------------------+----------+------+-----------+\r\n| id                                   | name     | size | status    |\r\n+--------------------------------------+----------+------+-----------+\r\n| c9c0e9e7-ce7a-4566-99d5-d7e40f2987ab | myvolume |    8 | available |\r\n+--------------------------------------+----------+------+-----------+\r\n\n",
                "title": "To create a volume"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume delete <volume>\r\n\n\n<volume>\n\nVolume ID or name\n\nFor example, to delete the volume myvolume2, run:# vinfra service compute volume delete myvolume2\r\nOperation successful\r\n\n",
                "title": "To remove a volume"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOn the Compute > Storage > Volumes tab, click Create volume.\n\n\n\n\n\nIn the Create volume window, specify a volume name and size in gigabytes, select a storage policy, and then click Create.\n\n",
                "title": "To create a volume"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, check the status of the volume you want to remove.\n If the status is \"In use\", click the volume, and then click Force detach.\nIf the status is \"Available\", click the volume, and then click Delete. \n\n",
                "title": "To remove a volume"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-and-deleting-volumes.html"
    },
    {
        "title": "Disabling PCI passthrough and vGPU support",
        "content": "Disabling PCI passthrough and vGPU support\nIf you want to stop using PCI devices on a node, you need to remove them from the configuration file, and then use this file to reconfigure the compute cluster.\nPrerequisites\n\nThe compute cluster is reconfigured for PCI passthrough or vGPU support, as described in Enabling PCI passthrough and vGPU support.\n Before disabling PCI passthrough or vGPU support for a host device, stop using this device inside virtual machines. To do this, stop the VMs that are currently using this device, and then change their flavor to the one without PCI passthrough and vGPU-related properties.\n\nTo disable PCI passthrough and vGPU for all devices on a node\n\nCreate the configuration file with an empty device list:# cat config-empty.yaml\r\n- node_id: c3b2321a-7c12-8456-42ce-8005ff937e12\r\n  devices: []\r\n- node_id: 1d6481c2-1fd5-406b-a0c7-330f24bd0e3d\r\n  devices: []\n\nReconfigure the compute cluster by using the new configuration file. For example:# vinfra service compute set --pci-passthrough-config config-empty.yaml\n\nTo disable PCI\u00a0passthrough or vGPU for a particular device on a node\n\nRemove the information about the host device that you want to stop using from the configuration file. For example, to disable passthrough of the physical GPU with the 1b36:0100 VID and PID, remove these lines from config.yaml:- device_type: generic\r\n  device: 1b36:0100\r\n  alias: gpu\n\nReconfigure the compute cluster by using the updated configuration file. For example:# vinfra service compute set --pci-passthrough-config config.yaml\n\nSee also\n\nEnabling PCI passthrough and vGPU support",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/disabling-pci-passthrough-and-vgpu-support.html"
    },
    {
        "title": "Showing volume details",
        "content": "Showing volume detailsGET /v3/{project_id}/volumes/{volume_id}\r\n\nShow the details of a volume with the specified ID.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=show-a-volume-s-details-detail#show-a-volume-s-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nvolume_id\n\npath\nstring\nThe UUID of the volume.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/76736e1a-ad97-4599-8ca8-476650459310\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvolume\n\nbody\nobject\nA volume object.\n\nmigration_status (Optional)\nbody\nstring\nThe volume migration status. Admin only.\n\nattachments\n\nbody\narray\n\nInstance attachment information.  If this volume\r\nis attached to a server instance, the attachments list includes\r\nthe UUID of the attached server, an attachment UUID, the name of\r\nthe attached host, if any, the volume UUID, the device, and the\r\ndevice UUID.  Otherwise, this list is empty. For example:\n\n[\r\n  {\r\n    'server_id': '6c8cf6e0-4c8f-442f-9196-9679737feec6',\r\n    'attachment_id': '3dafcac4-1cb9-4b60-a227-d729baa10cf6',\r\n    'attached_at': '2019-09-30T19:30:34.000000',\r\n    'host_name': null,\r\n    'volume_id': '5d95d5ee-4bdd-4452-b9d7-d44ca10d3d53',\r\n    'device': '/dev/vda',\r\n    'id': '5d95d5ee-4bdd-4452-b9d7-d44ca10d3d53'\r\n  }\r\n]\r\n\n\nid\n\nbody\nstring\nThe UUID of the volume.\n\nlinks\n\nbody\narray\nThe volume links.\n\nname\n\nbody\nstring\nThe volume name.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\nbootable\n\nbody\nstring\nEnables or disables the bootable attribute. You\r\ncan boot an instance from a bootable volume.\n\nstatus\n\nbody\nstring\nThe volume status.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\navailability_zone (Optional)\nbody\nstring\nThe name of the availability zone.\n\ndescription\n\nbody\nstring\nThe volume description.\n\nmultiattach\n\nbody\nboolean\nIf true, this volume can attach to more than one\r\ninstance.\n\nsource_volid (Optional)\nbody\nstring\nThe UUID of the source volume. The API creates a new volume with the same\r\nsize as the source volume unless a larger size is requested.\n\nvolume_type\n\nbody\nstring\nThe associated volume type name for the volume.\n\nservice_uuid\n\nbody\nstring\n\nA unique identifier that\u00e2\u0080\u0099s used to indicate what node the volume-service\r\nfor a particular volume is being serviced by.\nNew in version 3.48\n\nshared_targets\n\nbody\nboolean\n\nAn indicator whether the back-end hosting the volume utilizes\r\nshared_targets or not. Default is True.\nNew in version 3.48\n\nos-vol-host-attr:host (Optional)\nbody\nstring\nCurrent back-end of the volume.\r\nHost format is host@backend#pool.\n\nencrypted\n\nbody\nboolean\nIf true, this volume is encrypted.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nreplication_status\n\nbody\nstring\nThe volume replication status.\n\nsnapshot_id (Optional)\nbody\nstring\nTo create a volume from an existing snapshot,\r\nspecify the UUID of the volume snapshot. The volume is created in\r\nsame availability zone and with same size as the snapshot.\n\nuser_id\n\nbody\nstring\nThe UUID of the user.\n\nos-vol-tenant-attr:tenant_id\n\nbody\nstring\nThe project ID which the volume belongs to.\n\nos-vol-mig-status-attr:migstat (Optional)\nbody\nstring\nThe status of this volume migration (None means\r\nthat a migration is not currently in progress).\n\nos-vol-mig-status-attr:name_id (Optional)\nbody\nstring\nThe volume ID that this volume name on the backend is based on.\n\nmetadata\n\nbody\nobject\nA metadata object. Contains one or more\r\nmetadata key and value pairs that are associated with the volume.\n\nvolume_image_metadata (Optional)\nbody\nobject\nList of image metadata entries.  Only included for volumes that were\r\ncreated from an image, or from a snapshot of a volume originally created\r\nfrom an image.\n\nconsistencygroup_id\n\nbody\nstring\nThe UUID of the consistency group.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"volume\": {\r\n    \"migration_status\": null,\r\n    \"attachments\": [\r\n      {\r\n        \"server_id\": \"e1ae6f7e-c35d-4656-a4fd-2371f9a791d4\",\r\n        \"attachment_id\": \"90d2562a-635b-4db0-a1eb-5f4bffe0c73c\",\r\n        \"attached_at\": \"2020-03-04T13:21:18.367315\",\r\n        \"host_name\": null,\r\n        \"volume_id\": \"76736e1a-ad97-4599-8ca8-476650459310\",\r\n        \"device\": \"/dev/vda\",\r\n        \"id\": \"76736e1a-ad97-4599-8ca8-476650459310\"\r\n      }\r\n    ],\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/76736e1a-ad97-4599-8ca8-476650459310\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8776/f5d834d636c642c7bfe8af86139c6f26/volumes/76736e1a-ad97-4599-8ca8-476650459310\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"availability_zone\": \"nova\",\r\n    \"os-vol-host-attr:host\": \"node1.vstoragedomain@vstorage#vstorage\",\r\n    \"encrypted\": false,\r\n    \"updated_at\": \"2020-03-04T13:21:18.415069\",\r\n    \"replication_status\": null,\r\n    \"snapshot_id\": null,\r\n    \"id\": \"76736e1a-ad97-4599-8ca8-476650459310\",\r\n    \"size\": 1,\r\n    \"user_id\": \"eb481bff7b7c4ec6a686646957d8064b\",\r\n    \"os-vol-tenant-attr:tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"os-vol-mig-status-attr:migstat\": null,\r\n    \"metadata\": {\r\n      \"applied-storage-policy\": \"2020-01-31T12:14:46.143657\",\r\n      \"attached_mode\": \"rw\"\r\n    },\r\n    \"status\": \"in-use\",\r\n    \"volume_image_metadata\": {\r\n      \"os_distro\": \"linux\",\r\n      \"image_validated\": \"yes\",\r\n      \"container_format\": \"bare\",\r\n      \"min_ram\": \"0\",\r\n      \"disk_format\": \"qcow2\",\r\n      \"image_name\": \"cirros\",\r\n      \"trait:CUSTOM_HCI_122E856B9E9C4D80A0F8C21591B5AFCB\": \"required\",\r\n      \"image_id\": \"c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n      \"checksum\": \"443b7623e27ecf03dc9e01ee93f67afe\",\r\n      \"min_disk\": \"1\",\r\n      \"os_type\": \"linux\",\r\n      \"hw_disk_bus\": \"virtio\",\r\n      \"size\": \"12716032\"\r\n    },\r\n    \"description\": \"Instance-e1ae6f7e-c35d-4656-a4fd-2371f9a791d4\",\r\n    \"multiattach\": false,\r\n    \"source_volid\": null,\r\n    \"consistencygroup_id\": null,\r\n    \"os-vol-mig-status-attr:name_id\": null,\r\n    \"name\": \"vm1/cirros/Boot volume\",\r\n    \"bootable\": \"true\",\r\n    \"created_at\": \"2020-03-04T13:21:10.245192\",\r\n    \"volume_type\": \"policy1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-volume-details.html"
    },
    {
        "title": "Assigning QoS policies",
        "content": "Assigning QoS policies\nAlongside the default QoS policy, you can assign QoS policies to specific network ports, floating IP addresses, and entire networks.\nPrerequisites\n\nA QoS policy is created, as described in Creating QoS policies.\n\nTo assign a QoS policy to a network port\nFind out the ID of the required network port, and then set the policy with openstack port set --qos-policy <qos-policy>. For example:# openstack --insecure port list\r\n+--------------------------------------+-----+----------------------------+\r\n| ID                                   | <\u00e2\u0080\u00a6> | Fixed IP Addresses         |\r\n+--------------------------------------+-----+----------------------------+\r\n| c0ea690f-4993-4467-afd5-5389016a0658 |     | ip_address='10.136.18.133' |\r\n+--------------------------------------+-----+----------------------------+\r\n# openstack --insecure port set --qos-policy policy1 c0ea690f-4993-4467-afd5-5389016a0658\n To assign a QoS policy to a  floating IP address\nFind out the ID of the required floating IP, and then set the policy with openstack floating ip set --qos-policy <qos-policy>. For example:# openstack --insecure floating ip list\r\n+--------------------------------------+---------------------+-----+\r\n| ID                                   | Floating IP Address | <\u00e2\u0080\u00a6> |\r\n+--------------------------------------+---------------------+-----+\r\n| 866203a2-4e1c-459f-807f-14ed563409f1 | 10.136.18.135       |     |\r\n+--------------------------------------+---------------------+-----+\r\n# openstack --insecure floating ip set --qos-policy policy1 866203a2-4e1c-459f-807f-14ed563409f1\nTo assign a QoS policy to all ports in a network\nFind out the ID or name of the required network, and then set the policy with openstack network set --qos-policy <qos-policy>. For example:# openstack --insecure network list\r\n+--------------------------------------+----------+-----+\r\n| ID                                   | Name     | <\u00e2\u0080\u00a6> |\r\n+--------------------------------------+----------+-----+\r\n| c6ee561e-9cf7-489b-bbab-7bca557ee7a5 | public   |     |\r\n+--------------------------------------+----------+-----+\r\n# openstack --insecure network set --qos-policy policy1 public\nSee also\n\nSetting the default QoS policy\n\nModifying QoS policy rules\n\nUnassigning QoS policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/assigning-qos-policies.html"
    },
    {
        "title": "Listing host aggregates",
        "content": "Listing host aggregatesGET /os-aggregates\r\n\nList host aggregates.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=list-aggregates-detail#list-aggregates\nRequest\nExamplecurl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/6ef5371261ea42008e3d1d41ba051977/os-aggregates\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\naggregates\n\nbody\narray\nThe list of existing aggregates.\n\nname\n\nbody\nstring\nThe name of the host aggregate.\n\navailability_zone\n\nbody\nstring\nThe availability zone of the host aggregate.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted_at\n\nbody\nstring\n\nThe date and time when the resource was deleted. If the resource has\r\nnot been deleted yet, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted\n\nbody\nboolean\nA boolean indicates whether this aggregate is deleted or not, if it has\r\nnot been deleted, false will appear.\n\nhosts\n\nbody\narray\nAn array of host information.\n\nid\n\nbody\ninteger\nThe ID of the host aggregate.\n\nmetadata\n\nbody\nobject\nMetadata key and value pairs associated with the aggregate.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nuuid\n\nbody\nstring\n\nThe UUID of the host aggregate.\nNew in version 2.41\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"aggregates\": [\r\n    {\r\n      \"name\": \"CUSTOM_HCI_E3A45A6A4B614263893D72015BFB1A5F\",\r\n      \"availability_zone\": null,\r\n      \"deleted\": false,\r\n      \"created_at\": \"2020-04-16T13:22:56.413373\",\r\n      \"updated_at\": null,\r\n      \"hosts\": [\r\n        \"node2.vstoragedomain\",\r\n        \"node3.vstoragedomain\"\r\n      ],\r\n      \"deleted_at\": null,\r\n      \"id\": 1,\r\n      \"metadata\": {\r\n        \"trait:CUSTOM_HCI_E3A45A6A4B614263893D72015BFB1A5F\": \"required\"\r\n      }\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-host-aggregates.html"
    },
    {
        "title": "13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\u00c2\u00b6",
        "content": "13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\u00c2\u00b6\n\nIn this chapter:\n\n13.1. Defining Pool-Based Plans\n13.1.1. Protocol Plans\n13.1.2. Power Control Plans\n13.1.3. Release Plans\n\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/offering-vhi-desktops/index.html"
    },
    {
        "title": "Editing and deleting placements",
        "content": "Editing and deleting placements\nLimitations\n\nYou cannot delete a placement that has nodes, images, or flavors.\nAfter deleting a placement, it is not automatically unassigned from virtual machines and volumes. To clean up placements from VMs and volumes, use the --no-placements option for the vinfra service compute server set and vinfra service compute volume set commands.\n\nPrerequisites\n\nPlacements for compute nodes are created, as described in Creating placements.\nBefore deleting a placement, ensure that its assignments are removed by following instructions in Changing placement assignment.\n\nTo edit a placement\n\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, select the required placement, and then click Edit on its right pane.\n\nEnter a new name or change the description, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nCommand-line interface\nUse the following command:vinfra service compute placement update [--name <name>] [--description <description>]\r\n                                        [--non-isolated | --isolated] <placement>\r\n\n\n--name <placement-name>\n\nA new name for the placement\n--description <placement-description>\n\nA new description for the placement\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--non-isolated\n\nMake the placement non-isolated (soft policy)\n--isolated\n\nMake the placement isolated (hard policy)\n\nFor example, to rename the placement placement1 to placement2, run:# vinfra service compute placement update --name placement2 placement1\n\nTo delete a placement\n\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, select the required placement.\nOn the placement right pane, click Delete.\nIn the confirmation window, click Delete placement.\n\nCommand-line interface\nUse the following command:vinfra service compute placement delete <placement>\r\n\n\n<placement>\n\nPlacement ID or name\n\nFor example, to delete the placement placement1, run:# vinfra service compute placement delete placement1\n\nSee also\n\nManaging virtual machines in placements",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute placement update [--name <name>] [--description <description>]\r\n                                        [--non-isolated | --isolated] <placement>\r\n\n\n--name <placement-name>\n\nA new name for the placement\n--description <placement-description>\n\n\nA new description for the placement\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--non-isolated\n\nMake the placement non-isolated (soft policy)\n--isolated\n\nMake the placement isolated (hard policy)\n\nFor example, to rename the placement placement1 to placement2, run:# vinfra service compute placement update --name placement2 placement1\n",
                "title": "To edit a placement"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute placement delete <placement>\r\n\n\n<placement>\n\nPlacement ID or name\n\nFor example, to delete the placement placement1, run:# vinfra service compute placement delete placement1\n",
                "title": "To delete a placement"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, select the required placement, and then click Edit on its right pane.\n\nEnter a new name or change the description, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n",
                "title": "To edit a placement"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, select the required placement.\nOn the placement right pane, click Delete.\nIn the confirmation window, click Delete placement.\n\n",
                "title": "To delete a placement"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/editing-and-deleting-placements.html"
    },
    {
        "title": "Supported guest operating systems",
        "content": "Supported guest operating systems\nThe guest operating systems listed below have been tested and are supported in virtual machines.\nOnly the x64 architecture is supported.\n\nWindows\n\nVersion\nEdition\nCPU hot plug support\nRAM hot plug support\n\nWindows Server 2022\nEssentials\nNo\nNo\n\nStandard, Datacenter\nYes\nYes\n\nWindows Server 2019\nEssentials\nNo\nNo\n\nStandard, Datacenter\nYes\nYes\n\nWindows Server 2016\nEssentials\nNo\nNo\n\nStandard, Datacenter\nYes*\nYes\n\nWindows Server 2012 R2\nEssentials, Standard, Datacenter\nYes\nYes\n\nWindows Server 2012\nStandard, Datacenter\nYes\nYes\n\nWindows Server 2008 R2\nStandard, Datacenter\nNo\nNo\n\nWindows 10\nHome, Professional, Enterprise,\r\nEnterprise 2016 LTSB\nNo\nNo\n\nWindows 8.1\nHome, Professional, Enterprise\nNo\nNo\n\n* CPU hot plug does not work properly due to a Windows bug with a wrongly installed driver. To fix the issue, refer to this solution.\n\nFor a Windows in-place upgrade to work, install the guest tools inside a virtual machine and restart it, as described in Installing guest tools.\n\nLinux\n\nDistribution\nVersion\nCPU hot plug support\nRAM hot plug support\n\nRocky Linux\n9.x, 8.x\nYes\nYes\n\nAlmaLinux\n9.x, 8.x\nYes\nYes\n\nCentOS\n8.x, 7.x\nYes\nYes\n\n6.x\nNo\nNo\n\nRed Hat Enterprise Linux \n9.x, 8.x, 7.x\nYes\nYes\n\nDebian\n10.x, 9.x\nYes\nYes\n\nUbuntu\n22.04.x, 20.04.x, 18.04.x\nYes\nYes\n\nOracle Linux\n7.3, 7.9\nYes\nYes\n\nSUSE Linux Enterprise\n15.x (SP3, SP4, SP5) \nYes\nYes\n\nWhat's next\n\nCreating virtual machines\n\nChanging virtual machine resources",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-guest-oses.html"
    },
    {
        "title": "Sending email notifications",
        "content": "Sending email notifications\nVirtuozzo Hybrid Infrastructure can send automatic email notifications about errors, warnings, and alerts.\nPrerequisites\n\nThe management node must be able to access the SMTP server.\n\nTo set up email notifications\n\nAdmin panel\n\nGo to Settings > System settings > Email notifications and turn on the toggle switch Enable email notification.\n\nSpecify the SMTP server details:\n\nIn User account and User password, the credentials of the notification sender registered on the SMTP server.\nIn SMTP server, the DNS name of the SMTP server, either public (for example, smtp.gmail.com) or the one in your organization.\nIn SMTP port, a custom  SMTP port that the server uses.\nIn Security, the security protocol of the SMTP server.\n\nSelect Errors, Warnings, and/or Information, to be notified about these alerts.\n\nSpecify the sender and recipient details:\n\nIn From and Sender name, the notification sender\u00e2\u0080\u0099s email and name.\nIn To , enter one or more notification recipients\u00e2\u0080\u0099 emails, comma separated.\n\nTo send a test email, click Test.\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra cluster settings email-notifications set [--user-account <user-account>]\r\n                                                [--user-password <user-password>]\r\n                                                --smtp-server <smtp-server>\r\n                                                --smtp-port <smtp-port>\r\n                                                --security {SSL,STARTTLS}\r\n                                                --severity {error,warning,info}\r\n                                                [--from <from>] [--sender-name <sender-name>]\r\n                                                [--email-recipients-list <email-recipients-list>]\n\n--user-account <user-account>\n\nUser account of the notification sender\n--user-password <user-password>\n\nPassword for the user account\n--smtp-server <smtp-server>\n\nDNS name of the SMTP server\n--smtp-port <smtp-port>\n\nSMTP port used by the SMTP server\n--security {SSL,STARTTLS}\n\nSecurity protocol of the SMTP server\n--severity {error,warning,info}\n\nSeverity type of email notifications. This option can be used multiple times.\n--from <from>\n\nEmail address of the notification sender\n--sender-name <sender-name>\n\nNotification sender name\n--email-recipients-list <email-recipients-list>\n\nA comma-separated list of notification recipients' emails\n\nFor example, to set up email notification from notifier@example.com to user1@example.com, user2@example.com, and user3@example.com, run:# vinfra cluster settings email-notifications set --user-account notifier@example.com --user-password ****** \\\r\n--smtp-server smtp.example.com --smtp-port 587 --security SSL --severity warning --severity error \\\r\n--from notifier@example.com --sender-name \"Event notifier\" --email-recipients-list user1@example.com,user2@example.com,user3@example.com\nYou can view the email notifications settings in the vinfra cluster settings email-notifications show output:# vinfra cluster settings email-notifications show\r\n+-----------------------+------------------------------------+\r\n| Field                 | Value                              |\r\n+-----------------------+------------------------------------+\r\n| notification_settings | alerts_severities:                 |\r\n|                       | - warning                          |\r\n|                       | - error                            |\r\n|                       | email_recipients_list:             |\r\n|                       | - user1@example.com                |\r\n|                       | - user2@example.com                |\r\n|                       | - user3@example.com                |\r\n|                       | from: notifier@example.com         |\r\n|                       | sender_name: Event notifier        |\r\n| smtp_settings         | account_name: notifier@example.com |\r\n|                       | connection_security: SSL           |\r\n|                       | port: 587                          |\r\n|                       | smtp_server: smtp.example.com      |\r\n+-----------------------+------------------------------------+\n\nTo disable email notifications\n\nAdmin panel\n\nGo to Settings > System settings > Email notifications and turn off the toggle switch Enable email notification.\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra cluster settings email-notifications disable\n\nSee also\n\nViewing alerts\n\nViewing audit log\n\nMonitoring infrastructure nodes\n\nMonitoring cluster objects via SNMP",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings email-notifications set [--user-account <user-account>]\r\n                                                [--user-password <user-password>]\r\n                                                --smtp-server <smtp-server>\r\n                                                --smtp-port <smtp-port>\r\n                                                --security {SSL,STARTTLS}\r\n                                                --severity {error,warning,info}\r\n                                                [--from <from>] [--sender-name <sender-name>]\r\n                                                [--email-recipients-list <email-recipients-list>]\n\n--user-account <user-account>\n\nUser account of the notification sender\n--user-password <user-password>\n\nPassword for the user account\n--smtp-server <smtp-server>\n\nDNS name of the SMTP server\n--smtp-port <smtp-port>\n\nSMTP port used by the SMTP server\n--security {SSL,STARTTLS}\n\nSecurity protocol of the SMTP server\n--severity {error,warning,info}\n\nSeverity type of email notifications. This option can be used multiple times.\n--from <from>\n\nEmail address of the notification sender\n--sender-name <sender-name>\n\nNotification sender name\n--email-recipients-list <email-recipients-list>\n\nA comma-separated list of notification recipients' emails\n\nFor example, to set up email notification from notifier@example.com to user1@example.com, user2@example.com, and user3@example.com, run:# vinfra cluster settings email-notifications set --user-account notifier@example.com --user-password ****** \\\r\n--smtp-server smtp.example.com --smtp-port 587 --security SSL --severity warning --severity error \\\r\n--from notifier@example.com --sender-name \"Event notifier\" --email-recipients-list user1@example.com,user2@example.com,user3@example.com\nYou can view the email notifications settings in the vinfra cluster settings email-notifications show output:# vinfra cluster settings email-notifications show\r\n+-----------------------+------------------------------------+\r\n| Field                 | Value                              |\r\n+-----------------------+------------------------------------+\r\n| notification_settings | alerts_severities:                 |\r\n|                       | - warning                          |\r\n|                       | - error                            |\r\n|                       | email_recipients_list:             |\r\n|                       | - user1@example.com                |\r\n|                       | - user2@example.com                |\r\n|                       | - user3@example.com                |\r\n|                       | from: notifier@example.com         |\r\n|                       | sender_name: Event notifier        |\r\n| smtp_settings         | account_name: notifier@example.com |\r\n|                       | connection_security: SSL           |\r\n|                       | port: 587                          |\r\n|                       | smtp_server: smtp.example.com      |\r\n+-----------------------+------------------------------------+\n",
                "title": "To set up email notifications"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings email-notifications disable\n",
                "title": "To disable email notifications"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Email notifications and turn on the toggle switch Enable email notification.\n\nSpecify the SMTP server details:\n\nIn User account and User password, the credentials of the notification sender registered on the SMTP server.\nIn SMTP server, the DNS name of the SMTP server, either public (for example, smtp.gmail.com) or the one in your organization.\nIn SMTP port, a custom  SMTP port that the server uses.\nIn Security, the security protocol of the SMTP server.\n\n\n\n\n\n\nSelect Errors, Warnings, and/or Information, to be notified about these alerts.\n\nSpecify the sender and recipient details:\n\nIn From and Sender name, the notification sender\u00e2\u0080\u0099s email and name.\nIn To , enter one or more notification recipients\u00e2\u0080\u0099 emails, comma separated.\n\n\n\n\n\n\nTo send a test email, click Test.\nClick Save to apply your changes.\n\n",
                "title": "To set up email notifications"
            },
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Email notifications and turn off the toggle switch Enable email notification.\nClick Save to apply your changes.\n\n",
                "title": "To disable email notifications"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/sending-email-notifications.html"
    },
    {
        "title": "Managing compute resources",
        "content": "Managing compute resources",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-compute-resources.html"
    },
    {
        "title": "Listing project quotas",
        "content": "Listing project quotas\nCores and RAMGET /v2.1/{authorized_project_id}/os-quota-sets/{project_id}\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"ram\": 32768,\r\n    <...>\r\n    \"cores\": 8,\r\n    <...>\r\n  }\r\n}\r\n\nStorage limits of storage policies and volume backupsGET /v3/{authorized_project_id}/os-quota-sets/{project_id}\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"backup_gigabytes\": 20,\r\n    \"gigabytes_default\": 64,\r\n    <...>\r\n    \"gigabytes_policy1\": 128\r\n  }\r\n}\r\n\nFloating IPs and VPN connectionsGET /v2.0/quotas/{project_id}\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota\": {\r\n    <...>\r\n    \"floatingip\": 24,\r\n    <...>\r\n    \"ipsec_site_connection\": -1,\r\n    <...>\r\n  }\r\n}\r\n\nLoad balancersGET /v2/lbaas/quotas/{project_id}\nThe add-on service must be installed.\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9888/v2/lbaas/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota\": {\r\n    \"load_balancer\": 8,\r\n    <...>\r\n  }\r\n}\r\n\nKubernetes clustersGET /v1/quotas/{project_id}/Cluster\nThe add-on service must be installed.\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9513/v1/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92/Cluster\r\n\nResponse{\r\n  \"resource\": \"Cluster\",\r\n   <...>\r\n  \"hard_limit\": 8,\r\n   <...>\r\n}\r\n\nPlacementsGET /quotas/{project_id}\nThe add-on service must be installed. Specify the microversion in the header, e.g., OpenStack-API-Version: placement 1.32.\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\n-H 'OpenStack-API-Version: placement 1.32' \\\r\nhttps://<node_IP_addr>:8780/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quotas\": {\r\n    \"CUSTOM_HCI_122E856B9E9C4D80A0F8C21591B5AFCB\": 16\r\n  }\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-project-quotas.html"
    },
    {
        "title": "Deleting bucket limits via CLI",
        "content": "Deleting bucket limits via CLI\nYou can delete the current limits with the rm-limits command and parameter -b specifying the bucket name:# ostor-s3-admin rm-limits -b example\r\nops:default=0.00ops/s\r\nops:get=0.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=0kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-bucket-limits-via-cli.html"
    },
    {
        "title": "Assigning Kubernetes pods to specific nodes",
        "content": "Assigning Kubernetes pods to specific nodes\nBy using worker groups, you can assign a pod in Kubernetes to specific nodes. When you create a custom worker group, its nodes are added a label with the group name. If you want your pod to be scheduled on a node from a specific worker group, add the node selector section with the node label to the pod's configuration file.\nTo create a pod that will be scheduled on a specific node\nClick + Create on the Kubernetes dashboard and specify a YAML file that defines this object. For example:apiVersion: v1\r\nkind: Pod\r\nmetadata:\r\n  name: nginx\r\n  labels:\r\n    env: test\r\nspec:\r\n  containers:\r\n  - name: nginx\r\n    image: nginx\r\n    imagePullPolicy: IfNotPresent\r\n  nodeSelector:\r\n    magnum.openstack.org/nodegroup: mygroup\nThis manifest describes the pod nginx that will be assigned to a node from the node group mygroup. \nWhen the pod is created, check that the hosting node belongs to the specified worker group.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/assigning-kubernetes-pods-to-specific-nodes.html"
    },
    {
        "title": "Modifying QoS policy rules",
        "content": "Modifying QoS policy rules\nYou can modify QoS policy rules at runtime. Changes will take effect on all ports to which the policy is applied.\nPrerequisites\n\nA QoS policy is created, as described in Creating QoS policies.\n\nTo edit a policy rule\nSpecify new parameter values, the policy name, and its rule ID with openstack network qos rule set. For example:# openstack --insecure network qos policy show policy1\r\n+-------+---------------------------------------------------------------+\r\n| Field | Value                                                         |\r\n+-------+---------------------------------------------------------------+\r\n| <\u00e2\u0080\u00a6>   |                                                               |\r\n| name  | policy1                                                       |\r\n| rules | [{u'max_kbps': 3000, u'direction': u'ingress',                |\r\n|       |   u'qos_policy_id': u'8e2511c9-7db5-456c-b8ee-939f7729d981',  |\r\n|       |   u'type': u'bandwidth_limit', u'max_burst_kbps': 2400,       |\r\n|       |   u'id': u'6f036f09-d952-420d-986b-27c7eb14b2da'}]            |\r\n| <\u00e2\u0080\u00a6>   |                                                               |\r\n+-------+---------------------------------------------------------------+\r\n# openstack --insecure network qos rule set --max-kbps 2000 --max-burst-kbits 1600 \\--ingress policy1 6f036f09-d952-420d-986b-27c7eb14b2da\nSee also\n\nSetting the default QoS policy\n\nAssigning QoS policies\n\nUnassigning QoS policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/modifying-qos-policy-rules.html"
    },
    {
        "title": "About the storage cluster",
        "content": "About the storage cluster\nThe storage cluster provides the most efficient usage of the hardware with erasure coding, integrated SSD caching, automatic load balancing, and RDMA/InfiniBand support. The cluster space can be used for:\n\niSCSI block storage (hot data and virtual machines)\nS3 object storage (protected with geo-replication or cross-region replication between datacenters)\nFile storage (NFS)\n\nIn addition, Virtuozzo Hybrid Infrastructure is integrated with Acronis Cyber Protection solutions for storing backups in the cluster, sending them to cloud services (like Google Cloud, Microsoft Azure, and AWS S3), or storing them on NAS via the NFS protocol. Geo-replication is available for Backup Gateways set up on different storage backends: a local storage cluster, NFS share, or public cloud.\nData storage policies can be customized to meet various use cases: each data volume can have a specific redundancy mode, storage tier, and failure domain. Moreover, the data can be encrypted with the AES-256 standard.\n\nSee also\n\nDeploying the storage cluster\n\nData redundancy\n\nFailure domains\n\nStorage tiers\n\nStorage policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/about-the-storage-cluster.html"
    },
    {
        "title": "Deploying the appliance virtual machine",
        "content": "Deploying the appliance virtual machine\nTo create a virt-v2v appliance VM\n\nDownload the virt-v2v appliance image from the official repository.\n\nUpload the image to Virtuozzo Hybrid Infrastructure. For example:# vinfra service compute image create virt-v2v-img --file vmware_to_vip.qcow2\n\nCreate an SSH key for the appliance if you do not have one. For example:# vinfra service compute key create publickey --public-key virt-v2v-app-key.pub\r\n\n\nCreate a virtual machine and deploy the uploaded image in it. The VM needs at least two CPUs, 4 GiB RAM, and enough storage space to accommodate the largest VM to be migrated to Virtuozzo Hybrid Infrastructure. It must also be connected to the network that handles the Compute API traffic type and the network with access to VMware vCenter API. For example:# vinfra service compute server create virt-v2v-appliance --flavor medium --key-name <key>\r\n--network id=<compute_API> --network id=<vcenter_API> --volume source=image,id=virt-v2v-img,size=<size>\r\n\nWhere:\n\n<key> is the SSH key to authorize in the appliance VM.\n<compute_API> is the network that handles the traffic type Compute API.\n<vcenter_API> is the network that can access the VMware vCenter API.\n<size> is the disk size. For online migration, it must be enough to accommodate the largest VM of all you are going to migrate. For offline migration, it must be enough to accommodate twice as much.\n\nWhat's next\n\nSetting up authentication in the appliance virtual machine",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/deploying-the-appliance-virtual-machine.html"
    },
    {
        "title": "Account management",
        "content": "Account management\nThis section describes how to manage S3 accounts, which are containers for S3 users with additional credentials.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/account-management.html"
    },
    {
        "title": "Creating volumes from images",
        "content": "Creating volumes from images\nYou can create volumes from both ISO images and templates. \nTo make a  volume from an image\n\nGo to the Images screen, and then click the required image.\nOn the image panel, click Create volume.\n\nIn the Create volume window, specify the volume name, size, and select a storage policy.\n\nClick Create.\n\nThe new volume will appear on the Volumes screen.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-volumes-from-images.html"
    },
    {
        "title": "Deleting images",
        "content": "Deleting imagesDELETE /v2/images/{image_id}\r\n\nDelete an image with the specified ID.\nPreconditions:\n\nYou can delete an image in any status except deleted.\nThe protected attribute of the image cannot be true.\nYou must be allowed to delete images by the image deletion policy.\n\nSource: https://docs.openstack.org/api-ref/image/v2/index.html?expanded=delete-image-detail#delete-image\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nimage_id\n\npath\nstring\nThe UUID of the image.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9292/v2/images/a353024f-ea44-4609-b6d0-fb00de7112ec\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-images.html"
    },
    {
        "title": "Object storage metrics",
        "content": "Object storage metrics\n Metrics used for monitoring object storage are configured in the Prometheus recording rules and can be found in these files on any node in the cluster:\n\n/var/lib/prometheus/rules/s3.rules\n\n/var/lib/prometheus/rules/ostor.rules\n\nMetrics that are used to generate object storage alerts are added to the alerting rules in /var/lib/prometheus/alerts/s3.rules. These metrics are described in the table:\n\nMetric\nDescription\n\ninstance_vol_svc:ostor_s3gw_req:rate5m\n\nNumber of all requests per second by a particular S3 gateway service for 5 minutes\n\ninstance_vol_svc:ostor_s3gw_req_cancelled:rate5m\n\nNumber of canceled requests per second by a particular S3 gateway service for 5 minutes\n\ninstance_vol_svc:ostor_req_server_err:rate5m\n\nNumber of failed requests with a server error (5XX status code) per second by a particular S3 gateway service for 5 minutes\n\ninstance_vol_svc:ostor_s3gw_get_req_latency_ms_bucket:rate5m\n\nCurrent GET request latency by a particular S3 gateway service for 5 minutes, for each bucket\n\ninstance_vol_svc:ostor_commit_latency_us_bucket:rate5m\n\nCurrent commit latency by the Object storage service for 5 minutes, for each bucket\n\ninstance_vol_svc_req:ostor_os_req_latency_ms_bucket:rate5m\n\nCurrent request latency by a particular OS service for 5 minutes, for each bucket\n\ninstance_vol_svc_req:ostor_ns_req_latency_ms_bucket:rate5m\n\nCurrent request latency by a particular NS service for 5 minutes, for each bucket\n\npcs_process_inactive_seconds_total\n\nTotal amount of time a process has been inactive\n\nprocess_cpu_seconds_total\n\nTotal amount of time a process has used CPU\n\nostor_svc_start_failed_count_total\n\nTotal number of failed attempts to start a service\n\nostor_svc_registry_cfg_failed_total\n\nTotal number of failed attempts to connect to the configuration service\n\nnds_staged_messages_count\n\nTotal number of unprocessed NDS notification messages that are staged on the storage\n\nnds_endpoint_process_count\n\nNumber of NDS notification messages that are being simultaneously processed on the endpoint\n\ninstance_vol_svc:ostor_nds_total:rate5m\n\nNumber of NDS notification messages per second by a particular NDS service for 5 minutes\n\ninstance_vol_svc:ostor_nds_repeat_total:rate5m\n\nNumber of repeated NDS notification messages per second by a particular NDS service for 5 minutes\n\ninstance_vol_svc:ostor_nds_error_total:rate5m\n\nNumber of all NDS notification processing errors per second by a particular NDS service for 5 minutes\n\ninstance_vol_svc:ostor_nds_delete_error_total:rate5m\n\nNumber of all NDS notification deletion errors per second by a particular NDS service for 5 minutes\n\nrpc_errors_total\n\nNumber of RPC errors reported by the user space part of storage\n\nfused_kernel_rpc_errors_total\n\nNumber of RPC errors reported by the kernel part of storage\n\nBucket and user size metrics\nMetrics that report object storage usage per bucket and per user are not available by default. To collect this statistics, you need to enable it by running the following command on an S3 node:# ostor-ctl set-vol -V 0100000000000002 --enable-stat\nThe following metrics will appear in Prometheus:\n\naccount_control_buckets_size: Bucket size, in bytes\naccount_control_user_size: Total size of all user buckets, in bytes\n\nSee also\n\nObject storage alerts\n\nCore storage metrics\n\nBackup storage metrics\n\nCompute metrics\n\nCluster update metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/s3-metrics.html"
    },
    {
        "title": "Monitoring load balancers",
        "content": "Monitoring load balancers\nTo monitor performance and health of a load balancer\nOpen the Overview tab on the load balancer right pane.\nThe following charts are available:\n\nMembers state\n\nThe total number of members in the balancing pools grouped by status: \u00e2\u0080\u009cHealthy,\u00e2\u0080\u009d \u00e2\u0080\u009cUnhealthy,\u00e2\u0080\u009d \u00e2\u0080\u009cError,\u00e2\u0080\u009d and \u00e2\u0080\u009cDisabled\u00e2\u0080\u009d.\nNetwork\n\nIncoming and outgoing network traffic.\nActive connections\n\nThe number of active connections.\nError requests\n\nThe number of error requests.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/monitoring-load-balancers.html"
    },
    {
        "title": "Changing the storage policy for volumes",
        "content": "Changing the storage policy for volumes\nIf you use redundancy by replication for a compute volume, you can update the chosen redundancy scheme by changing the storage policy. With redundancy by erasure coding, however, changing the redundancy scheme applied to the volume is disabled. The storage policy can only be changed for available volumes, that is, volumes not attached to any virtual machines.\nLimitations\n\nOnly storage policies enabled by project quotas will be available for selection.\nChanging the storage policy with the erasure coding redundancy type is disabled.\nYou cannot change the storage policy of a volume with the \"In use\" status.\n\nPrerequisites\n\nA volume is created, as described in Creating and deleting volumes.\n\nTo change the storage policy of a volume\n\nOn the Volumes screen, click a volume.\nClick the pencil icon in the Storage policy field.\nSelect a new storage policy, and then click the tick icon. You can choose only between storage policies with the replication redundancy type.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/changing-volume-storage-policy.html"
    },
    {
        "title": "Updating Kubernetes clusters",
        "content": "Updating Kubernetes clusters\nWhen a new Kubernetes version becomes available, you can update your Kubernetes cluster to it. An update is non-disruptive for Kubernetes worker nodes, which means that these nodes are updated one by one, with the data availability unaffected. The Kubernetes API will be unavailable during an update, unless high availability is enabled for the master node.\nStarting from a Kubernetes cluster update to version 1.24.3, Kubernetes virtual machines are re-created based on a newer Fedora CoreOS image. Such a rolling update is used to preserve the cluster data. Before starting the update, you need to make sure that the compute cluster has enough resources and quotas for at least one extra VM of the largest flavor used by your Kubernetes cluster. If the master and worker node flavors differ, then you should take into account the largest one of them.\nLimitations\n\nYou cannot update Kubernetes clusters with versions 1.15.x\u00e2\u0080\u00931.17.x to newer versions.\nYou can update Kubernetes clusters only to the next minor version in one iteration. For example, to update a cluster from version 1.25 to 1.27, you need to update it to version 1.26 first.\nKubernetes clusters can have only one minor version difference between node groups (for example, 1.26 and 1.27).\nYou cannot manage Kubernetes clusters in the self-service panel during an update.\n\nPrerequisites\n\nA Kubernetes cluster is created, as described in Creating and deleting Kubernetes clusters.\n\nTo update a Kubernetes cluster\n\nClick a Kubernetes cluster that is marked with the Update available tag.\nOn the Kubernetes cluster pane, click Update in the Kubernetes version field.\n\nIn the Update window, do the following:\n\nSelect a Kubernetes version to update to and follow the provided link to read about API resources that are deprecated or obsoleted in the selected version. Then, click Next.\n\nChoose how to proceed:\n\nSelect Update all to update all of the node groups in the Kubernetes cluster.\nSelect Custom update to update only specific node groups. The master node group is selected automatically and is mandatory for an update.\n\nIn the confirmation window, click Confirm. The update process will start.\n\nDo not manage Kubernetes virtual machines during the update as it may lead to disruption of the update process and cluster inoperability.\n\nWhen node groups in a Kubernetes cluster have different versions, the cluster tag changes to Partially updated. In this case, new worker groups will be created with the version of the master node group. To finish the Kubernetes cluster upgrade, you need to repeat the update procedure for worker groups with an older version.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/updating-kubernetes-clusters.html"
    },
    {
        "title": "About WHMCS",
        "content": "About WHMCS\nWHMCS is an all-in-one hosting automation platform with client management, provisioning of services, billing and support. It handles everything from signup to termination of customers. Its functionality is expandable with extensions, add-ons, and hooks executing third-party code on certain events. You can find more information about WHMCS at https://www.whmcs.com/.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/about-whmcs.html"
    },
    {
        "title": "Showing virtual subnet details",
        "content": "Showing virtual subnet detailsGET /v2.0/subnets/{subnet_id}\r\n\nShows the details of a subnet with the specified ID.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-subnet-details-detail#show-subnet-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nsubnet_id\n\npath\nstring\nThe ID of the subnet.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/subnets/aa29d149-b2a4-45a0-8066-dc63fa9c9b77\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nsubnet\n\nbody\nobject\nA subnet object.\n\nid\n\nbody\nstring\nThe ID of the subnet.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\nenable_dhcp\n\nbody\nboolean\nIndicates whether dhcp is enabled or disabled\r\nfor the subnet.\n\nnetwork_id\n\nbody\nstring\nThe ID of the network to which the subnet belongs.\n\ndns_nameservers\n\nbody\narray\nList of dns name servers associated with the subnet.\n\nallocation_pools\n\nbody\narray\nAllocation pools with start and end IP addresses\r\nfor this subnet.\n\nhost_routes\n\nbody\narray\nAdditional routes for the subnet. A list of dictionaries with\r\ndestination and nexthop parameters.\n\nip_version\n\nbody\ninteger\nThe IP protocol version. Value is 4 or 6.\n\ngateway_ip\n\nbody\nstring\nGateway IP of this subnet. If the value is null that implies no\r\ngateway is associated with the subnet.\n\ncidr\n\nbody\nstring\nThe CIDR of the subnet.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndescription\n\nbody\nstring\nA human-readable description for the subnet.\n\nipv6_address_mode\n\nbody\nstring\nThe IPv6 address modes specifies mechanisms for assigning IP addresses.\r\nValue is slaac, dhcpv6-stateful, dhcpv6-stateless or null.\n\nipv6_ra_mode\n\nbody\nstring\nThe IPv6 router advertisement specifies whether the networking service\r\nshould transmit ICMPv6 packets, for a subnet. Value is slaac,\r\ndhcpv6-stateful, dhcpv6-stateless or null.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the subnet.\n\nsegment_id\n\nbody\nstring\nThe ID of a network segment the subnet is associated with.\r\nIt is available when segment extension is enabled.\n\nsubnetpool_id\n\nbody\nstring\nThe ID of the subnet pool associated with the subnet.\n\nservice_types\n\nbody\narray\nThe service types associated with the subnet.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\ndns_publish_fixed_ip\n\nbody\nboolean\nWhether to publish DNS records for IPs from this subnet.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"subnet\": {\r\n    \"service_types\": [],\r\n    \"description\": \"\",\r\n    \"enable_dhcp\": true,\r\n    \"tags\": [],\r\n    \"network_id\": \"c5252a20-9206-4b8e-9a0f-45bd22ee7bc8\",\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-02-14T13:42:56Z\",\r\n    \"dns_nameservers\": [\r\n      \"10.30.0.27\",\r\n      \"10.30.0.28\"\r\n    ],\r\n    \"updated_at\": \"2020-02-14T13:42:56Z\",\r\n    \"gateway_ip\": \"192.168.10.1\",\r\n    \"ipv6_ra_mode\": null,\r\n    \"allocation_pools\": [\r\n      {\r\n        \"start\": \"192.168.10.2\",\r\n        \"end\": \"192.168.10.254\"\r\n      }\r\n    ],\r\n    \"host_routes\": [],\r\n    \"revision_number\": 0,\r\n    \"ip_version\": 4,\r\n    \"ipv6_address_mode\": null,\r\n    \"cidr\": \"192.168.10.0/24\",\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"id\": \"aa29d149-b2a4-45a0-8066-dc63fa9c9b77\",\r\n    \"subnetpool_id\": null,\r\n    \"name\": \"\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-virtual-subnet-details.html"
    },
    {
        "title": "Creating backups",
        "content": "Creating backupsPOST /v3/{project_id}/backups\nCreate a backup from a volume or snapshot.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/#create-a-backup\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nbackup\n\nbody\nobject\nA backup object.\n\nvolume_id\n\nbody\nstring\nThe UUID of the volume.\n\ncontainer (Optional)\nbody\nstring\nThe container name or null.\n\ndescription (Optional)\nbody\nstring\nThe backup description or null.\n\nincremental (Optional)\nbody\nboolean\nThe backup mode. A valid value is true for the incremental backup mode or false for the full backup mode. Default is false.\n\nforce (Optional)\nbody\nboolean\nIndicates whether to back up, even if the volume is attached. Default is false.\n\nname (Optional)\nbody\nstring\nThe name of the volume backup.\n\navailability_zone (Optional)\nbody\nstring\nThe name of the availability zone.\n\nsnapshot_id (Optional)\nbody\n\r\nstring\nThe UUID of the source volume snapshot.\n\nmetadata (Optional)\nbody\nobject\n\nThe backup metadata key value pairs.\nNew in version 3.43\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\{\r\n    \"backup\": {\r\n        \"volume_id\": \"98db149d-b9e6-42d7-814d-492563c56fef\",\r\n        \"name\": \"vm2/cirros/Boot volume-2024-05-09T10:41:13\",\r\n        \"description\": \"New backup\",\r\n        \"incremental\": false,\r\n        \"snapshot_id\": null\r\n    }\r\n}' https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nbackup\n\nbody\nobject\nA backup object.\n\nid\n\nbody\nstring\nThe UUID of the backup.\n\nlinks\n\nbody\narray\nLinks for the backup.\n\nname\n\nbody\nstring\nThe backup name.\n\nmetadata (Optional)\nbody\nobject\n\nThe backup metadata key value pairs.\nNew in version 3.43\n\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\nExample{\r\n  \"backup\": {\r\n    \"id\": \"bcb8fc88-a0ba-4cd0-801a-e9face1eac88\",\r\n    \"name\": \"vm2/cirros/Boot volume-2024-05-09T10:41:13\",\r\n    \"links\": [\r\n      {\r\n        \"rel\": \"self\",\r\n        \"href\": \"https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\"\r\n      },\r\n      {\r\n        \"rel\": \"bookmark\",\r\n        \"href\": \"https://<node_IP_addr>:8776/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\"\r\n      }\r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-backups.html"
    },
    {
        "title": "Enabling nested virtualization",
        "content": "Enabling nested virtualization\nNested virtualization allows you to run virtual machines in Virtuozzo Hybrid Infrastructure clusters that are deployed inside Virtuozzo Hybrid Infrastructure virtual machines. To support nested virtualization, the virtualization engine adds Intel VT-x or AMD-V instructions to VMs, so that a virtual machine can use the hypervisor to run nested VMs.\nLimitations\n\nVirtuozzo Hybrid Infrastructure supports nested virtualization for evaluation purposes only. Do not use nested virtualization for production workloads.\n\nTo enable nested virtualization\n\nLog in to your compute node via SSH.\n\nCreate the /etc/modprobe.d/dist.conf file as follows:\n\n[For Intel-based systems] Add the line options kvm_intel nested=y:# cat > /etc/modprobe.d/dist.conf <<\\EOT\r\noptions kvm_intel nested=y\r\nEOT\n\n[For AMD-based systems] Add the line options kvm_amd nested=y:# cat > /etc/modprobe.d/dist.conf <<\\EOT\r\noptions kvm_amd nested=y\r\nEOT\n\n[For AMD-based systems only] Add the svm flag to your CPU model. For example:# vinfra service compute set --cpu-model EPYC-IBPB --cpu-features svm\n\nReboot the node:# reboot\n\nRepeat the steps on all other compute nodes.\n\nAll virtual machines created after the configuration will support nested virtualization.\nYou can check if nested virtualization is enabled as follows:\n\nFor a node:\n\n[For Intel-based systems] Run this command on the node:# cat /sys/module/kvm_intel/parameters/nested\r\nY\n\n[For AMD-based systems] Run this command on the node:# cat /sys/module/kvm_amd/parameters/nested\r\nY\n\nFor a virtual machine, run this command inside the VM:\n\nThe virtual machine should be created after enabling nested virtualization.\n# cat /proc/cpuinfo | grep vmx\n\nSee also\n\nConfiguring CPU features for virtual machines\n\nChanging virtual CPU overcommitment\n\nConfiguring memory for virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-nested-virtualization.html"
    },
    {
        "title": "Managing images",
        "content": "Managing images\nVirtuozzo Hybrid Infrastructure allows you to upload ISO images and templates that can be used to create VM volumes:\n\nAn ISO image is a typical OS distribution that needs to be installed on disk. You can upload an ISO image to the compute cluster.\nA template is a ready boot volume in the QCOW2 (rarely RAW or IMG) format with an installed operating system and applications. Many OS vendors offer templates of their operating systems under the name \u00e2\u0080\u009ccloud images\u00e2\u0080\u009d. You can upload a cloud image from the OS official repository or prepare your own template in the compute cluster.\n\nPrerequisites\n\nKnowledge of the supported guest operating systems listed in Supported guest operating systems. \r\n\t\t",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-images.html"
    },
    {
        "title": "Showing backup details",
        "content": "Showing backup detailsGET /v3/{project_id}/backups/{backup_id}\nShows details for a backup.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/#show-backup-detail\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nbackup_id\n\npath\nstring\nThe UUID for a backup.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nbackup\n\nbody\nobject\nA backup object.\n\nid\n\nbody\nstring\nThe UUID of the backup.\n\nvolume_id\n\nbody\nstring\nThe UUID of the volume.\n\nstatus\n\nbody\nstring\nThe backup status.\n\nobject_count\n\nbody\ninteger\nThe number of objects in the backup.\n\nfail_reason\n\nbody\nstring\n\r\nIf the backup failed, the reason for the failure. Otherwise, null.\n\ncontainer (Optional)\nbody\nstring\nThe container name or null.\n\ndescription (Optional)\nbody\nstring\nThe backup description or null.\n\navailability_zone (Optional)\nbody\nstring\nThe name of the availability zone.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\n\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated.\n\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nlinks\n\nbody\narray\nLinks for the backup.\n\nname\n\nbody\nstring\nThe backup name.\n\nhas_dependent_backups (Optional)\nbody\nboolean\nIf this value is true, there are other backups depending on this backup.\n\nsize\n\nbody\n\r\ninteger\nThe size of the volume, in gibibytes (GiB).\n\nis_incremental (Optional)\nbody\nboolean\nIndicates whether the backup mode is incremental. If this value is true, the backup mode is incremental. If this value is false, the backup mode is full.\n\ndata_timestamp\n\nbody\nstring\nThe time when the data on the volume was first saved. If it is a backup from a volume, it will be the same as created_at for a backup. If it is a backup from a snapshot, it will be the same as created_at for the snapshot.\n\nsnapshot_id (Optional)\nbody\n\r\nstring\nThe UUID of the source volume snapshot.\n\nos-backup-project-attr:project_id\n\nbody\nstring\n\nThe UUID of the owning project.\nNew in version 3.18\n\nmetadata (Optional)\nbody\nobject\n\nThe backup metadata key value pairs.\nNew in version 3.43\n\nuser_id\n\nbody\nstring\n\nThe UUID of the project owner.\nNew in version 3.56\n\nencryption_key_id (Optional)\nbody\nstring\n\nThe UUID of the encryption key. Only included for encrypted volumes.\nNew in version 3.64\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"backup\": {\r\n    \"id\": \"bcb8fc88-a0ba-4cd0-801a-e9face1eac88\",\r\n    \"status\": \"available\",\r\n    \"size\": 1,\r\n    \"object_count\": 4,\r\n    \"availability_zone\": null,\r\n    \"container\": \"bucket1\",\r\n    \"created_at\": \"2024-05-09T14:16:49.594833\",\r\n    \"updated_at\": \"2024-05-09T14:17:03.236015\",\r\n    \"name\": \"vm2/cirros/Boot volume-2024-05-09T10:41:13\",\r\n    \"description\": \"New backup\",\r\n    \"fail_reason\": null,\r\n    \"volume_id\": \"98db149d-b9e6-42d7-814d-492563c56fef\",\r\n    \"links\": [\r\n      {\r\n        \"rel\": \"self\",\r\n        \"href\": \"https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\"\r\n      },\r\n      {\r\n        \"rel\": \"bookmark\",\r\n        \"href\": \"https://<node_IP_addr>:8776/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\"\r\n      }\r\n    ],\r\n    \"is_incremental\": false,\r\n    \"has_dependent_backups\": false,\r\n    \"snapshot_id\": null,\r\n    \"data_timestamp\": \"2024-05-09T14:16:49.594833\",\r\n    \"progress\": 100.0\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-backup-details.html"
    },
    {
        "title": "Preparing to run the benchmark",
        "content": "Preparing to run the benchmark\nIf the cluster nodes have SSD/NVMe caches, make sure they have been flushed before running any benchmarks. You can check the caches as follows:\n\nOn a cluster node, run:# vstorage -c <cluster_name> top\n\nWhile in the text-based dashboard, press c to expand the chunks tab, and then cycle columns by pressing i until you see the JRN_FULL and FLAGS columns.\n\nWait until JRN_FULL is 0% and each CS ID is marked by the c flag, for example, JCc. This may take some time when the cluster is not under I/O load. The journal cleaning can be forced by running:# vstorage -c <cluster_name> set-config cs.force_checkpoint=1\r\n# vstorage -c <cluster_name> set-config cs.force_checkpoint=0\n\nWhat's next\n\nRunning the benchmark for NFS and iSCSI\n\nRunning the benchmark for S3",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-to-run-benchmark.html"
    },
    {
        "title": "Updating users",
        "content": "Updating usersPATCH /v3/users/{user_id}\r\n\nChange the name and password of a user with the specified ID.\nIf the back-end driver does not support this functionality, this\r\ncall might return the HTTP Not Implemented (501) response code.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=update-user-detail#update-user\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nuser_id\n\npath\nstring\nThe user ID.\n\nuser\n\nbody\nobject\nA user object.\n\ndefault_project_id (Optional)\nbody\nstring\n\nThe ID of the default project for the user.\n\ndomain_id (Optional)\nbody\nstring\nThe ID of the new domain for the user. The ability to change the domain\r\nof a user is now deprecated, and will be removed in subequent release.\r\nIt is already disabled by default in most Identity service implementations.\n\nenabled (Optional)\nbody\nboolean\nEnables or disables the user.  An enabled user\r\ncan authenticate and receive authorization.  A disabled user\r\ncannot authenticate or receive authorization. Additionally, all\r\ntokens that the user holds become no longer valid. If you re-enable\r\nthis user, pre-existing tokens do not become valid.  To enable the\r\nuser, set to true. To disable the user, set to false.\r\nDefault is true.\n\nname (Optional)\nbody\nstring\nThe new name for the user. Must be unique within the owning domain.\n\npassword (Optional)\nbody\nstring\nThe password for the user.\n\noptions (Optional)\nbody\nobject\nThe resource options for the user. Available resource options are\r\nignore_change_password_upon_first_use, ignore_password_expiry,\r\nignore_lockout_failure_attempts, lock_password,\r\nmulti_factor_auth_enabled, and multi_factor_auth_rulesignore_user_inactivity.\n\nExample# curl -ks -X PATCH -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"user\": {\r\n    \"enabled\": true,\r\n\t\"password\": \"newpasswd\",\r\n\t\"name\": \"user1_renamed\"\r\n\r\n  }\r\n}' https://<node_IP_addr>:5000/v3/users/2973892bee384ca6b8c9886f0c4a8815\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nuser\n\nbody\nobject\nA user object.\n\ndefault_project_id (Optional)\nbody\nstring\n\nThe ID of the default project for the user.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain.\n\nenabled\n\nbody\nboolean\nIf the user is enabled, this value is true.\r\nIf the user is disabled, this value is false.\n\nid\n\nbody\nstring\nThe user ID.\n\nlinks\n\nbody\nobject\nThe links for the user resource.\n\nname\n\nbody\nstring\nThe user name. Must be unique within the owning domain.\n\npassword_expires_at\n\nbody\nstring\n\nThe date and time when the password expires. The time zone\r\nis UTC.\nThis is a response object attribute; not valid for requests.\r\nA null value indicates that the password never expires.\nNew in version 3.7\n\noptions\n\nbody\nobject\nThe resource options for the user. Available resource options are\r\nignore_change_password_upon_first_use, ignore_password_expiry,\r\nignore_lockout_failure_attempts, lock_password,\r\nmulti_factor_auth_enabled, and multi_factor_auth_rulesignore_user_inactivity.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n501 - Not Implemented\n\nThe server either does not recognize the request method, or it lacks the ability to fulfill the request.\n\nExample{\r\n    \"user\": {\r\n        \"name\": \"user1_renamed\",\r\n        \"links\": {\r\n            \"self\": \"https://<node_IP_addr>:5000/v3/users/2973892bee384ca6b8c9886f0c4a8815\"\r\n        },\r\n        \"extra\": {\r\n            \"email\": \"user1@example.com\"\r\n        },\r\n        \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n        \"enabled\": true,\r\n        \"options\": {},\r\n        \"id\": \"2973892bee384ca6b8c9886f0c4a8815\",\r\n        \"email\": \"user1@example.com\",\r\n        \"password_expires_at\": null\r\n    }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-users.html"
    },
    {
        "title": "3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nBefore deploying and configuring the virtual appliance, you need to configure networks in Virtuozzo Hybrid Infrastructure.\nThe network requirements for the agent are:\n\nThe virtual appliance requires at least two network adapters. The actual number may vary depending on the network architecture.\nThe virtual appliance must be connected to Virtuozzo networks with the following network traffic types: Compute API, VM Backup, ABGW Public, VM Public.\n\nFor more information about configuring the networks, see Requirements for the compute cluster and Network requirements and recommendations  sections in the Virtuozzo Hybrid Infrastructure documentation.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-agent-for-virtuozzo-hybrid-infrastructure-from-qcow2-template/configuring-networks-in-virtuozzo-hybrid-infrastructure.html"
    },
    {
        "title": "Running commands in virtual machines without network connectivity",
        "content": "Running commands in virtual machines without network connectivity\nIf a VM cannot access a network for some reason, you can still run commands in it from the node the VM resides on. You will need the VM ID that you can obtain with vinfra service compute server list. You can also use a virsh domain name that you can get by using virsh list.\nPrerequisites\n\nVirtual machines have the guest tools installed, as instructed in Installing guest tools.\n\nTo run commands in a virtual machine without network connectivity\n\nWindows\n\nTo run an arbitrary command inside a Windows VM and receive the output to your console, use the virsh x-exec command. For example:# virsh x-exec bbf4a6ec-865f-4e2c-ac21-8639d1bfb85c --shell dir c:\\\\\r\n Volume in drive C has no label.\r\n Volume Serial Number is D0BE-A8D1\r\n\r\n Directory of c:\\\r\n\r\n06/10/2009  01:42 PM                24 autoexec.bat\r\n06/10/2009  01:42 PM                10 config.sys\r\n07/13/2009  06:37 PM    <DIR>          PerfLogs\r\n11/12/2018  07:45 AM    <DIR>          Program Files\r\n11/12/2018  07:55 AM    <DIR>          test\r\n11/12/2018  06:23 AM    <DIR>          Users\r\n11/12/2018  07:53 AM    <DIR>          Windows\r\n               2 File(s)             34 bytes\r\n               5 Dir(s)  59,329,495,040 bytes free\r\n\n\nTo copy a file to a Windows VM, use the virsh x-exec and prl_cat commands. For example:# virsh x-exec bbf4a6ec-865f-4e2c-ac21-8639d1bfb85c \\\r\n--shell '%programfiles%\\\\qemu-ga\\\\prl_cat' 'c:\\test\\test.file' < /home/test.file\r\n\n\nTo get a file from a Windows VM, use the virsh x-exec and type commands. For example:# virsh x-exec bbf4a6ec-865f-4e2c-ac21-8639d1bfb85c \\\r\n--shell type 'c:\\test\\test.file' > test.file\r\n\n\nLinux\n\nTo run an arbitrary command inside a Linux VM and receive the output to your console, use the virsh x-exec command. For example:# virsh x-exec 1d45a54b-0e20-4d5e-8f11-12c8b4f300db /usr/bin/bash -c 'lsblk'\r\nNAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\r\nloop0         7:0    0 945.9M  1 loop\r\nloop1         7:1    0     5G  1 loop\r\n\u00e2\u0094\u009c\u00e2\u0094\u0080live-rw   253:0    0     5G  0 dm   /\r\n\u00e2\u0094\u0094\u00e2\u0094\u0080live-base 253:1    0     5G  1 dm\r\nloop2         7:2    0    32G  0 loop\r\n\u00e2\u0094\u0094\u00e2\u0094\u0080live-rw   253:0    0     5G  0 dm   /\r\nsda           8:0    0    64G  0 disk\r\nsdc           8:32   0     1G  1 disk\r\nsr0          11:0    1     2G  0 rom  /run/initramfs/live\r\n\n\nTo copy a file to a Linux VM, use the virsh x-exec and cat commands. For example:# virsh x-exec 1d45a54b-0e20-4d5e-8f11-12c8b4f300db \\\r\n--shell 'cat > test.file' < /home/test.file\r\n\n\nTo get a file from a Linux VM, use the virsh x-exec and cat commands as well. For example:# virsh x-exec 1d45a54b-0e20-4d5e-8f11-12c8b4f300db \\\r\n--shell 'cat /home/test.file' > test.file\r\n\n\nSee also\n\nTroubleshooting virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/running-commands-in-vms-without-connectivity.html"
    },
    {
        "title": "Managing exclusive traffic types",
        "content": "Managing exclusive traffic types\nExclusive traffic types can only be reassigned from one network to another and only one at a time. Reassignment can be performed even if the related services are already deployed. This can be useful, for example, if the initial network configuration is wrong but the storage cluster is already populated with data and running critical services; or after adding a network card, which requires changing network settings, adding a new network, and assigning traffic types to it.\nLimitations\n\nExclusive traffic types cannot be edited or deleted.\nYou cannot manage access rules for exclusive traffic types.\nIf the management node high availability is enabled, you cannot reassign the Internal management and Compute API traffic types.\n\nPrerequisites\n\nAll of the connected node interfaces are online.\nEach network interface has only one IP address.\nThe number of interfaces on nodes connected to the source and target networks must be the same. Unassigned nodes are also taken into account.\nThe deployed related services are in the healthy state.\nIf you have restricted outbound traffic in your cluster, you need to manually add a rule that will allow outbound traffic on TCP and UDP ports 60000\u00e2\u0080\u009360100, as described in Configuring outbound firewall rules.\n\nTo reassign an exclusive traffic type\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Assign to network next to the Exclusive traffic types section, and then select the traffic type you want to reassign.\nReassign the traffic type to another network by selecting the corresponding radio button, and then click Save.\n\nIn the Reassign traffic type window, review the source and target networks, and important information about potential risks, and then click Continue to start the traffic type reassignment.\n\nIf the related services are already deployed, wait until the connected interfaces are tested and the new configuration is created. Then, click Apply.\n\nWhile traffic type reassignment is in progress, users cannot perform other tasks in the admin panel. Moreover, the self-service users may not have access to the portal and will need to wait until the reassignment is complete.\n\nIf the connectivity checks fail, you can revert to your old network configuration by clicking Revert. Then, you need to fix the found issues and try again.\nWait until the reassignment is complete on all the connected interfaces, and then click Done.\nIf you reassign the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\nCommand-line interface\n\nStart the traffic type reassignment by using the following command:vinfra cluster traffic-type assignment start --traffic-type <traffic-type>\r\n                                             --target-network <target-network>\r\n\n\n--traffic-type <traffic-type>\n\nTraffic type name\n--target-network <target-network>\n\nTarget network ID or name\n\nFor example:# vinfra cluster traffic-type assignment start --traffic-type Storage --target-network Public\r\n+---------------+---------------------------------------------------------------+\r\n| Field         | Value                                                         |\r\n+---------------+---------------------------------------------------------------+\r\n| configuration | target_network: 69ad1db5-512f-4994-ab08-7d643fdb7b39          |\r\n|               | traffic_type: Storage                                         |\r\n| link          | href: /api/v2/network/traffic-type-assignment/285be91b-<...>/ |\r\n|               | method: GET                                                   |\r\n|               | rel: traffic-type-assignment-details                          |\r\n| operation     | traffic-type-assignment                                       |\r\n| progress      | 0.0                                                           |\r\n| state         | preparing                                                     |\r\n| task_id       | 285be91b-77ee-4f8f-a118-8410ab792148                          |\r\n| transitions   | 0                                                             |\r\n+---------------+---------------------------------------------------------------+\r\n\n\nView the traffic type reassignment details. For example:# vinfra cluster traffic-type assignment show\r\n+-------------+---------------------------------------------------------------+\r\n| Field       | Value                                                         |\r\n+-------------+---------------------------------------------------------------+\r\n| link        | href: /api/v2/network/traffic-type-assignment/285be91b-<...>/ |\r\n|             | method: GET                                                   |\r\n|             | rel: traffic-type-assignment-details                          |\r\n| operation   | traffic-type-assignment                                       |\r\n| progress    | 1.0                                                           |\r\n| state       | test-passed                                                   |\r\n| task_id     | 285be91b-77ee-4f8f-a118-8410ab792148                          |\r\n| transitions | 3                                                             |\r\n+-------------+---------------------------------------------------------------+\nThe output shows that the new network configuration has been tested and can be applied.\n\nContinue the traffic type reassignment and apply the new network configuration. For example:# vinfra cluster traffic-type assignment apply\n\nIf you reassign the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\nIf the connectivity checks fail, you need to fix the found issues and try again by running:# vinfra cluster traffic-type assignment retry\nAlternatively, you can revert to your old network configuration with vinfra cluster traffic-type assignment revert, fix the issue, and try again.\n\nTo troubleshoot a failed reassignment\n\nConnect to your cluster via SSH.\nInvestigate /var/log/vstorage-ui-backend/celery.log to find the root cause.\nFix the issue.\nGo back to the wizard screen and click Retry.\n\nSee also\n\nManaging regular traffic types\n\nManaging custom traffic types\n\nChanging network configuration\n\nManaging networks",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nStart the traffic type reassignment by using the following command:vinfra cluster traffic-type assignment start --traffic-type <traffic-type>\r\n                                             --target-network <target-network>\r\n\n\n--traffic-type <traffic-type>\n\nTraffic type name\n--target-network <target-network>\n\nTarget network ID or name\n\nFor example:# vinfra cluster traffic-type assignment start --traffic-type Storage --target-network Public\r\n+---------------+---------------------------------------------------------------+\r\n| Field         | Value                                                         |\r\n+---------------+---------------------------------------------------------------+\r\n| configuration | target_network: 69ad1db5-512f-4994-ab08-7d643fdb7b39          |\r\n|               | traffic_type: Storage                                         |\r\n| link          | href: /api/v2/network/traffic-type-assignment/285be91b-<...>/ |\r\n|               | method: GET                                                   |\r\n|               | rel: traffic-type-assignment-details                          |\r\n| operation     | traffic-type-assignment                                       |\r\n| progress      | 0.0                                                           |\r\n| state         | preparing                                                     |\r\n| task_id       | 285be91b-77ee-4f8f-a118-8410ab792148                          |\r\n| transitions   | 0                                                             |\r\n+---------------+---------------------------------------------------------------+\r\n\n\n\nView the traffic type reassignment details. For example:# vinfra cluster traffic-type assignment show\r\n+-------------+---------------------------------------------------------------+\r\n| Field       | Value                                                         |\r\n+-------------+---------------------------------------------------------------+\r\n| link        | href: /api/v2/network/traffic-type-assignment/285be91b-<...>/ |\r\n|             | method: GET                                                   |\r\n|             | rel: traffic-type-assignment-details                          |\r\n| operation   | traffic-type-assignment                                       |\r\n| progress    | 1.0                                                           |\r\n| state       | test-passed                                                   |\r\n| task_id     | 285be91b-77ee-4f8f-a118-8410ab792148                          |\r\n| transitions | 3                                                             |\r\n+-------------+---------------------------------------------------------------+\nThe output shows that the new network configuration has been tested and can be applied.\n\n\nContinue the traffic type reassignment and apply the new network configuration. For example:# vinfra cluster traffic-type assignment apply\n\n\nIf you reassign the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\n\nIf the connectivity checks fail, you need to fix the found issues and try again by running:# vinfra cluster traffic-type assignment retry\nAlternatively, you can revert to your old network configuration with vinfra cluster traffic-type assignment revert, fix the issue, and try again.\n",
                "title": "To reassign an exclusive traffic type"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Assign to network next to the Exclusive traffic types section, and then select the traffic type you want to reassign.\nReassign the traffic type to another network by selecting the corresponding radio button, and then click Save.\n\nIn the Reassign traffic type window, review the source and target networks, and important information about potential risks, and then click Continue to start the traffic type reassignment.\n\n\n\n\n\n\nIf the related services are already deployed, wait until the connected interfaces are tested and the new configuration is created. Then, click Apply.\n\n\n\n\n\nWhile traffic type reassignment is in progress, users cannot perform other tasks in the admin panel. Moreover, the self-service users may not have access to the portal and will need to wait until the reassignment is complete.\n\n\nIf the connectivity checks fail, you can revert to your old network configuration by clicking Revert. Then, you need to fix the found issues and try again.\nWait until the reassignment is complete on all the connected interfaces, and then click Done.\nIf you reassign the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\n",
                "title": "To reassign an exclusive traffic type"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-exclusive-traffic-types.html"
    },
    {
        "title": "Listing domains",
        "content": "Listing domainsGET /v3/domains\r\n\nList all domains.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=list-domains-detail#list-domains\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nenabled (Optional)\nquery\nstring\nIf set to true, then only domains that are enabled will be returned, if set\r\nto false, only that are disabled will be returned. Any value other than\r\n0, including no value, will be interpreted as true.\n\nname (Optional)\nquery\nstring\nFilters the response by a domain name.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/domains\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ndomains\n\nbody\narray\nA list of domain objects.\n\ndescription\n\nbody\nstring\nThe description of the domain.\n\nenabled\n\nbody\nstring\nIf set to true, domain is enabled. If set to\r\nfalse, domain is disabled.\n\nid\n\nbody\nstring\nThe ID of the domain.\n\nlinks\n\nbody\nobject\nThe links to the domain resource.\n\nname\n\nbody\nstring\nThe name of the domain.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n405 - Method Not Allowed\n\nMethod is not valid for this endpoint.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"domains\": [\r\n    {\r\n      \"description\": \"The default domain\",\r\n      \"links\": {\r\n        \"self\": \"https://<node_IP_addr>:5000/v3/domains/default\"\r\n      },\r\n      \"tags\": [],\r\n      \"enabled\": true,\r\n      \"id\": \"default\",\r\n      \"name\": \"Default\"\r\n    },\r\n    {\r\n      \"description\": \"\",\r\n      \"links\": {\r\n        \"self\": \"https://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\"\r\n      },\r\n      \"tags\": [],\r\n      \"enabled\": true,\r\n      \"id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n      \"name\": \"domain1\"\r\n    },\r\n    {\r\n      \"description\": \"\",\r\n      \"links\": {\r\n        \"self\": \"https://<node_IP_addr>:5000/v3/domains/1254790bf4bf4f8c8a7c28b5dfa83d68\"\r\n      },\r\n      \"tags\": [],\r\n      \"enabled\": true,\r\n      \"id\": \"1254790bf4bf4f8c8a7c28b5dfa83d68\",\r\n      \"name\": \"heat\"\r\n    }\r\n  ],\r\n  \"links\": {\r\n    \"self\": \"https://<node_IP_addr>:5000/v3/domains\",\r\n    \"previous\": null,\r\n    \"next\": null\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-domains.html"
    },
    {
        "title": "Creating volumes",
        "content": "Creating volumes\nWhile it is convenient to create desired volumes while creating a target group, you can also do this at any time afterwards.\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nA target group is created, as described in Creating target groups.\n\nTo create a volume\n\nAdmin panel\n\nOpen Storage services > Block storage > Volumes, and then click Create volume. A wizard will open.\n\nOn Name and size, enter a volume name and specify a size in gigabytes. Note that volumes can be extended later but not shrunk.\n\nOn Storage policy, select a redundancy mode, a storage tier, and a failure domain. To benefit from high availability, select a mode other than No redundancy and failure domain other than Disk.\n\nOn Summary, review the volume details. You can go back to change them if necessary. Click Create.\n\nCommand-line interface\nUse the following command:vinfra service block-storage volume create --size <size> --tier {0,1,2,3} (--replicas <norm> | --encoding <M>+<N>)\r\n                                           --failure-domain {0,1,2,3,4} <name>\n\n--size <size>\n\nVolume size, in bytes\n--tier {0,1,2,3}\n\nStorage tier (default: 0)\n--replicas <norm>\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain (default: 1)\n\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: the number of data blocks\nN: the number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n<name>\n\nVolume name\n\nFor example, to create the volume vol1 with the size of 100 GiB, the 3 replicas redundancy mode on tier 0 and the failure domain host, run:# vinfra service block-storage volume create vol1 --size 107374182400 --tier 0 --replicas 3 --failure-domain 1\nThe created volume will appear in the vinfra service block-storage volume list output:# vinfra service block-storage volume list\r\n+------------------+--------------+------+--------------+-----------+----------+--------+-----+\r\n| id               | serial       | name | size         | used_size | grp_name | grp_id | lun |\r\n+------------------+--------------+------+--------------+-----------+----------+--------+-----+\r\n| 9841d72f-5d68<\u00e2\u0080\u00a6> | cd96cf1031b6 | vol1 | 107374182400 | 1048576   |          |        |     |\r\n+------------------+--------------+------+--------------+-----------+----------+--------+-----+\n\nWhat's next\n\nAttaching volumes to target groups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage volume create --size <size> --tier {0,1,2,3} (--replicas <norm> | --encoding <M>+<N>)\r\n                                           --failure-domain {0,1,2,3,4} <name>\n\n--size <size>\n\nVolume size, in bytes\n--tier {0,1,2,3}\n\nStorage tier (default: 0)\n--replicas <norm>\n\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain (default: 1)\n\n\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: the number of data blocks\nN: the number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n<name>\n\nVolume name\n\nFor example, to create the volume vol1 with the size of 100 GiB, the 3 replicas redundancy mode on tier 0 and the failure domain host, run:# vinfra service block-storage volume create vol1 --size 107374182400 --tier 0 --replicas 3 --failure-domain 1\nThe created volume will appear in the vinfra service block-storage volume list output:# vinfra service block-storage volume list\r\n+------------------+--------------+------+--------------+-----------+----------+--------+-----+\r\n| id               | serial       | name | size         | used_size | grp_name | grp_id | lun |\r\n+------------------+--------------+------+--------------+-----------+----------+--------+-----+\r\n| 9841d72f-5d68<\u00e2\u0080\u00a6> | cd96cf1031b6 | vol1 | 107374182400 | 1048576   |          |        |     |\r\n+------------------+--------------+------+--------------+-----------+----------+--------+-----+\n",
                "title": "To create a volume"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > Volumes, and then click Create volume. A wizard will open.\n\nOn Name and size, enter a volume name and specify a size in gigabytes. Note that volumes can be extended later but not shrunk.\n\n\n\n\n\n\nOn Storage policy, select a redundancy mode, a storage tier, and a failure domain. To benefit from high availability, select a mode other than No redundancy and failure domain other than Disk.\n\n\n\n\n\nOn Summary, review the volume details. You can go back to change them if necessary. Click Create.\n\n",
                "title": "To create a volume"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-volumes.html"
    },
    {
        "title": "Backup storage on the local cluster",
        "content": "Backup storage on the local cluster\n\nGeneral requirements are listed in General requirements.\n\nTo better understand how to calculate the hardware configuration for backup storage with the local cluster destination, consider the following examples with RAM and CPU reservations.\nExample 1. If you have 1 physical node (1 system+metadata disk and 5 storage disks) and want use the 3+2 encoding mode with the disk failure domain, refer to the table below for the calculations. Note that this configuration has redundancy only in case of a disk failure, the node failure will lead to data unavailability and potential data loss.\n\n1 node for backup storage on the local cluster                    \n\nService\nThe only node\n\nSystem\n4.5 GB,\t3.3 cores\n\nStorage services\n\n5 storage disks and 1 metadata on system disk (each takes 0.5 GB and 0.2 cores), that is 3 GB and 1.2 cores in total\n\nBackup Gateway\n1 GB, 0.5 cores\n\nService reservations\n7.5 GB of RAM and\r\n4.6 cores\n\nMinimum hardware configuration\n12 GB of RAM and 6 cores\n\nRecommended hardware configuration\n16 GB1 All extra RAM is used to cache disk reads. of RAM and 6 cores\n\nExample 2. If you have 5 nodes (1 system disk, 1 metadata disk, and 10 storage disks) and want to use them for backup storage, refer to the table below for the calculations. Note that three nodes are used for the management node high availability, and each of them meets the requirements for the management node.\n\n5 nodes for backup storage on the local cluster                   \n\nService\nManagement nodes (nodes 1-3)\nSecondary nodes (nodes 4-5)\n\nSystem\n4.5 GB,\t3.3 cores\n1.5 GB,\t1.1 cores\n\nStorage services\n10 storage disks and 1 metadata disk (each takes 0.5 GB and 0.2 cores), that is 5.5 GB and 2.2 cores in total\n10 storage disks and 1 metadata disk (each takes 0.5 GB and 0.2 cores), that is 5.5 GB and 2.2 cores in total\n\nBackup Gateway\n1 GB, 0.5 cores\n1 GB, 0.5 cores\n\nService reservations\n11 GB of RAM and\r\n6 cores\n8 GB of RAM and\r\n3.8 cores\n\nMinimum hardware configuration\n12 GB of RAM and 6 cores\n8 GB of RAM and 4 cores\n\nRecommended hardware configuration\n242 All extra RAM is used to cache disk reads. GB of RAM and 8 cores\n16 GB3 All extra RAM is used to cache disk reads. of RAM and 6 cores\n\nSee also\n\nAcronis Backup Storage network requirements\n\nProvisioning Acronis Backup Storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup-storage-on-the-local-cluster.html"
    },
    {
        "title": "Managing assets",
        "content": "Managing assets\nProvider actions\nProviders can suspend assets due to administrative purposes or payment issues. Suspending an asset temporarily disables its items. In a suspended state, an asset item does not operate but can be resumed without any data loss. Providers can also create billing requests of assets with the reservation model. A billing request provides information about billing of item associated with the asset for a particular period.\nTo perform any of these actions, go to the asset details page, click Actions and select an action from the Provider Actions list.\nCustomer actions\nCustomers can change resource reservation by changing asset items and cancel subscription by canceling an asset.\nTo change asset items, do the following:\n\nGo to the asset details page, click Actions and select Change.\n\nIn Change Asset - Step 1 Overview, read the information and click Next.\n\nIn Change Asset - Step 2 Asset Items, set new quantity values for the desired items and click Create change request.\n\nIn Change Asset - Step 3 Summary, check the asset and request status and click Close.\n\nIf an asset is no longer needed, a customer can cancel it as follows:\n\nGo to the asset details page, click Actions and select Cancel.\nIn Cancel asset \u00e2\u0080\u0094 Step 1 Overview, read the information and click Create cancel request.\nIn Cancel asset \u00e2\u0080\u0094 Step 2 Summary, check the asset and fulfillment request status and click Close.\n\n Once an asset is canceled, its status becomes Terminated and the asset cannot be processed. A new fulfillment request must be created in order to proceed.\nIn Virtuozzo Hybrid Infrastructure, the asset project is disabled after an asset is canceled.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/managing-assets.html"
    },
    {
        "title": "Resizing volumes",
        "content": "Resizing volumes\nYou can change volume size only by increasing it. Volumes can be extended for both running (online resizing) and stopped (offline resizing) virtual machines. Online volume resizing allows users to avoid downtime and enables scaling VM\u00a0storage capacity on the fly without service interruption.\nLimitations\n\nYou cannot shrink volumes.\nDuring volume resizing, the file system inside the guest OS is not extended.\nIf you revert a volume to a snapshot that was taken before the volume extension, the new volume size will be retained.\n\nPrerequisites\n\nA volume is created, as described in Creating and deleting volumes.\n\nTo extend a volume\n\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\n Click the pencil icon in the Size field. \nEnter the desired volume capacity, and then click the tick icon.\n\n After the volume is extended, you will need to re-partition the disk inside the guest OS to allocate the added disk space.\n\nCommand-line interface\nUse the following command:vinfra service compute volume extend --size <size_gb> <volume>\r\n\n\n<volume>\n\nVolume ID or name\n\nFor example, to extend the volume myvolume to 16 GB, run:# vinfra service compute volume extend myvolume --size 16\n\nSee also\n\nAttaching and detaching volumes\n\nChanging the storage policy for volumes\n\nCloning volumes\n\nManaging volume snapshots",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume extend --size <size_gb> <volume>\r\n\n\n<volume>\n\nVolume ID or name\n\nFor example, to extend the volume myvolume to 16 GB, run:# vinfra service compute volume extend myvolume --size 16\n",
                "title": "To extend a volume"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\n Click the pencil icon in the Size field. \nEnter the desired volume capacity, and then click the tick icon.\n\n After the volume is extended, you will need to re-partition the disk inside the guest OS to allocate the added disk space.\n",
                "title": "To extend a volume"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/resizing-volumes.html"
    },
    {
        "title": "Setting bandwidth per second for buckets via REST API",
        "content": "Setting bandwidth per second for buckets via REST API\nYou can limit outgoing bandwidth of a response with the ostor-limits service and the following parameters: bucket specifying the bucket name, bandwidth specifying the limit type, and out= specifying the limit value:# s3_curl PUT \"http://s3.example.com/?ostor-limits&bucket=client&limit-type=bandwidth&limit-resource=out&limit-value=100\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-bandwidth-per-second-for-buckets-via-rest-api.html"
    },
    {
        "title": "Connecting to virtual machines",
        "content": "Connecting to virtual machines\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\nTo be able to connect via SSH, the virtual machine must have cloud-init and OpenSSH installed. \n\nTo connect to a virtual machine via the VNC console\nSelect a VM, and then click Console on its right pane. The console will open in a separate browser window. In the console, you can send a key combination to a VM, take a screenshot of the console window, and download the console log (refer to Troubleshooting virtual machines).\nTo connect to a virtual machine via SSH\nSpecify the username and VM IP address in the SSH terminal:# ssh <username>@<VM_IP_address>\r\n\nLinux cloud images have the default login, depending on the operating system, for example, centos or ubuntu. To connect to a Windows VM, enter the username that you specified during Cloudbase-Init installation.\nIf you have deployed a VM without specifying an SSH key, you also need to enter a password to log in to the VM.\nSee also\n\nSetting a password inside virtual machines\n\nManaging guest tools\n\nManaging virtual machine power state\n\nReconfiguring virtual machines\n\nMonitoring virtual machines\n\nMigrating virtual machines\n\nWhat's next\n\nManaging guest tools",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/connecting-to-virtual-machines.html"
    },
    {
        "title": "Preparing Windows templates",
        "content": "Preparing Windows templates\nWindows guests have neither Cloudbase-Init nor OpenSSH Server preinstalled by default. You need to install and configure them manually.\nTo install Cloudbase-Init and OpenSSH Server inside a Windows virtual machine\n\nLog in to a Windows VM.\nCreate a new administrator account that will be used for SSH connections and log in with it.\n\nTo install and configure OpenSSH Server:\n\nRun Windows PowerShell with administrator privileges and set the execution policy to unrestricted to be able to run scripts:> Set-ExecutionPolicy Unrestricted\r\n\n\nDownload OpenSSH Server (for example, from the GitHub repository), extract the archive into the C:\\Program Files directory, and then install it by running:> & 'C:\\Program Files\\OpenSSH-Win64\\install-sshd.ps1'\r\n\n\nStart the sshd service and set its startup type to \u00e2\u0080\u009cAutomatic\u00e2\u0080\u009d:> net start sshd> Set-Service sshd -StartupType Automatic\r\n\n\nOpen TCP port 22 for the OpenSSH service in the Windows Firewall:\n\nOn Windows 8.1, Windows Server 2012, and newer versions, run:> New-NetFirewallRule -Protocol TCP -LocalPort 22 -Direction Inbound -Action Allow -DisplayName OpenSSH\r\n\n\nOn Windows Server 2008/2008 R2, run:> netsh advfirewall firewall add rule name=sshd dir=in action=allow protocol=TCP localport=22\r\n\n\nOpen the C:\\ProgramData\\ssh\\sshd_config file:> notepad 'C:\\ProgramData\\ssh\\sshd_config'\r\n\nComment out the following lines at the end of the file:#Match Group administrators#AuthorizedKeysFile __PROGRAMDATA__/ssh/administrators_authorized_keys\r\n\nSave the changes.\n\nCreate the .ssh directory in C:\\Users\\<current_user> and an empty authorized_keys file inside it:> cd C:\\Users\\<current_user>> mkdir .ssh> notepad .\\.ssh\\authorized_keys\r\n\nRemove the .txt extension from the created file:> move .\\.ssh\\authorized_keys.txt .\\.ssh\\authorized_keys\r\n\n\nModify the permissions for the created file to disable inheritance:> icacls .\\.ssh\\authorized_keys /inheritance:r\r\n\n\nDownload Cloudbase-Init from https://cloudbase.it/cloudbase-init/#download, and then install it by following the procedure from the Installation section at https://cloudbase.it/cloudbase-init/.\n\nThe password for the user specified during the Cloudbase-Init installation will be reset on the next VM startup. If this user does not exist, a new user account will be created. You will be able to log in with this account by using the key authentication method or you can set a new password with a customization script. If there are multiple Windows users at the image preparation time, the passwords for other users will not be changed.\nWhen the Cloudbase-Init installation is complete, do not select the option to run Sysprep before clicking Finish. Otherwise, you will not be able to modify cloudbase-init.conf.\n\nRun Windows PowerShell with administrator privileges and open the file C:\\Program Files\\Cloudbase Solutions\\Cloudbase-Init\\conf\\cloudbase-init.conf:> notepad 'C:\\Program Files\\Cloudbase Solutions\\Cloudbase-Init\\conf\\cloudbase-init.conf'\r\n\nAdd metadata_services and plugins on two lines:metadata_services=\\cloudbaseinit.metadata.services.configdrive.ConfigDriveService,\\cloudbaseinit.metadata.services.httpservice.HttpServiceplugins=cloudbaseinit.plugins.common.mtu.MTUPlugin,\\cloudbaseinit.plugins.windows.ntpclient.NTPClientPlugin,\\cloudbaseinit.plugins.common.sethostname.SetHostNamePlugin,\\cloudbaseinit.plugins.windows.createuser.CreateUserPlugin,\\cloudbaseinit.plugins.common.networkconfig.NetworkConfigPlugin,\\cloudbaseinit.plugins.windows.licensing.WindowsLicensingPlugin,\\cloudbaseinit.plugins.common.sshpublickeys.SetUserSSHPublicKeysPlugin,\\cloudbaseinit.plugins.windows.extendvolumes.ExtendVolumesPlugin,\\cloudbaseinit.plugins.common.setuserpassword.SetUserPasswordPlugin,\\cloudbaseinit.plugins.common.userdata.UserDataPlugin,\\cloudbaseinit.plugins.windows.winrmlistener.ConfigWinRMListenerPlugin,\\cloudbaseinit.plugins.windows.winrmcertificateauth.\\ConfigWinRMCertificateAuthPlugin,\\cloudbaseinit.plugins.common.localscripts.LocalScriptsPlugin\r\n\n\nMake sure to remove all backslashes in the lines above.\n\nSave the changes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/preparing-windows-templates.html"
    },
    {
        "title": "Troubleshooting virtual machines",
        "content": "Troubleshooting virtual machines\nIf a virtual machine fails to deploy\nReview the error message on the VM right pane. One of the possible root causes is that compute nodes lack free RAM or CPU resources to host the VM.\nIf a virtual machine is in the error state\n\nExamine the VM history in the History tab on the VM right pane. The event log will contain all of the VM management operations performed by users in the user or command-line interface. You can expand each log entry to view operation details by clicking the arrow icon next to it. The details include the operation name, date and time, status, initiator, and request ID.\n\nIf a virtual machine is stuck in a failed or transitional state\n\n Reset the VM to its last stable state: active, shut down or shelved:\n\n Click the stuck VM.\nOn the VM right pane, click Reset state.\n\nIf a virtual machine fails to boot\n\nExamine the VM console log by clicking Download console log on the VM right pane. The log will contain log messages only if logging is enabled inside the VM (refer to Enabling logging for virtual machines).",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/troubleshooting-virtual-machines.html"
    },
    {
        "title": "Querying S3 user information via CLI",
        "content": "Querying S3 user information via CLI\nTo display information about the specified user, use the ostor-s3-admin query-user-info command. You need to specify either the user email (-e) or S3 ID (-i). For example:# ostor-s3-admin query-user-info -e user@email.com -V 0100000000000002\r\nQuery user: user id=d866d9d114cc3d20, user email=user@email.com\r\nKey pair[0]: access key id=d866d9d114cc3d20G456,\r\nsecret access key=5EAne6PLL1jxprouRqq8hmfONMfgrJcOwbowCoTt\r\nKey pair[1]: access key id=d866d9d114cc3d20D8EW,\r\nsecret access key=83tTsNAuuRyoBBqhxMFqHAC60dhKHtTCCkQe54zu\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-s3-user-information-via-cli.html"
    },
    {
        "title": "Managing domain groups",
        "content": "Managing domain groups\nA domain group is a group of users with the same role permissions within a particular domain. Users assigned to a domain group inherit role permissions set to this domain group. Using domain groups allows you to configure permissions of multiple users without the need to do it individually. \nYou can create, edit, and delete the existing domain groups. Also, you can manage user and project assignment to domain groups.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-domain-groups.html"
    },
    {
        "title": "Installing in the attended mode",
        "content": "Installing in the attended mode\nLimitations\n\nShingled magnetic recording (SMR) HDDs cannot be used for system and are not displayed in the installer.\n\nPrerequisites\n\nA bootable USB drive, an IPMI virtual drive, or a PXE server is prepared, as described in Preparing the bootable media.\n\nThe time needs to be synchronized via NTP on all nodes in the same cluster. Make sure that the nodes can access the NTP server.\n\nIf you want to change the default MTU, it must be configured on the network hardware.\n\nTo install in the attended mode\n\nConfigure the server to boot from the chosen media.\nBoot the server and wait for the Welcome screen.\nOn the Welcome screen, select Install Virtuozzo Hybrid Infrastructure.\nOn Step 1, carefully read and accept the End-User License Agreement.\n\nOn Step 2, configure the network:\n\nSpecify a unique host name: either a fully qualified domain name (<hostname>.<domainname>) or a short name (<hostname>).\n\nThe only way to change the host name later is by contacting the technical support.\n\nConfigure your network cards. Usually the network is configured automatically (via DHCP). If manual configuration is required, select a network card, click Configure\u00e2\u0080\u00a6, and specify the necessary parameters.\n\nSet MTU on each network card. By default, MTU is set to 1500, while 9000 is recommended.\n\nThe MTU value must be the same across the entire network.\n\nIf you are integrating Virtuozzo Hybrid Infrastructure into an existing network, adjust the MTU value to that of the network. \nIf you are deploying Virtuozzo Hybrid Infrastructure from scratch alongside a new network, set the MTU value to the recommended 9000.\n\nAccording to network recommendations, you may want to create bonded and virtual local area network (VLAN) interfaces for network security and better performance:\n\nCreate bonded connections\n\nBonded connections increase throughput beyond the capabilities of a single network card, as well as improve redundancy.\n\nClick the plus button at the bottom of the screen, select Bond, and then click Add.\n\nIn the Editing Bond connection<N> window, set the following parameters for an Ethernet bonding interface:\n\nMode to one required by your network\nLink Monitoring to MII (recommended)\nMonitoring frequency, Link up delay, and Link down delay to 300\n\nIt is also recommended to manually set xmit_hash_policy to layer3+4 after the installation.\n\nIn the Bonded connections section on the Bond tab, click Add.\n\nIn the Editing bond<N> slave<N> window, select a network interface to bond in Device.\n\nConfigure MTU, if required, and then click Save.\nRepeat steps 3 to 5 for each network interface you need to add to the bonded connection.\nConfigure IPv4 settings, if required, and then click Save.\n\nCreate VLAN interfaces\n\nClick the plus button at the bottom of the screen, select VLAN, and then click Add.\n\nIn the Editing VLAN connection<N> window:\n\nFrom the Parent interface drop-down list, select a physical adapter or bonded connection that the VLAN adapter will be based on.\nSpecify a VLAN adapter identifier in the VLAN ID field. The value must be between 1 and 4094.\n\nConfigure MTU and  IPv4 settings, if required, and then click Save.\n\nOn Step 3, ensure that the Network Time toggle switch is turned on, and then select your time zone. The date and time will be set via NTP. You will need an Internet connection for synchronization to complete.\n\nWe only support the UTC time zone. Changing the time zone for nodes is not supported and may lead to system unavailability.\n\nOn Step 4, specify what type of node you are installing:\n\nIf you are installing on the primary node\n\nThe primary node, also called the management node, is the first node in the infrastructure. This node will host cluster management services and the admin panel. It will also serve as a storage node. Only one primary node is required.\n\nSelect Yes, create a new cluster. \nIn Internal management network, select a network interface for internal management and configuration purposes.\r\n                    \nIn Admin panel network, select a network interface that will provide access to the admin panel.\nCreate and confirm a password for the superadmin account of the admin panel.\n\nIf you are installing on a secondary node\n\nA secondary node is a node added to an already existing infrastructure. Such nodes will run services related to data storage and will be added to the infrastructure during installation.\n\nSelect No, add it to an existing cluster.\n\nObtain the token and management node address in the admin panel:\n\nLog in to the admin panel on port 8888. The panel\u00e2\u0080\u0099s IP address is shown in the console after deploying the primary node. Use the default user name shown on the login screen and the primary node\u00e2\u0080\u0099s root password.\nIf prompted, add the security certificate to the browser\u00e2\u0080\u0099s exceptions.\n\nIn the admin panel, open Infrastructure > Nodes, and then click Connect node to invoke a screen with the management node address and the token.\n\nA single token can be used to deploy multiple secondary nodes in parallel. You can generate a new token, if needed. Generating a new token invalidates the old one.\n\nOn the installation screen, select the private IP address of the management node and enter the token.\n\nIf you want to register the node in the admin panel manually after the installation, select Skip cluster configuration.\n\nOn Step 5, select a disk for the operating system:\n\nAll information on all disks recognized by the installer will be destroyed.\n\nTo partition your system disk automatically\n\nIn the Device Selection section, select a disk.\nIn the Storage Configuration section, select Automatic.\n\nThis disk will have the supplementary role System, although you will still be able to set it up for data storage in the admin panel.\n\nTo partition your system disk manually\n\nIn the Device Selection section, select a disk.\nIn the Storage Configuration section, select Custom.\nOn the Manual Partitioning screen, create and configure the required mount points for your system disk.\nOn the summary screen, review your changes and accept them.\n\nThis disk will have the supplementary role System, although you will still be able to set it up for data storage in the admin panel.\n\nTo create a software RAID mirror for  your system disk\n\nIn the Device Selection section, select at least two disks.\nIn the Storage Configuration section, select Automatic, and then select Combine disks in a software RAID mirror.\n\nIt is recommended to create a RAID mirror from disks of the same size, as the volume equals the size of the smallest disk.\n\nOn Step 6,  enter and confirm the password for the root account, and then click Start installation.\n\nOnce the installation is complete, the node will reboot automatically. The admin panel IP address will be shown in the welcome prompt.\n\r\n            What's next\n\nAfter deploying the primary node, proceed to deploy the required amount of secondary nodes.\nWhen all the required nodes are displayed in the admin panel on the Infrastructure > Nodes screen as Unassigned, proceed to create the storage cluster, as outlined in Deployment and configuration.\n\nIf you skipped cluster configuration on step 4 and want to add the unassigned node manually:\n\nConfigure the primary node\n\nOn the node, run the following command as the root user to configure the admin panel component:echo <password> | /usr/libexec/vstorage-ui-backend/bin/configure-backend.sh -i <private_iface> -x <public_iface>\r\n\nwhere\n\n<password> is the password of the superadmin account for the admin panel\n<private_iface> is the name of the private network interface (the one you would select for the management network during attended installation)\n<public_iface> is the name of the public network interface (the one you would select for the admin panel network during attended installation)\n\nStart the admin panel service on the node:# systemctl start vstorage-ui-backend\r\n\n\nRegister the node in the admin panel:# /usr/libexec/vstorage-ui-agent/bin/register-storage-node.sh -m <MN_IP_address> -x <public_iface>\r\n\nwhere \n\n<MN_IP_address> is the IP address of the node's private network interface\n<public_iface> is the name of the public network interface\n\nNow you can proceed to deploying secondary nodes.\n\nConfigure a secondary node\n\nRun the following script on the node,  to register it in the admin panel:# /usr/libexec/vstorage-ui-agent/bin/register-storage-node.sh -m <MN_IP_address> -t <token>\r\n\nwhere\n\n<MN_IP_address> is the IP address of the private network interface on the node with the admin panel\n<token> is the token obtained in the admin panel or from the vinfra node token show output",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/installing-in-the-attended-mode.html"
    },
    {
        "title": "Editing network interfaces",
        "content": "Editing network interfaces\nLimitations\n\nA network can only be assigned to one network interface per node.\nA network interface must have at least one IPv4 address.\nYou can only assign an IPv6 address manually. Obtaining an IPv6 address via DHCP is not supported.\n\nPrerequisites\n\nIf you want to change the default MTU, it must be configured on the network hardware.\n\nTo edit a network interface\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface.\nOn the interface right pane, click Edit.\n\nIn the Edit network interface window, select a network to assign the interface to, and then specify the network parameters:\n\nSelect Automatically (DHCP) to obtain the IP address, DNS, and routing settings from the DHCP server.\nSelect Automatically (DHCP address only) to obtain only the IP address from the DHCP server.\nSelect Manually, and then specify the IPv4 address and optionally the IPv6 address in CIDR notation by clicking Add.\n\nDynamic IP address allocation will cause network issues as soon as the IP addresses of cluster nodes change. Configure static IP addresses from the start or as soon as possible.\n\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\n\nIf you have set a custom maximum transmission unit (MTU) on the network hardware, enter the same value in the MTU field.\n\nSetting a custom MTU in the admin panel prior to configuring it on the network hardware will result in network failure on the node and require manual resetting. Setting an MTU that differs from the one configured on the network hardware may result in a network outage or poor performance.\n\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra node iface set [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                      [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                      [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                      [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                      [--network <network> | --no-network] [--ifaces <ifaces>]\r\n                      [--bond-type <bond-type>] [--node <node>] <iface>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--no-network\n\nRemove a network from the interface\n--ifaces <ifaces>\n\nA comma-separated list of network interface names, for example, iface1,iface2,...,ifaceN\n--bond-type <bond-type>\n\nBond type (balance-rr, balance-xor, broadcast, 802.3ad, balance-tlb, balance-alb)\nBond type for an OVS interface (balance-tcp, active-backup)\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nExample 1. To assign the network MyNet to the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --network MyNet --node node002\nExample 2. To unassign a network from the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --node node002 --no-network\nExample 3. To enable IP address allocation via DCHP for the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --node node002 --dhcp4\nExample 4. To disable DHCP and set the IP address 192.168.30.20/24 for the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --node node002 --no-dhcp4 --ipv4 192.168.30.20/24\r\n\nExample 5. To change the bond type of the network bond bond0 located on the node node002 to balance-xor, run:# vinfra node iface set bond0 --node node002 --bond-type balance-xor\nThe updated interface will be listed in the vinfra node iface list output:# vinfra node iface list --node node002\r\n+------+----------------+--------------------+-------+---------+\r\n| name | node_id        | ipv4               | state | network |\r\n+------+----------------+--------------------+-------+---------+\r\n| eth0 | 4f96acf5-<...> | - 10.94.29.218/16  | up    | Public  |\r\n| eth1 | 4f96acf5-<...> | - 10.37.130.101/24 | up    | Private |\r\n| eth2 | 4f96acf5-<...> | - 192.168.30.20/24 | up    | MyNet   |\r\n+------+----------------+--------------------+-------+---------+\r\n\n\nSee also\n\nChanging network interface parameters\n\nManaging network interfaces\n\nWhat's next\n\nAdding external DNS servers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface set [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                      [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                      [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                      [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                      [--network <network> | --no-network] [--ifaces <ifaces>]\r\n                      [--bond-type <bond-type>] [--node <node>] <iface>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--no-network\n\nRemove a network from the interface\n--ifaces <ifaces>\n\nA comma-separated list of network interface names, for example, iface1,iface2,...,ifaceN\n--bond-type <bond-type>\n\n\nBond type (balance-rr, balance-xor, broadcast, 802.3ad, balance-tlb, balance-alb)\nBond type for an OVS interface (balance-tcp, active-backup)\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nExample 1. To assign the network MyNet to the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --network MyNet --node node002\nExample 2. To unassign a network from the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --node node002 --no-network\nExample 3. To enable IP address allocation via DCHP for the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --node node002 --dhcp4\nExample 4. To disable DHCP and set the IP address 192.168.30.20/24 for the network interface eth2 located on the node node002, run:# vinfra node iface set eth2 --node node002 --no-dhcp4 --ipv4 192.168.30.20/24\r\n\nExample 5. To change the bond type of the network bond bond0 located on the node node002 to balance-xor, run:# vinfra node iface set bond0 --node node002 --bond-type balance-xor\nThe updated interface will be listed in the vinfra node iface list output:# vinfra node iface list --node node002\r\n+------+----------------+--------------------+-------+---------+\r\n| name | node_id        | ipv4               | state | network |\r\n+------+----------------+--------------------+-------+---------+\r\n| eth0 | 4f96acf5-<...> | - 10.94.29.218/16  | up    | Public  |\r\n| eth1 | 4f96acf5-<...> | - 10.37.130.101/24 | up    | Private |\r\n| eth2 | 4f96acf5-<...> | - 192.168.30.20/24 | up    | MyNet   |\r\n+------+----------------+--------------------+-------+---------+\r\n\n",
                "title": "To edit a network interface"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface.\nOn the interface right pane, click Edit.\n\nIn the Edit network interface window, select a network to assign the interface to, and then specify the network parameters:\n\nSelect Automatically (DHCP) to obtain the IP address, DNS, and routing settings from the DHCP server.\nSelect Automatically (DHCP address only) to obtain only the IP address from the DHCP server.\nSelect Manually, and then specify the IPv4 address and optionally the IPv6 address in CIDR notation by clicking Add.\n\n\nDynamic IP address allocation will cause network issues as soon as the IP addresses of cluster nodes change. Configure static IP addresses from the start or as soon as possible.\n\n\n\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\n\n\nIf you have set a custom maximum transmission unit (MTU) on the network hardware, enter the same value in the MTU field.\n\nSetting a custom MTU in the admin panel prior to configuring it on the network hardware will result in network failure on the node and require manual resetting. Setting an MTU that differs from the one configured on the network hardware may result in a network outage or poor performance.\n\n\nClick Save to apply your changes.\n\n\n\n\n\n",
                "title": "To edit a network interface"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/editing-network-interfaces.html"
    },
    {
        "title": "Integrations",
        "content": "IntegrationsHystax Acura IntegrationLeostream IntegrationBitNinja IntegrationCloudBlue Connect IntegrationStorware IntegrationStorage for Vertica in Eon Mode",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/integrations/"
    },
    {
        "title": "Compute cluster architecture",
        "content": "Compute cluster architecture\nThe following diagram shows the major compute components of Virtuozzo Hybrid Infrastructure.\n\nThe identity service provides authentication and authorization capabilities for Virtuozzo Hybrid Infrastructure.\nThe compute service enables users to create, run, and manage virtual machines. This service relies on the custom QEMU/KVM hypervisor.\nThe networking service provides physical and virtual network capabilities for virtual machines.\nThe image service enables users to upload, store, and use images of supported guest operating systems and virtual disks. This service relies on the base storage cluster for data redundancy.\nThe storage service provides virtual disks to virtual machines. This service relies on the base storage cluster for data redundancy.\nThe Kubernetes service allows users to deploy Kubernetes clusters in virtual machines.\nThe load balancer service distributes incoming network traffic across virtual machines from a balancing pool.\nThe backup service allows you to back up compute volumes, and then restore virtual machines and volumes from them.\n\nSee also\n\nCompute network architecture",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/compute-cluster-architecture.html"
    },
    {
        "title": "Adding volumes to backup plans",
        "content": "Adding volumes to backup plansPOST /v3/{project_id}/os-volume-backup-plan/associate\nAdd volumes to a backup plan.\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nbackup_plan_id\n\nbody\nstring\nThe backup plan UUID.\n\nbackup_plan_hash\n\nbody\nstring\nThe backup plan hash. It can be obtained from the details of a backup plan (refer to Showing backup plan details).\n\nvolume_ids\n\nbody\narray\nA list of volumes.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"backup_plan_id\": \"4f40774a4da945cda806d59ca7c74355\",\r\n    \"backup_plan_hash\": \"69932aac5f2e4468fe668e5166265485aa3f7cdf\",\r\n    \"volume_ids\": [\r\n        \"a0494a55-fdc0-4233-8c80-a3022ab8f4af\", \r\n        \"98db149d-b9e6-42d7-814d-492563c56fef\"\r\n    ]\r\n}' https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/os-volume-backup-plan/associate\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/adding-volumes-to-backup-plans.html"
    },
    {
        "title": "Viewing outgoing traffic usage",
        "content": "Viewing outgoing traffic usage\nThe bandwidth metric that can show outgoing traffic usage is not available by default. To be able to use it, you need to configure it first. A meter must be created for each new project. The meter only accounts traffic that goes through a virtual router. You cannot measure traffic going to or from ports directly attached to virtual machines.\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo measure outgoing traffic for a project\n\nCreate a meter for a project. For example, to create the meter outgoing_traffic_project1 in the project project1 within the domain domain1, run: # openstack --insecure network meter create outgoing_traffic_project1 --project project1 --project-domain domain1\n\nCreate a rule for the meter to account all traffic leaving the project router. For example:# openstack --insecure network meter rule create outgoing_traffic_project1 --egress --include \\\r\n--remote-ip-prefix 0.0.0.0/0 --project project1 --project-domain domain1\nThe new meter with the type bandwidth will be created and associated with the project project1 in the domain domain1.\n\n List all of the bandwidth metrics. For example:# gnocchi --insecure metric list | grep bandwidth\r\n+--------------------------------------+---------------------+-----------+------+--------------------------------------+\r\n| id                                   | archive_policy/name | name      | unit | resource_id                          |\r\n+--------------------------------------+---------------------+-----------+------+--------------------------------------+\r\n| a7982897-42c3-4586-bb4a-8c1b8d11fcc6 | low                 | bandwidth | B    | 883fb5e5-be97-4fbf-b1bd-8f33e552f214 |\r\n| ac2bf21d-f2b0-4043-9fb1-59e1930e497c | low                 | bandwidth | B    | 7147aba5-829e-49b7-a520-01b300178f6c |\r\n+--------------------------------------+---------------------+-----------+------+--------------------------------------+\nIn this output, resource_id is the meter ID, so you can use it to identify meters.# openstack --insecure network meter list\r\n+--------------------------------------+---------------------------+-------------+--------+\r\n| ID                                   | Name                      | Description | Shared |\r\n+--------------------------------------+---------------------------+-------------+--------+\r\n| 883fb5e5-be97-4fbf-b1bd-8f33e552f214 | outgoing_traffic_project1 |             |        |\r\n| 7147aba5-829e-49b7-a520-01b300178f6c | outgoing_traffic_project2 |             |        |\r\n+--------------------------------------+---------------------------+-------------+--------+\r\n\n\n View the measures by using the metric id. For example:# gnocchi --insecure measures show a7982897-42c3-4586-bb4a-8c1b8d11fcc6 --aggregation sum\r\n+---------------------------+-------------+---------+\r\n| timestamp                 | granularity |   value |\r\n+---------------------------+-------------+---------+\r\n| 2021-10-03T02:40:00+03:00 |       300.0 |  1045.0 |\r\n| 2021-10-03T02:50:00+03:00 |       300.0 |  1907.0 |\r\n| 2021-10-03T02:55:00+03:00 |       300.0 | 15932.0 |\r\n+---------------------------+-------------+---------+\n\nTo exclude outgoing traffic for a network\nCreate a rule for the meter to exclude outgoing traffic for a particular network. For example, for the network with the CIDR 10.0.0.0/24, run:# openstack --insecure network meter rule create outgoing_traffic --egress --exclude \\\r\n--remote-ip-prefix 10.0.0.0/24 --project project1 --project-domain domain1\nSee also\n\nViewing resources, metrics, and measures\n\nChanging retention period for metrics\n\nViewing resource usage per project",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-outgoing-traffic-usage.html"
    },
    {
        "title": "Aggregating provisioned storage space",
        "content": "Aggregating provisioned storage spacePOST /v1/aggregates?details=False&needed_overlap=0.0&start={start_date}&stop={stop_date}\r\n\nAggregate the total amount of provisioned storage space per project or the amount of storage space per storage policy for a specific period of time.\n\nIf the start or stop date is not specified, the missing value will be set to the first or last timestamp common across the time series.\n\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\noperation\n\nbody\nstring\nOperations to apply to the time series. For aggregation across metrics, use the following syntax: aggregate <aggregation_method> ((metric <metric_id> <aggregation_method>), ...). Supported aggregation methods are: mean, median, std, min, max, sum, var, count.\n\nsearch\n\nbody\nstring\nA query to filter resources. The syntax includes an attribute, operator, and value. For example, the query id=90d58eea-70d7-4294-a49a-170dcdf44c3c will filter a resource with the specified ID. You can use more complex queries, for example, not (flavor_id!=\u00e2\u0080\u009d1\u00e2\u0080\u009d and memory>=24). Use \u00e2\u0080\u009c\u00e2\u0080\u009d to interpret data as a string. Supported operators are: not, and, \u00e2\u0088\u00a7 or, \u00e2\u0088\u00a8, >=, <=, !=, >, <, =, ==, eq, ne, lt, gt, ge, le, in, like, \u00e2\u0089\u00a0, \u00e2\u0089\u00a5, \u00e2\u0089\u00a4, like, in.\n\nresource_type\n\nbody\nstring\n\nA resource type that a metric is associated with. For example, these metrics are bound to:\n\nvCPU and RAM metrics\u00e2\u0080\u0094the instance resource type\nStorage metrics\u00e2\u0080\u0094the volume resource type\nFloating IP addresses\u00e2\u0080\u0094the network resource type\nLoad balancers\u00e2\u0080\u0094the loadbalancer resource type\nKubernetes clusters\u00e2\u0080\u0094the coe_cluster resource type\n\nExample 1\nAggregate the total amount of provisioned storage space for the project with the ID 75521ab61d1f4e9090aac5836c219492 from 12:00 PM July 18, 2021, to 13:00 PM July 19, 2021.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"operations\":\"(aggregate sum (metric volume.size mean))\",\r\n    \"search\":\"project_id=75521ab61d1f4e9090aac5836c219492\",\r\n    \"resource_type\":\"volume\"\r\n}' https://<node_IP_addr>:8041/v1/aggregates?details=False&needed_overlap=0.0&\\\r\nstart=2021-07-18T12:00:00&stop=2021-07-19T12:00:00\r\n\nExample 2\nAggregate the amount of provisioned storage space with the storage policy with the ID 10056d2e-6fc9-4f2e-92c2-dbebb1714778 from 12:00 PM July 18, 2021, to 13:00 PM July 19, 2021.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"operations\":\"(aggregate sum (metric volume.size.10056d2e-6fc9-4f2e-92c2-dbebb1714778 mean))\",\r\n    \"search\":\"project_id=75521ab61d1f4e9090aac5836c219492\",\r\n    \"resource_type\":\"volume\"\r\n}' https://<node_IP_addr>:8041/v1/aggregates?details=False&needed_overlap=0.0&\\\r\nstart=2021-07-18T12:00:00&stop=2021-07-19T12:00:00\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nmeasures\n\nbody\nstring\nA list of measures for a metric.\n\naggregated\n\nbody\narray\nA number of aggregates, each consisting of a timestamp, granularity, and value.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"measures\": {\r\n    \"aggregated\": [\r\n      [\r\n        \"2021-07-18T12:00:00+00:00\",\r\n        300.0,\r\n        80.0\r\n      ],\r\n      <...>\r\n      [\r\n        \"2021-07-19T11:55:00+00:00\",\r\n        300.0,\r\n        80.0\r\n      ] \r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/aggregating-provisioned-storage-space.html"
    },
    {
        "title": "Using metering for compute resources",
        "content": "Using metering for compute resources\nYou can collect usage data of compute resources using Gnocchi. This time series database processes and stores measurement data of compute resources and provides access to it via REST API or the command-line tool.\nMeasurements can be sampled from such compute resources as virtual machines, VM disks and interfaces, compute networks, volumes, etc. All resources are being revised: if any attribute of a resource changes, this change is recorded in the history of the resource. For a VM, for example, you can measure the amount of allocated memory and virtual CPUs, as well as the memory and CPU usage.\nAn entity storing aggregates composed of a timestamp and value is called a metric. A metric is attached to a specific resource and associated to an archive policy. A policy defines how long aggregates are kept in a metric and how they are computed (minimum, maximum, average, etc.).\nTwo default archive policies, low and ceilometer-low-rate, are used for storing metrics. These policies imply that all computed aggregates are kept for one month with 5-minute granularity. The differences between them are the following:\n\nceilometer-low-rate is used for cumulative metrics and stores only mean values and the average of delta values per interval\nlow is used for gauge metrics and stores minimum, maximum, and mean values, standard deviation, as well as the sum and number of all measurements\n\nThe following metrics are available for aggregation:\n\nMetric\nType\nResource type\nDescription\n\nmemory\n\ngauge\ninstance\nAmount of RAM allocated to the VM, in megabytes\n\nmemory.usage\n\ngauge\ninstance\nPercentage of RAM used by the VM\n\nvcpus\n\ngauge\ninstance\nNumber of virtual CPUs allocated to the VM\n\ncpu\n\ncumulative\ninstance\nAmount of CPU time used by the VM, in nanoseconds\n\ndisk.device.read.requests\n\ncumulative\ninstance_disk\nNumber of read requests\n\ndisk.device.write.requests\n\ncumulative\ninstance_disk\nNumber of write requests\n\ndisk.device.read.bytes\n\ncumulative\ninstance_disk\nAmount of data read, in bytes\n\ndisk.device.write.bytes\n\ncumulative\ninstance_disk\nAmount of data written, in bytes\n\nnetwork.incoming.bytes\n\ncumulative\ninstance_network_interface\nIncoming network traffic, in bytes\n\nnetwork.outgoing.bytes\n\ncumulative\ninstance_network_interface\nOutgoing network traffic, in bytes\n\nnetwork.incoming.packets\n\ncumulative\ninstance_network_interface\nIncoming network traffic, in packets\n\nnetwork.outgoing.packets\n\ncumulative\ninstance_network_interface\nOutgoing network traffic, in packets\n\nimage.size\n\ngauge\nimage\nSize of the uploaded image, in bytes\n\nvolume.size\n\ngauge\nvolume\nSize of the volume, in gigabytes\n\nsnapshot.size\n\ngauge\nvolume\nSize of the volume snapshot, in gigabytes\n\nmagnum.cluster\n\ngauge\ncoe_cluster\nNumber of Container Orchestration Engine (COE),\r\nthat is, Kubernetes clusters\n\nbandwidth\n\ndelta\nnetwork\nIncoming and outgoing network traffic for a physical compute network, in bytes\n\nCumulative metrics are polled every 5 minutes and increase over time, delta metrics are polled every 5 minutes and change over time, and gauge metrics are updated on events and show fluctuating values.\nPrerequisites\n\nThe billing metering service is installed, as explained in Provisioning billing metering.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-metering-for-compute-resources.html"
    },
    {
        "title": "Managing floating IP addresses",
        "content": "Managing floating IP addresses\nA virtual machine connected to a virtual network can be accessed from public networks, such as the Internet, by means of a floating IP address. Such an address is picked from a physical network and mapped to the VM\u00e2\u0080\u0099s private IP address. The floating and private IP addresses are used at the same time on the VM\u00e2\u0080\u0099s network interface. The private IP address is used to communicate with other VMs on the virtual network. The floating IP address is used to access the VM from public networks. The VM guest operating system is unaware of the assigned floating IP address.\nPrerequisites\n\nYou have a virtual router created, as described in Creating virtual routers.\nThe virtual machine to assign a floating IP to has a fixed private IP address.\nThe virtual router connects the physical network, from which a floating IP will be picked, with the VM\u00e2\u0080\u0099s virtual network.\n\nTo create a floating IP address and assign it to a virtual machine\n\nAdmin panel\n\nOn the Compute > Network > Floating IPs tab, click Add floating IP.\n\nIn the Add floating IP address, select a physical network, from which a floating IP will be picked, and a VM network interface with a fixed private IP address.\n\nClick Add.\n\nCommand-line interface\nUse the following command:vinfra service compute floatingip create [--floating-ip <floating-ip>]\r\n                                         [--port-id <port-id>]\r\n                                         [--fixed-ip <fixed-ip>]\r\n                                         [--description <description>]\r\n                                         --network <network>\r\n\n\n--floating-ip <floating-ip>\n\nFloating IP address\n--port-id <port-id>\n\nID of the port to be associated with the floating IP address. To learn the port ID of the selected virtual machine, use the command vinfra service compute server iface list.\n--fixed-ip <fixed-ip>\n\nPort IP address (required only if the port has multiple IP addresses)\n--description <description>\n\nDescription of the floating IP address\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--network <network>\n\nID or name of the network from which to allocate the floating IP\n\nFor example, to create a floating IP address from the physical network public and assign it to a virtual machine on port with the ID 418c8c9e-aaa5-42f2-8da7-24bfead6f28b and the virtual IP address 192.168.128.5, run:# vinfra service compute floatingip create public --port-id 418c8c9e-aaa5-42f2-8da7-24bfead6f28b \\\r\n--fixed-ip-address 192.168.128.5\r\n+---------------------+--------------------------------------+\r\n| Field               | Value                                |\r\n+---------------------+--------------------------------------+\r\n| attached_to         | a172cb6a-1c7b-4157-9e86-035f3077646f |\r\n| description         |                                      |\r\n| fixed_ip_address    | 192.168.128.5                        |\r\n| floating_ip_address | 10.94.129.72                         |\r\n| floating_network_id | 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                  | a709f884-c43f-4a9a-a243-a340d7682ef8 |\r\n| port_id             | 418c8c9e-aaa5-42f2-8da7-24bfead6f28b |\r\n| project_id          | 894696133031439f8aaa7e4868dcbd4d     |\r\n| router_id           | f7f86029-a553-4d61-b7ec-6f581d9c5f5f |\r\n| status              | DOWN                                 |\r\n+---------------------+--------------------------------------+\r\n\nThe created floating IP address will appear in the vinfra service compute floatingip list output:# vinfra service compute floatingip list -c id -c fixed_ip_address -c port_id -c floating_ip_address\r\n+----------------+------------------+----------------+---------------------+\r\n| id             | fixed_ip_address | port_id        | floating_ip_address |\r\n+----------------+------------------+----------------+---------------------+\r\n| a709f884-<...> | 192.168.128.5    | 418c8c9e-<...> | 10.94.129.72        |\r\n+----------------+------------------+----------------+---------------------+\n\nTo re-assign a floating IP address to another virtual machine\n\nAdmin panel\n\nClick the ellipsis icon next to the floating IP address, and then click Unassign.\nOnce the VM name disappears in the Assigned to column, click the ellipsis icon again, and then select Assign.\nIn the Assign floating IP address window, select a VM network interface with a fixed private IP address.\nClick Assign.\n\nCommand-line interface\nUse the following command:vinfra service compute floatingip set [--port-id <port-id>] [--fixed-ip <fixed-ip>]\r\n                                      [--description <description>] <floating-ip>\r\n\n\n--port-id <port-id>\n\nID of the port to be associated with the floating IP address\n--fixed-ip <fixed-ip>\n\nPort IP address (required only if the port has multiple IP addresses)\n--description <description>\n\nDescription of the floating IP address\n<floating-ip>\n\nID of the floating IP address\n\nFor example, to assign the floating IP address with the ID a709f884-c43f-4a9a-a243-a340d7682ef8 to a virtual machine on port with the ID 8c11c29b-9a73-4017-baff-1e872b18b54b and the virtual IP address 192.128.30.15, run:# vinfra service compute floatingip set a709f884-c43f-4a9a-a243-a340d7682ef8 \\\r\n--port-id 8c11c29b-9a73-4017-baff-1e872b18b54b --fixed-ip-address 192.128.30.15\r\n+---------------------+--------------------------------------+\r\n| Field               | Value                                |\r\n+---------------------+--------------------------------------+\r\n| attached_to         | 3a092f6f-bbaf-47a9-bcc7-f86223aacb55 |\r\n| description         |                                      |\r\n| fixed_ip_address    | 192.128.30.15                        |\r\n| floating_ip_address | 10.94.129.72                         |\r\n| floating_network_id | 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                  | a709f884-c43f-4a9a-a243-a340d7682ef8 |\r\n| port_id             | 8c11c29b-9a73-4017-baff-1e872b18b54b |\r\n| project_id          | 894696133031439f8aaa7e4868dcbd4d     |\r\n| router_id           | f7f86029-a553-4d61-b7ec-6f581d9c5f5f |\r\n| status              | ACTIVE                               |\r\n+---------------------+--------------------------------------+\r\n\n\nTo remove a floating IP address\n\nAdmin panel\n\nUnassign it from a virtual machine. Click the ellipsis icon next to the floating IP address, and then click Unassign.\nClick the ellipsis icon again, and then select Delete.\n\nCommand-line interface\nUse the following command:vinfra service compute floatingip delete <floating-ip>\r\n\n\n<floating-ip>\n\nID of the floating IP address\n\nFor example, to delete the floating IP address with the ID a709f884-c43f-4a9a-a243-a340d7682ef8, run:# vinfra service compute floatingip delete a709f884-c43f-4a9a-a243-a340d7682ef8\r\nOperation successful\r\n\n\nSee also\n\nManaging compute networks\n\nManaging virtual routers\n\nManaging load balancers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute floatingip create [--floating-ip <floating-ip>]\r\n                                         [--port-id <port-id>]\r\n                                         [--fixed-ip <fixed-ip>]\r\n                                         [--description <description>]\r\n                                         --network <network>\r\n\n\n--floating-ip <floating-ip>\n\nFloating IP address\n--port-id <port-id>\n\nID of the port to be associated with the floating IP address. To learn the port ID of the selected virtual machine, use the command vinfra service compute server iface list.\n--fixed-ip <fixed-ip>\n\nPort IP address (required only if the port has multiple IP addresses)\n--description <description>\n\n\nDescription of the floating IP address\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--network <network>\n\nID or name of the network from which to allocate the floating IP\n\nFor example, to create a floating IP address from the physical network public and assign it to a virtual machine on port with the ID 418c8c9e-aaa5-42f2-8da7-24bfead6f28b and the virtual IP address 192.168.128.5, run:# vinfra service compute floatingip create public --port-id 418c8c9e-aaa5-42f2-8da7-24bfead6f28b \\\r\n--fixed-ip-address 192.168.128.5\r\n+---------------------+--------------------------------------+\r\n| Field               | Value                                |\r\n+---------------------+--------------------------------------+\r\n| attached_to         | a172cb6a-1c7b-4157-9e86-035f3077646f |\r\n| description         |                                      |\r\n| fixed_ip_address    | 192.168.128.5                        |\r\n| floating_ip_address | 10.94.129.72                         |\r\n| floating_network_id | 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                  | a709f884-c43f-4a9a-a243-a340d7682ef8 |\r\n| port_id             | 418c8c9e-aaa5-42f2-8da7-24bfead6f28b |\r\n| project_id          | 894696133031439f8aaa7e4868dcbd4d     |\r\n| router_id           | f7f86029-a553-4d61-b7ec-6f581d9c5f5f |\r\n| status              | DOWN                                 |\r\n+---------------------+--------------------------------------+\r\n\nThe created floating IP address will appear in the vinfra service compute floatingip list output:# vinfra service compute floatingip list -c id -c fixed_ip_address -c port_id -c floating_ip_address\r\n+----------------+------------------+----------------+---------------------+\r\n| id             | fixed_ip_address | port_id        | floating_ip_address |\r\n+----------------+------------------+----------------+---------------------+\r\n| a709f884-<...> | 192.168.128.5    | 418c8c9e-<...> | 10.94.129.72        |\r\n+----------------+------------------+----------------+---------------------+\n",
                "title": "To create a floating IP address and assign it to a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute floatingip set [--port-id <port-id>] [--fixed-ip <fixed-ip>]\r\n                                      [--description <description>] <floating-ip>\r\n\n\n--port-id <port-id>\n\nID of the port to be associated with the floating IP address\n--fixed-ip <fixed-ip>\n\nPort IP address (required only if the port has multiple IP addresses)\n--description <description>\n\nDescription of the floating IP address\n<floating-ip>\n\nID of the floating IP address\n\nFor example, to assign the floating IP address with the ID a709f884-c43f-4a9a-a243-a340d7682ef8 to a virtual machine on port with the ID 8c11c29b-9a73-4017-baff-1e872b18b54b and the virtual IP address 192.128.30.15, run:# vinfra service compute floatingip set a709f884-c43f-4a9a-a243-a340d7682ef8 \\\r\n--port-id 8c11c29b-9a73-4017-baff-1e872b18b54b --fixed-ip-address 192.128.30.15\r\n+---------------------+--------------------------------------+\r\n| Field               | Value                                |\r\n+---------------------+--------------------------------------+\r\n| attached_to         | 3a092f6f-bbaf-47a9-bcc7-f86223aacb55 |\r\n| description         |                                      |\r\n| fixed_ip_address    | 192.128.30.15                        |\r\n| floating_ip_address | 10.94.129.72                         |\r\n| floating_network_id | 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                  | a709f884-c43f-4a9a-a243-a340d7682ef8 |\r\n| port_id             | 8c11c29b-9a73-4017-baff-1e872b18b54b |\r\n| project_id          | 894696133031439f8aaa7e4868dcbd4d     |\r\n| router_id           | f7f86029-a553-4d61-b7ec-6f581d9c5f5f |\r\n| status              | ACTIVE                               |\r\n+---------------------+--------------------------------------+\r\n\n",
                "title": "To re-assign a floating IP address to another virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute floatingip delete <floating-ip>\r\n\n\n<floating-ip>\n\nID of the floating IP address\n\nFor example, to delete the floating IP address with the ID a709f884-c43f-4a9a-a243-a340d7682ef8, run:# vinfra service compute floatingip delete a709f884-c43f-4a9a-a243-a340d7682ef8\r\nOperation successful\r\n\n",
                "title": "To remove a floating IP address"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Floating IPs tab, click Add floating IP.\n\nIn the Add floating IP address, select a physical network, from which a floating IP will be picked, and a VM network interface with a fixed private IP address.\n\n\n\n\n\nClick Add.\n\n",
                "title": "To create a floating IP address and assign it to a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nClick the ellipsis icon next to the floating IP address, and then click Unassign.\nOnce the VM name disappears in the Assigned to column, click the ellipsis icon again, and then select Assign.\nIn the Assign floating IP address window, select a VM network interface with a fixed private IP address.\nClick Assign.\n\n",
                "title": "To re-assign a floating IP address to another virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nUnassign it from a virtual machine. Click the ellipsis icon next to the floating IP address, and then click Unassign.\nClick the ellipsis icon again, and then select Delete.\n\n",
                "title": "To remove a floating IP address"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-floating-ip-addresses.html"
    },
    {
        "title": "Benchmarking NFS, iSCSI, and S3",
        "content": "Benchmarking NFS, iSCSI, and S3\nIn this guide, the open-source fio (Flexible I/O) tester is used to benchmark the performance of NFS and iSCSI, and GOSBench is used to benchmark the performance of S3 services.\nPrerequisites\n\nKnowledge of the storage cluster best practices and configurations listed in Storage cluster best practices and Configuration examples.\n\nNFS, iSCSI, or S3 benchmarking overview\n\nEnsure that the benchmarking requirements are met.\n\nDeploy virtual machines with load generators from the prebuilt images.\n\nCreate the NFS, iSCSI, or S3 service in the test cluster.\nSet up and prepare to run the benchmark.\nRun the benchmark.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/benchmarking-nfs-iscsi-s3.html"
    },
    {
        "title": "Managing self-service users",
        "content": "Managing self-service users\nYou can add more domain administrators and project members, as described in Configuring multitenancy. Also, you can edit user credentials and permissions, manage project assignment, as well as enable/disable and delete the existing users. Enabling and disabling users allows or prohibits user login in the self-service panel.\nTo edit user credentials and permissions\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the ellipsis icon next to the user, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nCommand-line interface\nUse the following command:vinfra domain user set [--password] [--email <email>] [--name <name>] [--description <description>]\r\n                       [--domain-permissions <domain_permissions>] --domain <domain> <user>\r\n\n\n--password\n\nRequest the password from stdin\n--email <email>\n\nUser email\n--name <name>\n\nUser name\n--description <description>\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to change the email of the user myuser to user@example.com, run:# vinfra domain user set myuser --domain mydomain --email user@example.com\n\nTo enable or disable a user\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the ellipsis icon next to the user, and then click Enable or Disable.\n\nCommand-line interface\nUse the following command:vinfra domain user set [--enable | --disable] --domain <domain> <user>\r\n\n\n--enable\n\nEnable user\n--disable\n\nDisable user\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to disable the user myuser within the domain mydomain, run:# vinfra domain user set myuser --domain mydomain --disable\n\nTo assign a user to projects\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the ellipsis icon next to a user with the Project member role, and then click Manage projects.\nIn the Manage projects window, select only those projects that you want to assign the user to, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra domain user set --assign <project> <role> --domain <domain> <user>\r\n\n\n--assign <project> <role>\n\nAssign a user to a project with one or more permission sets. Specify this option multiple times to assign the user to multiple projects.\n\n<project>: project ID or name\n<role>: user role in the project (project_admin)\n\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to assign the user myuser from the domain mydomain to the project myproject as a project administrator, run:# vinfra domain user set myuser --domain mydomain --assign myproject project_admin\n\nTo unassign a user from projects\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the required user with the Project member role.\nOn the Projects tab, click the bin icon next to a project that you want to remove the user from.\n\nCommand-line interface\nUse the following command:vinfra domain user set --unassign <project> --domain <domain> <user>\r\n\n\n--unassign <project>\n\nUnassign a user from a project. Specify this option multiple times to unassign the user from multiple projects.\n\n<project>: project ID or name\n\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to unassign the user myuser from the domain mydomain from the project myproject, run:# vinfra domain user set myuser --domain mydomain --unassign myproject\n\nTo delete a user\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to delete a user.\nGo to the Domain users tab, click the ellipsis icon next to it, and then click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra domain user delete --domain <domain> <user>\r\n\n\n--domain <domain>\n\nDomain ID or name\n<user>\n\nUser ID or name\n\nFor example, to delete the user myuser from the domain mydomain:# vinfra domain user delete myuser --domain mydomain\n\nSee also\n\nAssigning users to multiple domains\n\nManaging projects\n\nManaging domain groups\n\nUnlocking user accounts",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user set [--password] [--email <email>] [--name <name>] [--description <description>]\r\n                       [--domain-permissions <domain_permissions>] --domain <domain> <user>\r\n\n\n--password\n\nRequest the password from stdin\n--email <email>\n\nUser email\n--name <name>\n\nUser name\n--description <description>\n\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to change the email of the user myuser to user@example.com, run:# vinfra domain user set myuser --domain mydomain --email user@example.com\n",
                "title": "To edit user credentials and permissions"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user set [--enable | --disable] --domain <domain> <user>\r\n\n\n--enable\n\nEnable user\n--disable\n\nDisable user\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to disable the user myuser within the domain mydomain, run:# vinfra domain user set myuser --domain mydomain --disable\n",
                "title": "To enable or disable a user"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user set --assign <project> <role> --domain <domain> <user>\r\n\n\n--assign <project> <role>\n\n\nAssign a user to a project with one or more permission sets. Specify this option multiple times to assign the user to multiple projects.\n\n<project>: project ID or name\n<role>: user role in the project (project_admin)\n\n\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to assign the user myuser from the domain mydomain to the project myproject as a project administrator, run:# vinfra domain user set myuser --domain mydomain --assign myproject project_admin\n",
                "title": "To assign a user to projects"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user set --unassign <project> --domain <domain> <user>\r\n\n\n--unassign <project>\n\n\nUnassign a user from a project. Specify this option multiple times to unassign the user from multiple projects.\n\n<project>: project ID or name\n\n\n--domain <domain>\n\nDomain name or ID\n<user>\n\nUser ID or name\n\nFor example, to unassign the user myuser from the domain mydomain from the project myproject, run:# vinfra domain user set myuser --domain mydomain --unassign myproject\n",
                "title": "To unassign a user from projects"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user delete --domain <domain> <user>\r\n\n\n--domain <domain>\n\nDomain ID or name\n<user>\n\nUser ID or name\n\nFor example, to delete the user myuser from the domain mydomain:# vinfra domain user delete myuser --domain mydomain\n",
                "title": "To delete a user"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the ellipsis icon next to the user, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n",
                "title": "To edit user credentials and permissions"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the ellipsis icon next to the user, and then click Enable or Disable.\n\n",
                "title": "To enable or disable a user"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the ellipsis icon next to a user with the Project member role, and then click Manage projects.\nIn the Manage projects window, select only those projects that you want to assign the user to, and then click Save.\n\n",
                "title": "To assign a user to projects"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a user.\nGo to the Domain users tab, click the required user with the Project member role.\nOn the Projects tab, click the bin icon next to a project that you want to remove the user from.\n\n",
                "title": "To unassign a user from projects"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to delete a user.\nGo to the Domain users tab, click the ellipsis icon next to it, and then click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a user"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-self-service-users.html"
    },
    {
        "title": "Managing compute subnets",
        "content": "Managing compute subnets\nYou can add, edit, and delete subnets of physical compute networks. Also, if you exhaust all public IP addresses in a physical compute network, you can add more subnets to this network by using the vinfra command-line tool. The new subnets will be available in the admin and self-service panel for IP address allocation and management.\nLimitations\n\nFor an IPv6 subnet, you cannot change the IPv6 address mode.\nA compute network with enabled IP address management must have at least one subnet.\n\nPrerequisites\n\nCompute networks are created automatically during the compute cluster deployment or manually, as described in Creating physical compute networks and Creating virtual compute networks.\n\nTo add a subnet to a physical compute network\n\nAdmin panel\n\nOn the Compute > Networks tab, click the desired physical network. \nIn the Subnets section, click Add, and then select IPv4 subnet or IPv6 subnet, depending on the available option.\nIn the new window, specify the subnet settings, and then click Add.\n\nCommand-line interface\nUse the following command:vinfra service compute subnet create [--dhcp | --no-dhcp] [--dns-nameserver <dns-nameserver>]\r\n                                     [--allocation-pool <allocation-pool>] [--gateway <gateway> | --no-gateway]\r\n                                     [--ipv6-address-mode {dhcpv6-stateful,dhcpv6-stateless,slaac}]\r\n                                     --network <network> --cidr <cidr>\n\n--dhcp\n\nEnable DHCP\n--no-dhcp\n\nDisable DHCP\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: <starting_ip_address>-<ending_ip_address>. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n--ipv6-address-mode {dhcpv6-stateful,dhcpv6-stateless,slaac}\n\nIPv6 address mode. Valid modes are dhcpv6-stateful, dhcpv6-stateless, and slaac.\n--network <network>\n\nNetwork ID or name\n--cidr <cidr>\n\nSubnet range in CIDR notation\n\nFor example, to add an IPv6 subnet to the physical network public, run:# vinfra service compute subnet create --network public --cidr 2001:bd8::/64 --ipv6-address-mode dhcpv6-stateful \\\r\n--dhcp --allocation-pool 2001:bd8::100-2001:bd8::200 --dns-nameserver 2001:4860:4860::8888\nThe created subnet will appear in the vinfra service compute subnet list output:# vinfra service compute subnet list --network public -c id -c network_id -c cidr\r\n+--------------------------------------+--------------------------------------+----------------+\r\n| id                                   | network_id                           | cidr           |\r\n+--------------------------------------+--------------------------------------+----------------+\r\n| 8d2169a1-3459-4e87-9f5c-6d2d20353eea | d94545f0-c974-49ac-99f6-db6da73cd23d | 10.136.16.0/20 |\r\n| afa4710a-a82c-4273-a1b0-72d5d2884be6 | d94545f0-c974-49ac-99f6-db6da73cd23d | 2001:bd8::/64  |\r\n+--------------------------------------+--------------------------------------+----------------+\n\nTo add more subnets to a physical compute network\n\nIdentify the required network by listing all of the existing networks:# vinfra service compute network list -c id -c name -c physical_network -c cidr\r\n+--------------------------------------+---------+------------------+------------------+\r\n| id                                   | name    | physical_network | cidr             |\r\n+--------------------------------------+---------+------------------+------------------+\r\n| 3cbd594b-a1ff-4ee4-a771-1010822607c4 | private |                  | 192.168.128.0/24 |\r\n| d94545f0-c974-49ac-99f6-db6da73cd23d | public  | Public           | 10.136.16.0/20   |\r\n+--------------------------------------+---------+------------------+------------------+\n\nCreate a new subnet in the network by using the vinfra service compute subnet create command. For example:# vinfra service compute subnet create --network public --cidr 10.164.132.0/24 --gateway 10.164.132.1 \\\r\n--dhcp --allocation-pool 10.164.132.201-10.164.132.250 --dns-nameserver 8.8.8.8\n\nTo edit a subnet of a physical compute network\n\nAdmin panel\n\nOn the Compute > Networks tab, click the desired physical network. \nIn the Subnets section, click the pencil icon next to the subnet you want to edit.\nIn the Edit subnet window, change the subnet settings, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra service compute subnet set [--dhcp | --no-dhcp] [--dns-nameserver <dns-nameserver>]\r\n                                  [--allocation-pool <allocation-pool>]\r\n                                  [--gateway <gateway> | --no-gateway] <subnet>\n\n--dhcp\n\nEnable DHCP\n--no-dhcp\n\nDisable DHCP\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: <starting_ip_address>-<ending_ip_address>. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n<subnet>\n\nSubnet ID\n\nFor example, to add more IP addresses to the subnet allocation pool, run:# vinfra service compute subnet set 8d2169a1-3459-4e87-9f5c-6d2d20353eea --allocation-pool 10.136.18.201-10.136.18.250\n\nTo delete a subnet from a physical compute network\n\nAdmin panel\n\nOn the Compute > Networks tab, click the desired physical network. \n\nIn the Subnets section, click the bin icon next to the subnet you want to remove.\n\nYou cannot delete the only subnet.\n\nCommand-line interface\nUse the following command:vinfra service compute subnet delete <subnet>\n\n<subnet>\n\nSubnet ID\n\nFor example, to delete the IPv6 subnet from the physical network public, run:# vinfra service compute subnet delete afa4710a-a82c-4273-a1b0-72d5d2884be6\n\nSee also\n\nManaging security groups\n\nManaging virtual routers\n\nManaging floating IP addresses\n\nManaging load balancers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute subnet create [--dhcp | --no-dhcp] [--dns-nameserver <dns-nameserver>]\r\n                                     [--allocation-pool <allocation-pool>] [--gateway <gateway> | --no-gateway]\r\n                                     [--ipv6-address-mode {dhcpv6-stateful,dhcpv6-stateless,slaac}]\r\n                                     --network <network> --cidr <cidr>\n\n--dhcp\n\nEnable DHCP\n--no-dhcp\n\nDisable DHCP\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: <starting_ip_address>-<ending_ip_address>. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n--ipv6-address-mode {dhcpv6-stateful,dhcpv6-stateless,slaac}\n\nIPv6 address mode. Valid modes are dhcpv6-stateful, dhcpv6-stateless, and slaac.\n--network <network>\n\nNetwork ID or name\n--cidr <cidr>\n\nSubnet range in CIDR notation\n\nFor example, to add an IPv6 subnet to the physical network public, run:# vinfra service compute subnet create --network public --cidr 2001:bd8::/64 --ipv6-address-mode dhcpv6-stateful \\\r\n--dhcp --allocation-pool 2001:bd8::100-2001:bd8::200 --dns-nameserver 2001:4860:4860::8888\nThe created subnet will appear in the vinfra service compute subnet list output:# vinfra service compute subnet list --network public -c id -c network_id -c cidr\r\n+--------------------------------------+--------------------------------------+----------------+\r\n| id                                   | network_id                           | cidr           |\r\n+--------------------------------------+--------------------------------------+----------------+\r\n| 8d2169a1-3459-4e87-9f5c-6d2d20353eea | d94545f0-c974-49ac-99f6-db6da73cd23d | 10.136.16.0/20 |\r\n| afa4710a-a82c-4273-a1b0-72d5d2884be6 | d94545f0-c974-49ac-99f6-db6da73cd23d | 2001:bd8::/64  |\r\n+--------------------------------------+--------------------------------------+----------------+\n",
                "title": "To add a subnet to a physical compute network"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute subnet set [--dhcp | --no-dhcp] [--dns-nameserver <dns-nameserver>]\r\n                                  [--allocation-pool <allocation-pool>]\r\n                                  [--gateway <gateway> | --no-gateway] <subnet>\n\n--dhcp\n\nEnable DHCP\n--no-dhcp\n\nDisable DHCP\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: <starting_ip_address>-<ending_ip_address>. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n<subnet>\n\nSubnet ID\n\nFor example, to add more IP addresses to the subnet allocation pool, run:# vinfra service compute subnet set 8d2169a1-3459-4e87-9f5c-6d2d20353eea --allocation-pool 10.136.18.201-10.136.18.250\n",
                "title": "To edit a subnet of a physical compute network"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute subnet delete <subnet>\n\n<subnet>\n\nSubnet ID\n\nFor example, to delete the IPv6 subnet from the physical network public, run:# vinfra service compute subnet delete afa4710a-a82c-4273-a1b0-72d5d2884be6\n",
                "title": "To delete a subnet from a physical compute network"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Networks tab, click the desired physical network. \nIn the Subnets section, click Add, and then select IPv4 subnet or IPv6 subnet, depending on the available option.\nIn the new window, specify the subnet settings, and then click Add.\n\n",
                "title": "To add a subnet to a physical compute network"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Networks tab, click the desired physical network. \nIn the Subnets section, click the pencil icon next to the subnet you want to edit.\nIn the Edit subnet window, change the subnet settings, and then click Save.\n\n",
                "title": "To edit a subnet of a physical compute network"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Networks tab, click the desired physical network. \n\nIn the Subnets section, click the bin icon next to the subnet you want to remove.\n\nYou cannot delete the only subnet.\n\n\n\n",
                "title": "To delete a subnet from a physical compute network"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-compute-subnets.html"
    },
    {
        "title": "Removing unassigned nodes",
        "content": "Removing unassigned nodes\nTo be completely removed from the infrastructure, the node must not be a part of the storage cluster.\nPrerequisites\n\nThe node is removed from the storage cluster, as described in Releasing nodes from the storage cluster.\n\nTo remove a node from the infrastructure\n\nAdmin panel\n\nSelect the unassigned node on the Infrastructure > Nodes screen, and then click Remove.\n\nFor security purposes, clean up node certificates and identity by deleting the following from the node:# rm -rf /usr/libexec/vstorage-ui-backend/ca\r\n# rm -rf /etc/nginx/ssl\r\n# rm -f /etc/vstorage/host_id\r\n# rm -f /etc/vstorage/vstorage-ui-agent.conf\n\nAfter such a cleanup, the only way to add the node back to the cluster is by re-installing Virtuozzo Hybrid Infrastructure on it from scratch.\n\nCommand-line interface\nUse the following command:vinfra node forget <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to unregister the node node005 from Virtuozzo Hybrid Infrastructure, run:# vinfra node forget node005\n\nSee also\n\nRe-adding unassigned nodes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node forget <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to unregister the node node005 from Virtuozzo Hybrid Infrastructure, run:# vinfra node forget node005\n",
                "title": "To remove a node from the infrastructure"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nSelect the unassigned node on the Infrastructure > Nodes screen, and then click Remove.\n\nFor security purposes, clean up node certificates and identity by deleting the following from the node:# rm -rf /usr/libexec/vstorage-ui-backend/ca\r\n# rm -rf /etc/nginx/ssl\r\n# rm -f /etc/vstorage/host_id\r\n# rm -f /etc/vstorage/vstorage-ui-agent.conf\n\nAfter such a cleanup, the only way to add the node back to the cluster is by re-installing Virtuozzo Hybrid Infrastructure on it from scratch.\n\n\n\n",
                "title": "To remove a node from the infrastructure"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/removing-unassigned-nodes.html"
    },
    {
        "title": "About object storage",
        "content": "About object storage\nVirtuozzo Hybrid Infrastructure allows you to export cluster disk space to customers in the form of an S3-like object-based storage.\nVirtuozzo Hybrid Infrastructure is implemented as an Amazon S3-like API, which is one of the most common object storage APIs. End users can work with Virtuozzo Hybrid Infrastructure as they work with Amazon S3. You can use the usual applications for S3 and continue working with them after the data migration from Amazon S3 to Virtuozzo Hybrid Infrastructure.\nObject storage is a storage architecture that enables managing data as objects (like in a key-value storage), as opposed to files in file systems or blocks in a block storage. Except for the data, each object has metadata that describes it as well as a unique identifier that allows finding the object in the storage. Object storage is optimized for storing billions of objects, in particular for application storage, static web content hosting, online storage services, big data, and backups. All of these uses are enabled by object storage thanks to a combination of very high scalability, data availability, and consistency.\nCompared to other types of storage, the key difference of object storage is that parts of an object cannot be modified; so if the object changes, a new version of it is spawned instead. This approach is extremely important for maintaining data availability and consistency. First of all, changing an object as a whole eliminates the issue of conflicts. That is, the object with the latest timestamp is considered to be the current version and that is it. As a result, objects are always consistent, that is, their state is relevant and appropriate.\nAnother feature of object storage is eventual consistency. Eventual consistency does not guarantee that reads are to return the new state after the write has been completed. Readers can observe the old state for an undefined period of time, until the write is propagated to all the replicas (copies).\nIn Virtuozzo Hybrid Infrastructure, object storage offers eventual consistency to improve performance and availability of geographically distant datacenters, as they may not be able to perform data update synchronously (for example, due to network latency) and the update itself may also be slow, as awaiting acknowledges from all the data replicas over long distances can take hundreds of milliseconds. So eventual consistency helps hide communication latencies on writes at the cost of the probable old state observed by readers. However, many use cases can easily tolerate it.\nNote that within the same cluster:\n\nOperations on objects are strongly consistent.\nOperations on buckets (such as updating policies) are eventually consistent.\n\nSee also\n\nProvisioning object storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/about-object-storage.html"
    },
    {
        "title": "Showing snapshot details",
        "content": "Showing snapshot detailsGET /v3/{project_id}/snapshots/{snapshot_id}\r\n\nShows the details of a snapshot with the specified ID.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=show-a-snapshot-s-details-detail#show-a-snapshot-s-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nsnapshot_id\n\npath\nstring\nThe UUID of the snapshot.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/snapshots/aebe052f-6c13-417a-8ea9-771f40d6667f\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nsnapshot\n\nbody\nobject\nA snapshot object.\n\nuser_id\n\nbody\nstring\n\nThe UUID of the user.\nNew in version 3.41\n\nvolume_id\n\nbody\nstring\nIf the snapshot was created from a volume, the\r\nvolume ID.\n\nname\n\nbody\nstring\nThe name of the snapshot.\n\nstatus\n\nbody\nstring\nThe status for the snapshot.\n\nos-extended-snapshot-attributes:progress\n\nbody\nstring\nA percentage value for the build progress.\n\nos-extended-snapshot-attributes:project_id\n\nbody\nstring\nThe UUID of the owning project.\n\ndescription\n\nbody\nstring\nA description for the snapshot.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nmetadata\n\nbody\nobject\nOne or more metadata key and value pairs for the\r\nsnapshot, if any.\n\nid\n\nbody\nstring\nThe snapshot UUID.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nExample{\r\n  \"snapshot\": {\r\n    \"status\": \"available\",\r\n    \"description\": null,\r\n    \"updated_at\": \"2020-03-11T14:01:56.522040\",\r\n    \"volume_id\": \"cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n    \"id\": \"aebe052f-6c13-417a-8ea9-771f40d6667f\",\r\n    \"size\": 2,\r\n    \"os-extended-snapshot-attributes:progress\": \"100%\",\r\n    \"name\": \"Snapshot-vol1/2020-03-11 05:01:53\",\r\n    \"os-extended-snapshot-attributes:project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-03-11T14:01:54.381048\",\r\n    \"metadata\": {}\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-snapshot-details.html"
    },
    {
        "title": "Changing parameters in OpenStack configuration files",
        "content": "Changing parameters in OpenStack configuration files\nYou can modify the following parameters in the OpenStack configuration files:\n\nParameter\nConfiguration file\nDescription\nValue\n\nscheduler_host_subset_size\n\n/etc/kolla/nova-scheduler/nova.conf\n\nDefines a number of compute nodes best suited for a new VM, one of which is randomly chosen by the scheduler.\nValid values are 1 or greater. Any value less than 1 is treated as 1. The higher the value, the less optimal the chosen node may be for a VM. The default value is 1.\n\nvxlan_udp_port\n\n/etc/kolla/neutron-openvswitch-agent/ml2_conf.ini\n\nSpecifies the UDP port used for VXLAN tunnels. When changing the port, iptables rules are automatically configured for both the old and new ports.\nThe default port is 4789.\n\ncpu_allocation_ratio\n\n/etc/kolla/nova-compute/nova.conf\n\nDefines the virtual CPU to physical CPU allocation ratio.\n\nChanging CPU allocation ratio will not affect virtual CPUs already provisioned for virtual machines.\n\nValid values are positive integer or float. The default value is 8.0.\n\nram_allocation_ratio\n\n/etc/kolla/nova-compute/nova.conf\n\nDefines the maximum reserved RAM to physical RAM allocation ratio.\n\nChanging RAM allocation ratio will not affect RAM already provisioned for virtual machines.\n\nValid values are positive integer or float. The default value is 1.0. The maximum recommended value is 1.5.\n\nTo change a compute parameter\nUse the following command:vinfra service compute set [--custom-param <service_name> <config_file> <section> <property> <value>]\r\n                           [--nova-compute-ram-allocation-ratio <value>]\r\n                           [--neutron-openvswitch-vxlan-port <value>]\r\n                           [--nova-scheduler-host-subset-size <value>]\r\n                           [--nova-compute-cpu-allocation-ratio <value>]\r\n\n\n--custom-param <service_name> <config_file> <section> <property> <value>\n\nSet custom parameters for OpenStack configuration files:\n\nservice_name is the service name: nova-compute or neutron-openvswitch-agent\nconfig_file specifies the service configuration file: nova.conf for nova-compute or ml2_conf.ini for neutron-openvswitch-agent\nsection specifies the section in the service configuration file where the parameter is defined: DEFAULT in nova.conf or agent in ml2_conf.ini\nproperty is the parameter to be changed: ram_allocation_ratio, scheduler_host_subset, and cpu_allocation_ratio in nova.conf; vxlan_udp_port in ml2_conf.ini\nvalue is a new parameter value\n\n--nova-compute-ram-allocation-ratio <value>\n\nShortcut for --custom-param nova-compute nova.conf DEFAULT ram_allocation_ratio <value>\n--neutron-openvswitch-vxlan-port <value>\n\nShortcut for --custom-param neutron-openvswitch-agent ml2_conf.ini agent vxlan_udp_port <value>\n--nova-scheduler-host-subset-size <value>\n\nShortcut for --custom-param nova-scheduler nova.conf DEFAULT scheduler_host_subset_size <value>\n--nova-compute-cpu-allocation-ratio <value>\n\nShortcut for --custom-param nova-scheduler nova.conf DEFAULT cpu_allocation_ratio <value>\n\nFor example, to change cpu_allocation_ratio and vxlan_udp_port, run:# vinfra service compute set --nova-compute-cpu-allocation-ratio 16.0 --neutron-openvswitch-vxlan-port 4787\r\n\nTo check that the custom parameters are successfully modified, run:# vinfra service compute show\r\n+--------------+-------------------------------------------+\r\n| Field        | Value                                     |\r\n+--------------+-------------------------------------------+\r\n| <...>        | <...>                                     |\r\n| options      | cpu_model: ''                             |\r\n|              | custom_params:                            |\r\n|              | - config_file: nova.conf                  |\r\n|              |   property: cpu_allocation_ratio          |\r\n|              |   section: DEFAULT                        |\r\n|              |   service_name: nova-compute              |\r\n|              |   value: 16.0                             |\r\n|              | - config_file: ml2_conf.ini               |\r\n|              |   property: vxlan_udp_port                |\r\n|              |   section: agent                          |\r\n|              |   service_name: neutron-openvswitch-agent |\r\n|              |   value: 4787                             |\r\n|              | notification_forwarding: disabled         |\r\n| status       | active                                    |\r\n+--------------+-------------------------------------------+\r\n\nThe applied changes are consistent on all compute nodes and not overwritten after product updates and upgrades.\nIf you want to change the vCPU or RAM allocation ratio on a particular compute node, use this command with the --nodes option. For example, to set cpu_allocation_ratio to 16 on the node node001, run:# vinfra service compute set --nova-compute-cpu-allocation-ratio 16.0 --nodes node001\nSee also\n\nConfiguring memory for virtual machines\n\nChanging virtual CPU overcommitment",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-parameters-in-openstack-configuration-files.html"
    },
    {
        "title": "Monitoring node disks",
        "content": "Monitoring node disks\nLimitations\n\nYou cannot monitor performance of shingled magnetic recording (SMR) disks.\n\nTo monitor performance of a node disk\n\nGo to the Infrastructure > Nodes screen and click the node name. \nOn the Disks tab, click a node disk, and then take a look at the charts on the Monitoring tab.\n\nThe disk charts display its current usage, average latency, and read/write activity. For advanced monitoring, click Grafana dashboard.\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.\nTo view the service details\n\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOn the Disks tab, click a node disk, and then go to the Service tab.\n\nService properties differ depending on the disk role:\n\nService properties\nStorage\nMetadata\nMetadata+Cache\nCache\n\nStatus\n\nStorage service status:\n\nActive\n\nThe service is up and running.\nUnresponsive\n\nThe service stops responding and degrades the cluster performance. The disk is isolated from the cluster I/O.\nInactive\n\nThe service has not responded for some time, but data replication has not started yet. A storage service is marked as inactive during its first 5 minutes of inactivity. \n\nOffline\n\nThe service is inactive for more than 5 minutes. After a storage service goes offline, the cluster starts replicating data to restore the chunks that were stored on the affected storage disk.\n\nOut of space\n\nThe disk that runs the service is running out of space.\nReleasing\n\nThe service is being released.\nFailed\n\nThe service is running but a problem has occurred with the storage disk.\nRelease failed\n\nThe service failed to be released.\nEntering maintenance\n\nThe node that hosts the service is entering the maintenance mode.\nMaintenance\n\nThe node that hosts the service is in the maintenance mode. The service is active, but not available for allocating new data chunks.\nUnknown\n\nThe state of the service is unknown.\nDropped\n\nThe service was removed by the administrator.\nUnavailable\n\nThe service is active, but not available for allocating new data chunks.\nUnrecognized\n\nThe service cannot be recognized.\n\nMetadata service status:\n\nAvailable\n\nThe service is online.\nSyncing\n\nThe service is syncing the cluster metadata.\nUnavailable\n\nThe service is offline.\n\n\u00e2\u0080\u0094\n\nSystemd\nShows the state of vstorage-csd.<cluster_name>.<CS_ID>.service\n\nShows the state of vstorage-mdsd.<cluster_name>.<MDS_ID>.service\n\n\u00e2\u0080\u0094\n\nTier\n\nShows the assigned storage tier\n\n\u00e2\u0080\u0094\n\nShows tiers that are being cached\n\nService ID\n\nStorage service ID\n\nMetadata service ID\n\n\u00e2\u0080\u0094\n\nUsage\n\nSpace usage on the disk\n\nCaching\n\nEnabled/Disabled\n\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\nCache location\n\nShows the SSD disk where this disk's write cache is saved to.\n\nDisplayed if caching is enabled.\n\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\nChecksumming\nEnabled/Disabled\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\nEncryption\nEnabled/Disabled\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\nCommand-line interface\nUse the following command:vinfra node disk show [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname\n<disk>\n\nDisk ID or device name (default: node001.vstoragedomain)\n\nFor example, to view the details of the disk nvme0n1 attached to the node node003, run:# vinfra node disk show nvme0n1 --node node003\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| Field              | Value                                                                                    |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| being_assigned     | False                                                                                    |\r\n| being_released     | False                                                                                    |\r\n| device             | nvme0n1                                                                                  |\r\n| disk_status        | ok                                                                                       |\r\n| encryption         |                                                                                          |\r\n| form_factor        |                                                                                          |\r\n| id                 | B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                                     |\r\n| is_blink_available | False                                                                                    |\r\n| is_blinking        | False                                                                                    |\r\n| issues             | []                                                                                       |\r\n| lun_id             |                                                                                          |\r\n| model              | INTEL SSDPE2KX020T8                                                                      |\r\n| node_id            | e40195d1-64b8-4117-85f3-00bb5d7a1db6                                                     |\r\n| nvme               | True                                                                                     |\r\n| physical_size      | 2000398934016                                                                            |\r\n| protocol           | name: NVMe                                                                               |\r\n|                    | speed: null                                                                              |\r\n| role               | cs                                                                                       |\r\n| rpm                |                                                                                          |\r\n| serial_number      | PHLJ950101C02P0BGN                                                                       |\r\n| service_id         | 1091                                                                                     |\r\n| service_params     | fail_messages: null                                                                      |\r\n|                    | journal_data_size: 270532608                                                             |\r\n|                    | journal_disk_id: B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                    |\r\n|                    | journal_path: /vstorage/dc7aea32/journal/journal-cs-6aa56a11-70e6-4fd3-be4c-bf7fcd65e5d6 |\r\n|                    | journal_type: inner_cache                                                                |\r\n|                    | repo_dir: /vstorage/dc7aea32/cs                                                          |\r\n|                    | systemd: active                                                                          |\r\n|                    | tier: 0                                                                                  |\r\n| service_status     | active                                                                                   |\r\n| smart_status       | passed                                                                                   |\r\n| space              | size: 1968848437248                                                                      |\r\n|                    | used: 1540324716544                                                                      |\r\n| tasks              |                                                                                          |\r\n| temperature        | 36.0                                                                                     |\r\n| type               | ssd                                                                                      |\r\n| zoned              |                                                                                          |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n\nIn the command output, service properties differ depending on the disk role:\n\nService properties\ncs\n\nmds\n\nmds-journal\n\njournal\n\nservice_id\n\nStorage service ID\n\nMetadata service ID\n\n\u00e2\u0080\u0094\n\nservice_params\n\njournal_data_size\n\nSize of cached data for the storage service\njournal_disk_id\n\nCache disk ID\njournal_path\n\nPath to the directory with the write journal\njournal_type\n\nCache type used for the storage service:\n\nno_cache\n\ninner_cache\n\nexternal_cache\n\nrepo_dir\n\nPath to the repository with the storage service\nsystemd\n\nShows the state of vstorage-csd.<cluster_name>.<CS_ID>.service\ntier\n\nShows the assigned storage tier\n\nrepo_dir\n\nPath to the repository with the metadata service\nsystemd\n\nShows the state of vstorage-mdsd.<cluster_name>.<MDS_ID>.service\n\n\u00e2\u0080\u0094\n\nservice_status\n\nStorage service status:\n\nactive\n\nThe service is up and running.\nill\n\nThe service stops responding and degrades the cluster performance. The disk is isolated from the cluster I/O.\ninactive\n\nThe service has not responded for some time, but data replication has not started yet. A storage service is marked as inactive during its first 5 minutes of inactivity.\noffline\n\nThe service is inactive for more than 5 minutes. After a storage service goes offline, the cluster starts replicating data to restore the chunks that were stored on the affected storage disk.\nno space\n\nThe disk that runs the service is running out of space.\nreleasing\n\nThe service is being released.\nfailed\n\nThe service is running but a problem has occurred with the storage disk.\nfailed rel\n\nThe service failed to be released.\nentering_maintenance\n\nThe node that hosts the service is entering the maintenance mode.\nmaintenance\n\nThe node that hosts the service is in the maintenance mode. The service is active, but not available for allocating new data chunks\nunknown\n\nThe state of the service is unknown.\ndropped\n\nThe service was removed by the administrator.\nunavailable\n\nThe service is active, but not available for allocating new data chunks.\nunrecognized\n\nThe service cannot be recognized.\n\nMetadata service status:\n\navail\n\nThe service is online.\nstale\n\nThe service is syncing the cluster metadata.\nunavail\n\nThe service is offline.\n\n\u00e2\u0080\u0094\n\nTo view the disk details\n\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOn the Disks tab, click a node disk, and then go to the Disk tab.\n\nDisk properties include the drive name, state, type, physical capacity, disk protocol, model, serial number, S.M.A.R.T. status, and temperature. A disk can have the following states:\n\nHealthy\n\nThe disk is functioning normally.\nUnavailable\n\nThe disk is powered down or disconnected.\nFailed\n\nThe disk has failed or S.M.A.R.T. reported an error. You need to replace the disk.\n\nCommand-line interface\nUse the following command:vinfra node disk show [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname\n<disk>\n\nDisk ID or device name (default: node001.vstoragedomain)\n\nFor example, to view the details of the disk nvme0n1 attached to the node node003, run:# vinfra node disk show nvme0n1 --node node003\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| Field              | Value                                                                                    |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| being_assigned     | False                                                                                    |\r\n| being_released     | False                                                                                    |\r\n| device             | nvme0n1                                                                                  |\r\n| disk_status        | ok                                                                                       |\r\n| encryption         |                                                                                          |\r\n| form_factor        |                                                                                          |\r\n| id                 | B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                                     |\r\n| is_blink_available | False                                                                                    |\r\n| is_blinking        | False                                                                                    |\r\n| issues             | []                                                                                       |\r\n| lun_id             |                                                                                          |\r\n| model              | INTEL SSDPE2KX020T8                                                                      |\r\n| node_id            | e40195d1-64b8-4117-85f3-00bb5d7a1db6                                                     |\r\n| nvme               | True                                                                                     |\r\n| physical_size      | 2000398934016                                                                            |\r\n| protocol           | name: NVMe                                                                               |\r\n|                    | speed: null                                                                              |\r\n| role               | cs                                                                                       |\r\n| rpm                |                                                                                          |\r\n| serial_number      | PHLJ950101C02P0BGN                                                                       |\r\n| service_id         | 1091                                                                                     |\r\n| service_params     | fail_messages: null                                                                      |\r\n|                    | journal_data_size: 270532608                                                             |\r\n|                    | journal_disk_id: B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                    |\r\n|                    | journal_path: /vstorage/dc7aea32/journal/journal-cs-6aa56a11-70e6-4fd3-be4c-bf7fcd65e5d6 |\r\n|                    | journal_type: inner_cache                                                                |\r\n|                    | repo_dir: /vstorage/dc7aea32/cs                                                          |\r\n|                    | systemd: active                                                                          |\r\n|                    | tier: 0                                                                                  |\r\n| service_status     | active                                                                                   |\r\n| smart_status       | passed                                                                                   |\r\n| space              | size: 1968848437248                                                                      |\r\n|                    | used: 1540324716544                                                                      |\r\n| tasks              |                                                                                          |\r\n| temperature        | 36.0                                                                                     |\r\n| type               | ssd                                                                                      |\r\n| zoned              |                                                                                          |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n\nIn the command output, the disk properties include the device name, disk status, type, physical size, protocol, model, serial number, S.M.A.R.T. status, temperature, etc. iSCSi disks also have its LUN ID.\n\nTo check storage disks with enabled caching\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOn the Disks tab, click a node disk with the Cache role, and then go to the Cache for disks tab.\n\nThe tab lists all of the storage disks that are being cached on the current disk.\nTo have the disk blink its activity LED\n\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOn the Disks tab, click a node disk.\nOn the disk right pane, click Blink.\n\nTo have the disk stop blinking, click Unblink.\n\nCommand-line interface\nUse the following commands:\n\nTo start blinking the specified disk bay:vinfra node disk blink on [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<disk>\n\nDisk ID or device name\n\nFor example, to start blinking the disk sda on the node node005, run:# vinfra node disk blink on sda --node node005\n\nTo stop blinking the specified disk bay:vinfra node disk blink off [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<disk>\n\nDisk ID or device name\n\nFor example, to stop blinking the disk sda on the node node005, run:# vinfra node disk blink off sda --node node005\n\nSee also\n\nMonitoring node performance\n\nMonitoring node network interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node disk show [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname\n<disk>\n\nDisk ID or device name (default: node001.vstoragedomain)\n\nFor example, to view the details of the disk nvme0n1 attached to the node node003, run:# vinfra node disk show nvme0n1 --node node003\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| Field              | Value                                                                                    |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| being_assigned     | False                                                                                    |\r\n| being_released     | False                                                                                    |\r\n| device             | nvme0n1                                                                                  |\r\n| disk_status        | ok                                                                                       |\r\n| encryption         |                                                                                          |\r\n| form_factor        |                                                                                          |\r\n| id                 | B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                                     |\r\n| is_blink_available | False                                                                                    |\r\n| is_blinking        | False                                                                                    |\r\n| issues             | []                                                                                       |\r\n| lun_id             |                                                                                          |\r\n| model              | INTEL SSDPE2KX020T8                                                                      |\r\n| node_id            | e40195d1-64b8-4117-85f3-00bb5d7a1db6                                                     |\r\n| nvme               | True                                                                                     |\r\n| physical_size      | 2000398934016                                                                            |\r\n| protocol           | name: NVMe                                                                               |\r\n|                    | speed: null                                                                              |\r\n| role               | cs                                                                                       |\r\n| rpm                |                                                                                          |\r\n| serial_number      | PHLJ950101C02P0BGN                                                                       |\r\n| service_id         | 1091                                                                                     |\r\n| service_params     | fail_messages: null                                                                      |\r\n|                    | journal_data_size: 270532608                                                             |\r\n|                    | journal_disk_id: B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                    |\r\n|                    | journal_path: /vstorage/dc7aea32/journal/journal-cs-6aa56a11-70e6-4fd3-be4c-bf7fcd65e5d6 |\r\n|                    | journal_type: inner_cache                                                                |\r\n|                    | repo_dir: /vstorage/dc7aea32/cs                                                          |\r\n|                    | systemd: active                                                                          |\r\n|                    | tier: 0                                                                                  |\r\n| service_status     | active                                                                                   |\r\n| smart_status       | passed                                                                                   |\r\n| space              | size: 1968848437248                                                                      |\r\n|                    | used: 1540324716544                                                                      |\r\n| tasks              |                                                                                          |\r\n| temperature        | 36.0                                                                                     |\r\n| type               | ssd                                                                                      |\r\n| zoned              |                                                                                          |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n\nIn the command output, service properties differ depending on the disk role:\n\n\n\n\n\n\n\n\nService properties\ncs\n\nmds\n\nmds-journal\n\njournal\n\n\n\n\n\nservice_id\n\n\nStorage service ID\n\n\nMetadata service ID\n\n\u00e2\u0080\u0094\n\n\nservice_params\n\n\n\njournal_data_size\n\nSize of cached data for the storage service\njournal_disk_id\n\nCache disk ID\njournal_path\n\nPath to the directory with the write journal\njournal_type\n\n\nCache type used for the storage service:\n\nno_cache\n\ninner_cache\n\nexternal_cache\n\n\n\nrepo_dir\n\nPath to the repository with the storage service\nsystemd\n\nShows the state of vstorage-csd.<cluster_name>.<CS_ID>.service\ntier\n\nShows the assigned storage tier\n\n\n\n\nrepo_dir\n\nPath to the repository with the metadata service\nsystemd\n\nShows the state of vstorage-mdsd.<cluster_name>.<MDS_ID>.service\n\n\n\u00e2\u0080\u0094\n\n\nservice_status\n\n\nStorage service status:\n\nactive\n\nThe service is up and running.\nill\n\nThe service stops responding and degrades the cluster performance. The disk is isolated from the cluster I/O.\ninactive\n\nThe service has not responded for some time, but data replication has not started yet. A storage service is marked as inactive during its first 5 minutes of inactivity.\noffline\n\nThe service is inactive for more than 5 minutes. After a storage service goes offline, the cluster starts replicating data to restore the chunks that were stored on the affected storage disk.\nno space\n\nThe disk that runs the service is running out of space.\nreleasing\n\nThe service is being released.\nfailed\n\nThe service is running but a problem has occurred with the storage disk.\nfailed rel\n\nThe service failed to be released.\nentering_maintenance\n\nThe node that hosts the service is entering the maintenance mode.\nmaintenance\n\nThe node that hosts the service is in the maintenance mode. The service is active, but not available for allocating new data chunks\nunknown\n\nThe state of the service is unknown.\ndropped\n\nThe service was removed by the administrator.\nunavailable\n\nThe service is active, but not available for allocating new data chunks.\nunrecognized\n\nThe service cannot be recognized.\n\n\n\nMetadata service status:\n\navail\n\nThe service is online.\nstale\n\nThe service is syncing the cluster metadata.\nunavail\n\nThe service is offline.\n\n\n\u00e2\u0080\u0094\n\n\n\n",
                "title": "To view the service details"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node disk show [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname\n<disk>\n\nDisk ID or device name (default: node001.vstoragedomain)\n\nFor example, to view the details of the disk nvme0n1 attached to the node node003, run:# vinfra node disk show nvme0n1 --node node003\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| Field              | Value                                                                                    |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n| being_assigned     | False                                                                                    |\r\n| being_released     | False                                                                                    |\r\n| device             | nvme0n1                                                                                  |\r\n| disk_status        | ok                                                                                       |\r\n| encryption         |                                                                                          |\r\n| form_factor        |                                                                                          |\r\n| id                 | B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                                     |\r\n| is_blink_available | False                                                                                    |\r\n| is_blinking        | False                                                                                    |\r\n| issues             | []                                                                                       |\r\n| lun_id             |                                                                                          |\r\n| model              | INTEL SSDPE2KX020T8                                                                      |\r\n| node_id            | e40195d1-64b8-4117-85f3-00bb5d7a1db6                                                     |\r\n| nvme               | True                                                                                     |\r\n| physical_size      | 2000398934016                                                                            |\r\n| protocol           | name: NVMe                                                                               |\r\n|                    | speed: null                                                                              |\r\n| role               | cs                                                                                       |\r\n| rpm                |                                                                                          |\r\n| serial_number      | PHLJ950101C02P0BGN                                                                       |\r\n| service_id         | 1091                                                                                     |\r\n| service_params     | fail_messages: null                                                                      |\r\n|                    | journal_data_size: 270532608                                                             |\r\n|                    | journal_disk_id: B9F2C34F-19CF-4133-A3AF-A1440BE837AD                                    |\r\n|                    | journal_path: /vstorage/dc7aea32/journal/journal-cs-6aa56a11-70e6-4fd3-be4c-bf7fcd65e5d6 |\r\n|                    | journal_type: inner_cache                                                                |\r\n|                    | repo_dir: /vstorage/dc7aea32/cs                                                          |\r\n|                    | systemd: active                                                                          |\r\n|                    | tier: 0                                                                                  |\r\n| service_status     | active                                                                                   |\r\n| smart_status       | passed                                                                                   |\r\n| space              | size: 1968848437248                                                                      |\r\n|                    | used: 1540324716544                                                                      |\r\n| tasks              |                                                                                          |\r\n| temperature        | 36.0                                                                                     |\r\n| type               | ssd                                                                                      |\r\n| zoned              |                                                                                          |\r\n+--------------------+------------------------------------------------------------------------------------------+\r\n\nIn the command output, the disk properties include the device name, disk status, type, physical size, protocol, model, serial number, S.M.A.R.T. status, temperature, etc. iSCSi disks also have its LUN ID.\n",
                "title": "To view the disk details"
            },
            {
                "example": "\nCommand-line interface\nUse the following commands:\n\n\nTo start blinking the specified disk bay:vinfra node disk blink on [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<disk>\n\nDisk ID or device name\n\nFor example, to start blinking the disk sda on the node node005, run:# vinfra node disk blink on sda --node node005\n\n\nTo stop blinking the specified disk bay:vinfra node disk blink off [--node <node>] <disk>\r\n\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<disk>\n\nDisk ID or device name\n\nFor example, to stop blinking the disk sda on the node node005, run:# vinfra node disk blink off sda --node node005\n\n\n",
                "title": "To have the disk blink its activity LED"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOn the Disks tab, click a node disk, and then go to the Service tab.\n\nService properties differ depending on the disk role:\n\n\n\n\n\n\n\n\nService properties\nStorage\nMetadata\nMetadata+Cache\nCache\n\n\n\n\nStatus\n\nStorage service status:\n\nActive\n\nThe service is up and running.\nUnresponsive\n\nThe service stops responding and degrades the cluster performance. The disk is isolated from the cluster I/O.\nInactive\n\n\nThe service has not responded for some time, but data replication has not started yet. A storage service is marked as inactive during its first 5 minutes of inactivity. \n\nOffline\n\n\nThe service is inactive for more than 5 minutes. After a storage service goes offline, the cluster starts replicating data to restore the chunks that were stored on the affected storage disk.\n\nOut of space\n\nThe disk that runs the service is running out of space.\nReleasing\n\nThe service is being released.\nFailed\n\nThe service is running but a problem has occurred with the storage disk.\nRelease failed\n\nThe service failed to be released.\nEntering maintenance\n\nThe node that hosts the service is entering the maintenance mode.\nMaintenance\n\nThe node that hosts the service is in the maintenance mode. The service is active, but not available for allocating new data chunks.\nUnknown\n\nThe state of the service is unknown.\nDropped\n\nThe service was removed by the administrator.\nUnavailable\n\nThe service is active, but not available for allocating new data chunks.\nUnrecognized\n\nThe service cannot be recognized.\n\n\n\nMetadata service status:\n\nAvailable\n\nThe service is online.\nSyncing\n\nThe service is syncing the cluster metadata.\nUnavailable\n\nThe service is offline.\n\n\n\u00e2\u0080\u0094\n\n\nSystemd\nShows the state of vstorage-csd.<cluster_name>.<CS_ID>.service\n\nShows the state of vstorage-mdsd.<cluster_name>.<MDS_ID>.service\n\n\u00e2\u0080\u0094\n\n\nTier\n\nShows the assigned storage tier\n\n\u00e2\u0080\u0094\n\nShows tiers that are being cached\n\n\n\nService ID\n\nStorage service ID\n\n\nMetadata service ID\n\n\u00e2\u0080\u0094\n\n\nUsage\n\nSpace usage on the disk\n\n\n\nCaching\n\nEnabled/Disabled\n\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\n\nCache location\n\nShows the SSD disk where this disk's write cache is saved to.\n\nDisplayed if caching is enabled.\n\n\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\n\nChecksumming\nEnabled/Disabled\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\n\nEncryption\nEnabled/Disabled\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\u00e2\u0080\u0094\n\n\n\n",
                "title": "To view the service details"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOn the Disks tab, click a node disk, and then go to the Disk tab.\n\nDisk properties include the drive name, state, type, physical capacity, disk protocol, model, serial number, S.M.A.R.T. status, and temperature. A disk can have the following states:\n\nHealthy\n\nThe disk is functioning normally.\nUnavailable\n\nThe disk is powered down or disconnected.\nFailed\n\nThe disk has failed or S.M.A.R.T. reported an error. You need to replace the disk.\n\n",
                "title": "To view the disk details"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOn the Disks tab, click a node disk.\nOn the disk right pane, click Blink.\n\nTo have the disk stop blinking, click Unblink.\n",
                "title": "To have the disk blink its activity LED"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-node-disks.html"
    },
    {
        "title": "Creating S3 users",
        "content": "Creating S3 users\nLimitations\n\nS3 users created in the S3 service cannot log in to the self-service panel.\n\nPrerequisites\n\nThe S3 cluster is created by following the instructions in Creating the S3 cluster.\n\nTo add an S3 user\n\nOn the Storage services > S3 > Users screen, click Create user.\n\nSpecify a valid email address as login for the user, and then click Create.\n\nSee also\n\nEnabling S3 access for the self service\n\nWhat's next\n\nManaging object storage\n\nMonitoring object storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-s3-users.html"
    },
    {
        "title": "Creating backup storage in a public cloud",
        "content": "Creating backup storage in a public cloud\nWith Backup Gateway, you can have Acronis Cyber Protect Cloud or Acronis Cyber Protect store backups in a number of public clouds and on-premises object storage solutions:\n\nAmazon S3\nIBM Cloud\nAlibaba Cloud\nIIJ\nCleversafe\nCloudian\nMicrosoft Azure\nSwift object storage\nSoftlayer (Swift)\nGoogle Cloud Platform\nWasabi\nOther solutions using S3\n\nHowever, compared to the local storage cluster, storing backup data in a public cloud increases the latency of all I/O requests to backups and reduces performance. For this reason, it is recommended to use the local storage cluster as the storage backend.\nBackups are cold data with a specific access pattern: the data is not accessed frequently but is expected to be available immediately when accessed. For this use case, it is cost-efficient to choose storage classes intended for long-term storage with infrequently accessed data. The recommended storage classes include the following:\n\nInfrequent Access for Amazon S3\nCool Blob Storage for Microsoft Azure\nNearline and Coldline storage for Google Cloud Platform\n\nArchive storage classes like Amazon S3 Glacier, Azure Archive Blob, or Google Archive cannot be used for backup because they do not provide instant access to data. High access latency (several hours) makes it technically impossible to browse archives, restore data fast, and create incremental backups. Even though the archive storage is usually very cost-efficient, keep in mind that there are a number of different cost factors. In fact, the total cost of public cloud storage consists of payments for storing data, operations, traffic, data retrieval, early deletion, and so on. For example, an archive storage service can charge six months\u00e2\u0080\u0099 storage payment for just one data recall operation. If the storage data is expected to be accessed more frequently, the added costs increase significantly the total cost of data storage. In order to avoid the low data retrieval rate and to cut expenses, we recommend using Acronis Cyber Protect Cloud for storing backup data.\nLimitations\n\nRedundancy by replication is not supported for backup storage.\nWith external backup destinations, redundancy has to be provided by the external storage. Backup storage does not provide data redundancy or perform data deduplication itself.\n\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nThe storage cluster has at least one disk with the Storage role.\nThe destination storage has enough space for both existing and new backups.\nEnsure that each node to join the backup storage cluster has the TCP port 44445 open for outgoing Internet connections, as well as for incoming connections from Acronis backup software.\n\nTo select a public cloud as the backup destination\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the Backup (ABGW) private and Backup (ABGW) public traffic types are added to the networks you intend to use.\nOpen the Storage services > Backup storage screen, and then click Create backup storage.\nOn the Backup destination step, select Public cloud.\nOn the Nodes step, select nodes to add to the backup storage cluster, and then click Next.\n\nOn the Public cloud step, specify information relevant for your public cloud provider:\n\nSelect a public cloud provider. If your provider is S3 compatible but not in the list, try AuthV2 compatible (S3) or AuthV4 compatible (S3).\nDepending on the provider, specify Region, Authentication (keystone) URL, or Endpoint URL.\nIn the case of Swift object storage, specify the authentication protocol version and attributes required by it.\nSpecify user credentials. In the case of Google Cloud, select a JSON file with keys to upload.\n\nSpecify the folder (bucket, container) to store backups in. The folder must be writeable.\n\nClick Next.\n\nOn the Storage policy step, select the desired tier, failure domain, and data redundancy mode for the local storage. Then, click Next.\n\nOn the DNS step, do one of the following:\n\nSelect Register now, and then specify an external DNS name for backup storage (for example, backupstorage.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data.\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\nSelect Register later to add registrations for your backup storage later or configure it as the secondary cluster for geo-replication.\n\nFor complex environments, HAProxy might be used to build a scalable and redundant load balancing platform, which can be easily moved or migrated and is independent from Virtuozzo Hybrid Infrastructure. For more information, refer to https://kb.acronis.com/content/64787.\n\nIf you selected Register now, specify the following information for your Acronis product on the Acronis account step:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\nOn the Summary step, review the configuration, and then click Create.\n\nAfter creating the backup storage, you can increase its storage capacity at any time by adding space to the public cloud storage.\n\nCommand-line interface\nUse the following command:vinfra service backup cluster deploy-standalone --nodes <nodes> --name <name> --address <address>\r\n                                                [--location <location>] --username <username>\r\n                                                --account-server <account-server>\r\n                                                --tier {0,1,2,3} --encoding <M>+<N> \r\n                                                --failure-domain {0,1,2,3,4}\r\n                                                --storage-type {s3,swift,azure,google}\r\n                                                [--s3-flavor <flavor>]\r\n                                                [--s3-region <region>]\r\n                                                [--s3-bucket <bucket>]\r\n                                                [--s3-endpoint <endpoint>]\r\n                                                [--s3-access-key-id <access-key-id>]\r\n                                                [--s3-secret-key-id <secret-key-id>]\r\n                                                [--s3-cert-verify <cert-verify>]\r\n                                                [--swift-auth-url <auth-url>]\r\n                                                [--swift-auth-version <auth-version>]\r\n                                                [--swift-user-name <user-name>]\r\n                                                [--swift-api-key <api-key>]\r\n                                                [--swift-domain <domain>]\r\n                                                [--swift-domain-id <domain-id>]\r\n                                                [--swift-tenant <tenant>]\r\n                                                [--swift-tenant-id <tenant-id>]\r\n                                                [--swift-tenant-domain <tenant-domain>]\r\n                                                [--swift-tenant-domain-id <tenant-domain-id>]\r\n                                                [--swift-trust-id <trust-id>]\r\n                                                [--swift-region <region>]\r\n                                                [--swift-internal <internal>]\r\n                                                [--swift-container <container>]\r\n                                                [--swift-cert-verify <cert-verify>]\r\n                                                [--azure-endpoint <endpoint>]\r\n                                                [--azure-container <container>]\r\n                                                [--azure-account-name <account-name>]\r\n                                                [--azure-account-key <account-key>]\r\n                                                [--google-bucket <bucket>]\r\n                                                [--google-credentials <credentials>] [--stdin]\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--name <name>\n\nBackup registration name.\n--address <address>\n\nBackup registration address.\n--location <location>\n\nBackup registration location.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--storage-type {local,nfs,s3,swift,azure,google}\n\nStorage type\n--stdin\n\nUse for setting registration password from stdin.\n\nStorage parameters for the s3 storage type:\n\n--s3-flavor <flavor> (optional)\nFlavor name\n--s3-region <region> (optional)\nSet region for Amazon S3.\n--s3-bucket <bucket>\n\nBucket name\n--s3-endpoint <endpoint>\n\nEndpoint URL\n--s3-access-key-id <access-key-id>\n\nAccess key ID\n--s3-secret-key-id <secret-key-id>\n\nSecret key ID\n--s3-cert-verify <cert-verify> (optional)\nAllow self-signed certificate of the S3 endpoint\n\nStorage parameters for the swift storage type:\n\n--swift-auth-url <auth-url>\n\nAuthentication (keystone) URL\n--swift-auth-version <auth-version> (optional)\nAuthentication protocol version\n--swift-user-name <user-name>\n\nUser name\n--swift-api-key <api-key>\n\nAPI key (password)\n--swift-domain <domain> (optional)\nDomain name\n--swift-domain-id <domain-id> (optional)\nDomain ID\n--swift-tenant <tenant> (optional)\nTenant name\n--swift-tenant-id <tenant-id> (optional)\nTenant ID\n--swift-tenant-domain <tenant-domain> (optional)\nTenant domain name\n--swift-tenant-domain-id <tenant-domain-id> (optional)\nTenant domain ID\n--swift-trust-id <trust-id> (optional)\nTrust ID\n--swift-region <region> (optional)\nRegion name\n--swift-container <container> (optional)\nContainer name\n--swift-cert-verify <cert-verify> (optional)\nAllow self-signed certificate of the Swift endpoint (true or false)\n\nStorage parameters for the azure storage type:\n\n--azure-endpoint <endpoint>\n\nEndpoint URL\n--azure-container <container>\n\nContainer name\n--azure-account-name <account-name>\n\nAccount name\n--azure-account-key <account-key>\n\nAccount key\n\nStorage parameters for the google storage type:\n\n--google-bucket <bucket>\n\nGoogle bucket name\n--google-credentials <credentials>\n\nPath to the file with Google credentials\n\nFor example, to create the backup cluster from three nodes on the S3 storage, run:# vinfra service backup cluster deploy-standalone --nodes node001,node002,node003 --name registration1 \\\r\n--address backupstorage.example.com --storage-type s3 --tier 0 --encoding 1+2 --failure-domain host --s3-bucket mybucket \\\r\n--s3-endpoint s3.amazonaws.com --s3-access-key-id e302a06df8adbe9fAIF1 --s3-secret-key-id x1gXquRH<\u00e2\u0080\u00a6> \\\r\n--s3-cert-verify true --username account@example.com --account-server https://cloud.acronis.com/ --stdin\nThis command also specifies the registration name and address, tier, failure domain, registration account and server, as well as the required S3 parameters.\nYou can view the backup storage details in the vinfra service backup cluster show output:# vinfra service backup cluster show\r\n+-----------------+---------------------------------------------+\r\n| Field           | Value                                       |\r\n+-----------------+---------------------------------------------+\r\n| dc_uid          | 966ac53e-a92c-11ec-be79-fa163ea9f01a        |\r\n| deployment_mode | - standalone                                |\r\n| geo_replication |                                             |\r\n| hosts           | - hostname: node001.vstoragedomain          |\r\n|                 |   id: 24a953ce-b50e-40c2-bf44-0668aafb421d  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node002.vstoragedomain          |\r\n|                 |   id: c1de8940-c38a-d7ae-41b5-bdd35581a906  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node003.vstoragedomain          |\r\n|                 |   id: 2307dc2c-a954-70a2-3673-8a8f832bd46a  |\r\n|                 |   systemd: active                           |\r\n| registrations   | - account_server: https://cloud.acronis.com |\r\n|                 |   address: backupstorage.example.com        |\r\n|                 |   expires: '2025-03-20T15:20:59+00:00'      |\r\n|                 |   id: be526718-d9f8-4f2c-9bd3-04a987f7e4c4  |\r\n|                 |   name: registration1                       |\r\n|                 |   type: ABC                                 |\r\n|                 |   username: account@example.com             |\r\n| status          | deployed                                    |\r\n| storage_params  |                                             |\r\n| storage_type    | local                                       |\r\n| upstreams       | []                                          |\r\n+-----------------+---------------------------------------------+\r\n\n\nWhat's next\n\nAdding backup locations to Acronis Cyber Protect and Acronis Cyber Protect Cloud",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup cluster deploy-standalone --nodes <nodes> --name <name> --address <address>\r\n                                                [--location <location>] --username <username>\r\n                                                --account-server <account-server>\r\n                                                --tier {0,1,2,3} --encoding <M>+<N> \r\n                                                --failure-domain {0,1,2,3,4}\r\n                                                --storage-type {s3,swift,azure,google}\r\n                                                [--s3-flavor <flavor>]\r\n                                                [--s3-region <region>]\r\n                                                [--s3-bucket <bucket>]\r\n                                                [--s3-endpoint <endpoint>]\r\n                                                [--s3-access-key-id <access-key-id>]\r\n                                                [--s3-secret-key-id <secret-key-id>]\r\n                                                [--s3-cert-verify <cert-verify>]\r\n                                                [--swift-auth-url <auth-url>]\r\n                                                [--swift-auth-version <auth-version>]\r\n                                                [--swift-user-name <user-name>]\r\n                                                [--swift-api-key <api-key>]\r\n                                                [--swift-domain <domain>]\r\n                                                [--swift-domain-id <domain-id>]\r\n                                                [--swift-tenant <tenant>]\r\n                                                [--swift-tenant-id <tenant-id>]\r\n                                                [--swift-tenant-domain <tenant-domain>]\r\n                                                [--swift-tenant-domain-id <tenant-domain-id>]\r\n                                                [--swift-trust-id <trust-id>]\r\n                                                [--swift-region <region>]\r\n                                                [--swift-internal <internal>]\r\n                                                [--swift-container <container>]\r\n                                                [--swift-cert-verify <cert-verify>]\r\n                                                [--azure-endpoint <endpoint>]\r\n                                                [--azure-container <container>]\r\n                                                [--azure-account-name <account-name>]\r\n                                                [--azure-account-key <account-key>]\r\n                                                [--google-bucket <bucket>]\r\n                                                [--google-credentials <credentials>] [--stdin]\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--name <name>\n\nBackup registration name.\n--address <address>\n\nBackup registration address.\n--location <location>\n\nBackup registration location.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--storage-type {local,nfs,s3,swift,azure,google}\n\nStorage type\n--stdin\n\nUse for setting registration password from stdin.\n\nStorage parameters for the s3 storage type:\n\n--s3-flavor <flavor> (optional)\nFlavor name\n--s3-region <region> (optional)\nSet region for Amazon S3.\n--s3-bucket <bucket>\n\nBucket name\n--s3-endpoint <endpoint>\n\nEndpoint URL\n--s3-access-key-id <access-key-id>\n\nAccess key ID\n--s3-secret-key-id <secret-key-id>\n\nSecret key ID\n--s3-cert-verify <cert-verify> (optional)\nAllow self-signed certificate of the S3 endpoint\n\nStorage parameters for the swift storage type:\n\n--swift-auth-url <auth-url>\n\nAuthentication (keystone) URL\n--swift-auth-version <auth-version> (optional)\nAuthentication protocol version\n--swift-user-name <user-name>\n\nUser name\n--swift-api-key <api-key>\n\nAPI key (password)\n--swift-domain <domain> (optional)\nDomain name\n--swift-domain-id <domain-id> (optional)\nDomain ID\n--swift-tenant <tenant> (optional)\nTenant name\n--swift-tenant-id <tenant-id> (optional)\nTenant ID\n--swift-tenant-domain <tenant-domain> (optional)\nTenant domain name\n--swift-tenant-domain-id <tenant-domain-id> (optional)\nTenant domain ID\n--swift-trust-id <trust-id> (optional)\nTrust ID\n--swift-region <region> (optional)\nRegion name\n--swift-container <container> (optional)\nContainer name\n--swift-cert-verify <cert-verify> (optional)\nAllow self-signed certificate of the Swift endpoint (true or false)\n\nStorage parameters for the azure storage type:\n\n--azure-endpoint <endpoint>\n\nEndpoint URL\n--azure-container <container>\n\nContainer name\n--azure-account-name <account-name>\n\nAccount name\n--azure-account-key <account-key>\n\nAccount key\n\nStorage parameters for the google storage type:\n\n--google-bucket <bucket>\n\nGoogle bucket name\n--google-credentials <credentials>\n\nPath to the file with Google credentials\n\nFor example, to create the backup cluster from three nodes on the S3 storage, run:# vinfra service backup cluster deploy-standalone --nodes node001,node002,node003 --name registration1 \\\r\n--address backupstorage.example.com --storage-type s3 --tier 0 --encoding 1+2 --failure-domain host --s3-bucket mybucket \\\r\n--s3-endpoint s3.amazonaws.com --s3-access-key-id e302a06df8adbe9fAIF1 --s3-secret-key-id x1gXquRH<\u00e2\u0080\u00a6> \\\r\n--s3-cert-verify true --username account@example.com --account-server https://cloud.acronis.com/ --stdin\nThis command also specifies the registration name and address, tier, failure domain, registration account and server, as well as the required S3 parameters.\nYou can view the backup storage details in the vinfra service backup cluster show output:# vinfra service backup cluster show\r\n+-----------------+---------------------------------------------+\r\n| Field           | Value                                       |\r\n+-----------------+---------------------------------------------+\r\n| dc_uid          | 966ac53e-a92c-11ec-be79-fa163ea9f01a        |\r\n| deployment_mode | - standalone                                |\r\n| geo_replication |                                             |\r\n| hosts           | - hostname: node001.vstoragedomain          |\r\n|                 |   id: 24a953ce-b50e-40c2-bf44-0668aafb421d  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node002.vstoragedomain          |\r\n|                 |   id: c1de8940-c38a-d7ae-41b5-bdd35581a906  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node003.vstoragedomain          |\r\n|                 |   id: 2307dc2c-a954-70a2-3673-8a8f832bd46a  |\r\n|                 |   systemd: active                           |\r\n| registrations   | - account_server: https://cloud.acronis.com |\r\n|                 |   address: backupstorage.example.com        |\r\n|                 |   expires: '2025-03-20T15:20:59+00:00'      |\r\n|                 |   id: be526718-d9f8-4f2c-9bd3-04a987f7e4c4  |\r\n|                 |   name: registration1                       |\r\n|                 |   type: ABC                                 |\r\n|                 |   username: account@example.com             |\r\n| status          | deployed                                    |\r\n| storage_params  |                                             |\r\n| storage_type    | local                                       |\r\n| upstreams       | []                                          |\r\n+-----------------+---------------------------------------------+\r\n\n",
                "title": "To select a public cloud as the backup destination"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the Backup (ABGW) private and Backup (ABGW) public traffic types are added to the networks you intend to use.\nOpen the Storage services > Backup storage screen, and then click Create backup storage.\nOn the Backup destination step, select Public cloud.\nOn the Nodes step, select nodes to add to the backup storage cluster, and then click Next.\n\nOn the Public cloud step, specify information relevant for your public cloud provider:\n\nSelect a public cloud provider. If your provider is S3 compatible but not in the list, try AuthV2 compatible (S3) or AuthV4 compatible (S3).\nDepending on the provider, specify Region, Authentication (keystone) URL, or Endpoint URL.\nIn the case of Swift object storage, specify the authentication protocol version and attributes required by it.\nSpecify user credentials. In the case of Google Cloud, select a JSON file with keys to upload.\n\nSpecify the folder (bucket, container) to store backups in. The folder must be writeable.\n\nClick Next.\n\n\n\n\n\n\n\nOn the Storage policy step, select the desired tier, failure domain, and data redundancy mode for the local storage. Then, click Next.\n\n\n\n\n\n\nOn the DNS step, do one of the following:\n\n\nSelect Register now, and then specify an external DNS name for backup storage (for example, backupstorage.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data.\n\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\n\n\n\n\n\n\n\nSelect Register later to add registrations for your backup storage later or configure it as the secondary cluster for geo-replication.\n\n\n\nFor complex environments, HAProxy might be used to build a scalable and redundant load balancing platform, which can be easily moved or migrated and is independent from Virtuozzo Hybrid Infrastructure. For more information, refer to https://kb.acronis.com/content/64787.\n\n\n\nIf you selected Register now, specify the following information for your Acronis product on the Acronis account step:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\n\n\n\n\n\nOn the Summary step, review the configuration, and then click Create.\n\nAfter creating the backup storage, you can increase its storage capacity at any time by adding space to the public cloud storage.\n",
                "title": "To select a public cloud as the backup destination"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-backup-storage-in-a-public-cloud.html"
    },
    {
        "title": "2.2. Configuring the Acronis Agent for VMware\u00c2\u00b6",
        "content": "2.2. Configuring the Acronis Agent for VMware | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n2.2. Configuring the Acronis Agent for VMware\u00c2\u00b6\nAfter creating the agent appliance, start it. In the vSphere Client, open Inventory, right-click the appliance name, and then select Power > Power On. Select the Console tab.\nThe console to the appliance virtual machine will open.\n\nConfigure the agent as follows:\n\n(Optional) Configure a proxy server if you have one in your network:\n\nStart the command shell by pressing CTRL+SHIFT+F2 while in the virtual appliance UI.\nEdit the following section in the file /etc/Acronis/Global.config:\n<key name=\"HttpProxy\">\n<value name=\"Enabled\" type=\"Tdword\">\"1\"</value>\n<value name=\"Host\" type=\"TString\">\"ADDRESS\"</value>\n<value name=\"Port\" type=\"Tdword\">\"PORT\"</value>\n<value name=\"Login\" type=\"TString\">\"LOGIN\"</value>\n<value name=\"Password\" type=\"TString\">\"PASSWORD\"</value>\n</key>\n\n\nIf the section is missing, copy and paste it to the file inside the <registry name=\"Global\">...</registry> tag.\n\nReplace ADDRESS with your proxy server host name or IP address and PORT with the port number.\nIf your proxy server requires authentication, replace LOGIN and PASSWORD with the proxy server credentials. Otherwise, delete these lines.\nLocate (or create) the env section in the file /opt/acronis/etc/aakore.yaml and add the following lines to it:\nhttp-proxy: LOGIN:PASSWORD@ADDRESS:PORT\nhttps-proxy: LOGIN:PASSWORD@ADDRESS:PORT\n\n\nReplace LOGIN and PASSWORD with the proxy server credentials, and ADDRESS:PORT with the address and port number of the proxy server.\nReboot the appliance with reboot.\n\nThe agent\u00e2\u0080\u0099s network connection will be configured automatically via DHCP. To change the default configuration, under AGENT OPTIONS, in eth0, click Change and specify the desired network settings.\n\nUnder AGENT OPTIONS, in vCenter/ESX(i), click Change and specify the vCenter Server name or IP address. The agent will be able to back up and recover any virtual machines managed by the vCenter Server.\nIf you do not use a vCenter Server, specify the name or IP address of the ESXi host whose virtual machines you want to back up and recover. Normally, backups run faster when the agent backs up virtual machines located on its own host.\nSpecify the credentials that the agent will use to connect to the vCenter Server or ESXi. It is recommended to use an account that has the Administrator role assigned. Otherwise, provide an account with the necessary privileges on the vCenter Server or ESXi.\nClick Check connection to ensure the access credentials are correct.\n\nUnder AGENT OPTIONS, in Management Server, click Change.\nIn Server name/IP, select Cloud. The software will display the Cyber Protection service address. Do not change this address unless instructed otherwise.\nIn User name and Password, specify the user name and password for the Cyber Protection service. The agent and the virtual machines managed by the agent will be registered under this account.\n\nUnder VIRTUAL MACHINE, in Time zone, click Change. Select the time zone of your location to ensure that the scheduled operations run at the appropriate time.\n\nOptionally, you can attach an additional disk to the virtual appliance so the Acronis Agent for VMware can back up to this locally attached storage.\nAdd the disk by editing the settings of the virtual machine and click Refresh. The Create storage link will become available. Click this link, select the disk, and then specify a label for it.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-acronis-agent-for-vmware-from-ovf-template/configuring-acronis-agent-for-vmware.html"
    },
    {
        "title": "Provisioning Kubernetes clusters",
        "content": "Provisioning Kubernetes clusters\nThe Kubernetes service allows you to deploy scalable and production-ready Kubernetes clusters with preintegrated persistent storage. \nA Kubernetes cluster includes the following components:\n\nUnderlying OS: Fedora 39 CoreOS\nContainer runtime: containerd 1.6.23\nNetwork plugin:Flannel VXLAN (for public VM networks)Flannel host-gw (for private VM networks)\n\nKubernetes clusters are created and managed by self-service users.\r\nHowever, to provide self-service users with this functionality, you need to install the Kubernetes service in the admin panel. \nLimitations\n\nIn the current version of Virtuozzo Hybrid Infrastructure, the installed service cannot be removed.\n\nIf you install the service after creating a project, Kubernetes clusters are not automatically enabled in the project quotas.\nInstalling Kubernetes automatically installs the load balancer service, as well.\nThe maximum number of Kubernetes clusters supported per project is 20.\n\nPrerequisites\n\nAccording to the requirements listed in Kubernetes-as-a-Service network requirementsThe etcd discovery service must be accessible at https://discovery.etcd.io from all management nodes and the public network with the VM public traffic type.The public Docker Hub repository must be accessible at https://registry-1.docker.io from the public network with the VM public traffic type.The compute API must be accessible from the public network with the VM public traffic type.The Kubernetes API must be accessible at the public or floating IP address of the Kubernetes load balancer or master VM on port 6443 from all management nodes.If the Compute API traffic type is added to a private network that is inaccessible directly from the network with the VM public traffic type, but exposed to public networks via NAT and available publicly via the DNS name, you need to set the DNS name for the compute API, as described in Setting a DNS name for the compute API.\nThe compute cluster is created, as described in Creating the compute cluster.\n\nTo install the Kubernetes service\n\nAdmin panel\n\nGo to the Settings > Add-on services screen. \nIn the Kubernetes service section, click Install.\n\nInstalling Kubernetes automatically installs the load balancer service as well.\n\nCommand-line interface\nRun the following command:# vinfra service compute set --enable-k8saas\n\nWhat's next\n\nManaging Kubernetes clusters",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nRun the following command:# vinfra service compute set --enable-k8saas\n",
                "title": "To install the Kubernetes service"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Settings > Add-on services screen. \nIn the Kubernetes service section, click Install.\n\n\nInstalling Kubernetes automatically installs the load balancer service as well.\n\n",
                "title": "To install the Kubernetes service"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-kubernetes.html"
    },
    {
        "title": "Changing virtual CPU overcommitment",
        "content": "Changing virtual CPU overcommitment\nYou can configure the number of virtual CPUs that can be provisioned for virtual machines by setting the vCPU overcommitment ratio on a particular node or on all of the compute nodes. This is the ratio of the number of virtual CPUs to physical. The default ratio is 8, which means that you can provision eight times over the number of physical CPUs available on a compute node. By increasing the ratio on a compute node, you can increase the number of virtual machines running on this node but potentially reduce their performance.\nTo change vCPU overcommitment per cluster\nUse the command vinfra service compute set with the --nova-compute-cpu-allocation-ratio option. For example, to set the vCPU overcommitment ratio to 16, run:# vinfra service compute set --nova-compute-cpu-allocation-ratio 16.0\nTo check that the ratio is successfully modified, execute the vinfra service compute show command:# vinfra service compute show\r\n+--------------+-------------------------------------------+\r\n| Field        | Value                                     |\r\n+--------------+-------------------------------------------+\r\n| <...>        | <...>                                     |\r\n| options      | cpu_model: ''                             |\r\n|              | custom_params:                            |\r\n|              | - config_file: nova.conf                  |\r\n|              |   property: cpu_allocation_ratio          |\r\n|              |   section: DEFAULT                        |\r\n|              |   service_name: nova-compute              |\r\n|              |   value: 16.0                             |\r\n| <...>        | <...>                                     |\r\n+--------------+-------------------------------------------+\r\n\nTo change vCPU overcommitment per node\nUse the command vinfra service compute set with the --nova-compute-cpu-allocation-ratio option and specify particular nodes with the --nodes option. For example, to set the vCPU overcommitment ratio to 16 on the node node001, run:# vinfra service compute set --nova-compute-cpu-allocation-ratio 16.0 --nodes node001\nTo check that the ratio is successfully modified, execute the vinfra service compute node show command:# vinfra service compute node show node001\r\n+----------------+------------------------------------------+\r\n| Field          | Value                                    |\r\n+----------------+------------------------------------------+\r\n| custom_params  | - config_file: nova.conf                 |\r\n|                |   property: cpu_allocation_ratio         |\r\n|                |   section: DEFAULT                       |\r\n|                |   service_name: nova-compute             |\r\n|                |   value: 16.0                            |\r\n| fenced_reason  |                                          |\r\n| host           | node001.vstoragedomain                   |\r\n| <...>          | <...>                                    |\r\n+----------------+------------------------------------------+\nTo disable vCPU overcommitment per cluster\nChange the ratio to 1 by running:# vinfra service compute set --nova-compute-cpu-allocation-ratio 1\nTo disable vCPU overcommitment per node\nChange the node overcommitment ratio to the default cluster value by setting it to 0:# vinfra service compute set --nova-compute-cpu-allocation-ratio 0 --node node001\nSee also\n\nChanging parameters in OpenStack configuration files\n\nConfiguring memory for virtual machines\n\nConfiguring CPU features for virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-vcpu-overcommitment.html"
    },
    {
        "title": "Quota management",
        "content": "Quota management\nThis section describes storage usage quotas that can be defined for S3 users and buckets.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/quota-management.html"
    },
    {
        "title": "Creating virtual networks",
        "content": "Creating virtual networksPOST /v2.0/networks\r\n\nCreate a network.\nThe next step is to create a subnet for the network ID, as described in Creating virtual subnets.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-network-detail#create-network\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nnetwork\n\nbody\nobject\nA network object.\n\nadmin_state_up (Optional)\nbody\nboolean\nThe administrative state of the network, which is\r\nup (true) or down (false).\n\navailability_zone_hints (Optional)\nbody\narray\nThe availability zone candidate for the network.\n\ndns_domain (Optional)\nbody\nstring\nA valid DNS domain.\n\nmtu (Optional)\nbody\ninteger\nThe maximum transmission unit (MTU) value to\r\naddress fragmentation. Minimum value is 68 for IPv4, and 1280 for\r\nIPv6.\n\nname (Optional)\nbody\nstring\nHuman-readable name of the network.\n\nport_security_enabled (Optional)\nbody\nboolean\nThe port security status of the network. Valid values are\r\nenabled (true) and disabled (false).\r\nThis value is used as the default value of port_security_enabled\r\nfield of a newly created port.\n\nproject_id (Optional)\nbody\nstring\nThe ID of the project that owns the resource.\r\nOnly administrative and users with advsvc role can specify\r\na project ID other than their own.\r\nYou cannot change this value through authorization policies.\n\nprovider:network_type (Optional)\nbody\nstring\nThe type of physical network that this network should be mapped to.\r\nFor example, flat, vlan, vxlan, or gre.\r\nValid values depend on a networking back-end.\n\nprovider:physical_network (Optional)\nbody\nstring\nThe physical network where this network should be implemented.\r\nThe Networking API v2.0 does not provide a way to list available\r\nphysical networks. For example, the Open vSwitch plug-in configuration\r\nfile defines a symbolic name that maps to specific bridges on each\r\ncompute host.\n\nprovider:segmentation_id (Optional)\nbody\ninteger\nThe ID of the isolated segment on the physical network.\r\nThe network_type attribute defines the segmentation model.\r\nFor example, if the network_type value is vlan, this ID is a vlan\r\nidentifier. If the network_type value is gre, this ID is a gre key.\n\nqos_policy_id (Optional)\nbody\nstring\nThe ID of the QoS policy associated with the network.\n\nrouter:external (Optional)\nbody\nboolean\nIndicates whether the network has an external routing facility that\u00e2\u0080\u0099s not\r\nmanaged by the networking service.\n\nsegments (Optional)\nbody\narray\nA list of provider segment objects.\n\nshared (Optional)\nbody\nboolean\nIndicates whether this resource is shared across all projects.\r\nBy default, only administrative users can change this value.\n\ntenant_id (Optional)\nbody\nstring\nThe ID of the project that owns the resource.\r\nOnly administrative and users with advsvc role can specify\r\na project ID other than their own.\r\nYou cannot change this value through authorization policies.\n\nvlan_transparent (Optional)\nbody\nboolean\nIndicates the VLAN transparency mode of the network, which is\r\nVLAN transparent (true) or not VLAN transparent (false).\n\ndefault_vnic_type (Optional)\nbody\nstring\nSets the vnic_type parameter for each virtual port that will be created in this network, if vnic_type is not specified explicitly. The valid values are direct, direct-physical, normal, macvtap, baremetal, virtio-forwarder, and smart-nic.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the network.\r\nDefault is an empty string.\n\nis_default (Optional)\nbody\nboolean\nThe network is default or not.\n\nExample 1\nCreate a private virtual network:# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"network\": {\r\n        \"name\": \"privnet1\",\r\n        \"port_security_enabled\": true\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/networks\r\n\nExample 2\nCreate a public virtual network bound to a physical network:# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"network\": {\r\n    \"name\": \"net2\",\r\n    \"port_security_enabled\": true,\r\n    \"provider:physical_network\": \"Public\",\r\n    \"provider:network_type\": \"flat\",\r\n    \"shared\": true\r\n  }\r\n}' https://<node_IP_addr>:9696/v2.0/networks\r\n\nYou can find out the physical network name from /etc/kolla/neutron-openvswitch-agent/ml2_conf.ini. For example:# cat /etc/kolla/neutron-openvswitch-agent/ml2_conf.ini | grep bridge_mappings\r\nbridge_mappings = Public:br-eth0\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nnetwork\n\nbody\nobject\nA network object.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the network, which is\r\nup (true) or down (false).\n\navailability_zone_hints\n\nbody\narray\nThe availability zone candidate for the network.\n\navailability_zones\n\nbody\narray\nThe availability zone for the network.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\nid\n\nbody\nstring\nThe ID of the network.\n\nipv4_address_scope\n\nbody\nstring\nThe ID of the IPv4 address scope that the network is associated with.\n\nipv6_address_scope\n\nbody\nstring\nThe ID of the IPv6 address scope that the network is associated with.\n\nl2_adjacency\n\nbody\nboolean\nIndicates whether L2 connectivity is available throughout\r\nthe network.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to\r\naddress fragmentation. Minimum value is 68 for IPv4, and 1280 for\r\nIPv6.\n\nname\n\nbody\nstring\nHuman-readable name of the network.\n\nport_security_enabled\n\nbody\nboolean\nThe port security status of the network. Valid values are\r\nenabled (true) and disabled (false).\r\nThis value is used as the default value of port_security_enabled\r\nfield of a newly created port.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nprovider:network_type\n\nbody\nstring\nThe type of physical network that this network is mapped to.\r\nFor example, flat, vlan, vxlan, or gre.\r\nValid values depend on a networking back-end.\n\nprovider:physical_network\n\nbody\nstring\nThe physical network where this network/segment is implemented.\n\nprovider:segmentation_id\n\nbody\ninteger\nThe ID of the isolated segment on the physical network.\r\nThe network_type attribute defines the segmentation model.\r\nFor example, if the network_type value is vlan, this ID is a vlan\r\nidentifier. If the network_type value is gre, this ID is a gre key.\n\nqos_policy_id\n\nbody\nstring\nThe ID of the QoS policy associated with the network.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the network.\n\nrouter:external\n\nbody\nboolean\nIndicates whether the network has an external routing facility that\u00e2\u0080\u0099s not\r\nmanaged by the networking service. If the network is updated from external\r\nto internal the unused floating IPs of this network are automatically\r\ndeleted when extension floatingip-autodelete-internal is present.\n\nsegments\n\nbody\narray\nA list of provider segment objects.\n\nshared\n\nbody\nboolean\nIndicates whether this network is shared across all tenants. By default,\r\nonly administrative users can change this value.\n\nstatus\n\nbody\nstring\nThe network status. Values are ACTIVE, DOWN, BUILD or ERROR.\n\nsubnets\n\nbody\narray\nThe associated subnets.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvlan_transparent\n\nbody\nboolean\nIndicates the VLAN transparency mode of the network, which is\r\nVLAN transparent (true) or not VLAN transparent (false).\n\ndefault_vnic_type\n\nbody\nstring\nThe default value of the vnic_type parameter for each virtual port created in this network.\n\ndescription\n\nbody\nstring\nA human-readable description for the network.\n\nis_default\n\nbody\nboolean\nThe network is default pool or not.\n\ntags\n\nbody\narray\nThe list of tags on the network.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample 1\nCreate a private virtual network:{\r\n  \"network\": {\r\n    \"provider:physical_network\": null,\r\n    \"ipv6_address_scope\": null,\r\n    \"revision_number\": 1,\r\n    \"port_security_enabled\": true,\r\n    \"provider:network_type\": \"vxlan\",\r\n    \"id\": \"c5252a20-9206-4b8e-9a0f-45bd22ee7bc8\",\r\n    \"router:external\": false,\r\n    \"availability_zone_hints\": [],\r\n    \"availability_zones\": [],\r\n    \"ipv4_address_scope\": null,\r\n    \"shared\": false,\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"status\": \"ACTIVE\",\r\n    \"subnets\": [],\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"updated_at\": \"2020-02-14T13:36:11Z\",\r\n    \"is_default\": false,\r\n    \"provider:segmentation_id\": 5,\r\n    \"name\": \"privnet1\",\r\n    \"admin_state_up\": true,\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-02-14T13:36:11Z\",\r\n    \"mtu\": 1450\r\n  }\r\n}\nExample 2\nCreate a public virtual network:{\r\n  \"network\": {\r\n    \"provider:physical_network\": \"Public\",\r\n    \"ipv6_address_scope\": null,\r\n    \"revision_number\": 1,\r\n    \"port_security_enabled\": true,\r\n    \"provider:network_type\": \"flat\",\r\n    \"id\": \"c5a5d68e-55cd-40b8-a272-3768cbb86bd1\",\r\n    \"router:external\": false,\r\n    \"availability_zone_hints\": [],\r\n    \"availability_zones\": [],\r\n    \"ipv4_address_scope\": null,\r\n    \"shared\": true,\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"status\": \"ACTIVE\",\r\n    \"subnets\": [],\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"updated_at\": \"2020-02-17T11:27:17Z\",\r\n    \"is_default\": false,\r\n    \"provider:segmentation_id\": null,\r\n    \"name\": \"net2\",\r\n    \"admin_state_up\": true,\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-02-17T11:27:17Z\",\r\n    \"mtu\": 1500\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-virtual-networks.html"
    },
    {
        "title": "Modifying and deleting load balancers",
        "content": "Modifying and deleting load balancers\nTo edit the name or description of a load balancer\n\nOn the Load balancers screen, click a load balancer you want to edit.\nOn the load balancer right pane, click Edit.\n\nIn the Edit load balancer window, modify the name or description, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nTo disable or enable a load balancer\n\nOn the Load balancers screen, click a load balancer you want to change.\nOn the load balancer right pane, click Disable or Enable, depending on the load balancer's current state.\n\nTo remove a load balancer\n\nOn the Load balancers screen, click a load balancer to delete.\nOn the load balancer right pane, click Delete.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/modifying-and-deleting-load-balancers.html"
    },
    {
        "title": "General requirements",
        "content": "General requirements\nVerify that all servers to be joined to the cluster meet the following general requirements.\nStorage requirements\nThe following table lists the minimum and recommended storage requirements according to the disk roles (refer to About the storage cluster):\n\nDisk role\nQuantity\nDisk size\nType\nEndurance\n\nSystem\nOne disk per node\n\n100 GB minimum\n250 GB recommended\n\nSATA/SAS HDD minimum\nSATA/SAS SSD recommended\n\n\u00e2\u0080\u0094\n\nMetadata\n\nOne disk per node\nFive disks recommended for one cluster\n\n100 GB\nEnterprise-grade SSD with power loss protection\n1 DWPD minimum\n\nCache\n\nOptional\nOne SSD disk per 4-12 HDDs\n\n100+ GB\nEnterprise-grade SSD with power loss\r\nprotection and 75 MB/s sequential write performance per serviced HDD\n\n1 DWPD minimum\n10 DWPD recommended\n\nStorage\nAt least one per cluster\n\n100 GB minimum\nUnlimited size on a physical server; 10 TB maximum recommended inside a virtual machine\n\n SATA/SAS HDD or enterprise-grade SATA/SAS/NVMe SSD with power loss protection\n1 DWPD minimum\n\nCPU and RAM reservations\nThe following table lists the amount of RAM and CPU cores that will be reserved on one node, according to the services you will use:\n\nService\nManagement node \nSecondary node\n\nRAM1 Use only Error correction code (ECC) memory, to avoid data corruption.\nCPU cores2 A CPU core here is a physical core in a multicore processor (hyperthreading is not taken into account).\nRAM3 Use only Error correction code (ECC) memory, to avoid data corruption.\nCPU cores4 A CPU core here is a physical core in a multicore processor (hyperthreading is not taken into account).\n\nSystem\n4.5 GB\n1 core\n1.5 GB\n1 core\n\nStorage services: each disk with Metadata, Storage, or Cache role (any size)5 For clusters larger than 1 PB of physical space, add 0.5 GB of RAM per Metadata service.\n0.5 GB\n0.2 cores\n0.5 GB\n0.2 cores\n\nCompute6 The recommended configuration for a compute cluster node starts with 64+ GB and 16+ cores.\nService\n8 GB\n1 core\n\u00a0\n\u00a0\n\nEach virtual machine\n128 MB\n\u00a0\n128 MB\n\u00a0\n\nDatabase cache\nup to 10% of node RAM\n\u00a0\n\u00a0\n\u00a0\n\nLoad balancer (add-on service)\n1.5 GB\n0.5 cores\n\u00a0\n\u00a0\n\nKubernetes (add-on service)\n1 GB\n0.5 cores\n\u00a0\n\u00a0\n\nMetering (add-on service)\n3 GB\n1 core\n\u00a0\n\u00a0\n\nBackup Gateway7 When working with public clouds and NFS, Backup Gateway consumes as much RAM and CPU as with a local storage.\n1 GB\n0.5 cores\n1 GB\n0.5 cores\n\nS38 By default, each S3 node runs 4 S3 gateways and can run up to 10 NS and 10 OS instances, but the entire S3 cluster cannot host more than 24 OS and 16 NS instances. The number of OS and NS services is defined during the initial S3 cluster setup. Adding more nodes to the S3 cluster does not affect it. The CPU and RAM reservations depend on the number of S3 nodes. Generally, the larger the S3 cluster, the less resources are reserved on each node.\nEach S3 gateway\n256 MB\n1 core\n256 MB\n1 core\n\nEach OS service\n256 MB\n0.1 cores\n256 MB\n0.1 cores\n\nEach NS service\n512 MB\n0.2 cores\n512 MB\n0.2 cores\n\nNFS\nService\n4 GB\n1 core\n4 GB\n1 core\n\nEach share9 The RAM reservation for an NFS share depends on the number of cluster nodes. The larger the NFS cluster, the less RAM is reserved on each node.\nup to 9 GB\nup to 8 cores\nup to 9 GB\nup to 8 cores\n\niSCSI\n1 GB\n1 core\n1 GB\n1 core\n\nThese reserved values correspond to absolute minimum requirements. In general, the more resources you provide for your cluster, the better it works. All extra RAM is used to cache disk reads, while extra CPU cores increase the performance and reduce latency. \nCPU and RAM limits\nThe following table lists the current RAM and CPU limits for Virtuozzo Hybrid Infrastructure servers:\n\nHardware\nTheoretical\nCertified\n\nRAM\n64 TB\n1 TB\n\nCPU\n5120 logical CPUs10 A logical CPU is a core (thread) in a multicore (multithreading) processor.\n384 logical CPUs11 A logical CPU is a core (thread) in a multicore (multithreading) processor.\n\nCPU recommendations\n\nThe minimum CPU frequency for Virtuozzo Hybrid Infrastructure servers is 2.0 GHz. The recommended CPU frequency is at least 2.4 GHz.\nCPU frequency affects the cluster performance. Higher CPU frequency reduces latency almost linearly, thus increasing the performance. If other CPU parameters are the same, higher CPU frequency is preferable to a larger number of CPU cores.\nNodes running the metadata service should have high CPU frequency, because this service is CPU intensive.\nTo improve erasure coding performance, it is recommended to use CPUs that support the AVX-512 instruction set, such as Intel Xeon Silver 4110, Intel Xeon Gold 5115, Intel Xeon Platinum 8171, or newer.\n\nNetwork interface requirements\nAt least 2 x 10 GbE interfaces are recommended, for internal and external traffic; 25 GbE, 40 GbE, and 100 GbE are even better. Bonding is recommended. However, for external traffic, you can start with 1 GbE links, but they can limit cluster throughput on modern loads.\nSee also\n\nQuantity of servers\n\nConsiderations for using blade servers\n\nAcronis Backup Storage requirements\n\nCompute cluster requirements\n\nObject storage requirements",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/general-requirements.html"
    },
    {
        "title": "Releasing nodes from the storage cluster",
        "content": "Releasing nodes from the storage cluster\nTo release a node means to remove it from the storage cluster. Once you initiate the release, the storage cluster will start replicating data chunks that were stored on the released node, and then distributing them among other storage nodes in the cluster. Depending on the amount of data to replicate, the process may take as much as several hours. If necessary, you can also release a node forcibly, that is, without replication.\n\nReleasing nodes forcibly may result in data loss.\n\nPrerequisites\n\nIf the node runs one of the three required metadata services, the metadata role must be added to another node. You need to ensure that the cluster has at least three metadata services running at any time.\nIf the node has any access points, the same access points are configured on other nodes in the cluster as well.\nIf the node is in an iSCSI target group, it must be removed from the target group first.\nIf the node has an S3 or backup gateway, the node IP addresses must be removed from the DNS records of S3 and Backup Gateway access points. Next, the node should be released from the S3 and Backup Gateway clusters.\nIf the node is in the compute cluster, it must be removed from the compute cluster.\nThe cluster has enough storage space to accommodate the data from the released node.\n\nTo release a node from the storage cluster\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the line with the node to release.\nOn the right pane, click Release node.\n(Optional, highly not recommended) To release the node without data migration, select Release without data migration.\nClick Release. \n\nThe released node will be displayed as Unassigned on the Infrastructure > Nodes screen.\n\nCommand-line interface\nUse the following command:vinfra node release [--force] <node>\r\n\n\n--force\n\nRelease node without data migration\n<node>\n\nNode ID or hostname\n\nFor example, to release the node node005 from the storage cluster with migration of data to maintain the set redundancy mode, run:# vinfra node release node005\n\nWhat's next\n\nRemoving unassigned nodes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node release [--force] <node>\r\n\n\n--force\n\nRelease node without data migration\n<node>\n\nNode ID or hostname\n\nFor example, to release the node node005 from the storage cluster with migration of data to maintain the set redundancy mode, run:# vinfra node release node005\n",
                "title": "To release a node from the storage cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the line with the node to release.\nOn the right pane, click Release node.\n(Optional, highly not recommended) To release the node without data migration, select Release without data migration.\nClick Release. \n\nThe released node will be displayed as Unassigned on the Infrastructure > Nodes screen.\n",
                "title": "To release a node from the storage cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/releasing-storage-nodes.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Storage User Guide\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nStorage User Guide\n\nHome\n\nContents\n\nIndex\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureStorage User Guide\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/index.html"
    },
    {
        "title": "Generating S3 user access keys via REST API",
        "content": "Generating S3 user access keys via REST API\nYou can generate a new or additional access key pair for the specified user by sending a POST request to the ostor-users service along with the user email address and the genKey parameter:# s3_curl POST \"http://s3.example.com/?ostor-users&emailAddress=user@example.com&genKey\"\r\n{\r\n    \"UserEmail\": \"user@example.com\",\r\n    \"UserId\": \"ca55631f9f3d59dc\",\r\n    \"AWSAccessKeys\": [\r\n        {\r\n            \"AWSAccessKeyId\": \"ca55631f9f3d59dcZMDX\",\r\n            \"AWSSecretAccessKey\": \"ffWvnOcNiH0jkQod4huv51BMYBuSWs4zRLFVwd4d\"\r\n        }\r\n    ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/generating-s3-user-access-keys-via-rest-api.html"
    },
    {
        "title": "Recovering nodes",
        "content": "Recovering nodes\nInformation about storage services is stored on a system disk and may be lost in case of a system disk failure. If this happens, you can recover the system disk and the node configuration by reinstalling the product from an ISO image in the recovery mode. The recovery mode provides basic troubleshooting steps when a node fails to boot.\nDuring the recovery process, the configuration of deployed services and infrastructure is automatically detected and recovered from storage disks.\nLimitations\n\nSingle-node clusters cannot be recovered.\nManagement nodes with disabled high availability cannot be recovered.\nThe configuration of the compute, iSCSI, S3, and NFS services cannot be automatically recovered. For the manual recovery, contact the technical support.\nRecovery is only possible if the node hardware configuration has not been changed.\nThe primary management node can only be recovered during an upgrade.\nRemote iSCSI devices that are attached to cluster nodes as storage disks cannot be recovered. Data stored on such devices will be lost.\n\nTo recover a node\n\nBefore recovering a node, place the node into the maintenance mode to evacuate services and virtual machines from the node. To do this, click Enter maintenance on the node right pane.\nPrepare the bootable media by using the distribution ISO image, as described in Preparing the bootable media.\nAttach the bootable media to the node, and then reboot the node.\nConfigure the node to boot from the chosen media.\n\nReinstall Virtuozzo Hybrid Infrastructure on the node:\n\nOn the welcome screen, click Troubleshooting\u00e2\u0080\u0093>, and then Recover - Node recovery.\nOn step 1, accept the End-User License Agreement by selecting I accept the End-User License Agreement, and then click Next.\nOn step 2, specify the current network configuration for this node, and then click Next.\nOn step 3, choose the correct time zone, and then click Next.\nOn step 4, select No, add it to an existing cluster, and specify the private IP address of the management node and the token, obtained on the Infrastructure > Nodes > Connect node screen. Then, click Next.\nOn step 5, choose the system disk for reinstalling the operating system, and then click Next.\nOn step 6, enter and confirm the password for the root account, and then click Start installation.\n\nOnce the installation is complete and the node is rebooted, the recovery script will be executed automatically. Wait until the node recovery is finished.\n\nIf a node has the iSCSI, S3, or NFS services deployed:\n\nRelease the node from these services.\nReturn the node to operation by exiting the maintenance mode.\nRejoin the node to the relevant services.\n\nIf a node has the compute services deployed:\n\nThe recovery process fails when a network with the VM public traffic type does not include the Internal management traffic type. This happens because this network is not reassigned to a public interface after the product reinstallation. In this case, do the following:\n\nGo to the node's Network interfaces tab in the admin panel.\nAssign the network with the VM public traffic type to your public interface.\nOn the node pane, click Retry recovery.\n\nReturn the node to operation by exiting the maintenance mode.\nGo to Settings > System settings > Management node high availability and destroy the HA configuration.\nOn the Compute > Nodes screen, release the node from the compute cluster, and then add it again.\nRe-create the HA configuration.\n\nIf a node is not included in the compute cluster but is a part of the HA configuration, go to Settings > System settings > Management node high availability and do one of the following:\n\nIf the cluster has spare nodes for replacement, replace the node in HA configuration.\nIf the cluster has no spare nodes for replacement, destroy the HA configuration, and then re-create it.\n\nIf the node recovery fails\n\nOn the node right pane, click Retry recovery to repeat the attempt to recover the node.\nOn the node right pane, click Cancel recovery to wipe out and re-import disks on the node.\n\nSee also\n\nPerforming node maintenance\n\nInstalling updates\n\nTroubleshooting installation",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/recovering-nodes.html"
    },
    {
        "title": "Replacing node disks",
        "content": "Replacing node disks\nWhen a disk fails, data replication begins immediately and automatically, and finishes when the disk becomes healthy again. This might take some time depending on the cluster configuration. In case of a disk failure, the cluster administrator should determine whether this failure is due to a temporary or permanent condition:\n\nIf the condition is temporary (for example, a physical disconnection), you can try keeping a failed disk in the cluster and avoid replacing it. After fixing the issue, you can mark the disk as healthy. If successful, the cluster can be considered to be in a normal operating state.\nIf the condition is permanent, it is recommended to release and replace the disk as soon as possible. A failed disk can potentially lead to several issues, especially if the cluster does not have enough available resources, such as degraded performance, lack of space, inability to restore data redundancy, and other.\n\nTo replace a disk with a new disk, you need to release the old one from the storage cluster. If the new disk contains any data, the disk will not be considered suitable for use in the storage cluster.\nAfter the replacement, you will need to assign the role of the released disk to the new one:\n\nThe Storage role will be assigned automatically if you enabled automatic configuration of new disks before a disk failure.\nAll other roles need to be assigned by hand.\n\nPrerequisites\n\nThe disk failure has been troubleshooted, as described in Troubleshooting node disks.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/replacing-node-disks.html"
    },
    {
        "title": "2. What is BitNinja?\u00c2\u00b6",
        "content": "2. What is BitNinja? | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n2. What is BitNinja?\u00c2\u00b6\nBitNinja is an easy-to-use, security-as-a-service modular and multi-layered server security defense tool. It protects your server from hackers, botnets, attackers, and malicious activities with minimal effort and maintenance required from your side.\nBitNinja\u00e2\u0080\u0099s modular security approach, means that each module is designed to prevent, identify and mitigate different types of attacks (or intrusions) in order to keep your servers Safe. Once the BitNinja agent is installed on the workload you wish to protect, BitNinja will actively monitor your incoming and outgoing network traffic, and defend your Servers against already known attacking IPs found in their large IP Reputation pool containing millions of these addresses, and badly behaving new ones.\nThe BitNinja agent also has a Malware Scanner module for detecting already existing infected files on the installed server. BitNinja is also equipped with a WAF module for stopping incoming attacks directed at known vulnerabilities in Web Applications, for example, SQL injections, remote and local file inclusions and other attacks.\nThese are just a few of the modules that BitNinja uses to defend your servers against hackers. You can find all of their available modules listed on their documentation page here: https://docs.bitninja.io/docs/modules/sqlcleaning/.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/what-is-bitninja.html"
    },
    {
        "title": "Managing volumes in backup plans",
        "content": "Managing volumes in backup plans\nYou can manage compute volumes that you want to back up by adding them to or removing them from your backup plans. After removing a volume from a backup plan, all backups that have been already created remain intact.\nPrerequisites\n\nA backup plan is created, as described in Creating backup plans.\n\nTo add volumes to a backup plan\n\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, navigate to the Volumes to back up tab. All the compute volumes included in the backup plan will be shown here.\nClick Manage above the list of volumes.\nIn the Manage volumes window, select volumes that you want to back up, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra service compute backup-plan volume add <backup-plan> [<backup-plan-volume> ...]\n\n<backup-plan>\n\n        Backup plan ID or name\n<backup-plan-volume>\n\nVolume ID\n\nFor example, to add the volume with the ID 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b to the backup plan myplan, run:# vinfra service compute backup-plan volume add myplan 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b\nThe added volume will appear in the vinfra service compute backup-plan volume list output:# vinfra service compute backup-plan volume list myplan\r\n+-------------+------------------------+------+--------+----------------------------------+---------------------+\r\n| id          | name                   | size | status | project_id                       | storage_policy_name |\r\n+-------------+------------------------+------+--------+----------------------------------+---------------------+\r\n| 3b12cb5b<\u00e2\u0080\u00a6> | volume1                | 100  | in-use | 70eff98528054d0b95a8936bfa4aa2a3 | default             |\r\n| 5a66c317<\u00e2\u0080\u00a6> | vm1/cirros/Boot volume | 1    | in-use | d0460058ccc04936b81b0653e490a121 | default             |\r\n+-------------+------------------------+------+--------+----------------------------------+---------------------+\n\nTo remove volumes from a backup plan\n\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, navigate to the Volumes to back up tab. All the compute volumes included in the backup plan will be shown here.\nClick Manage above the list of volumes.\nIn the Manage volumes window, remove the selection from volumes that you do not want to back up. To see only the volumes assigned to the backup plan, select Show only selected items next to the Search field. Then, click Save.\n\nCommand-line interface\nUse the following command:vinfra service compute backup-plan volume remove <backup-plan> [<backup-plan-volume-id> ...]\n<backup-plan>\n        Backup plan ID or name\n<backup-plan-volume>\n\nVolume ID\n\nFor example, to remove the volume with the ID 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b from the backup plan myplan, run:# vinfra service compute backup-plan volume remove myplan 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b\nThe removed volume will disappear in the vinfra service compute backup-plan volume list output.\n\nSee also\n\nViewing backup plan history\n\nEditing and deleting backup plans\n\nRestoring volumes from backups\n\nRestoring virtual machines from backups\n\nCreating and deleting backups manually",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute backup-plan volume add <backup-plan> [<backup-plan-volume> ...]\n\n<backup-plan>\n\n        Backup plan ID or name\n<backup-plan-volume>\n\nVolume ID\n\nFor example, to add the volume with the ID 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b to the backup plan myplan, run:# vinfra service compute backup-plan volume add myplan 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b\nThe added volume will appear in the vinfra service compute backup-plan volume list output:# vinfra service compute backup-plan volume list myplan\r\n+-------------+------------------------+------+--------+----------------------------------+---------------------+\r\n| id          | name                   | size | status | project_id                       | storage_policy_name |\r\n+-------------+------------------------+------+--------+----------------------------------+---------------------+\r\n| 3b12cb5b<\u00e2\u0080\u00a6> | volume1                | 100  | in-use | 70eff98528054d0b95a8936bfa4aa2a3 | default             |\r\n| 5a66c317<\u00e2\u0080\u00a6> | vm1/cirros/Boot volume | 1    | in-use | d0460058ccc04936b81b0653e490a121 | default             |\r\n+-------------+------------------------+------+--------+----------------------------------+---------------------+\n",
                "title": "To add volumes to a backup plan"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute backup-plan volume remove <backup-plan> [<backup-plan-volume-id> ...]\n<backup-plan>\n        Backup plan ID or name\n<backup-plan-volume>\n\nVolume ID\n\nFor example, to remove the volume with the ID 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b from the backup plan myplan, run:# vinfra service compute backup-plan volume remove myplan 3b12cb5b-ce30-4ce4-97a5-4535b03fe43b\nThe removed volume will disappear in the vinfra service compute backup-plan volume list output.\n",
                "title": "To remove volumes from a backup plan"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, navigate to the Volumes to back up tab. All the compute volumes included in the backup plan will be shown here.\nClick Manage above the list of volumes.\nIn the Manage volumes window, select volumes that you want to back up, and then click Save.\n\n",
                "title": "To add volumes to a backup plan"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, navigate to the Volumes to back up tab. All the compute volumes included in the backup plan will be shown here.\nClick Manage above the list of volumes.\nIn the Manage volumes window, remove the selection from volumes that you do not want to back up. To see only the volumes assigned to the backup plan, select Show only selected items next to the Search field. Then, click Save.\n\n",
                "title": "To remove volumes from a backup plan"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-volumes-in-backup-plans.html"
    },
    {
        "title": "Assigning users to multiple domains",
        "content": "Assigning users to multiple domains\nBy using the vinfra tool, system administrators are able to create special service users that can be used by third-party applications to access the compute API with administrator privileges. These users cannot log in to the admin or self-service panels. Service users are similar to system administrators with the Compute permission: they exist only within the Default domain and can view and manage all objects in the compute cluster, including compute nodes. You can assign service users to domains, thus giving them ability to create compute objects in projects of these assigned domains (for example, to create a VM from a backup).\nService users can view virtual machines in all existing projects by specifying the all_tenants query parameter for the GET /servers request (refer to the OpenStack API documentation).\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo assign a service user to a domain\nUse the following command:vinfra domain user create --domain default --assign-domain <domain> compute <username>\n\n--assign-domain <domain>\n\nID or name of the domain to assign the service user to\n<username>\n\nService user name\n\nFor example, to create the service user my-service-user and assign it to the domains mydomain and mydomain2, run:# vinfra domain user create my-service-user --domain default --assign-domain mydomain compute \\\r\n--assign-domain mydomain2 compute\nTo check that the created service user is successfully assigned to the two domains, use the OpenStack client. For example, if the management node IP address is 10.136.16.227, run:# openstack --insecure --os-username my-service-user --os-user-domain-name \\\r\nDefault --os-auth-url=https://10.136.16.227:5000/v3 federation domain list\r\nPassword:\r\n+----------------------------------+---------+-----------+-------------+\r\n| ID                               | Enabled | Name      | Description |\r\n+----------------------------------+---------+-----------+-------------+\r\n| 2929ff42b1e64884a05dea3011862aed | True    | mydomain  |             |\r\n| 7e0d54797152424a9331ae904e220b88 | True    | mydomain2 |             |\r\n+----------------------------------+---------+-----------+-------------+\r\n\nYou can also view the list of all projects within the assigned domains by using this command:openstack --insecure --os-username <username> --os-user-domain-name Default --os-auth-url=https://<MN_IP_address>:5000/v3 federation project list\nTo unassign a service user from a domain\nUse the --unassign-domain <domain> option for the vinfra domain user set command. vinfra domain user set --domain default --unassign-domain <domain> <username>\n\n--unassign-domain <domain>\n\nID or name of the domain to unassign the service user from\n<username>\n\nService user name\n\nFor example, to unassign the service user my-service-user from the domain mydomain, run:# vinfra domain user set my-service-user --domain default --unassign-domain mydomain\nSee also\n\nConfiguring multitenancy\n\nManaging self-service users",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/assigning-users-to-multiple-domains.html"
    },
    {
        "title": "Preparing nodes for SR-IOV",
        "content": "Preparing nodes for SR-IOV\nTo use SR-IOV capabilities, check that the network adapter that you want to pass through supports them, and then enable IOMMU. For NVIDIA Mellanox network adapters, you need to additionally enable SR-IOV in firmware.\nTo check that a network adapter supports SR-IOV\nList all network adapters on a node and obtain their VID and PID:# lspci -nnD | grep Ethernet\r\n0000:00:03.0 Ethernet controller [0200]: Mellanox Technologies MT27800 Family [ConnectX-5] [15b3:1017]\r\n0000:00:04.0 Ethernet controller [0200]: Mellanox Technologies MT27800 Family [ConnectX-5] [15b3:1017]\n[15b3:1017] is the VID and PID of the network adapter.\nCheck that the chosen network adapter supports SR-IOV by using its VID and PID:# lspci -vv -d 15b3:1017 | grep SR-IOV\r\nCapabilities: [180 v1] Single Root I/O Virtualization (SR-IOV)\r\nCapabilities: [180 v1] Single Root I/O Virtualization (SR-IOV)\nTo enable IOMMU on a node\nRun the pci-helper.py script, and then reboot the node to apply the changes:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py enable-iommu\r\n# reboot\nThe script works for both Intel and AMD processors.\nYou can check that IOMMU is successfully enabled in the dmesg output:# dmesg | grep -e DMAR -e IOMMU\r\n[    0.000000] DMAR: IOMMU enabled\nTo enable SR-IOV in firmware for NVIDIA Mellanox network adapters\n\nDownload Mellanox Firmware Tools (MFT) from the official website and extract the archive on the node. For example:# wget https://www.mellanox.com/downloads/MFT/mft-4.17.0-106-x86_64-rpm.tgz\r\n# tar -xvzf mft-4.17.0-106-x86_64-rpm.tgz\n\nInstall the package, and then start Mellanox Software Tools (MST):# yum install rpm-build\r\n# . mft-4.17.0-106-x86_64-rpm/install.sh\r\n# mst start\n\nDetermine the MST device path:# mst status\n\nQuery the current configuration:# mlxconfig -d /dev/mst/mt4119_pciconf0 q\r\n...\r\nConfigurations:\r\n...\r\n         NUM_OF_VFS            4               # Number of activated VFs\r\n         SRIOV_EN              True(1)         # SR-IOV is enabled\r\n...\n\nSet the desired values, if necessary. For example, to increase the number of virtual functions to 8, run:# mlxconfig -d /dev/mst/mt4119_pciconf0 set SRIOV_EN=1 NUM_OF_VFS=8\n\nReboot the node to apply the changes.\n\nWhat's next\n\nEnabling PCI passthrough and vGPU support",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-nodes-for-sr-iov.html"
    },
    {
        "title": "Switching between GPU passthrough and vGPU",
        "content": "Switching between GPU passthrough and vGPU\nIf you have already enabled GPU passthrough for the compute cluster but want to use vGPU instead, or vice versa, you will need to reconfigure the node with the physical GPU and the compute cluster.\nPrerequisites\n\nThe compute cluster is reconfigured for GPU passthrough or vGPU support, as described in Enabling PCI passthrough and vGPU support.\nEnsure that the required GPU is not used by any virtual machine.\n\nTo reconfigure the compute cluster from GPU passthrough to vGPU support\n\nOn the node with the physical GPU, find out the service that is associated with the GPU. For example:# systemctl | grep stub\r\n  pcistub-0000:01:00.0.service       loaded active exited    Bind device to pci-stub driver\n\nDisable this service. For example:# systemctl disable pcistub-0000:01:00.0.service\n\nReboot the node to apply your changes:# reboot\n\nInstall the vGPU NVIDIA driver:\n\nInstall the kernel-devel and dkms packages:# dnf install kernel-devel dkms\r\n\n\nEnable and start the dkms service:\r\n# systemctl enable dkms.service \r\n# systemctl start dkms.service\n\nInstall the vGPU KVM kernel module from the NVIDIA GRID package with the --dkms option:# bash NVIDIA-Linux-x86_64-xxx.xx.xx-vgpu-kvm*.run --dkms\n\nRe-create the Linux boot image by running:# dracut -f\n\n[For modern GPUs with SR-IOV support] Enable the virtual functions for your GPU:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py nvidia-sriov-mgr --enable\n\nModify the configuration file:\n\nChange the device_type from generic to pgpu\nSpecify the GPU's PCI address in device\nRemove the alias field\nAdd the desired vgpu_type\n\nAs a result, your configuration file config.yaml may look as follows:- node_id: c3b2321a-7c12-8456-42ce-8005ff937e12\r\n  devices:\r\n    - device_type: pgpu\r\n      device: \"0000:01:00.0\"\r\n      vgpu_type: nvidia-224\n\nPass the configuration file to the vinfra service compute set command. For example:# vinfra service compute set --pci-passthrough-config config.yaml\n\nTo reconfigure the compute cluster from vGPU support to GPU passthrough\n\nRemove the vGPU-related information from the configuration file config.yaml. For example, you may need to remove these lines:- device_type: pgpu\r\n  device: \"0000:01:00.0\"\r\n  vgpu_type: nvidia-224\n\nReconfigure the compute cluster by using the updated configuration file config.yaml. For example:# vinfra service compute set --pci-passthrough-config config.yaml\n\n[For modern GPUs with SR-IOV support] Disable the virtual functions for your GPU:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py nvidia-sriov-mgr --disable\n\nUninstall the vGPU NVIDIA driver:# bash NVIDIA-Linux-x86_64-xxx.xx.xx-vgpu-kvm*.run --uninstall\n\nOn the node with the physical GPU, run the pci-helper.py script to assign the pci-stub driver to the GPU at its PCI address. For example:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py bind-to-stub 0000:01:00.0\n\nAdd the GPU card to the configuration file as a generic device. For example:- device_type: generic\r\n  device: 1b36:0100\r\n  alias: gpu\n\nPass the configuration file to the vinfra service compute set command. For example:# vinfra service compute set --pci-passthrough-config config.yaml\n\nWhat's next\n\nCreating virtual machines with physical GPUs\n\nCreating virtual machines with virtual GPUs\n\nCreating virtual machines with different vGPU types",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/switching-between-gpu-passthrough-and-vgpu.html"
    },
    {
        "title": "13.2. Building User Policies\u00c2\u00b6",
        "content": "13.2. Building User Policies | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n13.2. Building User Policies\u00c2\u00b6\nAfter you define pools and plans, you can then build policies.\n\nNote\nThe Leostream Connection Broker defines a policy as a set of rules that determine how desktops are offered, connected, and managed for a user, including what specific desktops are offered, which power control and release plans are applied to those desktops, what USB devices the user can access in their remote desktop, and more.\n\nThe Connection Broker provides a Default policy that applies if no other policy exists or is applicable. The Default policy assigns one desktop from the All Desktops pool. You can edit this policy to offer desktops from the pool you created in Chapter 5, as follows.\n\nGo to the Configuration > Policies menu.\nClick the Edit link next to the Default policy. The Edit Policy form, shown in the following figure, opens.\n\nGo to the Pool Assignments tab, shown in the following figure.\n\nClick the kabob menu on the left side of the All Desktops pool and select Edit.\nIn the Edit Pool Assignment form, use the Pool menu to select the pool you created previously. When a user is offered this policy, the Connection Broker sorts the desktops in the selected pool based on the other policy settings, then offers the user the top n desktops from the pool, where n is the number selected in the Number of desktops to offer drop-down menu.\n\nScroll down to the Plans section and notice that the policy already uses the default protocol, power control, and release plans. If you created new plans, use the drop-down menus in this section to select your plans.\n\nClick Save.\n\nUse the Create Policy link at the top of the Configuration > Policies page to create new policies. You can create as many policies as you need to model the different VDI workflows in your organization, however each user is assigned to one policy. If users need access to multiple pools, add those pools to the user\u00e2\u0080\u0099s policy.\nFor a complete description of setting up policies, see \u00e2\u0080\u009cConfiguring User Experience by Policy\u00e2\u0080\u009d in the Connection Broker Administrator\u00e2\u0080\u0099s Guide.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/offering-vhi-desktops/configuring-user-policies.html"
    },
    {
        "title": "Creating and deleting security groups",
        "content": "Creating and deleting security groups\nLimitations\n\nYou cannot delete a security group if it is assigned to a VM.\n\nTo create a security group\n\nOn the Security groups screen, click Add security group.\n\nIn the Add security group window, specify a name and description for the group, and then click Add.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nBy default, the new security group will deny all incoming traffic and allow only outgoing traffic to assigned virtual machines.\n\nTo delete a security group\n\nOn the Security groups screen, click the required security group.\nOn the group right pane, click Delete.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-and-deleting-security-groups.html"
    },
    {
        "title": "Setting project quotas",
        "content": "Setting project quotas\nCores and RAMPUT /v2.1/{authorized_project_id}/os-quota-sets/{project_id}\nRequest# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"quota_set\": {\r\n    \"ram\": 65536,\r\n    \"cores\": 12\r\n  }\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"ram\": 65536,\r\n    <...>\r\n    \"cores\": 12,\r\n    <...>\r\n  }\r\n}\r\n\nStorage limits of storage policies and volume backupsPUT /v3/{authorized_project_id}/os-quota-sets/{project_id}\nRequest# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"quota_set\": {\r\n    \"gigabytes_default\": 128,\r\n    \"gigabytes_policy1\": 64,\r\n    \"backup_gigabytes\": 20\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"backup_gigabytes\": 20,\r\n    \"gigabytes_default\": 128,\r\n    <...>\r\n    \"gigabytes_policy1\": 64\r\n  }\r\n}\r\n\nFloating IPs and VPN connectionsPUT /v2.0/quotas/{project_id}\nRequest# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n   \"quota\": {\r\n     \"floatingip\": 16,\r\n     \"ipsec_site_connection\": 10\r\n   }\r\n}' https://<node_IP_addr>:9696/v2.0/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota\": {\r\n    <...>\r\n    \"floatingip\": 16,\r\n    <...>\r\n    \"ipsec_site_connection\": 10,\r\n    <...>\r\n  }\r\n}\r\n\nLoad balancersPUT /v2/lbaas/quotas/{project_id}\nThe add-on service must be installed.\nRequest# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"quota\": {\r\n    \"load_balancer\": 12\r\n  }\r\n}' https://<node_IP_addr>:9888/v2/lbaas/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse{\r\n  \"quota\": {\r\n    \"load_balancer\": 12,\r\n    <...>\r\n  }\r\n}\r\n\nKubernetes clustersPUT /v1/quotas/{project_id}/Cluster\nThe add-on service must be installed.\nRequest# curl -ks -X PATCH -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"project_id\": \"afe9d74ab80149a2aa3d5fbf2a4f3c92\",\r\n  \"resource\": \"Cluster\",\r\n  \"hard_limit\": 6\r\n}' https://<node_IP_addr>:9513/v1/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92/Cluster\r\n\nResponse{\r\n  \"resource\": \"Cluster\",\r\n   <...>\r\n  \"hard_limit\": 6,\r\n   <...>\r\n}\r\n\nPlacementsPUT /quotas/{project_id}\nThe add-on service must be installed. Specify the microversion in the header, e.g., OpenStack-API-Version: placement 1.32.\nRequest# curl -ks -X PUT -H 'Content-Type: application/json' -H 'OpenStack-API-Version: placement 1.32' -H 'X-Auth-Token: gAAAAA<...>' -d ' \r\n{\r\n  \"quotas\": {\r\n    \"CUSTOM_HCI_122E856B9E9C4D80A0F8C21591B5AFCB\": 8\r\n  }\r\n}' https://<node_IP_addr>:8780/quotas/afe9d74ab80149a2aa3d5fbf2a4f3c92\r\n\nResponse\nDoes not return a response body if successful.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/setting-project-quotas.html"
    },
    {
        "title": "Benchmarking the network",
        "content": "Benchmarking the network\nTo benchmark the infrastructure network, we test network connectivity between all of the cluster nodes, and then the overall network throughput under the maximum load.\nPrerequisites\n\nKnowledge of the storage cluster best practices and configurations listed in Storage cluster best practices and Configuration examples.\nThe iperf3 utility is installed by default or by running yum install iperf3.\n\nTo test network connectivity between nodes\n\nStart the iperf3 server on each node:# for i in $(vinfra node list -f json | jq -r '.[].host'); do ssh $i iperf3 -s -p 30001 -D; done\n\nStart the benchmark on each node:# NODES=`vinfra node list -f json | jq -r '.[].host' | sort | grep -v $(hostname -s)`\r\n# for i in $NODES; do iperf3 -c $i -p 30001 ; done | egrep -i 'local|sender|receiver'\nThe output will be similar to the following:[  4] local 172.24.4.1 port 40666 connected to 172.24.4.2 port 30001\r\n[  4]   0.00-10.00  sec  28.6 GBytes  24.5 Gbits/sec    44            sender\r\n[  4]   0.00-10.00  sec  28.6 GBytes  24.5 Gbits/sec                  receiver\r\n[  4] local 172.24.4.1 port 44968 connected to 172.24.4.4 port 30001\r\n[  4]   0.00-10.00  sec  22.1 GBytes  19.0 Gbits/sec   1672           sender\r\n[  4]   0.00-10.00  sec  22.1 GBytes  19.0 Gbits/sec                  receiver\r\n\n\nTerminate the iperf server when done.\n\nIn the test report, check the following:\n\nThe measured network speed between all node pairs is similar, and that it is close to the rated network speed. Otherwise, this may indicate a network problem.\nThe number of retries (shown in the second-to-last column) is close to zero.\n\nTo test network throughput under load\n\nStart one iperf3 server on a different port per client on each node:# for i in $(vinfra node list -f json | jq -r '.[].host'); do ssh $i \"for j in 1 2 3; \\\r\ndo iperf3 -p 3000\\$j -s -D ; done\" ; done\n\nStart the benchmark simultaneously on all of the nodes:# PORT=30001 # use a different port on every client (ranged 30001\u00e2\u0080\u00a630003)\r\n# NODES=`vinfra node list -f json | jq -r '.[].host' | sort | grep -v $(hostname -s )`\r\n# for i in $NODES; do iperf3 -c $i -p $PORT ; done | egrep -i 'local|sender|receiver'\n\nTerminate the iperf server when done.\n\nThe test tries to maximize network load by generating traffic between all node pairs, and then reports the measured network speed between pairs.\nIn the test report, check the following:\n\nThe cumulative input and output of each node is close to the rated network speed.\nThe number of retries (shown in the second-to-last column) is close to zero.\n\nSee also\n\nGeneral considerations\n\nBenchmarking disks\n\nBenchmarking virtual machines\n\nBenchmarking NFS, iSCSI, and S3",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/benchmarking-network.html"
    },
    {
        "title": "Listing VPN endpoint groups",
        "content": "Listing VPN endpoint groupsGET /v2.0/vpn/endpoint-groups\nList VPN endpoint groups.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-vpn-endpoint-groups-detail#list-vpn-endpoint-groups\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfields (Optional)\nquery\nstring\n\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/endpoint-groups\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nendpoints\n\nbody\narray\nList of endpoints of the same type, for the endpoint group. The values will depend on the type.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ntype\n\nbody\nstring\nThe type of the endpoints in the group. A valid value is subnet, cidr, network, router, or vlan. Only subnet and cidr are supported at this moment.\n\nid\n\nbody\nstring\nThe ID of the VPN endpoint group.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"endpoint_groups\": [\r\n    {\r\n      \"id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n      \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n      \"name\": \"peers\",\r\n      \"description\": \"\",\r\n      \"type\": \"cidr\",\r\n      \"endpoints\": [\r\n        \"10.2.0.0/24\",\r\n        \"10.3.0.0/24\"\r\n      ],\r\n      \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n    },\r\n    {\r\n      \"id\": \"646938a8-322e-44b3-ac35-60deadcd4252\",\r\n      \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n      \"name\": \"locals\",\r\n      \"description\": \"\",\r\n      \"type\": \"subnet\",\r\n      \"endpoints\": [\r\n        \"79a060e3-3395-4fbf-9505-4517a65f81af\",\r\n        \"62cd794c-6682-4793-884b-828eb84324b0\"\r\n      ],\r\n      \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-vpn-endpoint-groups.html"
    },
    {
        "title": "Kickstart options",
        "content": "Kickstart options\nEven though your kickstart file may include any of the standard options, it is recommended to only use the ones listed in this section. They are mandatory and must be included in your kickstart file.\n\nauth --enableshadow --passalgo=sha512\n\nSpecifies authentication options for the Virtuozzo Hybrid Infrastructure physical server.\nautopart --type=lvm\n\nAutomatically partitions the system disk, which is sda. This option must follow clearpart --all.\nOther disks will be partitioned automatically during cluster creation.\n\nbootloader\n\nSpecifies how the boot loader should be installed.\nclearpart --all\n\nRemoves all partitions from all recognized disks.\n\nThis option will destroy data on all the disks that the installer can reach!\n\nkeyboard <layout>\n\nSets the system keyboard type.\nlang <lang>\n\nSets the language to use during installation and the default language to use on the installed system.\nlogvol\n\nCreates a logical volume for a Logical Volume Management (LVM) group.\nnetwork <options>\n\nConfigures network devices and creates bonds and VLANs.\nraid\n\nCreates a software RAID volume.\npart\n\nCreates a partition on the server.\n\nThe size of the /boot partition must be at least 1 GB.\n\nrootpw --iscrypted <passwd>\n\nSets the root password for the server. The value is your password\u00e2\u0080\u0099s hash obtained with the algorithm specified in the --passalgo parameter. For example, to create a SHA-512 hash of your password, run python -c 'import crypt; print(crypt.crypt(\"yourpassword\"))'.\nselinux --disabled\n\nDisables SElinux, because it prevents virtualization from working correctly.\nservices --enabled=\"chronyd\"\n\nEnables time synchronization via NTP.\ntimezone <timezone>\n\nSets the system time zone. For a list of time zones, run timedatectl list-timezones.\nvolgroup\n\nCreates a Logical Volume Management (LVM) group.\nzerombr\n\nInitializes disks with invalid partition tables.\n\nThis option will destroy data on all the disks that the installer can reach!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/kickstart-options.html"
    },
    {
        "title": "Shelving virtual machines",
        "content": "Shelving virtual machines\nYou can unbind a stopped VM from the node it is hosted on and release its reserved resources such as CPU and RAM. A shelved VM remains bootable and retains its configuration, including the IP addresses. \nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo shelve a virtual machine\n\nAdmin panel\n\nClick the desired virtual machine.\nIf the VM is stopped, click Shelve on its right pane.\nIf the VM is running or suspended, click Shut down or Power off on its right pane, and then select Shelve virtual machine in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute server shelve <server>\r\n\n\n<server>\n\nVirtual machine ID or name.\n\nFor example, to shelve the virtual machine myvm, run:# vinfra service compute server shelve myvm\n\nTo spawn a shelved VM on a node with enough resources to host it\n\nAdmin panel\n\nClick a shelved virtual machine.\nOn the VM right pane, click Unshelve.\n\nCommand-line interface\nUse the following command:vinfra service compute server unshelve <server>\r\n\n\n<server>\n\nVirtual machine ID or name.\n\nFor example, to unshelve the virtual machine myvm, run:# vinfra service compute server unshelve myvm\n\nSee also\n\nManaging virtual machine power state\n\nTroubleshooting virtual machines\n\nDeleting virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server shelve <server>\r\n\n\n<server>\n\nVirtual machine ID or name.\n\nFor example, to shelve the virtual machine myvm, run:# vinfra service compute server shelve myvm\n",
                "title": "To shelve a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server unshelve <server>\r\n\n\n<server>\n\nVirtual machine ID or name.\n\nFor example, to unshelve the virtual machine myvm, run:# vinfra service compute server unshelve myvm\n",
                "title": "To spawn a shelved VM on a node with enough resources to host it"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nClick the desired virtual machine.\nIf the VM is stopped, click Shelve on its right pane.\nIf the VM is running or suspended, click Shut down or Power off on its right pane, and then select Shelve virtual machine in the confirmation window.\n\n",
                "title": "To shelve a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nClick a shelved virtual machine.\nOn the VM right pane, click Unshelve.\n\n",
                "title": "To spawn a shelved VM on a node with enough resources to host it"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/shelving-virtual-machines.html"
    },
    {
        "title": "Showing flavor details",
        "content": "Showing flavor detailsGET /flavors/{flavor_id}\r\n\nShow details of a flavor with the specified ID.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=show-flavor-details-detail#show-flavor-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nflavor_id\n\npath\nstring\nThe ID of the flavor.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/flavors/100\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nflavor\n\nbody\nobject\nThe ID and links for the flavor for your server instance. A flavor is a combination\r\nof memory, disk size, and CPUs.\n\nname\n\nbody\nstring\nThe display name of a flavor.\n\ndescription\n\nbody\nstring\n\nThe description of the flavor.\nNew in version 2.55\n\nid\n\nbody\nstring\nThe ID of the flavor. While it may look like\r\nan integer, this is really a string.\n\nram\n\nbody\ninteger\nThe amount of RAM a flavor has, in MiB.\n\ndisk\n\nbody\ninteger\n\nThe size of the root disk that will be created in GiB. If 0 the\r\nroot disk will be set to exactly the size of the image used to\r\ndeploy the instance. However, in this case filter scheduler cannot\r\nselect the compute host based on the virtual image size. Therefore,\r\n0 should only be used for volume-booted instances or for testing\r\npurposes. Volume-backed instances can be enforced for flavors with\r\nzero root disk via the os_compute_api:servers:create:zero_disk_flavor\r\npolicy rule.\n\nThis platform supports only volume-booted instances, so this \r\nparameter value should be 0.\n\nvcpus\n\nbody\ninteger\nThe number of virtual CPUs that will be allocated to the server.\n\nlinks\n\nbody\narray\nLinks to the resources in question. See API Guide / Links and\r\nReferences\r\nfor more info.\n\nOS-FLV-EXT-DATA:ephemeral\n\nbody\ninteger\nThe size of the ephemeral disk that will be created, in\r\nGiB. Ephemeral disks may be written over on server state\r\nchanges. So should only be used as a scratch space for\r\napplications that are aware of its limitations. Defaults to 0.\n\nOS-FLV-DISABLED:disabled (Optional)\nbody\nboolean\nWhether or not the flavor has been administratively disabled.\r\nThis is typically only visible to administrative users.\n\nswap\n\nbody\ninteger\nThe size of a dedicated swap disk that will be allocated, in\r\nMiB. If 0 (the default), no dedicated swap disk will be created.\r\nCurrently, the empty string (\u00e2\u0080\u0098\u00e2\u0080\u0099) is used to represent 0.\r\nAs of microversion 2.75 default return value of swap is 0\r\ninstead of empty string.\n\nrxtx_factor\n\nbody\nfloat\nThe receive / transmit factor (as a float) that will be set on\r\nports if the network backend supports the QOS extension.\r\nOtherwise it will be ignored. It defaults to 1.0.\n\nos-flavor-access:is_public\n\nbody\nboolean\nWhether the flavor is public (available to all projects) or scoped\r\nto a set of projects. Default is True if not specified.\n\nextra_specs (Optional)\nbody\nobject\n\nA dictionary of the flavor\u00e2\u0080\u0099s extra-specs key-and-value pairs.  This will\r\nonly be included if the user is allowed by policy to index flavor\r\nextra_specs.\nNew in version 2.61\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"flavor\": {\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/flavors/100\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/flavors/100\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"ram\": 512,\r\n    \"OS-FLV-DISABLED:disabled\": false,\r\n    \"os-flavor-access:is_public\": true,\r\n    \"rxtx_factor\": 1,\r\n    \"disk\": 0,\r\n    \"id\": \"100\",\r\n    \"name\": \"tiny\",\r\n    \"vcpus\": 1,\r\n    \"swap\": \"\",\r\n    \"OS-FLV-EXT-DATA:ephemeral\": 0\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-flavor-details.html"
    },
    {
        "title": "Deleting flavors",
        "content": "Deleting flavorsDELETE /flavors/{flavor_id}\r\n\nDelete a flavor with the specified ID.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=delete-flavor-detail#delete-flavor\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nflavor_id\n\npath\nstring\nThe ID of the flavor.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/flavors/9b26eaff-d651-497a-bbb4-d6315459b050\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-flavors.html"
    },
    {
        "title": "Configuring new storage disks automatically",
        "content": "Configuring new storage disks automatically\nLimitations\n\nIf the new disk is smaller than the old one, it will not be assigned the Storage role. Instead, you will be alerted about the size difference and will have to assign the role manually (or change the disk to a larger one).\nIf the new disk is of a different type than the old one (for example, if you replaced an SSD with an HDD or vice versa), it will not be assigned the Storage role. Instead, you will be alerted about the type difference and will have to assign the role manually (or change the disk to one of the needed type).\nIf you enable this feature after a disk fails, its replacement will not be assigned the Storage role.\nIf you accidentally remove and then re-attach a healthy Storage disk, its data will be reused.\nIf you add a disk that does not replace any failed ones, it will not be assigned the Storage role.\nIf you add a disk and one of the CSes is inactive or offline, the disk will be assigned the Storage role and a new CS will be created.\nIf you attach multiple replacement disks at once, the Storage role will be assigned to them in no particular order, as long as their size and type fit. They will also be assigned to correct tiers, if applicable.\n\nTo have the storage role assigned to new disks automatically\n\nAdmin panel\n\nGo to Settings > System settings > Automatic disk replacement.\nTurn on the toggle switch Enable automatic configuration of new disks.\n\nSelect tiers to scan for failed disks. If a disk on an unselected tier breaks down, you will have to assign roles to its replacement manually.\n\nClick Save.\n\nFrom now on, when you replace a failed Storage disk, the new disk will be detected, formatted, assigned the same role, and placed on the same tier (if applicable). You will see the result on node\u00e2\u0080\u0099s Disks screen.\n\nCommand-line interface\nUse the following command:vinfra cluster settings automatic-disk-replacement set [--tier0 {on,off}] [--tier1 {on,off}]\r\n                                                       [--tier2 {on,off}] [--tier3 {on,off}]\r\n\n\n--tier0 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 0\n--tier1 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 1\n--tier2 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 2\n--tier3 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 3\n\nFor example, to enable automatic storage disk configuration for all storage tiers, run:# vinfra cluster settings automatic-disk-replacement set --tier0 on --tier1 on --tier2 on --tier3 on\nYou can view the automatic storage disk configuration in the vinfra cluster settings automatic-disk-replacement show output:# vinfra cluster settings automatic-disk-replacement show\r\n+-------+-------+\r\n| Field | Value |\r\n+-------+-------+\r\n| tier0 | True  |\r\n| tier1 | False |\r\n| tier2 | True  |\r\n| tier3 | False |\r\n+-------+-------+\r\n\n\nWhat's next\n\nReleasing node disks",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings automatic-disk-replacement set [--tier0 {on,off}] [--tier1 {on,off}]\r\n                                                       [--tier2 {on,off}] [--tier3 {on,off}]\r\n\n\n--tier0 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 0\n--tier1 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 1\n--tier2 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 2\n--tier3 {on,off}\n\nEnable or disable automatic storage disk configuration for tier 3\n\nFor example, to enable automatic storage disk configuration for all storage tiers, run:# vinfra cluster settings automatic-disk-replacement set --tier0 on --tier1 on --tier2 on --tier3 on\nYou can view the automatic storage disk configuration in the vinfra cluster settings automatic-disk-replacement show output:# vinfra cluster settings automatic-disk-replacement show\r\n+-------+-------+\r\n| Field | Value |\r\n+-------+-------+\r\n| tier0 | True  |\r\n| tier1 | False |\r\n| tier2 | True  |\r\n| tier3 | False |\r\n+-------+-------+\r\n\n",
                "title": "To have the storage role assigned to new disks automatically"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Automatic disk replacement.\nTurn on the toggle switch Enable automatic configuration of new disks.\n\nSelect tiers to scan for failed disks. If a disk on an unselected tier breaks down, you will have to assign roles to its replacement manually.\n\n\n\n\n\nClick Save.\n\nFrom now on, when you replace a failed Storage disk, the new disk will be detected, formatted, assigned the same role, and placed on the same tier (if applicable). You will see the result on node\u00e2\u0080\u0099s Disks screen.\n",
                "title": "To have the storage role assigned to new disks automatically"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-new-disks-automatically.html"
    },
    {
        "title": "Cloning volumes",
        "content": "Cloning volumes\nLimitations\n\nYou can clone volumes that are not attached to VMs or attached to stopped VMs.\n\nPrerequisites\n\nA volume is created, as described in Creating and deleting volumes.\n\nTo clone a volume\n\nOn the Volumes screen, click a volume.\nOn the volume right pane, click Clone.\n\nIn the Clone volume window, specify a volume name, size, and storage policy. Click Clone.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/cloning-volumes.html"
    },
    {
        "title": "Creating and deleting volumes",
        "content": "Creating and deleting volumes\nLimitations\n\nA volume is removed along with all of its snapshots.\n\nTo create a volume\n\nOn the Volumes screen, click Create volume.\n\nIn the Create volume window, specify a volume name and size in gigabytes, select a storage policy, and then click Create.\n\nTo remove a volume\n\nOn the Volumes tab, check the status of the volume you want to remove.\n If the status is \"In use\", click the volume, and then click Force detach.\nIf the status is \"Available\", click the volume, and then click Delete. ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-and-deleting-volumes.html"
    },
    {
        "title": "4.2. Recovering Virtual Machines\u00c2\u00b6",
        "content": "4.2. Recovering Virtual Machines | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\n\n4.2. Recovering Virtual Machines\u00c2\u00b6\nTo complete migration, virtual machines need to be recovered from their backups to the desired location.\nOne prerequisite is that a virtual machine must be stopped during recovery. By default, the software stops the machine without a prompt. When the recovery is completed, you have to start the machine manually. You can change the default behavior by using the VM power management recovery option (Recovery options > VM power management).\nTo recover a VM to a desired location:\n\nDo one of the following:\n\nSelect a backed-up machine, click Recovery, and then select a recovery point.\n\nSelect a recovery point on the Backup storage tab.\n\nClick Recover > Entire machine.\n\nBy default, the software automatically selects the original machine as the target machine.\n\nTo recover to another virtual machine, click Target machine, and then do the following:\n\nSelect the hypervisor Virtuozzo Hybrid Infrastructure.\nSelect whether to recover to a new or existing machine.\nSelect the storage, domain, project and specify the new machine name, or select an existing target machine.\nClick OK.\n\nSet up the additional recovery options if needed.\nClick Start recovery.\n\nWhen recovering to an existing virtual machine, confirm that you want to overwrite the disks.\n\nThe recovery progress is shown on the Activities tab.\n\nAfter a successful migration, you will see your VM in Virtuozzo Hybrid Infrastructure.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/migrating-virtual-machines/recovering-virtual-machines.html"
    },
    {
        "title": "Configuring multitenancy",
        "content": "Configuring multitenancy\nTo configure multitenancy for the compute or S3 cluster, you need to create domains, projects, and assign users to them.\nLimitations\n\nYou can set domain and project quotas only after deploying the compute cluster.\n\nPrerequisites\n\nA clear understanding of the concept Multitenancy.\n\nTo create a domain\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click Create domain.\n\nIn the Create domain window, specify the domain name and, optionally, description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra domain create [--description <description>] [--enable | --disable] <name>\r\n\n\n--description <description>\n\nDomain description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--enable\n\nEnable domain\n--disable\n\nDisable domain\n<name>\n\nDomain name\n\nFor example, to create the domain mydomain, run:# vinfra domain create mydomain\nThe created domain will appear in the vinfra domain list output:# vinfra domain list\r\n+--------------+----------+---------+--------------------+\r\n| id           | name     | enabled | description        |\r\n+--------------+----------+---------+--------------------+\r\n| default      | Default  | True    | The default domain |\r\n| 24986479e<\u00e2\u0080\u00a6> | mydomain | True    |                    |\r\n+--------------+----------+---------+--------------------+\r\n\n\nTo create a project\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click a domain within which the project will be created.\nOn the Projects tab, click Create project.\n\nIn the Create project window, specify the project name and, optionally, description. The project name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra domain project create [--description <description>] [--enable | --disable]\r\n                             --domain <domain> <name>\r\n\n\n--description <description>\n\nProject description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--enable\n\nEnable project\n--disable\n\nDisable project\n--domain <domain>\n\nDomain name or ID\n<name>\n\nProject name\n\nFor example, to create the project myproject within the domain mydomain and add a description to it, run:# vinfra domain project create myproject --domain mydomain --description \"A custom project\"\nThe created project will appear in the vinfra domain project list output:# vinfra domain project list --domain mydomain\r\n+-------------+-----------+---------+------------------+--------------+\r\n| id          | name      | enabled | description      | domain_id    |\r\n+-------------+-----------+---------+------------------+--------------+\r\n| 79830e3c<\u00e2\u0080\u00a6> | myproject | True    | A custom project | 24986479e<\u00e2\u0080\u00a6> |\r\n+-------------+-----------+---------+------------------+--------------+\r\n\n\nTo create a self-service user\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click a domain within which the user will be created.\nGo to the Domain users tab, and then click Create user.\n\nIn the Create user window, specify the user name, password, and, if required, a user email address and description. The user name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nSelect the user role:\n\nTo create a domain administrator\n\nSelect the Domain administrator role.\n\nEnable Image uploading to allow the user to upload images and configure this permission for other domain users.\n\nEnable Project and quota management to allow the user to manage projects and quotas, as well as configure this permission for other domain administrators.\n\nTo create a project administrator\n\nSelect the Project member role.\n\nEnable Image uploading to allow the user to upload images.\n\nClick Manage in the Projects section and select a project to assign the user to. Then, click Save.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra domain user create [--email <email>] [--description <description>]\r\n                          [--assign <project> <role>] [--assign-domain <domain> <roles>]\r\n                          [--domain-permissions <domain_permissions>]\r\n                          [--enable | --disable] --domain <domain> <name>\r\n\n\n--email <email>\n\nUser email\n--description <description>\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--assign <project> <role>\n\nAssign a user to a project with one or more permission sets. Specify this option multiple times to assign the user to multiple projects.\n\n<project>: project ID or name\n<role>: user role in the project (project_admin)\n\n--assign-domain <domain> <roles>\n\nAssign a user to a domain with one or more permission sets. Specify this option multiple times to assign the user to multiple domains. This option is only valid for service accounts.\n\n<domain>: domain ID or name\n<roles>: a comma-separated list of service account roles (compute)\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--enable\n\nEnable user\n--disable\n\nDisable user\n--domain <domain>\n\nDomain name or ID\n<name>\n\nUser name\n\nExample 1. To create a domain administrator account called myadmin within the domain mydomain and grant this user the permission to manage projects and their quotas, run:# vinfra domain user create myadmin --domain mydomain --domain-permissions domain_admin,quota_manager\nSpecify the user password when prompted.\nExample 2. To create the project member myuser for the project myproject within the domain mydomain and grant this user the permission to upload images, run:# vinfra domain user create myuser --domain mydomain --assign myproject project_admin --domain-permissions image_upload\nSpecify the user password when prompted.\nThe created users will appear in the vinfra domain user list output:# vinfra domain user list --domain mydomain\r\n+-------------+---------+-------+---------+-------------+--------------------+---------------------------+\r\n| id          | name    | email | enabled | description | domain_permissions | assigned_projects         |\r\n+-------------+---------+-------+---------+-------------+--------------------+---------------------------+\r\n| 28aa0207<\u00e2\u0080\u00a6> | myadmin |       | True    |             | - domain_admin     | []                        |\r\n|             |         |       |         |             | - quota_manager    |                           |\r\n| fb9fa0b2<\u00e2\u0080\u00a6> | myuser  |       | True    |             | - image_upload     | - project_id: 79830e3c<\u00e2\u0080\u00a6> |\r\n|             |         |       |         |             |                    |   role: project_admin     |\r\n+-------------+---------+-------+---------+-------------+--------------------+---------------------------+\r\n\n\nSee also\n\nManaging domains, users, and projects\n\nWhat's next\n\nProviding access to the self-service portal",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain create [--description <description>] [--enable | --disable] <name>\r\n\n\n--description <description>\n\n\nDomain description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--enable\n\nEnable domain\n--disable\n\nDisable domain\n<name>\n\nDomain name\n\nFor example, to create the domain mydomain, run:# vinfra domain create mydomain\nThe created domain will appear in the vinfra domain list output:# vinfra domain list\r\n+--------------+----------+---------+--------------------+\r\n| id           | name     | enabled | description        |\r\n+--------------+----------+---------+--------------------+\r\n| default      | Default  | True    | The default domain |\r\n| 24986479e<\u00e2\u0080\u00a6> | mydomain | True    |                    |\r\n+--------------+----------+---------+--------------------+\r\n\n",
                "title": "To create a domain"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain project create [--description <description>] [--enable | --disable]\r\n                             --domain <domain> <name>\r\n\n\n--description <description>\n\n\nProject description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--enable\n\nEnable project\n--disable\n\nDisable project\n--domain <domain>\n\nDomain name or ID\n<name>\n\nProject name\n\nFor example, to create the project myproject within the domain mydomain and add a description to it, run:# vinfra domain project create myproject --domain mydomain --description \"A custom project\"\nThe created project will appear in the vinfra domain project list output:# vinfra domain project list --domain mydomain\r\n+-------------+-----------+---------+------------------+--------------+\r\n| id          | name      | enabled | description      | domain_id    |\r\n+-------------+-----------+---------+------------------+--------------+\r\n| 79830e3c<\u00e2\u0080\u00a6> | myproject | True    | A custom project | 24986479e<\u00e2\u0080\u00a6> |\r\n+-------------+-----------+---------+------------------+--------------+\r\n\n",
                "title": "To create a project"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain user create [--email <email>] [--description <description>]\r\n                          [--assign <project> <role>] [--assign-domain <domain> <roles>]\r\n                          [--domain-permissions <domain_permissions>]\r\n                          [--enable | --disable] --domain <domain> <name>\r\n\n\n--email <email>\n\nUser email\n--description <description>\n\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--assign <project> <role>\n\n\nAssign a user to a project with one or more permission sets. Specify this option multiple times to assign the user to multiple projects.\n\n<project>: project ID or name\n<role>: user role in the project (project_admin)\n\n\n--assign-domain <domain> <roles>\n\n\nAssign a user to a domain with one or more permission sets. Specify this option multiple times to assign the user to multiple domains. This option is only valid for service accounts.\n\n<domain>: domain ID or name\n<roles>: a comma-separated list of service account roles (compute)\n\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--enable\n\nEnable user\n--disable\n\nDisable user\n--domain <domain>\n\nDomain name or ID\n<name>\n\nUser name\n\nExample 1. To create a domain administrator account called myadmin within the domain mydomain and grant this user the permission to manage projects and their quotas, run:# vinfra domain user create myadmin --domain mydomain --domain-permissions domain_admin,quota_manager\nSpecify the user password when prompted.\nExample 2. To create the project member myuser for the project myproject within the domain mydomain and grant this user the permission to upload images, run:# vinfra domain user create myuser --domain mydomain --assign myproject project_admin --domain-permissions image_upload\nSpecify the user password when prompted.\nThe created users will appear in the vinfra domain user list output:# vinfra domain user list --domain mydomain\r\n+-------------+---------+-------+---------+-------------+--------------------+---------------------------+\r\n| id          | name    | email | enabled | description | domain_permissions | assigned_projects         |\r\n+-------------+---------+-------+---------+-------------+--------------------+---------------------------+\r\n| 28aa0207<\u00e2\u0080\u00a6> | myadmin |       | True    |             | - domain_admin     | []                        |\r\n|             |         |       |         |             | - quota_manager    |                           |\r\n| fb9fa0b2<\u00e2\u0080\u00a6> | myuser  |       | True    |             | - image_upload     | - project_id: 79830e3c<\u00e2\u0080\u00a6> |\r\n|             |         |       |         |             |                    |   role: project_admin     |\r\n+-------------+---------+-------+---------+-------------+--------------------+---------------------------+\r\n\n",
                "title": "To create a self-service user"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click Create domain.\n\nIn the Create domain window, specify the domain name and, optionally, description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\nClick Create.\n\n",
                "title": "To create a domain"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click a domain within which the project will be created.\nOn the Projects tab, click Create project.\n\nIn the Create project window, specify the project name and, optionally, description. The project name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\nClick Create.\n\n",
                "title": "To create a project"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click a domain within which the user will be created.\nGo to the Domain users tab, and then click Create user.\n\nIn the Create user window, specify the user name, password, and, if required, a user email address and description. The user name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\nSelect the user role:\n\n\nTo create a domain administrator\n\n\nSelect the Domain administrator role.\n\nEnable Image uploading to allow the user to upload images and configure this permission for other domain users.\n\n\nEnable Project and quota management to allow the user to manage projects and quotas, as well as configure this permission for other domain administrators.\n\n\n\n\n\n\n\n\n\n\nTo create a project administrator\n\n\nSelect the Project member role.\n\nEnable Image uploading to allow the user to upload images.\n\nClick Manage in the Projects section and select a project to assign the user to. Then, click Save.\n\n\n\n\n\n\n\n\n\n\nClick Create.\n\n",
                "title": "To create a self-service user"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-multitenancy.html"
    },
    {
        "title": "Disk health analyzers",
        "content": "Disk health analyzers\nThe core part of calculating disk health are analyzers. Each analyzer calculates disks health based on its own algorithm. The overall disk health is a product of disk health values from all of the analyzers.\nFor example:\n\nAccording to the S.M.A.R.T. attributes, the disk health is 0.9.\nThe slow disk analyzer reports that the disk health is 0.4.\nThe slow CS analyzer reports that the disk health is 0.5.\nAccording to SCSI errors, the disk health is 1.0.\n\nThe overall disk health is calculated as 0.9*0.4*0.5*1.0 and equals 0.18 or 18%.\nS.M.A.R.T. attributes\nThe following table contains the S.M.A.R.T. attributes that affect the health value:\n\nID\nS.M.A.R.T. attribute\nWeight1 Defines by how many percent the attribute value decreases the total disk health value.\nLimit2 Defines the maximum impact the attribute may have on the total disk health., in percent\n\n05\nReallocated Sectors Count\n2\n70\n\n187\nReported Uncorrectable Errors\n1\n70\n\n188\nCommand Timeout\n1\n20\n\n197\nCurrent Pending Sectors Count\n2\n70\n\n198\nOffline uncorrectable Sectors Count\n2\n70\n\n233\nMedia Wearout Indicator\n1\n100\n\nThe  disk health is calculated by using the following formula:Disk health (%) = K * \u00d0\u009f (100% - D)\nwhere:\n\nK is the reduction coefficient. A disk is considered less healthy if it reports more then one type of S.M.A.R.T. errors. The coefficient formula is 0.8^({Number of S.M.A.R.T. attributes with error} \u00e2\u0080\u0093 1). Possible values are 0\u00e2\u0080\u00931.\n\u00d0\u009f is a product of minimums  calculated for each critical S.M.A.R.T. attribute.\n100% is the initial health of the disk.\nD is a minimum from the limit and attribute value with its weight. Its formula is (min(limit, attribute_value * weight)).\nlimit is a limit of each critical S.M.A.R.T. attribute.\nattribute_value is the current attribute value.\nweight is weight of each critical S.M.A.R.T. attribute.\n\nFor example:\n\nReallocated Sectors Count: attribute value = 30, weight = 2, limit = 70\nCommand Timeout: attribute value = 23, weight = 1, limit = 20\n\nK = 0.8 * (2\u00e2\u0080\u00931) = 0.8\n\nThe S.M.A.R.T. disk health is calculated as follows: 0.8 * (100% \u00e2\u0080\u0093 (min(30*2, 70))) * (100% - min(23*1, 20))) = 0.8 * 0.4 * 0.8 = 0.256 (26%)\nSlow disk and slow CS analyzers\nSlow disk and CS analyzers calculate disk health according to the average I/O latency over time (15 minutes).\nThe following table shows the default thresholds:\n\nAnalyzer\nOK latency3 Maximum latency value to consider disk health to be 100%., in seconds\nFATAL latency4  Latency value to consider disk health to be 0%., in seconds\n\nSlow CS\n0.1\n60\n\nSlow HDD Disk\n0.1\n30\n\nSlow SSD Disk\n0.01\n10\n\nIf disk latency is less than OK latency, the disk health is considered to be 100%. If disk latency exceeds FATAL latency, the disk health is considered to be 0%. Disk latency that lies within these two thresholds will vary linearly from 100% to 0%.\n\nWhen disk health becomes 0%, the service generates an alert and marks this CS as unresponsive. Such a CS does not trigger automatic replication but is no longer available for chunk allocation. \nSCSI errors\nBy default, each SCSI failure decrease the overall disk heath by 4%. The maximum health impact is set to 70.\nSee also\n\nDisk-related metrics in Prometheus",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/disk-health-analyzers.html"
    },
    {
        "title": "Querying statistics objects via REST API",
        "content": "Querying statistics objects via REST API\nYou can display usage statistics with the ostor-usage service and parameter obj specifying the statistics object. The output includes the accessed buckets, user ID, and counters. For example:# s3_curl GET \"http://s3.example.com/?ostor-usage&obj=s3-usage-8000000000000065-2017-02-01T16:31:54.000Z-1800\"\r\n{\r\n    \"fmt_version\": 1,\r\n    \"service_id\": 8000000000000065,\r\n    \"start_ts\": 1485966714,\r\n    \"period\": 1390,\r\n    \"nr_items\": 1,\r\n    \"items\": [\r\n        {\r\n            \"key\": {\r\n                \"bucket\": \"client\",\r\n                \"epoch\": 98309,\r\n                \"user_id\": \"b81d6c5f895a8c86\",\r\n                \"tag\": \"\"\r\n            },\r\n            \"counters\": {\r\n                \"ops\": {\r\n                    \"put\": 1,\r\n                    \"get\": 3,\r\n                    \"list\": 0,\r\n                    \"other\": 0\r\n                },\r\n                \"net_io\": {\r\n                    \"uploaded\": 41258,\r\n                    \"downloaded\": 45511311\r\n                }\r\n            }\r\n        }\r\n    ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-statistics-objects-via-rest-api.html"
    },
    {
        "title": "How to deploy Osie on Kubernetes",
        "content": "How to deploy Osie on KubernetesThis guide describes how to deploy Osie on top of a Kubernetes cluster based on Virtuozzo Hybrid Infrastructure.About OsieOsie is a modern control panel and billing system for OpenStack that provides all the tools for effortless cloud business management. Osie is officially supported for Virtuozzo Hybrid Infrastructure and allows selling cloud services with the pay-as-you-go (PAYG) pricing model.Prerequisites1. Read about identity management to understand the need of an OpenID provider (IdP). By default, this chart will install Keycloak as an OpenID provider for the user authentication.2. Deploy a Virtuozzo Hybrid Infrastructure cluster.3. Create the compute cluster with the Kubernetes and load balancing services.4. Configure a storage policy named standard for boot volumes on Kubernetes master nodes. Ensure that the selected policy is available for all projects where you are planning to deploy Kubernetes.5. Create a Kubernetes cluster.6. Install cert-manager with a ClusterIssuer called letsencrypt.7. Create a storage class named standard: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n# cat > storage-class.yaml <<\\EOT\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: standard\n  namespace: default\nprovisioner: cinder.csi.openstack.org\nparameters:\n  type: standard\nreclaimPolicy: Retain\nallowVolumeExpansion: true\nEOT\nApply the configuration file:1\n# kubectl create -f storage-class.yaml\nNote: The storage policy standard must be available in your project.8. Configure a domain where to install Osie:cloud.<your-domain>.<tld> configured in your DNS pointing to your ingress IPan auth.<your-domain>.<tld> subdomain for Keycloak, if you don\u2019t already have an identity provider (IdP)9. Install Helm on your local machine.10. Create an ingress-nginx controller that will be exposed via a public IP address:10.1. Create the nginx-values.yaml configuration file: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# cat > nginx-values.yaml <<\\EOT\ncontroller:\n  publishService:\n    enabled: true\n  config:\n  service:\n    annotations:\n      service.beta.kubernetes.io/openstack-internal-load-balancer: \"false\"\n      loadbalancer.openstack.org/keep-floatingip: \"true\"\n    loadBalancerIP: \"xx.xx.xx.xx\"\nEOT\nIn loadBalancerIP, specify a public IP address for the controller. Use keep-floatingip to keep this IP address, otherwise it will be randomly reassigned from the subnet pool.10.2. Create the ingress-nginx controller by using Helm:1\n# helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx --create-namespace -f nginx-values.yaml\nInstalling Osie1. Add the Helm repository:1\n2\n# helm repo add osie https://helm.osie.io\n# helm repo update\n2. Configure the values.yaml file:To install with Keycloak included: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n# cat > values.yaml <<\\EOT\nglobal:\n  ingress:\n    enabled: true\n    hostname: \"cloud.example.com\"\n    ingressClassName: \"nginx\"\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt\n      # Required by Keycloak when using Nginx ingress\n      nginx.ingress.kubernetes.io/proxy-buffer-size: \"128k\"\n    tls: true\nkeycloak:\n  ingress:\n    hostname: auth.example.com\nsmtp:\n  password: # smtp password \n  user: # smtp user \n  starttls: true\n  auth: true\n  port: 587\n  host: # smtp server \n  from: support@mydomain.com\n  fromDisplayName: My Cloud Company\nEOT\nThis configuration installs Keycloak as well using the Keycloak chart from Bitnami.To install without Keycloak:Note: If you have deployed your own identity provider, you have to manually specify the Oauth2 / OpenID configuration. 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n# cat > values.yaml <<\\EOT\nglobal:\n  ingress:\n    enabled: true\n    hostname: \"cloud.example.com\"\n    ingressClassName: \"nginx\"\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt\n    tls: true\n# OpenID configuration for the Osie client portal\nui:\n  oauth2:\n    clientId: client-id\n    issuerUri: https://auth.example.com/path/to/openid\n# (Optional) if you use different OpenID for the Administrators\n# otherwise the ones from the client portal will be used\nadmin:\n  oauth2:\n    clientId: admin-client-id\n    issuerUri: https://auth.example.com/path/to/openid   \n\nkeycloak:\n  enabled: false\nsmtp:\n  ...\nEOT\nFor the complete list of configurable variables, check the values.yaml file of the Chart.3. If you have a highly available Kubernetes cluster (with three master nodes), then you can deploy the databases and the services with replication and high availability. In this case, adjust the replicaCount and architecture as follows: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n# cat > values.yaml <<\\EOT\nui:\n replicaCount: 3\nadmin:\n replicaCount: 3\napi:\n replicaCount: 3 \nkeycloak:\n  replicaCount: 3\n  postgresql:\n    architecture: replication\nmongodb:\n   architecture: replicaset\n   replicaCount: 3\nredis:\n   architecture: replication\nEOT\n4. Install Osie by using the the created values.yaml file:1\n# helm --namespace osie upgrade --install --create-namespace osie osie/osie -f values.yaml\n5. Check the Kubernetes pods in the namespace:1\n2\n3\n4\n5\n6\n7\n8\n9\n# kubectl -n osie get pods\nosie-admin-5dc5b4ff59-hbzmz     1/1     Running   0          22h\nosie-api-0                      1/1     Running   0          22h\nosie-keycloak-0                 1/1     Running   0          28h\nosie-mongodb-5fc58bbc78-mc6xw   1/1     Running   0          28h\nosie-postgresql-0               1/1     Running   0          28h\nosie-rabbitmq-0                 1/1     Running   0          28h\nosie-redis-master-0             1/1     Running   0          28h\nosie-ui-566c759d8-srskk         1/1     Running   0          22h\n6. Check the ingress hostnames:1\n2\n3\n4\n5\n# kubectl -n osie get ingress\nosie-admin      nginx   cloud.example.com        12.34.56.78   80, 443   28h\nosie-api        nginx   cloud.example.com        12.34.56.78   80, 443   28h\nosie-keycloak   nginx   cloud.example.com        12.34.56.78   80, 443   28h\nosie-ui         nginx   cloud.example.com        12.34.56.78   80, 443   28h\nNow, Osie is installed on your Kubernetes cluster and ready to be used.Performing post-installation stepsSaving the bcrypt passwordOsie encrypts some sensitive information that\u2019s stored in the database, such as passwords and access keys. It uses a bcrypt symmetric key configured as an environment variable (OSIE_ENCRYPTION_DEFAULT_KEY). Since the encryption is symmetric, the same key must be used to decrypt the data. Therefore, is very important the key is not lost, otherwise some data from the database cannot be decrypted.The helm chart generates a random bcrypt password key that is saved inside the <release-name>-bcrypt secret. It is recommended to save the key somewhere externally as well, so that you can reuse it in the event of a disaster recovery.To retrieve the bcrypt password and save it somewhere externally, run:1\n# kubectl -n osie get secret osie-bcrypt -o json | jq -r '.data.\"bcrypt-password\"' | base64 -d\nLogging in to Osie admin panelThe admin panel should be accessible at https://cloud.example.com/osie_admin.The default admin username is osie_admin.To retrieve the admin password from the Kubernetes secret if you have jq installed, run:1\n# kubectl -n osie get secret osie-keycloak -o json | jq -r '.data.\"admin-password\"' | base64 -d\nTo retrieve the secret and base64 decode the data.admin-password key, run:1\n# kubectl -n osie get secret osie-keycloak -o yaml \nUpgrading or reconfiguringYou can use the helm upgrade command to upgrade to newer versions of Osie or to restart the components if you make changes to values.yaml.If you used the chart to install Keycloak as well, it is recommended to prevent the keycloakConfigCli running again, since that is only needed during the first installation.1. Disable keycloakConfigCli to run again by making the following changes in values.yaml:1\n2\n3\nkeycloak:\n  keycloakConfigCli:\n    enabled: false\n2. Update the helm repository to get the latest chart version:1\n# helm repo update\n3. Run the helm upgrade command:1\n# helm --namespace osie upgrade osie osie/osie -f values.yaml\nAutomated backupsConfigure automated backups with Velero.Setting up the Osie notifier containerThe Osie notifier container (osie-notifier) allows Osie to get notifications from Virtuozzo Hybrid Infrastructure by using RabbitMQ.1. Create and configure a virtual machine for osie-notifier:1.1. In Virtuozzo Hybrid Infrastructure, create a virtual machine with the following parameters:Image: Ubuntu 22.04vCPU: 1RAM: 2Storage: 20 GBThe network must have an access to a private infrastructure network and accessible from Osie.1.2. Connect to the VM and install Docker inside it: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# sudo apt update\n# sudo apt upgrade -y  \n# sudo apt install apt-transport-https ca-certificates curl software-properties-common -y\n# curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n# echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) # # # stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n# sudo apt update\n# apt-cache policy docker-ce\n# sudo apt install docker-ce -y\n# sudo systemctl status docker\n# sudo usermod -aG docker ${USER}\n# exit\n1.3. Log in to your VM again and install Docker Compose:1\n2\n3\n4\n# mkdir -p ~/.docker/cli-plugins/\n# curl -SL https://github.com/docker/compose/releases/download/v2.3.3/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose\n# chmod +x ~/.docker/cli-plugins/docker-compose\n# docker compose version\n1.4. If you run this VM on Virtuozzo Cloud, you need to perform additional steps:1.4.1. Configure MTU for Docker:Important: Make sure that the Docker MTU settings match those of your VM network. Otherwise, some applications running inside Docker containers might not work.For example, you have a VM with the following network configuration: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: ens4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1413 qdisc fq_codel state UP group default qlen 1000\n    link/ether fa:16:3e:fd:75:1a brd ff:ff:ff:ff:ff:ff\n    altname enp0s4\n    inet 10.0.0.64/24 metric 100 brd 10.0.0.255 scope global dynamic ens4\n       valid_lft 24231sec preferred_lft 24231sec\n    inet6 fe80::f816:3eff:fefd:751a/64 scope link \n       valid_lft forever preferred_lft forever\n3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:44:a4:40:fe brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:44ff:fea4:40fe/64 scope link \n       valid_lft forever preferred_lft forever\nDocker will have issues with this VM, as your ens4 and docker0 network interfaces have different MTU settings and Docker sets MTU to 1500 bytes by default. To change this, create a file with a new MTU setting, and then restart Docker:1\n2\n3\n# vi /etc/docker/daemon.json\n{\"mtu\": 1413}\n# systemctl restart docker.service\n2. Configure Virtuozzo Hybrid Infrastructure to access RabbitMQ. To do this, you need to open port 5672 on all of your management nodes. RabbitMQ is available on a network with the traffic type Internal management assigned.2.1. In the Virtuozzo Hybrid Infrastructure admin panel, go to the Infrastructure > Networks screen and click Create traffic type. Specify the following parameters:Name: rabbitmqPort: 5672Access rules: keep the default settings2.2. Assign the rabbitmq traffic type to the network that has the Internal management traffic type assigned.2.3. Connect to the Virtuozzo Hybrid Infrastructure master node and get the connection parameters for RabbitMQ:1\n2\n# grep rabb /etc/kolla/nova-conductor/nova.conf\ntransport_url = rabbit://openstack:<rabbit_password>@rabbitmq.svc.vstoragedomain.:5672\nSave <rabbit_password> as you will need to add it to the osie-container configuration later.3. Configure and run osie-notifier:3.1. Configure the osie-notifier container.3.2. Modify the osie-notifier application.yaml configuration file by changing <rabbitmq_ip_1>, <rabbitmq_ip_2>, and <rabbitmq_ip_3>to the IP addresses of your management nodes in Virtuozzo Hybrid Infrastructure.An example configuration file: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\nosie:\n  dsn:\n  - https://<osie_server_url>/api-v1/os-notification/652d0dd8327e272e0e45e871/RegionOne\nspring:\n  rabbitmq:\n    username: openstack\n    password: <rabbit_password>\n    addresses: <rabbitmq_ip_1>:5672,<rabbitmq_ip_2>:5672,<rabbitmq_ip_3>:5672\nnotifications:\n  queue: osie-notifier\nopenstack:\n  topic: notifications.*\n  services:\n  # adapt this depending on the enabled services\n  - exchange: nova\n  - exchange: neutron\n  - exchange: openstack\n  - exchange: heat\n  - exchange: cinder\nserver:\n  port: 7476\nEnjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/osie-on-kubernetes/"
    },
    {
        "title": "Preparing benchmarks for disks",
        "content": "Preparing benchmarks for disks\nFor more accurate results, we recommend tuning the following parameters in the fio scripts listed below:\n\nsize is 4G by default, but can be set to twice the node\u00e2\u0080\u0099s RAM divided by the node\u00e2\u0080\u0099s CPU cores.\nnumjobs is the number of CPU cores divided by 2 for an HDD, or the number of CPU cores for an SSD.\niodepth is set to 2 or 4 for an HDD, or to 32 for an SSD.\n\nSave the following scripts with the suggested filename on each node:\n\nfio.write.single.randwrite\n[job]\r\nblocksize=4k\r\nrw=randwrite\r\ndirect=1\r\nbuffered=0\r\nioengine=libaio\r\niodepth=32\r\nfdatasync=32\r\nsize=8G\r\nnumjobs=16\r\n\nfio.write.single.seqwrite\n[job]\r\nblocksize=1m\r\nrw=write\r\ndirect=1\r\nbuffered=0\r\nioengine=libaio\r\niodepth=32\r\nfdatasync=32\r\nsize=8G\r\nnumjobs=16\r\n\nfio.write.all\n[job]\r\nblocksize=4k\r\nrw=randwrite\r\ndirect=1\r\nbuffered=0\r\nioengine=libaio\r\niodepth=32\r\nfdatasync=32\r\nsize=8G\r\nnumjobs=16\r\n\nfio.read.random\n[job]\r\nblocksize=4k\r\nrw=randread\r\ndirect=1\r\nbuffered=0\r\nioengine=libaio\r\niodepth=32\r\nfdatasync=32\r\nsize=8g\r\nnumjobs=16\r\n\nfio.write.random\n[job]\r\nblocksize=4k\r\nrw=randwrite\r\ndirect=1\r\nbuffered=0\r\nioengine=libaio\r\niodepth=32\r\nfdatasync=32\r\nsize=8g\r\nnumjobs=16\r\n\nfio.read.seq\n[job]\r\nblocksize=1m\r\nrw=read\r\ndirect=1\r\nbuffered=0\r\nioengine=libaio\r\niodepth=16\r\nfdatasync=32\r\nsize=8g\r\nnumjobs=16\r\n\nfio.write.seq\n[job]\r\nblocksize=1m\r\nrw=write\r\ndirect=1\r\nbuffered=0\r\nioengine=libaio\r\niodepth=16\r\nfdatasync=32\r\nsize=8g\r\nnumjobs=16\r\n\ncs_write_test.sh\n#!/bin/sh\r\n \r\ncs_mounts=$(vstorage -c $(cat /mnt/vstorage/.vstorage.info/clustername) list-services | grep vstorage.*cs | awk '{print$NF}' )\r\nfio_config=\"$1\"\r\n \r\nfor d in $cs_mounts; do\r\n        cs=`cat $d/control/id`\r\n        echo \"Testing $cs in $d...\"\r\n        test_dir=\"$(dirname $d)/test\"\r\n        mkdir $test_dir\r\n        f=$test_dir/file\r\n        log_file=\"$cs.$fio_config.log\"\r\n        fio --group_reporting --filename=$f $fio_config > $log_file\r\n        result=`grep \"write:\" $log_file`\r\n        echo $result\r\n        rm -f $f\r\n        rmdir $test_dir\r\ndone\r\n\ncs_all_write_test.sh\n#!/bin/sh\r\n \r\ncs_mounts=$(vstorage -c $(cat /mnt/vstorage/.vstorage.info/clustername) list-services | grep vstorage.*cs | awk '{print$NF}' )\r\nfio_config=\"$1\"\r\n \r\necho \"Test drives simultaneously...\"\r\nfilenames=\"\"\r\nlog_file=\"$fio_config.log\"\r\n \r\nfor d in $cs_mounts; do\r\n        cs=`cat $d/control/id`\r\n        test_dir=\"$(dirname $d)/test\"\r\n        mkdir $test_dir\r\n        f=$test_dir/file\r\n        path=\"--filename=$f\"\r\n        filenames=\"$filenames $path\"\r\ndone\r\n \r\nfio --group_reporting $filenames $fio_config > $log_file\r\nresult=`grep \"write:\" $log_file`\r\necho $result\r\n \r\nfor d in $cs_mounts; do\r\n        test_dir=\"$(dirname $d)/test\"\r\n        f=$test_dir/file\r\n#       echo \"Cleaning $f ...\"\r\n        rm -f $f\r\n        rmdir $test_dir\r\ndone\r\n\nstorage_test.sh\n#!/bin/sh\r\n \r\nfio_config=\"$1\"\r\nlog_file=\"$(hostname).$fio_config.log\"\r\n \r\ntest_dir=\"/mnt/vstorage/test/$(hostname)\"\r\nf=\"$test_dir/file\"\r\n \r\nmkdir -p $test_dir\r\necho \"Testing in $f ...\"\r\nfio --group_reporting --filename=$f $fio_config > $log_file\r\n \r\nresult=`egrep \"read:|write:\" $log_file`\r\necho $result\r\n \r\nrm -f $f\r\nrmdir $test_dir\r\n\n\nWhat's next\n\nRunning storage benchmarks",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-benchmarks-for-disks.html"
    },
    {
        "title": "Setting quotas for buckets via REST API",
        "content": "Setting quotas for buckets via REST API\nYou can limit storage usage per bucket with the ostor-quotas service and the following parameters: bucket specifying the bucket name and quota-size specifying the usage limit in gigabytes:# s3_curl PUT \"http://s3.example.com/?ostor-quotas&bucket=bucket1&quota-size=256\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-quotas-for-buckets-via-rest-api.html"
    },
    {
        "title": "Managing load balancers",
        "content": "Managing load balancers\nVirtuozzo Hybrid Infrastructure offers load balancing as a service for the compute infrastructure. Load balancing ensures fault tolerance and improves performance of web applications by distributing incoming network traffic across virtual machines from a balancing pool. A load balancer receives and then routes incoming requests to a suitable VM based on a configured balancing algorithm and VM health.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-load-balancers.html"
    },
    {
        "title": "Deleting bucket limits via REST API",
        "content": "Deleting bucket limits via REST API\nYou can delete the current limits with the ostor-limits service and parameter bucket specifying the bucket name:# s3_curl DELETE \"http://s3.example.com/?ostor-limits&bucket=client\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-bucket-limits-via-rest-api.html"
    },
    {
        "title": "Configuring memory for virtual machines",
        "content": "Configuring memory for virtual machines\nTo optimize memory usage by virtual machines, Virtuozzo Hybrid Infrastructure uses a Linux feature called kernel same-page merging (KSM). The KSM daemon periodically scans memory for pages with identical content and merges those into a single page. That page is marked as copy-on-write (COW), so when a virtual machine needs to change its contents, the kernel creates a copy of the page for that VM and changes it. KSM allows using RAM overcommitment and avoiding swapping when many similar workloads run on the same server. However, we strongly recommend configuring swap space if you enable memory overcommitment.\nAdditionally, virtual machines running on a server are bound to its NUMA nodes, to keep VM processes as close to the memory they access as possible. When the load difference between NUMA nodes exceeds 50%, hosted VMs are rebalanced based on their memory and CPU usage.\nYou can configure the amount of memory that can be provisioned for virtual machines by setting the RAM overcommitment ratio on a particular node or on all of the compute nodes. This is the ratio of the amount of maximum reserved RAM to physical. The default ratio is 1, which means that you cannot provision more than the amount of physical RAM available on a compute node. By increasing the ratio on a compute node, you can increase the number of virtual machines running on this node but potentially reduce their performance. By default, memory guarantees for virtual machines are set to 50%, which allows increasing the RAM overcommitment ratio up to 2. However, the maximum recommended RAM overcommitment ratio is 1.5.\nMemory overcommitment for virtual machines is only available if a compute node has enough swap space. Before enabling RAM overcommitment, you need to calculate the required swap space, and then configure it on a compute node.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-memory-for-virtual-machines.html"
    },
    {
        "title": "Monitoring infrastructure nodes",
        "content": "Monitoring infrastructure nodes\nNodes added to the infrastructure are listed on the Infrastructure > Nodes screen. If the storage cluster has not been created yet, you will only see nodes with the Unassigned status.\n\nA node can have one of the following statuses:\n\nHealthy\n\nAll the storage services on the node are running.\nUnhealthy\n\nOne or more storage services on the node have failed.\nIn maintenance\n\nThe node is in maintenance mode. It does not participate in new chunk allocation.\nRecovering\n\nThe configuration of deployed services and infrastructure is being recovered on the node.\nRecovery failed\n\nThe recovery process has failed on the node.\nIn progress\n\nThe node is deploying, entering, or exiting maintenance. Nodes in this state cannot be managed.\nUnassigned\n\nThe node is not assigned to a storage cluster.\n\nTo view the node details\n\nAdmin panel\nOpen the Infrastructure > Nodes screen and click the required node line. On the right pane, the Overview tab includes the node details, such as the node ID and hostname, its status and location, assigned IP addresses, deployed services, and the number of disks and network interfaces.\n\nCommand-line interface\nUse the following command:vinfra node show <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to view the details of the node node003, run:# vinfra node show node003\r\n+---------------+--------------------------------------+\r\n| Field         | Value                                |\r\n+---------------+--------------------------------------+\r\n| has_kvm       | True                                 |\r\n| host          | node003.vstoragedomain               |\r\n| id            | c4d14337-0863-4a67-9dbd-f19c3e49e114 |\r\n| is_assigned   | True                                 |\r\n| is_in_ha      | False                                |\r\n| is_installing | False                                |\r\n| is_online     | True                                 |\r\n| is_primary    | False                                |\r\n| is_virt       | False                                |\r\n| maintenance   |                                      |\r\n| orig_hostname | node003                              |\r\n| roles         | cses:                                |\r\n|               |   active: 4                          |\r\n|               |   being_released: 0                  |\r\n|               | mdses:                               |\r\n|               |   avail: 1                           |\r\n|               |   being_released: 0                  |\r\n|               |   is_master: true                    |\r\n| tasks         |                                      |\r\n+---------------+--------------------------------------+\nIn the command output, the node details include the node ID, hostname, the number and status of storage services. Also, you can check whether the node is joined to the storage cluster and HA configuration, and if it is online or in the maintenance mode.\n\nTo view all processes on nodes\nGo to the Monitoring > Dashboard screen, and then click Grafana dashboard. A separate browser tab will open with preconfigured Grafana dashboards. Open the Process details dashboard, to see a list of processes on your infrastructure nodes. The charts on this dashboard show CPU and memory usage for each process. The displayed data can be filtered per node or process group.",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node show <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to view the details of the node node003, run:# vinfra node show node003\r\n+---------------+--------------------------------------+\r\n| Field         | Value                                |\r\n+---------------+--------------------------------------+\r\n| has_kvm       | True                                 |\r\n| host          | node003.vstoragedomain               |\r\n| id            | c4d14337-0863-4a67-9dbd-f19c3e49e114 |\r\n| is_assigned   | True                                 |\r\n| is_in_ha      | False                                |\r\n| is_installing | False                                |\r\n| is_online     | True                                 |\r\n| is_primary    | False                                |\r\n| is_virt       | False                                |\r\n| maintenance   |                                      |\r\n| orig_hostname | node003                              |\r\n| roles         | cses:                                |\r\n|               |   active: 4                          |\r\n|               |   being_released: 0                  |\r\n|               | mdses:                               |\r\n|               |   avail: 1                           |\r\n|               |   being_released: 0                  |\r\n|               |   is_master: true                    |\r\n| tasks         |                                      |\r\n+---------------+--------------------------------------+\nIn the command output, the node details include the node ID, hostname, the number and status of storage services. Also, you can check whether the node is joined to the storage cluster and HA configuration, and if it is online or in the maintenance mode.\n",
                "title": "To view the node details"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nOpen the Infrastructure > Nodes screen and click the required node line. On the right pane, the Overview tab includes the node details, such as the node ID and hostname, its status and location, assigned IP addresses, deployed services, and the number of disks and network interfaces.\n",
                "title": "To view the node details"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-infrastructure-nodes.html"
    },
    {
        "title": "Integration with WHMCS",
        "content": "Integration with WHMCS\nThis chapter explains ways to provision, enable, disable, and terminate S3 users as well as set user and bucket limits for billing purposes.\nThe provided examples are PHP scripts with which you can send requests to S3 cluster\u00e2\u0080\u0099s REST API via cURL and OpenSSL.\n\r\n                Replace http://s3.example.com in examples with your actual S3 gateway URL and http://whmcs.example.com with you actual WHMCS portal URL.\r\n            ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/integration-with-whmcs.html"
    },
    {
        "title": "Backing up management database",
        "content": "Backing up management database\nTo back up the database manually \n\nAdmin panel\nGo to Settings > System settings > Management database backup, and then click Back up now.\n\nOnce the backup is complete, the date and time in the Last backup time field will be refreshed.\n\nDo not rename the backup file! Otherwise you will not be able to restore the management database from it.\n\nCommand-line interface\nUse the following command:vinfra cluster backup create\r\n\nYou can view the details of the last cluster backup and the ID of the ongoing backup task, if any, in the vinfra cluster backup show output:# vinfra cluster backup show\r\n+----------------------+-----------------------------+\r\n| Field                | Value                       |\r\n+----------------------+-----------------------------+\r\n| last_backup_date     | 2019-08-21T15:41:24+00:00   |\r\n| last_backup_location | /mnt/vstorage/webcp/backup/ |\r\n| ready                | True                        |\r\n| tasks                | []                          |\r\n+----------------------+-----------------------------+\r\n\n\nWhat's next\n\nRestoring management database from backup\n\nRestoring management database with the compute cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster backup create\r\n\nYou can view the details of the last cluster backup and the ID of the ongoing backup task, if any, in the vinfra cluster backup show output:# vinfra cluster backup show\r\n+----------------------+-----------------------------+\r\n| Field                | Value                       |\r\n+----------------------+-----------------------------+\r\n| last_backup_date     | 2019-08-21T15:41:24+00:00   |\r\n| last_backup_location | /mnt/vstorage/webcp/backup/ |\r\n| ready                | True                        |\r\n| tasks                | []                          |\r\n+----------------------+-----------------------------+\r\n\n",
                "title": "To back up the database manually "
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nGo to Settings > System settings > Management database backup, and then click Back up now.\n\n\n\n\nOnce the backup is complete, the date and time in the Last backup time field will be refreshed.\n\nDo not rename the backup file! Otherwise you will not be able to restore the management database from it.\n\n",
                "title": "To back up the database manually "
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backing-up-management-database.html"
    },
    {
        "title": "Running storage benchmarks",
        "content": "Running storage benchmarks\nThese tests measure the system behavior in various simulated workload conditions. If desired, you can use them to trigger and analyze scenarios described in Performance issues and symptoms.\nPrerequisites\n\nThe benchmarks for disks are prepared as described in Preparing benchmarks for disks.\n\nTo run benchmarks for disks\n\nOn each node, install the fio utility:# yum install fio\n\nOn each node, test the random and sequential write IOPS performance of each drive:# ./cs_write_test.sh fio.write.single.randwrite\r\n# ./cs_write_test.sh fio.write.single.seqwrite\n\nOn any node, check the cumulative random and sequential write IOPS performance:# grep 'write:' *fio.write.single.randwrite.log | awk -F'[=k,]' '{sum+=$2} END {print sum}'\r\n# grep 'write:' *fio.write.single.seqwrite.log | awk -F'[=k,]' '{sum+=$2} END {print sum}'\n\nOn each node, test the cumulative random write IOPS:# ./cs_all_write_test.sh fio.write.all\n\nTo test replication settings\n\nCreate the test directory /mnt/vstorage/test, and then apply the desired replication settings on it. For example:# mkdir /mnt/vstorage/test\r\n# vstorage set-attr -R /mnt/vstorage/test replicas=3:2\r\n# vstorage set-attr -R /mnt/vstorage/test failure-domain=host\r\n# vstorage set-attr -R /mnt/vstorage/test tier=0\r\n\n\nOn any node, test the random read and write IOPS performance:# ./storage_test.sh fio.read.random\r\n# ./storage_test.sh fio.write.random\r\n\n\nOn any node, test the sequential read and write IOPS performance:# ./storage_test.sh fio.read.seq\r\n# ./storage_test.sh fio.write.seq\r\n\n\nSee also\n\nGeneral considerations\n\nBenchmarking the network\n\nBenchmarking virtual machines\n\nBenchmarking NFS, iSCSI, and S3",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/running-storage-benchmarks.html"
    },
    {
        "title": "Creating image records",
        "content": "Creating image recordsPOST /v2/images\r\n\nCreate an image record. You need to provide a name and specify container_format and disk_format.\nNext, upload an image file to the record, according to Uploading image data.\nSource: https://docs.openstack.org/api-ref/image/v2/index.html?expanded=create-image-detail#create-image\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ncontainer_format (Optional)\nbody\nenum\n\nFormat of the image container.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud.\nExample formats are: ami, ari, aki, bare,\r\novf, ova, or docker.\nThe value might be null (JSON null data type).\n\ndisk_format (Optional)\nbody\nenum\n\nThe format of the disk.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud. See the Image Schema\r\nresponse from the cloud itself for the valid values available.\nExample formats are: ami, ari, aki, vhd,\r\nvhdx, vmdk, raw, qcow2, vdi, ploop or\r\niso.\nThe value might be null (JSON null data type).\n\nid (Optional)\nbody\nstring\n\nA unique, user-defined image UUID, in the format:nnnnnnnn-nnnn-nnnn-nnnn-nnnnnnnnnnnn\r\n\nWhere n is a hexadecimal digit from 0 to f, or F.\nFor example:b2173dd3-7ad6-4362-baa6-a68bce3565cb\r\n\nIf you omit this value, the API generates a UUID for the image.  If you\r\nspecify a value that has already been assigned, the request fails with\r\na 409 response code.\n\nmin_disk (Optional)\nbody\ninteger\nAmount of disk space in GB that is required to boot the image.\n\nmin_ram (Optional)\nbody\ninteger\nAmount of RAM in MB that is required to boot the image.\n\nname (Optional)\nbody\nstring\nThe name of the image.\n\nprotected (Optional)\nbody\nboolean\nImage protection for deletion. Valid value is true or false.\r\nDefault is false.\n\ntags (Optional)\nbody\narray\nList of tags for this image.  Each tag is a string of at most 255 chars.\r\nThe maximum number of tags allowed on an image is set by the operator.\n\nvisibility (Optional)\nbody\nstring\n\nVisibility for this image. Valid value is one of: public, private,\r\nshared, or community.\r\nAt most sites, only an administrator can make an image public.\r\nSome sites may restrict what users can make an image community.\r\nSome sites may restrict what users can perform member operations on\r\na shared image.\n\nSince the Image API v2.5, the default value is shared.\n\nExample# curl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"container_format\": \"bare\",\r\n    \"disk_format\": \"qcow2\",\r\n    \"name\": \"cirros3\"\r\n}' https://<node_IP_addr>:9292/v2/images\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nLocation\n\nheader\nstring\nThe URL to access the image file from the\r\nexternal store.\n\nOpenStack-image-import-methods (Optional)\nheader\nstring\n\nA comma separated list of import method identifiers.  Included\r\nonly if image import is enabled in your cloud.\nNew in version 2.6\n\nOpenStack-image-store-ids (Optional)\nheader\nstring\nA comma separated list of available store identifiers.  If this header\r\nis missing the cloud does not support multiple backend stores.\n\nchecksum\n\nbody\nstring\nHash that is used over the image data. The Image\r\nservice uses this value for verification.  The value might be\r\nnull (JSON null data type).\n\ncontainer_format\n\nbody\nenum\n\nFormat of the image container.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud.\nExample formats are: ami, ari, aki, bare,\r\novf, ova, or docker.\nThe value might be null (JSON null data type).\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndisk_format\n\nbody\nenum\n\nThe format of the disk.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud. See the Image Schema\r\nresponse from the cloud itself for the valid values available.\nExample formats are: ami, ari, aki, vhd,\r\nvhdx, vmdk, raw, qcow2, vdi, ploop or\r\niso.\nThe value might be null (JSON null data type).\n\nfile\n\nbody\nstring\nThe URL for the virtual machine image file.\n\nid\n\nbody\nstring\n\nA unique, user-defined image UUID, in the format:nnnnnnnn-nnnn-nnnn-nnnn-nnnnnnnnnnnn\r\n\nWhere n is a hexadecimal digit from 0 to f, or F.\nFor example:b2173dd3-7ad6-4362-baa6-a68bce3565cb\r\n\nIf you omit this value, the API generates a UUID for the image.\n\nmin_disk\n\nbody\ninteger\nAmount of disk space in GB that is required to boot the image.\r\nThe value might be null (JSON null data type).\n\nmin_ram\n\nbody\ninteger\nAmount of RAM in MB that is required to boot the image.\r\nThe value might be null (JSON null data type).\n\nname\n\nbody\nstring\nThe name of the image.  Value might be null (JSON null data type).\n\nos_hash_algo\n\nbody\nstring\n\nThe algorithm used to compute a secure hash of the image data for this\r\nimage.  The result of the computation is displayed as the value of the\r\nos_hash_value property.  The value might be null (JSON null\r\ndata type).  The algorithm used is chosen by the cloud operator; it\r\nmay not be configured by end users.\nNew in version 2.7\n\nos_hash_value\n\nbody\nstring\n\nThe hexdigest of the secure hash of the image data computed using the\r\nalgorithm whose name is the value of the os_hash_algo property.\r\nThe value might be null (JSON null data type) if data has not\r\nyet been associated with this image, or if the image was created using\r\na version of the Image Service API prior to version 2.7.\nNew in version 2.7\n\nos_hidden\n\nbody\nboolean\n\nThis field controls whether an image is displayed in the default\r\nimage-list response.  A \u00e2\u0080\u009chidden\u00e2\u0080\u009d image is out of date somehow (for\r\nexample, it may not have the latest updates applied) and hence should\r\nnot be a user\u00e2\u0080\u0099s first choice, but it\u00e2\u0080\u0099s not deleted because it may be\r\nneeded for server rebuilds.  By hiding it from the default image list,\r\nit\u00e2\u0080\u0099s easier for end users to find and use a more up-to-date version of\r\nthis image.\nNew in version 2.7\n\nowner\n\nbody\nstring\nAn identifier for the owner of the image, usually the project (also\r\ncalled the \u00e2\u0080\u009ctenant\u00e2\u0080\u009d) ID.\r\nThe value might be null (JSON null data type).\n\nprotected\n\nbody\nboolean\nA boolean value that must be false or the image cannot be deleted.\n\nschema\n\nbody\nstring\nThe URL for the schema describing a virtual machine image.\n\nself\n\nbody\nstring\nThe URL for the virtual machine image.\n\nsize\n\nbody\ninteger\nThe size of the image data, in bytes.  The value\r\nmight be null (JSON null data type).\n\nstatus\n\nbody\nstring\nThe image status.\n\ntags\n\nbody\narray\nList of tags for this image, possibly an empty list.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvirtual_size\n\nbody\ninteger\nThe virtual size of the image.  The value might\r\nbe null (JSON null data type).\n\nvisibility\n\nbody\nstring\nImage visibility, that is, the access permission for the image.\n\ndirect_url (Optional)\nbody\nstring\n\nThe URL to access the image file kept in external store.  It is present\r\nonly if the show_image_direct_url option is true in the Image\r\nservice\u00e2\u0080\u0099s configuration file.\n\nAs it presents a security risk, this\r\noption is disabled by default.\n\nlocations (Optional)\nbody\narray\n\nA list of objects, each of which describes an image location.  Each object\r\ncontains a url key, whose value is a URL specifying a location, and a\r\nmetadata key, whose value is a dict of key:value pairs containing\r\ninformation appropriate to the use of whatever external store is indicated\r\nby the URL.  This list appears only if the show_multiple_locationsoption is set to true in the Image service\u00e2\u0080\u0099s configuration file.\n\nAs it presents a security risk, this option is disabled by\r\ndefault.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n415 - Unsupported Media Type\n\nThe request entity has a media type which the server or resource does not support.\n\nExample{\r\n  \"container_format\": \"bare\",\r\n  \"min_ram\": 0,\r\n  \"updated_at\": \"2020-02-11T12:05:52Z\",\r\n  \"file\": \"/v2/images/c7c31840-ff42-4ef1-b489-48af638fdf7f/file\",\r\n  \"owner\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n  \"id\": \"c7c31840-ff42-4ef1-b489-48af638fdf7f\",\r\n  \"size\": null,\r\n  \"self\": \"/v2/images/c7c31840-ff42-4ef1-b489-48af638fdf7f\",\r\n  \"disk_format\": \"qcow2\",\r\n  \"os_hash_algo\": null,\r\n  \"schema\": \"/v2/schemas/image\",\r\n  \"status\": \"queued\",\r\n  \"tags\": [],\r\n  \"visibility\": \"shared\",\r\n  \"min_disk\": 0,\r\n  \"virtual_size\": null,\r\n  \"name\": \"cirros3\",\r\n  \"checksum\": null,\r\n  \"created_at\": \"2020-02-11T12:05:52Z\",\r\n  \"os_hidden\": false,\r\n  \"protected\": false,\r\n  \"os_hash_value\": null\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-image-records.html"
    },
    {
        "title": "Accessing the admin panel via SSL",
        "content": "Accessing the admin panel via SSL\nWhen configuring the Virtuozzo Hybrid Infrastructure and services, you may need to enter sensitive information such as credentials for user and email accounts, S3 services, and so on. The system uses a pregenerated self-signed certificate by default, but you may want to upload one issued by a trusted certificate authority instead. You can also generate a new self-signed certificate instead of the one used by default. However, it will not be trusted and you will have to manually accept it in your browser.\nLimitations\n\nYou can upload RSA certificates only. SSL certificates based on other algorithms are not supported.\nYou can upload an SSL certificate before creating the high availability (HA) cluster. However, if you later create the HA cluster, the admin panel will move to the chosen virtual IP address. In case you have the certificate issued for the admin panel\u00e2\u0080\u0099s current IP address, you will need to acquire a new SSL certificate issued for the virtual IP address. In case you have the certificate issued for the domain name, ensure this domain name resolves to the virtual IP address.\n\nPrerequisites\n\nIf you acquired an SSL certificate from an intermediate certificate authority (CA)\n\nYou should have an end-user certificate along with a CA bundle that contains the root and intermediate certificates. To be able to use these certificates, you need to merge them into a chain first. A certificate chain includes the end-user certificate, the certificates of intermediate CAs, and the certificate of a trusted root CA. In this case, an SSL certificate can only be trusted if every certificate in the chain is properly issued and valid.\nFor example, if you have an end-user certificate, two intermediate CA certificates, and a root CA certificate, create a new certificate file and add all certificates to it in the following order:# End-user certificate issued by the intermediate CA 1\r\n-----BEGIN CERTIFICATE-----\r\nMIICiDCCAg2gAwIBAgIQNfwmXNmET8k9Jj1X<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 1 certificate issued by the intermediate CA 2\r\n-----BEGIN CERTIFICATE-----\r\nMIIEIDCCAwigAwIBAgIQNE7VVyDV7exJ9ON9<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 2 certificate issued by the root CA\r\n-----BEGIN CERTIFICATE-----\r\nMIIC8jCCAdqgAwIBAgICZngwDQYJKoZIhvcN<...>\r\n-----END CERTIFICATE-----\r\n# Root CA certificate\r\n-----BEGIN CERTIFICATE-----\r\nMIIDODCCAiCgAwIBAgIGIAYFFnACMA0GCSqG<...>\r\n-----END CERTIFICATE-----\r\n\n\nTo upload a third-party SSL certificate\n\nAdmin panel\n\nGo to Settings > System settings > SSL certificate.\n\nSelect Upload a certificate, and then upload the following:\n\nAn SSL certificate issued for the admin panel\u00e2\u0080\u0099s current IP address or domain name\nThe matching private key or password (this option shows after uploading a valid certificate)\n\nClick Save.\nIn the Change SSL certificate window, confirm that you want to change the SSL certificate. After you click Change, the admin panel will be automatically restarted.\n\nThe uploaded certificate will be added to the configuration of the web server that hosts the admin panel and you will be able to access it over HTTPS.\n\nCommand-line interface\nUse the following command:vinfra cluster settings ssl set --cert-file <cert_file> [--key-file <key_file>] [--password]\n\n--cert-file <cert_file>\n\nPath to a file with the new certificate\n--key-file <key_file>\n\nPath to a file with the private key\n--password\n\nRead certificate password from stdin.\n\nFor example, to upload an SSL certificate from the cert.pem and key.pem files, run:# vinfra cluster settings ssl set --cert-file cert.pem --key-file key.pem\nYou can view the uploaded SSL certificate in the vinfra cluster settings ssl show output:# vinfra cluster settings ssl show\r\n+-------------+-------+\r\n| Field       | Value |\r\n+-------------+-------+\r\n| is_valid    | True  |\r\n| self_signed | False |\r\n| ssl         | True  |\r\n+-------------+-------+\n\nTo generate a new self-signed SSL certificate\n\nAdmin panel\n\nGo to Settings > System settings > SSL certificate.\nSelect Generate a certificate, and then click Save.\nIn the Change SSL certificate window, confirm that you want to change the SSL certificate. After you click Change, the admin panel will be automatically restarted.\n\nThe uploaded certificate will be added to the configuration of the web server that hosts the admin panel, but  you will have to manually accept it in your browser.\n\nCommand-line interface\nUse the following command:vinfra cluster settings ssl set --self-signed\n\n--self-signed\n\nGenerate a new self-signed certificate.\n\nFor example, to generate a new self-signed certificate, run:# vinfra cluster settings ssl set --self-signed\nYou can view the SSL certificate in the vinfra cluster settings ssl show output:# vinfra cluster settings ssl show\r\n+-------------+-------+\r\n| Field       | Value |\r\n+-------------+-------+\r\n| is_valid    | True  |\r\n| self_signed | True  |\r\n| ssl         | True  |\r\n+-------------+-------+\n\nSee also\n\nBest practices for cluster security\n\nEnabling management node high availability\n\nSecuring root access to cluster nodes over SSH\n\nEnabling data encryption",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings ssl set --cert-file <cert_file> [--key-file <key_file>] [--password]\n\n--cert-file <cert_file>\n\nPath to a file with the new certificate\n--key-file <key_file>\n\nPath to a file with the private key\n--password\n\nRead certificate password from stdin.\n\nFor example, to upload an SSL certificate from the cert.pem and key.pem files, run:# vinfra cluster settings ssl set --cert-file cert.pem --key-file key.pem\nYou can view the uploaded SSL certificate in the vinfra cluster settings ssl show output:# vinfra cluster settings ssl show\r\n+-------------+-------+\r\n| Field       | Value |\r\n+-------------+-------+\r\n| is_valid    | True  |\r\n| self_signed | False |\r\n| ssl         | True  |\r\n+-------------+-------+\n",
                "title": "To upload a third-party SSL certificate"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings ssl set --self-signed\n\n--self-signed\n\nGenerate a new self-signed certificate.\n\nFor example, to generate a new self-signed certificate, run:# vinfra cluster settings ssl set --self-signed\nYou can view the SSL certificate in the vinfra cluster settings ssl show output:# vinfra cluster settings ssl show\r\n+-------------+-------+\r\n| Field       | Value |\r\n+-------------+-------+\r\n| is_valid    | True  |\r\n| self_signed | True  |\r\n| ssl         | True  |\r\n+-------------+-------+\n",
                "title": "To generate a new self-signed SSL certificate"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > SSL certificate.\n\nSelect Upload a certificate, and then upload the following:\n\nAn SSL certificate issued for the admin panel\u00e2\u0080\u0099s current IP address or domain name\nThe matching private key or password (this option shows after uploading a valid certificate)\n\n\n\n\n\n\nClick Save.\nIn the Change SSL certificate window, confirm that you want to change the SSL certificate. After you click Change, the admin panel will be automatically restarted.\n\nThe uploaded certificate will be added to the configuration of the web server that hosts the admin panel and you will be able to access it over HTTPS.\n",
                "title": "To upload a third-party SSL certificate"
            },
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > SSL certificate.\nSelect Generate a certificate, and then click Save.\nIn the Change SSL certificate window, confirm that you want to change the SSL certificate. After you click Change, the admin panel will be automatically restarted.\n\nThe uploaded certificate will be added to the configuration of the web server that hosts the admin panel, but  you will have to manually accept it in your browser.\n",
                "title": "To generate a new self-signed SSL certificate"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/accessing-admin-panel-via-ssl.html"
    },
    {
        "title": "Migrating virtual machines to Virtuozzo Hybrid Infrastructure online",
        "content": "Migrating virtual machines to Virtuozzo Hybrid Infrastructure online\nLimitations\n\nYou can migrate VMs created on vCenter 5.0 or newer.\n\nPrerequisites\n\nAuthentication is configured in the appliance VM, as described in Setting up authentication in the appliance virtual machine.\nRemove VMware tools from Windows VMs before the migration to avoid issues on boot afterwards. VMware tools will be removed from Linux guests automatically.\n\nTo migrate a VM from VMware vCenter online\n\nLog in to the appliance VM as the admin user with the SSH key.\nGet root privileges, for example, with sudo -i.\n\nSet OpenStack credentials:# source user-openrc.sh\r\n\n\nTest the connection between libvirt and VMware vCenter. For example:# virsh -c 'vpx://<domain>%5c<user>@<hostname>?no_verify=1' list --all\r\nEnter root's password for vcenter.example.com: ***\r\n+----+--------------+----------+\r\n| Id | Name         | <...>    |\r\n+----+--------------+----------+\r\n| -  | Fedora 20    | <...>    |\r\n| -  | Windows 2008 | <...>    |\r\n+----+--------------+----------+\r\n\nWhere <hostname> is the name of the VMware ESXi host that runs virtual machines. Its full path looks like <vCenter_hostname>/<datacenter_name>/<cluster_name>/<server_hostname> and can be found in VMware vCenter.\nIf the VPX username contains a backslash (for example, <domain>\\<user>), escape it with %5c: <domain>%5c<user>. Similarly, escape spaces with %20.\n\nCheck the OpenStack connection and find out the virt-v2v appliance ID. For example:# openstack --insecure server list\r\n+--------------------------------------+--------------------+--------+-------+\r\n| ID                                   | Name               | Status | <...> |\r\n+--------------------------------------+--------------------+--------+-------+\r\n| 635ae4cc-4c01-461a-ae63-91ca4187a7b1 | virt-v2v-appliance | ACTIVE | <...> |\r\n+--------------------------------------+--------------------+--------+-------+\r\n\n\nShut down the VM. Windows VMs must be shut down gracefully for the migration to be successful.\n\nMigrate the VM to a volume in Virtuozzo Hybrid Infrastructure specifying a storage policy. To list available storage policies, run vinfra service compute storage-policy list in Virtuozzo Hybrid Infrastructure. For example:# virt-v2v -ip password.txt -ic 'vpx://<domain>%5c<user>@<hostname>\\\r\n?no_verify=1' 'Windows 2008' -o openstack -oo server-id=635ae4cc-\\\r\n4c01-461a-ae63-91ca4187a7b1 -os <policy_name>\nWhere <policy_name> is the storage policy for the converted volume.\n\nFind out the new volume\u00e2\u0080\u0099s ID or name. For example:# openstack --insecure volume list\r\n+---------------------+------+-----------+------+-------------+\r\n| ID                  | Name | Status    | Size | Attached to |\r\n+---------------------+------+-----------+------+-------------+\r\n| 024b6843-2de3-<...> | sda1 | available |   64 |             |\r\n+---------------------+------+-----------+------+-------------+\r\n\n\nIf the VM used UEFI firmware, manually set the correct OS distribution and UEFI firmware type for the converted volume. To list available distributions, run vinfra service compute show in Virtuozzo Hybrid Infrastructure. For example:# openstack --insecure volume set sda1 --image-property os_distro=win2k8\r\n# openstack --insecure volume set sda1 --image-property hw_firmware_type=uefi\n\nIn Virtuozzo Hybrid Infrastructure, create a virtual machine based on the new volume. For example:# vinfra service compute server create migratedvm --network id=private \\\r\n--network id=public --volume source=volume,id=sda1,size=64 --flavor medium\r\n\n\nAfter the migration, it is recommended to install the guest tools inside the VM. The guest tools installation will prevent possible problems with guest OS interaction via the VNC console.\nSee also\n\nMigrating virtual machines to Virtuozzo Hybrid Infrastructure offline\n\nWhat's next\n\nInstalling guest tools",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/migrating-vms-to-infrastructure-online.html"
    },
    {
        "title": "Installing guest tools",
        "content": "Installing guest tools\nYou can install the guest tools inside a virtual machine by using ISO images stored either in the official repository or on a compute node. The latter case includes additional steps performed by  a user with the system administrator role.\nAs a system administrator\nUpload the guest tools ISO files located in the /usr/share/vz-guest-tools/ directory on any compute node to the compute cluster:\n\nfor a Windows guest, upload vz-guest-tools-win.iso by running:# vinfra service compute image create vz-guest-tools-win --file /usr/share/vz-guest-tools/vz-guest-tools-win.iso --public\n\nfor a Linux guest, upload vz-guest-tools-lin.iso by running:# vinfra service compute image create vz-guest-tools-lin --file /usr/share/vz-guest-tools/vz-guest-tools-lin.iso --public\n\nAs a virtual machine user\n\nAdmin panel\n\nCreate a compute volume from the vz-guest-tools-win or vz-guest-tools-lin image, depending on the VM operating system:\n\nOn the Compute > Virtual machines > Images tab, click the vz-guest-tools-win or vz-guest-tools-lin image.\nOn the image right pane, click Create volume.\nIn the Create volume from image window, specify a name for the volume, and then click Create.\n\nAttach the volume with the guest tools to the virtual machine:\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM.\nOn the VM right pane, click the pencil icon in the Volumes field.\nIn the Volumes window, click Attach.\nIn the Attach volume window, select the created volume with the guest tools, and then click Attach. The attached volume will be marked as ISO.\nIn the Volumes window, click Done, to save your changes.\n\nLog in to the virtual machine.\n\nInside the VM, do the following:\n\nInside a Windows VM, go to the mounted optical drive in Explorer and install the guest tools by running setup.exe. After the installation is complete, restart the VM.\n\nInside a Linux VM, create a mount point for the optical drive with the guest tools image and run the installer:# mkdir /mnt/cdrom\r\n# mount <path_to_guest_tools_iso> /mnt/cdrom\r\n# bash /mnt/cdrom/install\t\t\t\t\t\t\t\t\n\nCommand-line interface\n\nCreate a compute volume from the vz-guest-tools-win or vz-guest-tools-lin image, depending on the VM operating system. For example:# vinfra service compute volume create guest-tools-lin --image vz-guest-tools-lin \\\r\n--storage-policy default --size 1\n\nAttach the volume with the guest tools to the required virtual machine. For example:# vinfra service compute server volume attach guest-tools-lin --server centos7\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/sda                             |\r\n| id     | 132908e4-3543-419f-a4bf-c219f74e2640 |\r\n+--------+--------------------------------------+\r\n\n\nLog in to the virtual machine.\n\nInside the VM, do the following:\n\nInside a Windows VM, go to the mounted optical drive in Explorer and install the guest tools by running setup.exe. After the installation is complete, restart the VM.\n\nInside a Linux VM, create a mount point for the optical drive with the guest tools image and run the installer:# mkdir /mnt/cdrom\r\n# mount <path_to_guest_tools_iso> /mnt/cdrom\r\n# bash /mnt/cdrom/install\t\n\nSee also\n\nSetting a password inside virtual machines\n\nRunning commands in virtual machines without network connectivity\n\nManaging volume snapshots\n\nUninstalling guest tools",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nCreate a compute volume from the vz-guest-tools-win or vz-guest-tools-lin image, depending on the VM operating system. For example:# vinfra service compute volume create guest-tools-lin --image vz-guest-tools-lin \\\r\n--storage-policy default --size 1\n\n\nAttach the volume with the guest tools to the required virtual machine. For example:# vinfra service compute server volume attach guest-tools-lin --server centos7\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/sda                             |\r\n| id     | 132908e4-3543-419f-a4bf-c219f74e2640 |\r\n+--------+--------------------------------------+\r\n\n\nLog in to the virtual machine.\n\nInside the VM, do the following:\n\nInside a Windows VM, go to the mounted optical drive in Explorer and install the guest tools by running setup.exe. After the installation is complete, restart the VM.\n\nInside a Linux VM, create a mount point for the optical drive with the guest tools image and run the installer:# mkdir /mnt/cdrom\r\n# mount <path_to_guest_tools_iso> /mnt/cdrom\r\n# bash /mnt/cdrom/install\t\n\n\n\n\n",
                "title": "As a virtual machine user"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nCreate a compute volume from the vz-guest-tools-win or vz-guest-tools-lin image, depending on the VM operating system:\n\nOn the Compute > Virtual machines > Images tab, click the vz-guest-tools-win or vz-guest-tools-lin image.\nOn the image right pane, click Create volume.\nIn the Create volume from image window, specify a name for the volume, and then click Create.\n\n\n\nAttach the volume with the guest tools to the virtual machine:\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM.\nOn the VM right pane, click the pencil icon in the Volumes field.\nIn the Volumes window, click Attach.\nIn the Attach volume window, select the created volume with the guest tools, and then click Attach. The attached volume will be marked as ISO.\nIn the Volumes window, click Done, to save your changes.\n\n\nLog in to the virtual machine.\n\nInside the VM, do the following:\n\nInside a Windows VM, go to the mounted optical drive in Explorer and install the guest tools by running setup.exe. After the installation is complete, restart the VM.\n\nInside a Linux VM, create a mount point for the optical drive with the guest tools image and run the installer:# mkdir /mnt/cdrom\r\n# mount <path_to_guest_tools_iso> /mnt/cdrom\r\n# bash /mnt/cdrom/install\t\t\t\t\t\t\t\t\n\n\n\n\n",
                "title": "As a virtual machine user"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/installing-guest-tools.html"
    },
    {
        "title": "Creating storage classes",
        "content": "Creating storage classes\nIn Virtuozzo Hybrid Infrastructure, storage classes map to compute storage policies defined in the admin panel. Creating a storage class is required for all storage operations in a Kubernetes cluster.\nTo create a storage class\n\u00d0\u00a1lick + Create on the Kubernetes dashboard and specify a YAML file that defines this object. For example:apiVersion: storage.k8s.io/v1\r\nkind: StorageClass\r\nmetadata:\r\n  name: default\r\n  annotations:\r\n    storageclass.kubernetes.io/is-default-class: \"true\"\r\nprovisioner: cinder.csi.openstack.org\r\nparameters:\r\n  type: default\nThis manifest describes the storage class default with the storage policy default. It also marks this storage policy as default for the Kubernetes cluster. The storage policy must exist in the compute cluster and be specified in the storage quotas to the current project.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-storage-classes.html"
    },
    {
        "title": "Provisioning file storage space",
        "content": "Provisioning file storage space\nFile storage space is provisioned via Network File System (NFS) exports created in the NFS cluster.\nPrerequisites\n\nA clear understanding of file storage, which is explained in About file storage.\nYour hardware meets the requirements listed in Server requirements.\nYour infrastructure networks are set up, as described in Setting up networks for file storage.\nThe storage cluster is created by following the instructions in Deploying the storage cluster.\n\nProvisioning overview\n\nCreate the NFS cluster.\nCreate NFS shares.\nCreate NFS exports.\nAccess NFS shares by mounting user exports, as described in Accessing NFS shares in the Storage User\u00e2\u0080\u0099s Guide.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-file-storage.html"
    },
    {
        "title": "Creating S3 users via REST API",
        "content": "Creating S3 users via REST API\nYou can create an S3 user by sending a PUT request to the ostor-users service along with an email address:# s3_curl PUT \"http://s3.example.com/?ostor-users&emailAddress=user@example.com\"\r\n{\r\n    \"UserEmail\": \"user@example.com\",\r\n    \"UserId\": \"ca55631f9f3d59dc\",\r\n    \"AWSAccessKeys\": [\r\n        {\r\n            \"AWSAccessKeyId\": \"ca55631f9f3d59dcDF4M\",\r\n            \"AWSSecretAccessKey\": \"QCbj17BzeepyvUAdJeFNFYW9fCzbq0uFal6e5pGm\"\r\n        }\r\n    ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/creating-s3-users-via-rest-api.html"
    },
    {
        "title": "Listing SSH keys",
        "content": "Listing SSH keysGET /os-keypairs\r\n\nList key pairs that are associated with the account.\nSource: https://docs.openstack.org/api-ref/compute/index.html?expanded=list-keypairs-detail#list-keypairs\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nuser_id (Optional)\nquery\nstring\n\nThis allows administrative users to operate key pairs of specified\r\nuser ID.\nNew in version 2.10\n\nlimit (Optional)\nquery\ninteger\n\nRequests a page size of items. Returns a number of items up to a limit value.\r\nUse the limit parameter to make an initial limited request and use the\r\nlast-seen item from the response as the marker parameter value in a\r\nsubsequent limited request.\nNew in version 2.35\n\nmarker (Optional)\nquery\nstring\n\nThe last seen item. Use the limit parameter to make an initial limited\r\nrequest and use the last seen item from the response as the marker\r\nparameter value in a subsequent limited request.\nNew in version 2.35\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\n-H 'X-OpenStack-Nova-API-Version: 2.72' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-keypairs\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nkeypairs\n\nbody\narray\nArray of keypair objects\n\nkeypair\n\nbody\nobject\nThe keypair object.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nname\n\nbody\nstring\nA name for the key pair which will be used to reference it later.\n\npublic_key\n\nbody\nstring\nThe key pair public key.\n\nfingerprint\n\nbody\nstring\nThe fingerprint for the key pair.\n\ntype\n\nbody\nstring\n\nThe type of the key pair. Allowed values are ssh or x509.\nNew in version 2.2\n\nkeypairs_links (Optional)\nbody\narray\n\nLinks pertaining to key pair. See API Guide / Links and\r\nReferences\r\nfor more info.\nNew in version 2.35\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"keypairs\": [\r\n    {\r\n      \"keypair\": {\r\n        \"public_key\": \"ssh-rsa AAAA<...> VSTOR-KEY-DESC:Key description\",\r\n        \"created_at\": \"2021-02-08T19:07:30.441615\",\r\n        \"type\": \"ssh\",\r\n        \"name\": \"key1\",\r\n        \"fingerprint\": \"c9:6c:cc:ea:9f:f2:d4:0b:6e:1b:57:12:27:4e:1f:a5\"\r\n      }\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-ssh-keys.html"
    },
    {
        "title": "Deleting S3 accounts via REST API",
        "content": "Deleting S3 accounts via REST API\nYou can delete an existing account of an S3 user by sending a DELETE request to the ostor-accounts service along with the user email address and account name:# s3_curl DELETE \"http://s3.example.com/?ostor-accounts&emailAddress=user@example.com&accountName=account\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-s3-accounts-via-rest-api.html"
    },
    {
        "title": "Managing virtual routers",
        "content": "Managing virtual routers\nVirtual routers provide L3 services such as routing and Source Network Address Translation (SNAT) between virtual and physical networks, or different virtual networks:\n\nA virtual router between virtual and physical networks provides access to public networks, such as the Internet, for VMs connected to this virtual network.\nA virtual router between different virtual networks provides network communication for VMs connected to these virtual networks.\n\nA virtual router has two types of ports:\n\nAn external gateway that is connected to a physical network.\nAn internal port that is connected to a virtual network.\n\nWith virtual routers, you can do the following:\n\nCreate virtual routers\nChange external or internal router interfaces\nCreate, edit, and delete static routes\nChange a router name\nDelete a router\n\nLimitations\n\nA router can only connect networks that have IP management enabled.\n\nYou can delete a virtual router if no floating IP addresses are associated with any network it is connected to.\n\nPrerequisites\n\nCompute networks are created, as described in Managing virtual networks.\nThe compute networks that are to be connected to a router have a gateway specified.\n\nTo create a virtual router\n\nNavigate to the Routers screen, and then click Add router.\n\nIn the Add router window:\n\nSpecify a router name.\nFrom the Network drop-down menu, select a physical network through which external access will be provided via an external gateway. The new external gateway will pick an unused IP address from the selected physical network.\nIn the Add internal interfaces section, select one or more virtual networks to connect to a router via internal interfaces. The new internal interfaces will attempt to use the gateway IP address of the selected virtual networks by default.\n\nSelect or deselect the SNAT check box to enable or disable SNAT on the external gateway of the router. With SNAT enabled, the router replaces VM private IP addresses with the public IP address of its external gateway.\n\nClick Create.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-virtual-routers.html"
    },
    {
        "title": "Deleting SSH keys",
        "content": "Deleting SSH keysDELETE /os-keypairs/{keypair_name}\r\n\nDelete a key pair with the specified name.\nSource: https://docs.openstack.org/api-ref/compute/index.html?expanded=delete-keypair-detail#delete-keypair\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nkeypair_name\n\npath\nstring\nThe key pair name.\n\nuser_id (Optional)\nbody\nstring\n\nThe user ID for a key pair. This allows administrative users to\r\nupload keys for other users than themselves.\nNew in version 2.10\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-keypairs/key2\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-ssh-keys.html"
    },
    {
        "title": "3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nTo configure the agent appliance, you need a Virtuozzo Hybrid Infrastructure user account. This account must have the Administrator role in the Default domain. For more information about users, refer to the Virtuozzo Hybrid Infrastructure documentation. Grant this account access to all projects in the Default domain.\nTo do this, run the following script in the Virtuozzo Hybrid Infrastructure cluster via the OpenStack Command-Line Interface. For more information on how to connect to this interface, refer to the Virtuozzo Hybrid Infrastructure documentation.\n# su - vstoradmin\n# kolla-ansible post-deploy\n# exit\n# . /etc/kolla/admin-openrc.sh\n# openstack --insecure user set --project admin --project-domain Default --domain Default USERNAME\n# openstack --insecure role add --domain Default --user USERNAME --user-domain Default compute --inherited\n\n\nHere, USERNAME is the Virtuozzo Hybrid Infrastructure account with the Administrator role in the Default domain. The virtual appliance will use this account in order to back up and restore the virtual machines in any child project under the Default domain.\nReplace Default with the name of another domain to manage backups for virtual machines in that domain.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-agent-for-virtuozzo-hybrid-infrastructure-from-qcow2-template/configuring-user-accounts-in-virtuozzo-hybrid-infrastructure.html"
    },
    {
        "title": "4.4. Configuring Client Functions\u00c2\u00b6",
        "content": "4.4. Configuring Client Functions | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n4.4. Configuring Client Functions\u00c2\u00b6\nIn Products & Services > Your Order Page > Your Product > Client Functions you can control what features the customer will have access to in the client portal, by clicking Enable/Disable next to the given option. Use the Edit button to adjust function appearance in the client portal.\nFor more information about standard client functions.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/hostbill-bitninja/configuring-functions.html"
    },
    {
        "title": "Deleting bucket quotas via CLI",
        "content": "Deleting bucket quotas via CLI\nYou can delete the current quotas per bucket with the rm-quotas command and parameter -b specifying the bucket name:# ostor-s3-admin rm-quotas -b bucket1 -V 0100000000000002\r\nsuccessfully removed quotas",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-bucket-quotas-via-cli.html"
    },
    {
        "title": "Setting quotas for buckets via CLI",
        "content": "Setting quotas for buckets via CLI\nYou can limit storage usage per bucket with the set-quotas command and the following parameters: -b specifying the bucket name and -q specifying the usage limit in gigabytes:# ostor-s3-admin set-quotas -b bucket1 -q 256 -V 0100000000000002\r\nversion: '1'\r\nsize: '256'\r\ntype: 'bucket'",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-quotas-for-buckets-via-cli.html"
    },
    {
        "title": "Creating S3 accounts via CLI",
        "content": "Creating S3 accounts via CLI\nYou can create an account for an S3 user and generate an access key pair (S3 Access Key ID, S3 Secret Access Key) by using the ostor-s3-admin create-account command. You need to specify the user email and an account name. For example:# ostor-s3-admin create-account -V 0100000000000002 -n account -e user@email.com\r\nUserEmail:user@email.com\r\nUserId:b09693b73b3c7686\r\nAccountName:account\r\nFlags:none\r\nKeyPair[0]:S3AccessKeyId:b09693b73b3c7686ESY0\r\nKeyPair[0]:S3SecretAccessKey:VxGZc12KKECUe1361IWrvXSVvZOdZAsfg4pL4M7T\nThe first 16 symbols of the generated access key ID are equal to the user ID.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/creating-s3-accounts-via-cli.html"
    },
    {
        "title": "Deleting S3 accounts via CLI",
        "content": "Deleting S3 accounts via CLI\nYou can delete existing S3 accounts with the ostor-s3-admin delete-account command. You need to specify either the user email (-e) or S3 ID (-i) and the account name. For example:# ostor-s3-admin delete-account -V 0100000000000002 -n account -e user@email.com",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-s3-accounts-via-cli.html"
    },
    {
        "title": "2. Deploying the Acronis Agent for VMware from an OVF Template\u00c2\u00b6",
        "content": "2. Deploying the Acronis Agent for VMware from an OVF Template | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n2. Deploying the Acronis Agent for VMware from an OVF Template\u00c2\u00b6\nThe migration process will be divided in to four sections:\nBefore you proceed to deploy one or more agents, take note of the following:\n\nAgent system requirements.\nBy default, a virtual appliance is assigned 4 GB of RAM and 2 vCPUs, which is optimal and sufficient for most operations. It is recommended, however, to let an agent have 8 GB of RAM and 4 vCPUs to improve backup performance if the backup traffic exceeds 100 MB/s (in 10 Gbps networks, for example).\nAs for storage, appliance virtual disks occupy no more than 6 GB. Thick or thin disk format does not matter as it does not affect the appliance performance.\n\nThe number of agents.\nEven though one virtual appliance can protect the entire vSphere environment, the best practice is to deploy one virtual appliance per vSphere cluster (or per host, if there are no clusters). This makes for faster backups because the appliance can attach the backed-up disks by using the HotAdd transport and therefore direct the backup traffic from one local disk to another.\nYou can use both the virtual appliance and Acronis Agent for VMware for Windows at the same time, as long as they are connected to the same vCenter Server or different ESXi hosts. Avoid connecting one agent to an ESXi directly and another to the vCenter Server which manages this ESXi.\nIt is not recommended to use locally attached storage (i.e. storing backups on virtual disks added to the virtual appliance) if you have more than one agent.\n\nDisable automatic DRS for the agents.\nIf the virtual appliance is deployed to a vSphere cluster, be sure to disable automatic vMotion for it. In the cluster DRS settings, enable individual virtual machine automation levels, and then set Automation level for the virtual appliance to Disabled.\n\nIn this chapter:\n\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-acronis-agent-for-vmware-from-ovf-template/index.html"
    },
    {
        "title": "Listing user buckets via REST API",
        "content": "Listing user buckets via REST API\nYou can list all buckets in S3 with the ostor-buckets service:# s3_curl GET \"http://s3.example.com/?ostor-buckets\"\r\n{\r\n\"Buckets\": [\r\n    {\r\n        \"size\": {\r\n            \"current\": 12288,\r\n            \"h_integral\": 7360512,\r\n            \"hmax\": 12288,\r\n            \"last_ts\": 424241\r\n        },\r\n        \"epoch\": 0,\r\n        \"owner_id\": \"ba7eba06129464c5\",\r\n        \"name\": \"bucket1\",\r\n        \"creation_date\": \"2018-05-25T17:12:00.000Z\"\r\n    },\r\n    {\r\n        \"size\": {\r\n            \"current\": 46700160,\r\n            \"h_integral\": 28160196480,\r\n            \"hmax\": 46700160,\r\n            \"last_ts\": 424237\r\n        },\r\n        \"epoch\": 0,\r\n        \"owner_id\": \"ccbec013d9fd3918\",\r\n        \"name\": \"bucket2\",\r\n        \"creation_date\": \"2018-05-25T13:51:55.000Z\"\r\n    },\r\n    {\r\n        \"size\": {\r\n            \"current\": 12288,\r\n            \"h_integral\": 8036352,\r\n            \"hmax\": 12288,\r\n            \"last_ts\": 424186\r\n        },\r\n        \"epoch\": 0,\r\n        \"owner_id\": \"9d80d59edbe2862a\",\r\n        \"name\": \"bucket3\",\r\n        \"creation_date\": \"2018-05-23T10:30:49.000Z\"\r\n    }\r\n]}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/listing-user-buckets-via-rest-api.html"
    },
    {
        "title": "Deleting statistics objects via REST API",
        "content": "Deleting statistics objects via REST API\nYou can delete existing statistics objects with the ostor-usage service and parameter obj specifying the statistics object:# s3_curl DELETE \"http://s3.example.com/?ostor-usage&obj=s3-usage-8000000000000065-2017-02-01T16:31:54.000Z-1800\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-statistics-objects-via-rest-api.html"
    },
    {
        "title": "Managing router interfaces",
        "content": "Managing router interfaces\nPrerequisites\n\nYou have a virtual router created, as described in Creating virtual routers.\n\nTo add an external router interface\n\nAdmin panel\n\nIf you already have an external gateway, remove the existing one first.\nOn the Routers screen, click the router name. Open the Interfaces tab to view the list of its interfaces.\nClick Add on the toolbar, or click Add interface if there are no interfaces to show.\n\nIn the Add interface window, do the following:\n\nSelect External gateway.\nFrom the Network drop-down menu, select a physical network to connect to the router. The new interface will pick an unused IP address from the selected physical network. You can also provide a specific IP address from the selected physical network to assign to the interface in the IP address field.\n\nSelect or deselect the SNAT check box to enable or disable SNAT on the external gateway of the router. With SNAT enabled, the router replaces VM private IP addresses with the public IP address of its external gateway.\n\nClick Add.\n\nCommand-line interface\nUse the following command:vinfra service compute router iface add [--ip-address <ip-address>]\r\n                                        --interface <network> router\r\n\n\n--ip-address <ip-address>\n\nIP address\n--interface <network>\n\nNetwork name or ID\nrouter\n\nVirtual router name or ID\n\nFor example, to add an external interface from the physical network public to the virtual router myrouter with the IP address 10.94.129.76, run:# vinfra service compute router iface add myrouter --interface public \\\r\n--ip-address 10.94.129.76\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| network_id                           | is_external | ip_addresses    | status |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-49de-9346-26513d8d1262 | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-48b2-9e4f-64a128ce97ae | False       | - 192.168.128.1 | ACTIVE |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n\nThe added interface will appear in the vinfra service compute router iface list output:# vinfra service compute router iface list myrouter\r\n+--------------------------------+-------------+-----------------+--------+\r\n| network_id                     | is_external | ip_addresses    | status |\r\n+--------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-<...> (public)   | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-<...> (private)  | False       | - 192.168.128.1 | ACTIVE |\r\n+--------------------------------+-------------+-----------------+--------+\r\n\n\nTo add an internal router interface\n\nAdmin panel\n\nOn the Routers screen, click the router name to open the list of its interfaces.\nClick Add.\n\nIn the Add interface window, select a network to connect to the router from the Network drop-down menu. The new interface will attempt to use the gateway IP address of the selected virtual network by default. If it is in use, specify an unused IP address from the selected virtual network to assign to the interface in the IP address field.\n\nClick Add.\n\nCommand-line interface\nUse the following command:vinfra service compute router iface add [--ip-address <ip-address>]\r\n                                        --interface <network> router\r\n\n\n--ip-address <ip-address>\n\nIP address\n--interface <network>\n\nNetwork name or ID\nrouter\n\nVirtual router name or ID\n\nFor example, to add an interface from the virtual network private2 to the virtual router myrouter with the IP address 192.168.30.3, run:# vinfra service compute router iface add myrouter --interface private2 \\\r\n--ip-address 192.168.30.3\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| network_id                           | is_external | ip_addresses    | status |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-49de-9346-26513d8d1262 | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-48b2-9e4f-64a128ce97ae | False       | - 192.168.128.1 | ACTIVE |\r\n| 86803e07-a6d7-4809-9566-1cbe4a89adfd | False       | - 192.168.30.3  | DOWN   |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n\nThe added interface will appear in the vinfra service compute router iface list output:# vinfra service compute router iface list myrouter\r\n+--------------------------------+-------------+-----------------+--------+\r\n| network_id                     | is_external | ip_addresses    | status |\r\n+--------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-<...> (public)   | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-<...> (private)  | False       | - 192.168.128.1 | ACTIVE |\r\n| 86803e07-a6d7-<...> (private2) | False       | - 192.168.30.3  | ACTIVE |\r\n+--------------------------------+-------------+-----------------+--------+\r\n\n\nTo edit external interface parameters\n\nAdmin panel\n\nClick the ellipsis icon next to the external interface, and then click Edit. \nIn the Edit interface window, change the  IP address or configure SNAT. \nClick Save to save your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute router set [--external-gateway <network> |\r\n                                  --no-external-gateway]\r\n                                  [--fixed-ip <fixed-ip>]\r\n                                  [--enable-snat | --disable-snat]\r\n                                  <router>\r\n\n\n--external-gateway <network>\n\nSpecify a physical network to be used as the router\u00e2\u0080\u0099s external gateway (name or ID)\n--no-external-gateway\n\nRemove the external gateway from the router\n--enable-snat\n\nEnable source NAT on the external gateway\n--disable-snat\n\nDisable source NAT on the external gateway\n--fixed-ip <fixed-ip>\n\nDesired IP on the external gateway\n<router>\n\nVirtual router name or ID\n\nFor example, to disable SNAT on the external gateway of the virtual router myrouter, run:# vinfra service compute router set myrouter --disable-snat --external-gateway public\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | []                                               |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\r\n\n\nTo remove a router interface \n\nAdmin panel\n\nSelect the interface you want to remove.\nClick the ellipsis icon next to it, and then click Delete.\nIn the confirmation window, click Delete.\n\nCommand-line interface\nUse the following command:vinfra service compute router iface remove --interface <network> router\r\n\n\n--interface <network>\n\nNetwork name or ID\nrouter\n\nVirtual router name or ID\n\nFor example, to remove the interface from the virtual network private2 from the virtual router myrouter, run:# vinfra service compute router iface remove myrouter --interface private2\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| network_id                           | is_external | ip_addresses    | status |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-49de-9346-26513d8d1262 | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-48b2-9e4f-64a128ce97ae | False       | - 192.168.128.1 | ACTIVE |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n\n\nSee also\n\nManaging static routes\n\nViewing router ports",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router iface add [--ip-address <ip-address>]\r\n                                        --interface <network> router\r\n\n\n--ip-address <ip-address>\n\nIP address\n--interface <network>\n\nNetwork name or ID\nrouter\n\nVirtual router name or ID\n\nFor example, to add an external interface from the physical network public to the virtual router myrouter with the IP address 10.94.129.76, run:# vinfra service compute router iface add myrouter --interface public \\\r\n--ip-address 10.94.129.76\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| network_id                           | is_external | ip_addresses    | status |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-49de-9346-26513d8d1262 | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-48b2-9e4f-64a128ce97ae | False       | - 192.168.128.1 | ACTIVE |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n\nThe added interface will appear in the vinfra service compute router iface list output:# vinfra service compute router iface list myrouter\r\n+--------------------------------+-------------+-----------------+--------+\r\n| network_id                     | is_external | ip_addresses    | status |\r\n+--------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-<...> (public)   | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-<...> (private)  | False       | - 192.168.128.1 | ACTIVE |\r\n+--------------------------------+-------------+-----------------+--------+\r\n\n",
                "title": "To add an external router interface"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router iface add [--ip-address <ip-address>]\r\n                                        --interface <network> router\r\n\n\n--ip-address <ip-address>\n\nIP address\n--interface <network>\n\nNetwork name or ID\nrouter\n\nVirtual router name or ID\n\nFor example, to add an interface from the virtual network private2 to the virtual router myrouter with the IP address 192.168.30.3, run:# vinfra service compute router iface add myrouter --interface private2 \\\r\n--ip-address 192.168.30.3\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| network_id                           | is_external | ip_addresses    | status |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-49de-9346-26513d8d1262 | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-48b2-9e4f-64a128ce97ae | False       | - 192.168.128.1 | ACTIVE |\r\n| 86803e07-a6d7-4809-9566-1cbe4a89adfd | False       | - 192.168.30.3  | DOWN   |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n\nThe added interface will appear in the vinfra service compute router iface list output:# vinfra service compute router iface list myrouter\r\n+--------------------------------+-------------+-----------------+--------+\r\n| network_id                     | is_external | ip_addresses    | status |\r\n+--------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-<...> (public)   | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-<...> (private)  | False       | - 192.168.128.1 | ACTIVE |\r\n| 86803e07-a6d7-<...> (private2) | False       | - 192.168.30.3  | ACTIVE |\r\n+--------------------------------+-------------+-----------------+--------+\r\n\n",
                "title": "To add an internal router interface"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router set [--external-gateway <network> |\r\n                                  --no-external-gateway]\r\n                                  [--fixed-ip <fixed-ip>]\r\n                                  [--enable-snat | --disable-snat]\r\n                                  <router>\r\n\n\n--external-gateway <network>\n\nSpecify a physical network to be used as the router\u00e2\u0080\u0099s external gateway (name or ID)\n--no-external-gateway\n\nRemove the external gateway from the router\n--enable-snat\n\nEnable source NAT on the external gateway\n--disable-snat\n\nDisable source NAT on the external gateway\n--fixed-ip <fixed-ip>\n\nDesired IP on the external gateway\n<router>\n\nVirtual router name or ID\n\nFor example, to disable SNAT on the external gateway of the virtual router myrouter, run:# vinfra service compute router set myrouter --disable-snat --external-gateway public\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | []                                               |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\r\n\n",
                "title": "To edit external interface parameters"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router iface remove --interface <network> router\r\n\n\n--interface <network>\n\nNetwork name or ID\nrouter\n\nVirtual router name or ID\n\nFor example, to remove the interface from the virtual network private2 from the virtual router myrouter, run:# vinfra service compute router iface remove myrouter --interface private2\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| network_id                           | is_external | ip_addresses    | status |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n| 720e45bc-4225-49de-9346-26513d8d1262 | True        | - 10.94.129.76  | ACTIVE |\r\n| e6f146ce-a6d0-48b2-9e4f-64a128ce97ae | False       | - 192.168.128.1 | ACTIVE |\r\n+--------------------------------------+-------------+-----------------+--------+\r\n\n",
                "title": "To remove a router interface "
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nIf you already have an external gateway, remove the existing one first.\nOn the Routers screen, click the router name. Open the Interfaces tab to view the list of its interfaces.\nClick Add on the toolbar, or click Add interface if there are no interfaces to show.\n\nIn the Add interface window, do the following:\n\nSelect External gateway.\nFrom the Network drop-down menu, select a physical network to connect to the router. The new interface will pick an unused IP address from the selected physical network. You can also provide a specific IP address from the selected physical network to assign to the interface in the IP address field.\n\nSelect or deselect the SNAT check box to enable or disable SNAT on the external gateway of the router. With SNAT enabled, the router replaces VM private IP addresses with the public IP address of its external gateway.\n\n\n\n\n\n\n\nClick Add.\n\n",
                "title": "To add an external router interface"
            },
            {
                "example": "\nAdmin panel\n\nOn the Routers screen, click the router name to open the list of its interfaces.\nClick Add.\n\nIn the Add interface window, select a network to connect to the router from the Network drop-down menu. The new interface will attempt to use the gateway IP address of the selected virtual network by default. If it is in use, specify an unused IP address from the selected virtual network to assign to the interface in the IP address field.\n\n\n\n\n\nClick Add.\n\n",
                "title": "To add an internal router interface"
            },
            {
                "example": "\nAdmin panel\n\nClick the ellipsis icon next to the external interface, and then click Edit. \nIn the Edit interface window, change the  IP address or configure SNAT. \nClick Save to save your changes.\n\n",
                "title": "To edit external interface parameters"
            },
            {
                "example": "\nAdmin panel\n\nSelect the interface you want to remove.\nClick the ellipsis icon next to it, and then click Delete.\nIn the confirmation window, click Delete.\n\n",
                "title": "To remove a router interface "
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-router-interfaces.html"
    },
    {
        "title": "Querying bucket limits in WHMCS",
        "content": "Querying bucket limits in WHMCS\nYou can display the current limits with the ostor-limits service and parameter bucket specifying the bucket name. WHMCS displays the bucket limits in S3 cluster when you click the Get button. Create a file S3_getLimitsForBucket.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Get s3 bucket limits.\r\nfunction S3_getLimitsForBucket($bucket) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get s3 user limits.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-limits&bucket=\" . $bucket,\r\n        \"GET\"\r\n    );\r\n\r\n    // Store s3 result.\r\n    $_SESSION['s3_limits_bucket'] = $s3_client;\r\n    $_SESSION['s3_bucket'] = $bucket;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_getLimitsForBucket($_GET['bucket']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-bucket-limits-in-whmcs.html"
    },
    {
        "title": "Enabling and disabling data-in-transit encryption",
        "content": "Enabling and disabling data-in-transit encryption\nPrerequisites\n\nEnsure that an infrastructure network and network switches are configured to use jumbo frames (MTU 9000). Otherwise, enabling data-in-transit encryption will significantly decrease the cluster performance.\nIf you want to encrypt an infrastructure network with the Storage traffic type, ensure that IPv6 traffic and IPv6 multicast addresses are allowed on your network equipment.\nIf you want to encrypt an infrastructure network with the VM private traffic type, keep in mind that the encryption increases the default MTU overhead for virtual networks from 50 to 87 bytes. If you have virtual networks created in version 5.2 or earlier, or virtual networks with a custom MTU setting, you need to manually adjust the MTU of virtual machines connected to such virtual networks before enabling the encryption.\nIf you want to encrypt an infrastructure network with the VM backups traffic type, note that the encryption may break agentless backup integration. To avoid this, reassign the VM backups traffic type to an unencrypted network.\n\nTo enable data-in-transit encryption\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Enable encryption.\nIn the Enable encryption window, review the important information about the encryption requirements, and click Enable.\nWait until the operation is finished. You cannot manage infrastructure networks while the operation is in progress.\n\nCommand-line interface\nUse the following command:vinfra cluster network encryption enable [--no-switch-storage-ipv6] <network1> [<network2> ...]\n\n--no-switch-storage-ipv6\n\nDo not switch chunk services to IPv6 addresses\n<network>\n\nNetwork ID or name\n\nFor example, to enable data-in-transit encryption for the Private network, run:# vinfra cluster network encryption enable Private\nTo check the encryption status of your networks, use the vinfra cluster network encryption status command:# vinfra cluster network encryption status\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n| id                                   | name    | status   | subnets                               |\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n| fa0d118e-2ec5-43e5-8813-41ab95d7f1f1 | Private | enabled  | - enabled    192.168.128.0/24         |\r\n|                                      |         |          | - enabled    fd48:e4ee:f220:2808::/64 |\r\n| 178f54ac-7040-40db-95cb-099cc3e8394e | Public  | disabled | - disabled   10.136.16.0/20           |\r\n+--------------------------------------+---------+----------+---------------------------------------+\n\nTo disable data-in-transit encryption\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Disable encryption.\nIn the confirmation window, click Disable.\nWait until the operation is finished. You cannot manage infrastructure networks while the operation is in progress.\n\nCommand-line interface\nUse the following command:vinfra cluster network encryption disable <network1> [<network2> ...]\n\n<network>\n\nNetwork ID or name\n\nFor example, to disable data-in-transit encryption for the Private network, run:# vinfra cluster network encryption disable Private\nTo check the encryption status of your networks, use the vinfra cluster network encryption status command:+--------------------------------------+---------+----------+---------------------------------------+\r\n| id                                   | name    | status   | subnets                               |\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n| fa0d118e-2ec5-43e5-8813-41ab95d7f1f1 | Private | disabled | - disabled   192.168.128.0/24         |\r\n|                                      |         |          | - disabled   fd48:e4ee:f220:2808::/64 |\r\n| 178f54ac-7040-40db-95cb-099cc3e8394e | Public  | disabled | - disabled   10.136.16.0/20           |\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n\n\nSee also\n\nManaging encryption exceptions\n\nRenewing encryption certificates",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network encryption enable [--no-switch-storage-ipv6] <network1> [<network2> ...]\n\n--no-switch-storage-ipv6\n\nDo not switch chunk services to IPv6 addresses\n<network>\n\nNetwork ID or name\n\nFor example, to enable data-in-transit encryption for the Private network, run:# vinfra cluster network encryption enable Private\nTo check the encryption status of your networks, use the vinfra cluster network encryption status command:# vinfra cluster network encryption status\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n| id                                   | name    | status   | subnets                               |\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n| fa0d118e-2ec5-43e5-8813-41ab95d7f1f1 | Private | enabled  | - enabled    192.168.128.0/24         |\r\n|                                      |         |          | - enabled    fd48:e4ee:f220:2808::/64 |\r\n| 178f54ac-7040-40db-95cb-099cc3e8394e | Public  | disabled | - disabled   10.136.16.0/20           |\r\n+--------------------------------------+---------+----------+---------------------------------------+\n",
                "title": "To enable data-in-transit encryption"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network encryption disable <network1> [<network2> ...]\n\n<network>\n\nNetwork ID or name\n\nFor example, to disable data-in-transit encryption for the Private network, run:# vinfra cluster network encryption disable Private\nTo check the encryption status of your networks, use the vinfra cluster network encryption status command:+--------------------------------------+---------+----------+---------------------------------------+\r\n| id                                   | name    | status   | subnets                               |\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n| fa0d118e-2ec5-43e5-8813-41ab95d7f1f1 | Private | disabled | - disabled   192.168.128.0/24         |\r\n|                                      |         |          | - disabled   fd48:e4ee:f220:2808::/64 |\r\n| 178f54ac-7040-40db-95cb-099cc3e8394e | Public  | disabled | - disabled   10.136.16.0/20           |\r\n+--------------------------------------+---------+----------+---------------------------------------+\r\n\n",
                "title": "To disable data-in-transit encryption"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Enable encryption.\nIn the Enable encryption window, review the important information about the encryption requirements, and click Enable.\nWait until the operation is finished. You cannot manage infrastructure networks while the operation is in progress.\n\n",
                "title": "To enable data-in-transit encryption"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Disable encryption.\nIn the confirmation window, click Disable.\nWait until the operation is finished. You cannot manage infrastructure networks while the operation is in progress.\n\n",
                "title": "To disable data-in-transit encryption"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-and-disabling-data-in-transit-encryption.html"
    },
    {
        "title": "Accessing iSCSI targets from Microsoft Hyper-V",
        "content": "Accessing iSCSI targets from Microsoft Hyper-V\nBefore connecting an iSCSI initiator of Microsoft Hyper-V to iSCSI targets working in the ALUA mode, you need to install and configure Multipath I/O (MPIO). This feature can be used starting from Windows Server 2008 R2. To connect the initiator, for example, on Microsoft Hyper-V Server 2016, do the following:\n\nRun Windows PowerShell with administrator privileges and install MPIO.> Enable-WindowsOptionalFeature \u00e2\u0080\u0093Online \u00e2\u0080\u0093FeatureName MultiPathIO\r\n\nYour server will automatically reboot to finalize the installation.\n\nIn the Windows PowerShell console, configure MPIO as follows:\n\nEnable support for iSCSI disks:> Enable-MSDSMAutomaticClaim -BusType iSCSI\r\n\n\nSet the failover policy to Fail Over Only. The policy uses a single active path for sending all I/O, and all other paths are standby. If the active path fails, one of the standby paths is used. When the path recovers, it becomes active again.> Set-MSDSMGlobalDefaultLoadBalancePolicy -Policy FOO\r\n\n\nEnable path verification. By default, the initiator will verify each path every 30 seconds.> Set-MPIOSetting -NewPathVerificationState Enabled\r\n\n\nReboot the server.\n\nConnect your targets to the iSCSI initiator as follows:\n\nIn the Control Panel > System and Security > Administrative Tools > Services window, make sure that Microsoft iSCSI Initiator Service is running and its startup type is set to Automatic.\n\nLaunch iSCSI Initiator.\n\nIn the iSCSI Initiator Properties window, open the Discovery tab and click Discover Portal.\n\nIn the Discover Target Portal window, enter the target IP address and click OK. Repeat this step for each target from the target group.\n\nOn the Targets tab, click Refresh to discover the added targets.\n\nClick Connect for each target to connect it to the initiator. In the Connect To Target window, select the Enable multi-path checkbox and click OK.\n\nOn the Targets tab, click Devices.., select the connected LUN, and click MPIO...\n\nMake sure the connected LUN has several paths.\n\nYou can now initialize the newly added disk for use in Microsoft Hyper-V. Do the following:\n\nOpen Disk Management, right-click the added disk, and choose Properties from the drop-down menu.\n\nCheck the settings on the MPIO tab. The first connected target becomes Active/Optimized and the preferred path.\n\nPartition and format the disk as usual.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/accessing-iscsi-targets-from-microsoft-hyper-v.html"
    },
    {
        "title": "5. Limitations\u00c2\u00b6",
        "content": "5. Limitations | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nPrev\n\n5. Limitations\u00c2\u00b6\nThe Hystax Acura limitations are listed in the official documentation.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nPrev\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/limitations.html"
    },
    {
        "title": "PUT service ostor-settings",
        "content": "PUT service ostor-settings\nDescription\nChanges existing object storage settings.\nRequests\nSyntaxPUT /?ostor-settings&name=<parameter_name>&value=<parameter_value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nPUT service ostor-settings parameters\n\nParameter name\nDescription\nPossible values\nDefault value\n\nOS.max_count\n\nMaximum number of object services. When this value is reached, the automatic split stops.\n1\u00e2\u0080\u009365536\n100\n\nOS.max_size\n\nMaximum size of the object service, in gigabytes. When this value is reached, the automatic split is performed.\n1\u00e2\u0080\u009316000\n1000\n\ncfg.autosplit.enabled\n\nEnables or disables the automatic split.\n0/1\n1\n\ncfg.autosplit.max_active\n\nMaximum number of splits ongoing at the same time.\n0\u00e2\u0080\u00932^31\n1\n\nostor.default_cors.enabled\n\nDefault CORS behavior if no policy is specified. To allow all CORS, specify 1. Otherwise, specify 0.\n0/1\n1\n\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nErrors\nReturns Error Code 400 if a wrong set of parameters is specified.\nExamples\nSample request\nThe following request updates the default CORS behavior.PUT /?ostor-settings&name=ostor.default_cors.enabled&value=0 /HTTP1.1\r\nDate : Mon, 14 Nov 2023 14:41:05 GMT+3:00\r\nHost : s3.example.com\r\nAuthorization : <authorization_string>\nSample responseHTTP/1.1 200 OK\r\nx-amz-req-time-micros : 404\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nx-amz-request-id : 80000000000000030008e3ac6b0bc436\r\nDate : Mon, 14 Nov 2023 14:41:07 GMT\r\nContent-type : application/json\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/put-service-ostor-settings.html"
    },
    {
        "title": "2.1. Creating an Appliance with the Acronis Agent for VMware\u00c2\u00b6",
        "content": "2.1. Creating an Appliance with the Acronis Agent for VMware | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n2.1. Creating an Appliance with the Acronis Agent for VMware\u00c2\u00b6\nTo create an appliance with the Acronis Agent for VMware from an OVF template, do the following:\n\nIn Acronis Cyber Cloud, click All devices > Add > VMware ESXi > Virtual Appliance (OVF).\nThe archived template will be downloaded to your machine.\n\nUnpack the archive. It will contain an OVF file and two VMDK files.\nMake sure that these files can be accessed from the machine running the vSphere Client.\nStart the vSphere Client and log on to the vCenter Server.\nIn the vSphere Client, click Deploy OVF Template in the Actions menu.\nThe corresponding wizard will open.\n\nOn wizard step #1, select all three files of the template.\n\nOn wizard step #2, type in a name and choose a location for the appliance.\n\nOn wizard step #3, choose a destination compute resource.\n\nOn wizard step #4, review the template details.\n\nOn wizard step #5, select storage for the appliance. If possible, select a shared datastore. The disk format, thick or thin, does not matter as it does not affect the appliance performance.\n\nOn wizard step #6, select networks for the appliance. The agent will require an Internet connection to register in the cloud.\n\nOn wizard step #7, click Finish to create the appliance.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-acronis-agent-for-vmware-from-ovf-template/creating-appliance-with-acronis-agent-for-vmware.html"
    },
    {
        "title": "Hooks",
        "content": "Hooks\nHooks allow you to execute custom code when certain events occur in WHMCS. You will need to add S3-related action links to the admin page in WHMCS.\nChange to the directory whmcs/includes/hooks and create a file S3_adminAreaClientSummaryActionLinks.php with the following contents:<?php\r\n\r\n// Modify other actions admin page.\r\nfunction S3_adminAreaClientSummaryActionLinks($vars) {\r\n\r\n    // Create additional links.\r\n    $result[] = '<b>S3 - User Management</b>';\r\n    $result[] = '<a href=\"staas_scripts/S3_createUser.php?userid=' .\r\n        $vars['userid'] . '\"><img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> Create User</a>';\r\n    $result[] = '<a href=\"staas_scripts/S3_deleteUser.php?userid=' .\r\n        $vars['userid'] . '\"><img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> Delete User</a>';\r\n    $result[] = '<a href=\"staas_scripts/S3_enableUser.php?userid=' .\r\n        $vars['userid'] . '\"><img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> Enable User</a>';\r\n    $result[] = '<a href=\"staas_scripts/S3_disableUser.php?userid=' .\r\n        $vars['userid'] . '\"><img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> Disable User</a>';\r\n    $result[] = '<a href=\"staas_scripts/S3_generateAccessKey.php?userid=' .\r\n        $vars['userid'] . '\"><img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> Generate Access Key</a>';\r\n    $result[] = '<a href=\"staas_scripts/S3_revokeAccessKey.php?userid=' .\r\n        $vars['userid'] . '\"><img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> Revoke Access Key</a>';\r\n    $result[] = '<a href=\"staas_scripts/S3_queryUser.php?userid=' .\r\n        $vars['userid'] . '\"><img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> Query User (on/off)</a>';\r\n    $result[] = '<a href=\"staas_scripts/S3_listUsers.php\">\r\n        <img src=\"http://logo.acronis.com/ogimage.png\"\r\n            width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" /> List Users (on/off)</a>';\r\n    $result[] = '&nbsp;';\r\n    $result[] = '<b>S3 - User Limits Management</b>';\r\n    $result[] = '\r\n        <form>\r\n            <input name=\"userid\" type=\"hidden\" value=\"' . $vars['userid'] . '\">\r\n            <input name=\"ops-value\" size=\"4\">\r\n            <select name=\"ops-name\">\r\n                <option>default</option>\r\n                <option>get</option>\r\n                <option>put</option>\r\n                <option>list</option>\r\n                <option>delete</option>\r\n            </select> ops/s\r\n            <br />\r\n            <input name=\"bandwidth-value\" size=\"4\">\r\n            <select name=\"bandwidth-name\">\r\n                <option>out</option>\r\n            </select> bandwidth/s\r\n            <br />\r\n            <button type=\"submit\"\r\n                formaction=\"staas_scripts/S3_setLimitsForUser.php\">Set</button>\r\n            <button type=\"submit\"\r\n                formaction=\"staas_scripts/S3_getLimitsForUser.php\">Get</button>\r\n            <button type=\"submit\"\r\n                formaction=\"staas_scripts/S3_deleteLimitsForUser.php\">Delete</button>\r\n        </form>\r\n    ';\r\n    $result[] = '&nbsp;';\r\n    $result[] = '<b>S3 - Bucket Limits Management</b>';\r\n    $result[] = '\r\n        <form>\r\n            <input name=\"userid\" type=\"hidden\" value=\"' . $vars['userid'] . '\">\r\n            <input name=\"ops-value\" size=\"4\">\r\n            <select name=\"ops-name\">\r\n                <option>default</option>\r\n                <option>get</option>\r\n                <option>put</option>\r\n                <option>list</option>\r\n                <option>delete</option>\r\n            </select> ops/s\r\n            <br />\r\n            <input name=\"bandwidth-value\" size=\"4\">\r\n            <select name=\"bandwidth-name\">\r\n                <option>out</option>\r\n            </select> bandwidth/s\r\n            <br />\r\n            <input name=\"bucket\" size=\"4\"> bucket name\r\n            <br />\r\n            <button type=\"submit\"\r\n                formaction=\"staas_scripts/S3_setLimitsForBucket.php\">Set</button>\r\n            <button type=\"submit\"\r\n                formaction=\"staas_scripts/S3_getLimitsForBucket.php\">Get</button>\r\n            <button type=\"submit\"\r\n                formaction=\"staas_scripts/S3_deleteLimitsForBucket.php\">Delete</button>\r\n        </form>\r\n    ';\r\n    $result[] = '&nbsp;';\r\n    $result[] = '<b>S3 - Usage Statistics</b>';\r\n    $result[] = '\r\n        <a href=\"staas_scripts/S3_listStatsObjects.php\">\r\n            <img src=\"http://logo.acronis.com/ogimage.png\"\r\n                width=\"16\" height=\"16\" border=\"0\" align=\"absmiddle\" />\r\n                    List Statistics Objects (on/off)\r\n        </a>\r\n        <p>\r\n            <form>\r\n                <input name=\"object\" size=\"15\"> object name\r\n                <br />\r\n                <button type=\"submit\"\r\n                    formaction=\"staas_scripts/S3_getStatsForObject.php\">Get</button>\r\n                <button type=\"submit\"\r\n                    formaction=\"staas_scripts/S3_deleteStatsForObject.php\">Delete</button>\r\n            </form>\r\n        </p>\r\n    ';\r\n    $result[] = '&nbsp;';\r\n\r\n    // Return links.\r\n    return $result;\r\n}\r\n\r\n// Modify admin area.\r\nadd_hook('AdminAreaClientSummaryActionLinks', 1, \"S3_adminAreaClientSummaryActionLinks\");\r\n?>\r\n\nThe last file extends the admin summary page and displays S3 user information as well as user and bucket limits if the corresponding links are clicked. Create a file S3_adminAreaClientSummaryPage.php with the following contents:<?php\r\n\r\n// Modify admin client summary to show S3 information.\r\nfunction S3_adminAreaClientSummaryPage($vars) {\r\n\r\n    // Sane default.\r\n    $result = '\r\n    <div class=\"row client-summary-panels\">\r\n    ';\r\n\r\n    // Show users.\r\n    if ($_SESSION['s3_list_users'] == 1) {\r\n\r\n        // Table header.\r\n        $result = $result . '\r\n        <div class=\"col-lg-6 col-sm-12\">\r\n            <div class=\"clientssummarybox\">\r\n                <div class=\"title\">\r\n                    S3 Users List\r\n                </div>\r\n                <table class=\"clientssummarystats\" cellspacing=\"0\" cellpadding=\"2\">\r\n                    <tr>\r\n                        <td><b>UserId</b></td>\r\n                        <td><b>UserEmail</b></td>\r\n                    </tr>\r\n        ';\r\n\r\n        // One row per access key pair.\r\n        foreach ($_SESSION['s3_list'] as $s3_row) {\r\n            $result = $result . '\r\n                    <tr class=\"altrow\">\r\n                        <td>' . $s3_row['UserId'] . '</td>\r\n                        <td>' . $s3_row['UserEmail'] . '</td>\r\n                    </tr>\r\n            ';\r\n        }\r\n\r\n        // Table footer.\r\n        $result = $result . '\r\n                </table>\r\n            </div>\r\n        </div>\r\n        ';\r\n    }\r\n\r\n    // Show user.\r\n    if ($_SESSION['s3_query_user'] == 1) {\r\n\r\n        // Table header.\r\n        $result = $result . '\r\n        <div class=\"col-lg-6 col-sm-12\">\r\n            <div class=\"clientssummarybox\">\r\n                <div class=\"title\">\r\n                    S3 Information for User: ' . $_SESSION['s3_userid'] . '\r\n                </div>\r\n                <table class=\"clientssummarystats\" cellspacing=\"0\" cellpadding=\"2\">\r\n                    <tr>\r\n                        <td><b>AWSAccessKeyId</b></td>\r\n                        <td><b>AWSSecretAccessKey</b></td>\r\n                    </tr>\r\n        ';\r\n\r\n        // One row per access key pair.\r\n        foreach ($_SESSION['s3_aws_access_keys'] as $s3_row) {\r\n            $result = $result . '\r\n                    <tr class=\"altrow\">\r\n                        <td>' . $s3_row['AWSAccessKeyId'] . '</td>\r\n                        <td>' . $s3_row['AWSSecretAccessKey'] . '</td>\r\n                    </tr>\r\n            ';\r\n        }\r\n\r\n        // Table footer.\r\n        $result = $result . '\r\n                </table>\r\n            </div>\r\n        </div>\r\n        ';\r\n    }\r\n\r\n    // Table footer and next header.\r\n    $result = $result . '\r\n    </div>\r\n    <div class=\"row client-summary-panels\">\r\n    ';\r\n\r\n    // Show statistics list.\r\n    if ($_SESSION['s3_stat_objects'] == 1) {\r\n\r\n        // Table header.\r\n        $result = $result . '\r\n        <div class=\"col-lg-6 col-sm-12\">\r\n            <div class=\"clientssummarybox\">\r\n                <div class=\"title\">\r\n                    S3 Statistics List\r\n                </div>\r\n                <table class=\"clientssummarystats\" cellspacing=\"0\" cellpadding=\"2\">\r\n                    <tr>\r\n                        <td><b>Object Name</b></td>\r\n                    </tr>\r\n        ';\r\n\r\n        // One row per access key pair.\r\n        foreach ($_SESSION['s3_stat']['items'] as $s3_object) {\r\n            $result = $result . '\r\n                    <tr class=\"altrow\">\r\n                        <td>' . $s3_object . '</td>\r\n                    </tr>\r\n            ';\r\n        }\r\n\r\n        // Table footer.\r\n        $result = $result . '\r\n                </table>\r\n            </div>\r\n        </div>\r\n        ';\r\n    }\r\n\r\n    // Show limits for user.\r\n    if (!empty($_SESSION['s3_limits_user'])) {\r\n\r\n        // Table header.\r\n        $result = $result . '\r\n        <div class=\"col-lg-3 col-sm-6\">\r\n            <div class=\"clientssummarybox\">\r\n                <div class=\"title\">\r\n                    S3 Limits for User\r\n                </div>\r\n                <table class=\"clientssummarystats\" cellspacing=\"0\" cellpadding=\"2\">\r\n                    <tr>\r\n                        <td><b>Type</b></td>\r\n                        <td><b>Name</b></td>\r\n                        <td><b>Value</b></td>\r\n                    </tr>\r\n        ';\r\n\r\n        // One row per access key pair.\r\n        foreach ($_SESSION['s3_limits_user'] as $s3_limits => $s3_value) {\r\n            list($s3_type, $s3_limit) = explode(\":\", $s3_limits);\r\n            $result = $result . '\r\n                    <tr class=\"altrow\">\r\n                        <td>' . $s3_type . '</td>\r\n                        <td>' . $s3_limit . '</td>\r\n                        <td>' . $s3_value . '</td>\r\n                    </tr>\r\n            ';\r\n        }\r\n\r\n        // Table footer.\r\n        $result = $result . '\r\n                </table>\r\n            </div>\r\n        </div>\r\n        ';\r\n    }\r\n\r\n    // Show limits for bucket.\r\n    if (!empty($_SESSION['s3_limits_bucket'])) {\r\n\r\n        // Table header.\r\n        $result = $result . '\r\n        <div class=\"col-lg-3 col-sm-6\">\r\n            <div class=\"clientssummarybox\">\r\n                <div class=\"title\">\r\n                    S3 Limits for Bucket: ' . $_SESSION['s3_bucket'] . '\r\n                </div>\r\n                <table class=\"clientssummarystats\" cellspacing=\"0\" cellpadding=\"2\">\r\n                    <tr>\r\n                        <td><b>Type</b></td>\r\n                        <td><b>Name</b></td>\r\n                        <td><b>Value</b></td>\r\n                    </tr>\r\n        ';\r\n\r\n        // One row per access key pair.\r\n        foreach ($_SESSION['s3_limits_bucket'] as $s3_limits => $s3_value) {\r\n            list($s3_type, $s3_limit) = explode(\":\", $s3_limits);\r\n            $result = $result . '\r\n                    <tr class=\"altrow\">\r\n                        <td>' . $s3_type . '</td>\r\n                        <td>' . $s3_limit . '</td>\r\n                        <td>' . $s3_value . '</td>\r\n                    </tr>\r\n            ';\r\n        }\r\n\r\n        // Table footer.\r\n        $result = $result . '\r\n                </table>\r\n            </div>\r\n        </div>\r\n        ';\r\n    }\r\n\r\n    // Table footer and next header.\r\n    $result = $result . '\r\n    </div>\r\n    <div class=\"row client-summary-panels\">\r\n    ';\r\n\r\n    // Show statistics for object.\r\n    if (!empty($_SESSION['s3_object_statistic'])) {\r\n\r\n        // Table header.\r\n        $result = $result . '\r\n        <div class=\"col-lg-12 col-sm-24\">\r\n            <div class=\"clientssummarybox\">\r\n                <div class=\"title\">\r\n                    S3 Statistics for Object: ' . $_SESSION['s3_object'] . '\r\n                </div>\r\n                <table class=\"clientssummarystats\" cellspacing=\"0\" cellpadding=\"2\">\r\n                    <tr>\r\n                        <td><b>fmt_version</b></td>\r\n                        <td><b>service_id</b></td>\r\n                        <td><b>start_ts</b></td>\r\n                        <td><b>period</b></td>\r\n                        <td><b>bucket</b></td>\r\n                        <td><b>epoch</b></td>\r\n                        <td><b>user_id</b></td>\r\n                        <td><b>tag</b></td>\r\n                        <td><b>put</b></td>\r\n                        <td><b>get</b></td>\r\n                        <td><b>list</b></td>\r\n                        <td><b>other</b></td>\r\n                        <td><b>uploaded</b></td>\r\n                        <td><b>downloaded</b></td>\r\n                    </tr>\r\n        ';\r\n\r\n        // One row per access key pair.\r\n        foreach ($_SESSION['s3_object_statistic']['items'] as $s3_object) {\r\n            $result = $result . '\r\n                    <tr class=\"altrow\">\r\n                        <td>' . $_SESSION['s3_object_statistic']['fmt_version']. '</td>\r\n                        <td>' . $_SESSION['s3_object_statistic']['service_id']. '</td>\r\n                        <td>' . $_SESSION['s3_object_statistic']['start_ts']. '</td>\r\n                        <td>' . $_SESSION['s3_object_statistic']['period']. '</td>\r\n                        <td>' . $s3_object['key']['bucket'] . '</td>\r\n                        <td>' . $s3_object['key']['epoch'] . '</td>\r\n                        <td>' . $s3_object['key']['user'] . '</td>\r\n                        <td>' . $s3_object['key']['tag'] . '</td>\r\n                        <td>' . $s3_object['counters']['ops']['put'] . '</td>\r\n                        <td>' . $s3_object['counters']['ops']['get'] . '</td>\r\n                        <td>' . $s3_object['counters']['ops']['list'] . '</td>\r\n                        <td>' . $s3_object['counters']['ops']['other'] . '</td>\r\n                        <td>' . $s3_object['counters']['net_io']['uploaded'] . '</td>\r\n                        <td>' . $s3_object['counters']['net_io']['downloaded'] . '</td>\r\n                    </tr>\r\n            ';\r\n        }\r\n\r\n        // Table footer.\r\n        $result = $result . '\r\n                </table>\r\n            </div>\r\n        </div>\r\n        ';\r\n    }\r\n\r\n    // Table footer.\r\n    $result = $result . '\r\n    </div>\r\n    ';\r\n\r\n    // Return table.\r\n    return $result;\r\n}\r\n\r\n// Modify admin area.\r\nadd_hook('AdminAreaClientSummaryPage', 1, \"S3_adminAreaClientSummaryPage\");\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/hooks.html"
    },
    {
        "title": "10.2. Installing Leostream Agent\u00c2\u00b6",
        "content": "10.2. Installing Leostream Agent | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n10.2. Installing Leostream Agent\u00c2\u00b6\nWhen installed on a desktop, the Leostream Agent provides the Connection Broker with additional information about the user\u00e2\u0080\u0099s session, including:\n\nWhen the user logs into the remote desktop\nWhen the user disconnects from the remote session\nWhen the user logs off of the remote desktop\nWhen the user locks or unlocks their remote desktop\nWhen the user\u00e2\u0080\u0099s session is idle\n\nIn addition, the Connection Broker requires the Leostream Agent to enforce certain role and policy options, including:\n\nAdding Local Users or adding users to the Remote Desktop Users group\nTaking actions when the user disconnects from their remote session\nUsing release plan options to lock, disconnect, or log out the user after their session is idle\nAttaching network printers specified by Connection Broker printer plans\nUsing registry plans to modify or create registry keys on the remote desktop\nChanging the hostname and joining newly provisioned Windows virtual machines to an Active Directory domain\n\nLeostream provides a Leostream Agent version for Windows operating systems and a Java version of the Leostream Agent for Linux operating systems. Ensure that you download the appropriate Leostream Agent from the Leostream Downloads page. Consult the Leostream Installation Guide for instructions on how to install the Leostream Agent on your Virtuozzo Hybrid Infrastructure virtual machines.\nThe Connection Broker address can be specified when you install the Leostream Agent. If you need to specify or change the Connection Broker address after the Leostream Agent is installed, you can use the Leostream Control Panel dialog in Windows or set the address in the leostreamagent.conf file on Linux. See the Leostream Agent Administrator\u00e2\u0080\u0099s Guide for more information.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/preparing-master-images/installing-leostream-agent.html"
    },
    {
        "title": "How to deploy WordPress in Kubernetes",
        "content": "How to deploy WordPress in KubernetesThis guide describes how to deploy a scalable WordPress application inside a Kubernetes cluster based on Virtuozzo Hybrid Infrastructure.A typical simple WordPress application consists of the following components:The WordPress server that stores website content.The MySQL server that stores users and configurations.A load balancer that routes traffic from a public network to the WordPress server or servers.To provide high availability for your website or the ability to scale it according to the external load, we will deploy multiple WordPress servers. In a real-life scenario, you should also have multiple MySQL servers with the active-active or active-passive configuration, which is out of scope of this guide. You can find a lot of examples of highly available MySQL clusters for Kubernetes on the Internet.The schema of our WordPress deployment looks as follows:Prerequisites1. Deploy a Virtuozzo Hybrid Infrastructure cluster.2. Create the compute cluster with the Kubernetes service.3. Configure the default storage policy for boot volumes on Kubernetes master nodes. Ensure that the selected policy is available for all projects where you are planning to deploy Kubernetes.4. Install kubectl on your workstation.5. Install Helm on your workstation.6. Download and install Lens on your workstation.7. Download the following WordPress deployment files:storage-class.yamlkustomization.yamlmysql-deployment.yamlwordpress-deployment-nfs.yaml8. In Virtuozzo Hybrid Infrastructure, create a demo project with enough quotas to run a Kubernetes cluster. In your project, create a virtual network, a virtual router, and upload an SSH key:For the network, specify the following parameters:Name: privateIPv4 subnet: 10.0.0.0/24Gateway: 10.0.0.1DNS server: 8.8.8.8For the router, specify the following parameters:Name: routerThe router connects your private and public networks9. Download the ISO image of the TrueNAS server and upload it to your project.Preparing the demo environmentDeploying the NFS serverThe WordPress server itself does not support native scalability. With multiple WordPress servers, these servers must have access to the same persistent volumes (PV) where the WordPress server stores its content. To have simultaneous access from multiple Kubernetes pods to the same PV, this PV must support the ReadWriteMany (RWX) access mode. As the Virtuozzo Storage driver for Kubernetes does not support RWX, we need to use an external storage, such as NFS. For more details, refer to the Kubernetes CSI Storage Developer Documentation.For this environment, we will deploy a virtual instance of the TrueNAS server inside a virtual machine.1. Open the Virtuozzo Hybrid Infrastructure self-service panel, go to the Virtual machines screen, and click Create virtual machine. Specify the following parameters:Name: nas01Image: <truenas-iso-image>Volumes:100 GiB boot volume200 GiB data volumeFlavor: large (4 vCPUs, 8 GiB of RAM)Network interface: private2. Go to the Floating IPs screen and click Add floating IP. Select your public network to pick a floating IP from and assign this IP address to your nas01 private IP address.3. Go to the nas01 virtual console and configure the TrueNAS server.4. Go to the nas01 management IP address and log in to the interface.5. Go to Services, enable the NFS service, and configure the following settings:Enable NFSv4: enabledNFSv3 ownership model for NFSv4: enabledAllow non-root mount: enabledOther settings: disabled6. Go to Storage \u00e2\u0086\u0092 Pools, click Add, and specify the following parameters:Name: pool1Select your 200 GiB diskPolicy: stripe7. Go to Storage \u00e2\u0086\u0092 Pools \u00e2\u0086\u0092 pool1, click Add Dataset, and create a dataset with the name share1. Keep all other options by default.8. Go to Sharing \u00e2\u0086\u0092 Unix Shares (NFS), click Add, and specify the following parameters:Path: /mnt/pool1/share1General options:All dirs: enabledQuiet: disabledEnabled: enabledAdvanced options:Read only: disabledMaproot User: nonMaproot Group: nonMapall User: rootMapall Group: wheel9. Test the NFS share by mounting it to your workstation. For MacOS, for example, you can mount it as follows:1\n2\n3\n4\n5\n# mkdir /Users/<your_user>/Desktop/nfs\n# mount -t nfs <nas01>:/mnt/pool1/share1 /Users/<your_user>/Desktop/nfs\n# cd /Users/<your_user>/Desktop/nfs\n# touch file\n# rm file\n10. (Optional) As soon as you configure your NFS server, we recommend limiting access to it from the Internet. With the recommended security group, you will be able to access the NFS server management UI, while the NFS server itself will only be accessible from your private network. Configure the security policy as follows:Inbound rules:Any: from your private IP range onlyHTTPS: only from your own public IPOutbound rules: keep the default rulesCreating a Kubernetes cluster1. Open the Virtuozzo Hybrid Infrastructure self-service panel.2. Go to the Kubernetes screen, and click Create Kubernetes cluster.3. Specify the following parameters:Kubernetes version: the latest versionCluster name: cluster01SSH key: your uploaded SSH keyNetwork: privateFloating IP address: For Kubernetes APIHigh availability: enabled (it will create three master nodes in the HA configuration)Master node flavor: medium or any other flavor with at least 2 vCPUs and 4 GiB of RAMIntegrated monitoring: enabledNumber of workers: 3Worker node flavor: smallOther settings: keep the default values4. Click Create.Note: Boot volumes of Kubernetes master nodes use the default storage policy that you selected in the Compute \u00e2\u0086\u0092 Kubernetes \u00e2\u0086\u0092 Settings window in the admin panel.Accessing the Kubernetes cluster1. Once the status of your cluster01 Kubernetes cluster becomes Active, open its right panel and click Download kubeconfig to download the configuration file to your local machine.2. On your local machine, open the terminal and load the kubectl configuration file:1\n# export KUBECONFIG=<your_kubeconfig_file>\n3. View the list of nodes in your Kubernetes cluster:1\n2\n3\n4\n5\n6\n7\n# kubectl get nodes\nNAME                                STATUS   ROLES    AGE     VERSION\ncluster01-mxtbkucksr3w-master-0     Ready    master   5d20h   v1.23.5\ncluster01-mxtbkucksr3w-master-1     Ready    master   5d20h   v1.23.5\ncluster01-mxtbkucksr3w-master-2     Ready    master   5d20h   v1.23.5\ncluster01-mxtbkucksr3w-node-0       Ready    <none>   5d20h   v1.23.5\ncluster01-mxtbkucksr3w-node-1       Ready    <none>   5d20h   v1.23.5\n4. Connect Lens to your Kubernetes cluster:4.1. Open Lens and add a new Kubernetes cluster by adding your kubeconfig file.4.2. Open the new Kubernetes cluster to review its components.4.3. As the Kubernetes cluster has integrated monitoring enabled, you can also view the load for your master and worker nodes, as well as other helpful usage statistics provided by the integrated Prometheus server.5. Create a storage class that allows creating persistent volumes automatically. PVs will be based on OpenStack Cinder and the underlying storage policy, and we will use the default storage class to create them for the MySQL server.Note: If you want to use a storage class with a different name, you need to change it in the storage-class.yaml file.1\n2\n3\n4\n# kubectl apply -f storage-class.yaml\n# kubectl get storageclass\nNAME                  PROVISIONER        AGE\ndefault (default)     csi-cinderplugin   171m\nDeploying NFS subdir external provisionerWe use NFS subdir external provisioner to automatically manage NFS-based persistent volumes for Kubernetes. The detailed description is also available on the GitHub page.To deploy NFS subdir external provisioner, run the following command in your terminal:1\n2\n3\n4\n5\n# helm install nfs-external nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\\n    --set nfs.server=10.10.10.5 \\\n    --set nfs.path=/mnt/pool1/share1 \\\n    --set storageClass.accessModes=ReadWriteMany \\\n    --set storageClass.name=nfs\nWhere:nfs.server is the private IP address of your NFS server.nfs.path specifies the full path to your NFS share. If you configured TrueNAS according to this guide, the path will be /mnt/pool1/share1.storageClass.accessModes is the PV access policy. In our case, it is ReadWriteMany.\n= storageClass.name sets the name for the new storage class based on NFS. In our case, it is nfs.You can check that the new storage class is successfully created by running:1\n2\n3\n# kubectl get storageclass\nNAME  PROVISIONER                                                 RECLAIMPOLICY  VOLUMEBINDINGMODE  ALLOWVOLUMEEXPANSION  AGE\nnfs   cluster.local/nfs-external-nfs-subdir-external-provisioner  Delete         Immediate          true                  5d3h\nRunning the demoDeploying a WordPress applicationDuring the preparation stage, we have created two storage classes:1\n2\n3\n4\n# kubectl get storageclass\nNAME               PROVISIONER                                                 RECLAIMPOLICY  VOLUMEBINDINGMODE  ALLOWVOLUMEEXPANSION  AGE\ndefault (default)  cinder.csi.openstack.org                                    Delete         Immediate          false                 5d3h\nnfs                cluster.local/nfs-external-nfs-subdir-external-provisioner  Delete         Immediate          true                  5d3h\nThe default storage class is based on Virtuozzo Storage, and the nfs one is based on the external NFS server with RWX persistent volumes support.Now, we can deploy a WordPress application (refer to the Prerequisites section, to download the required deployment files).1. Use the kustomization.yaml file that does the following:1.1. Creates a secret with a password for the MySQL database. You can change the default password in the parameter password=Virtuozzo1.1.2. Creates the MySQL service and a pod by running the mysql-deployment.yaml file.1.3. Creates the WordPress service and pods by running the wordpress-deployment-nfs.yaml file.2. Run the command:1\n# kubectl apply -k ./\n3. To check the deployed components, use these commands: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# kubectl get secrets\nNAME                    TYPE                                  DATA   AGE\nmysql-pass-6t2254bh75   Opaque                                1      5d2h\n# kubectl get pvc\nNAME          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nmysql-pvc     Bound    pvc-40a1d6e7-c3f2-408a-bf28-2418b3580892   20Gi       RWO            default        4d2h\nwp-pv-claim   Bound    pvc-c90b7670-f6f5-466d-9f92-b2d128d8fa93   20Gi       RWX            nfs            4d2h\n# kubectl get deployment\nNAME                                           READY   UP-TO-DATE   AVAILABLE   AGE\nnfs-external-nfs-subdir-external-provisioner   1/1     1            1           5d3h\nwordpress                                      3/3     3            3           4d2h\nwordpress-mysql                                1/1     1            1           4d2h\n# kubectl get pod\nNAME                                                            READY   STATUS    RESTARTS        AGE\nnfs-external-nfs-subdir-external-provisioner-6b9f86956d-x5hhh   1/1     Running   1 (3d23h ago)   5d3h\nwordpress-7f74bffc48-f9865                                      1/1     Running   0               4d2h\nwordpress-7f74bffc48-n87cf                                      1/1     Running   0               4d2h\nwordpress-7f74bffc48-x98bl                                      1/1     Running   0               4d2h\nwordpress-mysql-776d8c78cd-vcc77                                1/1     Running   0               4d2h\n4. To get the public IP address of your WordPress, run:1\n2\n3\n# kubectl get services wordpress\nNAME        TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)        AGE\nwordpress   LoadBalancer   10.254.158.185   23.109.29.208   80:30717/TCP   4d2h\nIn this example, your public IP address is 23.109.29.208. This is the floating IP that is assigned to the load balancer created specifically for this WordPress application in your Virtuozzo Hybrid Infrastructure project.Now, you can open this IP address in your browser to access your WordPress website. To review the WordPress components, you can also use Lens.Testing WordPress availability and scalabilityFor high availability and the ability to scale our deployment, we have deployed three replicas of the WordPress server:1\n2\n3\n4\n5\n# kubectl get pod | grep wordpress\nwordpress-7f74bffc48-f9865                                      1/1     Running   0               4d2h\nwordpress-7f74bffc48-n87cf                                      1/1     Running   0               4d2h\nwordpress-7f74bffc48-x98bl                                      1/1     Running   0               4d2h\nwordpress-mysql-776d8c78cd-vcc77                                1/1     Running   0               4d2h\n1. Open the Virtuozzo Hybrid Infrastructure self-service panel, go to the Virtual machines screen, and find the Kubernetes worker node with a name similar to <cluster01-mxtbkucksr3w-node-0>. Stop the VM by clicking Power off.2. To check the status of our pods, list them by running:1\n2\n3\n4\n5\n6\n# kubectl get pod | grep wordpress\nwordpress-7f74bffc48-f9865                                      1/1     Terminating   0               4d2h\nwordpress-7f74bffc48-n87cf                                      1/1     Running       0               4d2h\nwordpress-7f74bffc48-x7kqx                                      1/1     Running       0               50s\nwordpress-7f74bffc48-x98bl                                      1/1     Running       0               4d2h\nwordpress-mysql-776d8c78cd-vcc77                                1/1     Running       0               4d2h\nYou can see that one of our pods has just been restarted. This happens because Kubernetes automatically supports the required number of pods and creates a new pod if one of them was lost due to worker node issues. The WordPress website is still available.Note: With the default Kubernetes settings, it takes up to five minutes to reschedule a pod.3. To add more WordPress servers to support the growing workload on our website, we need to change the number of replicas by running:1\n2\n# kubectl scale --replicas=5 deployment/wordpress \ndeployment.apps/wordpress scaled       0               4d2h\n4. Check the number of pods by listing them:1\n2\n3\n4\n5\n6\n7\n8\n# kubectl get pod | grep wordpress\nwordpress-7f74bffc48-6mk2q                                      1/1     Running       0               10s\nwordpress-7f74bffc48-f9865                                      1/1     Terminating   0               4d2h\nwordpress-7f74bffc48-hhvdb                                      1/1     Running       0               10s\nwordpress-7f74bffc48-n87cf                                      1/1     Running       0               4d2h\nwordpress-7f74bffc48-x7kqx                                      1/1     Running       0               5m40s\nwordpress-7f74bffc48-x98bl                                      1/1     Running       0               4d2h\nwordpress-mysql-776d8c78cd-vcc77                                1/1     Running       0               4d2h\nNow, we have five WordPress pods running.You can also scale WordPress by changing the number of replicas in the WordPress deployment file and re-running it:1. Open wordpress-deployment-nfs.yaml.2. Change the replicas parameter from 3 to 5 or vice versa.3. Run the command:1\n# kubectl apply -k ./\nIf you have any issues with pods, you can use the following command for troubleshooting:1\n2\n3\n4\n5\n6\n7\n8\n# kubectl describe pod wordpress-7f74bffc48-f9865\nName:                      wordpress-7f74bffc48-f9865\nNamespace:                 default\nPriority:                  0\nService Account:           default\nNode:                      cluster01-mxtbkucksr3w-node-1/10.11.0.141\nStart Time:                Tue, 29 Nov 2022 16:33:03 +0200\n...\n(Optional) Deploying WordPress with Helm and BitnamiHelm allows you to deploy WordPress with a fully highly available and scalable configuration in a single click by using the Bitnami WordPress template. The detailed description is also available on the GitHub page.Before you proceed, ensure that you have the following:Helm is installed.NFS provisioner is configured with the storage class named nfs.To deploy WordPress with Helm:1. Adapt the WordPress configuration file according to your requirements. To create the default file, run:1\n# helm show values oci://registry-1.docker.io/bitnamicharts/wordpress > wordpress.yaml\nThe file will be created in your local directory. Please inspect it. If you have the default configuration created based on this guide, you can download the example configuration file or use wget:1\n# wget https://virtuozzo-k8s-demo-nfs.s3.amazonaws.com/wordpress.yaml\nThe example file has the following additional settings:Storage policy for persistent volumes: nfsWordPress admin password: Virtuozzo1!WordPress app servers replication: enabled with 3 replicasMariaDB replication: enabled with the active-passive configurationMemcached server: enabledIntegrated metrics: enabled2. Run the command:1\n# helm install -f wordpress.yaml my-wp oci://registry-1.docker.io/bitnamicharts/wordpress\nNow, you can follow the onscreen guide to access your WordPress website:1\n2\n3\n4\n5\n6\n7\n1. Get the WordPress URL by running these commands:\n  NOTE: It may take a few minutes for the LoadBalancer IP to be available.\n        Watch the status with: 'kubectl get svc --namespace default -w my-wp-wordpress'\n   export SERVICE_IP=$(kubectl get svc --namespace default my-wp-wordpress --template \"{{ range (index .status.loadBalancer.ingress 0) }}{{ . }}{{ end }}\")\n   echo \"WordPress URL: http://$SERVICE_IP/\"\n   echo \"WordPress Admin URL: http://$SERVICE_IP/admin\"\n2. Open a browser and access WordPress using the obtained URL.\nEnjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/wordpress-in-kubernetes/"
    },
    {
        "title": "Setting operations per second for buckets via REST API",
        "content": "Setting operations per second for buckets via REST API\nYou can limit operations rate with the ostor-limits service and the following parameters: bucket specifying the bucket name, ops specifying the limit type, and default=, get=, put=, list=, or delete= specifying the limit value:# s3_curl PUT \"http://s3.example.com/?ostor-limits&bucket=client&limit-type=ops&limit-resource=get&limit-value=3600\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-operations-per-second-for-buckets-via-rest-api.html"
    },
    {
        "title": "How to customize OpenStack services",
        "content": "How to customize OpenStack servicesThis guide describes how to create a custom configuration for the OpenStack services, such as Nova, Cinder, and Neutron, used in Virtuozzo Hybrid Infrastructure.Important: As we do not support custom OpenStack parameters, you need to contact the technical support team to agree on your custom OpenStack configuration or do it at your own risk.Prerequisites1. Deploy a Virtuozzo Hybrid Infrastructure cluster.2. Create the compute cluster.Configuring Nova1. Create the configuration file /etc/kolla/config/nova.conf on all of the management nodes and add any OpenStack-supported parameters. To see a full list of all available configuration parameters, refer to the official Nova documentation.2. Run the following command on the primary management node:1\n2\n# su - vstoradmin\n# kolla-ansible reconfigure -t nova\nThe command will add new parameters from the /etc/kolla/config/nova.conf file or rewrite the existing parameters in the Nova configuration.Configuring Cinder1. Create the configuration file /etc/kolla/config/cinder.conf on all of the management nodes and add any OpenStack-supported parameters. To see a full list of all available configuration parameters, refer to the official Cinder documentation.2. Run the following command on the primary management node:1\n2\n# su - vstoradmin\n# kolla-ansible reconfigure -t cinder\nThe command will add new parameters from the /etc/kolla/config/cinder.conf file or rewrite the existing parameters in the Cinder configuration.Configuring Neutron1. Create the configuration file /etc/kolla/config/neutron.conf or /etc/kolla/config/neutron/ml2_conf.ini, depending on the parameters you want to use, on all of the management nodes, and then add any OpenStack-supported parameters. To see a full list of all available configuration parameters, refer to the official Neutron documentation.2. Run the following command on the primary management node:1\n2\n# su - vstoradmin\n# kolla-ansible reconfigure -t neutron\nThe command will add new parameters from the /etc/kolla/config/neutron.conf and /etc/kolla/config/neutron/ml2_conf.ini files or rewrite the existing parameters in the Neutron configuration.Important: Custom configuration files must exist on all of the management nodes. If you add or replace a management node afterwards, add the configuration files to a new management node and reconfigure the Openstack service.Enjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/custom-openstack-configuration/"
    },
    {
        "title": "How to use Velero for Kubernetes",
        "content": "How to use Velero for KubernetesThis guide describes how to deploy Velero for Kubernetes and manage backups for Kubernetes-based applications on Virtuozzo Hybrid Infrastructure.About VeleroVelero is an open-source tool to backup and restore, perform disaster recovery, and migrate Kubernetes cluster resources and persistent volumes.Velero lets you:Take backups of your cluster and restore in case of lossMigrate cluster resources to other clustersReplicate your production cluster to development and testing clustersVelero consists of:A server that runs on your clusterA command-line client that runs locallyPrerequisites1. Deploy a Virtuozzo Hybrid Infrastructure cluster.2. Create the compute cluster with the Kubernetes and load balancing services.3. Configure a storage policy named standard for boot volumes on Kubernetes master nodes. Ensure that the selected policy is available for all projects where you are planning to deploy Kubernetes.4. Create a Kubernetes cluster.5. Ensure that you have the credentials (the access key and secret key) to the object storage service. In this guide, we will use the S3 object storage and a bucket provided by Virtuozzo Hybrid Infrastructure.6. Create a storage class with the snapshot functionality enabled:6.1. Create the default storage class with the storage policy standard. The storage policy must be available in your project. 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# cat > storage-class.yaml <<\\EOT\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: default\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"true\"\nprovisioner: cinder.csi.openstack.org\nparameters:\n  type: standard\nEOT\nApply the configuration file:1\n# kubectl create -f storage-class.yaml\n6.2. Install the required custom resource definitions (CRD) for volume snapshots:6.2.1. Check the existing CRDs:1\n2\n3\n4\n# kubectl api-resources | grep volumesnapshot\nvolumesnapshotclasses    snapshot.storage.k8s.io/v1beta1        false        VolumeSnapshotClass\nvolumesnapshotcontents   snapshot.storage.k8s.io/v1beta1        false        VolumeSnapshotContent\nvolumesnapshots          snapshot.storage.k8s.io/v1beta1        true         VolumeSnapshot\n6.2.2. Install the missing CRDs (install only one version):1\n2\n3\n4\n5\n6\n7\n8\n# git clone https://github.com/kubernetes-csi/external-snapshotter/\n# cd ./external-snapshotter\n# git checkout release-5.0\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml\n# kubectl apply -f deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml -n kube-system\n# kubectl apply -f deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml -n kube-system\nImportant: The CSI snapshotter version must not be higher than release-5.0.6.3. Create a snapshot class: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n# cat > snapshotclass.yaml <<\\EOT\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshotClass\nmetadata:\n  name: snapclass\ndriver: cinder.csi.openstack.org\ndeletionPolicy: Delete\nparameters:\n  force-create: \"true\" \nEOT\nApply the configuration file:1\n# kubectl apply -f snapshot-class.yaml\nInstalling Velero in a Kubernetes cluster1. Download the required configuration files to your local machine:1\n2\n# wget https://virtuozzo-k8s-demo.s3.amazonaws.com/credentials-velero-example\n# wget https://virtuozzo-k8s-demo.s3.amazonaws.com/velero.yaml\n2. Install the Velero command-line client on your local machine.3. Connect to the Kubernetes cluster:1\n# export KUBECONFIG=<your_k8s_kubeconfig_file>\n4. In the Velero configuration file velero.yaml, change the following parameters:bucket to the name of your object storage buckets3Url to the address of your object storage endpoint5. In the object storage credentials file credentials-velero-example, change the following parameters:aws_access_key_id to your S3 access keyaws_secret_access_key to your S3 secret key5. Add the repository where the Velero Helm chart is located:1\n# helm repo add vmware-tanzu https://vmware-tanzu.github.io/helm-charts\n6. Install the chart from the added repository:1\n2\n# helm upgrade --install velero vmware-tanzu/velero --create-namespace --namespace velero \\\n--set-file credentials.secretContents.cloud=credentials-velero-example -f velero.yaml\n7. Verify the Velero installation:1\n2\n3\n4\n5\n6\n# kubectl get backupstoragelocations -n velero\nNAME      PHASE       LAST VALIDATED   AGE   DEFAULT\ndefault   Available   19s              20h   true\n# kubectl get volumesnapshotlocations -n velero\nNAME      AGE\ndefault   20h\nThe output shows that the backup and snapshot destinations (your S3 bucket) are properly configured.Creating a test applicationWe will be using WordPress as a test application deployed using the Bitnami template:1\n# helm install wp-test bitnami/wordpress\nCheck that you have the following components deployed:1\n2\n3\n4\n5\n6\n7\n8\n# kubectl get deployments -n default\nNAME                READY   UP-TO-DATE   AVAILABLE   AGE\nwp-test-wordpress   1/1     1            1           12h\n# kubectl get service -n default\nNAME                TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                      AGE\nkubernetes          ClusterIP      10.254.0.1      <none>           443/TCP                      40h\nwp-test-mariadb     ClusterIP      10.254.28.108   <none>           3306/TCP                     13h\nwp-test-wordpress   LoadBalancer   10.254.74.125   188.42.240.165   80:30964/TCP,443:30591/TCP   13h\nIn the output, the EXTERNAL-IP of your wp-test-wordpress load balancer is the public IP address of your test WordPress instance that you can use to access the application.Note: The WordPress template consists of the MariaDB database and the WordPress application itself.Creating the first backupTo create a backup, run the following command:1\n# velero backup create wp-test-b1 --selector app.kubernetes.io/instance=wp-test --snapshot-volumes --snapshot-move-data\nWhere:wp-test-b1 is the name of your backup.--selector app.kubernetes.io/instance=wp-test specifies the selector to identify Kubernetes entities for backup. All WordPress application components have the instance=wp-test tag, so Velero will back up all of them, including persistent volumes.--snapshot-volumes specifies the snapshot approach that will be used to back up your persistent volumes.--snapshot-move-data specifies that snapshots will be moved to your backup destination and not stored in the same Kubernetes cluster.To check that the backup was successfully created and the snapshots were uploaded to S3, run:1\n2\n3\n4\n5\n6\n7\n# kubectl get backups -n velero\nNAME                            AGE\nwp-test-b1                      13h\n# kubectl get datauploads -n velero\nNAME                 STATUS      STARTED   BYTES DONE   TOTAL BYTES   STORAGE LOCATION   AGE     NODE\nwp-test-b1-tcr98     Completed   13h       155618227    155618227     default            13h     k8s-103-mab4wz56ljff-node-0\nwp-test-b1-x6m97     Completed   13h       167394550    167394550     default            13h     k8s-103-mab4wz56lj\nAdditionally, go to your S3 bucket and verify that your file structure is as follows:You can also check the backup task status by running:1\n2\n3\n4\n5\n6\n7\n8\n9\n# velero backup describe wp-test-b1 --details\nName:         wp-test-b1\nNamespace:    velero\nLabels:       velero.io/storage-location=default\nAnnotations:  velero.io/resource-timeout=10m0s\n              velero.io/source-cluster-k8s-gitversion=v1.25.7\n              velero.io/source-cluster-k8s-major-version=1\n              velero.io/source-cluster-k8s-minor-version=25\nPhase:  Completed\nPhase should have the status Completed.Restoring the applicationTo test the restore functionality, let\u2019s destroy the WordPress application. To do this, you can delete the WordPress deployment:1\n2\n3\n4\n# kubectl delete deployments wp-test-wordpress\ndeployment.apps \"wp-test-wordpress\" deleted\n# kubectl get deployments -n default\nNo resources found in default namespace.\nYou can check that the WordPress application is no longer available by opening its public IP address in the browser.You can also delete the WordPress persistent volume:1\n2\n3\n4\n5\n6\n7\n# kubectl get pvc\nNAME                     STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\ndata-wp-test-mariadb-0   Bound    pvc-c8134c2b-9f0b-424f-a42a-63b25cfcf21c   8Gi        RWO            standard       12h\npvc01                    Bound    pvc-35e8f714-5c8f-4c6e-920e-230d1b421f0e   20Gi       RWO            standard       40h\nwp-test-wordpress        Bound    pvc-eef40f1c-dff7-4317-be74-f49a0df5feec   10Gi       RWO            standard       12h\n# kubectl delete pvc wp-test-wordpress\npersistentvolumeclaim \"wp-test-wordpress\" deleted\nTo restore the application from the created backup, run:1\n# velero create restore wp-test-restore1 --from-backup wp-test-b1\nWhere:wp-test-restore1 is the name of a restore taskwp-test-b1 is the name of your backupOpen the WordPress public IP address in the browser, to verify that the WordPress application is available again.Creating a backup scheduleFor managing backup schedules, Velero uses cron. To learn more, refer to the Velero documentation.To create backups every hour and send backup files, including snapshots, to your S3 storage, run:1\n# velero schedule create wp-test-hourly --schedule=\"0 * * * *\" --selector app.kubernetes.io/instance=wp-test --snapshot-volumes --snapshot-move-data\nCreating a file system-based backupVelero also supports file system backup. To learn more about this approach and how it is different from the snapshot-based backup, refer to the Velero documentation.To create a file system backup, run:1\n# velero backup create wp-test-b2 --selector app.kubernetes.io/instance=wp-test --default-volumes-to-fs-backup\nEnjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/kubernetes-backups-with-velero/"
    },
    {
        "title": "Showing virtual router details",
        "content": "Showing virtual router detailsGET /v2.0/routers/{router_id}\r\n\nShows details of a router with the specified ID.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-router-details-detail#show-router-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/routers/ce996632-45a2-4c6b-a951-a624eba74621\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nrouter\n\nbody\nobject\nA router object.\n\nid\n\nbody\nstring\nThe ID of the router.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\n\nstatus\n\nbody\nstring\nThe router status.\n\nexternal_gateway_info\n\nbody\nobject\nThe external gateway information of the router.\r\nIf the router has an external gateway, this would be a dictionary \r\nof network_id, enable_snat and external_fixed_ips.\r\nOtherwise, this would be null.\n\nnetwork_id\n\nbody\nstring\nNetwork ID which the router gateway is connected to.\n\nenable_snat\n\nbody\nboolean\nEnable Source NAT (SNAT) attribute.\r\ntrue means Network Address Translation (NAT) is enabled\r\nfor traffic generated by subnets attached to the router\r\nwhen the traffic is sent to/received from the external network.\r\nfalse means no NAT is applied for traffic from/to the external network.\r\nIt is available when ext-gw-mode extension is enabled.\n\nexternal_fixed_ips\n\nbody\narray\nIP address(es) of the external gateway of the router.\r\nIt is a list of IP addresses. Each element of the list\r\nis a dictionary of ip_address and subnet_id.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nroutes\n\nbody\narray\nThe extra routes configuration for L3 router.\r\nA list of dictionaries with destination and nexthop parameters.\r\nIt is available when extraroute extension is enabled.\n\ndestination\n\nbody\nstring\nThe destination CIDR.\n\nnexthop\n\nbody\nstring\nThe IP address of the next hop for the corresponding destination.\r\nThe next hop IP address must be a part of one of the subnets to\r\nwhich the router interfaces are connected.\n\ndistributed\n\nbody\nboolean\ntrue indicates a distributed router.\r\nIt is available when dvr extension is enabled.\n\nha\n\nbody\nboolean\ntrue indicates a highly-available router.\r\nIt is available when l3-ha extension is enabled.\n\navailability_zone_hints\n\nbody\narray\nThe availability zone candidates for the router.\r\nIt is available when router_availability_zone extension is enabled.\n\navailability_zones\n\nbody\narray\nThe availability zone(s) for the router.\r\nIt is available when router_availability_zone extension is enabled.\n\nservice_type_id\n\nbody\nstring\nThe ID of the service type associated with the router.\n\nflavor_id\n\nbody\nstring\nThe ID of the flavor associated with the router.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ntags\n\nbody\narray\nThe list of tags on the router.\n\nconntrack_helpers\n\nbody\narray\nThe associated conntrack helper resources for the router. If the\r\nrouter has multiple conntrack helper resources, this field has\r\nmultiple entries. Each entry consists of netfilter conntrack helper\r\n(helper), the network protocol (protocol), the network port\r\n(port).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n412 - Precondition Failed\n\nThe server does not meet one of the preconditions that the requester put on the request header fields.\n\nExample{\r\n  \"router\": {\r\n    \"status\": \"ACTIVE\",\r\n    \"external_gateway_info\": {\r\n      \"network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n      \"enable_snat\": true,\r\n      \"external_fixed_ips\": [\r\n        {\r\n          \"subnet_id\": \"351884c7-ee37-4a7d-9dcb-4cff4a1bba27\",\r\n          \"ip_address\": \"10.94.139.172\"\r\n        }\r\n      ]\r\n    },\r\n    \"availability_zone_hints\": [],\r\n    \"availability_zones\": [\r\n      \"nova\"\r\n    ],\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-03-04T15:22:40Z\",\r\n    \"admin_state_up\": true,\r\n    \"distributed\": false,\r\n    \"updated_at\": \"2020-03-04T15:22:44Z\",\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"flavor_id\": null,\r\n    \"revision_number\": 4,\r\n    \"routes\": [],\r\n    \"ha\": false,\r\n    \"id\": \"ce996632-45a2-4c6b-a951-a624eba74621\",\r\n    \"name\": \"router1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-virtual-router-details.html"
    },
    {
        "title": "Querying S3 users via REST API",
        "content": "Querying S3 users via REST API\nYou can display information, status, and all accounts of a user by sending a GET request to the ostor-users service along with the user email address:# s3_curl GET \"http://s3.example.com/?ostor-users&emailAddress=user@email.com\"\r\n{\r\n  \"UserEmail\": \"user@email.com\",\r\n  \"UserId\": \"b09693b73b3c7686\",\r\n  \"State\": \"enabled\",\r\n  \"OwnerId\": \"0000000000000000\",\r\n  \"Flags\": [],\r\n  \"AWSAccessKeys\": [\r\n    {\r\n      \"AWSAccessKeyId\": \"b09693b73b3c7686FIGH\",\r\n      \"AWSSecretAccessKey\": \"jO2p4JBN1tWc4FEGxwZ8qW2jPCJBYp8RJ4KgBcZP\"\r\n    }\r\n  ],\r\n  \"AccountCount\": \"3\",\r\n  \"Accounts\": [\r\n    {\r\n      \"Name\": \"account1\",\r\n      \"AWSAccessKeys\": [\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c768613NV\",\r\n          \"AWSSecretAccessKey\": \"CBUpFmnpUGlXskTivgDQu4qjYksWpceGZeH6Qyct\"\r\n        }\r\n      ]\r\n    },\r\n    {\r\n      \"Name\": \"account2\",\r\n      \"AWSAccessKeys\": [\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c7686LCZ5\",\r\n          \"AWSSecretAccessKey\": \"xLpUDFJMFMO5rR9acAbUDplrPqIO6fneKNFjEB5c\"\r\n        },\r\n        {\r\n          \"AWSAccessKeyId\": \"b09693b73b3c76866NI2\",\r\n          \"AWSSecretAccessKey\": \"ajowU8pWSGW5ZJhA7AR9OjTrt11HmHPCJsMd247W\"\r\n        }\r\n      ]\r\n    },\r\n    {\r\n      \"Name\": \"account3\",\r\n      \"AWSAccessKeys\": []\r\n    }\r\n  ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-s3-users-via-rest-api.html"
    },
    {
        "title": "Shelving virtual machines",
        "content": "Shelving virtual machines\nYou can unbind a stopped VM from the node it is hosted on and release its reserved resources such as CPU and RAM. A shelved VM remains bootable and retains its configuration, including the IP addresses. \nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo shelve a virtual machine\n\nClick the desired virtual machine.\nIf the VM is stopped, click Shelve on its right pane.\nIf the VM is running or suspended, click Shut down or Power off on its right pane, and then select Shelve virtual machine in the confirmation window.\n\nTo spawn a shelved VM on a node with enough resources to host it\n\nClick a shelved virtual machine.\nOn the VM right pane, click Unshelve.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/shelving-virtual-machines.html"
    },
    {
        "title": "Redundancy by replication",
        "content": "Redundancy by replication\nWith replication, Virtuozzo Hybrid Infrastructure breaks the incoming data stream into 256 MB chunks. Each chunk is replicated and replicas are stored on different failure domains, so that each failure domain has only one replica of a given chunk.\nThe following diagram illustrates the 2 replicas redundancy mode with the host failure domain.\n\nReplication in Virtuozzo Hybrid Infrastructure is similar to the RAID rebuild process, but has two key differences:\n\nReplication in Virtuozzo Hybrid Infrastructure is much faster than that of a typical online RAID 1/5/10 rebuild. The reason is that Virtuozzo Hybrid Infrastructure replicates chunks in parallel, to multiple failure domains.\nThe more storage nodes are in a cluster, the faster the cluster will recover from a disk or node failure.\n\nHigh replication performance minimizes the periods of reduced redundancy for the cluster. Replication performance is affected by:\n\nThe number of available storage nodes. As the replication runs in parallel, the more available replication sources and destinations there are, the faster it is.\nPerformance of storage node disks.\nNetwork performance. All replicas are transferred between failure domains over network. For example, 1 Gbps throughput can be a bottleneck (refer to Network requirements and recommendations).\nDistribution of data in the cluster. Some storage nodes may have much more data to replicate than others and may become overloaded during replication.\nI/O activity in the cluster during replication.\n\nFor production, it is recommended to use the replication mode with 3 replicas.\n\nSee also\n\nRedundancy by erasure coding\n\nNo redundancy\n\nRedundancy modes\n\nFailure domains\n\nStorage tiers\n\n\u00d0\u00a1luster rebuilding",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/redundancy-by-replication.html"
    },
    {
        "title": "Creating external storage policies",
        "content": "Creating external storage policies\nOnce you connect an external storage to the compute cluster, you can start using it by creating external storage policies and applying them to new volumes.\nLimitations\n\nExternal storage policies cannot be applied to existing compute volumes.\nExternal storage policies can only be edited via the command-line interface.\n\nPrerequisites\n\nAn external storage is attached to the compute cluster, as described in Attaching external iSCSI storage or Attaching external NFS storage.\n\nTo create an external storage policy\nUse the vinfra service compute storage-policy create command specifying the external storage and desired custom parameters in the key-value format.# vinfra service compute storage-policy create <policy_name> --storage <storage_name> --params <key=value>[,<key2=value2>,...]\nFor example, to create the storage policy pure-policy for the external storage pure-storage, run:# vinfra service compute storage-policy create pure-policy --storage pure-storage\nIn the admin panel, the created storage policy will appear with the External type.\nOnce you create as many storage policies for your external storage as required, you can start applying them to new compute volumes.\nSee also\n\nManaging compute volumes\n\nManaging storage policies\n\nUsing volume QoS policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-external-storage-policies.html"
    },
    {
        "title": "Managing access keys",
        "content": "Managing access keys\nAfter enabling access to the S3 storage, one access key pair is automatically generated for the current user. It is recommended to periodically delete old access key pairs and generate new ones. When you delete an access key, it cannot be retrieved.\nLimitations\n\nYou can have up to two access key pairs.\nIf you have only one access key pair, it cannot be deleted.\n\nPrerequisites\n\nAccess to the S3 storage is enabled, as described in Enabling access to S3 storage.\n\nTo create an S3 access key pair\n\nGo to the S3 > Access screen.\nIn the S3 access keys section, click Create.\n\nTo copy an S3 access key pair\n\nGo to the S3 > Access screen.\n\nIn the S3 access keys section, do the following:\n\nTo copy an access key ID, click the copy icon next to the key.\nTo copy a secret access key, click the ellipsis icon next to the key, and then click Copy secret access key.\n\nTo disable an S3 access key pair\n\nGo to the S3 > Access screen.\nIn the S3 access keys section, click the ellipsis icon next to the required key, and then click Disable.\n\nTo delete an S3 access key pair\n\nGo to the S3 > Access screen.\nIn the S3 access keys section, click the ellipsis icon next to the required key, and then click Delete.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-access-keys.html"
    },
    {
        "title": "Listing backup plans",
        "content": "Listing backup plansGET /v2/{project_id}/jobs\nList backup plans.\nSource: https://docs.openstack.org/api-ref/backup/v2/index.html#lists-jobs-v2\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number of items up to a limit value. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request.\n\noffset (Optional)\nquery\nstring\nThe ID of the last-seen item. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request.\n\nsearch (Optional)\nbody\ndict\nThe query option of a list. It is a JSON structure. It contains the keywords match, match_not, or one of the two. The values about the keys match and match_not are a list of {key, value}.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8736/v2/3046fb2c2a314a0fbb32607caa1e5277/jobs\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\njobs (Optional)\nbody\nlist\nA list of jobs.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"jobs\": [\r\n    {\r\n      \"created_at\": \"2024-05-09T09:51:10.785289\",\r\n      \"updated_at\": \"2024-05-09T09:52:58.261715\",\r\n      \"job_id\": \"e632eb1884e0468c8a41e656942df500\",\r\n      \"project_id\": \"3046fb2c2a314a0fbb32607caa1e5277\",\r\n      \"user_id\": \"d1899d7f32d64b1bb95e262e7a6a4bc2\",\r\n      \"job_schedule\": {\r\n        \"schedule_day_of_week\": \"0,1,2,3,4,5,6\",\r\n        \"schedule_month\": \"1,2,3,4,5,6,7,8,9,10,11,12\",\r\n        \"schedule_day\": \"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31\",\r\n        \"schedule_minute\": \"00\",\r\n        \"schedule_hour\": \"13\"\r\n      },\r\n      \"client_id\": \"hci\",\r\n      \"session_id\": \"\",\r\n      \"session_tag\": 0,\r\n      \"name\": \"myplan\",\r\n      \"description\": \"My new plan\",\r\n      \"job_actions\": [\r\n        {\r\n          \"freezer_action\": {\r\n            \"action\": \"backup\",\r\n            \"mode\": \"hci-volumes\",\r\n            \"recovery_points_rotation\": 7\r\n          },\r\n          \"user_id\": \"d1899d7f32d64b1bb95e262e7a6a4bc2\",\r\n          \"project_id\": \"3046fb2c2a314a0fbb32607caa1e5277\",\r\n          \"action_id\": \"b9dc9e548b914b80a06d752342828371\"\r\n        }\r\n      ],\r\n      \"status\": \"scheduled\",\r\n      \"disabled\": false,\r\n      \"started_at\": null,\r\n      \"ended_at\": null\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-backup-plans.html"
    },
    {
        "title": "Updating VPN endpoint groups",
        "content": "Updating VPN endpoint groupsPUT /v2.0/vpn/endpoint-groups/{endpoint_group_id}\nUpdate settings for a VPN endpoint group.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=update-vpn-endpoint-group-detail#update-vpn-endpoint-group\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nendpoint_group_id\n\npath\nstring\nThe ID of the VPN endpoint group.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"endpoint_group\": {\r\n        \"description\": \"Remote endpoint group\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/endpoint-groups/e3b89342-73ee-42b9-8ee9-fd91ec36aceb\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nendpoints\n\nbody\narray\nList of endpoints of the same type, for the endpoint group. The values will depend on the type.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ntype\n\nbody\nstring\nThe type of the endpoints in the group. A valid value is subnet, cidr, network, router, or vlan. Only subnet and cidr are supported at this moment.\n\nid\n\nbody\nstring\nThe ID of the VPN endpoint group.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"endpoint_group\": {\r\n    \"id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"peers\",\r\n    \"description\": \"Remote endpoint group\",\r\n    \"type\": \"cidr\",\r\n    \"endpoints\": [\r\n      \"10.2.0.0/24\",\r\n      \"10.3.0.0/24\"\r\n    ],\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-vpn-endpoint-groups.html"
    },
    {
        "title": "Troubleshooting Kubernetes clusters",
        "content": "Troubleshooting Kubernetes clusters\nIf a Kubernetes cluster fails, you can download its configuration file and the log files of its nodes for troubleshooting.\nAdditionally, you can get diagnostic information of Kubernetes services by running commands inside a Kubernetes virtual machine from the compute node this VM reside on. Kubernetes services that you need to check are the following:\n\nkubelet is a node agent that works on each Kubernetes node. It ensures that containers described in pod specification files are healthy and running.\nkube-proxy is a network proxy that runs on each Kubernetes node. It configures network rules that resolve connections to pods from within and without a Kubernetes cluster.\nkube-apiserver is an API server that runs only on master nodes. It validates and configures data for the API objects, such as  pods, services, replication controllers, and others. The API server also assigns pods to nodes and synchronizes pod information with the service configuration.\n\nTo download a Kubernetes configuration file\n\nFind out the ID of the required Kubernetes cluster:# vinfra service compute k8saas list\r\n+--------------------------------------+------+--------+\r\n| id                                   | name | status |\r\n+--------------------------------------+------+--------+\r\n| 834397b9-22d3-486d-afc7-5c0122d6735d | k8s1 | ERROR  |\r\n+--------------------------------------+------+--------+\n\nPrint the configuration of the Kubernetes cluster to a file. For example, to download the kubeconfig of the k8s1 cluster to the file k8s1.kubeconfig, run:# vinfra service compute k8saas config 834397b9-22d3-486d-afc7-5c0122d6735d > k8s1.kubeconfig\n\nTo download logs of a Kubernetes node\n\nFind out the name of the required Kubernetes virtual machine:# vinfra service compute server list\r\n+--------------------------------------+---------------+--------+------------------------+---------------------+\r\n| id                                   | name          | status | host                   | networks            |\r\n+--------------------------------------+---------------+--------+------------------------+---------------------+\r\n| 18fb7436-f1fa-4859-99dd-284cef9edc54 | k8s1-node-0   | ACTIVE | node002.vstoragedomain | - public=10.10.10.2 |\r\n| 66bc8454-efb4-4263-a0e2-523fd8f15bda | k8s1-master-0 | ACTIVE | node001.vstoragedomain | - public=10.10.10.1 |\r\n+--------------------------------------+---------------+--------+------------------------+---------------------+\r\n\n\nPrint the log of the Kubernetes VM to a file. For example, to download the log of the k8s1 master node to the file k8s1-master-0.log, run:# vinfra service compute server log k8s1-master-0 > k8s1-master-0.log\n\nTo run commands inside a Kubernetes node\n\nFind out the Kubernetes VM ID and the hostname of the node it runs on by listing all virtual machines in the compute cluster:# vinfra service compute server list\r\n+--------------------------------------+---------------+--------+------------------------+---------------------+\r\n| id                                   | name          | status | host                   | networks            |\r\n+--------------------------------------+---------------+--------+------------------------+---------------------+\r\n| 18fb7436-f1fa-4859-99dd-284cef9edc54 | k8s1-node-0   | ACTIVE | node002.vstoragedomain | - public=10.10.10.2 |\r\n| 66bc8454-efb4-4263-a0e2-523fd8f15bda | k8s1-master-0 | ACTIVE | node001.vstoragedomain | - public=10.10.10.1 |\r\n+--------------------------------------+---------------+--------+------------------------+---------------------+\r\n\nIn this example, the Kubernetes master node has the ID 66bc8454-efb4-4263-a0e2-523fd8f15bda and resides on the node node001.\n\nLog in to the node that hosts the needed Kubernetes VM, and then inside the VM. For example:# ssh node001.vstoragedomain\r\n[root@node001 ~]# virsh x-exec 66bc8454-efb4-4263-a0e2-523fd8f15bda\n\nNow, you can perform diagnostic checks inside the VM. For example, you may start with finding out what services have failed:[root@k8s1-master-0 /]# systemctl list-units --failed\r\n  UNIT               LOAD   ACTIVE SUB    DESCRIPTION\r\n\u00e2\u0097\u008f kube-proxy.service loaded failed failed kube-proxy via Hyperkube\nTo show more details about the failed service, run:[root@k8s1-master-0 /]# systemctl status kube-proxy\r\n\u00c3\u0097 kube-proxy.service - kube-proxy via Hyperkube\r\n     Loaded: loaded (/etc/systemd/system/kube-proxy.service; enabled; vendor preset: disabled)\r\n     Active: failed (Result: exit-code) since Thu 2022-04-28 11:20:18 UTC; 2min 6s ago\r\n    Process: 4603 ExecStartPre=/bin/mkdir -p /etc/kubernetes/ (code=exited, status=0/SUCCESS)\r\n    Process: 4604 ExecStartPre=/usr/bin/podman rm kube-proxy (code=exited, status=1/FAILURE)\r\n    Process: 4624 ExecStart=/bin/bash -c /usr/bin/podman run --name kube-proxy --log-opt path=/dev/null --privileged --net host --entrypoint /hyperkube --volume /e>\r\n    Process: 115468 ExecStop=/usr/bin/podman stop kube-proxy (code=exited, status=0/SUCCESS)\r\n   Main PID: 4624 (code=exited, status=2)\r\n        CPU: 2min 6.180s\r\n...\r\n\nSee also\n\nTroubleshooting virtual machines\n\nRunning commands in virtual machines without network connectivity",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/troubleshooting-kubernetes-clusters.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Compute API Reference\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nCompute API Reference\n\nHome\n\nContents\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureCompute API Reference\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/index.html"
    },
    {
        "title": "Managing Kubernetes worker groups",
        "content": "Managing Kubernetes worker groups\nTo meet system requirements of applications running in Kubernetes clusters, you can have worker nodes with different number of CPUs and amount of RAM. Creating workers with different flavors is possible by using worker groups. \nWhen creating a Kubernetes cluster, you can specify the configuration of only one worker group, the default worker group. After the cluster is created, add as many worker groups as you need. If required, you can also edit the number of workers in a group later.\nLimitations\n\nWorker groups are not available for Kubernetes version 1.15.x.\nThe default worker group cannot be deleted.\nIn Kubernetes version 1.21.x and earlier, autoscaling to zero nodes is not supported.\n\nPrerequisites\n\nA Kubernetes cluster is created, as described in Creating and deleting Kubernetes clusters.\n\nTo add a worker group\n\nOn the Kubernetes clusters screen, click a Kubernetes cluster.\nOn the cluster right pane, navigate to the Groups tab.\nIn the Workers section, click Add.\nIn the Add worker group window, specify a name for the group.\n\nIn the Worker group section,  select a flavor for each worker, and then decide whether you want to allow automatic scaling of the worker group:\n\nWith Autoscaling enabled, the number of workers will be automatically increased if there are pods stuck in the pending state due to insufficient resources, and reduced if there are workers with no pods running on them. For scaling of the worker group, set its minimum and maximum size.\n\nSome types of pods can prevent the autoscaler from removing a worker. To see a list of such pod types, refer to the official Kubernetes Autoscaler documentation.\n\nWith Autoscaling disabled, the number of worker nodes that you set will be permanent.\n\nIn the Labels section, enter labels that will be used to specify supplementary parameters for this Kubernetes cluster in the key=value format. For example: selinux_mode=permissive. Currently, only the selinux and flannel_network_cidr labels are supported. You can use other labels at your own risk. To see the full list of supported labels, refer to the OpenStack documentation.\n\nClick Add.\n\nWhen the worker group is created, you can assign pods to these worker nodes, as explained in Assigning Kubernetes pods to specific nodes.\nTo edit the number of workers in a group\n\nOn the Kubernetes cluster right pane, navigate to the Groups tab.\n\nIn the Workers section, click the pencil icon for the default worker group or the ellipsis icon for all other groups, and then select Edit.\n\nIn the Edit workers window, enable or disable Autoscaling, or change the number of workers in the group.\nClick Save.\n\nTo delete a worker group\nClick the ellipsis icon next to the required worker group, and then select Delete. The worker group will be deleted along with all of its workers. After the deletion, the worker group data will be lost.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-kubernetes-worker-groups.html"
    },
    {
        "title": "Performance-related system alerts",
        "content": "Performance-related system alerts\nDisk is out of space\nIt is strongly advised to monitor the following out-of-space disk alerts closely:\n\nCluster is out of space\nDisk may run out of space\nDisk is out of space\nMetadata disk is out of space\n\nDisks at near-full capacity typically show decreased performance, especially during write operations. Filling disks further might result in other access issues, such as inability to write more data. For these reasons, we do not recommend exceeding 80 percent of used disk space at all times.\nNote that this may happen regardless of space usage in an assigned storage tier. In other words, a disk may have more than 80 percent of used space even if its assigned storage tier is used by less than 80 percent.\nRAID resyncing\nThe Software RAID is not fully synced alert is raised when resyncing of a software RAID device managed by the md service is in progress. If the MDS disk is affected, this process decreases the cluster performance until the RAID rebuilding is finished.\nToo many chunks or files in the cluster\nWhen the cluster has too many files or chunks, the following alerts are raised:\n\nCluster has too many chunks\nCluster has a critically high number of chunks\nCluster has too many files\nCluster has a critically high number of files\n\nThis is a sign that the cluster is reaching its resource limit, which will impact the performance of metadata operations. When this limit is reached, the performance degradation may become a problem. In this case, you can increase the chunk size (however, this may also affect the performance), or redirect some workloads to a different cluster.\nThe general recommendation is not to exceed four million files and ten million chunks.\nCPU overload\nWhen the metadata (MDS) and S3 gateway services use CPU resources above a threshold, the system issues the following alerts:\n\nMetadata service has high CPU usage\nS3 Gateway service has high CPU usage\nS3 Gateway service has critically high CPU usage\n\nThe CPU usage of the metadata service can be checked either in Grafana or the command line.\nIn Grafana, you can check it on the Virtuozzo Storage MDS details dashboard:\n\nTo check the MDS CPU usage via the command line, use the following command:# vstorage -c <CLUSTER> top\nPress m to focus on the metadata service. In the command output, the current CPU usage will be reported in the %CPU column, as highlighted in the following example:MDSID STATUS   %CTIME   COMMITS   %CPU    MEM   UPTIME HOST\r\n    3 avail      0.0%       0/s   0.2%   142m   6d  1h management\u00e2\u0080\u00a6\r\nM   1 avail      0.1%       1/s   0.2%   149m   6d  1h management\u00e2\u0080\u00a6\r\n    2 avail      0.1%       1/s   0.2%   149m   6d  1h management\u00e2\u0080\u00a6\r\n\nThe alert is raised when the CPU usage is above 80 percent for at least five minutes. For the metadata service, it is normal to use 100 percent of the CPU during peak traffic. However, this may also indicate an issue if the alert persists longer than one day and it is accompanied by other performance issues (for example, high latency).\nSimilarly, the CPU usage of the Object storage service can be checked on the Object Storage overview dashboard in Grafana:\n\nHigh latency\nThere are several processes that can be affected by high latency. The system will issue alerts when the latency of these services is too high:\n\nMetadata service (MDS)\nChunk service (CS)\nObject storage (S3) services\n\nMetadata service latency\nThe metadata service latency represents the response time of all metadata operations. You can check the metadata service latency on the Virtuozzo Storage MDS details dashboard in Grafana:\n\nThe Metadata service has high commit latency alert triggers when the 95th percentile latency of the service is higher than one second for more than five minutes.\nThough it is considered normal for latency to increase during peak hours, it may also indicate an issue if the alert persists for more than one day and performance is below expectations.\nChunk server latency\nThe chunk service latency can be checked either in Grafana or the command line.\nIn Grafana, you can check it on the Virtuozzo Storage core cluster overview dashboard:\n\nYou can also monitor the latency of a particular disk on the Hardware node details dashboard:\n\nAlternatively, the latency of a storage disk is shown on the Virtuozzo Storage CS details dashboard:\n\nTo check the chunk server latency via the command line, use the following command:# vstorage -c <CLUSTER> top\nPress i to view the optime values. The command output will be similar to this:  CSID IOWAIT  SWAIT OPTIME(ms) IOLAT(ms)  SLAT(ms) QDEPTH        RMW       JRMW\r\n  1027     0%     0%        N/A       0/0       0/0    0.0     0ops/s     0ops/s\r\n  1029     0%     0%        N/A       0/0       0/0    0.0     0ops/s     0ops/s\r\n  1025     0%     0%        N/A       0/0       0/0    0.0     0ops/s     0ops/s \r\n... (rows 1-3 of 6)\r\n\nThe optime represents the average time spent serving each I/O request, ignoring the time it spent in the I/O queue. If the optime is consistently high, for example, higher than 100 ms, this means that there might be an issue with the I/O path. If the issue is caused by disk wear, it can be fixed by replacing the disk. Other solutions include upgrading the device firmware, replacing faulty cables, replacing a faulty controller, or adding capacity.\nObject storage service latency\nThe system raises alerts when one of the following latencies exceeds a certain threshold for more than five minutes:\n\nS3 gateway GET latency\nObject service commit latency\nObject service request latency\nName service commit latency\nName service request latency\n\nThough it is considered normal for latency to increase during peak hours, it may also indicate an issue if the alert persists for more than one day and performance is below expectations.\nYou can check the latency for the object storage services in Grafana. To monitor the S3 gateway GET and PUT latency, use the S3 overview dashboard:\n\nTo check the object service latency, go to the Object Storage OS details dashboard:\n\nThe name service latency can be checked on the Object Storage NS details dashboard:\n\nS.M.A.R.T. alerts\nS.M.A.R.T. alerts must be treated with high priority. All signs of disk wear can decrease the cluster performance, in addition to further performance degradation in case of a device failure (which may include the loss of redundancy and availability, and also node downtime if the system disk is affected). Moreover, recovery operations, such as storage rebalancing, may have an impact on the system performance.\nSee also\n\nPerformance issues and symptoms",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/performance-related-system-alerts.html"
    },
    {
        "title": "Managing virtual networks",
        "content": "Managing virtual networks",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-virtual-networks.html"
    },
    {
        "title": "Hardware requirements",
        "content": "Hardware requirements\nA minimum Virtuozzo Hybrid Infrastructure installation recommended for production consists of three nodes for storage and compute services with enabled high availability for the management node. This is to ensure that the cluster can survive failure of one node without data loss. The following table lists the minimal hardware requirements for all the three nodes. The recommended configurations are provided in \"System requirements\" in the Administrator Guide.\n\nType\nManagement node with storage and compute\n\nCPU\n\n64-bit x86 processors with AMD-V or\r\nIntel VT hardware virtualization\r\nextensions enabled.\n16 cores*\n\nRAM\n32 GB\n\nStorage\n\n1 disk: system + metadata, 100+ GB\r\nSATA HDD\n1 disk: storage, SATA HDD, size as\r\nrequired\n\nNetwork\n\n10 GbE for storage traffic\n1 GbE for other traffic\n\n* A CPU core here is a physical core in a multicore processor (hyperthreading is not taken into account).",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/hardware-requirements.html"
    },
    {
        "title": "Creating load balancers",
        "content": "Creating load balancersPOST /v2/lbaas/loadbalancers\r\n\nCreate a load balancer.\nIf the status is PENDING_CREATE, issue GET /v2/lbaas/loadbalancers/{loadbalancer_id} to view the progress of\r\nthe provisioning operation. When the load balancer status changes\r\nto ACTIVE, the load balancer is successfully provisioned and\r\nis ready for further configuration.\nAdministrative users can specify a project ID that is different than\r\ntheir own to create load balancers for other projects.\nSource: https://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=create-a-load-balancer-detail#create-a-load-balancer\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nloadbalancer\n\nbody\nobject\nA loadbalancer object.\n\nadmin_state_up (Optional)\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false). Default is true.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource.\n\nflavor_id (Optional)\nbody\nuuid\nThe ID of the flavor.\n\nlisteners (Optional)\nbody\narray\nThe associated listener IDs, if any.\n\nname (Optional)\nbody\nstring\nHuman-readable name of the resource.\n\nproject_id (Optional)\nbody\nstring\nThe ID of the project owning this resource.\n\nprovider (Optional)\nbody\nstring\nProvider name for the load balancer. Default is octavia.\n\ntags (Optional)\nbody\nlist\n\nA list of simple strings assigned to the resource.\nNew in version 2.5\n\nvip_address (Optional)\nbody\nstring\nThe IP address of the Virtual IP (VIP).\n\nvip_network_id (Optional)\nbody\nuuid\nThe ID of the network for the Virtual IP (VIP). One of vip_network_id,\r\nvip_port_id, or vip_subnet_id must be specified.\n\nvip_port_id (Optional)\nbody\nuuid\nThe ID of the Virtual IP (VIP) port. One of vip_network_id,\r\nvip_port_id, or vip_subnet_id must be specified.\n\nvip_qos_policy_id (Optional)\nbody\nuuid\nThe ID of the QoS Policy which will apply to the Virtual IP (VIP).\n\nvip_subnet_id (Optional)\nbody\nuuid\nThe ID of the subnet for the Virtual IP (VIP). One of vip_network_id,\r\nvip_port_id, or vip_subnet_id must be specified.\n\nvip_ip_version (Optional)\nbody\ninteger\nThe IP protocol version. Valid value is 4 or 6. Default is 4.\r\nOne of vip_network_id, vip_port_id, vip_subnet_id, or \r\nvip_ip_version must be specified.\n\nExample\nCreate a load balancer lb2 in a private network, with a pool of two members in the same private network, with an HTTP->HTTP listener on port 80->80. Additionally, assign an existing floating IP address 10.94.129.67 to the load balancer\u00e2\u0080\u0099s private IP address 192.168.10.5 to make it reachable from a public network.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"loadbalancer\": {\r\n    \"name\": \"lb2\",\r\n    \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"vip_subnet_id\": \"fd2de462-f93b-43a6-9b5c-254f1e690bf1\",\r\n    \"listeners\": [\r\n      {\r\n        \"name\": \"http_listener\",\r\n        \"protocol\": \"HTTP\",\r\n        \"protocol_port\": 80,\r\n        \"default_pool\": {\r\n          \"name\": \"rr_pool\",\r\n          \"protocol\": \"HTTP\",\r\n          \"default_protocol_port\": 80,\r\n          \"lb_algorithm\": \"ROUND_ROBIN\",\r\n          \"healthmonitor\": {\r\n            \"type\": \"HTTP\",\r\n            \"delay\": \"3\",\r\n            \"max_retries\": 2,\r\n            \"timeout\": 1\r\n          },\r\n          \"members\": [\r\n            {\r\n              \"address\": \"192.168.10.245\",\r\n              \"protocol_port\": 80\r\n            },\r\n            {\r\n              \"address\": \"192.168.10.168\",\r\n              \"protocol_port\": 80\r\n            }\r\n          ]\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}' https://<node_IP_addr>:9888/v2/lbaas/loadbalancers\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nloadbalancer\n\nbody\nobject\nA loadbalancer object.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\nflavor_id\n\nbody\nuuid\nThe ID of the flavor.\n\nid\n\nbody\nuuid\nThe ID of the load balancer.\n\nlisteners\n\nbody\narray\nThe associated listener IDs, if any.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\noperating_status\n\nbody\nstring\nThe operating status of the resource.\n\npools\n\nbody\narray\nThe associated pool IDs, if any.\n\nproject_id\n\nbody\nstring\nThe ID of the project owning this resource.\n\nprovider\n\nbody\nstring\nProvider name for the load balancer.\n\nprovisioning_status\n\nbody\nstring\nThe provisioning status of the resource.\n\ntags\n\nbody\nlist\n\nA list of simple strings assigned to the resource.\nNew in version 2.5\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvip_address\n\nbody\nstring\nThe IP address of the Virtual IP (VIP).\n\nvip_network_id\n\nbody\nuuid\nThe ID of the network for the Virtual IP (VIP).\n\nvip_port_id\n\nbody\nuuid\nThe ID of the Virtual IP (VIP) port.\n\nvip_qos_policy_id\n\nbody\nuuid\nThe ID of the QoS Policy which will apply to the Virtual IP (VIP).\n\nvip_subnet_id\n\nbody\nuuid\nThe ID of the subnet for the Virtual IP (VIP).\n\nvip_ip_version\n\nbody\ninteger\nThe IP protocol version.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"loadbalancer\": {\r\n    \"provider\": \"amphora\",\r\n    \"flavor_id\": null,\r\n    \"description\": \"\",\r\n    \"provisioning_status\": \"PENDING_CREATE\",\r\n    \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"created_at\": \"2020-03-20T12:58:20.584488\",\r\n    \"admin_state_up\": true,\r\n    \"updated_at\": null,\r\n    \"vip_qos_policy_id\": null,\r\n    \"vip_subnet_id\": \"fd2de462-f93b-43a6-9b5c-254f1e690bf1\",\r\n    \"listeners\": [\r\n      {\r\n        \"client_ca_tls_container_ref\": null,\r\n        \"protocol\": \"HTTP\",\r\n        \"default_tls_container_ref\": null,\r\n        \"updated_at\": \"2020-03-20T12:58:25.707818\",\r\n        \"default_pool_id\": \"bd04cc50-0575-45cc-a965-514357a4b62d\",\r\n        \"id\": \"1dc8539c-7545-4ae8-8081-3140a47b6342\",\r\n        \"insert_headers\": {},\r\n        \"sni_container_refs\": [],\r\n        \"timeout_member_connect\": 5000,\r\n        \"client_crl_container_ref\": null,\r\n        \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n        \"operating_status\": \"OFFLINE\",\r\n        \"description\": \"\",\r\n        \"provisioning_status\": \"PENDING_CREATE\",\r\n        \"timeout_member_data\": 50000,\r\n        \"protocol_port\": 80,\r\n        \"tags\": [],\r\n        \"timeout_tcp_inspect\": 0,\r\n        \"name\": \"http_listener\",\r\n        \"admin_state_up\": true,\r\n        \"client_authentication\": \"NONE\",\r\n        \"created_at\": \"2020-03-20T12:58:25.569526\",\r\n        \"timeout_client_data\": 50000,\r\n        \"connection_limit\": -1,\r\n        \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n        \"l7policies\": []\r\n      }\r\n    ],\r\n    \"tags\": [],\r\n    \"vip_port_id\": \"fb0e8e3e-2a71-420a-885c-94f6d2c2f2b7\",\r\n    \"vip_network_id\": \"15f7dc0a-712c-422f-bfd3-31dc351d9026\",\r\n    \"vip_address\": \"192.168.10.5\",\r\n    \"pools\": [\r\n      {\r\n        \"lb_algorithm\": \"ROUND_ROBIN\",\r\n        \"protocol\": \"HTTP\",\r\n        \"updated_at\": null,\r\n        \"id\": \"bd04cc50-0575-45cc-a965-514357a4b62d\",\r\n        \"tags\": [],\r\n        \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n        \"operating_status\": \"OFFLINE\",\r\n        \"tls_container_ref\": null,\r\n        \"description\": \"\",\r\n        \"provisioning_status\": \"PENDING_CREATE\",\r\n        \"members\": [\r\n          {\r\n            \"compute_server_id\": null,\r\n            \"monitor_port\": null,\r\n            \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n            \"name\": \"\",\r\n            \"weight\": 1,\r\n            \"admin_state_up\": true,\r\n            \"subnet_id\": null,\r\n            \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n            \"created_at\": \"2020-03-20T12:58:25.105009\",\r\n            \"provisioning_status\": \"PENDING_CREATE\",\r\n            \"monitor_address\": null,\r\n            \"updated_at\": null,\r\n            \"tags\": [],\r\n            \"address\": \"192.168.10.245\",\r\n            \"protocol_port\": 80,\r\n            \"backup\": false,\r\n            \"id\": \"2e6b7c79-6ed1-4ccb-8525-c65fca686cb2\",\r\n            \"operating_status\": \"OFFLINE\"\r\n          },\r\n          {\r\n            \"compute_server_id\": null,\r\n            \"monitor_port\": null,\r\n            \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n            \"name\": \"\",\r\n            \"weight\": 1,\r\n            \"admin_state_up\": true,\r\n            \"subnet_id\": null,\r\n            \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n            \"created_at\": \"2020-03-20T12:58:25.176757\",\r\n            \"provisioning_status\": \"PENDING_CREATE\",\r\n            \"monitor_address\": null,\r\n            \"updated_at\": null,\r\n            \"tags\": [],\r\n            \"address\": \"192.168.10.168\",\r\n            \"protocol_port\": 80,\r\n            \"backup\": false,\r\n            \"id\": \"3d648492-f353-4854-a196-7add03229642\",\r\n            \"operating_status\": \"OFFLINE\"\r\n          }\r\n        ],\r\n        \"ca_tls_container_ref\": null,\r\n        \"name\": \"rr_pool\",\r\n        \"admin_state_up\": true,\r\n        \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n        \"created_at\": \"2020-03-20T12:58:24.528983\",\r\n        \"tls_enabled\": false,\r\n        \"session_persistence\": null,\r\n        \"default_protocol_port\": 80,\r\n        \"listeners\": [\r\n          {\r\n            \"id\": \"1dc8539c-7545-4ae8-8081-3140a47b6342\"\r\n          }\r\n        ],\r\n        \"healthmonitor\": null,\r\n        \"crl_container_ref\": null\r\n      }\r\n    ],\r\n    \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"id\": \"6a4e1daf-2277-43aa-bd03-1eca6dfe9df1\",\r\n    \"operating_status\": \"OFFLINE\",\r\n    \"name\": \"lb2\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-load-balancers.html"
    },
    {
        "title": "Uploading images for virtual machines",
        "content": "Uploading images for virtual machines\nTo upload an image\n\nAdmin panel\n\nOn the Compute > Virtual machines > Images tab, click Add image.\r\n\n\nIn the Add image window, do the following:\n\n\r\n                        Click Browse and select a file in one of the supported formats: .iso, .img, .qcow2, .raw.\r\n                    \n\r\n                        Specify an image name to be shown in the admin panel.\r\n                    \n\nSelect the correct OS type from the drop-down list.\n\nThe OS type affects VM parameters such as hypervisor settings. VMs created from an image with an incorrect OS type may not work correctly, for example, they may crash.\n\nIf you have chosen an image in the QCOW2, RAW, or IMG format, select the UEFI boot check box, to mark the image as UEFI bootable. This option cannot be configured after the image is uploaded.\n\n\r\n                Select the Share between all projects check box. With the option disabled, the image will only be available in the admin project of the Default domain.\r\n            \n\n\r\n                Click Add to start uploading the image. The upload progress will be shown in the bottom right corner.\r\n            \n\nYou can hide the pop-up window without interrupting the upload process. The upload progress will be available in the notification center.\n\nCommand-line interface\nUse the following command:vinfra service compute image create [--min-disk <size-gb>] [--min-ram <size-mb>] [--os-distro <os-distro>]\r\n                                    [--protected | --unprotected] [--restricted] [--unrestricted]\r\n                                    [--public] [--private] [--disk-format <disk_format>]\r\n                                    [--container-format <format>] [--tags <tags>] --file <file> [--uefi] <image-name>\r\n\n\n--min-disk <size-gb>\n\nMinimum disk size required to boot from image, in gigabytes\n--min-ram <size-mb>\n\nMinimum RAM size required to boot from image, in megabytes\n--os-distro <os-distro>\n\nOS distribution. To list available distributions, run vinfra service compute cluster show.\n--protected\n\nProtect image from deletion\n--unprotected\n\nAllow image to be deleted\n--restricted\n\nMake image download restricted\n--unrestricted\n\nAllow image to be downloaded\n--public\n\nMake image accessible to all users\n--private\n\nMake image accessible only to the owners.\n--disk-format <disk_format>\n\nDisk format: detect, iso, qcow2, raw (default: detect)\n--container-format <format>\n\nContainer format: bare\n--tags <tags>\n\nA comma-separated list of tags\n--file <file>\n\nCreate image from a local file\n--uefi\n\nCreate image with UEFI boot\n<image-name>\n\nImage name\n\nFor example, to create a Cirros image from the local file and upload it to the compute cluster:# vinfra service compute image create mycirrosimg --file /distr/cirros-0.4.0-x86_64-disk.img\r\nUploading image to server [elapsed time: 0:00:04]... |\nThe upload progress will be shown in the command output. To see all of the existing images in the compute cluster, run:# vinfra service compute image list\r\n+---------------------+-------------+----------+--------+-------------+\r\n| id                  | name        |     size | status | disk_format |\r\n+---------------------+-------------+----------+--------+-------------+\r\n| 179f45ef-c5d6-<...> | mycirrosimg | 12716032 | active | qcow2       |\r\n| 4741274f-5cca-<...> | cirros      | 12716032 | active | qcow2       |\r\n+---------------------+-------------+----------+--------+-------------+\r\n\n\nSee also\n\nManaging notifications\n\nWhat's next\n\nCreating virtual machines\n\nManaging images",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute image create [--min-disk <size-gb>] [--min-ram <size-mb>] [--os-distro <os-distro>]\r\n                                    [--protected | --unprotected] [--restricted] [--unrestricted]\r\n                                    [--public] [--private] [--disk-format <disk_format>]\r\n                                    [--container-format <format>] [--tags <tags>] --file <file> [--uefi] <image-name>\r\n\n\n--min-disk <size-gb>\n\nMinimum disk size required to boot from image, in gigabytes\n--min-ram <size-mb>\n\nMinimum RAM size required to boot from image, in megabytes\n--os-distro <os-distro>\n\nOS distribution. To list available distributions, run vinfra service compute cluster show.\n--protected\n\nProtect image from deletion\n--unprotected\n\nAllow image to be deleted\n--restricted\n\nMake image download restricted\n--unrestricted\n\nAllow image to be downloaded\n--public\n\nMake image accessible to all users\n--private\n\nMake image accessible only to the owners.\n--disk-format <disk_format>\n\nDisk format: detect, iso, qcow2, raw (default: detect)\n--container-format <format>\n\nContainer format: bare\n--tags <tags>\n\nA comma-separated list of tags\n--file <file>\n\nCreate image from a local file\n--uefi\n\nCreate image with UEFI boot\n<image-name>\n\nImage name\n\nFor example, to create a Cirros image from the local file and upload it to the compute cluster:# vinfra service compute image create mycirrosimg --file /distr/cirros-0.4.0-x86_64-disk.img\r\nUploading image to server [elapsed time: 0:00:04]... |\nThe upload progress will be shown in the command output. To see all of the existing images in the compute cluster, run:# vinfra service compute image list\r\n+---------------------+-------------+----------+--------+-------------+\r\n| id                  | name        |     size | status | disk_format |\r\n+---------------------+-------------+----------+--------+-------------+\r\n| 179f45ef-c5d6-<...> | mycirrosimg | 12716032 | active | qcow2       |\r\n| 4741274f-5cca-<...> | cirros      | 12716032 | active | qcow2       |\r\n+---------------------+-------------+----------+--------+-------------+\r\n\n",
                "title": "To upload an image"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Images tab, click Add image.\r\n\n\nIn the Add image window, do the following:\n\n\r\n                        Click Browse and select a file in one of the supported formats: .iso, .img, .qcow2, .raw.\r\n                    \n\r\n                        Specify an image name to be shown in the admin panel.\r\n                    \n\nSelect the correct OS type from the drop-down list.\n\nThe OS type affects VM parameters such as hypervisor settings. VMs created from an image with an incorrect OS type may not work correctly, for example, they may crash.\n\n\n\n\n\n\n\n\n\nIf you have chosen an image in the QCOW2, RAW, or IMG format, select the UEFI boot check box, to mark the image as UEFI bootable. This option cannot be configured after the image is uploaded.\n\n\n\r\n                Select the Share between all projects check box. With the option disabled, the image will only be available in the admin project of the Default domain.\r\n            \n\n\r\n                Click Add to start uploading the image. The upload progress will be shown in the bottom right corner.\r\n            \n\nYou can hide the pop-up window without interrupting the upload process. The upload progress will be available in the notification center.\n",
                "title": "To upload an image"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/uploading-images.html"
    },
    {
        "title": "Resizing Kubernetes clusters",
        "content": "Resizing Kubernetes clustersPOST /v1/clusters/{cluster_ident}/actions/resize\r\n\nChange the number of workers in a Kubernetes cluster with the specified ID.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=resize-a-cluster-detail#resize-a-cluster\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ncluster_ident\n\npath\nstring\nThe UUID or name of clusters in Magnum.\n\nnode_count\n\nbody\ninteger\nThe number of servers that will serve as node in the bay/cluster. The\r\ndefault is 1.\n\nnodes_to_remove (Optional)\nbody\narray\nThe server ID list will be removed.\n\nExample# curl -ks -X POST -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{               \r\n    \"node_count\": 2\r\n}' https://<node_IP_addr>:9513/v1/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea/actions/resize\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/resizing-kubernetes-clusters.html"
    },
    {
        "title": "10.3. Requirements for Performing Domain Joins\u00c2\u00b6",
        "content": "10.3. Requirements for Performing Domain Joins | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n10.3. Requirements for Performing Domain Joins\u00c2\u00b6\nIf you plan to use Leostream to provision new Windows instances in Virtuozzo Hybrid Infrastructure and to have Leostream update and hostname and join these new Windows instances to your Microsoft Active Directory domain, please adhere to the following guidelines when building the master image to use for provisioning.\n\nThe instance used to create the image must not be joined to the domain. Leostream only joins instances to a domain if they are currently part of a Workgroup.\nThe instance must have an installed Leostream Agent that is registered with your Connection Broker. If the Leostream Agent cannot communicate with the Connection Broker, new instances will not be joined to the domain.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/preparing-master-images/domain-joins-requirements.html"
    },
    {
        "title": "Setting up networks for object storage",
        "content": "Setting up networks for object storage\nPrerequisites\n\nA clear understanding of the concept Traffic types.\n\nTo create the network configuration for object storage\n\nAdmin panel\n\nGo to Infrastructure > Networks and ensure that your infrastructure has the following networks: A private network with the OSTOR private traffic typeA public network with the S3 public traffic type\nEnsure the public network for the S3 nodes is balanced by an external DNS load balancer.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the S3 cluster.\n\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n\nSee also\n\nManaging infrastructure networks\n\nWhat's next\n\nConfiguring node network interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n",
                "title": "To create the network configuration for object storage"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Infrastructure > Networks and ensure that your infrastructure has the following networks: A private network with the OSTOR private traffic typeA public network with the S3 public traffic type\nEnsure the public network for the S3 nodes is balanced by an external DNS load balancer.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the S3 cluster.\n\n",
                "title": "To create the network configuration for object storage"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-networks-object-storage.html"
    },
    {
        "title": "Kickstart file example",
        "content": "Kickstart file example\nBelow is an example of a kickstart file that you can use to install and configure Virtuozzo Hybrid Infrastructure in the unattended mode. You can use this file as the basis for creating your own kickstart files.\n\nThis kickstart file instructs the installer to erase and automatically partition every disk that it recognizes. Make sure to disconnect any disks with useful data prior to installation.\n# Use the SHA-512 encryption for user passwords and enable shadow passwords.auth --enableshadow --passalgo=sha512# Use the US English keyboard.keyboard --vckeymap=us --xlayouts='us'# Use English as the installer language and the default system language.lang en_US.UTF-8# Specify the encrypted root password for the node.rootpw --iscrypted xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx# Disable SELinux.selinux --disabled# Enable time synchronization via NTP.services --enabled=\"chronyd\"# Set the system time zone.timezone America/New_York# Specify a hostname for the node.# NOTE: The only way to change the host name later is via the technical support.network --hostname=<hostname># Configure network interfaces via DHCP.network --device=<iface1> --activatenetwork --device=<iface2> --activate# Alternatively, assign static addresses to network interfaces.#network --device=<iface1> --activate --bootproto=static --ip=<IP_addr> \\#--netmask=<mask> --gateway=<gw> --nameserver=<ns1>[,<ns2>,...]#network --device=<iface2> --activate --bootproto=static --ip=<IP_addr> \\#--netmask=<mask> --gateway=<gw> --nameserver=<ns1>[,<ns2>,...]# If needed, uncomment and specify network interfaces to create a bond.#network --device=bond0 --bondslaves=<iface1>,<iface2> \\#--bondopts=mode=balance-xor,miimon=100,xmit_hash_policy=layer3+4# Erase all partitions from all recognized disks.# WARNING: Destroys data on all disks that the installer can reach!clearpart --all --initlabelzerombr# Automatically partition the system disk, which is 'sda'.autopart --type=lvm# Install the required packages on the node.%packages@^hci%end# Uncomment to install the admin panel and storage components.# Specify an internal interface for the management network and# an external interface for the admin panel network.#%addon com_vstorage --management --internal-iface=eth0 \\#--external-iface=eth1 --password=xxxxxxxxx#%end# Uncomment to install the storage component. To register the node,# specify the token as well as the IP address of the admin panel.#%addon com_vstorage --storage --token=xxxxxxxxx --mgmt-node-addr=10.37.130.1#%end\r\n\nExample for the system partition on software RAID1\nIt is recommended to create RAID1 from disks of the same size, as the volume equals the size of the smallest disk.\nTo create a system partition on a software RAID1 volume, do not use the autopart option in the kickstart file. Consider the following example for a BIOS-based server, which partitions the disks sda and sdb, assembles the software RAID1 array, and creates expandable swap and root LVM volumes:# Create partitions on sda.part biosboot   --size=1      --ondisk=sda --fstype=biosbootpart raid.sda1  --size=1024   --ondisk=sda --fstype=ext4part raid.sda2  --size=101376 --ondisk=sda --grow# Create partitions on sdb.part biosboot   --size=1      --ondisk=sdb --fstype=biosbootpart raid.sdb1  --size=1024   --ondisk=sdb --fstype=ext4part raid.sdb2  --size=101376 --ondisk=sdb --grow# Create software RAID1 from sda and sdb.raid /boot --level=RAID1 --device=md0 --fstype=ext4 raid.sda1 raid.sdb1raid pv.01 --level=RAID1 --device=md1 --fstype=ext4 raid.sda2 raid.sdb2# Make LVM volumes for swap and root partitions.volgroup vgsys pv.01logvol swap --fstype=swap --name=swap --vgname=vgsys --recommendedlogvol /    --fstype=ext4 --name=root --vgname=vgsys --size=10240 --grow# Set the RAID device md0 as the first drive in the BIOS boot order.bootloader --location=mbr --boot-drive=sda --driveorder=md0bootloader --location=mbr --boot-drive=sdb --driveorder=md0\nFor installation on EFI-based servers, specify the /boot/efi partition instead of biosboot.part /boot/efi --size=200 --ondisk={sda|sdb} --fstype=efi\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/kickstart-file-example.html"
    },
    {
        "title": "Listing resource providers",
        "content": "Listing resource providersGET /resource_providers\r\n\nList resource providers.\nSource: https://docs.openstack.org/api-ref/placement/?expanded=list-resource-providers-detail#list-resource-providers\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nname (Optional)\nquery\nstring\nThe name of a resource provider to filter the list.\n\nuuid (Optional)\nquery\nstring\nThe UUID of a resource provider.\n\nmember_of (Optional)\nquery\nstring\n\nA string representing an aggregate uuid; or the prefix in: followed by a comma-separated list of strings representing aggregate uuids. The returned resource providers must directly be associated with at least one of the aggregates identified by uuid:member_of=5e08ea53-c4c6-448e-9334-ac4953de3cfa\r\nmember_of=in:42896e0d-205d-4fe3-bd1e-100924931787,5e08ea53-c4c6-448e-9334-ac4953de3cfa\r\n\nStarting from microversion 1.24, specifying multiple member_of query string parameters is possible. Multiple member_of parameters will result in filtering providers that are associated with aggregates listed in all of the member_of query string values. For example, to get the providers that are associated with aggregate A as well as associated with any of aggregates B or C, the user could issue the following query:member_of=AGGA_UUID&member_of=in:AGGB_UUID,AGGC_UUID\r\n\nStarting from microversion 1.32, specifying forbidden aggregates is supported in the member_of query string parameter. Forbidden aggregates are prefixed with a !. This negative expression can also be used in multiple member_of parameters:member_of=AGGA_UUID&member_of=!AGGB_UUID\r\n\nwould translate logically to \u00e2\u0080\u009cCandidate resource providers must be in AGGA and NOT in AGGB.\u00e2\u0080\u009d\r\nWe do NOT support ! on the values within in:, but we support !in:. Both of the following two example queries return candidate resource providers that are NOT in AGGA, AGGB, or AGGC:member_of=!in:AGGA_UUID,AGGB_UUID,AGGC_UUID\r\nmember_of=!AGGA_UUID&member_of=!AGGB_UUID&member_of=!AGGC_UUID\r\n\nWe do not check if the same aggregate uuid is in both positive and negative expression to return 400 BadRequest. We still return 200 for such cases. For example:member_of=AGGA_UUID&member_of=!AGGA_UUID\r\n\nwould return an empty list for resource_providers, while:member_of=in:AGGA_UUID,AGGB_UUID&member_of=!AGGA_UUID\r\n\nwould return resource providers that are NOT in AGGA but in AGGB.\nNew in version 1.3\n\nresources (Optional)\nquery\nstring\n\nA comma-separated list of strings indicating an amount of\r\nresource of a specified class that a provider must have the\r\ncapacity and availability to serve:resources=VCPU:4,DISK_GB:64,MEMORY_MB:2048\r\n\nNote that the amount must be an integer greater than 0.\nNew in version 1.4\n\nin_tree (Optional)\nquery\nstring\n\nA UUID of a resource provider. The returned resource providers will be in the same \u00e2\u0080\u009cprovider tree\u00e2\u0080\u009d as the specified provider.\nNew in version 1.14\n\nrequired (Optional)\nquery\nstring\n\nA comma-delimited list of string trait names. Results will be filtered to include only resource providers having all the specified traits.\nStarting from microversion 1.22, traits which are forbidden from any resource provider may be expressed by prefixing a trait with a !.\nNew in version 1.18\n\nExamplecurl -ks -H 'Content-Type: application/json' -H 'OpenStack-API-Version: placement 1.32' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8780/resource_providers\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nresource_providers\n\nbody\narray\nA list of resource_provider objects.\n\ngeneration\n\nbody\ninteger\nA consistent view marker that assists with the management of concurrent resource provider updates.\n\nname\n\nbody\nstring\nThe name of one resource provider.\n\nuuid\n\nbody\nstring\nThe UUID of a resource provider.\n\nlinks\n\nbody\narray\n\nA list of links associated with one resource provider.\n\nAggregates relationship link is available starting from version 1.1.\r\nTraits relationship link is available starting from version 1.6.\r\nAllocations relationship link is available starting from version 1.11.\n\nparent_provider_uuid\n\nbody\nstring\n\nThe UUID of the immediate parent of the resource provider.\nNew in version 1.14\n\nroot_provider_uuid\n\nbody\nstring\n\nRead-only UUID of the top-most provider in this provider tree.\nNew in version 1.14\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\nExample{\r\n  \"resource_providers\": [\r\n    {\r\n      \"uuid\": \"34233b75-4022-4539-9e3f-305e9f9f1f18\",\r\n      \"parent_provider_uuid\": null,\r\n      \"generation\": 546,\r\n      \"links\": [\r\n        {\r\n          \"href\": \"/resource_providers/34233b75-4022-4539-9e3f-305e9f9f1f18\",\r\n          \"rel\": \"self\"\r\n        },\r\n        {\r\n          \"href\": \"/resource_providers/34233b75-4022-4539-9e3f-305e9f9f1f18/inventories\",\r\n          \"rel\": \"inventories\"\r\n        },\r\n        {\r\n          \"href\": \"/resource_providers/34233b75-4022-4539-9e3f-305e9f9f1f18/usages\",\r\n          \"rel\": \"usages\"\r\n        },\r\n        {\r\n          \"href\": \"/resource_providers/34233b75-4022-4539-9e3f-305e9f9f1f18/aggregates\",\r\n          \"rel\": \"aggregates\"\r\n        },\r\n        {\r\n          \"href\": \"/resource_providers/34233b75-4022-4539-9e3f-305e9f9f1f18/traits\",\r\n          \"rel\": \"traits\"\r\n        },\r\n        {\r\n          \"href\": \"/resource_providers/34233b75-4022-4539-9e3f-305e9f9f1f18/allocations\",\r\n          \"rel\": \"allocations\"\r\n        }\r\n      ],\r\n      \"root_provider_uuid\": \"34233b75-4022-4539-9e3f-305e9f9f1f18\",\r\n      \"name\": \"node1.vstoragedomain\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-resource-providers.html"
    },
    {
        "title": "Acronis Backup Storage network requirements",
        "content": "Acronis Backup Storage network requirements\n\nGeneral network requirements and recommendations are listed in Network requirements and Network recommendations.\n\nTo use only the Backup Gateway and storage services, configure two networks, for internal and external traffic:\n\nSee also\n\nAcronis Backup Storage requirements\n\nNetwork recommendations\n\nNetwork ports\n\nSetting up networks for backup storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup%20storage-network-requirements.html"
    },
    {
        "title": "Managing load balancers",
        "content": "Managing load balancers",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-load-balancers.html"
    },
    {
        "title": "Managing NFS exports",
        "content": "Managing NFS exports\nYou can reconfigure and delete existing NFS exports.\nPrerequisites\n\nNFS exports are created, as described in Creating NFS exports.\n\nTo reconfigure an NFS export\n\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab, and then click the name of the desired share. This will open the share screen.\nSelect an export, and then click Edit on the right pane.\nIn the Edit export window, change the access or root squashing settings, and then click Save. \n\nCommand-line interface\nUse the following command:vinfra service nfs export set [--path <path>] [--access-type <access-type>] [--security-types <security-types>]\r\n                              [--client <address=ip_addresses:access=access_type:security=security_types>]\r\n                              [--squash <squash>] [--anonymous-gid <anonymous-gid>] [--anonymous-uid <anonymous-uid>]\r\n                              <share-name> <export-name>\n\n--path <path>\n\nPath to the NFS export\n--access-type <access-type>\n\nType of access to the NFS export (none, rw, or ro)\n--security-types <security-types>\n\nTypes of NFS export security (none, sys, krb5, krb5i, or krb5p)\n--client <address=ip_addresses:access=access_type:security=security_types>\n\nClient access list of the NFS export\n--squash <squash>\n\nNFS export squash (root_squash, root_id_squash, all_squash, or none)\n--anonymous-gid <anonymous-gid>\n\nAnonymous GID of the NFS export\n--anonymous-uid <anonymous-uid>\n\nAnonymous UID of the NFS export\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to change the access type of the export export1 from the share share1 to read-only, run:# vinfra service nfs export set share1 export1 --access-type ro\n\nTo delete an NFS export\n\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab, and then click the name of the desired share. This will open the share screen.\nSelect an export, and then click Delete on the right pane.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service nfs export delete <share-name> <export-name>\n\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to delete the export export1 from the share share1, run:# vinfra service nfs export delete share1 export1\n\nSee also\n\nManaging NFS shares\n\nMonitoring file storage\n\nAdding nodes to the NFS cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs export set [--path <path>] [--access-type <access-type>] [--security-types <security-types>]\r\n                              [--client <address=ip_addresses:access=access_type:security=security_types>]\r\n                              [--squash <squash>] [--anonymous-gid <anonymous-gid>] [--anonymous-uid <anonymous-uid>]\r\n                              <share-name> <export-name>\n\n--path <path>\n\nPath to the NFS export\n--access-type <access-type>\n\nType of access to the NFS export (none, rw, or ro)\n--security-types <security-types>\n\nTypes of NFS export security (none, sys, krb5, krb5i, or krb5p)\n--client <address=ip_addresses:access=access_type:security=security_types>\n\nClient access list of the NFS export\n--squash <squash>\n\nNFS export squash (root_squash, root_id_squash, all_squash, or none)\n--anonymous-gid <anonymous-gid>\n\nAnonymous GID of the NFS export\n--anonymous-uid <anonymous-uid>\n\nAnonymous UID of the NFS export\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to change the access type of the export export1 from the share share1 to read-only, run:# vinfra service nfs export set share1 export1 --access-type ro\n",
                "title": "To reconfigure an NFS export"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs export delete <share-name> <export-name>\n\n<share-name>\n\nNFS share name\n<export-name>\n\nNFS export name\n\nFor example, to delete the export export1 from the share share1, run:# vinfra service nfs export delete share1 export1\n",
                "title": "To delete an NFS export"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab, and then click the name of the desired share. This will open the share screen.\nSelect an export, and then click Edit on the right pane.\nIn the Edit export window, change the access or root squashing settings, and then click Save. \n\n",
                "title": "To reconfigure an NFS export"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab, and then click the name of the desired share. This will open the share screen.\nSelect an export, and then click Delete on the right pane.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete an NFS export"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-nfs-exports.html"
    },
    {
        "title": "Setting virtual machine CPU model",
        "content": "Setting virtual machine CPU model\nVirtual machines are created with the host CPU model by default. If nodes in the compute cluster have different CPUs, live migration of VMs between compute nodes may not work or applications inside VMs that depend on particular CPUs may not function properly. To avoid this, you can find out which CPU model offers compatibility across all nodes or a group of nodes in the compute cluster, and then manually set it as default either for the compute cluster or for particular nodes. In this case, however, the most compatible CPU model will be the least advanced one and compute nodes will lose CPU capabilities of a more advanced processor.\nDuring live migration, the nova-scheduler service that manages scheduling of virtual machines does not filter the destination node by CPU model. A VM can migrate to a node with a different CPU model if this model is newer than that of the source node and supports all its CPU features. If a VM tries to migrate to a node with an older CPU model, this attempt will fail, and the scheduler will try to migrate the VM to another node.\nYou can view the list of supported CPU models by running the command vinfra service compute show.\nLimitations:\n\nChanging CPU model affects only new VMs, that is, those created after the change.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\n\nTo set the CPU model per compute cluster\n\nDetermine baseline CPU models for the compute cluster. For example:# vinfra service compute baseline-cpu\r\n+------------------------+-------------------+\r\n| Field                  | Value             |\r\n+------------------------+-------------------+\r\n| All selected nodes     | models:           |\r\n|                        | - Haswell-noTSX   |\r\n|                        | patched: true     |\r\n| node001.vstoragedomain | models:           |\r\n|                        | - EPYC-IBPB       |\r\n|                        | - Broadwell-noTSX |\r\n|                        | - Haswell-noTSX   |\r\n|                        | - HostPassthrough |\r\n|                        | patched: true     |\r\n| node002.vstoragedomain | models:           |\r\n|                        | - Haswell-noTSX   |\r\n|                        | - Broadwell-noTSX |\r\n|                        | patched: true     |\r\n| node003.vstoragedomain | models:           |\r\n|                        | - Haswell-noTSX   |\r\n|                        | patched: true     |\r\n+------------------------+-------------------+\nThe command will print the most compatible CPU model across all compute nodes. In the example, it is Haswell-noTSX.\n\nSet this CPU model for the compute cluster. For example:# vinfra service compute set --cpu-model Haswell-noTSX\n\nYou can check that the CPU model has been successfully applied to the compute cluster in the vinfra service compute show output:# vinfra service compute show | grep cpu_model:\r\n| options      | cpu_model: Haswell-noTSX      |\nTo set the  CPU model per node\n\nDetermine baseline CPU models for required nodes. For example:# vinfra service compute baseline-cpu --nodes node002,node003\r\n+------------------------+-------------------+\r\n| Field                  | Value             |\r\n+------------------------+-------------------+\r\n| All selected nodes     | models:           |\r\n|                        | - Haswell-noTSX   |\r\n|                        | patched: true     |\r\n| node002.vstoragedomain | models:           |\r\n|                        | - Haswell-noTSX   |\r\n|                        | - Broadwell-noTSX |\r\n|                        | patched: true     |\r\n| node003.vstoragedomain | models:           |\r\n|                        | - Haswell-noTSX   |\r\n|                        | patched: true     |\r\n+------------------------+-------------------+\nThe command will print the most compatible CPU model across the specified compute nodes. In the example, it is Haswell-noTSX.\n\nSet this CPU model for the compute nodes. For example:# vinfra service compute set --cpu-model Haswell-noTSX --nodes node002,node003\n\nYou can check that the CPU model has been successfully applied to the specified nodes in the vinfra service compute node show output:# vinfra service compute node show node002 | grep cpu_model\r\n| cpu_model      | Haswell-noTSX           |\r\n\nTo unset the  CPU model\nSpecify an empty value for the --cpu-model option. For example, to unset the  CPU model from specific nodes, run:# vinfra service compute set --cpu-model '' --nodes node002,node003\nIn this case, the specified nodes will use the cluster-wide CPU model.\nIf you want to unset the CPU model from the entire compute cluster, run:# vinfra service compute set --cpu-model '' \nSee also\n\nConfiguring CPU features for virtual machines\n\nWhat's next\n\nSetting a DNS name for the compute API",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-virtual-machine-cpu-model.html"
    },
    {
        "title": "Network requirements",
        "content": "Network requirements\nThe general network requirements are the following:\n\nAll network interfaces on a node must be assigned IP addresses that belong to different subnets. A network interface can be a VLAN-tagged logical interface, an untagged bond, or an Ethernet link.\nThe network for internal traffic can be non-routable, with minimum 10 Gbit/s bandwidth.\nNodes are added to clusters by their IP addresses, not FQDNs. Changing the IP address of a node in the cluster will remove that node from the cluster. If you plan to use DHCP in a cluster, make sure that IP addresses are bound to the MAC addresses of the nodes\u00e2\u0080\u0099 network interfaces.\nEach node must have Internet access so that updates can be installed.\nNetwork time synchronization is required for correct statistics. It is enabled by default via the chronyd service. If you want to use ntpdate or ntpd, stop and disable chronyd first.\n\nSee also\n\nNetwork recommendations\n\nNetwork ports",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/network-requirements.html"
    },
    {
        "title": "Provisioning compute resources",
        "content": "Provisioning compute resources\nMultitenant compute resources, such as vCPUs, RAM, storage, floating IPs, load balances and Kubernetes clusters, can be provisioned to end users in the self-service panel. Additionally, you can install the billing metering service to collect usage data of compute resources in different projects.\nLimitations\n\nCompute storage space is not fully thin provisioned.  After user data removal, unused storage space is not reclaimed and is reported as actual used space, which is charged according to your licensing model. For more details, refer to Logical space chart.\n\nPrerequisites\n\nA clear understanding of the compute cluster, which is explained in About the compute cluster.\nYour hardware meets the requirements listed in Compute cluster requirements.\n  Your infrastructure networks are set up, as described in Setting up networks for the compute cluster. \nThe storage cluster is created by following the instructions in Deploying the storage cluster.\nDomains, projects, and users are created, as described in Configuring multitenancy.\nYou have access to the self-service panel configured, as outlined in Providing access to the self-service portal.\n\nProvisioning overview\n\nCreate the compute cluster. After the cluster is created, you can manage compute objects in the admin panel (refer to Managing the compute cluster).\nSet the same CPU model to all of the compute nodes.\nSet a DNS name for the compute API.\nSecure the OpenStack API traffic with an SSL certificate.\nIf you want to provision Kubernetes as a Service, install the Kubernetes service.\nIf you want to provision Load Balancer as a Service, install the load balancer service.\nIf you want to provision billing metering, install the billing metering service.\nIf you want to provision Backup and Restore as a Service, enable and configure the backup service.\nTo manage compute resources in the self-service panel, log in there at http://<admin_panel_IP_address>:8800 as a self-service user, and then proceed to create virtual objects, as described in Managing compute resources in the Self-Service Guide.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-compute-resources.html"
    },
    {
        "title": "Deleting backup plans",
        "content": "Deleting backup plansDELETE /v2/{project_id}/jobs/{job_id}\nDelete a backup plan.\nSource: https://docs.openstack.org/api-ref/backup/v2/index.html#delete-jobs-v2\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\njob_id\n\npath\nstring\nThe job UUID.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8736/v2/3046fb2c2a314a0fbb32607caa1e5277/jobs/e632eb1884e0468c8a41e656942df500\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-backup-plans.html"
    },
    {
        "title": "Backup storage in a public cloud",
        "content": "Backup storage in a public cloud\n\nGeneral requirements are listed in General requirements.\n\nNote the additional requirements for backup storage with the public cloud destination:\n\nWhen working with public clouds, Backup Gateway uses the local storage as the staging area as well as to keep service information. It means that the data to be uploaded to a public cloud is first stored locally and only then sent to the destination. For this reason, it is vital that the local storage is persistent and redundant so the data does not get lost. There are multiple ways to ensure the persistence and redundancy of local storage. You can deploy Backup Gateway on multiple cluster nodes and select a good redundancy mode. If  Virtuozzo Hybrid Infrastructure with the gateway is deployed on a single physical node, you can make the local storage redundant by replicating it among local disks. If Virtuozzo Hybrid Infrastructure with the gateway is deployed in a virtual machine, make sure it is made redundant by the virtualization solution it runs on.\n\r\n        Make sure the local storage cluster has plenty of logical space for staging. For example, if you perform backup daily, provide enough space for at least 1.5 days\u00e2\u0080\u0099 worth of backups. If the daily backup total is 2 TB, provide at least 3 TB of logical space. The required raw storage will vary depending on the encoding mode: 9 TB (3 TB per node) in the 1+2 mode, 5 TB (1 TB per node) in the 3+2 mode, etc.\r\n        \nA separate object container is required for each backup storage cluster.\r\n    \n\nTo better understand how to calculate the hardware configuration for backup storage with the public cloud destination, consider the following example with RAM and CPU reservations.\nIf you have 1 virtual machine (1 system+metadata disk and 1 storage disk) and want to use the 1+0 encoding mode with the disk failure domain, refer to the table below for the calculations. Note that in this configuration redundancy is provided by the virtualization solution.\n\nBackup storage in a public cloud                    \n\nService\nThe only node\n\nSystem\n4.5 GB,\t3.3 cores\n\nStorage services\n\n1 storage disk1 The storage disk is used for data staging. and 1 metadata on system disk (each takes 0.5 GB and 0.2 cores), that is 1 GB and 0.4 cores in total\n\nBackup Gateway\n1 GB, 0.5 cores\n\nService reservations\n6.5 GB of RAM and\r\n4.2 cores\n\nMinimum hardware configuration\n8 GB of RAM and 4 cores\n\nRecommended hardware configuration\n16 GB2 All extra RAM is used to cache disk reads. of RAM and 6 cores\n\nSee also\n\nBackup storage in a virtual machine\n\nAcronis Backup Storage network requirements\n\nProvisioning Acronis Backup Storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup-storage-in-a-public-cloud.html"
    },
    {
        "title": "Querying default quotas via CLI",
        "content": "Querying default quotas via CLI\nYou can display the default quotas for all users or buckets with the query-quotas command and the following parameters: -o specifying user for users or bucket for buckets:# ostor-s3-admin query-quotas -o user -V 0100000000000002\r\nversion: '1'\r\nsize: '1024'\r\ntype: 'user'# ostor-s3-admin query-quotas -o bucket -V 0100000000000002\r\nversion: '1'\r\nsize: '256'\r\ntype: 'bucket'",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-default-quotas-via-cli.html"
    },
    {
        "title": "Detaching network interfaces from virtual machines",
        "content": "Detaching network interfaces from virtual machinesDELETE /servers/{server_id}/os-interface/{port_id}\r\n\nDetach a network interface from the given virtual machine.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=detach-interface-detail#detach-interface\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nport_id\n\npath\nstring\nThe port ID.\n\nExample\nDetach a network interface with the specified ID from a VM with the specified ID.# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-OpenStack-Nova-API-Version: 2.67' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/b906404c55bb44729da99987536ac5bc/servers/0785ee80-1eca-426b-b8c4-5b499fc7f614/os-interface/bfc3228d-384e-4864-a583-54157225a4ef\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n501 - Not Implemented\n\nThe server either does not recognize the request method, or it lacks the ability to fulfill the request.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/detaching-network-interfaces-from-virtual-machines.html"
    },
    {
        "title": "Managing file storage",
        "content": "Managing file storage\nThis section outlines common administrator's tasks for NFS nodes, shares and exports.\nPrerequisites\n\nNFS exports are created, as described in Creating NFS exports.\nIf you have restricted outbound traffic in your cluster, you need to manually add a rule that will allow outbound traffic on TCP ports 88 and 749, and UDP port 88, as described in Configuring outbound firewall rules.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-file-storage.html"
    },
    {
        "title": "Compute network architecture",
        "content": "Compute network architecture\nVirtuozzo Hybrid Infrastructure supports distributed virtual switching on the basis of Open vSwitch. The latter runs on every compute node and forwards network traffic between virtual machines on the same node, and between virtual machines and infrastructure networks. Distributed virtual switching provides centralized management and monitoring of virtual network configuration across all nodes in the compute cluster.\nDistributed virtual routing used for virtual network connectivity enables placing virtual routers on compute nodes and routing VM traffic directly from hosting nodes. In the DNAT scenario, a floating IP is assigned directly to the VM\u00e2\u0080\u0099s network interface. If SNAT is used, then traffic is routed via management nodes.\nPhysical network connectivity\nPhysical networks are connected to infrastructure networks on Layer 2.\nThe physical representation of physical network connectivity can be shown as follows:\n\nOn the figure above:\n\nFive virtual machines are distributed across the compute cluster and connected to two untagged physical networks via two physical switches: VM1 and VM2 belong to one physical network, while VM3, VM4, and VM5 belong to the other one.\nFor each compute network, the DHCP server runs on the management node.\nThe compute nodes are connected to one physical switch via the eth0 network interfaces, and to the other physical switch via eth1, and reside in two separate L2 segments.\nThe eth0 and eth1 network interfaces are connected to the infrastructure networks with the VM public traffic type.\nThe physical router interconnects two physical networks created on top of the infrastructure ones and provides access to public networks, such as the Internet.\n\nLogically, the physical networking scheme can be represented as follows:\n\nVirtual network connectivity\nVXLAN technology used for virtual networks allows creating logical L2 networks in L3 networks by encapsulating (tunneling) Ethernet frames over UDP packets.\nThe physical representation of virtual network connectivity can be shown as follows:\n\nOn the figure above:\n\nThree virtual machines are distributed across the compute cluster and connected to two virtual networks via two virtual switches: VM1 and VM2 belong to one virtual network, VM3 belongs to the other one.\nFor each compute network, the DHCP server runs on the management node.\nThe distributed virtual router connects the virtual networks and the untagged physical network created on top of the infrastructure one.\nThe compute nodes are connected to the physical switch via the eth0 network interfaces and reside in one L2 segment.\nThe eth0 network interfaces are connected to the infrastructure network with the VM private and VM public traffic types.\nThe physical router provides access to public networks, such as the Internet.\n\nLogically, the virtual networking scheme can be represented as follows:\n\nSee also\n\nCompute cluster architecture",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/compute-network-architecture.html"
    },
    {
        "title": "Managing S3 user and bucket limits via CLI",
        "content": "Managing S3 user and bucket limits via CLI\nThis section describes limits you can define for users and buckets via the command-line interface. You can apply the limits according to specific options that can be a part of your service plan.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-user-and-bucket-limits-via-cli.html"
    },
    {
        "title": "6. Limitations\u00c2\u00b6",
        "content": "6. Limitations | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\n\n6. Limitations\u00c2\u00b6\nThe Hystax Acura limitations are listed in the official documentation.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/limitations.html"
    },
    {
        "title": "Running the benchmark for S3",
        "content": "Running the benchmark for S3\nPrerequisites\n\nEnsure that you have configured the access script, as described in Setting up the benchmark for S3.\nIf the cluster nodes have SSD/NVMe caches, make sure they have been flushed, as instructed in Preparing to run the benchmark.\n\nTo run GOSBench\n\nOn the coordinator node, start the benchmark server:# ./server -c gosbench_script.yaml\n\nOn each load generator, start the benchmark workers:# ./worker -p 8009 -s <coordinator_IP>:2000\n\nTo collect GOSBench results\nGOSBench shows performance results in the console, and also uses Prometheus and Grafana to collect and graph results.\nAn example console output is as follows:INFO[2022-06-07T15:09:47+03:00] Ready to accept connections\r\nINFO[2022-06-07T15:09:58+03:00] 127.0.0.1:57956 connected to us\r\nINFO[2022-06-07T15:09:58+03:00] We found worker 1 / 1 for test 0              Worker=\"127.0.0.1:57956\"\r\nINFO[2022-06-07T15:10:03+03:00] All workers have finished preparations - starting performance test  test=\"write test\"\r\nINFO[2022-06-07T15:25:20+03:00] All workers have finished the performance test - continuing with next test  test=\"write test\"\r\nINFO[2022-06-07T15:25:20+03:00] GRAFANA: ?from=1654603803922&to=1654604720745  test=\"write test\"\r\nINFO[2022-06-07T15:25:20+03:00] PERF RESULTS  Average BW in Byte/s=6.638758826285763e+07 \\\r\nAverage latency in ms=3018.8787541713014 Test runtime on server=15m16.822798366s \\\r\nTotal Bytes=6.0183302998e+10 Total Operations=899 test=\"write test\"\r\n\nThe line starting with INFO[<date>:<time>] GRAFANA includes a query string that you can append to the Grafana dashboard URL. The admin panel provides the Grafana server and the S3 overview dashboard that you can use to check the benchmark behavior:\n\nSee also\n\nGeneral considerations\n\nRunning the benchmark for NFS and iSCSI\n\nBenchmarking disks\n\nBenchmarking the network\n\nTroubleshooting performance issues",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/running-benchmark-for-s3.html"
    },
    {
        "title": "Restoring default outbound firewall rules",
        "content": "Restoring default outbound firewall rules\nLimitations\n\nWhen resetting to defaults, your custom outbound firewall rules will be discarded.\n\nTo restore the default outbound firewall rules\nUse the following command:vinfra cluster network set --restore-default-outbound-allow-list <network>\n\n<network>\n\nNetwork ID or name\n\nFor example, to restore the default outbound allow rules for the Public network, run:vinfra cluster network set Public --restore-default-outbound-allow-list\r\n\nSee also\n\nDefault outbound firewall rules",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/restoring-default-outbound-firewall-rules.html"
    },
    {
        "title": "Managing placements for compute nodes",
        "content": "Managing placements for compute nodes\nA placement is a group of compute nodes that share a distinctive feature. It can be a special license for software to run in virtual machines or an advanced CPU model. When you group nodes into a placement, you can assign it to an image or a flavor. Then, all of the VMs created from this image or with this flavor will be placed on the nodes with the assigned placement. In this way, you can create placements to assign VMs that need a specific feature to the nodes that have it.\n\nWhen using placements, keep in mind that Kubernetes clusters and load balancers are created from predefined OS images, which follow the same placement rules as all other compute images. You need to assign the correct placement to these images:\n\nFor Kubernetes clusters\u00e2\u0080\u0094to fedora-coreos-x64-k8saas\nFor load balancers\u00e2\u0080\u0094to amphora-x64-haproxy",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-placements.html"
    },
    {
        "title": "Setting up the benchmark for NFS and iSCSI",
        "content": "Setting up the benchmark for NFS and iSCSI\nTo set up the benchmark for the NFS and iSCSI resources, install and confugure the fio tool, and then mount the resources to all load generators.\nPrerequisites\n\nThe load generator VMs are deployed, as described in Deploying virtual machines with load generators.\nThe target storage is created, as described in Creating the target storage.\nTo be able to mount an NFS resource, you might need to install the nfs-utils package by running yum install nfs-utils.\n\nTo install fio\n\nOn the coordinator node, create a directory to store the fio scripts, for example, /root/scripts.# mkdir /root/scripts\n\nDownload the fio benchmark scripts to the /root/scripts directory:# cd /root/scripts\r\n# url=https://docs.virtuozzo.com/fio/vm/; \\\r\nwget $url/expand.fio $url/prepare-set.fio $url/randread.fio $url/randrw.fio $url/randwrite.fio $url/seqread.fio $url/seqwrite.fio\n\nIf required, install the fio benchmark tool on each load generator and on the coordinator node:# yum install fio -y\n\nEnsure that the following parameters in the fio scripts  are correct:\n\nsize is at least twice the target node\u00e2\u0080\u0099s RAM, divided by the node\u00e2\u0080\u0099s CPU cores. For example, for a quad-core node with 16 GiB RAM, the value should be 4g. This parameter sets the total amount of data that each I/O thread will transfer.\nnumjobs is the number of CPU cores. If hyper-threading is enabled, use the number of CPU threads instead. The goal is to fully load the CPU without overcommitting it. For example, on a quad-core node with hyper-threading, the value should be 8. This parameter sets the amount of I/O threads that will be started.\ndirectory is the target directory to be tested. For example, if the resource to be tested is mounted to /mnt/test, then update this field accordingly.\n\nFor more options, refer to the fio documentation.\n\nTo mount the NFS resource\nMount the NFS resource  to each load generator by running the following command:# mount -t nfs -o vers=4.0 <share_IP>:<share_name> /mnt/test\nWhere:\n\n-o vers=4.0 is the NFS version to use.\n<target_IP> is the IP address or hostname of the NFS share.\n<share_name> is the identifier of the NFS share.\n /mnt/test is the target directory that you specified in the fio scripts.\n\nTo mount the iSCSI resource\n\nAccess the iSCSI resource by following  the detailed instructions in the Storage User Guide.\nMount the iSCSI device to each load generator. As a mount directory, use the target directory that you specified in the fio scripts, for example, /mnt/test.\n\nSee also\n\nSetting up the benchmark for S3\n\nWhat's next\n\nRunning the benchmark for NFS and iSCSI",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-benchmark-for-nfs-iscsi.html"
    },
    {
        "title": "System requirements",
        "content": "System requirements\nVirtuozzo Hybrid Infrastructure works on top of commodity hardware, so you can create a cluster from regular servers, disks, and network cards. Still, to achieve the optimal performance, a number of requirements must be met and a number of recommendations should be followed.\nFor production, you can run Virtuozzo Hybrid Infrastructure on a physical server, or inside a virtual machine to use backup storage in a public cloud. In any other case, deploying Virtuozzo Hybrid Infrastructure inside virtual machines is only supported for evaluation purposes. The hardware requirements and recommended number of servers in a cluster depend on the services you will deploy.\nIf you are unsure of what hardware to choose, contact your sales representative.\n\nSee also\n\nData redundancy\n\nFailure domains\n\nStorage tiers\n\nStorage policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/requirements.html"
    },
    {
        "title": "Attaching interfaces to virtual routers",
        "content": "Attaching interfaces to virtual routersPUT /v2.0/routers/{router_id}/add_router_interface\r\n\nAdds an internal interface to a virtual router.\r\nThis means a specified subnet is attached to a router\r\nas an internal router interface.\nYou will need to specify the internal network ID and the ID of a subnet or port in the request body:\n\nSubnet ID. The gateway IP address for the subnet is used as\r\nan IP address of the created router interface. You can also pass a custom IP address from the selected network in the ip_address parameter.\nPort ID. The IP address associated with the port is used as\r\nan IP address of the created router interface.\n\nWhen you specify an IPv6 subnet, this operation adds the subnet to\r\nan existing internal port with same network ID, on the router. If\r\na port with the same network ID does not exist, this operation\r\ncreates a port on the router for that subnet.\nThe limitation of one IPv4 subnet per router port remains, though a\r\nport can contain any number of IPv6 subnets that belong to the same\r\nnetwork ID.\nWhen you use the port-create command to add a port and then\r\ncall router-interface-add with this port ID, this operation\r\nadds the port to the router if the following conditions are met:\n\nThe port has no more than one IPv4 subnet.\nThe IPv6 subnets, if any, on the port do not have same network\r\nID as the network ID of IPv6 subnets on any other ports.\n\nIf you specify both subnet ID and port ID,\r\nthis operation returns the Bad Request (400) response code.\nIf the port is already in use, this operation returns the\r\nConflict (409) response code.\nThis operation returns a port ID that is either:\n\nThe same ID that is passed in the request body\r\nwhen a port is specified.\nThe ID of a port that this operation creates to attach the\r\nsubnet to the router.\n\nAfter you run this operation, the operation sets:\n\nThe device_id attribute of this port to the router ID\nThe device_owner attribute to network:router_interface\n\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=add-interface-to-router-detail#add-interface-to-router\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nsubnet_id (Optional)\nbody\nstring\nThe ID of the subnet.\r\nOne of subnet_id or port_id must be specified.\n\nport_id (Optional)\nbody\nstring\nThe ID of the port.\r\nOne of subnet_id or port_id must be specified.\n\nExample# curl -ks -X PUT -H 'Content-Type: applicaltion/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"subnet_id\": \"112f9b9c-7be2-41c9-8c31-903b263353e7\"\r\n}' https://<node_IP_addr>:9696/v2.0/routers/02542148-44cb-470d-a551-58f370c47b83/add_router_interface\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nid\n\nbody\nstring\nThe ID of the resource.\n\nsubnet_id\n\nbody\nstring\nThe ID of the subnet which the router interface belongs to.\n\nsubnet_ids\n\nbody\narray\nA list of the ID of the subnet which the router interface belongs to.\r\nThe list contains only one member.\n\nnetwork_id\n\nbody\nstring\nThe ID of the attached network.\n\nport_id\n\nbody\nstring\nThe ID of the port which represents the router interface.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"network_id\": \"c4e2f31b-fe3b-402b-ac1b-b182693f72f7\",\r\n  \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n  \"subnet_id\": \"112f9b9c-7be2-41c9-8c31-903b263353e7\",\r\n  \"subnet_ids\": [\r\n    \"112f9b9c-7be2-41c9-8c31-903b263353e7\"\r\n  ],\r\n  \"port_id\": \"fb40083e-e33f-4f75-adff-b76c3cfc5a42\",\r\n  \"id\": \"02542148-44cb-470d-a551-58f370c47b83\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/attaching-interfaces-to-virtual-routers.html"
    },
    {
        "title": "Revoking S3 user access keys via REST API",
        "content": "Revoking S3 user access keys via REST API\nYou can revoke the specified access key pair of the specified user by sending a POST request to the ostor-users service along with the user email address and access key in the key pair:# s3_curl POST \"http://s3.example.com/?ostor-users&emailAddress=user@example.com&revokeKey=ca55631f9f3d59dcZMDX\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/revoking-s3-user-access-keys-via-rest-api.html"
    },
    {
        "title": "Listing images",
        "content": "Listing imagesGET /v2/images\r\n\nList virtual machine images.\nUse filters to list only the images you need. For example, to list all images in a placement, append the following to the request:?trait:CUSTOM_HCI_<UUID>=required\r\n\nSource: https://docs.openstack.org/api-ref/image/v2/index.html?expanded=list-images-detail#list-images\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ncreated_at (Optional)\nquery\nstring\n\nSpecify a comparison filter based on the date and time when the resource\r\nwas created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nIf you omit the time zone, the UTC time zone is assumed.\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number of items up to a limit\r\nvalue. Use the limit parameter to make an initial limited request and\r\nuse the ID of the last-seen item from the response as the marker\r\nparameter value in a subsequent limited request.\n\nmarker (Optional)\nquery\nstring\nThe ID of the last-seen item. Use the limit parameter to make an\r\ninitial limited request and use the ID of the last-seen item from the\r\nresponse as the marker parameter value in a subsequent limited request.\n\nmember_status (Optional)\nquery\nstring\nFilters the response by a member status.  A valid value is accepted,\r\npending, rejected, or all.  Default is accepted.\n\nname (Optional)\nquery\nstring\nFilters the response by a name, as a string.  A valid value is the name of\r\nan image.\n\nos_hidden (Optional)\nquery\nboolean\n\nWhen true, filters the response to display only \u00e2\u0080\u009chidden\u00e2\u0080\u009d images.  By\r\ndefault, such images are not included in the image-list response.\nNew in version 2.7\n\nowner (Optional)\nquery\nstring\nFilters the response by a project (also called a \u00e2\u0080\u009ctenant\u00e2\u0080\u009d) ID.  Shows only\r\nimages that are shared with you by the specified owner.\n\nprotected (Optional)\nquery\nboolean\nFilters the response by the protected image property.  A valid value is\r\none of true, false (must be all lowercase).  Any other value will\r\nresult in a 400 response.\n\nsize_max (Optional)\nquery\nstring\nFilters the response by a maximum image size, in\r\nbytes.\n\nsize_min (Optional)\nquery\nstring\nFilters the response by a minimum image size, in\r\nbytes.\n\nstatus (Optional)\nquery\ninteger\nFilters the response by an image status.\n\ntag (Optional)\nquery\nstring\nFilters the response by the specified tag value.  May be repeated, but keep\r\nin mind that you are making a conjunctive query, so only images containing\r\nall the tags specified will appear in the response.\n\nupdated_at (Optional)\nquery\nstring\n\nSpecify a comparison filter based on the date and time when the resource\r\nwas most recently modified.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nIf you omit the time zone, the UTC time zone is assumed.\n\nvisibility (Optional)\nquery\nstring\nFilters the response by an image visibility value.  A valid value is\r\npublic, private, community, shared, or all.  (Note\r\nthat if you filter on shared, the images included in the response\r\nwill only be those where your member status is accepted unless you\r\nexplicitly include a member_status filter in the request.)  If you\r\nomit this parameter, the response shows public, private, and those\r\nshared images with a member status of accepted.\n\nsort_dir (Optional)\nquery\nstring\nSorts the response by a set of one or more sort\r\ndirection and attribute (sort_key) combinations. A valid value\r\nfor the sort direction is asc (ascending) or desc\r\n(descending). If you omit the sort direction in a set, the default\r\nis desc.\n\nsort_key (Optional)\nquery\nstring\nSorts the response by an attribute, such as\r\nname, id, or updated_at. Default is created_at.\r\nThe API uses the natural sorting direction of the sort_key\r\nimage attribute.\n\nsort (Optional)\nquery\nstring\n\nSorts the response by one or more attribute and sort direction\r\ncombinations. You can also set multiple sort keys and directions.\r\nDefault direction is desc.\nUse the comma (,) character to separate multiple values. For\r\nexample:\n\nGET /v2/images?sort=name:asc,status:desc\r\n\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<>' \\\r\nhttps://<node_IP_addr>:9292/v2/images\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nimages\n\nbody\narray\nA list of image objects.\n\nfirst\n\nbody\nstring\nThe URI for the first page of response.\n\nnext\n\nbody\nstring\nThe URI for the next page of response.  Will not be present on the last\r\npage of the response.\n\nschema\n\nbody\nstring\nThe URL for the schema describing a virtual machine image.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"images\": [\r\n    {\r\n      \"image_validated\": \"yes\",\r\n      \"container_format\": \"bare\",\r\n      \"min_ram\": 0,\r\n      \"updated_at\": \"2020-02-04T10:58:47Z\",\r\n      \"file\": \"/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67/file\",\r\n      \"owner\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"id\": \"c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n      \"size\": 12716032,\r\n      \"os_distro\": \"linux\",\r\n      \"self\": \"/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n      \"disk_format\": \"qcow2\",\r\n      \"os_hash_algo\": \"sha512\",\r\n      \"direct_url\": \"file:///mnt/vstorage/vols/datastores/glance/c92d820c-<...>\",\r\n      \"hw_disk_bus\": \"virtio\",\r\n      \"schema\": \"/v2/schemas/image\",\r\n      \"status\": \"active\",\r\n      \"tags\": [],\r\n      \"trait:CUSTOM_HCI_122E856B9E9C4D80A0F8C21591B5AFCB\": \"required\",\r\n      \"visibility\": \"public\",\r\n      \"min_disk\": 1,\r\n      \"virtual_size\": null,\r\n      \"name\": \"cirros\",\r\n      \"checksum\": \"443b7623e27ecf03dc9e01ee93f67afe\",\r\n      \"created_at\": \"2020-01-28T12:58:17Z\",\r\n      \"os_hidden\": false,\r\n      \"protected\": false,\r\n      \"os_hash_value\": \"6513f21e44aa3da349f248188a<...>\",\r\n      \"os_type\": \"linux\"\r\n    }\r\n  ],\r\n  \"schema\": \"/v2/schemas/images\",\r\n  \"first\": \"/v2/images\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-images.html"
    },
    {
        "title": "Listing backups with details",
        "content": "Listing backups with detailsGET /v3/{project_id}/backups/detail\nList backups with details to which the project has access.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/#list-backups-with-detail\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nall_tenants (Optional)\nquery\nstring\nShows details for all project. Admin only.\n\nsort (Optional)\nquery\nstring\nComma-separated list of sort keys and optional sort directions in the form of <key>[:<direction>]. A valid sort key value is name, status, container_format, disk_format, size, id, created_at, or updated_at. Default is created_at. A valid direction is asc (ascending) or desc (descending).\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number of items up to a limit value. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request.\n\noffset (Optional)\nquery\ninteger\nUsed in conjunction with limit to return a slice of items. offset specifies where to start in the list.\n\nmarker (Optional)\nquery\r\n\nstring\nThe ID of the last-seen item. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request.\n\nwith_count (Optional)\r\n\nquery\r\n\nboolean\n\nWhether to show count in the API response or not, default is False.\nNew in version 3.45\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/detail\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nbackups\n\nbody\narray\n\r\nA list of backup objects.\n\nid\n\nbody\nstring\nThe UUID of the backup.\n\nbackup_id\n\nbody\nstring\nThe UUID of the backup.\n\nvolume_id\n\nbody\nstring\nThe UUID of the volume.\n\nstatus\n\nbody\nstring\nThe backup status.\n\nobject_count\n\nbody\ninteger\nThe number of objects in the backup.\n\nfail_reason\n\nbody\nstring\n\r\nIf the backup failed, the reason for the failure. Otherwise, null.\n\ncontainer (Optional)\nbody\nstring\nThe container name or null.\n\ndescription (Optional)\nbody\nstring\nThe backup description or null.\n\navailability_zone (Optional)\nbody\nstring\nThe name of the availability zone.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\n\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated.\n\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nlinks\n\nbody\narray\nLinks for the backup.\n\nname\n\nbody\nstring\nThe backup name.\n\nhas_dependent_backups (Optional)\nbody\nboolean\nIf this value is true, there are other backups depending on this backup.\n\nsize\n\nbody\n\r\ninteger\nThe size of the volume, in gibibytes (GiB).\n\nis_incremental (Optional)\nbody\nboolean\nIndicates whether the backup mode is incremental. If this value is true, the backup mode is incremental. If this value is false, the backup mode is full.\n\ndata_timestamp\n\nbody\nstring\nThe time when the data on the volume was first saved. If it is a backup from a volume, it will be the same as created_at for a backup. If it is a backup from a snapshot, it will be the same as created_at for the snapshot.\n\nsnapshot_id (Optional)\nbody\n\r\nstring\nThe UUID of the source volume snapshot.\n\nos-backup-project-attr:project_id\n\nbody\nstring\n\nThe UUID of the owning project.\nNew in version 3.18\n\nmetadata (Optional)\nbody\nobject\n\nThe backup metadata key value pairs.\nNew in version 3.43\n\nuser_id\n\nbody\nstring\n\nThe UUID of the project owner.\nNew in version 3.56\n\nencryption_key_id (Optional)\nbody\nstring\n\nThe UUID of the encryption key. Only included for encrypted volumes.\nNew in version 3.64\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\nExample{\r\n  \"backups\": [\r\n    {\r\n      \"id\": \"1e49d21e-44e1-401c-acc5-59115c12f0c4\",\r\n      \"status\": \"available\",\r\n      \"size\": 1,\r\n      \"object_count\": 4,\r\n      \"availability_zone\": null,\r\n      \"container\": \"bucket1\",\r\n      \"created_at\": \"2024-05-09T10:41:14.272633\",\r\n      \"updated_at\": \"2024-05-09T10:41:28.005870\",\r\n      \"name\": \"vm2/cirros/Boot volume-2024-05-09T10:41:13\",\r\n      \"description\": null,\r\n      \"fail_reason\": null,\r\n      \"volume_id\": \"98db149d-b9e6-42d7-814d-492563c56fef\",\r\n      \"links\": [\r\n        {\r\n          \"rel\": \"self\",\r\n          \"href\": \"https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/1e49d21e-44e1-401c-acc5-59115c12f0c4\"\r\n        },\r\n        {\r\n          \"rel\": \"bookmark\",\r\n          \"href\": \"https://<node_IP_addr>:8776/3046fb2c2a314a0fbb32607caa1e5277/backups/1e49d21e-44e1-401c-acc5-59115c12f0c4\"\r\n        }\r\n      ],\r\n      \"is_incremental\": false,\r\n      \"has_dependent_backups\": false,\r\n      \"snapshot_id\": null,\r\n      \"data_timestamp\": \"2024-05-09T10:41:14.272633\",\r\n      \"progress\": 100.0\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-backups-with-details.html"
    },
    {
        "title": "Managing security groups",
        "content": "Managing security groups\nA security group is a set of network access rules that control incoming and outgoing traffic to virtual machines assigned to this group. With security group rules, you can specify the type and direction of traffic that is allowed access to a virtual interface port. Traffic that does not satisfy any rule is dropped.\nFor each project, the default security group is automatically created in the compute cluster. This group allows all traffic on all ports for all protocols and cannot be deleted. When you attach a network interface to a VM, the interface is associated with the default security group, unless you explicitly select a custom security group.\nYou can assign one or more security groups to both new and existing virtual machines. When you add rules to security groups or remove them, the changes are enforced at runtime.\nLimitations\n\nYou can manage only IPv4 security group rules.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-security-groups.html"
    },
    {
        "title": "Creating NFS shares",
        "content": "Creating NFS shares\nLimitations\n\nThe redundancy mode of an NFS share cannot be changed after its creation.\n\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nThe NFS cluster is created by following the instructions in Creating the NFS cluster.\n\nTo create an NFS share\n\nAdmin panel\n\nOpen the Storage services > NFS > Shares screen, and then click Add share.\n\nIn the Add share window, specify a unique name and IP address, which must be unused and, if authentication is enabled, domain resolvable. In addition, this IP address should be within the network subnet of the node\u00e2\u0080\u0099s interface.\n\nTo authenticate clients in an NFS share, do the following:\n\nCreate a principal with its key table for the share in Kerberos KDC (Key Distribution Center), as described in Authenticating NFS share users via Kerberos.\n\nUpload the corresponding keytab file.\n\nClick Next.\n\nOn the next step, specify the share size, in gibibytes, and redundancy parameters, such as a storage tier, failure domain, and redundancy mode. For users accessing exports, the share size will be the size of the file system.\n\nClick Add.\n\nAfter the share is created, you can proceed to create NFS exports.\n\nCommand-line interface\nUse the following command:vinfra service nfs share create --node <node> --ip-address <ip_address> --size <size> --tier {0,1,2,3}\r\n                                (--replicas <norm> | --encoding <M>+<N>) --failure-domain {0,1,2,3,4} \r\n                                [--krb-keytab <krb-keytab>] <name>\n\n--node <node>\n\nNode ID\n--ip-address <ip_address>\n\nIP address of the NFS share\n--size <size>\n\nNFS share size, in bytes. You can also specify the following units: KiB for kibibytes, MiB for mebibytes, GiB for gibibytes, TiB for tebibytes, and PiB for pebibytes.\n--tier {0,1,2,3}\n\nStorage tier (default: 0)\n--replicas <norm>\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain (default: 1)\n\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: the number of data blocks\nN: the number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain (default: 0)\n--krb-keytab <krb-keytab>\n\nKerberos keytab file\n<name>\n\nNFS share name\n\nFor example, to create the NFS share share1 with the IP address 10.136.18.149 on the node with the ID 923926da-a879-5f56-1b24-1462917ed335, run:# vinfra service nfs share create share1 --node 923926da-a879-5f56-1b24-1462917ed335 \\\r\n--ip-address 10.136.18.149 --size 107374182400 --tier 0 --encoding 1+2 --failure-domain 1\nThe created NFS share will appear in the vinfra service nfs share list output:# vinfra service nfs share list\r\n+--------+---------------+------------------------------------------+\r\n| name   | ip_address    | node                                     |\r\n+--------+---------------+------------------------------------------+\r\n| share1 | 10.136.18.149 | cfgd_id: 1                               |\r\n|        |               | has_configd: true                        |\r\n|        |               | id: 923926da-a879-5f56-1b24-1462917ed335 |\r\n|        |               | ip_address: node001.vstoragedomain       |\r\n+--------+---------------+------------------------------------------+\n\nWhat's next\n\nCreating NFS exports",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs share create --node <node> --ip-address <ip_address> --size <size> --tier {0,1,2,3}\r\n                                (--replicas <norm> | --encoding <M>+<N>) --failure-domain {0,1,2,3,4} \r\n                                [--krb-keytab <krb-keytab>] <name>\n\n--node <node>\n\nNode ID\n--ip-address <ip_address>\n\nIP address of the NFS share\n--size <size>\n\nNFS share size, in bytes. You can also specify the following units: KiB for kibibytes, MiB for mebibytes, GiB for gibibytes, TiB for tebibytes, and PiB for pebibytes.\n--tier {0,1,2,3}\n\nStorage tier (default: 0)\n--replicas <norm>\n\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain (default: 1)\n\n\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: the number of data blocks\nN: the number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain (default: 0)\n--krb-keytab <krb-keytab>\n\nKerberos keytab file\n<name>\n\nNFS share name\n\nFor example, to create the NFS share share1 with the IP address 10.136.18.149 on the node with the ID 923926da-a879-5f56-1b24-1462917ed335, run:# vinfra service nfs share create share1 --node 923926da-a879-5f56-1b24-1462917ed335 \\\r\n--ip-address 10.136.18.149 --size 107374182400 --tier 0 --encoding 1+2 --failure-domain 1\nThe created NFS share will appear in the vinfra service nfs share list output:# vinfra service nfs share list\r\n+--------+---------------+------------------------------------------+\r\n| name   | ip_address    | node                                     |\r\n+--------+---------------+------------------------------------------+\r\n| share1 | 10.136.18.149 | cfgd_id: 1                               |\r\n|        |               | has_configd: true                        |\r\n|        |               | id: 923926da-a879-5f56-1b24-1462917ed335 |\r\n|        |               | ip_address: node001.vstoragedomain       |\r\n+--------+---------------+------------------------------------------+\n",
                "title": "To create an NFS share"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen the Storage services > NFS > Shares screen, and then click Add share.\n\nIn the Add share window, specify a unique name and IP address, which must be unused and, if authentication is enabled, domain resolvable. In addition, this IP address should be within the network subnet of the node\u00e2\u0080\u0099s interface.\n\n\nTo authenticate clients in an NFS share, do the following:\n\nCreate a principal with its key table for the share in Kerberos KDC (Key Distribution Center), as described in Authenticating NFS share users via Kerberos.\n\nUpload the corresponding keytab file.\n\n\n\n\n\n\n\nClick Next.\n\nOn the next step, specify the share size, in gibibytes, and redundancy parameters, such as a storage tier, failure domain, and redundancy mode. For users accessing exports, the share size will be the size of the file system.\n\n\n\n\n\nClick Add.\n\nAfter the share is created, you can proceed to create NFS exports.\n",
                "title": "To create an NFS share"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-nfs-shares.html"
    },
    {
        "title": "Managing S3 access keys",
        "content": "Managing S3 access keys\nAn S3 user is created with one access key pair: an access key and a secret key. It is recommended to periodically delete old access key pairs and generate new ones. Enabling and disabling access keys allows or prohibits access to user data using these keys. When you delete an access key, it cannot be retrieved.\nLimitations\n\nAn S3 user can have up to two key pairs.\nThe last access key pair cannot be deleted.\n\nTo copy S3 access key pairs for an S3 user\n\n Open the Storage services > S3 > Users screen, and then select a user.\n\nOn the user right pane, browse the S3 access keys section:\n\nTo copy an access key ID, click the copy icon next to the key.\nTo copy a secret access key, click the ellipsis icon next to the key, and then click Copy secret access key.\n\nTo add an access key pair for an S3 user\n\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section and click Create.\nIn the Create S3 access key window, optionally specify a name for the key, and then click Create.\n\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys add [--domain <domain>] [--user <user>] [--access-key <key>]\r\n                                             [--secret-key <secret>] [--name <friendly-name>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--access-key <key>\n\nAccess key ID\n--secret-key <secret>\n\nSecret key\n--name <friendly-name>\n\nA friendly name for the key\n\nFor example, to add an access key pair for the S3 user user1 in the domain domain1, run:vinfra service s3 self-service user keys add --domain domain1 --user user1 --name new\nYou can check the user access keys in the vinfra service s3 self-service user show output:# vinfra service s3 self-service user show --domain domain1 --user user1\r\n+---------+----------------------------------------------------------------+\r\n| Field   | Value                                                          |\r\n+---------+----------------------------------------------------------------+\r\n| arn     | arn:aws:iam::dff4158faaa848ac92b7284fc011b72f:fef81edf9cbf754b |\r\n| enabled | True                                                           |\r\n| keys    | - acc_key: fef81edf9cbf754bO22W                                |\r\n|         |   acc_secrete: VgI3Mn4UEuJI4PxhdNJveVe8IouXyFzrCAgtJ0G1        |\r\n|         |   enabled: true                                                |\r\n|         |   name: null                                                   |\r\n|         | - acc_key: fef81edf9cbf754b0G5C                                |\r\n|         |   acc_secrete: ygENV2oBGhaD3qYr5tYqEh4xlFmthvcGWSs6fU3o        |\r\n|         |   enabled: true                                                |\r\n|         |   name: new                                                    |\r\n+---------+----------------------------------------------------------------+\n\nTo disable an access key pair for an S3 user\n\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section, click the ellipsis icon next to the key, and then click Disable.\nClick Disable in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys disable [--domain <domain>] [--user <user>] [--key <key>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--key <key>\n\nAccess key ID\n\nFor example, to disable the access key fef81edf9cbf754b0G5C for the S3 user user1 in the domain domain1, run:vinfra service s3 self-service user keys disable --domain domain1 --user user1 --key fef81edf9cbf754b0G5C\n\nTo enable an access key pair for an S3 user\n\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section, click the ellipsis icon next to the disabled key, and then click Enable.\nClick Enable in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys enable [--domain <domain>] [--user <user>] [--key <key>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--key <key>\n\nAccess key ID\n\nFor example, to enable the access key fef81edf9cbf754b0G5C for the S3 user user1 in the domain domain1, run:vinfra service s3 self-service user keys enable --domain domain1 --user user1 --key fef81edf9cbf754b0G5C\n\nTo delete an access key pair for an S3 user\n\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section, click the ellipsis icon next to the disabled key, and then click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys delete [--domain <domain>] [--user <user>] [--access-key <key>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--access-key <key>\n\nAccess key ID\n\nFor example, to delete the access key fef81edf9cbf754b0G5C for the S3 user user1 in the domain domain1, run:# vinfra service s3 self-service user keys delete --domain domain1 --user user1 --access-key fef81edf9cbf754b0G5C\n\nSee also\n\nManaging S3 user quotas\n\nManaging S3 user limits",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys add [--domain <domain>] [--user <user>] [--access-key <key>]\r\n                                             [--secret-key <secret>] [--name <friendly-name>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--access-key <key>\n\nAccess key ID\n--secret-key <secret>\n\nSecret key\n--name <friendly-name>\n\nA friendly name for the key\n\nFor example, to add an access key pair for the S3 user user1 in the domain domain1, run:vinfra service s3 self-service user keys add --domain domain1 --user user1 --name new\nYou can check the user access keys in the vinfra service s3 self-service user show output:# vinfra service s3 self-service user show --domain domain1 --user user1\r\n+---------+----------------------------------------------------------------+\r\n| Field   | Value                                                          |\r\n+---------+----------------------------------------------------------------+\r\n| arn     | arn:aws:iam::dff4158faaa848ac92b7284fc011b72f:fef81edf9cbf754b |\r\n| enabled | True                                                           |\r\n| keys    | - acc_key: fef81edf9cbf754bO22W                                |\r\n|         |   acc_secrete: VgI3Mn4UEuJI4PxhdNJveVe8IouXyFzrCAgtJ0G1        |\r\n|         |   enabled: true                                                |\r\n|         |   name: null                                                   |\r\n|         | - acc_key: fef81edf9cbf754b0G5C                                |\r\n|         |   acc_secrete: ygENV2oBGhaD3qYr5tYqEh4xlFmthvcGWSs6fU3o        |\r\n|         |   enabled: true                                                |\r\n|         |   name: new                                                    |\r\n+---------+----------------------------------------------------------------+\n",
                "title": "To add an access key pair for an S3 user"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys disable [--domain <domain>] [--user <user>] [--key <key>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--key <key>\n\nAccess key ID\n\nFor example, to disable the access key fef81edf9cbf754b0G5C for the S3 user user1 in the domain domain1, run:vinfra service s3 self-service user keys disable --domain domain1 --user user1 --key fef81edf9cbf754b0G5C\n",
                "title": "To disable an access key pair for an S3 user"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys enable [--domain <domain>] [--user <user>] [--key <key>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--key <key>\n\nAccess key ID\n\nFor example, to enable the access key fef81edf9cbf754b0G5C for the S3 user user1 in the domain domain1, run:vinfra service s3 self-service user keys enable --domain domain1 --user user1 --key fef81edf9cbf754b0G5C\n",
                "title": "To enable an access key pair for an S3 user"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 self-service user keys delete [--domain <domain>] [--user <user>] [--access-key <key>]\n\n--domain <domain>\n\nDomain name or ID\n--user <user>\n\nDomain user name or ID\n--access-key <key>\n\nAccess key ID\n\nFor example, to delete the access key fef81edf9cbf754b0G5C for the S3 user user1 in the domain domain1, run:# vinfra service s3 self-service user keys delete --domain domain1 --user user1 --access-key fef81edf9cbf754b0G5C\n",
                "title": "To delete an access key pair for an S3 user"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section and click Create.\nIn the Create S3 access key window, optionally specify a name for the key, and then click Create.\n\n",
                "title": "To add an access key pair for an S3 user"
            },
            {
                "example": "\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section, click the ellipsis icon next to the key, and then click Disable.\nClick Disable in the confirmation window.\n\n",
                "title": "To disable an access key pair for an S3 user"
            },
            {
                "example": "\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section, click the ellipsis icon next to the disabled key, and then click Enable.\nClick Enable in the confirmation window.\n\n",
                "title": "To enable an access key pair for an S3 user"
            },
            {
                "example": "\nAdmin panel\n\n Open the Storage services > S3 > Users screen, and then select a user.\nOn the user right pane, browse the S3 access keys section, click the ellipsis icon next to the disabled key, and then click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete an access key pair for an S3 user"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-s3-access-keys.html"
    },
    {
        "title": "Creating images from volumes",
        "content": "Creating images from volumes\nTo create multiple VMs with the same boot volume, you can create a template from an existing boot volume and deploy VMs from it. \nPrerequisites\n\nLinux virtual machines have cloud-Init installed, as described in Preparing Linux templates.\nWindows virtual machines have Cloudbase-Init and OpenSSH Server installed, as described in Preparing Windows templates.\n\nLogging is enabled inside a virtual machine, as instructed in Enabling logging for virtual machines.\n\nTo create a template from a boot volume\n\nPower off the VM that the original volume is attached to.\nSwitch to the Volumes screen, click volume\u00e2\u0080\u0099s ellipsis button and select Create image.\n\nIn the Create image window, enter an image name, and then click Create.\n\nThe new image will appear on the Images screen.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-images-from-volumes.html"
    },
    {
        "title": "Re-adding unassigned nodes",
        "content": "Re-adding unassigned nodes\nNodes removed from the infrastructure can be re-added as unassigned. If the infrastructure is empty, you need to add the management node first, and then proceed to join more nodes. \nLimitations\n\nIf you cleaned up the node during its release, you need to reinstall Virtuozzo Hybrid Infrastructure on the node from scratch.\n\nPrerequisites\n\nThe node is completely removed from the infrastructure, as described in Removing unassigned nodes.\n\nTo re-add the management node to the infrastructure\nLog in to the node via SSH and run the following script:# /usr/libexec/vstorage-ui-agent/bin/register-storage-node.sh -m <MN_IP_address> -x <public_iface>\nwhere\n\n<MN_IP_address> is the management node's IP address in the internal management network \n<public_iface> is the name of the public network interface connected to the admin panel network\n\nYou can obtain the both parameters by using the command ip a.\n To re-add a node to the infrastructure\nLog in to the node via SSH and run the following script:# /usr/libexec/vstorage-ui-agent/bin/register-storage-node.sh -m <MN_IP_address> -t <token>\r\n\nwhere\n\n<MN_IP_address> is the IP address of the private network interface on the node with the admin panel\n<token> is the token obtained in the admin panel or from the vinfra node token show output\n\nWhat's next\n\nDeploying the storage cluster",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/re-adding-unassigned-nodes.html"
    },
    {
        "title": "Managing virtual machine power state",
        "content": "Managing virtual machine power state\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo manage the power state of a virtual machine\n\nAdmin panel\nClick the virtual machine or the ellipsis button next to it to see the full list of actions available for the current state. \n\nTo power up a VM, click Run.\nTo gracefully shut down a running VM, click Shut down. The default shutdown timeout, after which a virtual machine will be powered off, is 10 minutes. You can configure this timeout per VM by using the vinfra service compute server stop --wait-time command.\nTo forcibly cut off power from a VM, click Power off.\nTo softly reboot a running VM, click Reboot.\nTo reboot a VM without the guest OS graceful shutdown, click Hard reboot.\nTo save the current VM state to a file, click Suspend. This may prove useful, for example, if you need to restart the host but do not want to quit the applications currently running in the VM or restart its guest OS.\nTo restore a VM from the suspended state, click Resume.\n\nCommand-line interface\nUse the following commands:\n\nTo power up a virtual machine:vinfra service compute server start <server>\n\nTo gracefully shut down a running virtual machine:vinfra service compute server stop <server> [--wait-time <seconds>]\r\n\n\n--wait-time <seconds>\n\nShutdown timeout, after which a virtual machine will be powered off. Specify \u00e2\u0080\u0098-1\u00e2\u0080\u0099 to set an infinite timeout. The default shutdown timeout is 10 minutes.\n\nTo forcibly cut off power from a virtual machine:vinfra service compute server stop <server> --hard\r\n\n\nTo softly reboot the running a virtual machine:vinfra service compute server reboot <server>\n\nTo reboot a virtual machine without the guest OS graceful shutdown:vinfra service compute server reboot <server> --hard\r\n\n\nTo save the current state of a virtual machine to a file:vinfra service compute server suspend <server>\nThis may prove useful, for example, if you need to restart the host but do not want to quit the applications currently running in the VM or restart its guest OS.\n\nTo restore a virtual machine from the suspended state:vinfra service compute server resume <server>\n\nTo pause a virtual machine:vinfra service compute server pause <server>\n\nTo continue operation of a virtual machine:vinfra service compute server unpause <server>\n\nSee also\n\nConnecting to virtual machines\n\nReconfiguring virtual machines\n\nMonitoring virtual machines\n\nShelving virtual machines\n\nTroubleshooting virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following commands:\n\n\nTo power up a virtual machine:vinfra service compute server start <server>\n\n\nTo gracefully shut down a running virtual machine:vinfra service compute server stop <server> [--wait-time <seconds>]\r\n\n\n--wait-time <seconds>\n\nShutdown timeout, after which a virtual machine will be powered off. Specify \u00e2\u0080\u0098-1\u00e2\u0080\u0099 to set an infinite timeout. The default shutdown timeout is 10 minutes.\n\n\n\nTo forcibly cut off power from a virtual machine:vinfra service compute server stop <server> --hard\r\n\n\n\nTo softly reboot the running a virtual machine:vinfra service compute server reboot <server>\n\n\nTo reboot a virtual machine without the guest OS graceful shutdown:vinfra service compute server reboot <server> --hard\r\n\n\n\nTo save the current state of a virtual machine to a file:vinfra service compute server suspend <server>\nThis may prove useful, for example, if you need to restart the host but do not want to quit the applications currently running in the VM or restart its guest OS.\n\n\nTo restore a virtual machine from the suspended state:vinfra service compute server resume <server>\n\n\nTo pause a virtual machine:vinfra service compute server pause <server>\n\n\nTo continue operation of a virtual machine:vinfra service compute server unpause <server>\n\n\n",
                "title": "To manage the power state of a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nClick the virtual machine or the ellipsis button next to it to see the full list of actions available for the current state. \n\nTo power up a VM, click Run.\nTo gracefully shut down a running VM, click Shut down. The default shutdown timeout, after which a virtual machine will be powered off, is 10 minutes. You can configure this timeout per VM by using the vinfra service compute server stop --wait-time command.\nTo forcibly cut off power from a VM, click Power off.\nTo softly reboot a running VM, click Reboot.\nTo reboot a VM without the guest OS graceful shutdown, click Hard reboot.\nTo save the current VM state to a file, click Suspend. This may prove useful, for example, if you need to restart the host but do not want to quit the applications currently running in the VM or restart its guest OS.\nTo restore a VM from the suspended state, click Resume.\n\n",
                "title": "To manage the power state of a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-vm-power-state.html"
    },
    {
        "title": "Managing security groups",
        "content": "Managing security groups\nA security group is a set of network access rules that control incoming and outgoing traffic to virtual machines assigned to this group. With security group rules, you can specify the type and direction of traffic that is allowed access to a virtual interface port. Traffic that does not satisfy any rule is dropped.\nFor each project, the default security group is automatically created in the compute cluster. This group allows all traffic on all ports for all protocols and cannot be deleted. When you attach a network interface to a VM, the interface is associated with the default security group, unless you explicitly select a custom security group.\nYou can assign one or more security groups to both new and existing virtual machines. When you add rules to security groups or remove them, the changes are enforced at runtime.\nLimitations\n\nYou can manage only IPv4 security group rules.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-security-groups.html"
    },
    {
        "title": "Querying user quotas via CLI",
        "content": "Querying user quotas via CLI\nYou can display the specific quotas per user with the query-quotas command and the following parameters: -e specifying the email address or -i specifying the user ID:# ostor-s3-admin query-quotas -e user@example.com -V 0100000000000002\r\nversion: '1'\r\nsize: '1024'\r\ntype: 'user'# ostor-s3-admin query-quotas -i fa153230721eed05 -V 0100000000000002\r\nversion: '1'\r\nsize: '1024'\r\ntype: 'user'",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-user-quotas-via-cli.html"
    },
    {
        "title": "Transferring volumes between projects",
        "content": "Transferring volumes between projects\nThere is no direct way to migrate a virtual machine between different projects. However, you can transfer the VM boot volume, and then create a new VM from it. You can transfer both boot and non-boot volumes to projects within different domains.\nLimitations\n\nYou can only transfer volumes with the \"Available\" status.\nTransferring volumes that have snapshots breaks the snapshots.\n\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\nYou have login credentials for the source and destination projects.\nIf you want to transfer a boot volume that is attached to a VM, clone this volume first, as described in Cloning volumes.\nIf you want to transfer a non-boot volume that is attached to a VM, detach it first, as described in Attaching and detaching volumes.\n\nTo transfer a volume between two projects\r\n\r\n\n\nLog in to the source project by changing the environment variables to the project credentials. For example:export OS_PROJECT_DOMAIN_NAME=domain1\r\nexport OS_USER_DOMAIN_NAME=domain1\r\nexport OS_PROJECT_NAME=project1\r\nexport OS_USERNAME=user1\r\nexport OS_PASSWORD=password\n\nList all volumes within your project to find out the ID of the volume you want to transfer:# openstack --insecure volume list\r\n+--------------------------------------+-------------------+-----------+------+\r\n| ID                                   | Name              | Status    | Size |\r\n+--------------------------------------+-------------------+-----------+------+\r\n| 2c8386fa-331b-4ba8-9e4c-de690969a4c8 | win10/Boot volume | available |   64 |\r\n+--------------------------------------+-------------------+-----------+------+\n\nCreate a transfer request by specifying the ID of the chosen volume. For example:# openstack --insecure volume transfer request create c0d4cf0e-48e3-417d-b6fc-f1fb36571c5f\r\n+------------+--------------------------------------+\r\n| Field      | Value                                |\r\n+------------+--------------------------------------+\r\n| auth_key   | 75fcf37d56f40182                     |\r\n| created_at | 2022-04-27T09:00:11.776511           |\r\n| id         | b9b835a3-ed41-489a-9552-483fae33c549 |\r\n| name       | None                                 |\r\n| volume_id  | c0d4cf0e-48e3-417d-b6fc-f1fb36571c5f |\r\n+------------+--------------------------------------+\r\n\nSave the request id and auth-key from the command output, to accept the transfer in the other project.\n\nLog in to the destination project by changing the environment variables to the project credentials. For example:export OS_PROJECT_DOMAIN_NAME=domain1\r\nexport OS_USER_DOMAIN_NAME=domain1\r\nexport OS_PROJECT_NAME=project2\r\nexport OS_USERNAME=user2\r\nexport OS_PASSWORD=password\n\nAccept the transfer request by specifying the request ID and authorization key. For example:# openstack --insecure volume transfer request accept --auth-key 75fcf37d56f40182 \\\r\nb9b835a3-ed41-489a-9552-483fae33c549\n\nOnce the volume is moved to the other project, you can create a virtual machine from it.\nSee also\n\nResizing volumes\n\nChanging the storage policy for volumes\n\nManaging volume snapshots\n\nWhat's next\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/transferring-volumes-between-projects.html"
    },
    {
        "title": "Authentication",
        "content": "Authentication\nEach request to compute API endpoints requires a token that you can obtain by performing password authentication with scoped authorization.\nSend a POST request to https://<node_IP_addr>:5000/v3/auth/tokens, where <node_IP_addr> is the IP address of a compute cluster node.\nIf authorization is successful, the response header will contain the token in the X-Subject-Token header. Pass it in the X-Auth-Token header in all requests.\n\nYou can secure traffic to compute API endpoints as described in \"Securing OpenStack API Traffic with SSL\" in the Administrator Guide. You can also set a DNS name for the endpoints as explained in \"Setting a DNS Name for the Compute API\" in the Administrator Guide.\n\nTo perform administrative actions, authorize in the project admin with the admin\u00e2\u0080\u0099s password.\nSample request:# curl -ksD - -o /dev/null -H 'Content-Type: application/json' -d '\r\n{\r\n  \"auth\": {\r\n    \"identity\": {\r\n      \"methods\": [\r\n        \"password\"\r\n      ],\r\n      \"password\": {\r\n        \"user\": {\r\n          \"name\": \"admin\",\r\n          \"domain\": {\r\n            \"id\": \"default\"\r\n          },\r\n          \"password\": \"admin_password\"\r\n        }\r\n      }\r\n    },\r\n    \"scope\": {\r\n      \"project\": {\r\n        \"name\": \"admin\",\r\n        \"domain\": {\r\n          \"id\": \"default\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n}' https://<node_IP_addr>:5000/v3/auth/tokens\r\n\nSample response:HTTP/1.1 201 CREATED\r\nServer: nginx\r\nDate: Fri, 24 Jan 2020 12:42:01 GMT\r\nContent-Type: application/json\r\nContent-Length: 7947\r\nConnection: keep-alive\r\nX-Subject-Token: gAAAAA<...>\r\nVary: X-Auth-Token\r\nx-openstack-request-id: req-f732464d-62b4-44fd-92fa-ea368efc9a36\r\n\nRegular users added to a project can authorize in that project in a similar way. They will need to specify the ID of the domain that the project is in. An authorized admin can find out which projects are in which domains by sending a GET request to https://<node_IP_addr>:5000/v3/projects (for more details, refer to Listing projects).\nSample request:# curl -ksD - -o /dev/null -H 'Content-Type: application/json' -d '\r\n{\r\n  \"auth\": {\r\n    \"identity\": {\r\n      \"methods\": [\r\n        \"password\"\r\n      ],\r\n      \"password\": {\r\n        \"user\": {\r\n          \"name\": \"user1\",\r\n          \"domain\": {\r\n            \"id\": \"cdc759b962e34e67997f59f8b1c21027\"\r\n          },\r\n          \"password\": \"user1_password\"\r\n        }\r\n      }\r\n    },\r\n    \"scope\": {\r\n      \"project\": {\r\n        \"name\": \"project1\",\r\n        \"domain\": {\r\n          \"id\": \"cdc759b962e34e67997f59f8b1c21027\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n}' https://<node_IP_addr>:5000/v3/auth/tokens\r\n\nSample response:HTTP/1.1 201 CREATED\r\nServer: nginx\r\nDate: Fri, 24 Jan 2020 12:42:01 GMT\r\nContent-Type: application/json\r\nContent-Length: 7947\r\nConnection: keep-alive\r\nX-Subject-Token: gAAAAA<...>\r\nVary: X-Auth-Token\r\nx-openstack-request-id: req-99df744f-4752-4b03-9695-ea6ec4447173\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/authentication.html"
    },
    {
        "title": "Deleting VPN services",
        "content": "Deleting VPN servicesDELETE /v2.0/vpn/vpnservices/{service_id}\nDelete a VPN service.\nIf the service has connections, the request is rejected.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=remove-vpn-service-detail#remove-vpn-service\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nservice_id\n\npath\nstring\nThe ID of the VPN service.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/vpnservices/d6116b75-db78-4d07-9911-226b4655838a\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-vpn-services.html"
    },
    {
        "title": "Object storage configuration",
        "content": "Object storage configuration\nThis section describes how to configure the object storage parameters, such as:\n\nMaximum number of object services\nMaximum size of the object service\nAutomatic split behavior\nMaximum number of concurrent splits\nDefault Cross-origin resource sharing (CORS) behavior",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/object-storage-configuration.html"
    },
    {
        "title": "Managing encryption exceptions",
        "content": "Managing encryption exceptions\nWhen enabling data-in-transit encryption for a network, you can add exceptions for particular IP addresses, prefixes, or ports to bypass the encryption. This is required for external communication of services that operate in the same subnet with cluster nodes.  For example, if you use a custom port, instead of TCP 443,  to connect your backup storage to an external S3 storage, you need to add this port to the encryption exceptions.\nPrerequisites\n\nData-in-transit encryption is enabled for an infrastructure network, as described in Enabling and disabling data-in-transit encryption.\n\nTo add exceptions for data-in-transit encryption\nUse the following command:vinfra cluster network encryption bypass add <subnet> <port>\n\n<subnet>\n\nSubnet range in CIDR notation or a single address\n<port>\n\nPort number\n\nFor example, to bypass encryption for the port 700, run:vinfra cluster network encryption bypass add 0.0.0.0/24 700\nTo list all exceptions for data-in-transit encryption, use the vinfra cluster network encryption bypass list command:# vinfra cluster network encryption bypass list\r\n+------------+------+\r\n| subnet     | port |\r\n+------------+------+\r\n| 0.0.0.0/24 | 700  |\r\n+------------+------+\nTo remove exceptions for data-in-transit encryption\nUse the following command:vinfra cluster network encryption bypass delete <subnet> <port>\n\n<subnet>\n\nSubnet range in CIDR notation or a single address\n<port>\n\nPort number\n\nFor example, to enable encryption for the port 700, run:vinfra cluster network encryption bypass delete 0.0.0.0/24 700\nSee also\n\nRenewing encryption certificates",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-encryption-exceptions.html"
    },
    {
        "title": "Leostream Integration for Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "Leostream Integration for Virtuozzo Hybrid Infrastructure | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nNext\n\nLeostream Integration for Virtuozzo Hybrid Infrastructure\u00c2\u00b6\n\n1. What is Leostream?\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n10. Preparing Master Images\n11. Integrating External Systems\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/index.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Storage-as-a-Service Integration Guide\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nStorage-as-a-Service Integration Guide\n\nHome\n\nContents\n\nIndex\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureStorage-as-a-Service Integration Guide\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/index.html"
    },
    {
        "title": "Creating backup plans",
        "content": "Creating backup plans\nYou can schedule an automatic backup job for multiple volumes by creating a backup plan. A backup plan defines the backup schedule and retention policy that are applied to all backups created by this plan.\nPrerequisites\n\nThe backup service is enabled in the command-line interface, as described in Provisioning the backup service.\n\nTo create a backup plan\n\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click Create backup plan.\n\nIn the Create backup plan window, specify a name for the backup plan and, optionally, a description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nIn What to back up, click Manage. In the Manage volumes window, select compute volumes that will be included in the backup plan, and then click Save.\n\nIn Schedule, select the schedule for the backup plan:\n\nSelect Retention 7 days to create a backup of the selected volumes every day and keep each backup for seven days.\nSelect Retention 14 days to create a backup of the selected volumes every day and keep each backup for 14 days.\nSelect Custom to configure a custom schedule for the automatic backup. You can choose months, days of the week, days of the month, time, and the maximum number of recovery points to keep.\n\nClick Create.\n\nCommand-line interface\n\nCreate a backup plan by using the following command:vinfra service compute backup-plan create [--description <description>] [--schedule-minute <minutes>] [--schedule-hour <hours>]\r\n                                          [--schedule-day <days>] [--schedule-day-of-week <days-of-week>] [--schedule-week <weeks>]\r\n                                          [--schedule-month <months>] [--schedule-interval <interval>] [--schedule-disable]\r\n                                          [--recovery-points-rotation <amount>] [--disabled] [--enabled] <backup-plan-name>\n\n<backup-plan-name>\n\nBackup plan name\n--description <description>\n\nBackup plan description\n--schedule-minute <minutes>\n\nComma-separated list of minutes. Specify '*' to schedule backup every minute.\n--schedule-hour <hours>\n\nComma-separated list of hours. Specify '*' to schedule backup every hour.\n--schedule-day <days>\n\nComma-separated list of days of the month. Specify '*' to schedule backup every day.\n--schedule-day-of-week <days-of-week>\n\nComma-separated list of days of the week. Specify '*' to schedule backup every week day.\n--schedule-week <weeks>\n\nComma-separated list of weeks. Specify '*' to schedule backup every week.\n--schedule-month <months>\n\nComma-separated list of months. Specify '*' to schedule backup every mouth.\n--schedule-interval <interval>\n\nInterval between backups, in hours. You can also specify the following units: h for hours, d for days, and w for weeks. Only one unit can be used at a time.\n--schedule-disable\n\nErase backup schedule.\n--recovery-points-rotation <amount>\n\nAmount of full recovery points to preserve.\n--disabled\n\nDisable backup plan.\n--enabled\n\nEnable backup plan.\n\nFor example, to create the backup plan myplan, schedule it to run every day, and set the maximum recovery points to 5, run:# vinfra service compute backup-plan create myplan --schedule-day '*' --recovery-points-rotation 5\nYou can check the backup plan details in the vinfra service compute backup-plan show output:# vinfra service compute backup-plan show myplan\r\n+-------------+----------------------------------+\r\n| Field       | Value                            |\r\n+-------------+----------------------------------+\r\n| created_at  | 2024-03-13T15:30:27.473014       |\r\n| description |                                  |\r\n| disabled    | False                            |\r\n| domain_id   | default                          |\r\n| ended_at    |                                  |\r\n| id          | bc9b9edc5ae346e1b49614a9cb0c3cdb |\r\n| name        | myplan                           |\r\n| project_id  | 70eff98528054d0b95a8936bfa4aa2a3 |\r\n| properties  | recovery_points_rotation: 5      |\r\n| schedule    | day: '*'                         |\r\n| started_at  |                                  |\r\n| status      | scheduled                        |\r\n| updated_at  | 2024-03-13T15:32:49.648791       |\r\n+-------------+----------------------------------+\n\nFind out the IDs of volumes in your compute cluster by running:# vinfra service compute volume list\r\n+--------------------------------------+------------------------+------+--------+------------------------------------------+\r\n| id                                   | name                   | size | status | os-vol-host-attr:host                    |\r\n+--------------------------------------+------------------------+------+--------+------------------------------------------+\r\n| 5a66c317-a218-4963-9f3e-d8f459e3d343 | vm1/cirros/Boot volume | 1    | in-use | node001.vstoragedomain@vstorage#vstorage |\r\n+--------------------------------------+------------------------+------+--------+------------------------------------------+\n\nAdd volumes that you want to back up to the backup plan by using the following command:vinfra service compute backup-plan volume add <backup-plan> [<backup-plan-volume> ...]\n\n<backup-plan>\n\n        Backup plan ID or name\n<backup-plan-volume>\n\nVolume ID\n\nFor example, to add the volume with the ID 5a66c317-a218-4963-9f3e-d8f459e3d343 to the backup plan myplan, run:# vinfra service compute backup-plan volume add myplan 5a66c317-a218-4963-9f3e-d8f459e3d343\nThe added volume will appear in the vinfra service compute backup-plan volume list output:# vinfra service compute backup-plan volume list myplan\r\n+-------------+------------------------+------+-----------+----------------------------------+---------------------+\r\n| id          | name                   | size | status    | project_id                       | storage_policy_name |\r\n+-------------+------------------------+------+-----------+----------------------------------+---------------------+\r\n| 5a66c317<\u00e2\u0080\u00a6> | vm1/cirros/Boot volume | 1    | in-use    | d0460058ccc04936b81b0653e490a121 | default             |\r\n+-------------+------------------------+------+-----------+----------------------------------+---------------------+\n\nSee also\n\nCreating and deleting backups manually\n\nManaging compute backup quotas\n\nWhat's next\n\nViewing backup plan history\n\nEditing and deleting backup plans\n\nManaging volumes in backup plans\n\nRestoring volumes from backups\n\nRestoring virtual machines from backups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nCreate a backup plan by using the following command:vinfra service compute backup-plan create [--description <description>] [--schedule-minute <minutes>] [--schedule-hour <hours>]\r\n                                          [--schedule-day <days>] [--schedule-day-of-week <days-of-week>] [--schedule-week <weeks>]\r\n                                          [--schedule-month <months>] [--schedule-interval <interval>] [--schedule-disable]\r\n                                          [--recovery-points-rotation <amount>] [--disabled] [--enabled] <backup-plan-name>\n\n<backup-plan-name>\n\nBackup plan name\n--description <description>\n\nBackup plan description\n--schedule-minute <minutes>\n\nComma-separated list of minutes. Specify '*' to schedule backup every minute.\n--schedule-hour <hours>\n\nComma-separated list of hours. Specify '*' to schedule backup every hour.\n--schedule-day <days>\n\nComma-separated list of days of the month. Specify '*' to schedule backup every day.\n--schedule-day-of-week <days-of-week>\n\nComma-separated list of days of the week. Specify '*' to schedule backup every week day.\n--schedule-week <weeks>\n\nComma-separated list of weeks. Specify '*' to schedule backup every week.\n--schedule-month <months>\n\nComma-separated list of months. Specify '*' to schedule backup every mouth.\n--schedule-interval <interval>\n\nInterval between backups, in hours. You can also specify the following units: h for hours, d for days, and w for weeks. Only one unit can be used at a time.\n--schedule-disable\n\nErase backup schedule.\n--recovery-points-rotation <amount>\n\nAmount of full recovery points to preserve.\n--disabled\n\nDisable backup plan.\n--enabled\n\nEnable backup plan.\n\nFor example, to create the backup plan myplan, schedule it to run every day, and set the maximum recovery points to 5, run:# vinfra service compute backup-plan create myplan --schedule-day '*' --recovery-points-rotation 5\nYou can check the backup plan details in the vinfra service compute backup-plan show output:# vinfra service compute backup-plan show myplan\r\n+-------------+----------------------------------+\r\n| Field       | Value                            |\r\n+-------------+----------------------------------+\r\n| created_at  | 2024-03-13T15:30:27.473014       |\r\n| description |                                  |\r\n| disabled    | False                            |\r\n| domain_id   | default                          |\r\n| ended_at    |                                  |\r\n| id          | bc9b9edc5ae346e1b49614a9cb0c3cdb |\r\n| name        | myplan                           |\r\n| project_id  | 70eff98528054d0b95a8936bfa4aa2a3 |\r\n| properties  | recovery_points_rotation: 5      |\r\n| schedule    | day: '*'                         |\r\n| started_at  |                                  |\r\n| status      | scheduled                        |\r\n| updated_at  | 2024-03-13T15:32:49.648791       |\r\n+-------------+----------------------------------+\n\n\nFind out the IDs of volumes in your compute cluster by running:# vinfra service compute volume list\r\n+--------------------------------------+------------------------+------+--------+------------------------------------------+\r\n| id                                   | name                   | size | status | os-vol-host-attr:host                    |\r\n+--------------------------------------+------------------------+------+--------+------------------------------------------+\r\n| 5a66c317-a218-4963-9f3e-d8f459e3d343 | vm1/cirros/Boot volume | 1    | in-use | node001.vstoragedomain@vstorage#vstorage |\r\n+--------------------------------------+------------------------+------+--------+------------------------------------------+\n\n\nAdd volumes that you want to back up to the backup plan by using the following command:vinfra service compute backup-plan volume add <backup-plan> [<backup-plan-volume> ...]\n\n<backup-plan>\n\n        Backup plan ID or name\n<backup-plan-volume>\n\nVolume ID\n\nFor example, to add the volume with the ID 5a66c317-a218-4963-9f3e-d8f459e3d343 to the backup plan myplan, run:# vinfra service compute backup-plan volume add myplan 5a66c317-a218-4963-9f3e-d8f459e3d343\nThe added volume will appear in the vinfra service compute backup-plan volume list output:# vinfra service compute backup-plan volume list myplan\r\n+-------------+------------------------+------+-----------+----------------------------------+---------------------+\r\n| id          | name                   | size | status    | project_id                       | storage_policy_name |\r\n+-------------+------------------------+------+-----------+----------------------------------+---------------------+\r\n| 5a66c317<\u00e2\u0080\u00a6> | vm1/cirros/Boot volume | 1    | in-use    | d0460058ccc04936b81b0653e490a121 | default             |\r\n+-------------+------------------------+------+-----------+----------------------------------+---------------------+\n\n\n",
                "title": "To create a backup plan"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click Create backup plan.\n\nIn the Create backup plan window, specify a name for the backup plan and, optionally, a description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\nIn What to back up, click Manage. In the Manage volumes window, select compute volumes that will be included in the backup plan, and then click Save.\n\nIn Schedule, select the schedule for the backup plan:\n\nSelect Retention 7 days to create a backup of the selected volumes every day and keep each backup for seven days.\nSelect Retention 14 days to create a backup of the selected volumes every day and keep each backup for 14 days.\nSelect Custom to configure a custom schedule for the automatic backup. You can choose months, days of the week, days of the month, time, and the maximum number of recovery points to keep.\n\n\n\n\n\n\nClick Create.\n\n",
                "title": "To create a backup plan"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-backup-plans.html"
    },
    {
        "title": "Managing custom traffic types",
        "content": "Managing custom traffic types\nYou can create custom traffic types, add them to multiple networks, edit, and delete.\nLimitations\n\nIf you create allow rules but leave the deny list empty, all incoming traffic will still be allowed.\nYou cannot change the name of a traffic type, if it is assigned to any network.\n\nTo create a custom traffic type\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Create traffic type.\nIn the Create traffic type window, specify a traffic type name and port to open. Traffic type names must be alphanumeric and 3 to 32 characters long.\n\nIn the Access rules section, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra cluster traffic-type create --port <port> [--inbound-allow-list <addresses>]\r\n                                   [--inbound-deny-list <addresses>] <traffic-type-name>\r\n\n\n--port <port>\n\nTraffic type port\n--inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses\n<traffic-type-name>\n\nTraffic type name\n\nFor example, to create a custom traffic type MyTrafficType on port 6900, run:# vinfra cluster traffic-type create \"MyTrafficType\" --port 6900\r\n+--------------------+---------------+\r\n| Field              | Value         |\r\n+--------------------+---------------+\r\n| exclusive          | False         |\r\n| hidden             | False         |\r\n| inbound_allow_list | []            |\r\n| inbound_deny_list  | []            |\r\n| name               | MyTrafficType |\r\n| port               | 6900          |\r\n| type               | custom        |\r\n+--------------------+---------------+\r\n\nThe created traffic type will appear in the vinfra cluster traffic-type list output:# vinfra cluster traffic-type list -c name -c type -c exclusive -c port\r\n+-----------------------+------------+-----------+------+\r\n| name                  | type       | exclusive | port |\r\n+-----------------------+------------+-----------+------+\r\n| Storage               | predefined | True      |      |\r\n| Internal management   | predefined | True      |      |\r\n| OSTOR private         | predefined | True      |      |\r\n| S3 public             | predefined | False     |      |\r\n| iSCSI                 | predefined | False     |      |\r\n| NFS                   | predefined | False     |      |\r\n| Backup (ABGW) private | predefined | True      |      |\r\n| Backup (ABGW) public  | predefined | False     |      |\r\n| Admin panel           | predefined | False     |      |\r\n| SSH                   | predefined | False     |      |\r\n| VM public             | predefined | False     |      |\r\n| VM private            | predefined | True      |      |\r\n| Compute API           | predefined | True      |      |\r\n| MyTrafficType         | custom     | False     | 6900 |\r\n+-----------------------+------------+-----------+------+\r\n\n\nTo assign, reassign, or unassign a custom traffic type\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Assign to networks next to the Custom traffic types section.\nAdd the needed traffic type to or remove it from your networks by selecting the corresponding check boxes.\nClick Save to apply the changes.\n\nCommand-line interface\nUse the following command:vinfra cluster network set [--traffic-types <traffic-types> | --add-traffic-types <traffic-types> |\r\n                           --del-traffic-types <traffic-types>] <network>\r\n\n\n--traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (overwrites network\u00e2\u0080\u0099s current traffic types)\n--add-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (adds the specified traffic types to the network)\n--del-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (removes the specified traffic types from the network)\n<network>\n\nNetwork ID or name\n\nFor example, to add the traffic type MyTrafficType to the MyNet network, run:# vinfra cluster network set MyNet --add-traffic-types \"MyTrafficType\"\n\nTo edit  a custom traffic type\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the ellipsis icon next to the traffic type name, and select Edit.\nIn the Edit traffic type window, change the traffic type name or port, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra cluster traffic-type set [--name <name>] [--port <port>] <traffic-type>\r\n\n\n--name <name>\n\nA new name for the traffic type\n--port <port>\n\nA new port for the traffic type\n<traffic-type>\n\nTraffic type name\n\nFor example, to rename the traffic type MyTrafficType to MyOtherTrafficType and change its port to 6901, run:# vinfra cluster traffic-type set \"MyTrafficType\" --name \"MyOtherTrafficType\" --port 6901\n\nTo delete a custom traffic type\n\nAdmin panel\n\nMake sure it is excluded from all networks.\nOn the Infrastructure > Networks screen, click the ellipsis icon next to the traffic type, and then select Delete.\nIn the Delete traffic type window, confirm your action by clicking Delete.\n\nCommand-line interface\nUse the following command:vinfra cluster traffic-type delete <traffic-type>\r\n\n\n<traffic-type>\n\nTraffic type name\n\nFor example, to delete the custom traffic type MyOtherTrafficType, run:# vinfra cluster traffic-type delete \"MyOtherTrafficType\"\n\nSee also\n\nManaging exclusive traffic types\n\nManaging regular traffic types\n\nConfiguring inbound firewall rules\n\nManaging networks",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster traffic-type create --port <port> [--inbound-allow-list <addresses>]\r\n                                   [--inbound-deny-list <addresses>] <traffic-type-name>\r\n\n\n--port <port>\n\nTraffic type port\n--inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses\n<traffic-type-name>\n\nTraffic type name\n\nFor example, to create a custom traffic type MyTrafficType on port 6900, run:# vinfra cluster traffic-type create \"MyTrafficType\" --port 6900\r\n+--------------------+---------------+\r\n| Field              | Value         |\r\n+--------------------+---------------+\r\n| exclusive          | False         |\r\n| hidden             | False         |\r\n| inbound_allow_list | []            |\r\n| inbound_deny_list  | []            |\r\n| name               | MyTrafficType |\r\n| port               | 6900          |\r\n| type               | custom        |\r\n+--------------------+---------------+\r\n\nThe created traffic type will appear in the vinfra cluster traffic-type list output:# vinfra cluster traffic-type list -c name -c type -c exclusive -c port\r\n+-----------------------+------------+-----------+------+\r\n| name                  | type       | exclusive | port |\r\n+-----------------------+------------+-----------+------+\r\n| Storage               | predefined | True      |      |\r\n| Internal management   | predefined | True      |      |\r\n| OSTOR private         | predefined | True      |      |\r\n| S3 public             | predefined | False     |      |\r\n| iSCSI                 | predefined | False     |      |\r\n| NFS                   | predefined | False     |      |\r\n| Backup (ABGW) private | predefined | True      |      |\r\n| Backup (ABGW) public  | predefined | False     |      |\r\n| Admin panel           | predefined | False     |      |\r\n| SSH                   | predefined | False     |      |\r\n| VM public             | predefined | False     |      |\r\n| VM private            | predefined | True      |      |\r\n| Compute API           | predefined | True      |      |\r\n| MyTrafficType         | custom     | False     | 6900 |\r\n+-----------------------+------------+-----------+------+\r\n\n",
                "title": "To create a custom traffic type"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network set [--traffic-types <traffic-types> | --add-traffic-types <traffic-types> |\r\n                           --del-traffic-types <traffic-types>] <network>\r\n\n\n--traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (overwrites network\u00e2\u0080\u0099s current traffic types)\n--add-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (adds the specified traffic types to the network)\n--del-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (removes the specified traffic types from the network)\n<network>\n\nNetwork ID or name\n\nFor example, to add the traffic type MyTrafficType to the MyNet network, run:# vinfra cluster network set MyNet --add-traffic-types \"MyTrafficType\"\n",
                "title": "To assign, reassign, or unassign a custom traffic type"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster traffic-type set [--name <name>] [--port <port>] <traffic-type>\r\n\n\n--name <name>\n\nA new name for the traffic type\n--port <port>\n\nA new port for the traffic type\n<traffic-type>\n\nTraffic type name\n\nFor example, to rename the traffic type MyTrafficType to MyOtherTrafficType and change its port to 6901, run:# vinfra cluster traffic-type set \"MyTrafficType\" --name \"MyOtherTrafficType\" --port 6901\n",
                "title": "To edit  a custom traffic type"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster traffic-type delete <traffic-type>\r\n\n\n<traffic-type>\n\nTraffic type name\n\nFor example, to delete the custom traffic type MyOtherTrafficType, run:# vinfra cluster traffic-type delete \"MyOtherTrafficType\"\n",
                "title": "To delete a custom traffic type"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Create traffic type.\nIn the Create traffic type window, specify a traffic type name and port to open. Traffic type names must be alphanumeric and 3 to 32 characters long.\n\nIn the Access rules section, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\n\n\n\n\n\nClick Create.\n\n",
                "title": "To create a custom traffic type"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Assign to networks next to the Custom traffic types section.\nAdd the needed traffic type to or remove it from your networks by selecting the corresponding check boxes.\nClick Save to apply the changes.\n\n",
                "title": "To assign, reassign, or unassign a custom traffic type"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the ellipsis icon next to the traffic type name, and select Edit.\nIn the Edit traffic type window, change the traffic type name or port, and then click Save.\n\n",
                "title": "To edit  a custom traffic type"
            },
            {
                "example": "\nAdmin panel\n\nMake sure it is excluded from all networks.\nOn the Infrastructure > Networks screen, click the ellipsis icon next to the traffic type, and then select Delete.\nIn the Delete traffic type window, confirm your action by clicking Delete.\n\n",
                "title": "To delete a custom traffic type"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-custom-traffic-types.html"
    },
    {
        "title": "Supported Amazon request headers",
        "content": "Supported Amazon request headers\nThe following Amazon S3 REST request headers are currently supported by the Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol:\n\nAuthorization\n\nThe information required for request authentication. For anonymous requests this header is not required.\nContent-Length\n\nLength of the message (without the headers) according to RFC 2616.\nContent-Type\n\nThe content type of the resource in case the request has content in the body.\nContent-MD5\n\nThe base64 encoded 128-bit MD5 digest of the message (without the headers) according to RFC 1864.\nDate\n\nThe date that can be used to create the signature contained in the Authorization header. If the Date header is to be used for signing it must be specified in the ISO 8601 basic YYYYMMDD'T'HHMMSS'Z' format.\nHost\n\nFor path-style requests, the value is s3.amazonaws.com. For virtual-style requests, the value is BucketName.s3.amazonaws.com.\nRange\n\nRetrieves a byte range of the object.\nx-amz-content-sha256\n\nWhen using signature version 4 to authenticate request, this header provides a hash of the request payload.\nx-amz-date\n\nThe date used to create the signature in the Authorization header (alternative to Date). The format must be ISO 8601 basic in the YYYYMMDD'T'HHMMSS'Z' format.\nx-amz-range\n\nRetrieves a range of the object (alternative to Range).\nx-amz-object-lock-retain-until-date\n\nThe date and time when you want the object lock to expire.\nx-amz-object-lock-mode\n\nThe object lock mode that you want to apply to an object.\nx-amz-bucket-object-lock-enabled\n\nSpecifies whether you want S3 object lock to be enabled for a new bucket.\nx-amz-object-lock-legal-hold\n\nSpecifies whether a legal hold will be applied to an object.\nx-amz-bypass-governance-retention\n\nIndicates whether an action should bypass governance-mode restrictions.\nx-amz-acl\n\nThe canned ACL to apply to the object.\nx-amz-meta-<name>\n\nUser-defined metadata, where <name> is the key.\nx-amz-storage-class\n\nThe storage class to use for storing the object. For example: STANDARD, type_1, type_2, type_3.\nIf-Match\n\nReturns the object only if its ETag matches the specified value.\nIf-None-Match\n\nReturns the object only if its ETag does not match the specified value.\nIf-Modified-Since\n\nReturns the object only if it has been modified since the specified time.\nIf-Unmodified-Since\n\nReturns the object only if it has not been modified since the specified time.\nx-amz-copy-source\n\nThe source object for a copy operation.\nx-amz-copy-source-range\n\nThe range of the source object for a copy operation.\nx-amz-copy-source-if-match\n\nCopies the object if its ETag matches the specified value.\nx-amz-copy-source-if-none-match\n\nCopies the object if its ETag does not match the specified value.\nx-amz-copy-source-if-modified-since\n\nCopies the object if it has been modified since the specified time.\nx-amz-copy-source-if-unmodified-since\n\nCopies the object if it has not been modified since the specified time.\n\nThe following Amazon S3 REST request headers are ignored:\n\nExpect\n\nWhen an application uses 100-continue, it does not send the request body until it receives an acknowledgment. If the message is rejected based on the headers, the body of the message is not sent. This header can be used only if you are sending a body.\nx-amz-security-token\n\nThis header is required for requests that use Amazon DevPay and requests that are signed by using temporary security credentials.\n\nFor more information about Amazon S3 REST error response headers, refer to the Amazon S3 REST API documentation.\n\nSee also\n\nSupported Amazon S3 REST operations\n\nSupported Amazon response headers\n\nSupported Amazon error response headers\n\nSupported authentication schemes\n\nAmazon S3 features supported by bucket policies\n\nSupported Amazon S3 object expiration actions",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-request-headers.html"
    },
    {
        "title": "Listing projects",
        "content": "Listing projectsGET /v3/projects\r\n\nList projects.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=list-projects-detail#list-projects\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nname (Optional)\nquery\nstring\nFilters the response by a project name.\n\nis_domain (Optional)\nquery\nboolean\n\nIf this is specified as true, then only projects acting as a domain are\r\nincluded. Otherwise, only projects that are not acting as a domain are\r\nincluded.\nNew in version 3.6\n\ndomain_id (Optional)\nquery\nstring\nFilters the response by a domain ID.\n\nenabled (Optional)\nquery\nboolean\nIf set to true, then only enabled projects will be returned. Any value\r\nother than 0 (including no value) will be interpreted as true.\n\nparent_id (Optional)\nquery\nstring\n\nFilters the response by a parent ID.\nNew in version 3.4\n\nExample\nList projects in the domain with the specified ID.# curl -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/projects?domain_id=f2eeaaf15c254d4fa10255796122c8ec\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nprojects\n\nbody\narray\nA list of project objects.\n\nname\n\nbody\nstring\nThe unique name of the project within the\r\nowning domain.\n\nis_domain\n\nbody\nboolean\n\nIndicates whether the project also acts as a domain. If set to true,\r\nthis project acts as both a project and domain. As a domain, the project\r\nprovides a name space in which you can create users, groups, and other\r\nprojects. If set to false, this project behaves as a regular project\r\nthat contains only resources.\nNew in version 3.6\n\ndescription\n\nbody\nstring\nThe description of the project.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain for the project.\n\nenabled\n\nbody\nboolean\nIf set to true, project is enabled. If set to\r\nfalse, project is disabled.\n\nid\n\nbody\nstring\nThe ID for the project.\n\nlinks\n\nbody\nobject\nThe link to the project resource.\n\nparent_id\n\nbody\nstring\n\nThe ID of the parent for the project.\nNew in version 3.4\n\ntags\n\nbody\narray\nA list of simple strings assigned to a project.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"links\": {\r\n    \"self\": \"https://<node_IP_addr>:5000/v3/projects?domain_id=f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"previous\": null,\r\n    \"next\": null\r\n  },\r\n  \"projects\": [\r\n    {\r\n      \"is_domain\": false,\r\n      \"description\": \"\",\r\n      \"links\": {\r\n        \"self\": \"https://<node_IP_addr>:5000/v3/projects/ec35eb7ceb594ad696839fc867817e4c\"\r\n      },\r\n      \"tags\": [],\r\n      \"enabled\": true,\r\n      \"id\": \"ec35eb7ceb594ad696839fc867817e4c\",\r\n      \"parent_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n      \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n      \"name\": \"project1\"\r\n    },\r\n    {\r\n      \"is_domain\": false,\r\n      \"description\": \"\",\r\n      \"links\": {\r\n        \"self\": \"https://<node_IP_addr>:5000/v3/projects/03013ec787054e78ae26806636ad18d9\"\r\n      },\r\n      \"tags\": [],\r\n      \"enabled\": true,\r\n      \"id\": \"03013ec787054e78ae26806636ad18d9\",\r\n      \"parent_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n      \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n      \"name\": \"project2\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-projects.html"
    },
    {
        "title": "Using volume QoS policies",
        "content": "Using volume QoS policies\nYou can use capacity-based quality of service (QoS) policies  to define dynamic limits of compute volumes. Per-GB QoS policies allow you to manually configure IOPS and bandwidth for volumes depending on their size. For example, with the limits 5 IOPS/GB and 1MB/sec per GB, a 100-GB volume will have the performance parameters of 500 IOPS and 100 MB/s, while a 1-TB volume will have as much as 5000 IOPS and 1000 MB/s. After you extend a volume with per-GB limits, its performance will automatically increase corresponding to its size.\nFor dynamic IOPS and bandwidth configuration, you can limit the following volume parameters:\n\nNumber of read operations per second per GB\nNumber of write operations per second per GB\nTotal number of read and write operations per second per GB\nNumber of bytes read per second per GB\nNumber of bytes written per second per GB\nTotal number of bytes read and written per second per GB\n\nAdditionally, you can control the minimum IOPS and bandwidth values, to guarantee high performance to small volumes.\nPer-GB QoS policies can be set to compute volumes by means of storage policies. You can either create a new storage policy with per-GB limits or add such limits to an existing storage policy.\nLimitations\n\nPer-GB limits are not applied to existing volumes on the fly. To apply them to an existing volume, restart the VM that this volume is attached to.\nYou can limit either total IOPS/bandwidth or read and write IOPS/bandwidth per QoS policy. For example, you cannot set the total-bytes-sec-per-gb parameter together with the write-bytes-sec-per-gb or read-bytes-sec-per-gb parameter.\n\nTo create a per-GB QoS policy\nUse the following command:vinfra service compute storage-policy create --tier {0,1,2,3} (--replicas <norm> | --encoding <M>+<N>)\r\n                                             --failure-domain {0,1,2,3,4}\r\n                                             [--write-bytes-sec-per-gb <limit>] [--write-bytes-sec-per-gb-min <limit>]\r\n                                             [--read-bytes-sec-per-gb <limit>] [--read-bytes-sec-per-gb-min <limit>]\r\n                                             [--write-iops-sec-per-gb <limit>] [--write-iops-sec-per-gb-min <limit>]\r\n                                             [--read-iops-sec-per-gb <limit>] [--read-iops-sec-per-gb-min <limit>]\r\n                                             [--total-bytes-sec-per-gb <limit>] [--total-bytes-sec-per-gb-min <limit>]\r\n                                             [--total-iops-sec-per-gb <limit>] [--total-iops-sec-per-gb-min <limit>]\r\n                                             <name>\r\n\n\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--replicas <norm>[:<min>]\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\nmin: minimum required number of replicas (optional)\n\n--write-bytes-sec-per-gb <limit>\n\nNumber of bytes written per second per GB\n--write-bytes-sec-per-gb-min <limit>\n\nMinimum number of bytes written per second per GB\n--read-bytes-sec-per-gb <limit>\n\nNumber of bytes read per second per GB\n--read-bytes-sec-per-gb-min <limit>\n\nMinimum number of bytes read per second per GB\n--write-iops-sec-per-gb <limit>\n\nNumber of write operations per second per GB\n--write-iops-sec-per-gb-min <limit>\n\nMinimum number of write operations per second per GB\n--read-iops-sec-per-gb <limit>\n\nNumber of read operations per second per GB\n--read-iops-sec-per-gb-min <limit>\n\nMinimum number of read operations per second per GB\n--total-bytes-sec-per-gb <limit>\n\nTotal number of bytes read and written per second per GB\n--total-bytes-sec-per-gb-min <limit>\n\nMinimum number of bytes read and written per second per GB\n--total-iops-sec-per-gb <limit>\n\nTotal number of read and write operations per second per GB\n--total-iops-sec-per-gb-min <limit>\n\nMinimum number of read and write operations per second per GB\n<name>\n\nStorage policy name\n\nFor example, to create a storage policy myqospolicy with the limit of 100 read and write operations per second per GB and the minimum of 50 read and write operations per second per GB, run:# vinfra service compute storage-policy create myqospolicy --tier 1 --failure-domain 1 --replicas 3 \\\r\n--total-iops-sec-per-gb 100 --total-iops-sec-per-gb-min 50\nTo add per-GB limits to an existing policy\nUse the command vinfra service compute storage-policy set and specify the required value for a parameter that you want to limit. For example, to add the bandwidth limit of 104857600 bytes read and written per second per GB to the storage policy myqospolicy, run:# vinfra service compute storage-policy set myqospolicy --total-bytes-sec-per-gb 104857600\nTo remove per-GB limits from an existing policy\nUse the command vinfra service compute storage-policy set and specify -1 as a value for a parameter that you want to be unlimited. For example, to make unlimited bandwidth for the storage policy myqospolicy, run:# vinfra service compute storage-policy set myqospolicy --total-bytes-sec-per-gb -1\nSee also\n\nManaging storage policies\n\nManaging compute volumes\n\nManaging external storages",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-volume-qos-policies.html"
    },
    {
        "title": "Adding nodes to object storage",
        "content": "Adding nodes to object storage\nYou can add more S3 nodes   for high availability and scalability of your object storage.\nPrerequisites\n\nThe S3 cluster is created, as described in Creating the S3 cluster.\n\nTo add nodes to the S3 cluster\n\nAdmin panel\n\nGo to the Storage services > S3 > Nodes screen.\nClick Add node.\nSelect nodes to join the S3 cluster, and then click Add. \n\nThe nodes will be added to your object storage.\n\nCommand-line interface\nUse the following command:vinfra service s3 node add --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n\nFor example, to add the node with the ID 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb to the S3 storage, run:# vinfra service s3 node add --nodes 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb\nThe added node will appear in the vinfra service s3 show output:# vinfra service s3 show\r\n+----------------+--------------------------------------------+\r\n| Field          | Value                                      |\r\n+----------------+--------------------------------------------+\r\n| failure_domain | 1                                          |\r\n| id             | 0100000000000002                           |\r\n| name           | cluster1                                   |\r\n| nodes          | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n|                | - id: 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb |\r\n| np             |                                            |\r\n| nusers         | 0                                          |\r\n| protocol       | scheme: https                              |\r\n| redundancy     | m: 1                                       |\r\n|                | n: 2                                       |\r\n|                | type: raid6                                |\r\n| s3gw_domain    | dns.example.com                            |\r\n| tier           | 0                                          |\r\n+----------------+--------------------------------------------+\n\nSee also\n\nChanging the redundancy scheme for S3 data\n\nChanging the storage tier for S3 metadata\n\nReplicating S3 data between datacenters\n\nReleasing nodes from object storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 node add --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n\nFor example, to add the node with the ID 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb to the S3 storage, run:# vinfra service s3 node add --nodes 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb\nThe added node will appear in the vinfra service s3 show output:# vinfra service s3 show\r\n+----------------+--------------------------------------------+\r\n| Field          | Value                                      |\r\n+----------------+--------------------------------------------+\r\n| failure_domain | 1                                          |\r\n| id             | 0100000000000002                           |\r\n| name           | cluster1                                   |\r\n| nodes          | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n|                | - id: 2f3f6091-0d44-45aa-94e3-ebc2b65c0eeb |\r\n| np             |                                            |\r\n| nusers         | 0                                          |\r\n| protocol       | scheme: https                              |\r\n| redundancy     | m: 1                                       |\r\n|                | n: 2                                       |\r\n|                | type: raid6                                |\r\n| s3gw_domain    | dns.example.com                            |\r\n| tier           | 0                                          |\r\n+----------------+--------------------------------------------+\n",
                "title": "To add nodes to the S3 cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > S3 > Nodes screen.\nClick Add node.\nSelect nodes to join the S3 cluster, and then click Add. \n\nThe nodes will be added to your object storage.\n",
                "title": "To add nodes to the S3 cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-s3-nodes.html"
    },
    {
        "title": "Deleting virtual machines",
        "content": "Deleting virtual machines\nLimitations\n\nA VM is removed along with its disks that have the Delete on termination option enabled during the VM deployment.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo remove one virtual machine\n\nClick the ellipsis button next to a VM you want to delete, and then click Delete.\nClick Delete in the confirmation window.\n\nTo remove multiple virtual machines\n\nSelect the check boxes next to VMs you want to delete.\nOver the VM list, click Delete.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/deleting-virtual-machines.html"
    },
    {
        "title": "Managing compute networks",
        "content": "Managing compute networks\nVirtuozzo Hybrid Infrastructure provides secure and isolated virtual networking for virtual machines using VXLAN encapsulation. The distributed virtual switching and routing simplify VM network configuration, and the built-in firewall makes it more secure. The integrated DHCP, IP, and DNS management provides for enhanced configuration of the network.\nIn the compute cluster, you can create and manage two types of networks:\n\nVirtual networks are VXLAN-based overlay networks that can be used for intercommunication between virtual machines (VMs). Each virtual network is isolated from other virtual networks, as well as physical networks. Virtual networks support only IPv4 address management.\nPhysical networks use IP address ranges of public infrastructure networks. Such networks can be used to provide Internet access to VMs. Physical networks support both IPv4 and IPv6 address management.\n\nLimitations\n\nWhen you create load balancers or Kubernetes clusters with highly available master nodes, the lb-mgmt-net virtual network appears in the compute cluster. This network is used by the system for load balancing. It is marked with the System tag and cannot be modified or deleted.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-compute-networks.html"
    },
    {
        "title": "Integration via REST API",
        "content": "Integration via REST API\nThis chapter explains ways to provision, enable, disable, and terminate S3 users and accounts, as well as set user and bucket limits for billing purposes.\nThe provided examples are Bash commands with which you can send requests to S3 cluster\u00e2\u0080\u0099s REST API via cURL and OpenSSL. Responses are in JSON format and can be processed further with tools like json_pp or json_reformat.\n\r\n                Replace http://s3.example.com in examples with your actual S3 gateway URL.\r\n            ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/integration-via-rest-api.html"
    },
    {
        "title": "Creating users in a domain",
        "content": "Creating users in a domainPOST /v3/users\r\n\nCreate a user in the domain with the specified ID.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=create-user-detail#create-user\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nuser\n\nbody\nobject\nA user object.\n\ndefault_project_id (Optional)\nbody\nstring\n\nThe ID of the default project for the user.\nA user\u00e2\u0080\u0099s default project must not be a domain. Setting this\r\nattribute does not grant any actual authorization on the project,\r\nand is merely provided for convenience. Therefore, the referenced\r\nproject does not need to exist within the user domain.  (Since v3.1)\r\nIf the user does not have authorization to their default project,\r\nthe default project is ignored at token creation.  (Since v3.1)\r\nAdditionally, if your default project is not valid, a token is\r\nissued without an explicit scope of authorization.\n\ndomain_id (Optional)\nbody\nstring\nThe ID of the domain of the user. If the domain ID is not\r\nprovided in the request, the Identity service will attempt to\r\npull the domain ID from the token used in the request. Note that\r\nthis requires the use of a domain-scoped token.\n\nenabled (Optional)\nbody\nboolean\nIf the user is enabled, this value is true.\r\nIf the user is disabled, this value is false.\n\npassword (Optional)\nbody\nstring\nThe password for the user.\n\nextra (Optional)\nbody\nstring\nThe extra attributes of a resource.\r\nThe actual name extra is not the key name in the request body,\r\nbut rather a collection of any attributes that a resource may contain\r\nthat are not part of the resource\u00e2\u0080\u0099s default attributes.\r\nGenerally these are custom fields that are added to a resource in keystone\r\nby operators for their own specific uses,\r\nsuch as email and description for users.\n\noptions (Optional)\nbody\nobject\nThe resource options for the user. Available resource options are\r\nignore_change_password_upon_first_use, ignore_password_expiry,\r\nignore_lockout_failure_attempts, lock_password,\r\nmulti_factor_auth_enabled, and multi_factor_auth_rulesignore_user_inactivity.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\n-d '{\r\n    \"user\": {\r\n        \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n        \"enabled\": true,\r\n        \"name\": \"user1\",\r\n        \"password\": \"passwd\",\r\n        \"description\": \"A new user\",\r\n        \"email\": \"user1@example.com\"\r\n    }\r\n}' https://<node_IP_addr>:5000/v3/users\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nuser\n\nbody\nobject\nA user object.\n\ndefault_project_id (Optional)\nbody\nstring\n\nThe ID of the default project for the user.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain.\n\nenabled\n\nbody\nboolean\nIf the user is enabled, this value is true.\r\nIf the user is disabled, this value is false.\n\nid\n\nbody\nstring\nThe user ID.\n\nlinks\n\nbody\nobject\nThe links for the user resource.\n\nname\n\nbody\nstring\nThe user name. Must be unique within the owning domain.\n\npassword_expires_at\n\nbody\nstring\n\nThe date and time when the password expires. The time zone\r\nis UTC.\nThis is a response object attribute; not valid for requests.\r\nA null value indicates that the password never expires.\nNew in version 3.7\n\noptions\n\nbody\nobject\nThe resource options for the user. Available resource options are\r\nignore_change_password_upon_first_use, ignore_password_expiry,\r\nignore_lockout_failure_attempts, lock_password,\r\nmulti_factor_auth_enabled, and multi_factor_auth_rulesignore_user_inactivity.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n    \"user\": {\r\n        \"name\": \"user1\",\r\n        \"links\": {\r\n            \"self\": \"https://<node_IP_addr>:5000/v3/users/8615e3ece62c44ffa9174c809664bd68\"\r\n        },\r\n        \"description\": \"A new user\",\r\n        \"enabled\": true,\r\n        \"email\": \"user1@example.com\",\r\n        \"options\": {},\r\n        \"id\": \"8615e3ece62c44ffa9174c809664bd68\",\r\n        \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n        \"password_expires_at\": null\r\n    }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-users-in-a-domain.html"
    },
    {
        "title": "Listing virtual machines",
        "content": "Listing virtual machinesGET /servers\r\n\nList virtual machines.\nBy default the servers are filtered using the project ID associated\r\nwith the authenticated request.\nServers contain a status attribute that indicates the current server\r\nstate. You can filter on the server status when you complete a list\r\nservers request. The server status is returned in the response\r\nbody. The possible server status values are:\n\nACTIVE: The server is active.\nBUILD: The server has not finished the original build process.\nDELETED: The server is permanently deleted.\nERROR: The server is in error.\nHARD_REBOOT: The server is hard rebooting. This is equivalent to\r\npulling the power plug on a physical server, plugging it back in,\r\nand rebooting it.\nMIGRATING: The server is being migrated to a new host.\nPASSWORD: The password is being reset on the server.\nPAUSED: In a paused state, the state of the server is stored in\r\nRAM. A paused server continues to run in frozen state.\nREBOOT: The server is in a soft reboot state. A reboot command\r\nwas passed to the operating system.\nREBUILD: The server is currently being rebuilt from an image.\nRESCUE: The server is in rescue mode. A rescue image is running\r\nwith the original server image attached.\nRESIZE: Server is performing the differential copy of data that\r\nchanged during its initial copy. Server is down for this stage.\nREVERT_RESIZE: The resize or migration of a server failed for\r\nsome reason. The destination server is being cleaned up and the\r\noriginal source server is restarting.\nSHELVED: The server is in shelved state. Depending on the shelve offload\r\ntime, the server will be automatically shelved offloaded.\nSHELVED_OFFLOADED: The shelved server is offloaded (removed from the\r\ncompute host) and it needs unshelved action to be used again.\nSHUTOFF: The server is powered off and the disk image still\r\npersists.\nSOFT_DELETED: The server is marked as deleted but the disk\r\nimages are still available to restore.\nSUSPENDED: The server is suspended, either by request or\r\nnecessity. When you suspend a server, its state is stored\r\non disk, all memory is written to disk, and the server is stopped.\r\nSuspending a server is similar to placing a device in hibernation and its\r\noccupied resource will not be freed but rather kept for when the server is\r\nresumed. If a server is infrequently used and the occupied resource needs\r\nto be freed to create other servers, it should be shelved.\nUNKNOWN: The state of the server is unknown. Contact your cloud\r\nprovider.\nVERIFY_RESIZE: System is awaiting confirmation that the server\r\nis operational after a move or resize.\n\nThere is an allowlist for valid filter keys. Any filter key other than from\r\nthe allowlist will be silently ignored.\n\nFor non-admin users, the allowlist is different from admin users' allowlist.\r\nThe valid allowlist can be configured by using the\r\nos_compute_api:servers:allow_all_filters policy rule. By default,\r\nthe valid allowlist for non-admin users includes:changes-sinceflavorimageipip6 (New in version 2.5)namenot-tags (New in version 2.26)not-tags-any (New in version 2.26)reservation_idstatustags (New in version 2.26)tags-any (New in version 2.26)changes-before (New in version 2.66)locked (New in version 2.73)availability_zone (New in version 2.83)config_drive (New in version 2.83)key_name (New in version 2.83)created_at (New in version 2.83)launched_at (New in version 2.83)terminated_at (New in version 2.83)power_state (New in version 2.83)task_state (New in version 2.83)vm_state (New in version 2.83)progress (New in version 2.83)user_id (New in version 2.83)\nFor admin users, the allowlist includes all filter keys.\n\nSource: https://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail#list-servers\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nname (Optional)\nquery\nstring\n\nFilters the response by a server name, as a string.  You can use regular expressions\r\nin the query. For example, the ?name=bob regular expression returns both bob\r\nand bobb. If you must match on only bob, you can use a regular expression that\r\nmatches the syntax of the underlying database server that is implemented for Compute,\r\nsuch as MySQL or PostgreSQL.\n\ndisplay_name can also be requested which is alias of name\r\nbut that is not recommended to use as that will be removed in future.\n\naccess_ip_v4 (Optional)\nquery\nstring\nFilter server list result by IPv4 address that should be used\r\nto access the server.\n\naccess_ip_v6 (Optional)\nquery\nstring\nFilter server list result by IPv6 address that should be used\r\nto access the server.\n\nall_tenants (Optional)\nquery\nboolean\nSpecify the all_tenants query parameter to list all instances\r\nfor all projects. By default this is only allowed by administrators.\r\nIf this parameter is specified without a value, the value defaults to\r\nTrue. If the value is specified, 1, t, true,\r\non, y and yes are treated as True. 0, f,\r\nfalse, off, n and no are treated as False.\r\n(They are case-insensitive.)\n\nauto_disk_config (Optional)\nquery\nstring\n\nFilter the server list result by the disk_config setting of the server,\r\nValid values are:\n\nAUTO\n\nMANUAL\n\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\navailability_zone (Optional)\nquery\nstring\n\nFilter the server list result by server availability zone.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nchanges-before (Optional)\nquery\nstring\n\nFilters the response by a date and time stamp when the server last changed.\r\nThose servers that changed before or equal to the specified date and time stamp\r\nare returned. To help keep track of changes this may also return recently deleted\r\nservers. If you omit the time zone, the UTC time zone is assumed.\r\n\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ssZ\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58Z-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nWhen both changes-since and changes-before are specified,\r\nthe value of the changes-before must be later than or equal to\r\nthe value of the changes-since otherwise API will return 400.\nNew in version 2.66\n\nchanges-since (Optional)\nquery\nstring\n\nFilters the response by a date and time stamp when the server last\r\nchanged status. To help keep track of changes this may also return\r\nrecently deleted servers.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ssZ\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58Z-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\r\nWhen both changes-since and changes-before are specified,\r\nthe value of the changes-since must be earlier than or equal to\r\nthe value of the changes-before otherwise API will return 400.\n\nconfig_drive (Optional)\nquery\nstring\n\nFilter the server list result by the config drive setting of the server.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\ncreated_at (Optional)\nquery\nstring\n\nFilter the server list result by a date and time stamp when server was created.\r\nIf you omit the time zone, the UTC time zone is assumed.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\ndeleted (Optional)\nquery\nboolean\n\nShow deleted items only. In some circumstances deleted items will still\r\nbe accessible via the backend database, however there is no\r\ncontract on how long, so this parameter should be used with\r\ncaution. 1, t, true, on, y and yes are treated as\r\nTrue (case-insensitive). Other than them are treated as False.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nflavor (Optional)\nquery\nstring\nFilters the response by a flavor, as a UUID. A flavor is a combination of memory,\r\ndisk size, and CPUs.\n\nimage (Optional)\nquery\nstring\n\nFilters the response by an image, as a UUID.\n\nimage_ref can also be requested which is alias of image\r\nbut that is not recommended to use as that will be removed in future.\n\nip (Optional)\nquery\nstring\nAn IPv4 address to filter results by.\n\nip6 (Optional)\nquery\nstring\n\nAn IPv6 address to filter results by.\nUp to microversion 2.4, this parameter is only valid when specified\r\nby administrators. If non-admin users specify this parameter,\r\nit is ignored.\r\nStarting from microversion 2.5, this parameter is valid for no-admin users\r\nas well as administrators.\n\nkernel_id (Optional)\nquery\nstring\n\nFilter the server list result by the UUID of the kernel image\r\nwhen using an AMI.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nkey_name (Optional)\nquery\nstring\n\nFilter the server list result by keypair name.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nlaunch_index (Optional)\nquery\ninteger\n\nFilter the server list result by the sequence in which the\r\nservers were launched.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nlaunched_at (Optional)\nquery\nstring\n\nFilter the server list result by a date and time stamp when the instance was launched. If you omit the time zone, the UTC time zone is assumed.\n\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number of items up to a limit value.\r\nUse the limit parameter to make an initial limited request and use the ID\r\nof the last-seen item from the response as the marker parameter value in a\r\nsubsequent limited request.\n\nlocked (Optional)\nquery\nboolean\n\nSpecify the locked query parameter to list all locked or unlocked\r\ninstances. If the value is specified, 1, t, true,\r\non, y and yes are treated as True. 0, f,\r\nfalse, off, n and no are treated as False.\r\n(They are case-insensitive.) Any other value provided will be considered\r\ninvalid.\nNew in version 2.73\n\nlocked_by (Optional)\nquery\nstring\n\nFilter the server list result by who locked the server, possible value\r\ncould be admin or owner.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nmarker (Optional)\nquery\nstring\nThe ID of the last-seen item. Use the limit parameter to make an initial limited\r\nrequest and use the ID of the last-seen item from the response as the marker\r\nparameter value in a subsequent limited request.\n\ndescription (Optional)\nquery\nstring\n\nFilter the server list result by description.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\ndisplay_description can also be requested which is alias of\r\ndescription but that is not recommended to use as that will\r\nbe removed in future.\n\nhost (Optional)\nquery\nstring\n\nFilter the server list result by the host name of compute node.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nhostname (Optional)\nquery\nstring\n\nFilter the server list result by the host name of server.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nnode (Optional)\nquery\nstring\n\nFilter the server list result by the node.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\npower_state (Optional)\nquery\ninteger\n\nFilter the server list result by server power state.\nPossible values are integer values that is mapped as:0: NOSTATE\r\n1: RUNNING\r\n3: PAUSED\r\n4: SHUTDOWN\r\n6: CRASHED\r\n7: SUSPENDED\r\n8: SHUTDOWN_ACTIVE\r\n\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nprogress (Optional)\nquery\ninteger\n\nFilter the server list result by the progress of the server.\r\nThe value could be from 0 to 100 as integer.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nproject_id (Optional)\nquery\nstring\n\nFilter the list of servers by the given project ID.\nThis filter only works when the all_tenants filter is also specified.\n\ntenant_id can also be requested which is alias of project_id\r\nbut that is not recommended to use as that will be removed in future.\n\nramdisk_id (Optional)\nquery\nstring\n\nFilter the server list result by the UUID of the ramdisk image when\r\nusing an AMI.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nreservation_id (Optional)\nquery\nstring\nA reservation id as returned by a servers multiple create call.\n\nroot_device_name (Optional)\nquery\nstring\n\nFilter the server list result by the root device name of the server.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nsoft_deleted (Optional)\nquery\nboolean\nFilter the server list by SOFT_DELETED status. This parameter is only valid\r\nwhen the deleted=True filter parameter is specified.\n\nsort_dir (Optional)\nquery\nstring\nSort direction. A valid value is asc (ascending) or desc (descending).\r\nDefault is desc. You can specify multiple pairs of sort key and sort direction\r\nquery parameters. If you omit the sort direction in a pair, the API uses the natural\r\nsorting direction of the direction of the server sort_key attribute.\n\nsort_key (Optional)\nquery\nstring\n\nSorts by a server attribute. Default attribute is created_at. You can\r\nspecify multiple pairs of sort key and sort direction query parameters. If\r\nyou omit the sort direction in a pair, the API uses the natural sorting\r\ndirection of the server sort_key attribute. The sort keys are limited\r\nto:\n\naccess_ip_v4\n\naccess_ip_v6\n\nauto_disk_config\n\navailability_zone\n\nconfig_drive\n\ncreated_at\n\ndisplay_description\n\ndisplay_name\n\nhost\n\nhostname\n\nimage_ref\n\ninstance_type_id\n\nkernel_id\n\nkey_name\n\nlaunch_index\n\nlaunched_at\n\nlocked (New in version 2.73)\nlocked_by\n\nnode\n\npower_state\n\nprogress\n\nproject_id\n\nramdisk_id\n\nroot_device_name\n\ntask_state\n\nterminated_at\n\nupdated_at\n\nuser_id\n\nuuid\n\nvm_state\n\nhost and node are only allowed for admin.\r\nIf non-admin users specify them, a 403 error is returned.\n\nstatus (Optional)\nquery\nstring\n\nFilters the response by a server status, as a string. For example, ACTIVE.\nUp to microversion 2.37, an empty list is returned if an invalid status is\r\nspecified. Starting from microversion 2.38, a 400 error is returned\r\nin that case.\n\ntask_state (Optional)\nquery\nstring\n\nFilter the server list result by task state.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nterminated_at (Optional)\nquery\nstring\n\nFilter the server list result by a date and time stamp when instance was terminated.\r\n\r\nIf you omit the time zone, the UTC time zone is assumed.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nuser_id (Optional)\nquery\nstring\n\nFilter the list of servers by the given user ID.\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nuuid (Optional)\nquery\nstring\n\nFilter the server list result by the UUID of the server.\nThis parameter is only valid when specified by administrators.\r\nIf non-admin users specify this parameter, it is ignored.\n\nvm_state (Optional)\nquery\nstring\n\nFilter the server list result by VM state.\nThe value could be:\n\nACTIVE\n\nBUILDING\n\nDELETED\n\nERROR\n\nPAUSED\n\nRESCUED\n\nRESIZED\n\nSHELVED\n\nSHELVED_OFFLOADED\n\nSOFT_DELETED\n\nSTOPPED\n\nSUSPENDED\n\nThis parameter is restricted to administrators until microversion 2.83.\r\nIf non-admin users specify this parameter before microversion 2.83,\r\nit will be ignored.\n\nnot-tags (Optional)\nquery\nstring\n\nA list of tags to filter the server list by. Servers that don\u00e2\u0080\u0099t\r\nmatch all tags in this list will be returned. Boolean expression in this\r\ncase is NOT (t1 AND t2). Tags in query must be separated by comma.\nNew in version 2.26\n\nnot-tags-any (Optional)\nquery\nstring\n\nA list of tags to filter the server list by. Servers that don\u00e2\u0080\u0099t\r\nmatch any tags in this list will be returned. Boolean expression in this\r\ncase is NOT (t1 OR t2). Tags in query must be separated by comma.\nNew in version 2.26\n\ntags (Optional)\nquery\nstring\n\nA list of tags to filter the server list by. Servers that match\r\nall tags in this list will be returned. Boolean expression in this\r\ncase is t1 AND t2. Tags in query must be separated by comma.\nNew in version 2.26\n\ntags-any (Optional)\nquery\nstring\n\nA list of tags to filter the server list by. Servers that match\r\nany tag in this list will be returned. Boolean expression in this\r\ncase is t1 OR t2. Tags in query must be separated by comma.\nNew in version 2.26\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers?all_tenants\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nservers\n\nbody\narray\nA list of server objects.\n\nid\n\nbody\nstring\nThe UUID of the server.\n\nlinks\n\nbody\narray\nLinks to the resources in question. See API Guide / Links and\r\nReferences\r\nfor more info.\n\nname\n\nbody\nstring\nThe server name.\n\nservers_links (Optional)\nbody\narray\nLinks to the next server. It is available when the number of servers exceeds\r\nlimit parameter or [api]/max_limit in the configuration file.\r\nSee Paginated collections\r\nfor more info.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"servers\": [\r\n    {\r\n      \"id\": \"bb4f4c8d-a6ca-4723-ace3-1683f54cca1e\",\r\n      \"links\": [\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/bb4f4c8d-a6ca-4723-ace3-1683f54cca1e\",\r\n          \"rel\": \"self\"\r\n        },\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/servers/bb4f4c8d-a6ca-4723-ace3-1683f54cca1e\",\r\n          \"rel\": \"bookmark\"\r\n        }\r\n      ],\r\n      \"name\": \"vm1\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-virtual-machines.html"
    },
    {
        "title": "Creating Kubernetes cluster templates",
        "content": "Creating Kubernetes cluster templatesPOST /v1/clustertemplates\r\n\nCreate a new Kubernetes cluster template. After this, you can create Kubernetes clusters based on this template.\nUse the template to specify network information. In addition, enable load balancing with master_lb_enabled for clusters with multiple masters and nodes. Some of the parameters (labels, flavor IDs, and such) can be specified either in a template or a cluster itself.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=create-new-cluster-template-detail#create-new-cluster-template\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfloating_ip_enabled\n\nbody\nboolean\nWhether enable or not using the floating IP of cloud provider. Some\r\ncloud providers used floating IP, some used public IP, thus Magnum\r\nprovide this option for specifying the choice of using floating IP.\n\nfixed_subnet (Optional)\nbody\nstring\nFixed subnet that are using to allocate network address for nodes in\r\nbay/cluster.\n\nmaster_flavor_id (Optional)\nbody\nstring\nThe flavor of the master node for this baymodel/cluster template.\n\nno_proxy (Optional)\nbody\nstring\nWhen a proxy server is used, some sites should not go through the proxy\r\nand should be accessed normally. In this case, users can specify these\r\nsites as a comma separated list of IPs. The default is None.\n\nhttps_proxy (Optional)\nbody\nstring\nThe IP address for a proxy to use when direct HTTPS access from the\r\nservers to sites on the external internet is blocked. This may happen in\r\ncertain countries or enterprises, and the proxy allows the servers and\r\ncontainers to access these sites. The format is a URL including a port\r\nnumber. The default is None.\n\ntls_disabled\n\nbody\nboolean\nTransport Layer Security (TLS) is normally enabled to secure the\r\nbay/cluster. In some cases, users may want to disable TLS in the\r\nbay/cluster, for instance during development or to troubleshoot certain\r\nproblems. Specifying this parameter will disable TLS so that users can\r\naccess the COE endpoints without a certificate. The default is TLS enabled.\n\nkeypair_id\n\nbody\nstring\nThe name of the SSH keypair to configure in the bay/cluster servers\r\nfor ssh access. Users will need the key to be able to ssh to the servers in\r\nthe bay/cluster. The login name is specific to the bay/cluster driver, for\r\nexample with fedora-atomic image, default login name is fedora.\n\npublic\n\nbody\nboolean\nAccess to a baymodel/cluster template is normally limited to the admin,\r\nowner or users within the same tenant as the owners. Setting this flag\r\nmakes the baymodel/cluster template public and accessible by other users.\r\nThe default is not public.\n\nlabels (Optional)\nbody\narray\nArbitrary labels in the form of key=value pairs. The accepted keys and\r\nvalid values are defined in the bay/cluster drivers. They are used as a way\r\nto pass additional parameters that are specific to a bay/cluster driver.\n\ndocker_volume_size\n\nbody\ninteger\nThe size in GB for the local storage on each server for the Docker daemon\r\nto cache the images and host the containers. Cinder volumes provide the\r\nstorage. The default is 25 GB. For the devicemapper storage driver,\r\nthe minimum value is 3 GB. For the overlay storage driver, the minimum\r\nvalue is 1 GB.\n\nserver_type\n\nbody\nstring\nThe servers in the bay/cluster can be vm or baremetal. This\r\nparameter selects the type of server to create for the bay/cluster.\r\nThe default is vm.\n\nexternal_network_id\n\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to the\r\nexternal internet for the bay/cluster. This network must be an external\r\nnetwork, i.e. its attribute router:external must be True. The\r\nservers in the bay/cluster will be connected to a private network and\r\nMagnum will create a router between this private network and the external\r\nnetwork. This will allow the servers to download images, access discovery\r\nservice, etc, and the containers to install packages, etc. In the opposite\r\ndirection, floating IPs will be allocated from the external network to\r\nprovide access from the external internet to servers and the container\r\nservices hosted in the bay/cluster.\n\nimage_id\n\nbody\nstring\nThe name or UUID of the base image in Glance to boot the servers for the\r\nbay/cluster. The image must have the attribute os_distro defined as\r\nappropriate for the bay/cluster driver.\n\nvolume_driver\n\nbody\nstring\nThe name of a volume driver for managing the persistent storage for the containers. The functionality supported are specific to the driver.\n\nregistry_enabled (Optional)\nbody\nboolean\nDocker images by default are pulled from the public Docker registry,\r\nbut in some cases, users may want to use a private registry. This option\r\nprovides an alternative registry based on the Registry V2: Magnum will\r\ncreate a local registry in the bay/cluster backed by swift to host the\r\nimages. The default is to use the public registry.\n\ndocker_storage_driver\n\nbody\nstring\nThe name of a driver to manage the storage for the images and the\r\ncontainer\u00e2\u0080\u0099s writable layer. The default is devicemapper.\n\nname\n\nbody\nstring\nName of the resource.\n\nnetwork_driver\n\nbody\nstring\nThe name of a network driver for providing the networks for the containers.\r\nNote that this is different and separate from the Neutron network for the\r\nbay/cluster. The operation and networking model are specific to the\r\nparticular driver.\n\nfixed_network (Optional)\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to\r\nthe internal network for the bay/cluster.\n\ncoe\n\nbody\nstring\nSpecify the Container Orchestration Engine to use. Supported COEs\r\ninclude kubernetes, swarm, mesos. If your environment has\r\nadditional bay/cluster drivers installed, refer to the bay/cluster driver\r\ndocumentation for the new COE names.\n\nflavor_id\n\nbody\nstring\nThe nova flavor ID or name for booting the node servers. The default is\r\nm1.small.\n\nmaster_lb_enabled\n\nbody\nboolean\nSince multiple masters may exist in a bay/cluster, a Neutron load balancer\r\nis created to provide the API endpoint for the bay/cluster and to direct\r\nrequests to the masters. In some cases, such as when the LBaaS service is\r\nnot available, this option can be set to false to create a bay/cluster\r\nwithout the load balancer. In this case, one of the masters will serve as\r\nthe API endpoint. The default is true, i.e. to create the load\r\nbalancer for the bay.\n\ndns_nameserver\n\nbody\nstring\nThe DNS nameserver for the servers and containers in the bay/cluster to\r\nuse. This is configured in the private Neutron network for the bay/cluster.\r\nThe default is 8.8.8.8.\n\nhidden (Optional)\nbody\nboolean\nIndicates whether the ClusterTemplate is hidden or not, the default\r\nvalue is false.\n\nExample# curl -ks -X POST -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"name\": \"kub1_template\",\r\n  \"server_type\": \"vm\",\r\n  \"cluster_distro\": \"fedora-atomic\",\r\n  \"image_id\": \"f1e62c6a-37d8-4e73-9729-ad957e509c11\",\r\n  \"volume_driver\": \"cinder\",\r\n  \"docker_storage_driver\": \"devicemapper\",\r\n  \"docker_volume_size\": \"10\",\r\n  \"network_driver\": \"flannel\",\r\n  \"coe\": \"kubernetes\",\r\n  \"master_lb_enabled\": true,\r\n  \"floating_ip_enabled\": true,\r\n  \"fixed_network\": \"666d0a98-9de7-45df-9301-5ed12a7efea1\",\r\n  \"fixed_subnet\": \"43b25f61-657c-407f-935c-3a456aab7943\",\r\n  \"external_network_id\": \"7cc2fa27-b387-4a67-8b89-94b608295623\",\r\n  \"labels\": {\r\n    \"kube_tag\": \"v1.15.6\",\r\n    \"cloud_provider_enabled\": \"true\",\r\n    \"cloud_provider_tag\": \"v1.15.0\",\r\n    \"kube_version\": \"v1.15.6\",\r\n    \"boot_volume_type\": \"default\",\r\n    \"flannel_tag\": \"v0.11.0-amd64\",\r\n    \"boot_volume_size\": \"10\",\r\n    \"heat_container_agent_tag\": \"hci-3.5-latest\",\r\n    \"docker_volume_type\": \"default\"\r\n  }\r\n}' https://<node_IP_addr>:9513/v1/clustertemplates\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ninsecure_registry\n\nbody\nstring\nThe URL pointing to users\u00e2\u0080\u0099s own private insecure docker registry to\r\ndeploy and run docker containers.\n\nlinks\n\nbody\narray\nLinks to the resources in question.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nfloating_ip_enabled\n\nbody\nboolean\nWhether enable or not using the floating IP of cloud provider. Some\r\ncloud providers used floating IP, some used public IP, thus Magnum\r\nprovide this option for specifying the choice of using floating IP.\n\nfixed_subnet (Optional)\nbody\nstring\nFixed subnet that are using to allocate network address for nodes in\r\nbay/cluster.\n\nmaster_flavor_id (Optional)\nbody\nstring\nThe flavor of the master node for this baymodel/cluster template.\n\nuuid\n\nbody\nUUID\nThe UUID of the cluster template.\n\nno_proxy (Optional)\nbody\nstring\nWhen a proxy server is used, some sites should not go through the proxy\r\nand should be accessed normally. In this case, users can specify these\r\nsites as a comma separated list of IPs. The default is None.\n\nhttps_proxy (Optional)\nbody\nstring\nThe IP address for a proxy to use when direct HTTPS access from the\r\nservers to sites on the external internet is blocked. This may happen in\r\ncertain countries or enterprises, and the proxy allows the servers and\r\ncontainers to access these sites. The format is a URL including a port\r\nnumber. The default is None.\n\ntls_disabled\n\nbody\nboolean\nTransport Layer Security (TLS) is normally enabled to secure the\r\nbay/cluster. In some cases, users may want to disable TLS in the\r\nbay/cluster, for instance during development or to troubleshoot certain\r\nproblems. Specifying this parameter will disable TLS so that users can\r\naccess the COE endpoints without a certificate. The default is TLS enabled.\n\nkeypair_id\n\nbody\nstring\nThe name of the SSH keypair to configure in the bay/cluster servers\r\nfor ssh access. Users will need the key to be able to ssh to the servers in\r\nthe bay/cluster. The login name is specific to the bay/cluster driver, for\r\nexample with fedora-atomic image, default login name is fedora.\n\npublic\n\nbody\nboolean\nAccess to a baymodel/cluster template is normally limited to the admin,\r\nowner or users within the same tenant as the owners. Setting this flag\r\nmakes the baymodel/cluster template public and accessible by other users.\r\nThe default is not public.\n\nlabels (Optional)\nbody\narray\nArbitrary labels in the form of key=value pairs. The accepted keys and\r\nvalid values are defined in the bay/cluster drivers. They are used as a way\r\nto pass additional parameters that are specific to a bay/cluster driver.\n\ndocker_volume_size\n\nbody\ninteger\nThe size in GB for the local storage on each server for the Docker daemon\r\nto cache the images and host the containers. Cinder volumes provide the\r\nstorage. The default is 25 GB. For the devicemapper storage driver,\r\nthe minimum value is 3 GB. For the overlay storage driver, the minimum\r\nvalue is 1 GB.\n\nserver_type\n\nbody\nstring\nThe servers in the bay/cluster can be vm or baremetal. This\r\nparameter selects the type of server to create for the bay/cluster.\r\nThe default is vm.\n\nexternal_network_id\n\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to the\r\nexternal internet for the bay/cluster. This network must be an external\r\nnetwork, i.e. its attribute router:external must be True. The\r\nservers in the bay/cluster will be connected to a private network and\r\nMagnum will create a router between this private network and the external\r\nnetwork. This will allow the servers to download images, access discovery\r\nservice, etc, and the containers to install packages, etc. In the opposite\r\ndirection, floating IPs will be allocated from the external network to\r\nprovide access from the external internet to servers and the container\r\nservices hosted in the bay/cluster.\n\ncluster_distro\n\nbody\nstring\nDisplay the attribute os_distro defined as appropriate metadata in\r\nimage for the bay/cluster driver.\n\nimage_id\n\nbody\nstring\nThe name or UUID of the base image in Glance to boot the servers for the\r\nbay/cluster. The image must have the attribute os_distro defined as\r\nappropriate for the bay/cluster driver.\n\nvolume_driver\n\nbody\nstring\nThe name of a volume driver for managing the persistent storage for the containers. The functionality supported are specific to the driver.\n\nregistry_enabled (Optional)\nbody\nboolean\nDocker images by default are pulled from the public Docker registry,\r\nbut in some cases, users may want to use a private registry. This option\r\nprovides an alternative registry based on the Registry V2: Magnum will\r\ncreate a local registry in the bay/cluster backed by swift to host the\r\nimages. The default is to use the public registry.\n\ndocker_storage_driver\n\nbody\nstring\nThe name of a driver to manage the storage for the images and the\r\ncontainer\u00e2\u0080\u0099s writable layer. The default is devicemapper.\n\napiserver_port\n\nbody\ninteger\nThe exposed port of COE API server.\n\nname\n\nbody\nstring\nName of the resource.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nnetwork_driver\n\nbody\nstring\nThe name of a network driver for providing the networks for the containers.\r\nNote that this is different and separate from the Neutron network for the\r\nbay/cluster. The operation and networking model are specific to the\r\nparticular driver.\n\nfixed_network (Optional)\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to\r\nthe internal network for the bay/cluster.\n\ncoe\n\nbody\nstring\nSpecify the Container Orchestration Engine to use. Supported COEs\r\ninclude kubernetes, swarm, mesos. If your environment has\r\nadditional bay/cluster drivers installed, refer to the bay/cluster driver\r\ndocumentation for the new COE names.\n\nflavor_id\n\nbody\nstring\nThe nova flavor ID or name for booting the node servers. The default is\r\nm1.small.\n\nmaster_lb_enabled\n\nbody\nboolean\nSince multiple masters may exist in a bay/cluster, a Neutron load balancer\r\nis created to provide the API endpoint for the bay/cluster and to direct\r\nrequests to the masters. In some cases, such as when the LBaaS service is\r\nnot available, this option can be set to false to create a bay/cluster\r\nwithout the load balancer. In this case, one of the masters will serve as\r\nthe API endpoint. The default is true, i.e. to create the load\r\nbalancer for the bay.\n\ndns_nameserver\n\nbody\nstring\nThe DNS nameserver for the servers and containers in the bay/cluster to\r\nuse. This is configured in the private Neutron network for the bay/cluster.\r\nThe default is 8.8.8.8.\n\nhidden (Optional)\nbody\nboolean\nIndicates whether the ClusterTemplate is hidden or not, the default\r\nvalue is false.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"insecure_registry\": null,\r\n  \"links\": [\r\n    {\r\n      \"href\": \"https://<node_IP_addr>:9513/v1/clustertemplates/b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n      \"rel\": \"self\"\r\n    },\r\n    {\r\n      \"href\": \"https://<node_IP_addr>:9513/clustertemplates/b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n      \"rel\": \"bookmark\"\r\n    }\r\n  ],\r\n  \"http_proxy\": null,\r\n  \"updated_at\": null,\r\n  \"floating_ip_enabled\": true,\r\n  \"fixed_subnet\": \"43b25f61-657c-407f-935c-3a456aab7943\",\r\n  \"master_flavor_id\": null,\r\n  \"user_id\": \"2a55cfc7747b4383b0856a0a622914dd\",\r\n  \"uuid\": \"b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n  \"no_proxy\": null,\r\n  \"https_proxy\": null,\r\n  \"tls_disabled\": false,\r\n  \"keypair_id\": null,\r\n  \"hidden\": false,\r\n  \"project_id\": \"888ea5e76b284d83a18b3bfaa6fdde16\",\r\n  \"public\": false,\r\n  \"labels\": {\r\n    \"cloud_provider_enabled\": \"true\",\r\n    \"kube_tag\": \"v1.15.6\",\r\n    \"heat_container_agent_tag\": \"hci-3.5-latest\",\r\n    \"kube_version\": \"v1.15.6\",\r\n    \"boot_volume_type\": \"default\",\r\n    \"flannel_tag\": \"v0.11.0-amd64\",\r\n    \"boot_volume_size\": \"10\",\r\n    \"cloud_provider_tag\": \"v1.15.0\",\r\n    \"docker_volume_type\": \"default\"\r\n  },\r\n  \"docker_volume_size\": 10,\r\n  \"server_type\": \"vm\",\r\n  \"external_network_id\": \"7cc2fa27-b387-4a67-8b89-94b608295623\",\r\n  \"cluster_distro\": \"fedora-atomic\",\r\n  \"image_id\": \"f1e62c6a-37d8-4e73-9729-ad957e509c11\",\r\n  \"volume_driver\": \"cinder\",\r\n  \"registry_enabled\": false,\r\n  \"docker_storage_driver\": \"devicemapper\",\r\n  \"apiserver_port\": null,\r\n  \"name\": \"kub1_template\",\r\n  \"created_at\": \"2020-04-14T13:26:01+00:00\",\r\n  \"network_driver\": \"flannel\",\r\n  \"fixed_network\": \"666d0a98-9de7-45df-9301-5ed12a7efea1\",\r\n  \"coe\": \"kubernetes\",\r\n  \"flavor_id\": null,\r\n  \"master_lb_enabled\": true,\r\n  \"dns_nameserver\": null\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-kubernetes-cluster-templates.html"
    },
    {
        "title": "6. Installing BitNinja Agent\u00c2\u00b6",
        "content": "6. Installing BitNinja Agent | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n6. Installing BitNinja Agent\u00c2\u00b6\nOnce the end-user has purchased the BitNinja License, they only need to run a one-line command to install the BitNinja agent.\n\nFig. 6.1 Example WHMCS BitNinja service view.\u00c2\u00b6\n\nFig. 6.2 BitNinja Agent installation wizard from the BitNinja Portal.\u00c2\u00b6\n\nInstallation starts, it takes approximately one minute to finish.\n\nOnce the installation process has finished, the agent will communicate with the BitNinja portal by sending a heartbeat.\n\nNow, the workload admin can log in to https://admin.bitninja.io/site/login and manage all the available security modules, review logs, perform or schedule malware scans and more. For more info, go to https://docs.bitninja.io/docs/Modules/SQLCleaning.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/installing-bitninja-agent.html"
    },
    {
        "title": "Migrating virtual machines",
        "content": "Migrating virtual machines\nVirtual machine migration helps facilitate cluster upgrades and workload balancing between compute nodes. Virtuozzo Hybrid Infrastructure allows you to perform two types of migration:\n\nCold migration for stopped virtual machines\nHot migration for running virtual machines (allows you to avoid VM downtime)\n\nFor both migration types, a virtual machine is migrated between compute nodes using shared storage, so no block device migration takes place.\nHot migration consists of the following steps:\n\nAll VM memory is copied to the destination node, while the virtual machine keeps running on the source node. If a VM memory page changes, it is copied again.\nWhen only a few memory pages are left to copy, the VM is stopped on the source node, the remaining pages are transferred, and the VM is restarted on the destination node.\n\nLarge virtual machines with write-intensive workloads write to memory faster than memory changes can be transferred to the destination node, thus preventing migration from converging. For such VMs, the auto-converge mechanism is used. When a lack of convergence is detected during live migration, the VM\u00e2\u0080\u0099s vCPU execution speed is throttled down, which also slows down writing to the VM memory. Initially, the virtual machine\u00e2\u0080\u0099s vCPU is throttled by 20 percent and then by 10 percent during each iteration. This process continues until writing to the VM memory slows down enough for migration to complete or the VM vCPU is throttled by 99 percent.\nLimitations\n\nVirtual machines are created with the host CPU model, by default. Having compute nodes with different CPUs may lead to live migration issues. To avoid them, you can manually set the CPU model for all new VMs, as described in Setting virtual machine CPU model. Alternatively, you can create a placement for each group of compute nodes with the same CPU model by using the instructions in Managing placements for compute nodes.\n\nMigration is not supported for suspended virtual machines.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo migrate a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click a VM to migrate.\nClick the ellipsis button next to the VM, and then select Migrate.\n\nIn the new window, specify the destination node:\n\nAuto. Automatically select the optimal destination among cluster nodes, based on available CPU and RAM resources.\nSelect the destination node manually from the drop-down list.\n\nBy default, running VMs are migrated live. You can change the migration mode to offline by selecting the Cold migration check box. A VM will be stopped and restarted on the destination node after migration.\n\nClick Migrate to reserve resources on the destination node and start migration.\n\nThe admin panel will show the migration progress.\n\nCommand-line interface\nUse the following command:vinfra service compute server migrate [--cold] [--node <node>] <server>\r\n\n\n--cold\n\nPerform cold migration. If not set, the migration type is determined automatically.\n--node <node>\n\nDestination node ID or hostname\n<server>\n\nVirtual machine ID or name\n\nFor example, to start migration of the virtual machine myvm to the compute node node003.vstoragedomain, run:# vinfra service compute server migrate myvm --node node003\n\nSee also\n\nManaging virtual machine power state\n\nMonitoring virtual machines\n\nTroubleshooting virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server migrate [--cold] [--node <node>] <server>\r\n\n\n--cold\n\nPerform cold migration. If not set, the migration type is determined automatically.\n--node <node>\n\nDestination node ID or hostname\n<server>\n\nVirtual machine ID or name\n\nFor example, to start migration of the virtual machine myvm to the compute node node003.vstoragedomain, run:# vinfra service compute server migrate myvm --node node003\n",
                "title": "To migrate a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click a VM to migrate.\nClick the ellipsis button next to the VM, and then select Migrate.\n\nIn the new window, specify the destination node:\n\nAuto. Automatically select the optimal destination among cluster nodes, based on available CPU and RAM resources.\nSelect the destination node manually from the drop-down list.\n\n\n\n\n\n\n\nBy default, running VMs are migrated live. You can change the migration mode to offline by selecting the Cold migration check box. A VM will be stopped and restarted on the destination node after migration.\n\nClick Migrate to reserve resources on the destination node and start migration.\n\nThe admin panel will show the migration progress.\n",
                "title": "To migrate a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/migrating-virtual-machines.html"
    },
    {
        "title": "Managing images",
        "content": "Managing images",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-images.html"
    },
    {
        "title": "Managing Kubernetes clusters",
        "content": "Managing Kubernetes clusters\nSelf-service users can deploy ready-to-use Kubernetes clusters with persistent storage for managing containerized applications.\nA Kubernetes cluster includes the following components:\n\nUnderlying OS: Fedora 39 CoreOS\nContainer runtime: containerd 1.6.23\nNetwork plugin:Flannel VXLAN (for public VM networks)Flannel host-gw (for private VM networks)\n\nLimitations\n\nKubernetes versions 1.15.x\u00e2\u0080\u00931.22.x are no longer supported. Kubernetes clusters created with these versions are marked with the Deprecated tag.\nKubernetes cluster certificates are issued for five years. To renew the certificates, use the openstack coe ca rotate command, as described in the OpenStack documentation.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-kubernetes-clusters.html"
    },
    {
        "title": "Mounting S3 storage with Mountain Duck",
        "content": "Mounting S3 storage with Mountain Duck\nMountain Duck enables you to mount and access Virtuozzo Hybrid Infrastructure S3 storage as a regular disk drive. Do the following:\n\nIf your service provider has provided you with an SSL certificate, install it.\n\nIn Mountain Duck, click New Bookmark.\n\nIn the properties window, select Amazon S3 profile from the first drop-down list and specify the following parameters:\n\n Disk drive name in the Nickname field\nEndpoint DNS name in the Server field\nAccess key ID in the Username field\n\nClick Connect.\n\nIn the login window, specify Secret Access Key and click Login.\n\nMountain Duck will mount the S3 storage as a disk drive. On the disk, you can manage buckets and store files in them.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/mounting-s3-storage-with-mountain-duck.html"
    },
    {
        "title": "Updating projects",
        "content": "Updating projectsPATCH /v3/projects/{project_id}\r\n\nChange the name and description of a project with the specified ID. You can also use this call to add and remove users in a project.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=update-project-detail#update-project\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe project ID.\n\nproject\n\nbody\nobject\nA project object.\n\nname (Optional)\nbody\nstring\nThe name of the project, which must be unique within the\r\nowning domain. A project can have the same name as its domain.\n\nis_domain (Optional)\nbody\nboolean\n\nIndicates whether the project also acts as a domain. If set to true,\r\nthis project acts as both a project and domain. As a domain, the project\r\nprovides a name space in which you can create users, groups, and other\r\nprojects. If set to false, this project behaves as a regular project\r\nthat contains only resources. Default is false. You cannot update\r\nthis parameter after you create the project.\nNew in version 3.6\n\ndescription (Optional)\nbody\nstring\nThe description of the project.\n\ndomain_id (Optional)\nbody\nstring\n\nThe ID of the new domain for the project. The ability to change the domain\r\nof a project is now deprecated, and will be removed in subequent release.\r\nIt is already disabled by default in most Identity service implementations.\n\nenabled (Optional)\nbody\nboolean\nIf set to true, project is enabled. If set to\r\nfalse, project is disabled. The default is true.\n\ntags (Optional)\nbody\narray\nA list of simple strings assigned to a project.\r\nTags can be used to classify projects into groups.\n\noptions (Optional)\nbody\nobject\nThe resource options for the project. Available resource options are\r\nimmutable.\n\nExample 1\nChange project name and description:# curl -ks -X PATCH -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"project\": {\r\n    \"description\": \"New project description\",\r\n    \"name\": \"project1_renamed\"\r\n  }\r\n}' https://<node_IP_addr>:5000/v3/projects/ec35eb7ceb594ad696839fc867817e4c\r\n\nExample 2\nAdd a user with the specified ID to a project with the role project_user also specified by its ID:# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/projects/03013ec787054e78ae26806636ad18d9/\\\r\nusers/2973892bee384ca6b8c9886f0c4a8815/roles/b05bd85e514a4abdbb46ee743f0d59a4\r\n\nExample 3\nRemove a user with the specified ID and the role project_user from a project:# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/projects/03013ec787054e78ae26806636ad18d9/\\\r\nusers/2973892bee384ca6b8c9886f0c4a8815/roles/b05bd85e514a4abdbb46ee743f0d59a4\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nproject\n\nbody\nobject\nA project object.\n\nname\n\nbody\nstring\nThe unique name of the project within the\r\nowning domain.\n\nis_domain\n\nbody\nboolean\n\nIndicates whether the project also acts as a domain. If set to true,\r\nthis project acts as both a project and domain. As a domain, the project\r\nprovides a name space in which you can create users, groups, and other\r\nprojects. If set to false, this project behaves as a regular project\r\nthat contains only resources.\nNew in version 3.6\n\ndescription\n\nbody\nstring\nThe description of the project.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain for the project.\n\nenabled\n\nbody\nboolean\nIf set to true, project is enabled. If set to\r\nfalse, project is disabled.\n\nid\n\nbody\nstring\nThe ID for the project.\n\nlinks\n\nbody\nobject\nThe link to the project resource.\n\nparent_id\n\nbody\nstring\n\nThe ID of the parent for the project.\nNew in version 3.4\n\noptions\n\nbody\nobject\nThe resource options for the project. Available resource options are\r\nimmutable.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"project\": {\r\n    \"is_domain\": false,\r\n    \"description\": \"New project description\",\r\n    \"links\": {\r\n      \"self\": \"https://<node_IP_addr>:5000/v3/projects/ec35eb7ceb594ad696839fc867817e4c\"\r\n    },\r\n    \"tags\": [],\r\n    \"extra\": {},\r\n    \"enabled\": true,\r\n    \"id\": \"ec35eb7ceb594ad696839fc867817e4c\",\r\n    \"parent_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"name\": \"project1_renamed\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-projects.html"
    },
    {
        "title": "Benchmarking disks",
        "content": "Benchmarking disks\nFirst, you need to prepare the benchmarking scripts, and then you can perform benchmarks for each disk individually and all of them cumulatively.\nPrerequisites\n\nKnowledge of the storage cluster best practices and configurations listed in Storage cluster best practices and Configuration examples.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/benchmarking-disks.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Object Storage Orchestration API Reference\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nObject Storage Orchestration API Reference\n\nHome\n\nContents\n\nIndex\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureObject Storage Orchestration API Reference\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/index.html"
    },
    {
        "title": "Deleting virtual machines",
        "content": "Deleting virtual machines\nLimitations\n\nA VM is removed along with its disks that have the Delete on termination option enabled during the VM deployment.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo remove one virtual machine\n\nAdmin panel\n\nClick the ellipsis button next to a VM you want to delete, and then click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute server delete <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to delete the virtual machine myvm, run:# vinfra service compute server delete myvm\n\nTo remove multiple virtual machines\n\nSelect the check boxes next to VMs you want to delete.\nOver the VM list, click Delete.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server delete <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to delete the virtual machine myvm, run:# vinfra service compute server delete myvm\n",
                "title": "To remove one virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nClick the ellipsis button next to a VM you want to delete, and then click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To remove one virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/deleting-virtual-machines.html"
    },
    {
        "title": "Scaling the storage cluster",
        "content": "Scaling the storage cluster\nAfter deploying the storage cluster, you can expand its storage capacity at any time by adding more storage disks (vertical scaling) or increasing the number of storage nodes (horizontal scaling). You can also replace storage disks with disks of larger size by following the instructions in Replacing node disks.\nTo better understand the difference between vertical and horizontal scaling, let\u00e2\u0080\u0099s have a look at the following scenarios:\n\nVertical scaling. The cluster has five nodes with 12 hard drive slots each. One disk is used for system and metadata, and 9 disks are used for storage on tier 0. Backup storage is deployed on top of the storage cluster with the 3+2 encoding mode. You can expand the storage capacity of the backup storage by adding two more disks to each node. As a result, the storage capacity will increase by 2/9.\nHorizontal scaling. The cluster has five nodes with 12 hard drive slots each. One disk is used for system and metadata, and 11 disks are used for storage on tier 0. Backup storage is deployed on top of the storage cluster with the 3+2 encoding mode. You can expand the storage capacity and throughput of the backup storage by adding two more nodes of the same size (that is, with 12 disks). As a result, the storage capacity will increase by 2/5. Additionally, to maximize the storage efficiency, you can update the encoding mode to 5+2, as described in Changing the redundancy scheme for backup storage.\n\nBefore you add new disks and nodes, consider the following recommendations for their sizing:\n\nIt is recommended for a storage tier to have an equal number of disks per node. Then, the data will be spread more evenly among nodes. For more information, refer to Logical space chart.\nHaving the same-size disks helps distribute the loads more evenly. Inside a cluster, the disk usage is proportional to the disk size. For example, if you have a disk of 10 \u00d0\u00a2B and a disk of 2 TB, a 50% cluster load will use 5 \u00d0\u00a2B and 1 TB, respectively.\n\nLimitations\n\nYou can assign a role to a disk only if its size is greater than 1 GiB.\nYou can assign an additional role to a system disk only if its size is at least 100 GiB.\nIt is recommended to assign the System and Metadata roles to either an SSD disk or different HDDs. Assigning both of these roles to the same HDD disk will result in mediocre performance suitable only for cold data (for example, archiving).\nThe System role cannot be combined with the Cache and Metadata+Cache roles. The reason is that the I/O generated by the operating system and applications would contend with the I/O generated by journaling, thus negating its performance benefits.\nYou can use shingled magnetic recording (SMR) HDDs only with the Storage role and only if the node has an SSD disk with the Cache role. Host-managed SMR disks are not supported.\nYou cannot use SMR and standard disks in the same tier.\nYou cannot assign roles to system and non-system disks at a time.\n\nPrerequisites\n\nThe storage cluster is created, as described in Deploying the storage cluster.\n\nTo add disks to the storage cluster\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node.\nOn the Disks tab, click the new disk without a role.\nOn the disk right pane, click Assign role.\n\nIn the Assign role window, select a disk role, that is how you want to use the disk:\n\n[Only for SSD drives] To store write cache\n\nSelect the Cache role.\nSelect a storage tier that you want to cache.\n\nFor storage disks to use cache, the Cache role must be assigned before the Storage role. You can also assign both of these roles to disks at the same time, and the system will configure the cache disk first.\n\nTo store data\n\nSelect the Storage role.\nSelect a storage tier where to store your data. To make better use of data redundancy, do not assign all of the disks on a node to the same tier. Instead, make sure that each tier is evenly distributed across the cluster.\n\nEnable data caching and checksumming:\n\nEnable SSD caching and checksumming. Available and recommended only for nodes with SSDs.\nEnable checksumming (default). Recommended for nodes with HDDs as it provides better reliability.\nDisable checksumming. Not recommended for production. For an evaluation or testing environment, you can disable checksumming for nodes with HDDs, to provide better performance.\n\nTo store cluster metadata\n\nSelect the Metadata role.\n\nIt is recommended to have only one disk with the Metadata role per node and maximum five such disks in a cluster.\n\n[Only for SSD drives] To store both metadata and write cache\n\nSelect the Metadata+Cache role.\nSelect a storage tier that you want to cache.\n\nClick Assign.\n\nCommand-line interface\nUse the following command:vinfra node disk assign --disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]\r\n                        [--node <node>]\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n\nFor example, to assign the role cs to the disk sdc on the node node003, run:# vinfra node disk assign --disk sdc:cs --node node003\nYou can view the node's disk configuration in the vinfra node disk list output:# vinfra node disk list --node node003\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| id                                   | device | type | role       | disk_status | used    | size     | physical_size | service_id | service_status |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| 2A006CA5-732F-4E17-8FB0-B82CE0F28DB2 | sdc    | hdd  | cs         | ok          | 11.2GiB | 125.8GiB | 128.0GiB      | 1026       | active         |\r\n| 642A7162-B66C-4550-9FB2-F06866FB7EA1 | sdb    | hdd  | cs         | ok          | 8.7GiB  | 125.8GiB | 128.0GiB      | 1025       | active         |\r\n| 45D38CD2-3B94-4F0F-8864-9D51F716D3B1 | sda    | hdd  | mds-system | ok          | 21.0GiB | 125.9GiB | 128.0GiB      | 1          | avail          |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n\n\nTo add nodes to the storage cluster\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click an unassigned node.\nOn the node right pane, click Join to cluster.\n\nIn the Join node to storage cluster window, check the default disk configuration. If it is correct, proceed to join the node to the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks. Alternatively, you can copy the disk configuration from another node by clicking Copy configuration from and selecting the desired node.\n\nOnce you finish configuring the disks, click Join, to add the node to the storage cluster.\n\nCommand-line interface\nUse the following command:vinfra node join [--disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]] <node>\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n<node>\n\nNode ID or hostname\n\nFor example, to add the node node002 to the storage cluster and assign roles to disks: mds-system to sda, cs to sdb and sdc, run:# vinfra node join f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4 --disk sda:mds-system \\\r\n--disk sdb:cs --disk sdc:cs\nThe added node will appear in the vinfra node list output:# vinfra node list\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| id           | host         | is_primary | is_online | is_assigned | is_in_ha |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| 09bb6b8<...> | node001<...> | True       | True      | True        | False    |\r\n| 187edb1<...> | node002<...> | False      | True      | True        | False    |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n\n\nSee also\n\nMonitoring the storage cluster\n\nManaging infrastructure nodes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node disk assign --disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]\r\n                        [--node <node>]\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n\nFor example, to assign the role cs to the disk sdc on the node node003, run:# vinfra node disk assign --disk sdc:cs --node node003\nYou can view the node's disk configuration in the vinfra node disk list output:# vinfra node disk list --node node003\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| id                                   | device | type | role       | disk_status | used    | size     | physical_size | service_id | service_status |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| 2A006CA5-732F-4E17-8FB0-B82CE0F28DB2 | sdc    | hdd  | cs         | ok          | 11.2GiB | 125.8GiB | 128.0GiB      | 1026       | active         |\r\n| 642A7162-B66C-4550-9FB2-F06866FB7EA1 | sdb    | hdd  | cs         | ok          | 8.7GiB  | 125.8GiB | 128.0GiB      | 1025       | active         |\r\n| 45D38CD2-3B94-4F0F-8864-9D51F716D3B1 | sda    | hdd  | mds-system | ok          | 21.0GiB | 125.9GiB | 128.0GiB      | 1          | avail          |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n\n",
                "title": "To add disks to the storage cluster"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node join [--disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]] <node>\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n<node>\n\nNode ID or hostname\n\nFor example, to add the node node002 to the storage cluster and assign roles to disks: mds-system to sda, cs to sdb and sdc, run:# vinfra node join f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4 --disk sda:mds-system \\\r\n--disk sdb:cs --disk sdc:cs\nThe added node will appear in the vinfra node list output:# vinfra node list\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| id           | host         | is_primary | is_online | is_assigned | is_in_ha |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| 09bb6b8<...> | node001<...> | True       | True      | True        | False    |\r\n| 187edb1<...> | node002<...> | False      | True      | True        | False    |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n\n",
                "title": "To add nodes to the storage cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node.\nOn the Disks tab, click the new disk without a role.\nOn the disk right pane, click Assign role.\n\nIn the Assign role window, select a disk role, that is how you want to use the disk:\n\n\n[Only for SSD drives] To store write cache\n\n\nSelect the Cache role.\nSelect a storage tier that you want to cache.\n\n\nFor storage disks to use cache, the Cache role must be assigned before the Storage role. You can also assign both of these roles to disks at the same time, and the system will configure the cache disk first.\n\n\n\n\n\nTo store data\n\n\nSelect the Storage role.\nSelect a storage tier where to store your data. To make better use of data redundancy, do not assign all of the disks on a node to the same tier. Instead, make sure that each tier is evenly distributed across the cluster.\n\nEnable data caching and checksumming:\n\nEnable SSD caching and checksumming. Available and recommended only for nodes with SSDs.\nEnable checksumming (default). Recommended for nodes with HDDs as it provides better reliability.\nDisable checksumming. Not recommended for production. For an evaluation or testing environment, you can disable checksumming for nodes with HDDs, to provide better performance.\n\n\n\n\n\n\n\nTo store cluster metadata\n\nSelect the Metadata role.\n\nIt is recommended to have only one disk with the Metadata role per node and maximum five such disks in a cluster.\n\n\n\n\n\n[Only for SSD drives] To store both metadata and write cache\n\n\nSelect the Metadata+Cache role.\nSelect a storage tier that you want to cache.\n\n\n\n\n\n\n\n\nClick Assign.\n\n",
                "title": "To add disks to the storage cluster"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click an unassigned node.\nOn the node right pane, click Join to cluster.\n\nIn the Join node to storage cluster window, check the default disk configuration. If it is correct, proceed to join the node to the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks. Alternatively, you can copy the disk configuration from another node by clicking Copy configuration from and selecting the desired node.\n\nOnce you finish configuring the disks, click Join, to add the node to the storage cluster.\n\n",
                "title": "To add nodes to the storage cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/scaling-the-storage-cluster.html"
    },
    {
        "title": "Managing S3 accounts",
        "content": "Managing S3 accounts\nAn S3 account is a container for S3 user with additional credentials. An account is owned by a single user while a user can have multiple accounts. You can create and manage S3 accounts by using the ostor-s3-admin command-line tool.\nWhen you create an S3 account, an access key pair (access key ID and secret access key) is generated automatically. It is recommended to periodically revoke old and generate new access key pairs.\nLimitations\n\nThe maximum of two active access key pairs are allowed per account.\n\nTo create an S3 account\n\nFind out the ID of the object storage volume. For example:# ostor-ctl get-config -V\r\nVOL_ID             TYPE     STATE\r\n0100000000000002   OBJ     READY\n\nCreate an account for an S3 user specifying the user email and an account name. For example, to create the account myaccount for the user with the email myuser@email.com, run:# ostor-s3-admin create-account -V 0100000000000002 -n myaccount -e myuser@email.com\nThis command requires the following parameters:\n\n-V, --volume <volume_id>\nThe volume ID obtained in step 1\n-n <account_name>\n\nAccount name\n-e <user_email>\n\nUser email\n\nCheck that the new account is created for the user. For example, if the user's email is myuser@email.com, run:# ostor-s3-admin list-user-accounts -V 0100000000000002 -e myuser@email.com\r\nNAME       USER_ID           EMAIL             S3AccessKeyId        S3SecretAccessKey\r\nmyaccount  b09693b73b3c7686  myuser@email.com  b09693b73b3c768613NV ***\r\n\n\nTo generate an access key pair for an S3 account\nUse the ostor-s3-admin gen-access-key command. For example:# ostor-s3-admin gen-access-key -V 0100000000000002 -n myaccount -e myuser@email.com\nThis command requires the following parameters:\n\n-V, --volume <volume_id>\nThe volume ID obtained by using the ostor-ctl get-config -V command\n-n <account_name>\n\nAccount name\n-e <user_email>\n\nUser email\n\nTo revoke an access key pair for an S3 account\nUse the ostor-s3-admin revoke-access-key command. For example:# ostor-s3-admin revoke-access-key -V 0100000000000002 -e user@email.com -k de86d1c19e616455YIPU\nThis command requires the following parameters:\n\n-V, --volume <volume_id>\nThe volume ID obtained by using the ostor-ctl get-config -V command\n-e <user_email>\n\nUser email\n-k <access_key_id>\n\nUser access key ID\n\nTo delete an S3 account\nUse the ostor-s3-admin delete-account command. For example:# ostor-s3-admin delete-account -V 0100000000000002 -n myaccount -e myuser@email.com\nThis command requires the following parameters:\n\n-V, --volume <volume_id>\nThe volume ID obtained in step 1\n-n <account_name>\n\nAccount name\n-e <user_email>\n\nUser email\n\nSee also\n\nManaging S3 users\n\nManaging S3 buckets\n\nDefining object storage classes",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-s3-accounts.html"
    },
    {
        "title": "Managing network interfaces",
        "content": "Managing network interfaces\nAfter configuring your node network interfaces, you can bring them up and down, as well as delete logical interfaces, bonds and VLANs.\nPrerequisites\n\nA network interface is configured, as described in Configuring node network interfaces.\n\nLimitations\n\nOpen vSwitch-based bridge interfaces cannot be brought down or deleted after creation.\nYou can only delete bonded and VLAN interfaces.\n\nTo bring a network interface up\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface with the Disabled status. \nOn the interface right pane, click Bring up.\n\nCommand-line interface\nUse the following command:vinfra node iface up [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname\n<iface>\n\nNetwork interface name\n\nFor example, to bring up the network interface eth2 located on the node node003, run:# vinfra node iface up eth2 --node node003\n\nTo bring a network interface down\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface with the Connected status. \nOn the interface right pane, click Bring down.\nClick Bring down in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra node iface down [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname\n<iface>\n\nNetwork interface name\n\nFor example, to bring down the network interface eth2 located on the node node003, run:# vinfra node iface down eth2 --node node003\n\nTo delete a network interface\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the logical network interface that you want to delete. \nOn the interface right pane, click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra node iface delete [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname\n<iface>\n\nNetwork interface name\n\nFor example, to delete the network interface eth2.100 located on the node node003, run:# vinfra node iface delete eth2.100 --node node003\n\nSee also\n\nChanging network interface parameters\n\nChanging network configuration",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface up [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname\n<iface>\n\nNetwork interface name\n\nFor example, to bring up the network interface eth2 located on the node node003, run:# vinfra node iface up eth2 --node node003\n",
                "title": "To bring a network interface up"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface down [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname\n<iface>\n\nNetwork interface name\n\nFor example, to bring down the network interface eth2 located on the node node003, run:# vinfra node iface down eth2 --node node003\n",
                "title": "To bring a network interface down"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface delete [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname\n<iface>\n\nNetwork interface name\n\nFor example, to delete the network interface eth2.100 located on the node node003, run:# vinfra node iface delete eth2.100 --node node003\n",
                "title": "To delete a network interface"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface with the Disabled status. \nOn the interface right pane, click Bring up.\n\n",
                "title": "To bring a network interface up"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface with the Connected status. \nOn the interface right pane, click Bring down.\nClick Bring down in the confirmation window.\n\n",
                "title": "To bring a network interface down"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the logical network interface that you want to delete. \nOn the interface right pane, click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a network interface"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-network-interfaces.html"
    },
    {
        "title": "Restoring volumes from backups",
        "content": "Restoring volumes from backups\nDuring the restore process, a new volume is created and the existing volume is not overwritten. You can restore a volume from a backup of a data or boot volume.\nPrerequisites\n\nA volume backup is created automatically, as described in Creating backup plans, or manually,  as described in Creating and deleting backups manually.\n\nTo restore a volume\n\nOn the Recovery points screen, click the recovery point from which you want to restore a volume.\nOn the right pane, click Restore volume.\n\nIn the Restore volume window, specify a volume name and select a storage policy, and then click Restore.\n\nThe new volume will appear on the Volumes screen.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/restoring-volumes-from-backups.html"
    },
    {
        "title": "Redundancy by erasure coding",
        "content": "Redundancy by erasure coding\nWith erasure coding, Virtuozzo Hybrid Infrastructure breaks the incoming data stream into fragments of a certain size, then splits each fragment into a certain number (M) of 1-megabyte pieces and creates a certain number (N) of parity pieces for redundancy. All pieces are distributed among M+N failure domains, that is, one piece per failure domain. On failure domains, pieces are stored in regular chunks of 256 MB but such chunks are not replicated as redundancy is already achieved. The cluster can survive failure of any N failure domains without data loss.\nThe values of M and N are indicated in the names of erasure coding redundancy modes. For example, in the 5+2 mode, the incoming data is broken into 5 MB fragments, each fragment is split into five 1 MB pieces and two more 1 MB parity pieces are added for redundancy. In addition, if N is 2, the data is encoded by using the RAID6 scheme, and if N is greater than 2, erasure codes are used.\nThe diagram below illustrates the 5+2 encoding mode with the host failure domain.\n\nFor production, it is recommended to use the erasure coding mode with at least 2 parity chunks.\n\nSee also\n\nRedundancy by replication\n\nNo redundancy\n\nRedundancy modes\n\nFailure domains\n\nStorage tiers\n\n\u00d0\u00a1luster rebuilding",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/redundancy-by-erasure-coding.html"
    },
    {
        "title": "About this guide",
        "content": "About this guide\nThis guide is intended for domain administrators and project members and explains how to manage compute and S3 resources, as well as projects and users, in the self-service panel.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/about-this-guide.html"
    },
    {
        "title": "Introduction",
        "content": "Introduction",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/introduction.html"
    },
    {
        "title": "Managing S3 accounts via CLI",
        "content": "Managing S3 accounts via CLI\nThis section describes how to manage S3 accounts  via the command-line interface. An S3 account is a container for S3 user with additional credentials. An account is owned by a single user while a user can have multiple accounts.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-accounts-via-cli.html"
    },
    {
        "title": "Setting bandwidth per second for users via REST API",
        "content": "Setting bandwidth per second for users via REST API\nYou can limit outgoing bandwidth of a response with the ostor-limits service and the following parameters: emailAddress specifying the email address, bandwidth specifying the limit type, and out= specifying the limit value:# s3_curl PUT \"http://s3.example.com/?ostor-limits&emailAddress=client@example.com&limit-type=bandwidth&limit-resource=out&limit-value=100\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-bandwidth-per-second-for-users-via-rest-api.html"
    },
    {
        "title": "Creating and deleting backups manually",
        "content": "Creating and deleting backups manually\nYou can initiate an instant backup job for a single volume by creating a backup manually. Such a backup does not have a retention policy and can only be deleted manually.\nTo manually create a volume backup\n\nOn the Volumes screen, click a volume that you want to back up.\nOn the volume right pane, click Create backup now.\n\nOnce the backup is created, it will appear on the Recovery points screen.\n\nTo manually delete a volume backup\n\nOn the Recovery points screen, click the recovery point that you want to delete.\nClick Delete in the confirmation window.\n\nAfter deleting a recovery point, all its data will be lost.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-and-deleting-backups-manually.html"
    },
    {
        "title": "Restoring management database with the compute cluster",
        "content": "Restoring management database with the compute cluster\nIf you have the compute cluster deployed, the management node database must be restored only on one of the compute nodes. After restoration, virtual machines that resided on the failed management node will be unmanageable in the admin panel and can only be deleted. However, you can rescue them by using the vinfra tool.\nLimitations\n\nIf management node high availability is enabled, you cannot restore database backups by using the script. In this case, contact the technical support team.\nIf you create compute objects after the backup, they will be lost.\nIf you modify or delete compute objects after the backup, they will be restored as follows:Compute objects used as configurations (flavors, storage policies, virtual networks, SSH keys) will be fully restored.All other compute objects (virtual machines, volumes, images, etc.) will be partially restored. They will be shown in the admin panel but unusable. You will only be able to remove them from the admin panel.\n\nPrerequisites\n\nThe management database is backed up automatically or manually, as described in Backing up management database.\n\nTo restore the management database on a compute node\nRun the restoration script with the -n option:/usr/libexec/vstorage-ui-backend/bin/restore-management-node.sh -x <public_net_iface> -i <private_net_iface> \\\r\n-f /mnt/vstorage/webcp/backup/<backup_file> -n\r\n\nwhere\n\nThe <public_net_iface> and <private_net_iface> are interfaces assigned the public and private networks.\nThe -f option specifies the path to the backup file. If omitted, the management node database will be restored from the latest backup.\nThe -n option denotes that the compute cluster will be reconfigured to use another management node. If you restore the management node database on the same node, omit the -n option.\n\nFor example, if the network interface eth0 is connected to the Public network, the network interface eth1 is connected to the Private network, and you want to restore the management node database with compute from the latest backup, run:# /usr/libexec/vstorage-ui-backend/bin/restore-management-node.sh -x eth0 -i eth1 -n\nTo rescue virtual machines from the failed management node\n\nCheck the VM state: VMs with enabled high availability will appear in the \u00e2\u0080\u009cRebuild\u00e2\u0080\u009d state, while VMs with disabled high availability will appear in the \u00e2\u0080\u009cActive\u00e2\u0080\u009d state.\nIf a VM in the \u00e2\u0080\u009cRebuild\u00e2\u0080\u009d state, reset its state with the vinfra service compute server reset-state command.\nEvacuate all VMs by using the vinfra service compute server evacuate command.\n\nSee also\n\nRestoring management database from backup",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/restoring-with-compute-cluster.html"
    },
    {
        "title": "Assigning users to projects",
        "content": "Assigning users to projects\nDomain administrators can manage project members\u00e2\u0080\u0099 assignment on the Projects and Users screens.\nTo assign a user to a project\n\nOn the Projects screen:\n\nClick the project to which you want to assign users (not the project name).\nOn the project panel, click Manage users.\nIn the Manage users window, select one or multiple users to assign to the project. Only user accounts with the Project member role are displayed. Then, click Save.\n\nOn the Users screen:\n\nClick the user account with the Project member role that you want to assign to the project.\nOn the user panel, click Manage projects.\nIn the Manage projects window, select one or multiple projects, and then click Save.\n\nTo unassign a user from a project\n\nOn the Projects screen:\n\nClick the project to unassign users from.\nOn the project panel, open the Users tab.\nClick the bin icon next to a user you want to remove from the project.\n\nOn the Users screen:\n\nClick the user to unassign from the project.\nOn the user panel, open the Projects tab.\nClick the bin icon next to the project that you want to remove the user from.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/assigning-users-to-projects.html"
    },
    {
        "title": "Deleting volumes",
        "content": "Deleting volumesDELETE /v3/{project_id}/volumes/{volume_id}\r\n\nDelete a volume with the specified ID.\nPreconditions:\n\nVolume status must be available, in-use, error,\r\nerror_restoring, error_extending, error_managing,\r\nand must not be migrating, attached, belong to a group or have snapshots.\nYou cannot already have a snapshot of the volume.\nYou cannot delete a volume that is in a migration.\n\nAsynchronous postconditions:\n\nThe volume is deleted in volume index.\nThe volume managed by OpenStack Block Storage is deleted in\r\nstorage node.\n\nTroubleshooting:\n\nIf volume status remains in deleting or becomes\r\nerror_deleting the request failed. Ensure you meet the\r\npreconditions then investigate the storage back end.\nThe volume managed by OpenStack Block Storage is not deleted from\r\nthe storage system.\n\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=delete-a-volume-detail#delete-a-volume\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nvolume_id\n\npath\nstring\nThe UUID of the volume.\n\ncascade (Optional)\nquery\nboolean\nRemove any snapshots along with the volume. Default is false.\n\nforce (Optional)\nquery\nboolean\n\nIndicates whether to force delete a volume even if\r\nthe volume is in deleting or error_deleting. Default is false.\nNew in version 3.23\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-volumes.html"
    },
    {
        "title": "Setting up networks for the compute cluster",
        "content": "Setting up networks for the compute cluster\nPrerequisites\n\nYour network topology meets the requirements listed in Compute cluster network requirements.\nA clear understanding of the concept Traffic types.\n\nMinimum network setup for the compute cluster\nFor the compute service deployed for evaluation purposes, the minimum network configuration includes two networks, for internal and external traffic. You can leave the default Public and Private networks as they are. In this case, traffic types should be assigned to these networks, according to the following table:\n\nMinimum network setup for compute\r\n                \n\nNetwork\nTraffic types\n\nPrivate\nStorage, Internal management, OSTOR private, Backup (ABGW) private, VM private\n\nPublic\nAdmin panel, SNMP, SSH, Self-service panel, Compute API, VM public, iSCSI, NFS, S3 public, Backup (ABGW) public\n\nTo create the minimum network configuration for the compute cluster\n\nAdmin panel\n\nAdd the required traffic types (Compute API, VM private, and VM public) to your infrastructure networks:On the Infrastructure > Networks screen, click the pencil icon next to the traffic type  in the Exclusive traffic types section or next to the Regular traffic types section.Add the needed traffic type to your network by selecting the corresponding radio button or check box.Click the check mark to apply the changes.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the compute cluster.\n\nCommand-line interface\nUse the following command:vinfra cluster network set-bulk --network <network>:<traffic-types>\r\n\n\n--network <network>:<traffic-types>\n\nNetwork configuration in the format:\n\n<network>: network ID or name.\n<traffic-types>: a comma-separated list of traffic type names\n\nThis option can be used multiple times.\n\nFor example, to set the required traffic types  to the Private and Public networks, run:# vinfra cluster network set-bulk --network Private:\"Storage\",\"Internal management\",\\\r\n\"OSTOR private\",\"Backup (ABGW) private\",\"VM private\",\"VM backups\",\"VM public\" \\\r\n--network Public:\"Admin panel\",\"SNMP\",\"SSH\",\"Self-service panel\",\"Compute API\",\\\r\n\"VM public\",\"iSCSI\",\"NFS\",\"S3 public\",\"Backup (ABGW) public\"\n\nRecommended network setup for the compute cluster\nFor the compute service deployed for production, the recommended network configuration implies creating additional networks. The following networks are required:\n\nPrivate network, assigned to the first bonded connection\nTrunk network, assigned to the trunk interface of the second bonded connection\nOverlay network, assigned to a VLAN created on the second bonded connection\nServices network, assigned to a VLAN created on the second bonded connection\nPublic network, assigned to a VLAN created on the second bonded connection\n\nThe required traffic types should be distributed between these networks, according to the following table:\n\nRecommended network setup for compute\r\n            \n\nNetwork\nTraffic types\n\nPrivate\nStorage, Internal management (optional: OSTOR private, Backup (ABGW) private)\n\nTrunk\nVM public\n\nOverlay\nVM private\n\nServices\nCompute API, Admin panel, Self-service panel, SSH (optional: S3 public, iSCSI, NFS, Backup (ABGW) public, SNMP)\n\nPublic\nVM public\n\nTo create the recommended network configuration for the compute cluster\n\nAdmin panel\n\nAdd three more networks:On the Infrastructure > Networks screen, click Create network.In the New network window, specify a network name. Network names may contain only Latin letters, numbers, and underscores, and must be 3 to 32 characters long.Click Create.\nAssign the required traffic types according to the recommended network setup:On the Infrastructure > Networks screen, click the pencil icon next to the traffic type  in the Exclusive traffic types section or next to the Regular traffic types section.Add the needed traffic type to your network by selecting the corresponding radio button or check box.Click the check mark to apply the changes.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nCreate bonded and VLAN connections on the nodes that you plan to join the compute cluster.\n\nCommand-line interface\n\nAdd three more networks by using vinfra cluster network create. For example:\n\nTo create the Overlay network and assign the VM private traffic type to it, run:# vinfra cluster network create Overlay --traffic-types \"VM private\"\n\nTo create the External VM network and assign the VM public traffic type to it, run:# vinfra cluster network create \"External VM\" --traffic-types \"VM public\"\n\nTo create the Backup network and assign the VM backups and VM public traffic types to it, run:# vinfra cluster network create Backup --traffic-types \"VM backups\",\"VM public\"\n\nAssign the SNMP, Compute API, and Self-service panel traffic types to the Public network by running:\r\n# vinfra cluster network set Public --add-traffic-types \"SNMP\",\"Compute API\",\"Self-service panel\"\r\n\n\nReview your network configuration:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+-------------+----------------------------------------------------------------------------------+\r\n| id                                   | name        | traffic_types                                                                    |\r\n+--------------------------------------+-------------+----------------------------------------------------------------------------------+\r\n| 0181a09c-3334-4b3b-a8d9-8c011de5c21c | Overlay     | VM private                                                                       |\r\n| 40dea510-d73c-497e-8cea-69bc52a5ae07 | External VM | VM public                                                                        |\r\n| 8b7d2be5-6cc5-4635-b3d9-16c6cc11275d | Backup      | VM backups,VM public                                                             |\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private     | Backup (ABGW) private,Internal management,OSTOR private,Storage                  |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public      | Backup (ABGW) public,Compute API,iSCSI,NFS,S3 public,Self-service ...<truncated> |\r\n+--------------------------------------+-------------+----------------------------------------------------------------------------------+\r\n\n\nSee also\n\nManaging infrastructure networks\n\nWhat's next\n\nConfiguring node network interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network set-bulk --network <network>:<traffic-types>\r\n\n\n--network <network>:<traffic-types>\n\n\nNetwork configuration in the format:\n\n<network>: network ID or name.\n<traffic-types>: a comma-separated list of traffic type names\n\nThis option can be used multiple times.\n\n\nFor example, to set the required traffic types  to the Private and Public networks, run:# vinfra cluster network set-bulk --network Private:\"Storage\",\"Internal management\",\\\r\n\"OSTOR private\",\"Backup (ABGW) private\",\"VM private\",\"VM backups\",\"VM public\" \\\r\n--network Public:\"Admin panel\",\"SNMP\",\"SSH\",\"Self-service panel\",\"Compute API\",\\\r\n\"VM public\",\"iSCSI\",\"NFS\",\"S3 public\",\"Backup (ABGW) public\"\n",
                "title": "To create the minimum network configuration for the compute cluster"
            },
            {
                "example": "\nCommand-line interface\n\n\nAdd three more networks by using vinfra cluster network create. For example:\n\n\nTo create the Overlay network and assign the VM private traffic type to it, run:# vinfra cluster network create Overlay --traffic-types \"VM private\"\n\n\nTo create the External VM network and assign the VM public traffic type to it, run:# vinfra cluster network create \"External VM\" --traffic-types \"VM public\"\n\n\nTo create the Backup network and assign the VM backups and VM public traffic types to it, run:# vinfra cluster network create Backup --traffic-types \"VM backups\",\"VM public\"\n\n\n\n\nAssign the SNMP, Compute API, and Self-service panel traffic types to the Public network by running:\r\n# vinfra cluster network set Public --add-traffic-types \"SNMP\",\"Compute API\",\"Self-service panel\"\r\n\n\n\nReview your network configuration:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+-------------+----------------------------------------------------------------------------------+\r\n| id                                   | name        | traffic_types                                                                    |\r\n+--------------------------------------+-------------+----------------------------------------------------------------------------------+\r\n| 0181a09c-3334-4b3b-a8d9-8c011de5c21c | Overlay     | VM private                                                                       |\r\n| 40dea510-d73c-497e-8cea-69bc52a5ae07 | External VM | VM public                                                                        |\r\n| 8b7d2be5-6cc5-4635-b3d9-16c6cc11275d | Backup      | VM backups,VM public                                                             |\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private     | Backup (ABGW) private,Internal management,OSTOR private,Storage                  |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public      | Backup (ABGW) public,Compute API,iSCSI,NFS,S3 public,Self-service ...<truncated> |\r\n+--------------------------------------+-------------+----------------------------------------------------------------------------------+\r\n\n\n\n",
                "title": "To create the recommended network configuration for the compute cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nAdd the required traffic types (Compute API, VM private, and VM public) to your infrastructure networks:On the Infrastructure > Networks screen, click the pencil icon next to the traffic type  in the Exclusive traffic types section or next to the Regular traffic types section.Add the needed traffic type to your network by selecting the corresponding radio button or check box.Click the check mark to apply the changes.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the compute cluster.\n\n",
                "title": "To create the minimum network configuration for the compute cluster"
            },
            {
                "example": "\nAdmin panel\n\nAdd three more networks:On the Infrastructure > Networks screen, click Create network.In the New network window, specify a network name. Network names may contain only Latin letters, numbers, and underscores, and must be 3 to 32 characters long.Click Create.\nAssign the required traffic types according to the recommended network setup:On the Infrastructure > Networks screen, click the pencil icon next to the traffic type  in the Exclusive traffic types section or next to the Regular traffic types section.Add the needed traffic type to your network by selecting the corresponding radio button or check box.Click the check mark to apply the changes.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nCreate bonded and VLAN connections on the nodes that you plan to join the compute cluster.\n\n",
                "title": "To create the recommended network configuration for the compute cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-networks-compute.html"
    },
    {
        "title": "Running the benchmark for NFS and iSCSI",
        "content": "Running the benchmark for NFS and iSCSI\nPrerequisites\n\nThe benchmarks for the NFS or iSCSI services are set up, as described in Setting up the benchmark for NFS and iSCSI.\nIf the cluster nodes have SSD/NVMe caches, make sure they have been flushed, as instructed in Preparing to run the benchmark.\n\nTo run fio scripts\n\nOn each load generator node, start the fio server:# fio --server\n\nOn the coordinator node, create the dataset. In this example, we assume the scripts are stored in the /root/scripts directory, and we want to run the preparation script for the three load generators at 10.10.10.11, 10.10.10.12, and 10.10.10.13:\r\n# for N in {10.10.10.11,10.10.10.12,10.10.10.13}; do fio --minimal --client=$N /root/scripts/prepare-set.fio; done\nYou can also specify the hostnames of cluster nodes, instead if their IP addresses.\nThis command will prepare identical test datasets on all cluster nodes in succession. This may take several minutes, but it will provide less deviation of results during actual benchmarking. Ignore any performance results displayed by this fio run.\n\nOn the coordinator node, start the desired benchmark script. In this example, we assume the scripts are stored in the /root/scripts directory, and we want to run randread.fio for the three load generators at 10.10.10.11, 10.10.10.12, and 10.10.10.13:# fio --client 10.10.10.11 --client 10.10.10.12 --client 10.10.10.13 /root/scripts/randread.fio\n\nTo collect fio results\nFio shows several reports, one for each load generator participating in the benchmark. At the bottom, you will find the section \"All clients\", which contains the summary of the overall performance.\nAn example output is as follows:\r\n[\u00e2\u0080\u00a6]\r\nAll clients: (groupid=0, jobs=4): err= 0: pid=5190: Mon Mar 7 15:16:09 2022\r\n  read: IOPS=18.9k, BW=73.9MiB/s (77.5MB/s)(8865MiB/120001msec)\r\n    slat (usec): min=105, max=97552, avg=206.52, stdev=187.96\r\n    clat (usec): min=5, max=299572, avg=53923.77, stdev=8760.84\r\n     lat (usec): min=210, max=299745, avg=54131.08, stdev=8784.92\r\n    clat percentiles (msec):\r\n     | 1.00th=[ 44], 5.00th=[ 46], 10.00th=[ 47], 20.00th=[ 48],\r\n     | 30.00th=[ 50], 40.00th=[ 52], 50.00th=[ 53], 60.00th=[ 54],\r\n     | 70.00th=[ 56], 80.00th=[ 59], 90.00th=[ 64], 95.00th=[ 68],\r\n     | 99.00th=[ 79], 99.50th=[ 82], 99.90th=[ 89], 99.95th=[ 106],\r\n     | 99.99th=[ 296]\r\n   bw ( KiB/s): min=39528, max=88968, per=99.97%, avg=75622.67, stdev=1440.79,\r\nsamples=957\r\n   iops : min= 9882, max=22242, avg=18905.56, stdev=360.20, samples=957\r\n  lat (usec) : 10=0.01%, 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%\r\n  lat (msec) : 2=0.01%, 4=0.01%, 10=0.01%, 20=0.01%, 50=32.91%\r\n  lat (msec) : 100=67.02%, 250=0.01%, 500=0.04%\r\n  cpu : usr=2.35%, sys=9.55%, ctx=2283821, majf=0, minf=1079\r\n  IO depths : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%\r\n     submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%\r\n     complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.1%\r\n     issued rwts: total=2269396,0,0,0 short=0,0,0,0 dropped=0,0,0,0\r\n     latency : target=0, window=0, percentile=100.00%, depth=256\r\n\r\nRun status group 0 (all jobs):\r\n   READ: bw=73.9MiB/s (77.5MB/s), 73.9MiB/s-73.9MiB/s (77.5MB/s-77.5MB/s),\r\nio=8865MiB (9295MB),\r\nrun=120001-120001msec\r\n\r\nDisk stats (read/write):\r\n   sda: ios=2267039/1298, merge=0/967, ticks=417590/1434, in_queue=418444,\r\nutil=99.22%\nIn this output, some of the most relevant metrics are highlighted in bold. They include IOPS, latency (lat), I/O depth, and bandwidth (bw).\nSee also\n\nGeneral considerations\n\nRunning the benchmark for S3\n\nBenchmarking disks\n\nBenchmarking the network\n\nTroubleshooting performance issues",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/running-benchmark-for-nfs-iscsi.html"
    },
    {
        "title": "Network ports",
        "content": "Network ports\nPorts that will be opened on cluster nodes depend on services that will run on the node and traffic types associated with them. Before enabling a specific service on a cluster node, you need to assign the respective traffic type to a network this node is connected to. Assigning a traffic type to a network configures a firewall on nodes connected to this network, opens specific ports on node network interfaces, and sets the necessary iptables rules.\nThe table below lists all the required ports and services associated with them:\n\nService\nTraffic type\nPort\nTraffic direction\nDescription\n\nWeb control panel\nAdmin panel1 Ports for this traffic type must only be open on management nodes.\nTCP 8888\nInbound\nExternal access to the admin panel.\n\nSelf-service panel\nTCP 8800\nInbound\nExternal access to the self-service panel.\n\nManagement\nInternal management\nall ports for a subnet\nInbound/outbound\nInternal cluster management and transfers\r\nof node monitoring data to the admin panel.\n\nMetadata service\nStorage\nall ports for a subnet\nInbound/outbound\nInternal communication between MDS services,\r\nas well as with chunks services and clients.\n\nChunk service\nall ports for a subnet\nInbound/outbound\nInternal communication with MDS services and\r\nclients.\n\nClient\nall ports for a subnet\nInbound/outbound\nInternal communication with MDS and chunk\r\nservices.\n\nBackup Gateway\nBackup (ABGW) public\nTCP 40440, 44445\nInbound\nExternal data exchange with Acronis Cyber Protect\r\nagents and Acronis Cyber Protect Cloud.\n\nBackup (ABGW) private\nall ports for a subnet\nInbound/outbound\nInternal management of and data exchange\r\nbetween multiple backup storage services.\n\n\u00e2\u0080\u0094\nTCP 8443\nOutbound\nData control for Acronis Cyber Protect agents and Management server\n\n\u00e2\u0080\u0094\nTCP 9877\nOutbound\nRegistration with Acronis Cyber Protect Management server in on-premises installations\n\niSCSI\niSCSI\nTCP 3260\nInbound\nExternal data exchange with the iSCSI\r\naccess point.\n\nS3\nS3 public\nTCP 80, 443\nInbound\nExternal data exchange with the S3 access\r\npoint.\n\nOSTOR private\nall ports for a subnet\nInbound/outbound\nInternal data exchange between multiple S3\r\nservices.\n\nNFS\nNFS\nTCP/UDP 111, 892,\r\n2049\nInbound\nExternal data exchange with the NFS access\r\npoint.\n\nOSTOR private\nall ports for a subnet\nInbound/outbound\nInternal data exchange between multiple NFS\r\nservices.\n\nCompute\nCompute API2 Ports for this traffic type must only be open on management nodes.\n\u00a0\n\u00a0\nExternal access to standard OpenStack API\r\nendpoints:\n\nTCP 5000\nInbound\nIdentity API v3\n\nTCP 6080\nInbound\nnoVNC Websocket Proxy\n\nTCP 8004\nInbound\nOrchestration Service API v1\n\nTCP 8041\nInbound\nGnocchi API (billing metering service)\n\nTCP 8774\nInbound\nCompute API\n\nTCP 8776\nInbound\nBlock Storage API v3\n\nTCP 8780\nInbound\nPlacement API\n\nTCP 9292\nInbound\nImage Service API v2\n\nTCP 9313\nInbound\nKey Manager API v1\n\nTCP 9513\nInbound\nContainer Infrastructure Management API\r\n(Kubernetes service)\n\nTCP 9696\nInbound\nNetworking API v2\n\nTCP 9888\nInbound\nOctavia API v2 (load balancer service)\n\nVM public\nL2 layer\nInbound/outbound\nExternal data exchange between VMs and public networks.\n\nVM private\nUDP 4789\nInbound/outbound\nNetwork traffic between VMs in compute virtual networks.\n\nTCP 15900\u00e2\u0080\u009316900\nInbound/outbound\nVNC console traffic.\n\nVM backups\nTCP 49300\u00e2\u0080\u009365535\nInbound/outbound3 Outbound traffic is only used for the Acronis Disaster Recovery (DR) hybrid deployment.\nExternal access to NBD endpoints.\n\n\u00e2\u0080\u0094\nUDP 500, 4500\nOutbound\nVPN as a Service\n\nSSH\nSSH\nTCP 22\nInbound\nRemote access to nodes via SSH.\n\nSNMP\nSNMP4 Ports for this traffic type must only be open on management nodes.\nUDP 161\nInbound\nExternal access to storage cluster\r\nmonitoring statistics via the SNMP protocol.\n\nDNS\n\u00e2\u0080\u0094\nTCP/UDP 53\nOutbound\nDNS name resolution.\n\nNTP\n\u00e2\u0080\u0094\nUDP 123\nOutbound\nTime syncronization.\n\nSee also\n\nNetwork requirements\n\nNetwork recommendations",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/network-ports.html"
    },
    {
        "title": "Managing flavors",
        "content": "Managing flavors",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-flavors.html"
    },
    {
        "title": "Setting up networks for backup storage",
        "content": "Setting up networks for backup storage\nLimitations\n\nBackup storage works with IPv4 and dual-stack (IPv4 + IPv6) networks. IPv6 networks are not supported.\n\nPrerequisites\n\nYour network topology meets the requirements listed in Acronis Backup Storage network requirements.\nA clear understanding of the concept Traffic types.\n\nFor backup storage, the recommended network configuration includes two networks, for internal and external traffic. You can leave the default Public and Private networks as they are. In this case, traffic types should be assigned to these networks, according to the following table:\n\nRecommended network setup for Backup Gateway\r\n                \n\nNetwork\nTraffic types\n\nPrivate\nStorage, Internal management, OSTOR private, Backup (ABGW) private\n\nPublic\nAdmin panel, SSH, S3 public, iSCSI, NFS, Backup (ABGW) public\n\nTo create the network configuration for backup storage\n\nAdmin panel\n\nReview your network configuration on the Infrastructure > Networks screen.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the backup storage.\n\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n\nSee also\n\nManaging infrastructure networks\n\nWhat's next\n\nConfiguring node network interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n",
                "title": "To create the network configuration for backup storage"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nReview your network configuration on the Infrastructure > Networks screen.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the backup storage.\n\n",
                "title": "To create the network configuration for backup storage"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-networks-backup-storage.html"
    },
    {
        "title": "Enabling logging for virtual machines",
        "content": "Enabling logging for virtual machines\nThe console log of a virtual machine can be used for troubleshooting boot issues. The log contains messages only if logging is enabled inside the VM, otherwise the log is empty.\nThe logging can be turned on by enabling the TTY1 and TTYS0 logging levels in Linux VMs and Emergency Management Services (EMS) console redirection in Windows VMs. You may also enable driver status logging in Windows VMs, to see the list of loaded drivers. This can be useful for troubleshooting a faulty driver or long boot process.\nTo enable TTY1 and TTYS0 logging in Linux virtual machines\n\nAdd the line GRUB_CMDLINE_LINUX_DEFAULT=\"console=tty1 console=ttyS0\" to the file /etc/default/grub.\n\nDepending on the boot loader, run either# grub-mkconfig -o /boot/grub/grub.cfg\r\n\nor# grub2-mkconfig -o /boot/grub2/grub.cfg\r\n\n\nReboot the VM.\n\nTo enable EMS console redirection in Windows virtual machines\n\nStart Windows PowerShell by using administrator privileges.\n\nIn the PowerShell console, set the COM port and baud rate for EMS console redirection. As Windows VMs have only the COM1 port with the transmission rate of 9600 bps, run:bcdedit /emssettings EMSPORT:1\r\n\n\nEnable EMS for the current boot entry:bcdedit /ems on\r\n\n\nTo enable driver status logging in Windows virtual machines\n\nStart System Configuration by using administrator privileges.\nIn the System Configuration windows, open the Boot tab, and select the check boxes OS boot information and Make all boot settings permanent.\nConfirm the changes and restart the system.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/enabling-logging-for-vms.html"
    },
    {
        "title": "Quantity of disks per node",
        "content": "Quantity of disks per node\nEach management node must have at least two disks (one for system and metadata, one for storage). Each secondary node must have at least two disks (one for system, one for storage). It is recommended to have at least three but not more than five metadata disks in a cluster.\nThe more disks per node, the lower the CAPEX. As an example, a cluster created from ten nodes with two disks in each will be less expensive than a cluster created from twenty nodes with one disk in each. \nIn general, a cluster with many nodes and few disks per node offers higher performance, while a cluster with the minimum number of nodes (3) and a lot of disks per node is cheaper. Refer to the following table for more details.\n\nCluster composition recommendations\r\n            \n\nDesign considerations\nMinimum nodes (3),\r\nmany disks per node\nMany nodes, few disks per node\r\n(all-flash configuration)\n\nOptimization\nLower cost.\nHigher performance.\n\nFree disk space to\r\nreserve\nMore space to reserve for\r\ncluster rebuilding, as fewer\r\nhealthy nodes will have to\r\nstore the data from a failed node.\nLess space to reserve for cluster\r\nrebuilding, as more healthy nodes\r\nwill have to store the data\r\nfrom a failed node.\n\nRedundancy\nFewer erasure coding choices.\nMore erasure coding choices.\n\nCluster balance and\r\nrebuilding performance\nWorse balance and slower rebuilding.\nBetter balance and faster\r\nrebuilding.\n\nNetwork capacity\nMore network bandwidth required to\r\nmaintain cluster performance during\r\nrebuilding.\nLess network bandwidth required\r\nto maintain cluster performance\r\nduring rebuilding.\n\nFavorable data type\nCold data (for example, backups).\nHot data (for example, virtual\r\nenvironments).\n\nSample server\r\nconfiguration\nSupermicro SSG-6047R-E1R36L (Intel\r\nXeon E5-2620 v1/v2 CPU, 32 GB RAM,\r\n36 x 12 TB HDDs, a 500 GB system\r\ndisk).\nSupermicro SYS-2028TP-HC0R-SIOM\r\n(4 x Intel E5-2620 v4 CPUs,\r\n4 x 16 GB RAM, 4 x 1.9 TB Samsung\r\nPM1643 SSDs).\n\nTake note of the following:\n\nThese considerations only apply if the failure domain is the host.\nVirtuozzo Hybrid Infrastructure supports hundreds of disks per node. If you plan to use more than 36 disks per node, contact our sales engineers who will help you design a more efficient cluster.\n\nSee also\n\nHDD/SSD configuration\n\nProtecting data during a power outage\n\nChecking disk data flushing capabilities\n\nServer requirements\n\nNetwork requirements and recommendations",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/quantity-of-disks-per-node.html"
    },
    {
        "title": "Managing S3 user and bucket quotas via REST API",
        "content": "Managing S3 user and bucket quotas via REST API\nThis section describes quotas you can define for S3 users and buckets via REST API. These quotas limit object storage usage per user or per bucket. You can apply them to different users or buckets separately or set the default quotas to apply them to all S3 users and buckets by default.\nBefore setting quotas on S3 storage usage, run the ostor-ctl add-acc command specifying the volume ID and the path to the storage:# ostor-ctl add-acc -V 0100000000000002 -s /mnt/vstorage/vols/ostor",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-user-and-bucket-quotas-via-rest-api.html"
    },
    {
        "title": "Setting default quotas via REST API",
        "content": "Setting default quotas via REST API\nYou can limit storage usage for all users or buckets by default with the ostor-quotas service and the following parameters: default specifying user for users or bucket for buckets and quota-size specifying the usage limit in gigabytes:# s3_curl PUT \"http://s3.example.com/?ostor-quotas&default=user&quota-size=1024\"\r\n# s3_curl PUT \"http://s3.example.com/?ostor-quotas&default=bucket&quota-size=256\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-default-quotas-via-rest-api.html"
    },
    {
        "title": "Listing network interfaces of virtual machines",
        "content": "Listing network interfaces of virtual machinesGET /servers/{server_id}/os-interface\r\n\nList network interfaces that are attached to the given virtual machine.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=list-port-interfaces-detail#list-port-interfaces\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nExample\nList all network interfaces that are attached to a VM with the specified ID.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/b906404c55bb44729da99987536ac5bc/servers/0785ee80-1eca-426b-b8c4-5b499fc7f614/os-interface\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ninterfaceAttachments\n\nbody\narray\nList of the interface attachments.\n\nport_state\n\nbody\nstring\nThe port state.\n\nfixed_ips\n\nbody\narray\nFixed IP addresses with subnet IDs.\n\nsubnet_id\n\nbody\nstring\nThe UUID of the subnet.\n\nip_address\n\nbody\nstring\nThe IP address.\n\nport_id\n\nbody\nstring\nThe port ID.\n\nnet_id\n\nbody\nstring\nThe network ID.\n\nmac_addr\n\nbody\nstring\nThe MAC address.\n\ntag\n\nbody\nstring\n\nThe device tag applied to the virtual network interface or null.\nNew in version 2.70\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n501 - Not Implemented\n\nThe server either does not recognize the request method, or it lacks the ability to fulfill the request.\n\nExample{\r\n  \"interfaceAttachments\": [\r\n    {\r\n      \"port_state\": \"ACTIVE\",\r\n      \"fixed_ips\": [\r\n        {\r\n          \"subnet_id\": \"d52aa9f4-6a4b-4268-a71d-1a50f9b60aa9\", \r\n          \"ip_address\": \"10.136.18.138\"\r\n        }\r\n      ],\r\n      \"port_id\": \"bfc3228d-384e-4864-a583-54157225a4ef\",\r\n      \"net_id\": \"a1d8d6ae-c89d-4307-8a0c-3cc2ee55d7e3\",\r\n      \"mac_addr\": \"fa:16:3e:3b:0b:c3\"\r\n    },\r\n    {\r\n      \"port_state\": \"ACTIVE\",\r\n      \"fixed_ips\": [\r\n        {\r\n          \"subnet_id\": \"470526d3-ea5a-48fb-81ac-20273f005f61\", \r\n          \"ip_address\": \"192.168.128.10\"\r\n        }\r\n      ],\r\n      \"port_id\": \"ff9edb95-611f-4969-b98a-498f77c0326a\",\r\n      \"net_id\": \"0bb6b7a7-da8d-432c-b8d5-12139f7924d1\",\r\n      \"mac_addr\": \"fa:16:3e:8d:73:9f\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-network-interfaces-of-virtual-machines.html"
    },
    {
        "title": "Resetting the admin user password",
        "content": "Resetting the admin user password\nThe default administrator account has the user name admin and the password that is specified during the management node deployment. You can reset this password in case if you have forgotten it and you have access to the root account of the management node.\nTo reset the admin user password\n\nFind the management node in your cluster. To do this, log in to each cluster node via SSH and check if vstorage-ui-backend service is enabled by running:# systemctl list-unit-files | grep vstorage-ui-backend.service\r\nUNIT FILE                           STATE           PRESET\r\nvstorage-ui-backend.service         enabled         disabled\n\nOn the management node, log in as the service user:# su - vstoradmin\n\nRun the following command:\r\n$ python3 ~vstoradmin/manage.py admin --password \"<new_password>\"\r\n...\r\nCreating user \"admin\"\r\nOk\n\nNow, you can use the newly set password to log in to the admin panel under the admin user.\nSee also\n\nManaging admin panel users\n\nBest practices for cluster security\n\nSecuring root access to cluster nodes over SSH",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/resetting-the-admin-user-password.html"
    },
    {
        "title": "Listing flavors",
        "content": "Listing flavorsGET /flavors\r\n\nList all flavors accessible to the specified project.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=list-flavors-detail#list-flavors\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nsort_key (Optional)\nquery\nstring\n\nSorts by a flavor attribute. Default attribute is flavorid. You can specify\r\nmultiple pairs of sort key and sort direction query parameters. If you omit the\r\nsort direction in a pair, the API uses the natural sorting direction of the flavor\r\nsort_key attribute. The sort keys are limited to:\n\ncreated_at\n\ndescription\n\ndisabled\n\nephemeral_gb\n\nflavorid\n\nid\n\nis_public\n\nmemory_mb\n\nname\n\nroot_gb\n\nrxtx_factor\n\nswap\n\nupdated_at\n\nvcpu_weight\n\nvcpus\n\nsort_dir (Optional)\nquery\nstring\nSort direction. A valid value is asc (ascending) or desc (descending).\r\nDefault is asc. You can specify multiple pairs of sort key and sort direction\r\nquery parameters. If you omit the sort direction in a pair, the API uses the natural\r\nsorting direction of the direction of the flavor sort_key attribute.\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number of items up to a limit value.\r\nUse the limit parameter to make an initial limited request and use the ID\r\nof the last-seen item from the response as the marker parameter value in a\r\nsubsequent limited request.\n\nmarker (Optional)\nquery\nstring\nThe ID of the last-seen item. Use the limit parameter to make an initial limited\r\nrequest and use the ID of the last-seen item from the response as the marker\r\nparameter value in a subsequent limited request.\n\nminDisk (Optional)\nquery\ninteger\nFilters the response by a minimum disk space, in GiB. For example, 100.\n\nminRam (Optional)\nquery\ninteger\nFilters the response by a minimum RAM, in MiB. For example, 512.\n\nis_public (Optional)\nquery\nstring\nThis parameter is only applicable to users with the administrative role.\r\nFor all other non-admin users, the parameter is ignored and only public\r\nflavors will be returned. Filters the flavor list based on whether the\r\nflavor is public or private. If the value of this parameter is not\r\nspecified, it is treated as True. If the value is specified, 1,\r\nt, true, on, y and yes are treated as True. 0,\r\nf, false, off, n and no are treated as False\r\n(they are case-insensitive). If the value is None (case-insensitive)\r\nboth public and private flavors will be listed in a single request.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/flavors\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nflavors\n\nbody\narray\nAn array of flavor objects.\n\nname\n\nbody\nstring\nThe display name of a flavor.\n\ndescription\n\nbody\nstring\n\nThe description of the flavor.\nNew in version 2.55\n\nid\n\nbody\nstring\nThe ID of the flavor. While it may look like\r\nan integer, this is really a string.\n\nlinks\n\nbody\narray\nLinks to the resources in question. See API Guide / Links and\r\nReferences\r\nfor more info.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"flavors\": [\r\n    {\r\n      \"id\": \"100\",\r\n      \"links\": [\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/flavors/100\",\r\n          \"rel\": \"self\"\r\n        },\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/flavors/100\",\r\n          \"rel\": \"bookmark\"\r\n        }\r\n      ],\r\n      \"name\": \"tiny\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-flavors.html"
    },
    {
        "title": "How to use Infrastructure as Code tools on Virtuozzo Hybrid Infrastructure",
        "content": "How to use Infrastructure as Code tools on Virtuozzo Hybrid InfrastructureThis guide describes how to use Infrastructure as Code (IaC) tools, such as Ansible and Terraform, to deploy complex workloads on Virtuozzo Hybrid infrastructure by leveraging the OpenStack API.Using automation tools on Virtuozzo Hybrid InfrastructureAutomation tools allows you to define your Infrastructure as Code (virtual machines running on Virtuozzo Hybrid Infrastructure) and deploy complex architectures in an idempotent way (only perform changes that differ from the previous definition) by defining the IaC and application configuration as desired.The IaC and application configuration definitions are created by using simple YAML files, which are very easy to read and understand.As an example, you can have a repository to store the IaC and application configuration definitions for a web application by using such versioning tools as Git, GitLab, or Bitbucket. If you need to update or deploy a defined application in Virtuozzo Hybrid Infrastructure Cloud, you can clone the repository locally to your machine (if you don\u2019t have such a copy yet), create a branch, change any variable for the deployment customization, and then deploy the application. If you want to make any changes, for example, update a playbook in the YAML format that defines the installation of a package version, you can make this in your local repository, push the changes to your branch, and then seamlessly redeploy the application. Instead of pushing these changes directly to a production environment, you can have a staging project to test your changes before bringing them to production.Using versioning tools as a source for your files will track changes and allow you to rollback to the previous version, if needed. Additionally, when working in a team, you will be able to track who made the changes and what has been changed.Supported automation toolsAny automation tool that can leverage the OpenStack API can be used to automate workload deployment on Virtuozzo Hybrid Infrastructure.In this guide, you can find an example with Ansible and Terraform, as they are the most popular IaC tools. Chef, Puppet, Salt, and other tools, however, have modules that support OpenStack Cloud management.To learn more about Ansible and Terraform, refer to these articles:Ansible Modules for OpenStack APITerraform RegistryIn this section:Infrastructure management with Terraform",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/infrastructure-as-code-on-vhi/"
    },
    {
        "title": "Enabling CPU\u00a0and RAM hot plug per domain",
        "content": "Enabling CPU\u00a0and RAM hot plug per domain\nTo allow self-service users to add more CPU and RAM resources to virtual machines at run time, you can enable CPU and RAM hot plug for a particular domain. In domains that have this feature disabled, users will need to stop a virtual machine first, to be able to change its flavor. By default, CPU and RAM hot plug is disabled for all domains.\nTo enable CPU and RAM hot plug for a domain\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > CPU and RAM hot plug screen, and then enable CPU and RAM hot plug.\n\nCommand-line interface\nUse the following command:vinfra domain properties create --key <key> --data <data> [--access <access>] <domain>\n\n--key <key>\n\nKey name\n--data <data>\n\nProperty sheet. Should be a valid JSON object.\n--access <access>\n\nAccess type:\n\npub: grant read access to all users (authentication is not required)\nauth: grant read access to authenticated users\ndomain: grant read access to domain users\n\nThe superadmin and domain admin have write access.\n\n<domain>\n\nDomain name or ID\n\nFor example, to create the property allow_live_resize that enables CPU and RAM hot plug for virtual machines within the domain mydomain, run:# vinfra domain properties create --key allow_live_resize mydomain --data '{\"enabled\":true}'\nThe created property will appear in the vinfra domain properties keys list output:# vinfra domain properties keys list\r\n+----------+---------------------+\r\n| domain   | keys                |\r\n+----------+---------------------+\r\n| mydomain | - allow_live_resize |\r\n| Default  | - allow_live_resize |\r\n+----------+---------------------+\r\n\n\nTo disable CPU and RAM hot plug for a domain\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > CPU and RAM hot plug screen, and then disable CPU and RAM hot plug.\n\nCommand-line interface\nUse the following command:vinfra domain properties update --key <key> --data <data> [--access <access>] <domain>\n\n--key <key>\n\nKey name\n--data <data>\n\nProperty sheet. Should be a valid JSON object.\n--access <access>\n\nAccess type:\n\npub: grant read access to all users (authentication is not required)\nauth: grant read access to authenticated users\ndomain: grant read access to domain users\n\nThe superadmin and domain admin have write access.\n\n<domain>\n\nDomain name or ID\n\nFor example, to change the property allow_live_resize to disable CPU and RAM hot plug for virtual machines within the domain mydomain, run:# vinfra domain properties update --key allow_live_resize mydomain \\\r\n--data '{\"enabled\": false}'\n\nSee also\n\nManaging domains\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain properties create --key <key> --data <data> [--access <access>] <domain>\n\n--key <key>\n\nKey name\n--data <data>\n\nProperty sheet. Should be a valid JSON object.\n--access <access>\n\n\nAccess type:\n\npub: grant read access to all users (authentication is not required)\nauth: grant read access to authenticated users\ndomain: grant read access to domain users\n\n\n\nThe superadmin and domain admin have write access.\n\n<domain>\n\nDomain name or ID\n\nFor example, to create the property allow_live_resize that enables CPU and RAM hot plug for virtual machines within the domain mydomain, run:# vinfra domain properties create --key allow_live_resize mydomain --data '{\"enabled\":true}'\nThe created property will appear in the vinfra domain properties keys list output:# vinfra domain properties keys list\r\n+----------+---------------------+\r\n| domain   | keys                |\r\n+----------+---------------------+\r\n| mydomain | - allow_live_resize |\r\n| Default  | - allow_live_resize |\r\n+----------+---------------------+\r\n\n",
                "title": "To enable CPU and RAM hot plug for a domain"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain properties update --key <key> --data <data> [--access <access>] <domain>\n\n--key <key>\n\nKey name\n--data <data>\n\nProperty sheet. Should be a valid JSON object.\n--access <access>\n\n\nAccess type:\n\npub: grant read access to all users (authentication is not required)\nauth: grant read access to authenticated users\ndomain: grant read access to domain users\n\n\n\nThe superadmin and domain admin have write access.\n\n<domain>\n\nDomain name or ID\n\nFor example, to change the property allow_live_resize to disable CPU and RAM hot plug for virtual machines within the domain mydomain, run:# vinfra domain properties update --key allow_live_resize mydomain \\\r\n--data '{\"enabled\": false}'\n",
                "title": "To disable CPU and RAM hot plug for a domain"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > CPU and RAM hot plug screen, and then enable CPU and RAM hot plug.\n\n",
                "title": "To enable CPU and RAM hot plug for a domain"
            },
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > CPU and RAM hot plug screen, and then disable CPU and RAM hot plug.\n\n",
                "title": "To disable CPU and RAM hot plug for a domain"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-cpu-and-ram-hot-plug.html"
    },
    {
        "title": "Installing in the unattended mode",
        "content": "Installing in the unattended mode\nIf you plan to perform an unattended installation of Virtuozzo Hybrid Infrastructure, you can use a kickstart file. It will automatically supply the installer with the options you would normally choose by hand. \nPrerequisites\n\nA PXE server is prepared, as outlined in Setting up a PXE server.\nA kickstart file is created by using the options and scripts described in Creating a kickstart file.\n\nTo install in the unattended mode\n\nMake the kickstart file accessible over the network:\n\nCopy the kickstart file to the same directory on the HTTP server where the Virtuozzo Hybrid Infrastructure installation files are stored (for example, to /var/www/html/stor).\n\nAdd the following string to the /tftpboot/pxelinux.cfg/default file on the PXE server:inst.ks=<HTTP_server_address>/<path_to_kickstart_file>\nFor EFI-based systems, the file you need to edit has the name of /tftpboot/pxelinux.cfg/efidefault or /tftpboot/pxelinux.cfg/<PXE_server_IP_address>.\nAssuming that the HTTP server has the IP address of 198.123.123.198, the DocumentRoot directory is set to /var/www/html, and the full path to your kickstart file on this server is /var/www/html/stor/ks.cfg, your default file may look like the following:default menu.c32prompt 0timeout 100ontimeout ASTORmenu title Boot Menulabel ASTOR        menu label Install        kernel vmlinuz        append initrd=initrd.img ip=dhcp inst.repo=http://198.123.123.198/stor inst.ks=http://198.123.123.198/stor/ks.cfg\n\nConfigure the server to boot from the chosen media.\nBoot the server and wait for the Welcome screen.\nOn the Welcome screen, select Install Virtuozzo Hybrid Infrastructure and press E to edit the menu entry.\n\nAppend the kickstart file location to the linux /images/pxeboot/vmlinuz line, and press Ctrl+X. For example:linux /images/pxeboot/vmlinuz inst.stage2=hd:LABEL=<ISO_img> quiet ip=dhcp logo.nologo=1 inst.ks=<URL>\r\n\n\nThe installation will proceed automatically. Once it is complete, the node will reboot automatically. The admin panel IP address will be shown in the welcome prompt.\nWhat's next\n\nAfter installation on the primary node\n\nIf you installed the admin panel and storage components without exposing the superadmin password and storage token in the kickstart file, do the following:\n\nOn the node, run the following command as the root user to configure the admin panel component:echo <password> | /usr/libexec/vstorage-ui-backend/bin/configure-backend.sh -i <private_iface> -x <public_iface>\r\n\nwhere\n\n<password> is the password of the superadmin account for the admin panel\n<private_iface> is the name of the private network interface (the one you would select for the management network during attended installation)\n<public_iface> is the name of the public network interface (the one you would select for the admin panel network during attended installation)\n\nStart the admin panel service on the node:# systemctl start vstorage-ui-backend\r\n\n\nRegister the node in the admin panel:# /usr/libexec/vstorage-ui-agent/bin/register-storage-node.sh -m <MN_IP_address> -x <public_iface>\r\n\nwhere \n\n<MN_IP_address> is the IP address of the node's private network interface\n<public_iface> is the name of the public network interface\n\nNow you can proceed to deploying secondary nodes.\n\nAfter installation on a secondary node\n\nIf you installed the storage component without exposing the storage token in the kickstart file, run the following script on the node,  to register it in the admin panel:# /usr/libexec/vstorage-ui-agent/bin/register-storage-node.sh -m <MN_IP_address> -t <token>\r\n\nwhere\n\n<MN_IP_address> is the IP address of the private network interface on the node with the admin panel\n<token> is the token obtained in the admin panel or from the vinfra node token show output\n\nWhen all the required nodes are displayed in the admin panel on the Infrastructure > Nodes screen as Unassigned, proceed to create the storage cluster, as outlined in Deployment and configuration.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/installing-in-the-unattended-mode.html"
    },
    {
        "title": "Managing volume snapshots in Kubernetes",
        "content": "Managing volume snapshots in Kubernetes\nYou can create a snapshot of a Kubernetes volume to copy its contents at a specific moment in time. This can be useful for restoring volume data in case of data loss.\nVolume snapshots are based on custom resource definitions (CRD), so you need to add them to your Kubernetes cluster first.\nPrerequisites\n\nA persistent volume claim is created, as described in Dynamically provisioning persistent volumes.\n\nTo add custom resource definitions\nRun the following commands:# git clone https://github.com/kubernetes-csi/external-snapshotter/\r\ncd ./external-snapshotter\r\n# git checkout release-5.0\r\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml\r\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml\r\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml\r\n# kubectl apply -f deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml -n kube-system\r\n# kubectl apply -f deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml -n kube-system\n\nThe CSI snapshotter version must not be higher than release-5.0.\n\nThese commands will create CRDs for VolumeSnapshotClass, VolumeSnapshotContent, VolumeSnapshot, as well as required ClusterRole, ServiceAccount, ClusterRoleBinding, Role, RoleBinding, and finally the snapshot-controller deployment.\nYou can check that the required resources are successfully created by using Lens, an easy tool for managing Kubernetes clusters and resources.\nTo create a volume snapshot\n\nCreate the snapshot-class.yaml file that defines the VolumeSnapshotClass object:cat > snapshot-class.yaml <<\\EOT\r\napiVersion: snapshot.storage.k8s.io/v1\r\nkind: VolumeSnapshotClass\r\nmetadata:\r\n  name: mysnapclass\r\ndriver: cinder.csi.openstack.org\r\ndeletionPolicy: Delete\r\nparameters:\r\n  force-create: \"true\"\r\nEOT\nThis manifest describes the volume snapshot class mysnapclass with the deletion policy Delete. This policy allows deleting the underlying storage snapshot along with the VolumeSnapshotContent object. To keep both the underlying snapshot and VolumeSnapshotContent when deleting the VolumeSnapshot object, set the deletion policy to Retain.\n\nCreate a snapshot class:$ kubectl apply -f snapshot-class.yaml \r\nvolumesnapshotclass.snapshot.storage.k8s.io/mysnapclass created\n\nCreate the snapshot.yaml file that defines the VolumeSnapshot\r\nobject:cat > snapshot.yaml <<\\EOT\r\napiVersion: snapshot.storage.k8s.io/v1\r\nkind: VolumeSnapshot\r\nmetadata:\r\n  name: mysnapshot\r\nspec:\r\n  volumeSnapshotClassName: mysnapclass\r\n  source:\r\n    persistentVolumeClaimName: mypvc\r\nEOT\nThis manifest specifies the volume snapshot mysnapshot that uses the volume snapshot class mysnapclass\r\nand creates a snapshot of the previously created volume bound to the persistent volume claim mypvc.\n\nCreate a volume snapshot:$ kubectl create -f snapshot.yaml \r\nvolumesnapshot.snapshot.storage.k8s.io/mysnapshot created\nIn the self-service panel, you can find the newly created snapshot mysnapshot on the Compute -> Volumes -> <pv_name> -> Snapshots tab.\n\nTo delete a volume snapshot\nRun the following command:$ kubectl delete -f snapshot.yaml \r\nvolumesnapshot.snapshot.storage.k8s.io \"mysnapshot\" deleted",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-volume-snapshots-in-kubernetes.html"
    },
    {
        "title": "Deploying the storage cluster",
        "content": "Deploying the storage cluster\nCreate the storage cluster on one (the first) node, then populate it with more nodes.\nLimitations\n\nYou can assign a role to a disk only if its size is greater than 1 GiB.\nYou can assign an additional role to a system disk only if its size is at least 100 GiB.\nIt is recommended to assign the System and Metadata roles to either an SSD disk or different HDDs. Assigning both of these roles to the same HDD disk will result in mediocre performance suitable only for cold data (for example, archiving).\nThe System role cannot be combined with the Cache and Metadata+Cache roles. The reason is that the I/O generated by the operating system and applications would contend with the I/O generated by journaling, thus negating its performance benefits.\nYou can use shingled magnetic recording (SMR) HDDs only with the Storage role and only if the node has an SSD disk with the Cache role. Host-managed SMR disks are not supported.\nYou cannot use SMR and standard disks in the same tier.\nYou cannot assign roles to system and non-system disks at a time.\n\nPrerequisites\n\nA clear understanding of the storage cluster architecture and disk roles, which are explained in About the storage cluster.\n A clear understanding of the concept Storage tiers.\nYour infrastructure networks are set up, as described in Setting up networks.\nThe node network interfaces are configured by following the instructions in Configuring node network interfaces.\n If  supported, RDMA  is enabled, as described in Enabling RDMA.\nIf your infrastructure nodes are equipped with NVMe or SSD disks, it is recommended to enable NVMe performance, as described in Configuring NVMe performance.\nExternal DNS servers are added automatically during the installation or manually, as described in Adding external DNS servers.\nLocations for your nodes are configured, as explained in Configuring node locations.\nAll of the nodes are shown in the admin panel on the Infrastructure > Nodes screen with the Unassigned status.\n\nTo create the storage cluster on the first node\n\nAdmin panel\n\nOpen the Infrastructure > Nodes screen, and then click Create storage cluster.\nIn the Create storage cluster window, enter a name for the cluster. The cluster name may only contain Latin letters (a-z, A-Z), numbers (0-9), and hyphens (\"-\"). It must start with a letter and end with a letter or number.\n\nEnable disk encryption for tiers. You can also enable it later.\n\nSelect one node to create the storage cluster from, and then click Next.\n\nIn the next window, check the default disk configuration. If it is correct, proceed to create the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks.\n\nTo assign roles to disks manually, do the following:\n\n[Only for SSD drives] To store write cache\n\nSelect the Cache role.\nSelect a storage tier that you want to cache.\n\nFor storage disks to use cache, the Cache role must be assigned before the Storage role. You can also assign both of these roles to disks at the same time, and the system will configure the cache disk first.\n\nTo store data\n\nSelect the Storage role.\nSelect a storage tier where to store your data. To make better use of data redundancy, do not assign all of the disks on a node to the same tier. Instead, make sure that each tier is evenly distributed across the cluster.\n\nEnable data caching and checksumming:\n\nEnable SSD caching and checksumming. Available and recommended only for nodes with SSDs.\nEnable checksumming (default). Recommended for nodes with HDDs as it provides better reliability.\nDisable checksumming. Not recommended for production. For an evaluation or testing environment, you can disable checksumming for nodes with HDDs, to provide better performance.\n\nTo store cluster metadata\n\nSelect the Metadata role.\n\nIt is recommended to have only one disk with the Metadata role per node and maximum five such disks in a cluster.\n\n[Only for SSD drives] To store both metadata and write cache\n\nSelect the Metadata+Cache role.\nSelect a storage tier that you want to cache.\n\nTo assign roles to disks automatically, click Disk actions > Configure automatically.\nTo assign a role to multiple disks at a time, click Disk actions > Bulk disk management, select disks, and then click Assign role. Choose the desired role for the selected disks, and then click Assign.\nTo reset the disk configuration, click Disk actions > Clear configuration.\n\nOnce you finish configuring the disks, click Create, to create the storage cluster.\n\nYou can monitor cluster creation on the Infrastructure > Nodes screen. The creation might take some time, depending on the number of disks to be configured. Once the configuration is complete, the cluster is created.\n\nCommand-line interface\nUse the following command:vinfra cluster create [--disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]] [--tier-encryption {0,1,2,3}]\r\n                      --node <node> <cluster-name>\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--tier-encryption {0,1,2,3}\n\nEnable encryption for storage cluster tiers. Encryption is disabled by default. This option can be used multiple times.\n--node <node>\n\nNode ID or hostname\n<cluster-name>\n\nStorage cluster name\n\nFor example, to create the storage cluster stor1 on the node node001, run:# vinfra cluster create stor1 --node node001\nAs disk roles are not explicitly specified, they are assigned automatically: mds-system to the system disk, and cs to all other disks.\nYou can view the storage cluster details in the vinfra cluster show output:# vinfra cluster show\r\n+-------+--------------------------------------------+\r\n| Field | Value                                      |\r\n+-------+--------------------------------------------+\r\n| id    | 1                                          |\r\n| name  | stor1                                      |\r\n| nodes | - host: node001.vstoragedomain             |\r\n|       |   id: f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4 |\r\n|       |   is_installing: false                     |\r\n|       |   is_releasing: false                      |\r\n+-------+--------------------------------------------+\r\n\n\nTo add nodes to the cluster\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click an unassigned node.\nOn the node right pane, click Join to cluster.\n\nIn the Join node to storage cluster window, check the default disk configuration. If it is correct, proceed to join the node to the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks. Alternatively, you can copy the disk configuration from another node by clicking Copy configuration from and selecting the desired node.\n\nOnce you finish configuring the disks, click Join, to add the node to the storage cluster.\n\nCommand-line interface\nUse the following command:vinfra node join [--disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]] <node>\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n<node>\n\nNode ID or hostname\n\nFor example, to add the node node002 to the storage cluster and assign roles to disks: mds-system to sda, cs to sdb and sdc, run:# vinfra node join f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4 --disk sda:mds-system \\\r\n--disk sdb:cs --disk sdc:cs\nThe added node will appear in the vinfra node list output:# vinfra node list\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| id           | host         | is_primary | is_online | is_assigned | is_in_ha |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| 09bb6b8<...> | node001<...> | True       | True      | True        | False    |\r\n| 187edb1<...> | node002<...> | False      | True      | True        | False    |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n\n\nSee also\n\nScaling the storage cluster\n\nMonitoring the storage cluster\n\nWhat's next\n\nEnabling management node high availability\n\nConfiguring multitenancy",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster create [--disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]] [--tier-encryption {0,1,2,3}]\r\n                      --node <node> <cluster-name>\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--tier-encryption {0,1,2,3}\n\nEnable encryption for storage cluster tiers. Encryption is disabled by default. This option can be used multiple times.\n--node <node>\n\nNode ID or hostname\n<cluster-name>\n\nStorage cluster name\n\nFor example, to create the storage cluster stor1 on the node node001, run:# vinfra cluster create stor1 --node node001\nAs disk roles are not explicitly specified, they are assigned automatically: mds-system to the system disk, and cs to all other disks.\nYou can view the storage cluster details in the vinfra cluster show output:# vinfra cluster show\r\n+-------+--------------------------------------------+\r\n| Field | Value                                      |\r\n+-------+--------------------------------------------+\r\n| id    | 1                                          |\r\n| name  | stor1                                      |\r\n| nodes | - host: node001.vstoragedomain             |\r\n|       |   id: f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4 |\r\n|       |   is_installing: false                     |\r\n|       |   is_releasing: false                      |\r\n+-------+--------------------------------------------+\r\n\n",
                "title": "To create the storage cluster on the first node"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node join [--disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]] <node>\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n<node>\n\nNode ID or hostname\n\nFor example, to add the node node002 to the storage cluster and assign roles to disks: mds-system to sda, cs to sdb and sdc, run:# vinfra node join f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4 --disk sda:mds-system \\\r\n--disk sdb:cs --disk sdc:cs\nThe added node will appear in the vinfra node list output:# vinfra node list\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| id           | host         | is_primary | is_online | is_assigned | is_in_ha |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n| 09bb6b8<...> | node001<...> | True       | True      | True        | False    |\r\n| 187edb1<...> | node002<...> | False      | True      | True        | False    |\r\n+--------------+--------------+------------+-----------+-------------+----------+\r\n\n",
                "title": "To add nodes to the cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen the Infrastructure > Nodes screen, and then click Create storage cluster.\nIn the Create storage cluster window, enter a name for the cluster. The cluster name may only contain Latin letters (a-z, A-Z), numbers (0-9), and hyphens (\"-\"). It must start with a letter and end with a letter or number.\n\nEnable disk encryption for tiers. You can also enable it later.\n\n\nSelect one node to create the storage cluster from, and then click Next.\n\n\n\n\n\n\nIn the next window, check the default disk configuration. If it is correct, proceed to create the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks.\n\n\nTo assign roles to disks manually, do the following:\n\n\n[Only for SSD drives] To store write cache\n\n\nSelect the Cache role.\nSelect a storage tier that you want to cache.\n\n\nFor storage disks to use cache, the Cache role must be assigned before the Storage role. You can also assign both of these roles to disks at the same time, and the system will configure the cache disk first.\n\n\n\n\n\nTo store data\n\n\nSelect the Storage role.\nSelect a storage tier where to store your data. To make better use of data redundancy, do not assign all of the disks on a node to the same tier. Instead, make sure that each tier is evenly distributed across the cluster.\n\nEnable data caching and checksumming:\n\nEnable SSD caching and checksumming. Available and recommended only for nodes with SSDs.\nEnable checksumming (default). Recommended for nodes with HDDs as it provides better reliability.\nDisable checksumming. Not recommended for production. For an evaluation or testing environment, you can disable checksumming for nodes with HDDs, to provide better performance.\n\n\n\n\n\n\n\nTo store cluster metadata\n\nSelect the Metadata role.\n\nIt is recommended to have only one disk with the Metadata role per node and maximum five such disks in a cluster.\n\n\n\n\n\n[Only for SSD drives] To store both metadata and write cache\n\n\nSelect the Metadata+Cache role.\nSelect a storage tier that you want to cache.\n\n\n\n\n\n\n\n\n\n\nTo assign roles to disks automatically, click Disk actions > Configure automatically.\nTo assign a role to multiple disks at a time, click Disk actions > Bulk disk management, select disks, and then click Assign role. Choose the desired role for the selected disks, and then click Assign.\nTo reset the disk configuration, click Disk actions > Clear configuration.\n\n\nOnce you finish configuring the disks, click Create, to create the storage cluster.\n\nYou can monitor cluster creation on the Infrastructure > Nodes screen. The creation might take some time, depending on the number of disks to be configured. Once the configuration is complete, the cluster is created.\n",
                "title": "To create the storage cluster on the first node"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click an unassigned node.\nOn the node right pane, click Join to cluster.\n\nIn the Join node to storage cluster window, check the default disk configuration. If it is correct, proceed to join the node to the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks. Alternatively, you can copy the disk configuration from another node by clicking Copy configuration from and selecting the desired node.\n\nOnce you finish configuring the disks, click Join, to add the node to the storage cluster.\n\n",
                "title": "To add nodes to the cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/deploying-the-storage-cluster.html"
    },
    {
        "title": "Changing the storage tier for S3 metadata",
        "content": "Changing the storage tier for S3 metadata\nTo improve S3 storage performance, you can place NS and OS journals on a faster storage tier than is used for data. The amount of space required for S3 metadata on a separate tier can be calculated as 0.5% \u00e2\u0080\u0093 1% of S3 data size.\nPrerequisites\n\nA clear understanding of the concept Storage tiers.\nThe S3 cluster is created, as described in Creating the S3 cluster.\n\nTo change the storage tier for S3 metadata\n\nAdmin panel\n\n Open the Storage services > S3 > Settings screen, and then click Storage policies.\nIn the Metadata storage policy section, select the desired storage tier.\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra service s3 cluster change [--metadata-tier {0,1,2,3}]\n\n--metadata-tier {0,1,2,3}\n\nStorage tier\n\nFor example, to change the storage tier to 2 for S3 metadata, run:# vinfra service s3 cluster change --metadata-tier 2\nThe updated parameters will be shown in the vinfra service s3 show output:# vinfra service s3 show\r\n+-----------------+--------------------------------------------+\r\n| Field           | Value                                      |\r\n+-----------------+--------------------------------------------+\r\n| failure_domain  | 1                                          |\r\n| id              | 0100000000000002                           |\r\n| metadata_policy | failure_domain: 1                          |\r\n|                 | redundancy:                                |\r\n|                 |   m: 1                                     |\r\n|                 |   n: 2                                     |\r\n|                 |   type: raid6                              |\r\n|                 | tier: 2                                    |\r\n| name            | cluster1                                   |\r\n| nodes           | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                 | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n| np              |                                            |\r\n| nusers          | 0                                          |\r\n| protocol        | scheme: https                              |\r\n| redundancy      | m: 1                                       |\r\n|                 | n: 2                                       |\r\n|                 | type: raid6                                |\r\n| s3gw_domain     | dns.example.com                            |\r\n| tier            | 0                                          |\r\n+-----------------+--------------------------------------------+\n\nSee also\n\nChanging the redundancy scheme for S3 data\n\nChanging S3 protocol settings\n\nChanging the TLS configuration for S3\n\nReplicating S3 data between datacenters",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 cluster change [--metadata-tier {0,1,2,3}]\n\n--metadata-tier {0,1,2,3}\n\nStorage tier\n\nFor example, to change the storage tier to 2 for S3 metadata, run:# vinfra service s3 cluster change --metadata-tier 2\nThe updated parameters will be shown in the vinfra service s3 show output:# vinfra service s3 show\r\n+-----------------+--------------------------------------------+\r\n| Field           | Value                                      |\r\n+-----------------+--------------------------------------------+\r\n| failure_domain  | 1                                          |\r\n| id              | 0100000000000002                           |\r\n| metadata_policy | failure_domain: 1                          |\r\n|                 | redundancy:                                |\r\n|                 |   m: 1                                     |\r\n|                 |   n: 2                                     |\r\n|                 |   type: raid6                              |\r\n|                 | tier: 2                                    |\r\n| name            | cluster1                                   |\r\n| nodes           | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                 | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n| np              |                                            |\r\n| nusers          | 0                                          |\r\n| protocol        | scheme: https                              |\r\n| redundancy      | m: 1                                       |\r\n|                 | n: 2                                       |\r\n|                 | type: raid6                                |\r\n| s3gw_domain     | dns.example.com                            |\r\n| tier            | 0                                          |\r\n+-----------------+--------------------------------------------+\n",
                "title": "To change the storage tier for S3 metadata"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n Open the Storage services > S3 > Settings screen, and then click Storage policies.\nIn the Metadata storage policy section, select the desired storage tier.\nClick Save to apply your changes.\n\n",
                "title": "To change the storage tier for S3 metadata"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-s3-metadata-storage-tier.html"
    },
    {
        "title": "Managing users",
        "content": "Managing users",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-users.html"
    },
    {
        "title": "Querying bucket limits via CLI",
        "content": "Querying bucket limits via CLI\nYou can display the current limits with the query-limits command and parameter -b specifying the bucket name:# ostor-s3-admin query-limits -b example\r\nops:default=0.00ops/s\r\nops:get=3600.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=100kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-bucket-limits-via-cli.html"
    },
    {
        "title": "Getting Started",
        "content": "Getting StartedQuick Start GuideInstallation GuideAdministrator GuideSelf-Service GuideStorage User GuideCompute API ReferenceObject Storage Orchestration API ReferenceRelease NotesProduct Lifecycle Policy",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/getting-started/"
    },
    {
        "title": "Connecting to virtual machines",
        "content": "Connecting to virtual machines\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\nTo be able to connect via SSH, the virtual machine must have cloud-init and OpenSSH installed. \n\nTo connect to a virtual machine via the VNC console\nSelect a VM, and then click Console on its right pane. The console will open in a separate browser window. In the console, you can send a key combination to a VM, take a screenshot of the console window, and download the console log (refer to Troubleshooting virtual machines).\nTo connect to a virtual machine via SSH\nSpecify the username and VM IP address in the SSH terminal:# ssh <username>@<VM_IP_address>\r\n\nLinux cloud images have the default login, depending on the operating system, for example, centos or ubuntu. To connect to a Windows VM, enter the username that you specified during Cloudbase-Init installation.\nIf you have deployed a VM without specifying an SSH key, you also need to enter a password to log in to the VM.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/connecting-to-virtual-machines.html"
    },
    {
        "title": "Core storage metrics",
        "content": "Core storage metrics\nMetrics used for monitoring core storage are configured in the Prometheus recording rules and can be found in these files on any node in the cluster:\n\n/var/lib/prometheus/rules/mdsd.rules\n\n/var/lib/prometheus/rules/csd.rules\n\n/var/lib/prometheus/rules/fused.rules\n\n/var/lib/prometheus/rules/rjournal.rules\n\nMetrics that are used to generate core storage alerts are added to the alerting rules in /var/lib/prometheus/alerts/pcs.rules. These metrics are described in the table:\n\nMetric\nDescription\n\nfused_stuck_reqs_30s\n\nNumber of stuck I/O requests on a node for more than 30 seconds\n\nfused_stuck_reqs_10s\n\nNumber of stuck I/O requests on a node for more than 10 seconds\n\nfused_maps_failed\n\nNumber of failed map requests on a node\n\nfused_map_failures_total\n\nTotal number of failed map requests on a node\n\nfused_unaligned_writes:rate5m\n\nNumber of unaligned write requests per second for 5 minutes\n\nfused_writes:rate5m\n\nNumber of write requests per second for 5 minutes\n\nfused_unaligned_reads:rate5m\n\nNumber of unaligned read requests per second for 5 minutes\n\nfused_reads:rate5m\n\nNumber of read requests per second for 5 minutes\n\nmdsd_cluster_replication_stuck_chunks\n\nNumber of chunks that block replication\n\nmdsd_cluster_replication_touts_total\n\nTotal number of chunks that slow down replication\n\nmdsd_fs_chunk_maps\n\nNumber of chunks in the storage cluster\n\nmdsd_fs_files\n\nNumber of user-visible files in the storage cluster\n\nmdsd_fs_file_nodes\n\nTotal number of files in the storage cluster\n\nmaster:mdsd_cs_status\n\nChunk service status\n\nmdsd_cluster_free_space_bytes\n\nAmount of free physical space in the storage cluster\n\nmdsd_cluster_space_bytes\n\nTotal amount of physical space in the storage cluster\n\nmdsd_is_master\n\nNode that runs the master metadata service\n\nmdsd_master_uptime\n\nMaster metadata uptime\n\ninstance_le:rjournal_commit_duration_seconds_bucket:rate5m\n\nCurrent commit latency by a particular metadata service for 5 minutes, for each bucket\n\ninstance_csid:csd_journal_usage_ratio:rate5m\n\nPercentage of free space for a chunk service journal for 5 minutes\n\nprocess_cpu_seconds_total\n\nTotal amount of time a process has used CPU\n\nprocess_swap_bytes\n\nAmount of swap space used by a process\n\nstorage_policy_allocatable_space\n\nAmount of allocatable space per storage policy\n\nThe Prometheus recording rules also include metrics that are used for monitoring the following processes:\n\nReplication is a process of restoring redundancy of data.\nRe-encoding is a process of changing redundancy of files with erasure coding.\nRebalancing is a process that moves data from one place to another.\n\nThese metrics are described in the table:\n\nMetric\nDescription\n\nmdsd_cluster_to_replicate_chunks\n\nNumber of chunks that need to be replicated\n\nmdsd_cluster_replicated_chunks\n\nTotal number of replicated chunks\n\nmdsd_cluster_replication_touts\n\nTotal number of timed out replications\n\nmdsd_cluster_replication_stuck_chunks\n\nNumber of chunks with last replication attempt failed\n\nmdsd_cluster_rebalance_pending_chunks\n\nNumber of chunks that need to be rebalanced\n\nmdsd_enc_pending_files\n\nNumber of files with re-encoding pending\n\nmdsd_enc_pending_bytes\n\nEstimated physical size of files to be re-encoded (excluding punch-holed data)\n\nmdsd_enc_pending_raw\n\nEstimated physical size of files to be re-encoded as a sum of sizes of involved chunks\n\nfused_ls_gc_reencoding_chunks\n\nAmount of chunks being re-encoded at this time\n\nfused_ls_gc_reencoded_bytes\n\nTotal amount of data re-encoded\n\nSee also\n\nCore storage alerts\n\nObject storage metrics\n\nBackup storage metrics\n\nCompute metrics\n\nCluster update metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/storage-metrics.html"
    },
    {
        "title": "Changing the redundancy scheme for backup storage",
        "content": "Changing the redundancy scheme for backup storage\nYou can update the redundancy scheme used for backup storage by changing the storage policy. Such a configurable redundancy scheme ensures high scalability and maximum efficiency of backup storage.\nDuring the re-encoding process, data is partially stored with a new redundancy scheme, and the other part is stored with an old scheme. However, the system uses the  storage policy with the least redundancy. For example, if you are switching from the 1+0 encoding mode to 1+2, the system will use the 1+0 encoding mode. In this case, it is critical not to turn off any storage node or disk until the process is complete.\nNote that the reported size of backup archives and their space usage in Acronis Cyber Protect Cloud change during and after the re-encoding process. During re-encoding, the size of backup archives increases for a short period of time. At some point, it may reach 120% of the initial size. After re-encoding, the reported size of backup archives and their space usage are usually lower than the initial values. This happens due to distribution optimization of storage chunks that is performed in addition to physical chunks optimization. The average difference between the initial backup size and its size after re-encoding is 10%.\nIf you changed the encoding scheme for your backup storage cluster with the help of the technical support team, re-apply your redundancy settings in the admin panel to ensure that all data was encoded.\nLimitations\n\nRedundancy by replication is not supported for backup storage. \n\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nThe backup storage cluster is created and registered in the Cloud Management Panel, as described in Provisioning Acronis Backup Storage space.\n\nTo change the storage policy\n\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Settings tab, and then click Storage policy.\n\nSelect the desired storage tier, failure domain, or data redundancy mode.\n\nClick Save.\n\nWhen the re-encoding process starts, its progress and the estimated time of completion will be shown on the screen. During this process, you can select another redundancy scheme. In this case, the current re-encoding process will be stopped and the new redundancy scheme will be applied.\n\nCommand-line interface\nUse the following command:vinfra service backup volume-params change [--tier {0,1,2,3}]\r\n                                           [--encoding <M>+<N>]\r\n                                           [--failure-domain {disk,host,rack,row,room}]\r\n\n\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n\nFor example, to change the storage tier to 0, the erasure coding scheme to 1+2, and the failure domain to host, run:# vinfra service backup volume-params change --tier 0 --encoding 1+2 \\\r\n--failure-domain host\nThe updated parameters will be shown in the vinfra service backup volume-params show output:# vinfra service backup volume-params show\r\n+----------------+-------------+\r\n| Field          | Value       |\r\n+----------------+-------------+\r\n| failure_domain | host        |\r\n| redundancy     | m: 1        |\r\n|                | n: 2        |\r\n|                | type: raid6 |\r\n| tier           | 0           |\r\n+----------------+-------------+\r\n\n\nSee also\n\nManaging registrations for backup storage\n\nManaging geo-replication for backup storage\n\nConfiguring throttling for backup storage\n\nChanging TLS configuration for backup storage\n\nMonitoring Acronis Backup Storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup volume-params change [--tier {0,1,2,3}]\r\n                                           [--encoding <M>+<N>]\r\n                                           [--failure-domain {disk,host,rack,row,room}]\r\n\n\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n\nFor example, to change the storage tier to 0, the erasure coding scheme to 1+2, and the failure domain to host, run:# vinfra service backup volume-params change --tier 0 --encoding 1+2 \\\r\n--failure-domain host\nThe updated parameters will be shown in the vinfra service backup volume-params show output:# vinfra service backup volume-params show\r\n+----------------+-------------+\r\n| Field          | Value       |\r\n+----------------+-------------+\r\n| failure_domain | host        |\r\n| redundancy     | m: 1        |\r\n|                | n: 2        |\r\n|                | type: raid6 |\r\n| tier           | 0           |\r\n+----------------+-------------+\r\n\n",
                "title": "To change the storage policy"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Settings tab, and then click Storage policy.\n\nSelect the desired storage tier, failure domain, or data redundancy mode.\n\n\n\n\n\nClick Save.\n\nWhen the re-encoding process starts, its progress and the estimated time of completion will be shown on the screen. During this process, you can select another redundancy scheme. In this case, the current re-encoding process will be stopped and the new redundancy scheme will be applied.\n",
                "title": "To change the storage policy"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-redundancy-scheme-for-backup-storage.html"
    },
    {
        "title": "Renewing encryption certificates",
        "content": "Renewing encryption certificates\nEncryption certificates, except for CA certificates, are automatically rotated on all cluster nodes upon their expiration, that is, once per year. If a certificate is compromised, you need to replace it manually.\nTo manually renew IPsec certificates\nUse the following command:vinfra node certificate ipsec renew <node>\n\n<node>\n\nNode ID or hostname\n\nFor example, to renew certificates for the node node1, run:vinfra node certificate ipsec renew node1\nSee also\n\nEnabling and disabling data-in-transit encryption\n\nManaging encryption exceptions",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/renewing-encryption-certificates.html"
    },
    {
        "title": "Managing domains",
        "content": "Managing domains\nYou can add more domains, as described in Configuring multitenancy. Also, you can edit domain details and quotas, as well as enable/disable and delete the existing domains. Disabling and enabling domains allows or prohibits access to domains in the self-service panel.\nLimitations\n\nYou can set domain quotas only after deploying the compute cluster.\nYou cannot configure domain quotas for floating IP addresses, VPN connections, load balancers, Kubernetes clusters, and placements.\nA domain cannot be deleted if it has projects.\n\nTo edit a domain name or description\n\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nCommand-line interface\nUse the following command:vinfra domain set [--description <description>] [--name <name>] <domain>\r\n\n\n--description <description>\n\nDomain description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--name <name>\n\nDomain name\n<domain>\n\nDomain ID or name\n\nFor example, to add a description for the domain mydomain, run:# vinfra domain set mydomain --description \"A custom domain\"\n\nTo edit domain quotas\n\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Edit quotas.\n\nDefine quotas for virtual resources that will be available inside the domain. To specify a certain value for a resource, clear the Unlimited check box next to it first.\n\nYou can only configure domain quotas for vCPUs, RAM, and storage space.\n\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute quotas update [--cores <cores>] [--ram-size <ram>]\r\n                                     [--storage-policy <storage_policy>]\r\n                                     [--volumes-backups <volumes-backups-size>]\r\n                                     <domain_id>\n\n--cores <cores>\n\nNumber of cores\n--ram-size <ram>\n\nAmount of RAM\n--storage-policy <storage_policy>\n\nStorage policy in the format <storage_policy>:<size> (this option can be used multiple times)\n--volumes-backups <volumes-backups-size>\n\nVolume backup size\n<domain_id>\n\nDomain ID\n\nFor example, to update quotas for the domain with the ID 0ed0dac39ba14e89b7d2b8cb7d5337f7 to 30 vCPUs, 60 GiB of RAM, 1024 GiB of disk space for the default storage policy, and 200 GiB of the volume backup size, run:# vinfra service compute quotas update --cores 30 --ram-size 60G --storage-policy default:1024G --volumes-backups 200G\\\r\n0ed0dac39ba14e89b7d2b8cb7d5337f7\nYou can view the updated quotas in the vinfra service compute quotas show output:# vinfra service compute quotas show 0ed0dac39ba14e89b7d2b8cb7d5337f7\r\n+----------------------------------------+----------+\r\n| Field                                  | Value    |\r\n+----------------------------------------+----------+\r\n| compute.cores.limit                    | 30       |\r\n| compute.ram_quota.limit                | 60.0GiB  |\r\n| storage.storage_policies.default.limit | 1.0TiB   |\r\n| storage.volumes_backups.limit          | 200.0GiB |\r\n+----------------------------------------+----------+\n\nTo enable or disable a domain\n\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Enable or Disable.\n\nCommand-line interface\nUse the following command:vinfra domain set [--enable | --disable] <domain>\r\n\n\n--enable\n\nEnable domain\n--disable\n\nDisable domain\n<domain>\n\nDomain ID or name\n\nFor example, to disable the domain mydomain, run:# vinfra domain set mydomain --disable\n\nTo delete a domain\n\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Delete.\n\nCommand-line interface\nUse the following command:vinfra domain delete <domain>\r\n\n\n<domain>\n\nDomain ID or name\n\nFor example, to delete the domain mydomain, run:# vinfra domain delete mydomain\n\nSee also\n\nManaging domain groups\n\nManaging projects\n\nManaging identity providers\n\nEnabling CPU\u00a0and RAM hot plug per domain",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain set [--description <description>] [--name <name>] <domain>\r\n\n\n--description <description>\n\n\nDomain description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--name <name>\n\nDomain name\n<domain>\n\nDomain ID or name\n\nFor example, to add a description for the domain mydomain, run:# vinfra domain set mydomain --description \"A custom domain\"\n",
                "title": "To edit a domain name or description"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute quotas update [--cores <cores>] [--ram-size <ram>]\r\n                                     [--storage-policy <storage_policy>]\r\n                                     [--volumes-backups <volumes-backups-size>]\r\n                                     <domain_id>\n\n--cores <cores>\n\nNumber of cores\n--ram-size <ram>\n\nAmount of RAM\n--storage-policy <storage_policy>\n\nStorage policy in the format <storage_policy>:<size> (this option can be used multiple times)\n--volumes-backups <volumes-backups-size>\n\nVolume backup size\n<domain_id>\n\nDomain ID\n\nFor example, to update quotas for the domain with the ID 0ed0dac39ba14e89b7d2b8cb7d5337f7 to 30 vCPUs, 60 GiB of RAM, 1024 GiB of disk space for the default storage policy, and 200 GiB of the volume backup size, run:# vinfra service compute quotas update --cores 30 --ram-size 60G --storage-policy default:1024G --volumes-backups 200G\\\r\n0ed0dac39ba14e89b7d2b8cb7d5337f7\nYou can view the updated quotas in the vinfra service compute quotas show output:# vinfra service compute quotas show 0ed0dac39ba14e89b7d2b8cb7d5337f7\r\n+----------------------------------------+----------+\r\n| Field                                  | Value    |\r\n+----------------------------------------+----------+\r\n| compute.cores.limit                    | 30       |\r\n| compute.ram_quota.limit                | 60.0GiB  |\r\n| storage.storage_policies.default.limit | 1.0TiB   |\r\n| storage.volumes_backups.limit          | 200.0GiB |\r\n+----------------------------------------+----------+\n",
                "title": "To edit domain quotas"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain set [--enable | --disable] <domain>\r\n\n\n--enable\n\nEnable domain\n--disable\n\nDisable domain\n<domain>\n\nDomain ID or name\n\nFor example, to disable the domain mydomain, run:# vinfra domain set mydomain --disable\n",
                "title": "To enable or disable a domain"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain delete <domain>\r\n\n\n<domain>\n\nDomain ID or name\n\nFor example, to delete the domain mydomain, run:# vinfra domain delete mydomain\n",
                "title": "To delete a domain"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n",
                "title": "To edit a domain name or description"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Edit quotas.\n\nDefine quotas for virtual resources that will be available inside the domain. To specify a certain value for a resource, clear the Unlimited check box next to it first.\n\nYou can only configure domain quotas for vCPUs, RAM, and storage space.\n\n\n\n\n\n\nClick Save to apply your changes.\n\n",
                "title": "To edit domain quotas"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Enable or Disable.\n\n",
                "title": "To enable or disable a domain"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Settings > Projects and users screen.\nClick the ellipsis icon next to the domain, and then click Delete.\n\n",
                "title": "To delete a domain"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-domains.html"
    },
    {
        "title": "Aggregating provisioned vCPUs",
        "content": "Aggregating provisioned vCPUsPOST /v1/aggregates?details=False&needed_overlap=0.0&start={start_date}&stop={stop_date}\r\n\nAggregate the number of provisioned vCPUs per project for a specific period of time.\n\nIf the start or stop date is not specified, the missing value will be set to the first or last timestamp common across the time series.\n\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\noperation\n\nbody\nstring\nOperations to apply to the time series. For aggregation across metrics, use the following syntax: aggregate <aggregation_method> ((metric <metric_id> <aggregation_method>), ...). Supported aggregation methods are: mean, median, std, min, max, sum, var, count.\n\nsearch\n\nbody\nstring\nA query to filter resources. The syntax includes an attribute, operator, and value. For example, the query id=90d58eea-70d7-4294-a49a-170dcdf44c3c will filter a resource with the specified ID. You can use more complex queries, for example, not (flavor_id!=\u00e2\u0080\u009d1\u00e2\u0080\u009d and memory>=24). Use \u00e2\u0080\u009c\u00e2\u0080\u009d to interpret data as a string. Supported operators are: not, and, \u00e2\u0088\u00a7 or, \u00e2\u0088\u00a8, >=, <=, !=, >, <, =, ==, eq, ne, lt, gt, ge, le, in, like, \u00e2\u0089\u00a0, \u00e2\u0089\u00a5, \u00e2\u0089\u00a4, like, in.\n\nresource_type\n\nbody\nstring\n\nA resource type that a metric is associated with. For example, these metrics are bound to:\n\nvCPU and RAM metrics\u00e2\u0080\u0094the instance resource type\nStorage metrics\u00e2\u0080\u0094the volume resource type\nFloating IP addresses\u00e2\u0080\u0094the network resource type\nLoad balancers\u00e2\u0080\u0094the loadbalancer resource type\nKubernetes clusters\u00e2\u0080\u0094the coe_cluster resource type\n\nExample\nAggregate the number of provisioned vCPUs for the project with the ID 75521ab61d1f4e9090aac5836c219492 from 12:00 PM July 18, 2021, to 12:00 PM July 19, 2021.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"operations\":\"(aggregate sum (metric vcpus mean))\",\r\n    \"search\":\"project_id=75521ab61d1f4e9090aac5836c219492\",\r\n    \"resource_type\":\"instance\"\r\n}' https://<node_IP_addr>:8041/v1/aggregates?details=False&needed_overlap=0.0&\\\r\nstart=2021-07-18T12:00:00&stop=2021-07-19T12:00:00\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nmeasures\n\nbody\nstring\nA list of measures for a metric.\n\naggregated\n\nbody\narray\nA number of aggregates, each consisting of a timestamp, granularity, and value.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"measures\": {\r\n    \"aggregated\": [\r\n      [\r\n        \"2021-07-19T12:00:00+00:00\",\r\n        300.0,\r\n        6.0\r\n      ],\r\n      <...>\r\n      [\r\n        \"2021-07-19T11:00:00+00:00\",\r\n        300.0,\r\n        6.0\r\n      ] \r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/aggregating-provisioned-vcpus.html"
    },
    {
        "title": "PUT service ostor-users",
        "content": "PUT service ostor-users\nDescription\nCreates a new user.\r\n\r\n\nRequests\nSyntaxPUT /?ostor-users&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nPUT service ostor-users parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes\n\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nA JSON dictionary with user information in the following format:{\r\n\"UserEmail\" : \"<email>\"\r\n\"UserId\" : \"<id>\",\r\n\"AWSAccessKeys : [\r\n{\r\n\"AWSAccessKeyId\" : \"<access_key>\",\r\n\"AWSSecretAccessKey\" : \"<secret_key>\"\r\n}]\r\n}\nErrors\nReturns Error Code 400 if multiple parameters are set at once.\nExamples\nSample request\nCreates a user with the email test@test.test.PUT /?ostor-users&emailAddress=test@test.test HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 16:01:03 GMT +3:00\r\nAuthorization: <authorization_string>\nSample responseHTTP/1.1 200 OK\r\nx-amz-req-time-micros : 186132\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nX-amz-request-id : 80000000000000030003746059efad68\r\nDate : Thu, 07 Apr 2016 13:01:08 GMT\r\nContent-type : application/json\r\n{\r\n\"UserEmail\": \"test@test.test\",\r\n\"UserId\": \"a721fc1a64f13a05\",\r\n\"AWSAccessKeys\": [\r\n{\r\n\"AWSAccessKeyId\": \"a721fc1a64f13a05OQF4\",\r\n\"AWSSecretAccessKey\": \"VtzYY4ZHWYzbWLUrRMSzVhB07UvD6Z5nGsAPtESV\"\r\n}]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/put-service-ostor-users.html"
    },
    {
        "title": "Creating virtual compute networks",
        "content": "Creating virtual compute networks\nLimitations\n\nIPv6 subnets are not available for virtual compute networks.\n\nPrerequisites\n\nA clear understanding of the compute architecture, which is explained in Compute network architecture.\n\nTo add a virtual compute network\n\nAdmin panel\n\nOn the Compute > Network > Networks tab, click Create network.\n\nOn the Network configuration step:\n\nEnable or disable IP address management:\n\nWith IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.\nWith IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.\n\nIn any case, you will be able to manually assign static IP addresses from inside the VMs.\n\nSelect the Virtual network type.\nSpecify a network name.\nClick Next.\n\nIf you enabled IP address management, you will move on to the IP address management step, where you can add an IPv4 subnet:\n\nIn the Subnets section, click Add and select IPv4 subnet.\nIn the Add IPv4 subnet window, specify the network\u00e2\u0080\u0099s IPv4 address range and, optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\nEnable or disable the built-in DHCP server:\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\nOn the Summary step, review the configuration, and then click Create network.\n\nCommand-line interface\nUse the following command:vinfra service compute network create [--dhcp | --no-dhcp]\r\n                                      [--dns-nameserver <dns-nameserver>]\r\n                                      [--allocation-pool <allocation-pool>]\r\n                                      [--gateway <gateway> | --no-gateway]\r\n                                      [--rbac-policies <rbac-policies>]\r\n                                      [--physical-network <physical-network>]\r\n                                      [--vlan-network <vlan-network>]\r\n                                      [--vlan <vlan>] [--cidr <cidr>]\r\n                                      [--ipv6-address-mode <ipv6-address-mode>]\r\n                                      <network-name>\r\n\n\n--dhcp\n\nEnable DHCP.\n--no-dhcp\n\nDisable DHCP.\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used  multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: ip_addr_start-ip_addr_end. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n--rbac-policies <rbac-policies>\n\nComma-separated list of RBAC policies in the format: <target>:<target_id>:<action> | none. Valid targets: project, domain. Valid actions: direct, full, routed. \u00e2\u0080\u0098*\u00e2\u0080\u0099 is valid target_id for all targets. Pass none to clear out all existing policies.\nExample: domain:default:routed,project:uuid1:full\n\n--physical-network <physical-network>\n\nAn infrastructure network to link to a physical network\n--vlan-network <vlan-network>\n\nA VLAN network to link\n--vlan <vlan>\n\nVirtual network VLAN ID\n--cidr <cidr>\n\nSubnet range in CIDR notation\n--ipv6-address-mode <ipv6-address-mode>\n\nIPv6 address mode: dhcpv6-stateful, dhcpv6-stateless, slaac\n<network-name>\n\nNetwork name\n\nFor example, to create a virtual network myprivnet with enabled IP management and specified network settings, run:# vinfra service compute network create myprivnet \r\n--cidr 192.168.128.0/24 \\\r\n--gateway 192.168.128.1 --dns-nameserver 8.8.8.8\r\n+---------------------+----------------------------------------------------+\r\n| Field               | Value                                              |\r\n+---------------------+----------------------------------------------------+\r\n| allocation_pools    | - end: 192.168.128.254                             |\r\n|                     |   start: 192.168.128.2                             |\r\n| cidr                | 192.168.128.0/24                                   |\r\n| dns_nameservers     | - 8.8.8.8                                          |\r\n| enable_dhcp         | True                                               |\r\n| gateway_ip          | 192.168.128.1                                      |\r\n| id                  | fa6d0ead-32de-4ce2-b620-5529a15eb52a               |\r\n| ip_version          | 4                                                  |\r\n| ipam_enabled        | True                                               |\r\n| name                | myprivnet                                          |\r\n| physical_network    |                                                    |\r\n| project_id          | b906404c55bb44729da99987536ac5bc                   |\r\n| rbac_policies       | []                                                 |\r\n| router_external     | False                                              |\r\n| shared              | False                                              |\r\n| spoofing_protection | True                                               |\r\n| subnet              | allocation_pools:                                  |\r\n|                     | - end: 192.168.128.254                             |\r\n|                     |   start: 192.168.128.2                             |\r\n|                     | cidr: 192.168.128.0/24                             |\r\n|                     | dns_nameservers:                                   |\r\n|                     | - 8.8.8.8                                          |\r\n|                     | enable_dhcp: true                                  |\r\n|                     | gateway_ip: 192.168.128.1                          |\r\n|                     | id: e607dd29-ffe1-46d8-a189-1baf392d1520           |\r\n|                     | ip_version: 4                                      |\r\n|                     | ipv6_address_mode: null                            |\r\n|                     | ipv6_ra_mode: null                                 |\r\n|                     | network_id: fa6d0ead-32de-4ce2-b620-5529a15eb52a   |\r\n| subnets             | - allocation_pools:                                |\r\n|                     |   - end: 192.168.128.254                           |\r\n|                     |     start: 192.168.128.2                           |\r\n|                     |   cidr: 192.168.128.0/24                           |\r\n|                     |   dns_nameservers:                                 |\r\n|                     |   - 8.8.8.8                                        |\r\n|                     |   enable_dhcp: true                                |\r\n|                     |   gateway_ip: 192.168.128.1                        |\r\n|                     |   id: e607dd29-ffe1-46d8-a189-1baf392d1520         |\r\n|                     |   ip_version: 4                                    |\r\n|                     |   ipv6_address_mode: null                          |\r\n|                     |   ipv6_ra_mode: null                               |\r\n|                     |   network_id: fa6d0ead-32de-4ce2-b620-5529a15eb52a |\r\n| tags                | []                                                 |\r\n| type                | virtual                                            |\r\n| vlan_id             |                                                    |\r\n+---------------------+----------------------------------------------------+\r\n\nThe new compute network will appear in the vinfra service compute network list output:# vinfra service compute network list -c id -c name -c cidr -c allocation_pools\r\n+----------------+---------------+------------------+---------------------------------+\r\n| id             | name          | cidr             | allocation_pools                |\r\n+----------------+---------------+------------------+---------------------------------+\r\n| 22674f9d-<...> | mypubnet      | 10.136.16.0/22   | - 10.136.18.141-10.136.18.148   |\r\n| 8f0dc747-<...> | mypubnet_vlan | 10.136.16.0/22   | - 10.136.18.131-10.136.18.138   |\r\n| a0019b43-<...> | myprivnet     | 192.168.128.0/24 | - 192.168.128.2-192.168.128.254 |\r\n+----------------+---------------+------------------+---------------------------------+\n\nSee also\n\nCreating physical compute networks\n\nEditing and deleting compute networks\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute network create [--dhcp | --no-dhcp]\r\n                                      [--dns-nameserver <dns-nameserver>]\r\n                                      [--allocation-pool <allocation-pool>]\r\n                                      [--gateway <gateway> | --no-gateway]\r\n                                      [--rbac-policies <rbac-policies>]\r\n                                      [--physical-network <physical-network>]\r\n                                      [--vlan-network <vlan-network>]\r\n                                      [--vlan <vlan>] [--cidr <cidr>]\r\n                                      [--ipv6-address-mode <ipv6-address-mode>]\r\n                                      <network-name>\r\n\n\n--dhcp\n\nEnable DHCP.\n--no-dhcp\n\nDisable DHCP.\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used  multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: ip_addr_start-ip_addr_end. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n--rbac-policies <rbac-policies>\n\n\nComma-separated list of RBAC policies in the format: <target>:<target_id>:<action> | none. Valid targets: project, domain. Valid actions: direct, full, routed. \u00e2\u0080\u0098*\u00e2\u0080\u0099 is valid target_id for all targets. Pass none to clear out all existing policies.\nExample: domain:default:routed,project:uuid1:full\n\n--physical-network <physical-network>\n\nAn infrastructure network to link to a physical network\n--vlan-network <vlan-network>\n\nA VLAN network to link\n--vlan <vlan>\n\nVirtual network VLAN ID\n--cidr <cidr>\n\nSubnet range in CIDR notation\n--ipv6-address-mode <ipv6-address-mode>\n\nIPv6 address mode: dhcpv6-stateful, dhcpv6-stateless, slaac\n<network-name>\n\nNetwork name\n\nFor example, to create a virtual network myprivnet with enabled IP management and specified network settings, run:# vinfra service compute network create myprivnet \r\n--cidr 192.168.128.0/24 \\\r\n--gateway 192.168.128.1 --dns-nameserver 8.8.8.8\r\n+---------------------+----------------------------------------------------+\r\n| Field               | Value                                              |\r\n+---------------------+----------------------------------------------------+\r\n| allocation_pools    | - end: 192.168.128.254                             |\r\n|                     |   start: 192.168.128.2                             |\r\n| cidr                | 192.168.128.0/24                                   |\r\n| dns_nameservers     | - 8.8.8.8                                          |\r\n| enable_dhcp         | True                                               |\r\n| gateway_ip          | 192.168.128.1                                      |\r\n| id                  | fa6d0ead-32de-4ce2-b620-5529a15eb52a               |\r\n| ip_version          | 4                                                  |\r\n| ipam_enabled        | True                                               |\r\n| name                | myprivnet                                          |\r\n| physical_network    |                                                    |\r\n| project_id          | b906404c55bb44729da99987536ac5bc                   |\r\n| rbac_policies       | []                                                 |\r\n| router_external     | False                                              |\r\n| shared              | False                                              |\r\n| spoofing_protection | True                                               |\r\n| subnet              | allocation_pools:                                  |\r\n|                     | - end: 192.168.128.254                             |\r\n|                     |   start: 192.168.128.2                             |\r\n|                     | cidr: 192.168.128.0/24                             |\r\n|                     | dns_nameservers:                                   |\r\n|                     | - 8.8.8.8                                          |\r\n|                     | enable_dhcp: true                                  |\r\n|                     | gateway_ip: 192.168.128.1                          |\r\n|                     | id: e607dd29-ffe1-46d8-a189-1baf392d1520           |\r\n|                     | ip_version: 4                                      |\r\n|                     | ipv6_address_mode: null                            |\r\n|                     | ipv6_ra_mode: null                                 |\r\n|                     | network_id: fa6d0ead-32de-4ce2-b620-5529a15eb52a   |\r\n| subnets             | - allocation_pools:                                |\r\n|                     |   - end: 192.168.128.254                           |\r\n|                     |     start: 192.168.128.2                           |\r\n|                     |   cidr: 192.168.128.0/24                           |\r\n|                     |   dns_nameservers:                                 |\r\n|                     |   - 8.8.8.8                                        |\r\n|                     |   enable_dhcp: true                                |\r\n|                     |   gateway_ip: 192.168.128.1                        |\r\n|                     |   id: e607dd29-ffe1-46d8-a189-1baf392d1520         |\r\n|                     |   ip_version: 4                                    |\r\n|                     |   ipv6_address_mode: null                          |\r\n|                     |   ipv6_ra_mode: null                               |\r\n|                     |   network_id: fa6d0ead-32de-4ce2-b620-5529a15eb52a |\r\n| tags                | []                                                 |\r\n| type                | virtual                                            |\r\n| vlan_id             |                                                    |\r\n+---------------------+----------------------------------------------------+\r\n\nThe new compute network will appear in the vinfra service compute network list output:# vinfra service compute network list -c id -c name -c cidr -c allocation_pools\r\n+----------------+---------------+------------------+---------------------------------+\r\n| id             | name          | cidr             | allocation_pools                |\r\n+----------------+---------------+------------------+---------------------------------+\r\n| 22674f9d-<...> | mypubnet      | 10.136.16.0/22   | - 10.136.18.141-10.136.18.148   |\r\n| 8f0dc747-<...> | mypubnet_vlan | 10.136.16.0/22   | - 10.136.18.131-10.136.18.138   |\r\n| a0019b43-<...> | myprivnet     | 192.168.128.0/24 | - 192.168.128.2-192.168.128.254 |\r\n+----------------+---------------+------------------+---------------------------------+\n",
                "title": "To add a virtual compute network"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Networks tab, click Create network.\n\nOn the Network configuration step:\n\n\nEnable or disable IP address management:\n\nWith IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.\nWith IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.\n\nIn any case, you will be able to manually assign static IP addresses from inside the VMs.\n\nSelect the Virtual network type.\nSpecify a network name.\nClick Next.\n\n\n\n\n\n\n\nIf you enabled IP address management, you will move on to the IP address management step, where you can add an IPv4 subnet:\n\nIn the Subnets section, click Add and select IPv4 subnet.\nIn the Add IPv4 subnet window, specify the network\u00e2\u0080\u0099s IPv4 address range and, optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\nEnable or disable the built-in DHCP server:\n\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\n\n\n\n\n\nOn the Summary step, review the configuration, and then click Create network.\n\n",
                "title": "To add a virtual compute network"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtual-compute-networks.html"
    },
    {
        "title": "Creating products",
        "content": "Creating products\nA product contains all services that a vendor exposes for sale, including product items, sales models, and requirements to product orders and fulfillment phase.\nTo create a new product, do the following:\n\nGo to Products and click + Create product.\n\nIn the Create product window, enter a product name and select Infrastructure from the Category drop-down list. Then, click Create.\n\nThe product ID will be automatically generated.\nConfiguring general information\nOn the product's General page, you can do the following:\n\nClick Edit next to the product name to change the product name and category or add a product icon and a short description.\nFor an icon, the recommend format is .png with a transparent background.\n\nClick Edit on the Overview tab to add a product description.\nClick + Add on the Media tab to add one or more media files for marketing purposes.\n\nClick Edit on the Capabilities tab to add various capabilities that automate certain processes in the order and usage flows.\nFor the pay-as-you-go model, enable Pay-as-you-go and select the reporting schema.\n\nCreating product items\nProduct items are compute resources in Virtuozzo Hybrid Infrastructure that customers order and pay for: CPU, RAM, storage, floating IP addresses, load balancers and Kubernetes clusters.\nProduct items can be defines for two billing models:\n\nA reservation model offers provisioning limited amount of compute resources.\nA pay-as-you-go model offers provisioning unlimited resources and charging them according to  daily usage reports.\n\nFor the reservation model, do the following:\n\nOn the product page, go to the Items > Reservation tab, remove the default items and click + Create item.\n\nIn Create item - Step 1 General, enter an item name, manufacturer part number, and description.\nFor the manufacturer part number, refer to the table below.\n\nResource\nManufacturer part number\n\nCPU \nCPU_limit\n\nRAM \nRAM_limit\n\nStorage \nStorage_limit\n\nFloating IP addresses\nfloating_ip\n\nLoad balancers\nlbaas_limit\n\nKubernetes clusters\nk8saas_limit\n\nLeave the default value in the Parent item field and click Next.\n\nIn Create item - Step 2 Type, select One Time in the Billing period field and units in the Unit field:\n\nFor RAM and storage, select Gb.\nFor other compute resources, select Units.\n\nClick Create.\n\nAfter adding all the six compute resources, you will have the following list.\n\nFor the pay-as-you-go model, do the following:\n\nOn the product page, go to the Items > Pay as you go tab, click + Create item.\nMake sure you have the Pay-as-you-go capability enabled on the product's General > Capabilities tab.\n\nIn Create item - Step 1 General, enter an item name, manufacturer part number, and description.\nFor the manufacturer part number, refer to the table below.\n\nResource\nManufacturer part number\n\nCPU \nCPU_consumption\n\nRAM \nRAM_consumption\n\nStorage \nStorage_consumption\n\nFloating IP addresses\nFloating_ip_consumption\n\nLoad balancers\nLB_consumption\n\nKubernetes clusters\nK8S_consumption\n\nClick Next.\n\nIn Create item - Step 2 Type, select Integer (Example: 42) in the Precision field and Unit*H in the Unit field.\n\nClick Create.\n\nAfter adding all the six compute resources, you will have the following list.\n\nCreating product parameters\nProduct parameters are used to create a product order and to fulfill a product request. You can create three types of parameters:\n\nConfiguration parameters are metadata specified during the product configuration. They can be assigned to the product in general, product item, and related marketplace. \nOrder parameters are specified by customers when ordering the product.\nFulfillment parameters are specified by the vendor  when fulfilling a product request.\n\nFor Virtuozzo Hybrid Infrastructure, you need to add the following parameters:\n\nParameter\nID\nPhase\n\nItem limit\nitem_limit\nConfiguration\n\nProject name\nproject\nOrdering\n\nUser name\nuser\nOrdering\n\nUser password\npassword\nOrdering\n\nDomain name\ndomain_name\nFulfillment \n\nDomain ID\ndomain_id\nFulfillment \n\nProject ID\nproject_id\nFulfillment \n\nUser ID\nuser_id\nFulfillment \n\nTo create a parameter, do the following:\n\nOn the product page, go to Parameters and click + Create parameter.\nIn Create parameter \u00e2\u0080\u0094 Step 1 Type, select Single line text to be able to enter a value for the parameter in a text line. Click Next.\n\nIn Create parameter \u00e2\u0080\u0094 Step 2 Phase, select the phase where the parameter will be used and click Next. \nFor the parameter phase, refer to the table above.\n\nIn Create parameter \u00e2\u0080\u0094 Step 3 Scope, select Asset and click Next.\nIn Create parameter \u00e2\u0080\u0094 Step 4 Constrains, enable Required to make the parameter mandatory. Click Next.\n\nIn Create parameter \u00e2\u0080\u0094 Step 5 Details, enter the parameter ID, title, and description. \nFor the parameter ID, refer to the table above. \n\nClick Create.\n\nIn Create parameter \u00e2\u0080\u0094 Step 6 Summary, review the parameter summary and click Close.\n\nAfter adding all the product parameters, you will have the following list:\n\nDefining configuration parameters\nOn the product's Configuration page, you can manage parameters associated with the configuration phase. Virtuozzo Hybrid Infrastructure has only one configuration parameter, item limit, which enables defining maximum resource limits for the reservation model.\nTo define the resource limits, do the following:\n\nOn the Configuration page, click the pencil icon next to the value you want to change.\n\nIn the Edit value window, set a new value and click Save.\n\nRepeat the steps for each item you need to modify.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/creating-products.html"
    },
    {
        "title": "Provisioning load balancers",
        "content": "Provisioning load balancers\nVirtuozzo Hybrid Infrastructure offers load balancing as a service for the compute infrastructure. Load balancing ensures fault tolerance and improves performance of web applications by distributing incoming network traffic across virtual machines from a balancing pool. A load balancer receives and then routes incoming requests to a suitable VM based on a configured balancing algorithm and VM health.\nLoad balancers are created and managed by self-service users, as described in \"Managing load balancers\" in the Self-Service Guide.\r\nHowever, to provide self-service users with this functionality, you need to enable the load balancer service in the admin panel or by using the vinfra command-line tool.\nLimitations \n\nIn the current version of Virtuozzo Hybrid Infrastructure, the installed service cannot be removed.\n\nFor self-service users to be able to create highly available load balancers, the compute cluster must have at least two nodes. However, we recommend having three compute nodes for the case of a load balancer failover after a failure.\nIf you install the service after creating a project, load balancers are not automatically enabled in the project quotas.\nThe maximum number of load balancers supported per project is 100.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\n\nTo enable the load balancer service\n\nAdmin panel\n\nGo to the Settings > Add-on services screen.\nIn the Load balancer service section, click Install.\n\nCommand-line interface\nRun the following command:# vinfra service compute lbaas configure [--enable] [--loadbalancer-topology {SINGLE,ACTIVE_STANDBY}]\r\n                                         [--amp-flavor-id <amp_flavor_id>] [--amp-image-tag <amp_image_tag>]\n\n--enable\n\nEnable compute load balancer service\n--loadbalancer-topology {SINGLE,ACTIVE_STANDBY}\n\nConfigure the load balancer topology:\n\nSINGLE: create one load balancer instance\nACTIVE_STANDBY: create two load balancer instances working in the Active/Standby mode\n\n--amp-flavor-id <amp_flavor_id>\n\nCompute flavor ID for the load balancer instance\n--amp-image-tag <amp_image_tag>\n\nCompute image tag for the amphora image to boot\n\nTo enable and configure the load balancer service to create two instances in the Active/Standby mode, run:# vinfra service compute lbaas configure --enable --loadbalancer-topology ACTIVE_STANDBY\nYou can check the load balancer service configuration in the vinfra service compute lbaas show\r\noutput:# vinfra service compute lbaas show\r\n+-----------------------+----------------+\r\n| Field                 | Value          |\r\n+-----------------------+----------------+\r\n| amp_flavor_id         | amphora        |\r\n| amp_image_tag         | amphora        |\r\n| loadbalancer_topology | ACTIVE_STANDBY |\r\n+-----------------------+----------------+\n\nWhat's next\n\nManaging load balancers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nRun the following command:# vinfra service compute lbaas configure [--enable] [--loadbalancer-topology {SINGLE,ACTIVE_STANDBY}]\r\n                                         [--amp-flavor-id <amp_flavor_id>] [--amp-image-tag <amp_image_tag>]\n\n--enable\n\nEnable compute load balancer service\n--loadbalancer-topology {SINGLE,ACTIVE_STANDBY}\n\n\nConfigure the load balancer topology:\n\nSINGLE: create one load balancer instance\nACTIVE_STANDBY: create two load balancer instances working in the Active/Standby mode\n\n\n--amp-flavor-id <amp_flavor_id>\n\nCompute flavor ID for the load balancer instance\n--amp-image-tag <amp_image_tag>\n\nCompute image tag for the amphora image to boot\n\nTo enable and configure the load balancer service to create two instances in the Active/Standby mode, run:# vinfra service compute lbaas configure --enable --loadbalancer-topology ACTIVE_STANDBY\nYou can check the load balancer service configuration in the vinfra service compute lbaas show\r\noutput:# vinfra service compute lbaas show\r\n+-----------------------+----------------+\r\n| Field                 | Value          |\r\n+-----------------------+----------------+\r\n| amp_flavor_id         | amphora        |\r\n| amp_image_tag         | amphora        |\r\n| loadbalancer_topology | ACTIVE_STANDBY |\r\n+-----------------------+----------------+\n",
                "title": "To enable the load balancer service"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Settings > Add-on services screen.\nIn the Load balancer service section, click Install.\n\n",
                "title": "To enable the load balancer service"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-load-balancers.html"
    },
    {
        "title": "Managing compute backups",
        "content": "Managing compute backups\nA backup, or recovery point (these terms are used interchangeably), is a full copy of a compute volume made at a specified time. With the backup service, you can create backups automatically by using backup plans or initiate backups manually. Backup plans define what data to back up, how frequently to create backups, and how long to keep them.\nThe backup service also allows you to restore virtual machines and volumes by creating new intances from backups.\nLimitations\n\nOnly full backups of compute volumes are supported.\nYou cannot back up the same volumes by using both the integrated backup service and an external backup solution.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\nThe backup service is enabled in the command-line interface, as described in Provisioning the backup service.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-compute-backups.html"
    },
    {
        "title": "Physical space chart",
        "content": "Physical space chart\n\nAdmin panel\nThe Physical space chart shows the current usage of physical space in the entire storage cluster and on each particular tier. The used space includes the space occupied by all data chunks and their replicas, plus the space occupied by any other data.\n\nCommand-line interface\nUse the following command:vinfra cluster overview\nFor example, to view the physical space usage in the cluster cluster1, take a look at these lines from the command output:\r\n+-------------------+-------------------------+\r\n| Field             | Value                   |\r\n+-------------------+-------------------------+\r\n| ...               | ...                     |\r\n| tiers             | - id: 0                 |\r\n|                   |   phys_space:           |\r\n|                   |     free: 611533008896  |\r\n|                   |     total: 675644723200 |\r\n|                   |     used: 64111714304   |\r\n+-------------------+-------------------------+\r\n\n\nHow the physical space is calculated\nThe total physical disk space is a total of all the disk space on all storage disks on the same tier. The used physical space is a total of all the user data on the storage disks of the same tier, considering the redundancy mode. The free disk space is the total physical space minus the used physical space.\nTo better understand how physical disk space is calculated, consider the following example:\n\n\u00a0\nUsed/Total (Free), GiB\n\nTier 0,\r\n3+2 encoding\n(67% overhead)\n\nTier 1,\r\n2 replicas\n(100% overhead)\n\nTier 2,\r\nno redundancy\n\nNode 1\n334/1024 (690)\n134/512 (378)\n50/256 (206)\n\nNode 2\n334/1024 (690)\n133/512 (379)\n50/256 (206)\n\nNode 3\n334/1024 (690)\n133/512 (379)\n\u00a0\n\nNode 4\n334/1024 (690)\n\u00a0\n\u00a0\n\nNode 5\n334/1024 (690)\n\u00a0\n\u00a0\n\nReported\r\nsummary\n1670/5120 (3450)\n400/1536 (1136)\n100/512 (412)\n\nThe cluster has ten disks with the storage role: five 1024 GiB disks are assigned to tier 0, three 512 GiB disks to tier 1, and two 256 GiB disk to tier 2. There is no other data on the disks (for example, system files). Tier 0 stores 1000 GiB of user data in the 3+2 encoding mode. Tier 1 stores 200 GiB of user data in the 2 replicas mode. Tier 2 stores 100 GB of user data with no redundancy.\nNo matter what redundancy mode is used, the cluster attempts to spread data chunks evenly across disks of the same tier.\nIn this example, the physical disk space on each tier is reported as follows:\n\nOn tier 0, the total disk space is 5120 GiB, the used disk space is 1670 GiB, and the free disk space is 3450 GiB.\nOn tier 1, the total disk space is 1536 GiB, the used disk space is 400 GiB, and the free disk space is 1136 GiB.\nOn tier 2, the total disk space is 512 GiB, the used disk space is 100 GiB, and the free disk space is 456 GiB.\n\nSee also\n\nI/O activity charts\n\nServices chart\n\nChunks chart\n\nLogical space chart",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/physical-space-chart.html"
    },
    {
        "title": "Troubleshooting installation",
        "content": "Troubleshooting installation\nThis chapter describes ways to troubleshoot installation of Virtuozzo Hybrid Infrastructure.\nInstalling in basic graphics mode\nIf the installer cannot load the correct driver for your graphics card, you can try to install Virtuozzo Hybrid Infrastructure in the basic graphics mode. In this mode, however, you may experience issues with the user interface. For example, some of its elements may not fit the screen.\nThe installation process itself is the same as in the default graphics mode.\nTo select basic graphics mode\nOn the welcome screen, select Troubleshooting\u00e2\u0080\u0093>, then Install in basic graphics mode.\nBooting into recovery mode\nIf a node fails to boot, you can recover the system disk and the node configuration by reinstalling the product from an ISO image in the recovery mode.\nDuring the recovery process, the configuration of deployed services and infrastructure is automatically detected and recovered from storage disks.\nTo enter the recovery mode\nOn the welcome screen, select Troubleshooting\u00e2\u0080\u0093>, then Recover - Node recovery.\nBooting into rescue mode\nIf you experience problems with your system, you can boot into the rescue mode to troubleshoot these problems. Once you are in the rescue mode, your Virtuozzo Hybrid Infrastructure installation is mounted under /mnt/sysimage. You can go to this directory and make the necessary changes to your system.\nTo enter the rescue mode\n\nBoot your system from the  distribution image.\nOn the welcome screen, click Troubleshooting\u00e2\u0080\u0093>, then Rescue system.\nOnce Virtuozzo Hybrid Infrastructure boots into the emergency mode, press Ctrl+D to load the rescue environment.\nIn the rescue environment, you can select one of the following options:Continue (press 1): mount the Virtuozzo Hybrid Infrastructure installation in read and write mode under /mnt/sysimage.Read-only mount (press 2): mount the Virtuozzo Hybrid Infrastructure installation in read-only mode under /mnt/sysimage.Skip to shell (press 3): load shell, if your file system cannot be mounted, for example, when it is corrupted.Quit (Reboot) (press 4): reboot the server.\nUnless you press 4, a shell prompt will appear. In it, run chroot /mnt/sysimage to make the Virtuozzo Hybrid Infrastructure installation the root environment. Now you can run commands and try to fix the problems you are experiencing.\nAfter you fix the problem, run exit to exit the chrooted environment, and then run reboot to restart the system.\n\nWhat's next\n\nInstalling in the attended mode",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/troubleshooting-installation.html"
    },
    {
        "title": "Using built-in Prometheus for monitoring",
        "content": "Using built-in Prometheus for monitoring\nTo use built-in Prometheus, you need to open a TCP port for the Prometheus API to be accessible from the outside. If you have an external Grafana account and want to use it for monitoring Virtuozzo Hybrid Infrastructure, you can add built-in Prometheus as a data source. Using the added Prometheus data source, you can import the default Grafana dashboards from Virtuozzo Hybrid Infrastructure or create new ones.\nTo open a port for the Prometheus API\n\nOn the Infrastructure > Networks screen, click Edit and then Create traffic type.\n\nIn the Create traffic type window, specify a custom name in the Name field and 9090 in the Port field. Then, click Create.\n\nClick Assign to networks next to the Custom traffic types section, and then add the created traffic type to your public network by selecting the corresponding check box.\nClick Save to apply the changes.\n\nYou can now access the Prometheus web-based user interface at http://<admin_panel_IP_address>:9090. For more information on using Prometheus, refer to its documentation.\nTo add Prometheus as a data source to Grafana\n\nLog in into your Grafana user interface.\nClick the cogwheel icon in the left menu, and then select Data Sources.\nOn the Data Sources tab, click Add data source.\nOn the Data Sources / New screen, specify the following parameters:Enter a custom data source name in the Name field.Set Type to Prometheus.Enter http://<admin_panel_IP_address>:9090 in the URL field.\nClick Save & Test.\n\nIf the specified parameters are correct, the \"Data source is working\" message will appear.\n\nSee also\n\nUsing external Prometheus for monitoring\n\nConfiguring retention policy for Prometheus metrics\n\nPrometheus metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-built-in-prometheus.html"
    },
    {
        "title": "Uninstalling guest tools",
        "content": "Uninstalling guest tools\nIf you find out that the guest tools are incompatible with some software inside a virtual machine, you can uninstall them by doing the following:\n\nInside a Windows VM:\n\nRemove the QEMU device drivers from the device manager.\n\nDo not remove the VirtIO/SCSI hard disk driver and NetKVM network driver. Without the former, the VM will not boot; without the latter, the VM will lose network connectivity.\n\nUninstall the QEMU guest agent and guest tools from the list of installed applications.\n\nStop and delete Guest Tools Monitor:> sc stop VzGuestToolsMonitor\r\n> sc delete VzGuestToolsMonitor\r\n\n\nUnregister Guest Tools Monitor from Event Log:> reg delete HKLM\\SYSTEM\\CurrentControlSet\\services\\eventlog\\Application\\\\\r\nVzGuestToolsMonitor\r\n\n\nDelete the autorun registry key for RebootNotifier:> reg delete HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run /v \\\r\nVzRebootNotifier\r\n\n\nDelete the C:\\Program Files\\Qemu-ga\\ directory.\nIf VzGuestToolsMonitor.exe is locked, close all the Event Viewer windows. If it remains locked, restart the eventlog service:> sc stop eventlog\r\n> sc start eventlog\r\n\n\nAfter removing the guest tools, restart the virtual machine.\n\nInside a Linux VM:\n\nRemove the packages:\n\nOn RPM-based systems (CentOS and other):# yum remove dkms-vzvirtio_balloon prl_nettool qemu-guest-agent-vz \\vz-guest-udev\r\n\n\nOn DEB-based systems (Debian and Ubuntu):# apt-get remove vzvirtio-balloon-dkms prl-nettool qemu-guest-agent-vz \\vz-guest-udev\r\n\nIf any of the packages listed above are not installed on your system, the command will fail. In this case, exclude these packages from the command and run it again.\n\nRemove the files:# rm -f /usr/bin/prl_backup /usr/share/qemu-ga/VERSION \\/usr/bin/install-tools \\\r\n/etc/udev/rules.d/90-guest_iso.rules /usr/local/bin/fstrim-static \\/etc/cron.weekly/fstrim\r\n\n\nReload the udev rules:# udevadm control --reload\r\n\n\nAfter removing guest tools, restart the virtual machine.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/uninstalling-guest-tools.html"
    },
    {
        "title": "Creating templates",
        "content": "Creating templates\nPrerequisites\n\nLinux virtual machines have cloud-init installed, as described in Obtaining Linux templates.\nWindows virtual machines have Cloudbase-Init and OpenSSH Server installed, as described in Configuring Windows boot volumes.\n\nLogging is enabled inside a virtual machine, as instructed in Enabling logging for virtual machines.\n\nTo create a template from a boot volume\n\nAdmin panel\n\nPower off the VM that the original volume is attached to.\nSwitch to the Compute > Storage > Volumes tab, click volume\u00e2\u0080\u0099s ellipsis button and select Create image.\n\nIn the Create image window, enter an image name, and then click Create.\n\nThe new image will appear on the Images screen.\n\nCommand-line interface\n\nShut down the VM which boot volume you want to use. For example:# vinfra service compute server stop myvm\n\nFind out the boot volume's ID. For example:# vinfra service compute server show myvm\r\n+---------------+--------------------------------------------+\r\n| Field         | Value                                      |\r\n+---------------+--------------------------------------------+\r\n| config_drive  |                                            |\r\n| created       | 2021-06-10T08:55:53Z                       |\r\n| description   |                                            |\r\n| fault         |                                            |\r\n| flavor        | disk: 0                                    |\r\n|               | ephemeral: 0                               |\r\n|               | extra_specs: {}                            |\r\n|               | original_name: tiny                        |\r\n|               | ram: 512                                   |\r\n|               | swap: 0                                    |\r\n|               | vcpus: 1                                   |\r\n| ha_enabled    | True                                       |\r\n| host          | amigai-ac-ve0.vstoragedomain               |\r\n| host_status   | UP                                         |\r\n| id            | 6d0fc132-7ea7-41f0-81ca-a4a2b2a2c893       |\r\n| key_name      |                                            |\r\n| metadata      | {}                                         |\r\n| name          | myvm                                       |\r\n| networks      | - id: bd17c207-5291-4096-be6a-0a8a4bf67792 |\r\n|               |   ipam_enabled: true                       |\r\n|               |   ips:                                     |\r\n|               |   - 192.168.128.100                        |\r\n|               |   mac_addr: fa:16:3e:6b:6c:83              |\r\n|               |   name: private                            |\r\n|               |   spoofing_protection: true                |\r\n| orig_hostname | amigai-ac-ve0                              |\r\n| placements    | []                                         |\r\n| power_state   | SHUTDOWN                                   |\r\n| project_id    | dfd99654b8c94b939b638f94abb2ad73           |\r\n| status        | SHUTOFF                                    |\r\n| task_state    |                                            |\r\n| updated       | 2021-06-15T11:24:05Z                       |\r\n| user_data     |                                            |\r\n| vm_state      | stopped                                    |\r\n| volumes       | - delete_on_termination: false             |\r\n|               |   id: 49be1057-c026-494f-b85d-e013728d41bd |\r\n|               | - delete_on_termination: false             |\r\n|               |   id: eca9f679-7e35-4768-ad20-9bcb6af6fd59 |\r\n+---------------+--------------------------------------------+\r\n\nThe first volume in the output is the boot one.\n\nUpload the boot volume to an image specifying the image name. For example:# vinfra service compute volume upload-to-image 49be1057-c026-494f-b85d-e013728d41bd \\\r\n--name image_from_volume\n\nThe new image will appear in the vinfra service compute image list output:# vinfra service compute image list\r\n+--------------------------------------+-------------------+-----------+--------+-------------+\r\n| id                                   | name              | size      | status | disk_format |\r\n+--------------------------------------+-------------------+-----------+--------+-------------+\r\n| d51ad587-6524-4685-b54c-56b7f3e0591d | image_from_volume | 171966464 | active | qcow2       |\r\n| cd964608-edef-479e-b10e-9851dbc0b431 | cirros            | 12716032  | active | qcow2       |\r\n+--------------------------------------+-------------------+-----------+--------+-------------+\n\nWhat's next\n\nCreating virtual machines\n\nRescuing virtual machines\n\nManaging images",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nShut down the VM which boot volume you want to use. For example:# vinfra service compute server stop myvm\n\n\nFind out the boot volume's ID. For example:# vinfra service compute server show myvm\r\n+---------------+--------------------------------------------+\r\n| Field         | Value                                      |\r\n+---------------+--------------------------------------------+\r\n| config_drive  |                                            |\r\n| created       | 2021-06-10T08:55:53Z                       |\r\n| description   |                                            |\r\n| fault         |                                            |\r\n| flavor        | disk: 0                                    |\r\n|               | ephemeral: 0                               |\r\n|               | extra_specs: {}                            |\r\n|               | original_name: tiny                        |\r\n|               | ram: 512                                   |\r\n|               | swap: 0                                    |\r\n|               | vcpus: 1                                   |\r\n| ha_enabled    | True                                       |\r\n| host          | amigai-ac-ve0.vstoragedomain               |\r\n| host_status   | UP                                         |\r\n| id            | 6d0fc132-7ea7-41f0-81ca-a4a2b2a2c893       |\r\n| key_name      |                                            |\r\n| metadata      | {}                                         |\r\n| name          | myvm                                       |\r\n| networks      | - id: bd17c207-5291-4096-be6a-0a8a4bf67792 |\r\n|               |   ipam_enabled: true                       |\r\n|               |   ips:                                     |\r\n|               |   - 192.168.128.100                        |\r\n|               |   mac_addr: fa:16:3e:6b:6c:83              |\r\n|               |   name: private                            |\r\n|               |   spoofing_protection: true                |\r\n| orig_hostname | amigai-ac-ve0                              |\r\n| placements    | []                                         |\r\n| power_state   | SHUTDOWN                                   |\r\n| project_id    | dfd99654b8c94b939b638f94abb2ad73           |\r\n| status        | SHUTOFF                                    |\r\n| task_state    |                                            |\r\n| updated       | 2021-06-15T11:24:05Z                       |\r\n| user_data     |                                            |\r\n| vm_state      | stopped                                    |\r\n| volumes       | - delete_on_termination: false             |\r\n|               |   id: 49be1057-c026-494f-b85d-e013728d41bd |\r\n|               | - delete_on_termination: false             |\r\n|               |   id: eca9f679-7e35-4768-ad20-9bcb6af6fd59 |\r\n+---------------+--------------------------------------------+\r\n\nThe first volume in the output is the boot one.\n\n\nUpload the boot volume to an image specifying the image name. For example:# vinfra service compute volume upload-to-image 49be1057-c026-494f-b85d-e013728d41bd \\\r\n--name image_from_volume\n\n\nThe new image will appear in the vinfra service compute image list output:# vinfra service compute image list\r\n+--------------------------------------+-------------------+-----------+--------+-------------+\r\n| id                                   | name              | size      | status | disk_format |\r\n+--------------------------------------+-------------------+-----------+--------+-------------+\r\n| d51ad587-6524-4685-b54c-56b7f3e0591d | image_from_volume | 171966464 | active | qcow2       |\r\n| cd964608-edef-479e-b10e-9851dbc0b431 | cirros            | 12716032  | active | qcow2       |\r\n+--------------------------------------+-------------------+-----------+--------+-------------+\n",
                "title": "To create a template from a boot volume"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nPower off the VM that the original volume is attached to.\nSwitch to the Compute > Storage > Volumes tab, click volume\u00e2\u0080\u0099s ellipsis button and select Create image.\n\nIn the Create image window, enter an image name, and then click Create.\n\n\n\n\n\n\nThe new image will appear on the Images screen.\n",
                "title": "To create a template from a boot volume"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-templates.html"
    },
    {
        "title": "Restricting access to target groups",
        "content": "Restricting access to target groups\nYou can restrict access to entire target groups (and all volumes attached to them) by using ACL-based authorization as well as password-based authentication (CHAP).\nPrerequisites\n\nA target group is created, as described in Creating target groups.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/restricting-access-to-target-groups.html"
    },
    {
        "title": "Creating and deleting users",
        "content": "Creating and deleting users\nDomain administrators can create and delete other domain administrators and project members:\n\nA domain administrator can manage virtual objects in all projects within the assigned domain, as well as projects and users in the self-service panel.\nA project member acts as a project administrator in a specific domain in the self-service panel. A project member can be assigned to different projects and can manage virtual objects in them.\n\nPrerequisites\n\nA domain administrator must have the Image uploading and Project and quota management permissions granted, to be able to configure these permissions for other users.\n\nTo create a user\n\nSelect the domain in the drop-down list in the top right corner.\nOpen the Users screen and click Create user.\n\nIn the Create user window, specify the user name, password, and, if required, a user email address and description. The user name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nSelect the user role:\n\nTo create a domain administrator\n\nSelect the Domain administrator role.\n\nEnable Image uploading to allow the user to upload images and configure this permission for other domain users.\n\nEnable Project and quota management to allow the user to manage projects and quotas, as well as configure this permission for other domain administrators.\n\nTo create a project administrator\n\nSelect the Project member role.\n\nEnable Image uploading to allow the user to upload images.\n\nClick Manage in the Projects section and select a project to assign the user to. Then, click Save.\n\nClick Create.\n\nTo delete a user\n\nSelect the domain in the drop-down list in the top right corner.\nOn the Users screen, click the ellipsis icon next to the user, and then click Delete.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-and-deleting-users.html"
    },
    {
        "title": "Accessing iSCSI targets",
        "content": "Accessing iSCSI targets\nThis section describes ways to attach iSCSI targets to operating systems and third-party virtualization solutions that support the explicit ALUA mode.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/accessing-iscsi-targets.html"
    },
    {
        "title": "Deleting backups",
        "content": "Deleting backupsDELETE /v3/{project_id}/backups/{backup_id}\nDelete a backup.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/#delete-a-backup\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nbackup_id\n\npath\nstring\nThe UUID for a backup.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-backups.html"
    },
    {
        "title": "Shutting down and starting up the cluster",
        "content": "Shutting down and starting up the cluster\nPrerequisites\n\nIf you have the compute cluster deployed, all running virtual machines must be stopped and no VMs should be in a transitional state. \nIf you have the NFS or block storage cluster deployed, iSCSI LUNs and NFS exports must be unmounted on the client\u00e2\u0080\u0099s side before stopping the services. Otherwise, shutting down the cluster may result in data loss.\n\nTo shut down the entire cluster\n\nShut down cluster nodes that are not running metadata services. To distinguish such nodes, go to Infrastructure > Nodes and look for the nodes without the Metadata service. On each of these nodes, do one of the following:\n\nIf you can access the node remotely, execute:# shutdown -h now\r\n\n\nIf you can access the node physically, briefly press the power button once\n\nShut down cluster nodes with metadata services by using the command from the previous step.\n\nTo start up the cluster\n\nBoot the nodes with the Metadata or/and Admin panel services. \nTurn on the other cluster nodes.\nCheck the storage and compute cluster statuses before starting working with Virtuozzo Hybrid Infrastructure.\n\nSee also\n\nMonitoring the storage cluster\n\nMonitoring the compute cluster",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/shutting-down-and-starting-up-the-cluster.html"
    },
    {
        "title": "Core storage alerts",
        "content": "Core storage alerts\nBased on the metrics listed in Core storage metrics, the core storage alerts are generated and displayed in the admin panel.\nStorage cluster alerts\n\n Not enough cluster nodes\n\nCluster <cluster_name> has only {1,2} node(s) instead of the recommended minimum of 3. Add more nodes to the cluster.\n\n Cluster is out of physical space\n\nCluster has just <free_space> TB (<free_space_in_percent>%) of physical storage space left. You may want to free some space or add more storage capacity.\n\n Cluster is running out of physical space on tier\n\nThere is little free physical space left on storage tier <tier> (less than 20% of free space).\n\n Cluster is out of physical space on tier\n\nThere is not enough free physical space on storage tier <tier> (less than 10% of free space).\n\n Cluster has blocked or slow replication\n\nChunk replication is blocked or too slow.\n\n Cluster has too many chunks\n\nThere are too many chunks in the cluster, which slows down the metadata service.\n\n Cluster has critically high number of chunks\n\nThere are too many chunks in the cluster, which slows down the metadata service.\n\n Cluster has too many files\n\nThere are too many files in the cluster, which slows down the metadata service.\n\n Cluster has critically high number of files\n\nThere are too many files in the cluster, which slows down the metadata service.\n\n Cluster has failed mount points\n\nSome mount points stopped working and need to be recovered.\n\n Cluster has unaligned I/O reads\n\nI/O reads are not aligned. It may be caused by a wrongly formatted disk in a virtual machine.\n\n Node has stuck I/O requests\n\nSome I/O requests are stuck on <node>.\n\n Node has failed map requests\n\nSome map requests on <node> have failed.\n\n CS journal is running out of space\n\nCS journal has less than 20% of free space left.\n\nMetadata service alerts\n\n Only one metadata disk in cluster\n\nCluster has only one MDS. There is only one disk with the metadata role at the moment. Losing this disk will completely destroy all cluster data irrespective of the redundancy schema.\n\n Not enough metadata disks\n\nCluster requires more disks with the metadata role. Losing one more MDS will halt cluster operation.\n\n More than one metadata service per node\n\nNode \u00e2\u0080\u009c<hostname>\u00e2\u0080\u009d has more than one metadata service located on it. It is recommended to have only one metadata service per node. Delete the extra metadata service(s) from this node and create them on other nodes instead.\n\n Four metadata services in cluster\n\nCluster has four metadata services. This configuration slows down the cluster performance and does not improve its availability. For a cluster of four nodes, it is enough to configure three MDSes. Delete an extra MDS from one of the cluster nodes.\n\n Over five metadata services in cluster\n\nCluster has more than five metadata services. This configuration slows down the cluster performance and does not improve its availability. For a large cluster, it is enough to configure five MDSes. Delete extra MDSes from the cluster nodes.\n\n Service failed\n\nMetadata service #<id> is in the \u00e2\u0080\u009c<status>\u00e2\u0080\u009d state. Node: <hostname>. Disk: <disk_name>. Disk serial: <disk_serial>.\n\n Metadata service has high CPU usage\n\nMetadata service on <node> has CPU usage higher than 80%. The service may be overloaded.\n\n Metadata service has high commit latency\n\nMetadata service on <node> has the 95th percentile latency higher than 1 second.\n\n Metadata service has critically high commit latency\n\nMetadata service on <node> has the 95th percentile latency higher than 5 seconds.\n\n Cluster has unavailable metadata services\n\nSome metadata services are offline or have failed. Check and restart them.\n\n Master metadata service changes too often\n\nMaster metadata service has changed more than once in 5 minutes.\n\nChunk service alerts\n\n Not enough storage disks\n\nCluster requires more disks with the storage role to be able to provide the required level of redundancy.\n\n Zero storage disks\n\nCluster has zero disks with the storage role and cannot provide the required level of redundancy.\n\n Service failed\n\nStorage service #<id> is in the \u00e2\u0080\u009c<status>\u00e2\u0080\u009d state. Node: <hostname>. Disk: <disk_name>. Disk serial: <disk_serial>.\n\n CS configuration is not optimal\n\nEncryption is disabled for CS#<cs_id> on tier <tier> but is enabled for other CSes on the same tier.\n\n Storage disk is unresponsive\n\nDisk <disk_name> (CS#<cs_id>) on node <hostname> is unresponsive. Check or replace this disk.\n\n Disk cache settings are not optimal\n\nDisk <disk_name> (CS#<cs_id> on node <hostname> has cache settings different from other disks of the same tier.\n\n Cluster has offline chunk services\n\nSome chunk services are offline. Check and restart them.\n\n Cluster has failed chunk services\n\nSome chunk services have failed. It may be caused by physical drive failure.\n\n Number of CSes per device does not match configuration\n\nNumber of CSes per device on node <node> with ID <id> does not match configuration. Check your disk configuration.\n\nWhat's next\n\nGetting technical support\n\nSee also\n\nInfrastructure alerts\n\nBackup storage alerts\n\nObject storage alerts\n\nBlock storage alerts\n\nCompute alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/storage-alerts.html"
    },
    {
        "title": "Generating S3 access keys in WHMCS",
        "content": "Generating S3 access keys in WHMCS\nYou can generate a new or additional access key pair with the ostor-users service and the following parameters: emailAddress specifying the user email address, genKey. WHMCS generates a new key pair when you click Generate Access Key. Create a file S3_generateAccessKey.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_addClientNote.php');\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Generate s3 access key pair.\r\nfunction S3_generateAccessKey($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Generate s3 key pair.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'] . \"&genKey\",\r\n        \"POST\"\r\n    );\r\n\r\n    // Add note with the s3 access key and s3 secret.\r\n    S3_addClientNote(\r\n        $s3_whmcs['userid'],\r\n        $s3_config['whmcs_username'],\r\n        $s3_client['UserId'],\r\n        $s3_client['AWSAccessKeys']['0']['AWSAccessKeyId'],\r\n        $s3_client['AWSAccessKeys']['0']['AWSSecretAccessKey']\r\n    );\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_generateAccessKey($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/generating-s3-access-keys-in-whmcs.html"
    },
    {
        "title": "3. Creating Virtuozzo Hybrid Infrastructure Resources\u00c2\u00b6",
        "content": "3. Creating Virtuozzo Hybrid Infrastructure Resources | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\u00c2\u00b6\nCreate the necessary resources on your Virtuozzo Hybrid Infrastructure (Domain, Project, and User) to host the Leostream VDI workloads and access them securely.\n\nLogin to the Virtuozzo Hybrid Infrastructure admin panel.\n\nGo to Settings > Projects and users in Virtuozzo Hybrid Infrastructure and click on Create domain.\n\nIn the Create domain form, shown in the following figure, enter a Name and Description for the Domain you will use to host our users and projects (tenants), and click Create.\n\nSelect your new domain on the Settings > Project and users page and go to the Domain users tab. Click Create user to create a Domain administrator. Specify the Login, Password, and optionally email address and description. As we are creating a Domain administrator, please ensure that you select Domain administrator from the Role drop-down menu.\n\nSelect your new domain on the Settings > Project and users page and go to the Projects tab. Click Create project to create a new project to host the Leostream Platform and Virtual Desktop Infrastructure resources. Enter a Name and optionally a Description for the project, and set any compute quotes, as shown in the following figure.\n\nSelect your new domain on the Settings > Project and users page and go to the Domain users tab. Click Create user to create a Project member from the Role drop-down menu, as shown in the following figure.\n\nTo assign the project user to your project, select your new domain on the Settings > Project and users page and go to the Projects tab. Click the ellipses at the far right of the project\u00e2\u0080\u0099s row then click Assign members.\nGo to the Compute > Networks page to enable your project to access the external network and a pool of Floating IP addresses.\n\nselect your external network\nfrom the panel right, click Edit in the Network access section\nensure your new project is selected in the Edit network access form, as shown in the following figure\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/creating-resources.html"
    },
    {
        "title": "Creating and deleting projects",
        "content": "Creating and deleting projects\nLimitations\n\nA project cannot be deleted if it has virtual objects.\n\nPrerequisites\n\nA domain administrator must have the Project and quota management permission granted, to be able to create projects.\n\nTo create a project\n\nSelect the domain in the drop-down list in the top right corner.\nOpen the Projects screen and click Create project.\n\nIn the Create project window, specify the project name and, optionally, description. The project name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nClear the Enabled check box to disable the created project.\n\nDefine quotas for virtual resources that will be available inside the project. To specify a certain value for a resource, clear the Unlimited check box next to it first.\n\nClick Create.\n\nTo delete a project\n\nSelect the domain in the drop-down list in the top right corner.\nOn the Projects screen, click the ellipsis icon next to the project, and then click Delete.\nIn the confirmation window, click Delete.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-and-deleting-projects.html"
    },
    {
        "title": "Listening to SNMP traps",
        "content": "Listening to SNMP traps\nPrerequisites\n\nThe SNMP access is enabled, as described in Enabling SNMP access.\n\nTo start listening to SNMP traps\n\nConfigure the snmptrapd daemon to log SNMP traps, allow them to trigger executable actions, and resend data to the network. To do this, uncomment the following public community string in the /etc/snmp/snmptrapd.conf file:authCommunity log,execute,net public\r\n\n\nConfigure the firewall to allow inbound traffic on UDP port 162.\nDownload the VSTORAGE-MIB.txt file and place it in the /usr/share/snmp/mibs directory.\n\nStart the daemon and specify the MIB file:# snmptrapd -M /usr/share/snmp/mibs -m VSTORAGE-MIB -n -f\r\n\nBy default, traps will be logged to /var/log/messages. You can redirect them to a custom log file with the -Lf <path> option. For example:# snmptrapd -M /usr/share/snmp/mibs -m VSTORAGE-MIB -n -f -Lf /tmp/traps.log\r\n\n\nSend a test trap from the Settings > System settings > SNMP tab in the admin panel.\n\nView the log file:# tail -f /tmp/traps.log\r\n2019-10-14 12:51:50 node001.vstoragedomain [UDP: [10.94.80.22]:40029->\\\r\n[10.94.80.22]:162]:#012DISMAN-EVENT-MIB::sysUpTimeInstance = Timeticks: \\\r\n(111150521) 12 days, 20:45:05.21#011SNMPv2-MIB::snmpTrapOID.0 = OID: \\\r\nNET-SNMP-MIB::netSnmp.161.3.100#011NET-SNMP-MIB::netSnmp.161.2.1 = STRING: \"TestTrap\"\\\r\n#011NET-SNMP-MIB::netSnmp.161.2.2 = STRING: \"It is the test trap from VStorage\"\\\r\n#011NET-SNMP-MIB::netSnmp.161.2.3 = Counter64: 0\r\n\n\nSee also\n\nAccessing cluster information objects via SNMP\n\nMonitoring the cluster with Zabbix",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/listening-to-snmp-traps.html"
    },
    {
        "title": "Showing IKE policy details",
        "content": "Showing IKE policy detailsGET /v2.0/vpn/ikepolicies/{ikepolicy_id}\nShows details for an IKE policy.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-ike-policy-details-detail#show-ike-policy-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicy_id\n\npath\nstring\nThe ID of the IKE policy.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ikepolicies/94edd562-8b10-4e96-98d7-7b8b99d3ca5d\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicies\n\nbody\narray\nA list of ikepolicy objects.\n\nikepolicy\n\nbody\nobject\nAn ikepolicy object.\n\nname (Optional)\r\n                    \nbody\nstring\n\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\n\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nphase1_negotiation_mode (Optional)\nbody\nstring\nThe IKE mode. A valid value is main, which is the default.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\n\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IKE policy.\n\nike_version (Optional)\n\nbody\nstring\n\nThe IKE version. A valid value is v1 or v2. Default is v1.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"ikepolicy\": {\r\n    \"id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"ikepolicy1\",\r\n    \"description\": \"\",\r\n    \"auth_algorithm\": \"sha1\",\r\n    \"encryption_algorithm\": \"aes-128\",\r\n    \"phase1_negotiation_mode\": \"main\",\r\n    \"lifetime\": {\r\n      \"units\": \"seconds\",\r\n      \"value\": 7200\r\n    },\r\n    \"ike_version\": \"v1\",\r\n    \"pfs\": \"group5\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-ike-policy-details.html"
    },
    {
        "title": "Listing domain quotas",
        "content": "Listing domain quotas\nCores and RAMGET /v2.1/{authorized_project_id}/os-quota-sets/{domain_id}?domain=True\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/0ed0dac39ba14e89b7d2b8cb7d5337f7?domain=True\r\n\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"ram\": 61440,\r\n    <...>\r\n    \"cores\": 30,\r\n    <...>\r\n  }\r\n}\r\n\nStorage limits of storage policies and volume backupsGET /v3/{authorized_project_id}/os-quota-sets/{domain_id}?domain=True\r\n\nRequest# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/0ed0dac39ba14e89b7d2b8cb7d5337f7?domain=True\r\n\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"backup_gigabytes\": 200,\r\n    \"gigabytes_default\": 1024,\r\n    <...>\r\n    \"gigabytes_policy1\": 512\r\n  }\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-domain-quotas.html"
    },
    {
        "title": "Managing virtual routers",
        "content": "Managing virtual routers",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-virtual-routers.html"
    },
    {
        "title": "Creating backup storage on the local cluster",
        "content": "Creating backup storage on the local cluster\nLimitations\n\nRedundancy by replication is not supported for backup storage.\n\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nThe storage cluster has at least one disk with the Storage role.\nThe destination storage has enough space for both existing and new backups.\nEnsure that each node to join the backup storage cluster has the TCP port 44445 open for outgoing Internet connections, as well as for incoming connections from Acronis backup software.\n\nTo select the local cluster as the backup destination\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the Backup (ABGW) private and Backup (ABGW) public traffic types are added to the networks you intend to use.\nOpen the Storage services > Backup storage screen, and then click Create backup storage.\nOn the Backup destination step, select Virtuozzo Hybrid Infrastructure cluster.\nOn the Nodes step, select nodes to add to the backup storage cluster, and then click Next.\n\nOn the Storage policy step, select the desired tier, failure domain, and data redundancy mode. Then, click Next.\n\nOn the DNS step, do one of the following:\n\nSelect Register now, and then specify an external DNS name for backup storage (for example, backupstorage.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data.\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\nSelect Register later to add registrations for your backup storage later or configure it as the secondary cluster for geo-replication.\n\nFor complex environments, HAProxy might be used to build a scalable and redundant load balancing platform, which can be easily moved or migrated and is independent from Virtuozzo Hybrid Infrastructure. For more information, refer to https://kb.acronis.com/content/64787.\n\nIf you selected Register now, specify the following information for your Acronis product on the Acronis account step:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\nOn the Summary step, review the configuration, and then click Create.\n\nAfter creating the backup storage, you can increase its storage capacity at any time by adding space to the local storage cluster, as described in Scaling the storage cluster.\n\nCommand-line interface\nUse the following command:vinfra service backup cluster deploy-standalone --nodes <nodes> --name <name> --address <address>\r\n                                                [--location <location>] --username <username>\r\n                                                --account-server <account-server>\r\n                                                --tier {0,1,2,3} --encoding <M>+<N> \r\n                                                --failure-domain {0,1,2,3,4}\r\n                                                --storage-type local [--stdin]\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--name <name>\n\nBackup registration name.\n--address <address>\n\nBackup registration address.\n--location <location>\n\nBackup registration location.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--storage-type local\n\nSet the storage type to local\n--stdin\n\nUse for setting registration password from stdin.\n\nFor example, to create the backup cluster from three nodes on the local storage, run:# vinfra service backup cluster deploy-standalone --nodes node001,node002,node003 \\\r\n--address backupstorage.example.com --storage-type local --tier 0 --encoding 1+2 --name registration1 \\\r\n--failure-domain 1 --username account@example.com --account-server https://cloud.acronis.com/ --stdin\nThis command also specifies the registration name and address, tier, failure domain, registration account and server.\nYou can view the backup storage details in the vinfra service backup cluster show output:# vinfra service backup cluster show\r\n+-----------------+---------------------------------------------+\r\n| Field           | Value                                       |\r\n+-----------------+---------------------------------------------+\r\n| dc_uid          | 966ac53e-a92c-11ec-be79-fa163ea9f01a        |\r\n| deployment_mode | - standalone                                |\r\n| geo_replication |                                             |\r\n| hosts           | - hostname: node001.vstoragedomain          |\r\n|                 |   id: 24a953ce-b50e-40c2-bf44-0668aafb421d  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node002.vstoragedomain          |\r\n|                 |   id: c1de8940-c38a-d7ae-41b5-bdd35581a906  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node003.vstoragedomain          |\r\n|                 |   id: 2307dc2c-a954-70a2-3673-8a8f832bd46a  |\r\n|                 |   systemd: active                           |\r\n| registrations   | - account_server: https://cloud.acronis.com |\r\n|                 |   address: backupstorage.example.com        |\r\n|                 |   expires: '2025-03-20T15:20:59+00:00'      |\r\n|                 |   id: be526718-d9f8-4f2c-9bd3-04a987f7e4c4  |\r\n|                 |   name: registration1                       |\r\n|                 |   type: ABC                                 |\r\n|                 |   username: account@example.com             |\r\n| status          | deployed                                    |\r\n| storage_params  |                                             |\r\n| storage_type    | local                                       |\r\n| upstreams       | []                                          |\r\n+-----------------+---------------------------------------------+\r\n\n\nWhat's next\n\nAdding backup locations to Acronis Cyber Protect and Acronis Cyber Protect Cloud",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup cluster deploy-standalone --nodes <nodes> --name <name> --address <address>\r\n                                                [--location <location>] --username <username>\r\n                                                --account-server <account-server>\r\n                                                --tier {0,1,2,3} --encoding <M>+<N> \r\n                                                --failure-domain {0,1,2,3,4}\r\n                                                --storage-type local [--stdin]\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--name <name>\n\nBackup registration name.\n--address <address>\n\nBackup registration address.\n--location <location>\n\nBackup registration location.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--storage-type local\n\nSet the storage type to local\n--stdin\n\nUse for setting registration password from stdin.\n\nFor example, to create the backup cluster from three nodes on the local storage, run:# vinfra service backup cluster deploy-standalone --nodes node001,node002,node003 \\\r\n--address backupstorage.example.com --storage-type local --tier 0 --encoding 1+2 --name registration1 \\\r\n--failure-domain 1 --username account@example.com --account-server https://cloud.acronis.com/ --stdin\nThis command also specifies the registration name and address, tier, failure domain, registration account and server.\nYou can view the backup storage details in the vinfra service backup cluster show output:# vinfra service backup cluster show\r\n+-----------------+---------------------------------------------+\r\n| Field           | Value                                       |\r\n+-----------------+---------------------------------------------+\r\n| dc_uid          | 966ac53e-a92c-11ec-be79-fa163ea9f01a        |\r\n| deployment_mode | - standalone                                |\r\n| geo_replication |                                             |\r\n| hosts           | - hostname: node001.vstoragedomain          |\r\n|                 |   id: 24a953ce-b50e-40c2-bf44-0668aafb421d  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node002.vstoragedomain          |\r\n|                 |   id: c1de8940-c38a-d7ae-41b5-bdd35581a906  |\r\n|                 |   systemd: active                           |\r\n|                 | - hostname: node003.vstoragedomain          |\r\n|                 |   id: 2307dc2c-a954-70a2-3673-8a8f832bd46a  |\r\n|                 |   systemd: active                           |\r\n| registrations   | - account_server: https://cloud.acronis.com |\r\n|                 |   address: backupstorage.example.com        |\r\n|                 |   expires: '2025-03-20T15:20:59+00:00'      |\r\n|                 |   id: be526718-d9f8-4f2c-9bd3-04a987f7e4c4  |\r\n|                 |   name: registration1                       |\r\n|                 |   type: ABC                                 |\r\n|                 |   username: account@example.com             |\r\n| status          | deployed                                    |\r\n| storage_params  |                                             |\r\n| storage_type    | local                                       |\r\n| upstreams       | []                                          |\r\n+-----------------+---------------------------------------------+\r\n\n",
                "title": "To select the local cluster as the backup destination"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the Backup (ABGW) private and Backup (ABGW) public traffic types are added to the networks you intend to use.\nOpen the Storage services > Backup storage screen, and then click Create backup storage.\nOn the Backup destination step, select Virtuozzo Hybrid Infrastructure cluster.\nOn the Nodes step, select nodes to add to the backup storage cluster, and then click Next.\n\nOn the Storage policy step, select the desired tier, failure domain, and data redundancy mode. Then, click Next.\n\n\n\n\n\n\nOn the DNS step, do one of the following:\n\n\nSelect Register now, and then specify an external DNS name for backup storage (for example, backupstorage.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data.\n\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\n\n\n\n\n\n\n\nSelect Register later to add registrations for your backup storage later or configure it as the secondary cluster for geo-replication.\n\n\n\nFor complex environments, HAProxy might be used to build a scalable and redundant load balancing platform, which can be easily moved or migrated and is independent from Virtuozzo Hybrid Infrastructure. For more information, refer to https://kb.acronis.com/content/64787.\n\n\n\nIf you selected Register now, specify the following information for your Acronis product on the Acronis account step:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\n\n\n\n\n\nOn the Summary step, review the configuration, and then click Create.\n\nAfter creating the backup storage, you can increase its storage capacity at any time by adding space to the local storage cluster, as described in Scaling the storage cluster.\n",
                "title": "To select the local cluster as the backup destination"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-backup-storage-on-the-local-cluster.html"
    },
    {
        "title": "Deleting IKE policies",
        "content": "Deleting IKE policiesDELETE /v2.0/vpn/ikepolicies/{ikepolicy_id}\nDelete an IKE policy.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=remove-ike-policy-detail#remove-ike-policy\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicy_id\n\npath\nstring\nThe ID of the IKE policy.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ikepolicies/94edd562-8b10-4e96-98d7-7b8b99d3ca5d\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-ike-policies.html"
    },
    {
        "title": "Listing outbound firewall rules",
        "content": "Listing outbound firewall rules\nTo check that all the required outbound allow rules apply to your network\nUse the following command:vinfra cluster network show <network>\n\n<network>\n\nNetwork ID or name\n\nFor example, to view the outbound allow rules of the Public network, run:# vinfra cluster network show Public\r\n+---------------------+---------------------------------------------+\r\n| Field               | Value                                       |\r\n+---------------------+---------------------------------------------+\r\n| encryption          | status: disabled                            |\r\n|                     | subnets:                                    |\r\n|                     | - cidr: 10.100.10.0/20                      |\r\n|                     |   status: disabled                          |\r\n| id                  | c2e799f5-c41d-4865-bcce-06b471affed6        |\r\n| inbound_allow_list  | []                                          |\r\n| inbound_deny_list   | []                                          |\r\n| name                | Public                                      |\r\n| outbound_allow_list | - 0.0.0.0:udp:500:IKE                       |\r\n|                     | - 0.0.0.0:udp:4500:IKE                      |\r\n|                     | - 0.0.0.0:tcp:8888:Admin panel              |\r\n|                     | - 0.0.0.0:tcp:80:HTTP                       |\r\n|                     | - 0.0.0.0:tcp:443:HTTPS                     |\r\n|                     | - 0.0.0.0:udp:53:DNS                        |\r\n|                     | - 0.0.0.0:tcp:53:DNS                        |\r\n|                     | - 0.0.0.0:udp:123:NTP                       |\r\n|                     | - 0.0.0.0:tcp:8443:ABGW registration        |\r\n|                     | - 0.0.0.0:tcp:44445:ABGW Geo-replication    |\r\n|                     | - 0.0.0.0:tcp:9877:Acronis Cyber Protect    |\r\n|                     | - 0.0.0.0:tcp:5900-6079:VM VNC Legacy       |\r\n|                     | - 0.0.0.0:tcp:15900-16900:VM VNC            |\r\n|                     | - 0.0.0.0:udp:4789:VXLAN                    |\r\n|                     | - 0.0.0.0:udp:2049:NFS                      |\r\n|                     | - 0.0.0.0:tcp:2049:NFS                      |\r\n|                     | - 0.0.0.0:tcp:111:NFS Rpcbind               |\r\n|                     | - 0.0.0.0:any:0:Allow all                   |\r\n| traffic_types       | Backup (ABGW) public,Compute API,iSCSI,NFS, |\r\n|                     | S3 public,Self-service ...<truncated>       |\r\n| vlan                | 0                                           |\r\n+---------------------+---------------------------------------------+\nSee also\n\nRestoring default outbound firewall rules",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/listing-outbound-firewall-rules.html"
    },
    {
        "title": "1. About This Guide\u00c2\u00b6",
        "content": "1. About This Guide | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n1. About This Guide\u00c2\u00b6\nThis guide explains how to migrate virtual machines using Acronis Cyber Cloud.\nYou will need to log in to the portal at https://cloud.acronis.com with your account.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/about-this-guide.html"
    },
    {
        "title": "Managing domains and projects",
        "content": "Managing domains and projects",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-domains-and-projects.html"
    },
    {
        "title": "Using application credentials",
        "content": "Using application credentials\nWith application credentials, you can allow your applications to authenticate to OpenStack without embedding user credentials in configuration files. This is especially important in cases when the user's identification is provided by an external system, such as LDAP or a single-sign-on service.\nTo grant an application access to a project, you need to create an application credential with delegated role assignments on this project, and then use the application credential identifier and a secret string for authentication. You can delegate the same role assignments that you have on that project to the application credential or only a subset of your role assignments. This is useful, for example, if you have administrative privileges on a project, but you want to limit the application privileges to read-only.\nTo learn how to create and manage application credentials, refer to the OpenStack documentation.\nSee also\n\nConnecting to OpenStack command-line interface",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-application-credentials.html"
    },
    {
        "title": "Storage cache architecture",
        "content": "Storage cache architecture\nThe terms \"cache\" and \"journal\" are sometimes used interchangeably. In the storage cluster, however, cache refers to a fast hardware device (for example, SSD- or NVMe-based) that is used to store the chunk service journal. A journal, in its turn, is a buffer that is used by the chunk service and stored in a cache device. As multiple chunk services can share the same cache device, one cache can contain multiple journals.\nAs such, caching does not count as an additional storage tier in the cluster. Instead, each cache device can be associated with multiple chunk services that are assigned to different tiers, and used to store data journals.\nBy default, the chunk service stores its journal on the same device as its data. This configuration is called \"inner cache.\" In order to use a fast cache device, the chunk service must be configured to use an \"external cache.\"\n\nIf you use the \"inner cache\" configuration, it is recommended to keep the default journal size of 256 MB.\n\nReads and writes behavior\nIn the storage cluster, cache is mainly used for writing data: when new data is ingested in the system, it is temporarily stored in the cache. As a cache device is faster than a capacity one, writing data on the cache device improves performance. For a certain amount of time, data only exists in the cache, with remote replicas on the other cluster nodes, if remote replication is configured. During this time, all read operations hit the cache and benefit from the performance boost, as well. When the cache is reclaimed and data is removed from it, all subsequent read operations are redirected to a capacity device.\nThe journal is used as a ring buffer: it stores data until there is a need to reclaim space and make room for new data. When this happens, data is offloaded to a capacity device in a first-in, first-out fashion (FIFO).\nCaching benefits\nCaching helps to significantly improve write speed and write latency, with only a slight increase in the system cost. Systems with cache can benefit from high capacity of low-cost and low-performance hard disk devices (HDD), while providing fast write access by using flash devices, such as solid-state drives (SSD) or non-volatile memory devices (NVMe). Though the cost of cache devices is higher than that of capacity devices, only a few cache devices are needed, thereby making the overall system cost generally low. Moreover, the performance boost often justifies such an upgrade.\nYou can benefit from using cache in the following scenarios:\n\n\"Hot\" data storage\nRandom writes\nSmaller block sizes or smaller files\nDatabases and environments with several clients/threads\n\nOn the other hand, scenarios that usually have small advantage when using cache include:\n\n\"Cold\" data storage\nConstant throughput workloads, such as video surveillance recording\nSequential writes of very large files\nRead-intensive workloads\n\nIn these cases, you might use an all-HDD solution, which will provide the same performance at a lower cost; or an all-flash solution, if your aim is to increase performance.\nSee also\n\nStorage cluster architecture\n\nCache configuration",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/storage-cache-architecture.html"
    },
    {
        "title": "Deleting projects",
        "content": "Deleting projectsDELETE /v3/projects/{project_id}\r\n\nDelete a project with the specified ID.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=delete-project-detail#delete-project\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe project ID.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/projects/ec35eb7ceb594ad696839fc867817e4c\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-projects.html"
    },
    {
        "title": "PUT service ostor-limits",
        "content": "PUT service ostor-limits\nDescription\nSets limit values for the specified user or bucket. Either operations count or bandwidth limits can be specified in a single request.\nRequests\nSyntaxPUT /?ostor-limits&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>PUT /?ostor-limits&bucket=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nPUT Service ostor-limits parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nYes*\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes\n\nbandwidth\n\nEnables bandwidth limits.\nBandwidth limits types: { out | kb/s }\nType: flag.\n\nYes**\n\nops\n\nEnables operations limits. If set, all unspecified bandwidth limits are set to 0.\nOperations limits types: { default | ops/min, put | ops/min , get | ops/min, list | ops/min, delete | ops/min }\nType: flag.\n\nYes**\n\ndefault\n\nSets the default value for operations limits. If set, all unspecified operations limits are set to default, otherwise they are set to 0.\nRequires the ops subresource to be set.\nType: integer.\nDefault: 0.\n\nNo\n\nput\n\nSets the PUT operations limit value.\nRequires the ops subresource to be set.\nType: integer.\nDefault: default.\n\nNo\n\nget\n\nSets the GET operations limit value.\nRequires the ops subresource to be set.\nType: integer.\nDefault: default.\n\nNo\n\ndelete\n\nSets the DELETE operations limit value.\nRequires the ops subresource to be set.\nType: integer.\nDefault: default.\n\nNo\n\nlist\n\nSets the LIST operations limit value.\nRequires the ops subresource to be set.\nType: integer.\nDefault: default.\n\nNo\n\nout\n\nSets an outgoing bandwidth limit.\nRequires the ops subresource to be set.\nType: integer.\nDefault: 0.\n\nNo\n\n* Only one of the required parameters can be set in a single request.\n** Either ops or bandwidth can be set in a single request.\r\n\r\n\nZero value means \u00e2\u0080\u009cunlimited\u00e2\u0080\u009d.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nErrors\nReturns Error Code 400 if a wrong set of parameters is specified.\nExamples\nSample request #1\nSets all operations limits for the user with the email user1@email.com to zero.PUT /?ostor-limits&emailAddress=user1@email.com&ops&default=0 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample response #1HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/json\nSample request #2\nSets all operations limits for the user with the email user1@email.com to 1 ops/sec.PUT /?ostor-limits&emailAddress=user1@email.com&ops&default=60 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/json\nSample request #3\nSets all badwidth.out limit for the bucket testbucket to 50 kb/s.PUT /?ostor-limits&bucket=testbucket&bandwidth&out=50 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample response #3HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/json\nSample request #4\nSets operations limits for the bucket testbucket. The new PUT operations limit is 60 ops/s, LIST limit is 0.5 ops/s, GET and DELETE limits are 1 ops/s.PUT /?ostor-limits&bucket=testbucket&ops&default=60&put=3600&list=30 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample response #4HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/json",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/put-service-ostor-limits.html"
    },
    {
        "title": "Configuring the S3 storage usage limit",
        "content": "Configuring the S3 storage usage limit\nTo prevent S3 data from occupying all space in the storage cluster, the S3 service has a limit on storage space usage. The limit defines the minimum percentage of free space the storage cluster must have to allow write operations. By default, this limit is set to 5%, which means that the S3 service can use up to 95% of storage space.\nYou can change the minimum percentage of free space in the storage cluster by using the ostor-ctl put-settings command and setting the OS.min_free_space_percentage parameter to the desired value. For example:# ostor-ctl put-settings OS.min_free_space_percentage=10\n\nDecreasing the default limit of 5% is not recommended as it might bring your storage cluster in the out-of-space condition.\n\nYou can check the new value in the ostor-ctl get-settings output:# ostor-ctl get-settings\r\n NS.bkup_hour=-24\r\n OS.bkup_hour=-24\r\n OS.max_count=100\r\n OS.max_size=1000\r\n OS.min_free_space_percentage=10\r\n cfg.autosplit.enabled=1\r\n cfg.autosplit.max_active=1\r\n gen.lj.max_size_mb=2048\r\n gen.lj.min_size_mb=16\r\n gen.paxos.cache_size=0\r\n gen.paxos.lease_tout=5000\r\n gen.rj.mismatch_abort=1\r\n gen.rj.obj_type_dump=0\r\n hostd.automaintenance.enabled=0\r\n hostd.automaintenance.threshold=10\r\n ostor.default_cors.enabled=1\nSee also\n\nSupported Amazon S3 features\n\nConfiguring the default CORS behavior\n\nManaging S3 buckets",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-s3-storage-usage-limit.html"
    },
    {
        "title": "Configuring the self-service panel",
        "content": "Configuring the self-service panel\nAfter you provide access to the self-service panel, you can configure  its virtual IP address and branding theme.\nPrerequisites\n\nThe port for accessing the self-service panel is opened by following the instructions in Providing access to the self-service portal.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-the-self-service-panel.html"
    },
    {
        "title": "Deleting Kubernetes clusters",
        "content": "Deleting Kubernetes clustersDELETE /v1/clusters/{cluster_ident}\r\n\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=delete-a-cluster-detail#delete-a-cluster\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ncluster_ident\n\npath\nstring\nThe UUID or name of clusters in Magnum.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9513/v1/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-kubernetes-clusters.html"
    },
    {
        "title": "Managing guest tools",
        "content": "Managing guest tools\nThis section explains how to install and uninstall the guest tools. This functionality is required for creating consistent snapshots of a running VM\u00e2\u0080\u0099s disks.\nLimitations\n\nGuest tools rely on the QEMU guest agent that is installed alongside the tools. The agent service must be running for the tools to work.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\nThe virtual machine has a guest operating system installed.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-guest-tools.html"
    },
    {
        "title": "Setting domain quotas",
        "content": "Setting domain quotas\nCores and RAMPUT /v2.1/{authorized_project_id}/os-quota-sets/{domain_id}?domain=True\nRequest# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"quota_set\": {\r\n    \"ram\": 65536,\r\n    \"cores\": 30\r\n  }\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/0ed0dac39ba14e89b7d2b8cb7d5337f7?domain=True\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"ram\": 61440,\r\n    <...>\r\n    \"cores\": 30,\r\n    <...>\r\n  }\r\n}\r\n\nStorage limits of storage policiesPUT /v3/{authorized_project_id}/os-quota-sets/{domain_id}?domain=True\r\n\nRequest# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"quota_set\": {\r\n    \"gigabytes_default\": 1024,\r\n    \"gigabytes_policy1\": 512,\r\n    \"backup_gigabytes\": 200\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/os-quota-sets/0ed0dac39ba14e89b7d2b8cb7d5337f7?domain=True\nResponse{\r\n  \"quota_set\": {\r\n    <...>\r\n    \"backup_gigabytes\": 200,\r\n    \"gigabytes_default\": 1024,\r\n    <...>\r\n    \"gigabytes_policy1\": 512\r\n  }\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/setting-domain-quotas.html"
    },
    {
        "title": "About the compute cluster",
        "content": "About the compute cluster\nThe compute cluster provides virtualization management for virtual machines and software-defined networks. In Virtuozzo Hybrid Infrastructure, virtual machines are based on open-source technology and can run both Windows and Linux guests. They are also highly available and can be migrated live with no downtime. Moreover, VM volume snapshots are application consistent.\nVirtuozzo Hybrid Infrastructure provides for the most efficient usage of the compute resources with Kubernetes as a Service, Load Balancer as a Service, Backup and Restore as a Service, and metering for account compute resources. To allocate space to virtual machines and select different redundancy modes, storage policies are applied to VM volumes. Storage policies can also limit bandwidth and IOPS in order to provide predictable performance levels for VM disks. Besides, to distribute the workload between nodes, the virtual machine placement can be based on the node characteristics.\nIn Virtuozzo Hybrid Infrastructure, administrators can create multiple domains, tenants, and users, and allocate resources according to tenant quotas. Moreover, they can use white-labeling to build their own public or private cloud storage solutions. At that, independent end users of compute resources are isolated and secure in their own self-service portals.\nVirtuozzo Hybrid Infrastructure provides secure and isolated virtual networking for virtual machines using VXLAN encapsulation. The distributed virtual switching and routing simplify VM network configuration, and the built-in firewall makes it more secure. The integrated DHCP, IP, and DNS management provides for enhanced configuration of the network.\n\nSee also\n\nProvisioning compute resources",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/about-the-compute-cluster.html"
    },
    {
        "title": "Listing IKE policies",
        "content": "Listing IKE policiesGET /v2.0/vpn/ikepolicies\nList IKE policies.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-ike-policies-detail#list-ike-policies\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ikepolicies\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicies\n\nbody\narray\nA list of ikepolicy objects.\n\nikepolicy\n\nbody\nobject\nAn ikepolicy object.\n\nname (Optional)\r\n                    \nbody\nstring\n\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\n\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nphase1_negotiation_mode (Optional)\nbody\nstring\nThe IKE mode. A valid value is main, which is the default.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\n\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IKE policy.\n\nike_version (Optional)\n\nbody\nstring\n\nThe IKE version. A valid value is v1 or v2. Default is v1.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"ikepolicies\": [\r\n    {\r\n      \"id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n      \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n      \"name\": \"ikepolicy1\",\r\n      \"description\": \"\",\r\n      \"auth_algorithm\": \"sha1\",\r\n      \"encryption_algorithm\": \"aes-128\",\r\n      \"phase1_negotiation_mode\": \"main\",\r\n      \"lifetime\": {\r\n        \"units\": \"seconds\",\r\n        \"value\": 7200\r\n      },\r\n      \"ike_version\": \"v1\",\r\n      \"pfs\": \"group5\",\r\n      \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-ike-policies.html"
    },
    {
        "title": "Admin panel requirements",
        "content": "Admin panel requirements\n\nThe admin panel requires a Full HD monitor to be displayed correctly. \nThe admin panel has been tested to work at resolutions 1280x720 and higher in the following web browsers: latest Firefox, Chrome, Safari.\nThe admin and self-service panels only support TLS versions 1.2 and 1.3.\n\nSee also\n\nHardware recommendations\n\nServer requirements\n\nDisk requirements\n\nNetwork requirements and recommendations",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/admin-panel-requirements.html"
    },
    {
        "title": "Configuring node network interfaces",
        "content": "Configuring node network interfaces\nBefore creating the storage cluster, you need to configure the network interfaces on each node. You can specify network parameters and assign networks to network interfaces by editing them.\nAccording to your network requirements, you might also need to create bonded and VLAN connections. In addition, if your node network adapters support RDMA, configure InfiniBand network infrastructure.\nPrerequisites\n\nYour network hardware meets the requirements listed in Network requirements and recommendations.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-node-network-interfaces.html"
    },
    {
        "title": "Removing outbound firewall rules",
        "content": "Removing outbound firewall rules\n\nWhen restricting outbound traffic, it is recommend to modify the default outbound rules to use specific IP addresses or subnets, according to your network infrastructure and security policies.\n\nTo remove outbound firewall rules\nUse the following command:vinfra cluster network set --del-outbound-allow-list <rules> <network>\n\n--add-outbound-allow-list <rules>\n\nA comma-separated list of allow rules in the format: <address>:<protocol>:<port>:<description>, where:\n\n<address> is a single IP address (10.10.10.10), address range (10.10.10.0-10.10.10.10), or subnet CIDR (10.10.10.0/32)\n<protocol> can be udp, tcp, or any\n<port> is an integer value (22) or a range (20-22)\n<description> usually contains the name of the service that uses the specified port\n\n<network>\n\nNetwork ID or name\n\nFor example, to remove the rule 0.0.0.0:any:0:Allow all, which allows all outbound traffic, run:# vinfra cluster network set Public --del-outbound-allow-list \"0.0.0.0:any:0:Allow all\"\nIn this case, all attempts to establish connections from the cluster to external endpoints will be blocked.\nWhat's next\n\nListing outbound firewall rules",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/removing-outbound-firewall-rules.html"
    },
    {
        "title": "Generating S3 account access key pairs via CLI",
        "content": "Generating S3 account access key pairs via CLI\nYou can generate a new access key pair for the specified account of an S3 user with the ostor-s3-admin gen-access-key command. The maximum of 2 active access key pairs are allowed per account. You need to specify either the user email (-e) or S3 ID (-i) and the account name. For example:# ostor-s3-admin gen-access-key -V 0100000000000002 -n account -e user@email.com\r\nS3AccessKeyId:b09693b73b3c7686WCF3\r\nS3SecretAccessKey:GMzOPHJ66qbnxjrqFMHrN2fnxjkGf67u9OXec3PQ\nIt is recommended to periodically revoke old and generate new access key pairs.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/generating-s3-account-access-key-pairs-via-cli.html"
    },
    {
        "title": "Installation",
        "content": "Installation\nThis section describes the installation process of Virtuozzo Hybrid Infrastructure.\nLimitations\n\nA display for the installation program must have a minimum screen resolution of 800x600. With 800x600, however, you may experience issues with the user interface. For example, some elements can be inaccessible. The recommended screen resolution is at least 1024x768. \nOne node can be a part of only one cluster.\nWe only support the UTC time zone. Changing the time zone for nodes is not supported and may lead to system unavailability.\n\nPrerequisites\n\nA clear understanding of the infrastructure, which is explained in About the infrastructure.\nYour infrastructure hardware meets the requirements listed in System requirements. \n\nInstallation overview\n\nObtain the distribution ISO image. To do that, visit the product page and submit a request for the trial version.\n\nPrepare the bootable media by using the distribution ISO image:  create a bootable USB drive, mount the distribution image to an IPMI virtual drive, or set up a PXE server.\nIf the server's display resolution is lower than  800x600, connect to the server from a remote machine  via VNC.\nIf you plan to perform an unattended installation, create a kickstart file.\n\nInstall Virtuozzo Hybrid Infrastructure on each server in the attended  or unattented mode.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/installation.html"
    },
    {
        "title": "Connecting virtual switches to trunk interfaces",
        "content": "Connecting virtual switches to trunk interfaces\nIf you plan to use a large number of VLAN-based networks for virtual machines, you can benefit from the automated procedure of VLAN-based network creation. When you create a VLAN-based network in the compute cluster, the system automatically creates an associated infrastructure network and configures VLAN network interfaces on all of the compute nodes via the distributed virtual switch.\nTo use the automated VLAN-based network creation, consider the following cases:\n\nIf a node's trunk interface is connected to a virtual switch (its name has the format br-<interface>), you can proceed to creating VLAN-based networks in the compute cluster.\nIf a node's trunk interface has no VLANs and is not connected to a virtual switch, assign the VM public traffic type to the infrastructure network connected to this trunk interface. The virtual switch will be configured automatically on the trunk interface after creating a VLAN-based network.\nIf you have existing VLANs but no virtual switch connected to a trunk interface, convert the trunk interface configuration to the virtual switch one, as described below.\n\nIf your network configuration includes only a few VLAN-based networks, you can create VLAN network interfaces separately on each compute node, as described in Creating VLAN interfaces.\nLimitations\n\nFor VLAN-based networks, the corresponding VLAN IDs must be configured on the physical switches connected to the compute nodes.\n\nTo connect a trunk network interface to a virtual switch\n\nCheck whether VLAN network interfaces connected to your network  can be converted to Open vSwitch VLAN. For example:# vinfra cluster network conversion precheck --network mynet\r\n+---------------------+-------------------------------------------------+\r\n| Field               | Value                                           |\r\n+---------------------+-------------------------------------------------+\r\n| affected_interfaces | - interface: eth0                               |\r\n|                     |   node_id: 13cb6cbf-0b9b-be0f-bb56-8ed6a0e9225c |\r\n|                     |   vlans:                                        |\r\n|                     |   - eth0.1                                      |\r\n|                     | - interface: eth0                               |\r\n|                     |   node_id: 6e5d9e91-5c4e-a874-38cd-fe6f4bef10a4 |\r\n|                     |   vlans:                                        |\r\n|                     |   - eth0.1                                      |\r\n|                     | - interface: eth0                               |\r\n|                     |   node_id: 1053e85b-351c-6113-5623-e0c6c64995e7 |\r\n|                     |   vlans:                                        |\r\n|                     |   - eth0.1                                      |\r\n| affected_networks   | - mynet                                         |\r\n| physical_network    | Public                                          |\r\n+---------------------+-------------------------------------------------+\r\n\n\nConvert the VLAN network interfaces to Open vSwitch VLAN. During the conversion you may experience connection timeouts. For example:# vinfra cluster network conversion start --network mynet\r\n+---------+--------------------------------------+\r\n| Field   | Value                                |\r\n+---------+--------------------------------------+\r\n| task_id | 058fc247-03a8-49fa-90e1-1e073dbafec9 |\r\n+---------+--------------------------------------+\r\n\nIf your trunk network interface is not assigned to any infrastructure network, specify the name of a new infrastructure network by using the --physical-network-name <name> option. The new infrastructure network will be automatically created with the given name and assigned to the trunk interface.\n\nCheck the conversion status. For example:# vinfra cluster network conversion status 058fc247-03a8-49fa-90e1-1e073dbafec9\r\n+---------------------+-------------------------------------------------+\r\n| Field               | Value                                           |\r\n+---------------------+-------------------------------------------------+\r\n| affected_interfaces | - interface: eth0                               |\r\n|                     |   node_id: 13cb6cbf-0b9b-be0f-bb56-8ed6a0e9225c |\r\n|                     |   vlans:                                        |\r\n|                     |   - eth0.1                                      |\r\n|                     | - interface: eth0                               |\r\n|                     |   node_id: 6e5d9e91-5c4e-a874-38cd-fe6f4bef10a4 |\r\n|                     |   vlans:                                        |\r\n|                     |   - eth0.1                                      |\r\n|                     | - interface: eth0                               |\r\n|                     |   node_id: 1053e85b-351c-6113-5623-e0c6c64995e7 |\r\n|                     |   vlans:                                        |\r\n|                     |   - eth0.1                                      |\r\n| flow                | done                                            |\r\n| physical_network    | Public                                          |\r\n| state               | success                                         |\r\n| task_id             | 058fc247-03a8-49fa-90e1-1e073dbafec9            |\r\n+---------------------+-------------------------------------------------+\r\n\n\nWhen the conversion is complete, you will be able to create more VLAN interfaces on the trunk network interface by using the simplified procedure.\nSee also\n\nCompute network architecture\n\nWhat's next\n\nCreating physical compute networks",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/connecting-virtual-switches-to-trunks.html"
    },
    {
        "title": "Listing S3 users via CLI",
        "content": "Listing S3 users via CLI\nYou can list all object storage users with the ostor-s3-admin query-users command. Information for each user can take one or more sequential rows in the table. Additional rows are used to lists S3 access key pairs associated with the user. If the user does not have any active key pairs, minus signs are shown instead. For example:# ostor-s3-admin query-users -V 0100000000000002\r\n      S3 USER ID      S3 ACCESS KEY ID     S3 SECRET ACCESS KEY  S3 USER EMAIL\r\nbf0b3b15eb7c9019  bf0b3b15eb7c9019I36Y                      ***  user2@abc.com\r\nd866d9d114cc3d20  d866d9d114cc3d20G456                      ***  user1@abc.com\r\n                  d866d9d114cc3d20D8EW                      ***\r\ne86d1c19e616455                      -                        -  user3@abc.com\r\n\nTo output the list in XML, use the -X option; to output secret keys, use the -a option. For example:# ostor-s3-admin query-users -V 0100000000000002 -a -X\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?><QueryUsersResult><Users><User><Id>a49e12a226bd760f</Id><Email>user@email.com</Email><Keys><OwnerId>0000000000000000</OwnerId><KeyPair><S3AccessKeyId>a49e12a226bd760fGHQ7</S3AccessKeyId><S3SecretAccessKey>HSDu2DA00JNGjnRcAhLKfhrvlymzOVdLPsCK2dcq</S3SecretAccessKey></KeyPair></Keys></User><User><Id>d7c53fc1f931661f</Id><Email>user@email.com</Email><Keys><OwnerId>0000000000000000</OwnerId><KeyPair><S3AccessKeyId>d7c53fc1f931661fZLIV</S3AccessKeyId><S3SecretAccessKey>JL7gt1OH873zR0Fzv8Oh9ZuA6JtCVnkgV7lET6ET</S3SecretAccessKey></KeyPair></Keys></User></Users></QueryUsersResult>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/listing-s3-users-via-cli.html"
    },
    {
        "title": "Listing floating IPs",
        "content": "Listing floating IPsGET /v2.0/floatingips\r\n\nLists floating IPs.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-floating-ips-detail#list-floating-ips\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nid (Optional)\nquery\nstring\nFilter the list result by the ID of the resource.\n\nrouter_id (Optional)\nquery\nstring\nFilter the floating IP list result by the ID of the router for the\r\nfloating IP.\n\nstatus (Optional)\nquery\nstring\nFilter the floating IP list result by the status of the floating IP.\r\nValues are ACTIVE, DOWN and ERROR.\n\ndescription (Optional)\nquery\nstring\nFilter the list result by the human-readable description of the resource.\n\ntenant_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\nrevision_number (Optional)\nquery\ninteger\nFilter the list result by the revision number of the resource.\n\nproject_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\nfloating_network_id (Optional)\nquery\nstring\nFilter the floating IP list result by the ID of the network associated\r\nwith the floating IP.\n\nfixed_ip_address (Optional)\nquery\nstring\nFilter the floating IP list result by the fixed IP address that\r\nis associated with the floating IP address.\n\nfloating_ip_address (Optional)\nquery\nstring\nFilter the floating IP list result by the floating IP address.\n\nport_id (Optional)\nquery\nstring\nFilter the floating IP list result by the ID of a port associated with\r\nthe floating IP.\n\nsort_dir (Optional)\nquery\nstring\nSort direction. A valid value is asc (ascending) or desc\r\n(descending). You can specify multiple pairs of sort key and\r\nsort direction query parameters.\n\nsort_key (Optional)\nquery\nstring\n\nSorts by a floatingip attribute. You can specify multiple pairs of sort key\r\nand sort direction query parameters. The sort keys are limited to:\n\nfixed_ip_address\n\nfloating_ip_address\n\nfloating_network_id\n\nid\n\nrouter_id\n\nstatus\n\ntenant_id\n\nproject_id\n\ntags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be returned.\r\nTags in query must be separated by comma.\n\ntags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be returned.\r\nTags in query must be separated by comma.\n\nnot-tags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be excluded.\r\nTags in query must be separated by comma.\n\nnot-tags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be excluded.\r\nTags in query must be separated by comma.\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/floatingips\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingips\n\nbody\narray\nA list of floatingip objects.\n\nid\n\nbody\nstring\nThe ID of the floating IP address.\n\nrouter_id\n\nbody\nstring\nThe ID of the router for the floating IP.\n\nstatus\n\nbody\nstring\nThe status of the floating IP. Values are\r\nACTIVE, DOWN and ERROR.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\ndns_name\n\nbody\nstring\nA valid DNS name.\n\nport_details\n\nbody\nstring\nThe information of the port that this floating IP associates with.\r\nIn particular, if the floating IP is associated with a port, this field\r\ncontains some attributes of the associated port, including name,\r\nnetwork_id, mac_address, admin_state_up, status,\r\ndevice_id and device_owner. If the floating IP is not associated\r\nwith a port, this field is null.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nfloating_network_id\n\nbody\nstring\nThe ID of the network associated with the\r\nfloating IP.\n\nfixed_ip_address\n\nbody\nstring\nThe fixed IP address that is associated with the\r\nfloating IP address.\n\nfloating_ip_address\n\nbody\nstring\nThe floating IP address.\n\nport_id\n\nbody\nstring\n\nThe ID of a port associated with the floating IP.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\nport_forwardings\n\nbody\narray\nThe associated port forwarding resources for the floating IP. If the\r\nfloating IP has multiple port forwarding resources, this field has\r\nmultiple entries. Each entry consists of network IP protocol\r\n(protocol), the fixed IP address of internal neutron port\r\n(internal_ip_address), the TCP or UDP port used by internal\r\nneutron port (internal_port) and the TCP or UDP port used by\r\nfloating IP (external_port).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"floatingips\": [\r\n    {\r\n      \"router_id\": \"02542148-44cb-470d-a551-58f370c47b83\",\r\n      \"status\": \"ACTIVE\",\r\n      \"description\": \"\",\r\n      \"tags\": [],\r\n      \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"created_at\": \"2020-03-04T16:37:27Z\",\r\n      \"updated_at\": \"2020-03-04T16:37:32Z\",\r\n      \"floating_network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n      \"port_details\": {\r\n        \"status\": \"ACTIVE\",\r\n        \"name\": \"\",\r\n        \"admin_state_up\": true,\r\n        \"network_id\": \"c4e2f31b-fe3b-402b-ac1b-b182693f72f7\",\r\n        \"device_owner\": \"compute:nova\",\r\n        \"mac_address\": \"fa:16:3e:66:ab:b3\",\r\n        \"device_id\": \"e1ae6f7e-c35d-4656-a4fd-2371f9a791d4\"\r\n      },\r\n      \"fixed_ip_address\": \"192.168.0.112\",\r\n      \"floating_ip_address\": \"10.94.139.170\",\r\n      \"revision_number\": 1,\r\n      \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"port_id\": \"165d5ff3-d015-4361-9bce-d59054c585cf\",\r\n      \"id\": \"239fe333-b801-4096-a04f-20f33f6177c3\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-floating-ips.html"
    },
    {
        "title": "Preparing Linux templates",
        "content": "Preparing Linux templates\nAs all Linux guests have OpenSSH Server preinstalled by default, you only need to make sure a Linux template has cloud-init installed.\nThe easiest way to get a Linux template with cloud-init installed is to obtain it from its official repository. You can also create a Linux template from an existing boot volume.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/preparing-linux-templates.html"
    },
    {
        "title": "Querying user quotas via REST API",
        "content": "Querying user quotas via REST API\nYou can display the specific quotas per user with the ostor-quotas service and parameter emailAddress specifying the email address:# s3_curl GET \"http://s3.example.com/?ostor-quotas&emailAddress=user@example.com\"\r\n{\r\n    \"version\": \"1\",\r\n    \"type\": \"user\",\r\n    \"size\": \"1024\"\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-user-quotas-via-rest-api.html"
    },
    {
        "title": "Configuring CPU features for virtual machines",
        "content": "Configuring CPU features for virtual machines\nYou can enable or disable CPU feature flags for virtual machines without changing them on compute nodes. By configuring particular CPU feature flags for the compute cluster, you can avoid live migration compatibility issues across compute nodes, as well as control nested virtualization capabilities.\nLimitations:\n\nChanging CPU features affects only new VMs, that is, those created after the change.\n\nPrerequisites\n\nThe compute cluster CPU model is set, as instructed in Setting virtual machine CPU model.\nCheck the supported CPU feature flags on your compute nodes in the lscpu command output.\n\nTo enable or disable CPU features\n\nCheck the CPU model set for the compute cluster. For example:# vinfra service compute show | grep cpu_model:\r\n| options      | cpu_model: Broadwell\n\nConfigure the desired CPU features for this CPU model. For example, to disable nested virtualization for Intel-based virtual machines, run:# vinfra service compute set --cpu-model Broadwell --cpu-features='-vmx'\n\nIf you want to re-enable this CPU feature, run:# vinfra service compute set --cpu-model Broadwell --cpu-features='+vmx'\n\nOnce you have configured CPU features for the compute cluster, you can start creating virtual machines.\nTo check CPU features of a virtual machine\n\nFind out the host and ID of the required virtual machine by listing VMs in the compute cluster. For example:# vinfra service compute server list\r\n+--------------------------------------+-------+--------+------------------------+---------------------------+\r\n| id                                   | name  | status | host                   | networks                  |\r\n+--------------------------------------+-------+--------+------------------------+---------------------------+\r\n| e893481f-f5d1-4c59-8c81-fc3df45b71f8 | myvm  | ACTIVE | node001.vstoragedomain | - private=192.168.128.237 |\r\n+--------------------------------------+-------+--------+------------------------+---------------------------+\n\nLog in to the host compute node and check the VM configuration by using the virsh dumpxml command. For example:# ssh node001.vstoragedomain\r\n# virsh dumpxml e893481f-f5d1-4c59-8c81-fc3df45b71f8 | grep vmx\r\n    <feature policy='disable' name='vmx'/>\n\nSee also\n\nEnabling nested virtualization\n\nChanging virtual CPU overcommitment\n\nConfiguring memory for virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-vm-cpu-features.html"
    },
    {
        "title": "Migration Guides",
        "content": "Migration GuidesAcronis Cyber Cloud Migration from VMwareHystax Acura Migration from VMwareArrosoft CloudAny Migration from VMwareCloudBase Coriolis Migration Guide",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/migration-guides/"
    },
    {
        "title": "Supported Amazon S3 features",
        "content": "Supported Amazon S3 features\nBesides basic Amazon S3 operations like GET, PUT, COPY, DELETE, the Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol supports the following features:\n\nMultipart upload\n\nAccess control lists (ACLs)\nVersioning\n\nPresigned URLs\n\nObject locking\n\nServer access logging\n\nObject storage classes (refer to Defining object storage classes)\nCross-region replication (CRR) (refer to Enabling S3 cross-region replication)\nBucket policies (refer to Amazon S3 features supported by bucket policies)\nBucket lifecycle (object expiration only) (refer to Supported Amazon S3 object expiration actions)\nCross-origin resource sharing (CORS) (refer to Configuring the default CORS behavior)\nBucket notifications (refer to Configuring bucket notifications)\n\nAll of the supported Amazon S3 operations, headers, and authentication schemes are listed further.\n\nSee also\n\nDefining object storage classes\n\nConfiguring the default CORS behavior\n\nConfiguring bucket notifications",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-s3-features.html"
    },
    {
        "title": "Server requirements",
        "content": "Server requirements\nThe hardware requirements and recommended number of servers in a cluster depend on the services you will deploy in your cluster.\n\nSee also\n\nHardware recommendations\n\nDisk requirements\n\nNetwork requirements and recommendations\n\nAdmin panel requirements",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/server-requirements.html"
    },
    {
        "title": "Provisioning block storage space",
        "content": "Provisioning block storage space\nBlock storage space is provisioned via storage volumes connected to a target group.\nLimitations\n\nEach node in a target group can host a single target for that group.\nBlock storage space is not fully thin provisioned. After user data removal, unused storage space is not reclaimed and is reported as actual used space, which is charged according to your licensing model. For more details, refer to Logical space chart.\n\nPrerequisites\n\nA clear understanding of block storage, which is explained in About block storage.\nYour hardware meets the requirements listed in Server requirements.\nYour infrastructure networks are set up, as described in Setting up networks for block storage.\nThe storage cluster is created by following the instructions in Deploying the storage cluster.\n\nProvisioning overview\n\nCreate a target group.\nCreate block volumes and attach them to the target group as LUNs.\n\nConnect initiators to targets by using standard tools of your operating system or product, as described in Accessing iSCSI targets in the Storage User\u00e2\u0080\u0099s Guide.\nTo view target IQNs, click the target group name.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-block-storage.html"
    },
    {
        "title": "Removing all volumes from backup plans",
        "content": "Removing all volumes from backup plansPOST /v3/{project_id}/os-volume-backup-plan/disassociate_all\nRemove all of the associated volumes from a backup plan.\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nbackup_plan_id\n\nbody\nstring\nThe backup plan UUID.\n\nbackup_plan_hash\n\nbody\nstring\nThe backup plan hash. It can be obtained from the details of a backup plan (refer to Showing backup plan details).\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"backup_plan_id\": \"4f40774a4da945cda806d59ca7c74355\",\r\n    \"backup_plan_hash\": \"69932aac5f2e4468fe668e5166265485aa3f7cdf\"\r\n}' https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/os-volume-backup-plan/disassociate_all\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/removing-all-volumes-from-backup-plans.html"
    },
    {
        "title": "Managing virtual machines",
        "content": "Managing virtual machines\nEach virtual machine (VM) is an independent system with an independent set of virtual hardware. Its main features are the following:\n\nA virtual machine resembles and works like a regular computer. It has its own virtual hardware. Software applications can run in virtual machines without any modifications or adjustment.\nVirtual machine configuration can be changed easily, for example, by adding new virtual disks or memory.\nAlthough virtual machines share physical hardware resources, they are fully isolated from each other (file system, processes, sysctl variables) and the compute node.\nA virtual machine can run any supported guest operating system.\n\nThe following table lists the current virtual machine configuration limits:\n\nResource\nLimit\n\nRAM\n1 TiB\n\nCPU\n64 virtual CPUs\n\nStorage\n15 volumes, 512 TiB each\n\nNetwork\n15 NICs\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-virtual-machines.html"
    },
    {
        "title": "Chunks chart",
        "content": "Chunks chart\n\nAdmin panel\nYou can monitor the state of all chunks in the cluster on the Chunks chart. Chunks can be in the following states:\n\nHealthy\n\nNumber and percentage of chunks that have enough active replicas. The normal state of chunks.\nOffline\n\nNumber and percentage of chunks all replicas of which are offline. Such chunks are completely inaccessible for the cluster and cannot be replicated, read from or written to. All requests to an offline chunk are frozen until a CS that stores that chunk\u00e2\u0080\u0099s replica goes online.\nGet offline chunk servers back online as fast as possible, to avoid losing data.\n\nBlocked\n\nNumber and percentage of chunks that have fewer active replicas than the set minimum amount. Write requests to a blocked chunk are frozen until it has at least the set minimum amount of replicas. Read requests to blocked chunks are allowed, however, as they still have some active replicas left. Blocked chunks have a higher replication priority than degraded chunks.\nHaving blocked chunks in the cluster increases the risk of losing data, so postpone any maintenance on working cluster nodes and get offline chunk servers back online as fast as possible.\n\nDegraded\n\nNumber and percentage of chunks whose active replicas are few, but not below the set minimum. Such chunks can be read from and written to. However, in the latter case a degraded chunk becomes urgent.\n\nHealthy chunks are highlighted on the scale in green, offline in red, blocked in yellow, and degraded in grey. For example:\n\nThe Replication section shows the information about replication activity in the cluster.\n\nCommand-line interface\nUse the following command:vinfra cluster overview\nFor example, to view the information about chunks in the cluster cluster1, take a look at these lines from the command output:\r\n+-------------------+-------------------------+\r\n| Field             | Value                   |\r\n+-------------------+-------------------------+\r\n| ...               | ...                     |\r\n| chunks            | blocked: 0              |\r\n|                   | degraded: 0             |\r\n|                   | deleting: 0             |\r\n|                   | healthy: 153            |\r\n|                   | offline: 0              |\r\n|                   | overcommitted: 0        |\r\n|                   | pending: null           |\r\n|                   | replicating: 0          |\r\n|                   | standby: null           |\r\n|                   | total: 153              |\r\n|                   | unique: 0               |\r\n|                   | urgent: 0               |\r\n|                   | void: 0                 |\r\n| ...               | ...                     |\r\n+-------------------+-------------------------+\r\n\n\nblocked\n\nNumber of chunks that have fewer active replicas than the set minimum amount. Write requests to a blocked chunk are frozen until it has at least the set minimum amount of replicas. Read requests to blocked chunks are allowed, however, as they still have some active replicas left. Blocked chunks have a higher replication priority than degraded chunks.\nHaving blocked chunks in the cluster increases the risk of losing data, so postpone any maintenance on working cluster nodes and get offline chunk servers back online as fast as possible.\n\ndegraded\n\nNumber of chunks whose active replicas are few, but not below the set minimum. Such chunks can be read from and written to. However, in the latter case, a degraded chunk becomes urgent.\ndeleting\n\nNumber of chunks queued for deletion.\nhealthy\n\nNumber of chunks that have enough active replicas. The normal state of chunks.\noffline\n\nNumber of chunks all replicas of which are offline. Such chunks are completely inaccessible for the cluster and cannot be replicated, read from or written to. All requests to an offline chunk are frozen until a CS that stores that chunk\u00e2\u0080\u0099s replica goes online.\nGet offline chunk servers back online as fast as possible, to avoid losing data.\n\novercommitted\n\nNumber of chunks that have more replicas than normal. Usually these chunks appear after the normal number of replicas has been lowered or a lot of data has been deleted. Extra replicas are eventually dropped, however, this process may slow down during replication.\npending\n\nNumber of chunks that must be replicated immediately. For a write request from client to a chunk to complete, the chunk must have at least the set minimum amount of replicas. If it does not, the chunk is blocked and the write request cannot be completed. As blocked chunks must be replicated as soon as possible, the cluster places them in a special high-priority replication queue and reports them as pending.\nreplicating\n\nNumber and percentage of chunks which are being replicated. Write operations on such chunks are frozen until replication ends.\nstandby\n\nNumber of chunks that have one or more replicas in the standby state. A replica is marked standby if it has been inactive for no more than 5 minutes.\ntotal\n\nTotal number of all chunks in the storage cluster.\nunique\n\nNumber of chunks that do not have replicas.\nurgent\n\nNumber and percentage of chunks which are degraded and have non-identical replicas. Replicas of a degraded chunk may become non-identical if some of them are not accessible during a write operation. As a result, some replicas happen to have the new data while some still have the old data. The latter are dropped by the cluster as fast as possible. Urgent chunks do not affect information integrity as the actual data is stored in at least the set minimum amount of replicas.\nvoid\n\nNumber and percentage of chunks that have been allocated but never used yet. Such chunks contain no data. It is normal to have some void chunks in the cluster.\n\nSee also\n\nI/O activity charts\n\nServices chart\n\nPhysical space chart\n\nLogical space chart",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/chunks-chart.html"
    },
    {
        "title": "Creating backup plans",
        "content": "Creating backup plansPOST /v2/{project_id}/jobs\nCreate a backup plan.\nSource: https://docs.openstack.org/api-ref/backup/v2/index.html#creates-job-v2\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nname\n\nbody\nstring\nThe name of the job.\n\ndescription\n\nbody\nstring\nThe description of the job.\n\nclient_id\n\nbody\nstring\nThe client UUID.\n\njob_schedule\n\nbody\ndict\nThe schedule information of the job.\n\njob_actions\n\nbody\nlist\nA list of actions that carry out the backup/restore job.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\{\r\n    \"name\": \"myplan\",\r\n    \"description\": \"My new plan\",\r\n    \"client_id\": \"hci\",\r\n    \"job_schedule\": {\r\n        \"schedule_day_of_week\": \"0,1,2,3,4,5,6\",\r\n        \"schedule_month\": \"1,2,3,4,5,6,7,8,9,10,11,12\",\r\n        \"schedule_day\": \"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31\",\r\n        \"schedule_minute\": \"00\",\r\n        \"schedule_hour\": \"13\"\r\n    },\r\n    \"job_actions\": [\r\n        {\r\n          \"freezer_action\": {\r\n            \"action\": \"backup\",\r\n            \"mode\": \"hci-volumes\",\r\n            \"recovery_points_rotation\": 7\r\n          },\r\n          \"user_id\": \"d1899d7f32d64b1bb95e262e7a6a4bc2\",\r\n          \"project_id\": \"3046fb2c2a314a0fbb32607caa1e5277\",\r\n          \"action_id\": \"b9dc9e548b914b80a06d752342828371\"\r\n        }\r\n    ]\r\n}' https://<node_IP_addr>:8736/v2/3046fb2c2a314a0fbb32607caa1e5277/jobs\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\njob_id\n\nbody\nstring\nThe job UUID.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"job_id\": \"e632eb1884e0468c8a41e656942df500\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-backup-plans.html"
    },
    {
        "title": "Managing guest tools",
        "content": "Managing guest tools\nThis section explains how to install and uninstall the guest tools. This functionality is required for running commands in virtual machines without network connectivity and setting a password inside virtual machines, as well as for creating consistent snapshots of a running VM\u00e2\u0080\u0099s disks.\nLimitations\n\nGuest tools rely on the QEMU guest agent that is installed alongside the tools. The agent service must be running for the tools to work.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\nThe virtual machine has a guest operating system installed.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-guest-tools.html"
    },
    {
        "title": "Introduction",
        "content": "Introduction \nThis guide explains how to enable and manage integration between Virtuozzo Hybrid Infrastructure and the CloudBlue billing system.\nBasically, you will need to do the following:\n\nCreate and configure a project in the CloudBlue Connect vendor portal.\n\nCreate a virtual machine in a cloud. Install, configure, and start the connector service inside the virtual machine. This service integrates with the Connect API to retrieve order requests and provision ordered subscriptions for Virtuozzo Hybrid Infrastructure.\nTo be able to connect to Virtuozzo Hybrid Infrastructure, the Compute API traffic type must be added to a  network accessible from the created virtual machine.\n\nTest creating and managing assets, that are customer projects, in the CloudBlue Connect vendor portal.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/introduction.html"
    },
    {
        "title": "9.2. Licensing Leostream Connection Broker\u00c2\u00b6",
        "content": "9.2. Licensing Leostream Connection Broker | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n9.2. Licensing Leostream Connection Broker\u00c2\u00b6\nYour Connection Broker license is derived from the serial number you received from Leostream Sales. If you do not have a Leostream 9 serial number, please contact sales@leostream.com. To obtain your license key:\n\nPoint a web browser at the IP address of the machine running the Connection Broker. The Connection Broker Sign In page opens.\nLog into your Connection Broker using the following default administrator credentials:\n\nusername=admin\npassword=leo\n\n\nOn the Leostream License page, select Enter manually from the How do you want to enter your license key drop-down menu.\nBelow the drop-down, click the link to go to https://license.leostream.com. The installation code for your Connection Broker is automatically populated.\nEnter the serial number you obtained from Leostream sales.\nEnter the email address associated with that serial number.\nClick Generate a license.\nClick the Apply to the broker button above the generated license key. The browser returns to the Leostream License page.\nSelect the I have read and accept the License Agreement check box.\nClick Save.\n\nImportant\nThe generated license key is linked to this Connection Broker installation or cluster. If you rebuild your Connection Broker or create a second Leostream environment, contact sales@leostream.com to obtain a new serial number for that environment.\n\nAfter you license your Connection Broker, you arrive at the Dashboard > Pool Statistics page, shown in the following figure.\n\nThere are six main management pages accessible from the menu along the left side:\n\nSigned in indicates who is logged in and contains tools for logging out and resetting the Administrator Password.\nDashboard provides information about pool statistics, reports, and Leostream component downloads.\nSetup integrates with external systems, such as Authentication Servers, MFA providers, Virtuozzo Hybrid Infrastructure, and Leostream Gateways.\nConfiguration defines VDI workflows, including pools, protocol plans, power control plans, release plans policies, locations, and assignments.\nResources lists all managed resources, including virtual machines imported from or generated on Virtuozzo Hybrid Infrastructure.\nSystem configures system parameters, such as SNMP, Alerts, Backups, add SSL certificates.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/configuring-broker/licensing-broker.html"
    },
    {
        "title": "Monitoring the cluster with Zabbix",
        "content": "Monitoring the cluster with Zabbix\nPrerequisites\n\nThe SNMP access is enabled, as described in Enabling SNMP access.\n\nTo configure cluster monitoring in Zabbix\n\nIn the admin panel, go to Settings > System settings > SNMP, and then click the provided link to download a template for Zabbix 6.4.\n\nYou can also download a template that is compatible with Zabbix 3.x.\n\nIn the Zabbix web interface, go to Data collection > Templates, and then click Import in the top right corner of the screen.\n\nIn the Import window, do the following:\n\nIn Import file, click Choose file and select the downloaded template.\nIn Rules, keep only Create new checked.\nClick Import.\n\nThe details of the new template will be displayed in the Templates window. Click Import.\n\nOnce the template is imported, go to Data collection > Hosts, and then click Create host in the top right corner of the screen.\n\nIn the New host window, do the following:\n\nIn Host name, specify the hostname of the management node.\nIn Visible name, specify the name that will be shown in Zabbix.\nIn Host groups, specify vstorage, and then select vstorage (new), to create a new host group.\nIn Interfaces, click Add, and then select SNMP as the interface type.\nIn IP address, specify the management node IP address.\nClick Add.\n\nTo link the template to the newly added host, click this host on the Data collection > Hosts screen. In Templates, start typing the name of the template Template VStorageSNMP,  and then select it from the drop-down list. Click Update.\n\nThe host now will have all the entities of the template, which includes items, triggers, graphs, low-level discovery rules, web scenarios, as well as dashboards.\n\nOn the Data collection > Hosts screen, the cluster\u00e2\u0080\u0099s SNMP label in the Availability column will turn green in a few minutes.\n\nTo monitor the cluster parameters in Zabbix\nGo to Monitoring > Hosts, and then click Latest data, Problems, or Graphs next to your host.\n\nSee also\n\nAccessing cluster information objects via SNMP\n\nListening to SNMP traps\n\nCluster objects and traps",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-the-cluster-with-zabbix.html"
    },
    {
        "title": "Enabling GPU support for Kubernetes nodes",
        "content": "Enabling GPU support for Kubernetes nodes\nTo enable GPU support for your Kubernetes cluster, you need to deploy the NVIDIA device plugin for Kubernetes.\n\nThis guide allows to deploy the latest version of the driver. If you need a specific version, you can build your own nvidia-driver-installer container image by following the instructions on this GitHub page.\n\nTo deploy the NVIDIA device plugin for Kubernetes\n\nDisable SELinux on Kubernetes worker nodes with GPU by using the selinux_mode=disabled label during the worker group creation.\n\nDeploy Node Feature Discovery (NFD), a Kubernetes add-on for detecting hardware features and system configuration, to automatically discover GPU devices on your Kubernetes nodes and add the required labels:# kubectl apply -f https://raw.githubusercontent.com/virtuozzo/nvidia-driver-installer/main/daemonsets/node-feature-discovery.yaml\n\nDeploy the NVIDIA device plugin for Kubernetes:# kubectl apply -f https://raw.githubusercontent.com/virtuozzo/nvidia-driver-installer/main/daemonsets/nvidia-gpu-driver.yaml\nThis deamon set will automatically distribute pods to all of your worker nodes with the required labels. For more details, refer to the official guide.\n\nYou can check that the plugin is installed correctly by doing as follows:\n\nRun a test pod:# kubectl apply -f https://raw.githubusercontent.com/virtuozzo/nvidia-driver-installer/main/tests/gpupod.yaml\n\nCheck the pod logs:# kubectl logs gpu-pod\r\n[Vector addition of 50000 elements]\r\nCopy input data from the host memory to the CUDA device\r\nCUDA kernel launch with 196 blocks of 256 threads\r\nCopy output data from the CUDA device to the host memory\r\nTest PASSED\r\nDone",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/enabling-gpu-support-for-kubernetes-nodes.html"
    },
    {
        "title": "Accessing iSCSI targets from VMware ESXi",
        "content": "Accessing iSCSI targets from VMware ESXi\nBefore using Virtuozzo Hybrid Infrastructure volumes with VMware ESXi, you need to configure it to properly work with ALUA Active/Passive storage arrays. It is recommended to switch to the VMW_PSP_RR path selection policy (PSP) to avoid any issues. For example, on VMware ESXi 6.5:\n\nTo set the default PSP for all devices, run:# esxcli storage nmp satp rule add --satp VMW_SATP_ALUA --vendor VSTORAGE \\\r\n--model VSTOR-DISK --psp VMW_PSP_RR -c tpgs_on\r\n\n\nTo set the PSP for a specific device, run:# esxcli storage core claimrule load\r\n\n\nNow you can proceed to create datastores from Virtuozzo Hybrid Infrastructure volumes exported via iSCSI. Log in to the VMware ESXi web panel and do the following:\n\nIn the Navigator, go to the Storage > Adapters tab and click Configure iSCSI.\n\nIn the Configure iSCSI window, click Add static target in the Static targets section, fill out target IQNs, IP addresses, and ports. Click Save configuration.\n\nProceed to the Devices tab and click Refresh. The newly added disk will appear in the list of devices.\n\nSelect the disk and click New datastore. In the wizard that appears, enter a name for the datastore and select partitioning options. Click Finish to actually partition the disk.\n\nPartitioning the disk will erase all data from it.\n\nThe ready-to-use disk will appear in the list of datastores. You can now view its contents it with the datastore browser and provision it to VMs.\n\nIf your ESXi host loses connectivity to VMFS3 or VMFS5 datastores, follow the instructions in KB article #2113956.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/accessing-iscsi-targets-from-vmware-esxi.html"
    },
    {
        "title": "Attaching ISO images to virtual machines",
        "content": "Attaching ISO images to virtual machines\nYou can attach ISO images to running or stopped virtual machines, for example, to install additional software inside them or to restore their operating system in the rescue mode. To attach an ISO image, you need to convert it to a volume, and then attach this volume to a VM.\nWhen you finish installing software from an ISO volume, you can detach it without stopping the VM first.\nTo create a volume from an ISO image\n\nAdmin panel\n\nOn the Compute > Virtual machines > Images tab, click the required ISO image.\nOn the image right pane, click Create volume.\nIn the Create volume from image window, specify a name for the volume, and then click Create.\n\nCommand-line interface\nUse the following command:vinfra service compute volume create [--description <description>] [--image <image>]\r\n                                     --storage-policy <storage_policy> --size <size-gb> <volume-name>\r\n\n\n--description <description>\n\nVolume description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--image <image>\n\nSource compute image ID or name\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n--size <size-gb>\n\nVolume size, in gigabytes\n<volume-name>\n\nVolume name\n\nFor example, to create a volume called guest-tools-lin with the size of 1 GB and the default storage policy from the guest-tools-lin-iso image, run:# vinfra service compute volume create guest-tools-lin --image guest-tools-lin-iso \\\r\n--storage-policy default --size 1\nThe new volume will appear in the vinfra service compute volume list output:#  vinfra service compute volume list | grep guest-tools\r\n| 132908e4-3543-419f-a4bf-c219f74e2640 | guest-tools-lin | 1    | available | node003.vstorage<\u00e2\u0080\u00a6> |\r\n\n\nTo attach an ISO volume to a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM.\nOn the Overview tab, click the pencil icon in the Volumes field.\nIn the Volumes window, click Attach.\nIn the Attach volume window, select the created volume, and then click Attach. The attached volume will be marked as ISO.\nIn the Volumes window, click Done to save your changes.\n\nThe attached volume will appear inside the VM operating system.\n\nCommand-line interface\nUse the following command:vinfra service compute server volume attach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to attach the guest-tools-lin volume to the centos7 VM, run:# vinfra service compute server volume attach guest-tools-lin --server centos7\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/sda                             |\r\n| id     | 132908e4-3543-419f-a4bf-c219f74e2640 |\r\n+--------+--------------------------------------+\r\n\nThe attached volume will appear in the vinfra service compute server volume list output:# vinfra service compute server volume list --server centos7\r\n+--------------------------------------+----------+\r\n| id                                   | device   |\r\n+--------------------------------------+----------+\r\n| 1dc6750e-22ee-4fa5-8718-7cbcb7553c59 | /dev/vda |\r\n| 132908e4-3543-419f-a4bf-c219f74e2640 | /dev/sda |\r\n+--------------------------------------+----------+\r\n\n\nTo detach an ISO volume from a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required VM.\nOn the Overview tab, click the pencil icon in the Volumes field.\nIn the Volumes window, click the ellipsis icon next to the ISO volume, and then click Force detach.\nClick Done to save your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute server volume detach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to dettach the guest-tools-lin volume from the centos7 VM, run:# vinfra service compute server volume detach guest-tools-lin --server centos7\r\nOperation successful.\r\n\n\nSee also\n\nConnecting to virtual machines\n\nManaging guest tools\n\nRescuing virtual machines\n\nReconfiguring virtual machines\n\nManaging images\n\nTroubleshooting virtual machines\n\nDeleting virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume create [--description <description>] [--image <image>]\r\n                                     --storage-policy <storage_policy> --size <size-gb> <volume-name>\r\n\n\n--description <description>\n\n\nVolume description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--image <image>\n\nSource compute image ID or name\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n--size <size-gb>\n\nVolume size, in gigabytes\n<volume-name>\n\nVolume name\n\nFor example, to create a volume called guest-tools-lin with the size of 1 GB and the default storage policy from the guest-tools-lin-iso image, run:# vinfra service compute volume create guest-tools-lin --image guest-tools-lin-iso \\\r\n--storage-policy default --size 1\nThe new volume will appear in the vinfra service compute volume list output:#  vinfra service compute volume list | grep guest-tools\r\n| 132908e4-3543-419f-a4bf-c219f74e2640 | guest-tools-lin | 1    | available | node003.vstorage<\u00e2\u0080\u00a6> |\r\n\n",
                "title": "To create a volume from an ISO image"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server volume attach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to attach the guest-tools-lin volume to the centos7 VM, run:# vinfra service compute server volume attach guest-tools-lin --server centos7\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/sda                             |\r\n| id     | 132908e4-3543-419f-a4bf-c219f74e2640 |\r\n+--------+--------------------------------------+\r\n\nThe attached volume will appear in the vinfra service compute server volume list output:# vinfra service compute server volume list --server centos7\r\n+--------------------------------------+----------+\r\n| id                                   | device   |\r\n+--------------------------------------+----------+\r\n| 1dc6750e-22ee-4fa5-8718-7cbcb7553c59 | /dev/vda |\r\n| 132908e4-3543-419f-a4bf-c219f74e2640 | /dev/sda |\r\n+--------------------------------------+----------+\r\n\n",
                "title": "To attach an ISO volume to a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server volume detach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to dettach the guest-tools-lin volume from the centos7 VM, run:# vinfra service compute server volume detach guest-tools-lin --server centos7\r\nOperation successful.\r\n\n",
                "title": "To detach an ISO volume from a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Images tab, click the required ISO image.\nOn the image right pane, click Create volume.\nIn the Create volume from image window, specify a name for the volume, and then click Create.\n\n",
                "title": "To create a volume from an ISO image"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM.\nOn the Overview tab, click the pencil icon in the Volumes field.\nIn the Volumes window, click Attach.\nIn the Attach volume window, select the created volume, and then click Attach. The attached volume will be marked as ISO.\nIn the Volumes window, click Done to save your changes.\n\nThe attached volume will appear inside the VM operating system.\n",
                "title": "To attach an ISO volume to a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required VM.\nOn the Overview tab, click the pencil icon in the Volumes field.\nIn the Volumes window, click the ellipsis icon next to the ISO volume, and then click Force detach.\nClick Done to save your changes.\n\n",
                "title": "To detach an ISO volume from a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/attaching-iso-images-to-vms.html"
    },
    {
        "title": "Configuring node locations",
        "content": "Configuring node locations\nThe location for a node can be selected before it is joined to the storage cluster. By default, the nodes are added to the Default rack in the Default row in the Default room.\nLocations are designed to be used as failure domains. You can create locations, move nodes between them, rename and delete locations.\nLimitations\n\nThe location can be changed for unassigned nodes only. If the node is added to the storage cluster, release it first. After moving the node, you will be able to join it back to the cluster.\nYou can only delete empty locations. If a location contains some nodes, move them first. The default location cannot be deleted as well. However, you can rename it to match your infrastructure.\n\nPrerequisites\n\nA clear understanding of the concept Failure domains.\n\nTo create locations\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the icon  to show the node filters and location (if hidden).\n\nIn the location sidebar, click the top of the tree with the cluster name.\n\nClick the Create room toolbar button and enter the room name.\nTo add a new row, click the created room. Click the Create row button and enter a name for it.\nTo add a new rack, click the created row. Click the Create rack button and enter a name for it. You can now move nodes to this rack.\n\nCommand-line interface\nUse the following command:vinfra location create --fd <fd> --name <location-name> [--parent-id <parent-id>]\r\n\n\n--fd <fd>\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n--name <location-name>\n\nName of the location to be created\n--parent-id <parent-id>\n\nID of the parent location where the child location should be created in\n\nFor example, to create the location row2, run:# vinfra location create --fd 3 --name row2 --parent-id 0\r\n+----------+-------+\r\n| Field    | Value |\r\n+----------+-------+\r\n| children | []    |\r\n| id       | 1     |\r\n| name     | row2  |\r\n| parent   | 0     |\r\n+----------+-------+\r\n\n\nTo create a location of level 4 (room), do not use the --parent-id argument.\n\nThe created location will appear in the vinfra location list output:# vinfra location list --fd 3\r\n+----+-------------+--------+----------+\r\n| id | name        | parent | children |\r\n+----+-------------+--------+----------+\r\n| 0  | Default row | 0      | - 0      |\r\n| 1  | row2        | 0      | []       |\r\n+----+-------------+--------+----------+\r\n\n\nTo rename locations\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the icon  to show the node filters and location (if hidden).\nIn the location sidebar, click the parent location for the item you want to rename. For example, click the row if you want to rename a rack in it.\nIn the list, click the required location. On the right pane, click Rename and enter a new name.\n\nThe location will be renamed.\n\nYou can rename the room, row, and rack locations by using the command-line interface. For example, you can rename rack to chassis to match your actual server location.\n\nCommand-line interface\nUse the following command:vinfra location rename --fd <fd> --id <location-id> --name <location-name>\r\n\n\n--fd <fd>\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n--id <location-id>\n\nID of the location to rename\n--name <location-name>\n\nA new location name\n\nFor example, to rename the location with the ID 1 to row_renamed, run:# vinfra location rename --fd 3 --id 1 --name row_renamed\nYou can also change names for failure domain levels 2, 3 and 4 by using the following command:vinfra failure domain rename {2,3,4} <singular-name> <plural-name>\r\n\n\n{2,3,4}\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n<singular-name>\n\nSingular name of the specified failure domain\n<plural-name>\n\nPlural name of the specified failure domain\n\nFor example, to rename the failure domain 2 to chassis, run:# vinfra failure domain rename 2 chassis chassis\n\nIf you use a name other than zone, enclosure, chassis, blade server, it will be replaced with location in the admin panel.\n\nTo move nodes to a new location\n\nOn the Infrastructure > Nodes screen, there are two ways to move a node to a new location. Either from the node location tree, you can select the rack to move the node to, and click Move nodes. Or you can click the line with a node to move, and click Move node on the right pane.\nIn the Move nodes window, select the required node/location and click Move.\nYou can now join this node to the cluster. To do this, click the line with the node, and on the right pane click Join to cluster. Click Join in the open window.\n\nThe node will be moved to the specified location.\nTo delete locations\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the icon  to show the node filters and location (if hidden).\nIn the location sidebar, click the parent location for the item you want to delete. For example, click the row if you want to delete a rack from it.\nIn the list, click the required location. On the right pane, click Delete.\n\nThe location will be deleted.\n\nCommand-line interface\nUse the following command:vinfra location delete --fd <fd> --id <location-id>\r\n\n\n--fd <fd>\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n--id <location-id>\n\nID of the location to delete\n\nFor example, to delete the location with the ID 1, run:# vinfra location delete --fd 3 --id 1\n\nWhat's next\n\nDeploying the storage cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra location create --fd <fd> --name <location-name> [--parent-id <parent-id>]\r\n\n\n--fd <fd>\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n--name <location-name>\n\nName of the location to be created\n--parent-id <parent-id>\n\nID of the parent location where the child location should be created in\n\nFor example, to create the location row2, run:# vinfra location create --fd 3 --name row2 --parent-id 0\r\n+----------+-------+\r\n| Field    | Value |\r\n+----------+-------+\r\n| children | []    |\r\n| id       | 1     |\r\n| name     | row2  |\r\n| parent   | 0     |\r\n+----------+-------+\r\n\n\nTo create a location of level 4 (room), do not use the --parent-id argument.\n\nThe created location will appear in the vinfra location list output:# vinfra location list --fd 3\r\n+----+-------------+--------+----------+\r\n| id | name        | parent | children |\r\n+----+-------------+--------+----------+\r\n| 0  | Default row | 0      | - 0      |\r\n| 1  | row2        | 0      | []       |\r\n+----+-------------+--------+----------+\r\n\n",
                "title": "To create locations"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra location rename --fd <fd> --id <location-id> --name <location-name>\r\n\n\n--fd <fd>\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n--id <location-id>\n\nID of the location to rename\n--name <location-name>\n\nA new location name\n\nFor example, to rename the location with the ID 1 to row_renamed, run:# vinfra location rename --fd 3 --id 1 --name row_renamed\nYou can also change names for failure domain levels 2, 3 and 4 by using the following command:vinfra failure domain rename {2,3,4} <singular-name> <plural-name>\r\n\n\n{2,3,4}\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n<singular-name>\n\nSingular name of the specified failure domain\n<plural-name>\n\nPlural name of the specified failure domain\n\nFor example, to rename the failure domain 2 to chassis, run:# vinfra failure domain rename 2 chassis chassis\n\nIf you use a name other than zone, enclosure, chassis, blade server, it will be replaced with location in the admin panel.\n\n",
                "title": "To rename locations"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra location delete --fd <fd> --id <location-id>\r\n\n\n--fd <fd>\n\nFailure domain ID: 0=disk, 1=host, 2=rack, 3=row, 4=room. You can view the list of failure domains by using vinfra failure domain list.\n--id <location-id>\n\nID of the location to delete\n\nFor example, to delete the location with the ID 1, run:# vinfra location delete --fd 3 --id 1\n",
                "title": "To delete locations"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the icon  to show the node filters and location (if hidden).\n\nIn the location sidebar, click the top of the tree with the cluster name.\n\n\n\nClick the Create room toolbar button and enter the room name.\nTo add a new row, click the created room. Click the Create row button and enter a name for it.\nTo add a new rack, click the created row. Click the Create rack button and enter a name for it. You can now move nodes to this rack.\n\n",
                "title": "To create locations"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the icon  to show the node filters and location (if hidden).\nIn the location sidebar, click the parent location for the item you want to rename. For example, click the row if you want to rename a rack in it.\nIn the list, click the required location. On the right pane, click Rename and enter a new name.\n\nThe location will be renamed.\n\nYou can rename the room, row, and rack locations by using the command-line interface. For example, you can rename rack to chassis to match your actual server location.\n\n",
                "title": "To rename locations"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the icon  to show the node filters and location (if hidden).\nIn the location sidebar, click the parent location for the item you want to delete. For example, click the row if you want to delete a rack from it.\nIn the list, click the required location. On the right pane, click Delete.\n\nThe location will be deleted.\n",
                "title": "To delete locations"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-node-locations.html"
    },
    {
        "title": "4. Providing Access to Hystax Acura Portal\u00c2\u00b6",
        "content": "4. Providing Access to Hystax Acura Portal | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n4. Providing Access to Hystax Acura Portal\u00c2\u00b6\nIn order to allow users to manage their migration workloads, we can create a user with project scope from the Hystax Acura web interface.\n\nLogin to the Hystax Acura Solution web interface and click on the Settings tab on the left-hand side. Then click on Roles and click Add.\n\nAssign the necessary permissions to the role. We will provide full access to the TriangleCakes target cloud.\n\nNow we will add a new user. Click Users and then click Add. Fill in all the information and select the Customer:Customer name as Organization.\n\nClick on the newly create user in order to assign a role to the user.\n\nClick Add in the Role section and add the role.\n\nThe user, at this point, will be able to login to the Hystax Acura web interface and perform and the Migration as a Service (self-service migration).\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/portal-access.html"
    },
    {
        "title": "Benchmarking requirements",
        "content": "Benchmarking requirements\nTest cluster requirements\nIn order to obtain the most realistic results, the test cluster must be the same as the\r\nproduction cluster. If this is impossible, the test environment can be a replica of the production cluster or very similar to it.\nWhen trying to determine the ideal setup size, you might want to plan ahead for the\r\npossibility to change the hardware configuration of your test cluster. With virtual machines, you can easily change the amount of RAM, the number of CPUs, disks, etc. However, unlike a physical environment, a virtual one might behave unpredictably.\nThe cluster should be made of identical nodes, to avoid performance disbalance, as the cluster performance is often limited by the performance of the slowest component.\nLoad generator requirements\nDepending on the benchmarking goal, the number of load generators can differ:\n\nUse a single load generator to benchmark the maximum performance achievable by a single process.\nUse as many load generators as possible to benchmark the maximum cumulative cluster throughput.\n\nIn either case, you can run load generators as virtual machines in the Virtuozzo Hybrid Infrastructure cluster or as external machines (physical or virtual). When using external virtual machines for load generators, keep in mind that virtual machines usually share the same network infrastructure. For more accurate results, you need to make sure there is enough physical bandwidth between load generators and the test cluster, and that there are plenty of other physical resources, such as CPUs.\nWhen targeting for the maximum cluster performance, or especially for the cumulative performance of multiple resources, we recommend planning a variable number of load generator clients. This number can reach or exceed the number of nodes in the Virtuozzo Hybrid Infrastructure cluster. If adding more load generators increases the performance results, this means that the load generators' resources or number are not sufficient. Similarly to cluster nodes, load generators must have the same hardware configuration.\nCoordinator node requirements\nThe coordinator node is a special node that is used to coordinate load generators, that is, to start and stop the benchmark on all other nodes. The coordinator node can be either a load generator or a cluster node.\nNetwork requirements\nWe recommend providing at least 50 GiB of network bandwidth, either as a single 50 GbE link or as a bonded 2x25 GbE network connection, between load generators and the test cluster. Keep in mind that the network can be a bottleneck when measuring performance.\nAll nodes must be able to reach each other over a network:\n\nCluster nodes must be reachable on network ports for standard iSCSI, NFS, and S3 services.\nLoad generators must be reachable on TCP port 8765 for fio testing.\nThe coordinator node must be reachable on TCP\u00a0port 2000 for S3 testing.\n\nYou can open the ports in the admin panel or via iptables:# iptables -I INPUT -p tcp -m tcp -m multiport --dports 8765 -j ACCEPT\r\n# iptables -I INPUT -p tcp -m tcp -m multiport --dports 2000 -j ACCEPT\nWhat's next\n\nDeploying virtual machines with load generators",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/benchmarking-requirements.html"
    },
    {
        "title": "Infrastructure alerts",
        "content": "Infrastructure alerts\nThe infrastructure alerts that are generated and displayed in the admin panel can be related to the management node and admin panel, license and updates, cluster connectivity, as well as to a specific node, its disks, and network interfaces.\nManagement node and admin panel alerts\n\n High availability for the admin panel\r\nmust be configured\n\nConfigure high availability for the admin panel in Settings > System settings > High availability configuration. Otherwise the admin panel will be a single point of failure.\n\n Management node backup does not exist\n\nManagement node backup is older than <number> days.\n\n Management node backup does not exist\n\nThe last management node backup has failed, does not exist, or is too old.\n\n Changes to the management database are not replicated\n\nChanges to the management database are not replicated to the node \"<hostname>\" because it is offline. Check the node's state and connectivity.\n\n Changes to the management database are not replicated\n\nChanges to the management database are not replicated to the node \"<hostname>\". Please contact the technical support.\n\n Management node HA has four nodes\n\nThe management node HA configuration has four nodes. It is recommended to have three or five nodes included.\n\n Management panel SSL certificate will expire in less than 30 days\n\nThe SSL certificate for the admin and self-service panels will expire in <number> days. Renew the certificate, as described in the product documentation, or contact the technical support.\n\nRenew the SSL certificate, as described in Accessing the admin panel via SSL.\n\n Management panel SSL certificate will expire in less than 7 days\n\nThe SSL certificate for the admin and self-service panels will expire in <number> days. Renew the certificate, as described in the product documentation, or contact the technical support.\n\nRenew the SSL certificate, as described in Accessing the admin panel via SSL.\n\n Management panel SSL certificate has expired\n\nThe SSL certificate for the admin and self-service panels has expired. Renew the certificate, as described in the product documentation, or contact the technical support.\n\nRenew the SSL certificate, as described in Accessing the admin panel via SSL.\n\nLicense alerts\n\n License is not loaded\n\nLicense is not loaded.\n\nContact the sales representative to obtain a license key.\nRegister the license key, as described in Managing licenses.\n\n License is not updated\n\nThe license cannot be updated automatically and will expire in less than 21 days. Check the cluster connectivity to the license server or contact the technical support.\n\nCalculate the licensed storage capacity that you need. To do it, you can use the previous licensed storage size or check the consumed storage capacity on the Monitoring > Dashboard > Logical space chart.\nContact the sales representative to prolong your license, with the storage capacity you have defined on step 1.\nUpgrade your license key, as described in Managing licenses.\n\n License will expire soon\n\nThe license has not been updated automatically and will expire in less than 7 days. Check the cluster connectivity to the license server and contact the technical support immediately.\n\nCalculate the licensed storage capacity that you need. To do it, you can use the previous licensed storage size or check the consumed storage capacity on the Monitoring > Dashboard > Logical space chart.\nContact the sales representative to prolong your license, with the storage capacity you have defined on step 1.\nUpgrade your license key, as described in Managing licenses.\n\n License expired\n\nThe license of cluster \"<cluster_name>\" has expired. \u00d0\u00a1ontact your reseller to update your license immediately!\n\nCalculate the licensed storage capacity that you need. To do it, you can use the previous licensed storage size or check the consumed storage capacity on the Monitoring > Dashboard > Logical space chart.\nContact the sales representative to prolong your license, with the storage capacity you have defined on step 1.\nUpgrade your license key, as described in Managing licenses.\n\n Licensed storage capacity is low\n\nCluster has reached 80% of licensed storage capacity.\n\nCheck the licensed and consumed storage capacity on the Monitoring > Dashboard > Logical space chart.\nContact the sales representative to add more storage capacity.\nRegister a new license key, as described in Managing licenses.\n\n Licensed storage capacity is critically low\n\nCluster has reached 90% of licensed storage capacity.\n\nCheck the licensed and consumed storage capacity on the Monitoring > Dashboard > Logical space chart.\nContact the sales representative to add more storage capacity.\nRegister a new license key, as described in Managing licenses.\n\n Cluster is out of licensed space\n\n\u00d0\u00a1luster \"<cluster_name>\" has run out of storage space allowed by license. No more data can be written. Please contact your reseller to update your license immediately!\n\nCheck the licensed and consumed storage capacity on the Monitoring > Dashboard > Logical space chart.\nContact the sales representative to add more storage capacity.\nRegister a new license key, as described in Managing licenses.\n\nUpdate alerts\n\n Software updates exist\n\nSoftware updates exist for the node <hostname>. Current version: <current_version>. Available version: <available_version>.\n\nUpdate Virtuozzo Hybrid Infrastructure to a new version, as described in Installing updates.\n\n Software updates exist for the Management panel and compute API\n\nSoftware updates exist for the Management panel and compute API. Current version: <current_version>. Available version: <available_version>.\n\nUpdate Virtuozzo Hybrid Infrastructure to a new version, as described in Installing updates.\n\n Update check failed\n\nUpdate check failed on the node <hostname>.\n\nThe connection to the update repository could not be established.\nCheck access to the update repositories:\n\nOpen the terminal on the node where the update check has failed.\n\nEnsure that the hci-base and hci-updates repositories are enabled and the mirrorlist URL matches the current release. To do this, run:# cat /etc/hci-release\r\n# grep -P \"^(mirrorlist|enabled)\" /etc/yum.repos.d/hci.repo\n\nDisable third-party repositories. Only two repositories must be enabled: hci-base and hci-updates. To check the enabled repositories, run:# yum -q repolist enabled\n\nCheck access to the repositories:# yum clean all; yum repoinfo hci-base; yum repoinfo hci-updates\n\nGet the mirrorlist content by running:# curl -L <mirrorlist_URL>\n\nInvestigate the log file /var/log/vstorage-ui-agent/updater.log.\n\n Multiple update checks failed\n\nUpdate checks failed multiple times on the node <hostname>.\n\nThe connection to the update repository could not be established for at least 3 days.\nCheck access to the update repositories:\n\nOpen the terminal on the node where the update check has failed.\n\nEnsure that the hci-base and hci-updates repositories are enabled and the mirrorlist URL matches the current release. To do this, run:# cat /etc/hci-release\r\n# grep -P \"^(mirrorlist|enabled)\" /etc/yum.repos.d/hci.repo\n\nDisable third-party repositories. Only two repositories must be enabled: hci-base and hci-updates. To check the enabled repositories, run:# yum -q repolist enabled\n\nCheck access to the repositories:# yum clean all; yum repoinfo hci-base; yum repoinfo hci-updates\n\nGet the mirrorlist content by running:# curl -L <mirrorlist_URL>\n\nInvestigate the log file /var/log/vstorage-ui-agent/updater.log.\n\n Update download failed\n\nUpdate download failed on the node <hostname>.\n\nThe reason can be one of the following:\n\nThe update check has failed.\nThere is not enough free space on the root file system.\n(Rare) A new version became available during the download, and the version that is currently being downloaded is not available anymore.\n\nTo solve the issue:\n\nCheck access to the update repositories:\n\nOpen the terminal on the node where the update check has failed.\n\nEnsure that the hci-base and hci-updates repositories are enabled and the mirrorlist URL matches the current release. To do this, run:# cat /etc/hci-release\r\n# grep -P \"^(mirrorlist|enabled)\" /etc/yum.repos.d/hci.repo\n\nDisable third-party repositories. Only two repositories must be enabled: hci-base and hci-updates. To check the enabled repositories, run:# yum -q repolist enabled\n\nCheck access to the repositories:# yum clean all; yum repoinfo hci-base; yum repoinfo hci-updates\n\nGet the mirrorlist content by running:# curl -L <mirrorlist_URL>\n\nInvestigate the log file /var/log/vstorage-ui-agent/updater.log.\n\nEnsure that the root file system has more than 1 GB of free space left.\n   Retry the update download.\n\n Node update failed\n\nSoftware update failed on the node <hostname>.\n\nThe reason can be one of the following:\n\nThe node rebooted unexpectedly.\nThere are third-party packages, which conflict with the official packages.\n\nTry updating the node again. If the issue persists, contact the technical support team.\n\n Update failed\n\nUpdate failed for the management panel and compute API.\n\nThe reason can be one of the following:\n\nThe management node rebooted unexpectedly.\nFailed to update the compute service.\n\nTry updating the component again. If the issue persists, contact the technical support team.\n\n Cluster update failed\n\nUpdate failed for the cluster.\n\nTry updating the cluster again. If the issue persists, contact the technical support team.\n\n Entering maintenance for update failed\n\nEntering maintenance failed while updating the node <hostname>.\n\nContact the technical support team.\n\nCluster connectivity alerts\n\n Network connectivity failed\n\nNo network traffic has been detected via network \"<network_name>\" from all nodes.\n\n Node network connectivity problem\n\nNode \"<hostname>\" has no network connectivity to node \"<hostname>\" via network \"<network_name>\".\n\n Node network packet loss\n\nNode \"<hostname>\" has a problem with network connectivity to node \"<hostname>\" via network \"<network_name>\" due to the loss of some packets.\n\n Node network persistent packet loss\n\nNode \"<hostname>\" has a problem with network connectivity to node \"<hostname>\" via network \"<network_name>\" due to the persistent loss of some packets over the last two hours.\n\n Node network unstable connectivity\n\nNode \"<hostname>\" has a problem with network connectivity to node \"<hostname>\" via network \"<network_name>\" due to the loss of all MTU-sized packets.\n\n Node network MTU packet loss\n\nNode \"<hostname>\" has a problem with network connectivity to node \"<hostname>\" via network \"<network_name>\" due to the loss of some MTU-sized packets.\n\n Node network persistent MTU packet loss\n\nNode \"<hostname>\" has a problem with network connectivity to node \"<hostname>\" via network \"<network_name>\" due to the persistent loss of some MTU-sized packets over the last two hours.\n\n MTU mismatch\n\nNetwork <network_name> has assigned interfaces with different MTU.\n\nNode alerts\n\n Node is offline\n\nNode \"<hostname>\" is offline.\n\n Node got offline too many times\n\nNode \"<hostname>\" got offline too many times for the last hour.\n\n Kernel is outdated\n\nNode \"<hostname>\" is not running the latest kernel.\n\n OOM killer triggered\n\nOOM killer has been triggered on node \"<hostname>\".\n\n Time is not synced\n\nTime on node \"<hostname>\" differs from time on backend node by more than <value_5<30> seconds.\n\n Node time critically unsynced\n\nTime on node <hostname> is critically unsynced, differing from the time on backend node by more than <value_>30> seconds.\n\n No Internet access\n\nCluster node <hostname> cannot reach the repository. Make sure that all cluster nodes have Internet access.\n\n Incompatible hardware detected\n\nIncompatible hardware detected on node \"<hostname>\": <hardware_list>. Using Mellanox and AMD may lead to data loss. Please double check that SR-IOV is properly enabled. Visit https://support.virtuozzo.com/hc/en-us/articles/19764365143953 to learn how to troubleshoot this issue.\n\n Node has high CPU usage\n\nNode <hostname> has CPU usage higher than 90%. The current value is <value>%.\n\n Node has high memory usage\n\nNode <hostname> has memory usage higher than 95%. The current value is <value>%.\n\n Node has high disk I/O usage\n\nDisk /dev/<disk_name> on node <hostname> has I/O usage higher than 85%. The current value is <value>%.\n\n Node has high swap usage\n\nNode <hostname> has swap usage higher than 40%. The current value is <value>%.\n\n Node has critically high swap usage\n\nNode <hostname> has critically high swap usage, exceeding 80%. The current value is <value>%.\n\n Node has high receive packet loss rate\n\nNode <hostname> has <value> receive packet loss rate reported by job <job_name>.\n\n Node has high transmit packet loss rate\n\nNode <hostname> has <value> transmit packet loss rate reported by job <job_name>.\n\n Node has high receive packet error rate\n\nNode <hostname> has <value> receive packet error rate reported by job <job_name>.\n\n Node has high transmit packet error rate\n\nNode <hostname> has <value> transmit packet error rate reported by job <job_name>.\n\n Reached \"node crash per hour\" threshold\n\nNode <hostname> with shaman node ID <id> has reached the \"node crash per hour\" threshold.\n\n OOM-kill event detected\n\nOOM-kill event detected on node <hostname> at least once for the last 24 hours. You need to check memory consumption.\n\n Node failed to return to operation\n\nNode <hostname> has failed to automatically return to operation within 30 minutes after a crash. Check the node's hardware, and then try returning it to operation manually.\n\n Node crash detected\n\nNode <hostname> crashed, which started the VM evacuation.\n\nDisk alerts\n\n Disk SMART warning\n\nDisk \"<disk_name>\" (<serial>) on node \"<hostname>\" has failed a S.M.A.R.T. check.\n\n Disk error\n\nDisk \"<disk_name>\" (<serial>) has failed on node \"<hostname>\".\n\n Disk is running out of space\n\nRoot partition on node \"<hostname>\" is running out of space (less than 10% or 5 GB of free space).\n\n Disk is out of space\n\nRoot partition on node \"<hostname>\" is running out of space (for non-compute nodes: less than 5% of free space).\n\n Compute node disk is out of space\n\nRoot partition on node \"<hostname>\" is running out of space (for compute nodes: less than 1 GB of free space).\n\n Software RAID is not fully synced\n\nSoftware RAID <disk_name> on node <hostname> is <value>% synced.\n\n Systemd service is flapping\n\nSystemd service <service_name> on node <hostname> has changed its state more than 5 times in 5 minutes or 15 times in one hour.\n\n SMART Media Wearout warning\n\nDisk <disk_name> on node <hostname> is almost worn out and may fail soon. Consider replacement.\n\nThe alert is based on the smart_media_wearout_indicator metric. For details on the Media Wearout Indicator S.M.A.R.T. attribute, refer to Disk health analyzers.\n\n SMART Media Wearout critical\n\nDisk <disk_name> on node <hostname> is worn out and will fail soon. Consider replacement.\n\nThe alert is based on the smart_media_wearout_indicator metric. For details on the Media Wearout Indicator S.M.A.R.T. attribute, refer to Disk health analyzers.\n\nNetwork interface alerts\n\n Network interface half duplex\n\nNetwork interface \"<iface_name>\" on node \"<hostname>\" is not in the full duplex mode.\n\n Low network interface speed\n\nNetwork interface \"<iface_name>\" on node \"<hostname>\" has speed lower than the minimally required 1 Gbps.\n\n Network interface is flapping\n\nNetwork interface <iface_name> on node <hostname> is flapping.\n\n Network bond is not redundant\n\nNetwork bond <iface_name> on node <hostname> is missing <number> subordinate interface(s).\n\nData-in-transit encryption alerts\n\n Enabling IPv6 mode takes too much time\n\nOperation to enable the IPv6 mode is running for more than 1 hour. Please contact the technical support.\n\n\u00d0\u00a1ancel the operation to enable the IPv6 mode by using the vinfra cluster network encryption cancel command.\nRetry the operation.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n Enabling traffic encryption takes too much time\n\nOperation to enable traffic encryption is running for more than 1 hour. Please contact the technical support.\n\nCancel the operation to enable traffic encryption by using the vinfra cluster network encryption cancel command.\nRetry the operation.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n System configuration is not optimal for traffic encryption\n\nTraffic encryption is enabled but the storage network is not in the IPv6 mode. Switch on the IPv6 configuration, as described in the product documentation.\n\nDisable traffic encryption for the storage network, and then enable it again, as described in Enabling and disabling data-in-transit encryption.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n Node IPsec certificate will expire in less than 7 days\n\nIPsec certificate for node <hostname> with ID <id> will expire in less than 7 days. Renew the certificate, as described in the product documentation, or contact the technical support.\n\nFollow the instructions in Renewing encryption certificates to renew the certificate.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n Node IPsec certificate has expired\n\nIPsec certificate for node <hostname> with ID <id> has expired. Renew the certificate, as described in the product documentation, or contact the technical support.\n\nFollow the instructions in Renewing encryption certificates to renew the certificate.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\nIdentity provider alerts\n\n Identity provider validation error\n\nUnable to connect to identity provider \"<idp_name>\" in domain \"<name>\".\n\n Identity provider validation error\n\nInvalid identity provider configuration \"<idp_name>\" in domain \"<name>\".\n\nWhat's next\n\nGetting technical support\n\nSee also\n\nCore storage alerts\n\nBackup storage alerts\n\nObject storage alerts\n\nBlock storage alerts\n\nCompute alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/infrastructure-alerts.html"
    },
    {
        "title": "Revoking S3 account access keys via REST API",
        "content": "Revoking S3 account access keys via REST API\nYou can revoke the specified access key pair for the specified account of an S3 user by sending a POST request to the ostor-users service along with the user email address, account name, and access key in the key pair:# s3_curl POST \"http://s3.example.com/?ostor-users&emailAddress=user@example.com&accountName=account&revokeKey=ca55631f9f3d59dcZMDX\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/revoking-s3-account-access-keys-via-rest-api.html"
    },
    {
        "title": "5.5. Software Compatibility Matrix\u00c2\u00b6",
        "content": "5.5. Software Compatibility Matrix | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n5.5. Software Compatibility Matrix\u00c2\u00b6\nBitNinja Software interoperability and compatibility matrix https://doc.bitninja.io/docs/Installation/compatibility.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/bitninja-agent-requirements/software-compatibility.html"
    },
    {
        "title": "Performing a failover",
        "content": "Performing a failover\nIf the primary cluster becomes unavailable, you can perform a manual failover by promoting the secondary cluster to primary. This operation will switch the configuration of the secondary cluster, including its DNS name, to the configuration of the primary one. Failover of the primary cluster can be performed in the following cases:\n\nThe current primary cluster is completely non-operational and isolated from the Internet and any backup agents.\nBackup agents are unable to communicate with the current primary cluster.\nThe DNS name of the primary cluster has been reconfigured to its IP addresses.\n\nPromoting the secondary cluster to primary is an irreversible operation that will invalidate all data on the primary cluster. Use it only in case of emergency.\n\nPrerequisites\n\nGeo-replication is enabled, as described in Enabling geo-replication.\nThe secondary cluster can reach itself via its own domain name on TCP port 44445.\n\nTo perform a failover\n\nAdmin panel\n\nOn the secondary cluster, go to Storage services > Backup storage > Geo-replication, and then click Promote to primary.\n\nClick Failover in the confirmation window.\nReconfigure the DNS records with the IP addresses of the former secondary cluster for each registration.\n\nIf the current primary cluster is still operational, forcibly delete all of its registrations, and then perform a failover.\n\nCommand-line interface\nRun the following command:# vinfra service backup geo-replication secondary promote-to-primary\n\nSee also\n\nMonitoring Acronis Backup Storage\n\nImporting registrations to the secondary cluster\n\nDisabling geo-replication",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nRun the following command:# vinfra service backup geo-replication secondary promote-to-primary\n",
                "title": "To perform a failover"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOn the secondary cluster, go to Storage services > Backup storage > Geo-replication, and then click Promote to primary.\n\n\n\n\n\nClick Failover in the confirmation window.\nReconfigure the DNS records with the IP addresses of the former secondary cluster for each registration.\n\nIf the current primary cluster is still operational, forcibly delete all of its registrations, and then perform a failover.\n",
                "title": "To perform a failover"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/performing-a-failover.html"
    },
    {
        "title": "Integration via command-line interface",
        "content": "Integration via command-line interface\nThis chapter explains ways to use the command-line interface (CLI) to provision, enable, disable, and terminate S3 users and accounts, as well as set user and bucket limits for billing purposes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/integration-via-command-line-interface.html"
    },
    {
        "title": "Monitoring compute nodes",
        "content": "Monitoring compute nodes\nYou can monitor the compute node status on the Compute > Nodes screen. Nodes in the compute cluster can have the following statuses:\n\nHealthy\nThe node operates normally.\nConfiguring\n\nThe node configuration (the default CPU model for VMs or the compute role) is changing.\nFenced\n\nThe node has become available after a failure, it is now fenced from scheduling new VMs on it.\nCritical\n\nThe node has encountered a critical problem and is not operational.\n\nTo check compute services on a node\n\nAdmin panel\nOn the Infrastructure > Nodes screen, click the line with a compute node. On the right pane, the Compute services tab provides information about deployed compute controller and worker services on the node. Healthy compute services are highlighted on the tab in green, failed services in red, and disabled services for a fenced node in yellow.\n\nCommand-line interface\nUse the following command:vinfra service compute node show <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to view the details of the compute node node001, run:# vinfra service compute node show node001\r\n+----------------+------------------------------------------+\r\n| Field          | Value                                    |\r\n+----------------+------------------------------------------+\r\n| fenced_reason  |                                          |\r\n| host           | node001.vstoragedomain                   |\r\n| host_ip        | 192.168.128.113                          |\r\n| hypervisor     | hypervisor_type: QEMU                    |\r\n|                | id: f36f9331-11a8-43c9-a90b-dbda9bdf9a00 |\r\n|                | is_evacuating: false                     |\r\n|                | state: up                                |\r\n|                | status: enabled                          |\r\n|                | vms: 0                                   |\r\n| id             | 52565ca3-5893-8f6b-62ce-2f07b175b549     |\r\n| in_maintenance | False                                    |\r\n| orig_hostname  | node001                                  |\r\n| placements     | []                                       |\r\n| roles          | - controller                             |\r\n|                | - compute                                |\r\n| services       | - name: cinder-scheduler                 |\r\n|                |   state: healthy                         |\r\n|                | - name: cinder-volume                    |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-dhcp-agent               |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-l3-agent                 |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-metadata-agent           |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-openvswitch-agent        |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-compute                     |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-conductor                   |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-scheduler                   |\r\n|                |   state: healthy                         |\r\n| state          | healthy                                  |\r\n+----------------+------------------------------------------+\n\nTo view compute node details\n\nAdmin panel\nOn the Compute > Nodes screen, click a compute node. You can view the following compute node information:\n\nVirtual CPU and RAM reservations:\n\nReserved for the system and storage services (refer to Server requirements)\nProvisioned to virtual machines located on the node\nFree virtual CPUs and RAM left on the node\nNode overcommitment ratio (refer to Enabling and disabling RAM overcommitment and Changing virtual CPU overcommitment)\n\nThe number of virtual CPUs is a product of the number of physical CPUs on a node and the node overcommitment ratio. The amount of RAM is a product of the amount of physical RAM on a node and the node overcommitment ratio.\n\nHosted virtual machines and their resource consumption\n\nCommand-line interface\nUse the following command:vinfra service compute node show <node> --with-stats\n\n<node>\n\nNode ID or hostname\n--with-stats\n\nGet node information with statistics\n\nFor example, to view the details of the compute node node001, run:# vinfra service compute node show node001 --with-stats\r\n+----------------+------------------------------------------+\r\n| Field          | Value                                    |\r\n+----------------+------------------------------------------+\r\n| fenced_reason  |                                          |\r\n| host           | node001.vstoragedomain                   |\r\n| host_ip        | 192.168.128.113                          |\r\n| hypervisor     | hypervisor_type: QEMU                    |\r\n|                | id: f36f9331-11a8-43c9-a90b-dbda9bdf9a00 |\r\n|                | is_evacuating: false                     |\r\n|                | state: up                                |\r\n|                | status: enabled                          |\r\n|                | vms: 0                                   |\r\n| id             | 52565ca3-5893-8f6b-62ce-2f07b175b549     |\r\n| in_maintenance | False                                    |\r\n| orig_hostname  | node001                                  |\r\n| placements     | []                                       |\r\n| roles          | - controller                             |\r\n|                | - compute                                |\r\n| services       | - name: cinder-scheduler                 |\r\n|                |   state: healthy                         |\r\n|                | - name: cinder-volume                    |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-dhcp-agent               |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-l3-agent                 |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-metadata-agent           |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-openvswitch-agent        |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-compute                     |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-conductor                   |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-scheduler                   |\r\n|                |   state: healthy                         |\r\n| state          | healthy                                  |\r\n| statistics     | compute:                                 |\r\n|                |   block_capacity: 0                      |\r\n|                |   block_usage: 0                         |\r\n|                |   cpu_usage: 0.0                         |\r\n|                |   vcpus: 0                               |\r\n|                |   vcpus_free: 8                          |\r\n|                |   vm_mem_capacity: 3731456000.0          |\r\n|                |   vm_mem_free: 3731456000.0              |\r\n|                |   vm_mem_reserved: 0                     |\r\n|                |   vm_mem_usage: 0                        |\r\n|                | datetime: '2023-01-10T13:04:18.280858'   |\r\n|                | physical:                                |\r\n|                |   cpu_cores: 4                           |\r\n|                |   cpu_usage: 14.212499999994177          |\r\n|                |   mem_free: 534638592                    |\r\n|                |   mem_total: 25110126592                 |\r\n|                |   swap_free: 0                           |\r\n|                |   swap_total: 0                          |\r\n|                |   vcpus_total: 32                        |\r\n|                | reserved:                                |\r\n|                |   cpus: 3                                |\r\n|                |   memory: 21378670592                    |\r\n|                |   vcpus: 24                              |\r\n+----------------+------------------------------------------+\n\nSee also\n\nMonitoring virtual machines\n\nMonitoring load balancers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute node show <node>\r\n\n\n<node>\n\nNode ID or hostname\n\nFor example, to view the details of the compute node node001, run:# vinfra service compute node show node001\r\n+----------------+------------------------------------------+\r\n| Field          | Value                                    |\r\n+----------------+------------------------------------------+\r\n| fenced_reason  |                                          |\r\n| host           | node001.vstoragedomain                   |\r\n| host_ip        | 192.168.128.113                          |\r\n| hypervisor     | hypervisor_type: QEMU                    |\r\n|                | id: f36f9331-11a8-43c9-a90b-dbda9bdf9a00 |\r\n|                | is_evacuating: false                     |\r\n|                | state: up                                |\r\n|                | status: enabled                          |\r\n|                | vms: 0                                   |\r\n| id             | 52565ca3-5893-8f6b-62ce-2f07b175b549     |\r\n| in_maintenance | False                                    |\r\n| orig_hostname  | node001                                  |\r\n| placements     | []                                       |\r\n| roles          | - controller                             |\r\n|                | - compute                                |\r\n| services       | - name: cinder-scheduler                 |\r\n|                |   state: healthy                         |\r\n|                | - name: cinder-volume                    |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-dhcp-agent               |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-l3-agent                 |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-metadata-agent           |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-openvswitch-agent        |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-compute                     |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-conductor                   |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-scheduler                   |\r\n|                |   state: healthy                         |\r\n| state          | healthy                                  |\r\n+----------------+------------------------------------------+\n",
                "title": "To check compute services on a node"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute node show <node> --with-stats\n\n<node>\n\nNode ID or hostname\n--with-stats\n\nGet node information with statistics\n\nFor example, to view the details of the compute node node001, run:# vinfra service compute node show node001 --with-stats\r\n+----------------+------------------------------------------+\r\n| Field          | Value                                    |\r\n+----------------+------------------------------------------+\r\n| fenced_reason  |                                          |\r\n| host           | node001.vstoragedomain                   |\r\n| host_ip        | 192.168.128.113                          |\r\n| hypervisor     | hypervisor_type: QEMU                    |\r\n|                | id: f36f9331-11a8-43c9-a90b-dbda9bdf9a00 |\r\n|                | is_evacuating: false                     |\r\n|                | state: up                                |\r\n|                | status: enabled                          |\r\n|                | vms: 0                                   |\r\n| id             | 52565ca3-5893-8f6b-62ce-2f07b175b549     |\r\n| in_maintenance | False                                    |\r\n| orig_hostname  | node001                                  |\r\n| placements     | []                                       |\r\n| roles          | - controller                             |\r\n|                | - compute                                |\r\n| services       | - name: cinder-scheduler                 |\r\n|                |   state: healthy                         |\r\n|                | - name: cinder-volume                    |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-dhcp-agent               |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-l3-agent                 |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-metadata-agent           |\r\n|                |   state: healthy                         |\r\n|                | - name: neutron-openvswitch-agent        |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-compute                     |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-conductor                   |\r\n|                |   state: healthy                         |\r\n|                | - name: nova-scheduler                   |\r\n|                |   state: healthy                         |\r\n| state          | healthy                                  |\r\n| statistics     | compute:                                 |\r\n|                |   block_capacity: 0                      |\r\n|                |   block_usage: 0                         |\r\n|                |   cpu_usage: 0.0                         |\r\n|                |   vcpus: 0                               |\r\n|                |   vcpus_free: 8                          |\r\n|                |   vm_mem_capacity: 3731456000.0          |\r\n|                |   vm_mem_free: 3731456000.0              |\r\n|                |   vm_mem_reserved: 0                     |\r\n|                |   vm_mem_usage: 0                        |\r\n|                | datetime: '2023-01-10T13:04:18.280858'   |\r\n|                | physical:                                |\r\n|                |   cpu_cores: 4                           |\r\n|                |   cpu_usage: 14.212499999994177          |\r\n|                |   mem_free: 534638592                    |\r\n|                |   mem_total: 25110126592                 |\r\n|                |   swap_free: 0                           |\r\n|                |   swap_total: 0                          |\r\n|                |   vcpus_total: 32                        |\r\n|                | reserved:                                |\r\n|                |   cpus: 3                                |\r\n|                |   memory: 21378670592                    |\r\n|                |   vcpus: 24                              |\r\n+----------------+------------------------------------------+\n",
                "title": "To view compute node details"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nOn the Infrastructure > Nodes screen, click the line with a compute node. On the right pane, the Compute services tab provides information about deployed compute controller and worker services on the node. Healthy compute services are highlighted on the tab in green, failed services in red, and disabled services for a fenced node in yellow.\n",
                "title": "To check compute services on a node"
            },
            {
                "example": "\nAdmin panel\nOn the Compute > Nodes screen, click a compute node. You can view the following compute node information:\n\n\nVirtual CPU and RAM reservations:\n\nReserved for the system and storage services (refer to Server requirements)\nProvisioned to virtual machines located on the node\nFree virtual CPUs and RAM left on the node\nNode overcommitment ratio (refer to Enabling and disabling RAM overcommitment and Changing virtual CPU overcommitment)\n\nThe number of virtual CPUs is a product of the number of physical CPUs on a node and the node overcommitment ratio. The amount of RAM is a product of the amount of physical RAM on a node and the node overcommitment ratio.\n\nHosted virtual machines and their resource consumption\n\n",
                "title": "To view compute node details"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-compute-nodes.html"
    },
    {
        "title": "Monitoring the storage cluster",
        "content": "Monitoring the storage cluster\nTo view the storage cluster status\n\nAdmin panel\nClick the cluster name at the bottom of the left menu. The status can be one of the following:\n\nHealthy\n\nAll cluster components are active and operate normally.\nUnavailable\n\nNot enough information about the cluster state (for example, because the cluster is inaccessible).\nDegraded\n\nSome of the cluster components are inactive or inaccessible. The cluster is trying to heal itself, data replication is scheduled or in progress.\nError\n\nThe cluster has too many inactive services and automatic replication is disabled. If the cluster enters this state, troubleshoot the nodes or contact the support team.\n\nCommand-line interface\nUse the following command:vinfra cluster overview\nFor example, to view the status of the cluster cluster1, take a look at this line from the command output:\r\n+-------------------+-------------------------+\r\n| Field             | Value                   |\r\n+-------------------+-------------------------+\r\n| ...               | ...                     |\r\n| status            | healthy                 |\r\n| ...               | ...                     |\r\n+-------------------+-------------------------+\r\n\n\nTo view the storage cluster statistics\n\nAdmin panel\nGo to the Monitoring > Dashboard screen:\n\nTo view the storage cluster statistics in full screen, click Fullscreen mode. \nTo exit the fullscreen mode, press Esc or click Exit fullscreen mode.\n\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.\n\nCommand-line interface\nUse the following command:vstorage -c <cluster_name> top\nFor example, to view the general information about the cluster cluster1, take a look at this section from the command output:Cluster 'cluster1': healthy\r\nSpace: [OK] allocatable 11.9TB of 57.3TB, free 13.0TB of 57.3TB\r\nMDS nodes: 3 of 3, epoch uptime: 13d  3h\r\nCS nodes:  32 of 32 (32 avail, 0 inactive, 0 offline)\r\nLicense: ACTIVE (expiration: 01/01/2100, capacity: 500TB, used: 21.2TB)\r\nReplication:  1 norm,  1 limit\r\nIO:       read 26.2MB/s (1.9Kop/s), write  426MB/s (11Kops/s)\r\n\n\nCluster\n\nOverall status of the cluster:\n\nhealthy\n\nAll chunk servers in the cluster are active.\nunknown\n\nThere is not enough information about the cluster state (for example, because the master MDS server was elected a while ago).\ndegraded\n\nSome of the chunk servers in the cluster are inactive.\nfailure\n\nThe cluster has too many inactive chunk servers; the automatic replication is disabled.\nSMART warning\n\nOne or more physical disks attached to cluster nodes are in pre-failure condition.\n\nSpace\n\nAmount of disk space in the cluster:\n\nfree\n\nFree physical disk space in the cluster.\nallocatable\n\nAmount of logical disk space available for storing data. Allocatable disk space is calculated on the basis of the current replication parameters and free disk space on chunk servers. It may also be limited by license.\n\nMDS nodes\n\nNumber of active MDS servers as compared to the total number of MDS servers configured for the cluster.\n\nepoch time\n\nTime elapsed since the MDS master server election.\n\nCS nodes\n\nNumber of active chunk servers as compared to the total number of chunk servers configured for the cluster. In parentheses, you can see the additional information on these chunk servers:\n\n avail\nActive chunk servers that are currently up and running in the cluster.\ninactive\n\nInactive chunk servers that are temporarily unavailable. A chunk server is marked as inactive during its first 5 minutes of inactivity.\noffline\n\nOffline chunk servers that have been inactive for more than 5 minutes. A chunk server changes its state to offline after 5 minutes of inactivity. Once the state is changed to offline, the cluster starts replicating data to restore the chunks that were stored on the offline chunk server.\n\nLicense\n\nKey number under which the license is registered on the Key Authentication server and license state.\nReplication\n\nReplication settings. The normal number of chunk replicas and the limit after which a chunk gets blocked until recovered.\nIO\n\nDisk I/O activity in the cluster:\n\nSpeed of read and write I/O operations, in bytes per second\nNumber of read and write I/O operations per second\n\nTo view more details about the storage cluster\nGo to the Monitoring > Dashboard screen, and then click Grafana dashboard. \nA separate browser tab will open with preconfigured Grafana dashboards where you can manage existing dashboards, create new ones, share them between users, configure alerting, etc. The dashboards use the Prometheus data source. Its metrics are stored for seven days. If you want to increase this retention period, you can configure it manually. For more information, refer to Grafana documentation.\nOn the Virtuozzo Storage core cluster overview dashboard, note the following charts:\n\nThe Mountpoint availability, MDS availability, and CS availability charts show availability of the corresponding storage services. Time periods when the services have not been available will be highlighted in gray. In this case, you will need to look into logs on the nodes with the failed service and report a problem. To see the logs, use the following commands:\n\nFor storage mountpoints:# blogcat /var/log/vstorage/<cluster_name>/vstorage-mount.*.blog\n\nFor MDS:# zstdcat /vstorage/mds/logs/mds.log.zst\n\nFor CS:# zstdcat /vstorage/<id>/cs/logs/cs.log.zst\n\nFor advanced monitoring of the core storage services, you can view the Virtuozzo Storage mountpoint details, Virtuozzo Storage MDS details, and Virtuozzo Storage CS details dashboards, which are intended for low-level troubleshooting by the support team.\n\nThe Data health chart shows the number of healthy chunks (the ones that have all the replicas available), the number of chunks that need to be replicated to have the configured number of replicas available, and the replication rate in chunks per second.\n\nThe Latency chart show the average latency of read and write I/O operations across all storage clients.\n\nOn the Reencoding overview dashboard, you can check the re-encoding process details, such as the re-encoding speed in the cluster and on particular nodes, the number and estimated physical size of files to be re-encoded, and the number of chunks to re re-encoded. \n\nSee also\n\nCore storage metrics\n\nConfiguring retention policy for Prometheus metrics",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster overview\nFor example, to view the status of the cluster cluster1, take a look at this line from the command output:\r\n+-------------------+-------------------------+\r\n| Field             | Value                   |\r\n+-------------------+-------------------------+\r\n| ...               | ...                     |\r\n| status            | healthy                 |\r\n| ...               | ...                     |\r\n+-------------------+-------------------------+\r\n\n",
                "title": "To view the storage cluster status"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vstorage -c <cluster_name> top\nFor example, to view the general information about the cluster cluster1, take a look at this section from the command output:Cluster 'cluster1': healthy\r\nSpace: [OK] allocatable 11.9TB of 57.3TB, free 13.0TB of 57.3TB\r\nMDS nodes: 3 of 3, epoch uptime: 13d  3h\r\nCS nodes:  32 of 32 (32 avail, 0 inactive, 0 offline)\r\nLicense: ACTIVE (expiration: 01/01/2100, capacity: 500TB, used: 21.2TB)\r\nReplication:  1 norm,  1 limit\r\nIO:       read 26.2MB/s (1.9Kop/s), write  426MB/s (11Kops/s)\r\n\n\nCluster\n\n\nOverall status of the cluster:\n\nhealthy\n\nAll chunk servers in the cluster are active.\nunknown\n\nThere is not enough information about the cluster state (for example, because the master MDS server was elected a while ago).\ndegraded\n\nSome of the chunk servers in the cluster are inactive.\nfailure\n\nThe cluster has too many inactive chunk servers; the automatic replication is disabled.\nSMART warning\n\nOne or more physical disks attached to cluster nodes are in pre-failure condition.\n\n\nSpace\n\n\nAmount of disk space in the cluster:\n\nfree\n\nFree physical disk space in the cluster.\nallocatable\n\nAmount of logical disk space available for storing data. Allocatable disk space is calculated on the basis of the current replication parameters and free disk space on chunk servers. It may also be limited by license.\n\n\nMDS nodes\n\n\nNumber of active MDS servers as compared to the total number of MDS servers configured for the cluster.\n\nepoch time\n\nTime elapsed since the MDS master server election.\n\n\nCS nodes\n\n\nNumber of active chunk servers as compared to the total number of chunk servers configured for the cluster. In parentheses, you can see the additional information on these chunk servers:\n\n avail\nActive chunk servers that are currently up and running in the cluster.\ninactive\n\nInactive chunk servers that are temporarily unavailable. A chunk server is marked as inactive during its first 5 minutes of inactivity.\noffline\n\nOffline chunk servers that have been inactive for more than 5 minutes. A chunk server changes its state to offline after 5 minutes of inactivity. Once the state is changed to offline, the cluster starts replicating data to restore the chunks that were stored on the offline chunk server.\n\n\nLicense\n\nKey number under which the license is registered on the Key Authentication server and license state.\nReplication\n\nReplication settings. The normal number of chunk replicas and the limit after which a chunk gets blocked until recovered.\nIO\n\n\nDisk I/O activity in the cluster:\n\nSpeed of read and write I/O operations, in bytes per second\nNumber of read and write I/O operations per second\n\n\n\n",
                "title": "To view the storage cluster statistics"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nClick the cluster name at the bottom of the left menu. The status can be one of the following:\n\nHealthy\n\nAll cluster components are active and operate normally.\nUnavailable\n\nNot enough information about the cluster state (for example, because the cluster is inaccessible).\nDegraded\n\nSome of the cluster components are inactive or inaccessible. The cluster is trying to heal itself, data replication is scheduled or in progress.\nError\n\nThe cluster has too many inactive services and automatic replication is disabled. If the cluster enters this state, troubleshoot the nodes or contact the support team.\n\n\n\n\n\n",
                "title": "To view the storage cluster status"
            },
            {
                "example": "\nAdmin panel\nGo to the Monitoring > Dashboard screen:\n\nTo view the storage cluster statistics in full screen, click Fullscreen mode. \nTo exit the fullscreen mode, press Esc or click Exit fullscreen mode.\n\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.\n",
                "title": "To view the storage cluster statistics"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-the-storage-cluster.html"
    },
    {
        "title": "5.2. Software Requirements\u00c2\u00b6",
        "content": "5.2. Software Requirements | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n5.2. Software Requirements\u00c2\u00b6\nBitNinja supports most modern Linux distributions. They have packages for .deb and .rpm-based Linux systems and do automatic testing for the following distributions:\n\nCentOS 6 64 bit\nCloudLinux 6\nDebian 6 64 bit\nDebian 7 64 bit\nUbuntu 14 64 bit\n\nBitNinja is also compatible with these Linux distributions:\n\nCentOS 7 and up\nCloudLinux 7 and up\nDebian 8 and up\nRedHat 6 and up\nUbuntu 15 and up\nAlmaLinux 8.4 and up\nVzLinux 7 and up\n\nFor more up-to-date information please check: https://doc.bitninja.io/docs/Installation/system_requirements#software-requirements.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/bitninja-agent-requirements/software-requirements.html"
    },
    {
        "title": "Managing storage policies",
        "content": "Managing storage policies\nA storage policy is a group of parameters that define how to store VM volumes: a tier, a failure domain, and a redundancy mode. A storage policy can also be used to limit the bandwidth or IOPS of the volume. These limits help customize the allocation of cluster resources between the virtual machines. It is also needed to provide predictable performance levels for virtual machine disks.\nWhen you deploy the compute cluster, you select parameters for the default storage policy, to be automatically created together with the cluster. The default policy cannot be deleted or renamed. By default, it is applied to uploaded images and base volumes created from these images.\nAbout base volumes\n\nA base volume is created from a source image when you deploy a VM. It is not used directly by a VM, but all volumes that a VM actually uses (which are listed on the Volumes tab) are in fact deltas (differences) from the base volume. It is important to keep base volumes available as VM volumes depend on them. For that, you need the default storage policy to enforce multiple replicas.\n\nIf the storage cluster does not have enough nodes to enable multiple replicas (not recommended), you can adjust the default storage policy once you add more nodes to the storage cluster. It will be applied to the images and base volumes that were created with the default policy.\nTo apply custom redundancy schemes to VM volumes, you can create, edit, or clone storage policies for them.\nLimitations\n\nYou cannot change the redundancy type of an existing storage policy.\nYou cannot change redundancy parameters of a storage policy with the erasure coding redundancy type.\nYou cannot delete a storage policy that governs existing volumes. If you still want to delete the storage policy, first remove these volumes or select another policy for them.\n\nPrerequisites\n\nA clear understanding of these concepts: Storage policies, Data redundancy, Failure domains, and Storage tiers.\n\nTo create a storage policy\n\nAdmin panel\n\nOn the Compute > Storage > Storage policies tab, click Create storage policy.\n\nIn the Create storage policy window, specify a policy name and select  redundancy settings.\n\nEnable IOPS limit or Bandwidth limit to set the corresponding limits on the volume.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra service compute storage-policy create --tier {0,1,2,3} (--replicas <norm>[:<min>] | --encoding <M>+<N>)\r\n                                             --failure-domain {0,1,2,3,4}\r\n                                             [--write-bytes-sec <limit>] [--read-bytes-sec <limit>]\r\n                                             [--read-iops-sec <limit>] [--write-iops-sec <limit>]\r\n                                             [--total-bytes-sec <limit>] [--total-iops-sec <limit>]\r\n                                             <name>\r\n\n\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--replicas <norm>[:<min>]\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\nmin: minimum required number of replicas (optional)\n\n--write-bytes-sec <limit>\n\nNumber of bytes written per second\n--read-bytes-sec <limit>\n\nNumber of bytes read per second\n--read-iops-sec <limit>\n\nNumber of read operations per second\n--write-iops-sec <limit>\n\nNumber of write operations per second\n--total-bytes-sec <bytes>\n\nTotal number of bytes per second\n--total-iops-sec <iops>\n\nTotal number of I/O operations per second\n<name>\n\nStorage policy name\n\nFor example, to create a storage policy mystorpolicy with the tier 3, erasure coding 3+2 scheme, host failure domain, and the limits of 100 IOPS and 104857600 bytes per second, run:# vinfra service compute storage-policy create mystorpolicy --tier 3 \\\r\n--encoding 3+2 --failure-domain 1 --total-bytes-sec 104857600 --total-iops-sec 100\nThe created storage policy will appear in the vinfra service compute storage-policy list output:# vinfra service compute storage-policy list\r\n+-------------+--------------+------+--------------+----------------+--------------------------------+\r\n| id          | name         | tier | redundancy   | failure_domain | qos                            |\r\n+-------------+--------------+------+--------------+----------------+--------------------------------+\r\n| 97b55811<\u00e2\u0080\u00a6> | mystorpolicy | 3    | encoding=3+2 | 1              | read_bytes_sec: -1             |\r\n|             |              |      |              |                | read_bytes_sec_per_gb: -1      |\r\n|             |              |      |              |                | read_bytes_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | read_iops_sec: -1              |\r\n|             |              |      |              |                | read_iops_sec_per_gb: -1       |\r\n|             |              |      |              |                | read_iops_sec_per_gb_min: -1   |\r\n|             |              |      |              |                | total_bytes_sec: 104857600     |\r\n|             |              |      |              |                | total_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | total_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | total_iops_sec: 100            |\r\n|             |              |      |              |                | total_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | total_iops_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | write_bytes_sec: -1            |\r\n|             |              |      |              |                | write_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | write_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | write_iops_sec: -1             |\r\n|             |              |      |              |                | write_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | write_iops_sec_per_gb_min: -1  |\r\n| 603bd56b<\u00e2\u0080\u00a6> | default      | 0    | replicas=3   | 1              | read_bytes_sec: -1             |\r\n|             |              |      |              |                | read_bytes_sec_per_gb: -1      |\r\n|             |              |      |              |                | read_bytes_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | read_iops_sec: -1              |\r\n|             |              |      |              |                | read_iops_sec_per_gb: -1       |\r\n|             |              |      |              |                | read_iops_sec_per_gb_min: -1   |\r\n|             |              |      |              |                | total_bytes_sec: -1            |\r\n|             |              |      |              |                | total_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | total_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | total_iops_sec: -1             |\r\n|             |              |      |              |                | total_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | total_iops_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | write_bytes_sec: -1            |\r\n|             |              |      |              |                | write_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | write_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | write_iops_sec: -1             |\r\n|             |              |      |              |                | write_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | write_iops_sec_per_gb_min: -1  |\r\n+-------------+--------------+------+--------------+----------------+--------------------------------+\n\nTo edit a storage policy\n\nAdmin panel\n\nOn the Compute > Storage > Storage policies tab, select a policy from the list.\nOn the policy right pane, click Edit.\nChange the required parameters, and then click Save.\n\nKeep in mind, that changes to the storage policy will affect the redundancy and performance of all the volumes covered by it.\n\nCommand-line interface\nUse the following command:vinfra service compute storage-policy set [--name <name>] [--tier {0,1,2,3}]\r\n                                          [--replicas <norm>[:<min>] |\r\n                                          --encoding <M>+<N>]\r\n                                          [--failure-domain {0,1,2,3,4}]\r\n                                          [--write-bytes-sec <limit>] [--read-bytes-sec <limit>]\r\n                                          [--read-iops-sec <limit>] [--write-iops-sec <limit>]\r\n                                          [--total-bytes-sec <limit>] [--total-iops-sec <limit>]\r\n                                          <storage-policy>\r\n\n\n--name <name>\n\nA new name for the storage policy\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--replicas <norm>[:<min>]\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\nmin: minimum required number of replicas (optional)\n\n--write-bytes-sec <limit>\n\nNumber of bytes written per second\n--read-bytes-sec <limit>\n\nNumber of bytes read per second\n--read-iops-sec <limit>\n\nNumber of read operations per second\n--write-iops-sec <limit>\n\nNumber of write operations per second\n--total-bytes-sec <bytes>\n\nTotal number of bytes per second\n--total-iops-sec <iops>\n\nTotal number of I/O operations per second\n<storage-policy>\n\nStorage policy ID or name\n\nFor example, to change the redundancy type for the storage policy mystorpolicy from 2 replicas to 3 replicas, run:# vinfra service compute storage-policy set mystorpolicy --replicas 3\n\nTo clone a storage policy\n\nOn the Compute > Storage > Storage policies tab, select a policy from the list.\nOn the policy right pane, click Clone.\n\nModify the existing parameters or just leave them as they are, and then click Clone.\n\nTo remove a storage policy\n\nAdmin panel\n\nOn the Compute > Storage > Storage policies tab, select a policy from the list.\nOn the policy right pane, click Delete.\nIn the confirmation window, click Delete policy.\n\nCommand-line interface\nUse the following command:vinfra service compute storage-policy delete <storage-policy>\r\n\n\n<storage-policy>\n\nStorage policy ID or name\n\nFor example, to delete the storage policy mystorpolicy, run:# vinfra service compute storage-policy delete mystorpolicy\n\nSee also\n\nUsing volume QoS policies\n\nManaging compute volumes\n\nManaging external storages",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute storage-policy create --tier {0,1,2,3} (--replicas <norm>[:<min>] | --encoding <M>+<N>)\r\n                                             --failure-domain {0,1,2,3,4}\r\n                                             [--write-bytes-sec <limit>] [--read-bytes-sec <limit>]\r\n                                             [--read-iops-sec <limit>] [--write-iops-sec <limit>]\r\n                                             [--total-bytes-sec <limit>] [--total-iops-sec <limit>]\r\n                                             <name>\r\n\n\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--replicas <norm>[:<min>]\n\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\nmin: minimum required number of replicas (optional)\n\n\n--write-bytes-sec <limit>\n\nNumber of bytes written per second\n--read-bytes-sec <limit>\n\nNumber of bytes read per second\n--read-iops-sec <limit>\n\nNumber of read operations per second\n--write-iops-sec <limit>\n\nNumber of write operations per second\n--total-bytes-sec <bytes>\n\nTotal number of bytes per second\n--total-iops-sec <iops>\n\nTotal number of I/O operations per second\n<name>\n\nStorage policy name\n\nFor example, to create a storage policy mystorpolicy with the tier 3, erasure coding 3+2 scheme, host failure domain, and the limits of 100 IOPS and 104857600 bytes per second, run:# vinfra service compute storage-policy create mystorpolicy --tier 3 \\\r\n--encoding 3+2 --failure-domain 1 --total-bytes-sec 104857600 --total-iops-sec 100\nThe created storage policy will appear in the vinfra service compute storage-policy list output:# vinfra service compute storage-policy list\r\n+-------------+--------------+------+--------------+----------------+--------------------------------+\r\n| id          | name         | tier | redundancy   | failure_domain | qos                            |\r\n+-------------+--------------+------+--------------+----------------+--------------------------------+\r\n| 97b55811<\u00e2\u0080\u00a6> | mystorpolicy | 3    | encoding=3+2 | 1              | read_bytes_sec: -1             |\r\n|             |              |      |              |                | read_bytes_sec_per_gb: -1      |\r\n|             |              |      |              |                | read_bytes_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | read_iops_sec: -1              |\r\n|             |              |      |              |                | read_iops_sec_per_gb: -1       |\r\n|             |              |      |              |                | read_iops_sec_per_gb_min: -1   |\r\n|             |              |      |              |                | total_bytes_sec: 104857600     |\r\n|             |              |      |              |                | total_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | total_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | total_iops_sec: 100            |\r\n|             |              |      |              |                | total_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | total_iops_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | write_bytes_sec: -1            |\r\n|             |              |      |              |                | write_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | write_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | write_iops_sec: -1             |\r\n|             |              |      |              |                | write_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | write_iops_sec_per_gb_min: -1  |\r\n| 603bd56b<\u00e2\u0080\u00a6> | default      | 0    | replicas=3   | 1              | read_bytes_sec: -1             |\r\n|             |              |      |              |                | read_bytes_sec_per_gb: -1      |\r\n|             |              |      |              |                | read_bytes_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | read_iops_sec: -1              |\r\n|             |              |      |              |                | read_iops_sec_per_gb: -1       |\r\n|             |              |      |              |                | read_iops_sec_per_gb_min: -1   |\r\n|             |              |      |              |                | total_bytes_sec: -1            |\r\n|             |              |      |              |                | total_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | total_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | total_iops_sec: -1             |\r\n|             |              |      |              |                | total_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | total_iops_sec_per_gb_min: -1  |\r\n|             |              |      |              |                | write_bytes_sec: -1            |\r\n|             |              |      |              |                | write_bytes_sec_per_gb: -1     |\r\n|             |              |      |              |                | write_bytes_sec_per_gb_min: -1 |\r\n|             |              |      |              |                | write_iops_sec: -1             |\r\n|             |              |      |              |                | write_iops_sec_per_gb: -1      |\r\n|             |              |      |              |                | write_iops_sec_per_gb_min: -1  |\r\n+-------------+--------------+------+--------------+----------------+--------------------------------+\n",
                "title": "To create a storage policy"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute storage-policy set [--name <name>] [--tier {0,1,2,3}]\r\n                                          [--replicas <norm>[:<min>] |\r\n                                          --encoding <M>+<N>]\r\n                                          [--failure-domain {0,1,2,3,4}]\r\n                                          [--write-bytes-sec <limit>] [--read-bytes-sec <limit>]\r\n                                          [--read-iops-sec <limit>] [--write-iops-sec <limit>]\r\n                                          [--total-bytes-sec <limit>] [--total-iops-sec <limit>]\r\n                                          <storage-policy>\r\n\n\n--name <name>\n\nA new name for the storage policy\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--replicas <norm>[:<min>]\n\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\nmin: minimum required number of replicas (optional)\n\n\n--write-bytes-sec <limit>\n\nNumber of bytes written per second\n--read-bytes-sec <limit>\n\nNumber of bytes read per second\n--read-iops-sec <limit>\n\nNumber of read operations per second\n--write-iops-sec <limit>\n\nNumber of write operations per second\n--total-bytes-sec <bytes>\n\nTotal number of bytes per second\n--total-iops-sec <iops>\n\nTotal number of I/O operations per second\n<storage-policy>\n\nStorage policy ID or name\n\nFor example, to change the redundancy type for the storage policy mystorpolicy from 2 replicas to 3 replicas, run:# vinfra service compute storage-policy set mystorpolicy --replicas 3\n",
                "title": "To edit a storage policy"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute storage-policy delete <storage-policy>\r\n\n\n<storage-policy>\n\nStorage policy ID or name\n\nFor example, to delete the storage policy mystorpolicy, run:# vinfra service compute storage-policy delete mystorpolicy\n",
                "title": "To remove a storage policy"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Storage policies tab, click Create storage policy.\n\nIn the Create storage policy window, specify a policy name and select  redundancy settings.\n\n\n\n\n\n\nEnable IOPS limit or Bandwidth limit to set the corresponding limits on the volume.\n\nClick Create.\n\n",
                "title": "To create a storage policy"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Storage policies tab, select a policy from the list.\nOn the policy right pane, click Edit.\nChange the required parameters, and then click Save.\n\nKeep in mind, that changes to the storage policy will affect the redundancy and performance of all the volumes covered by it.\n",
                "title": "To edit a storage policy"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Storage policies tab, select a policy from the list.\nOn the policy right pane, click Delete.\nIn the confirmation window, click Delete policy.\n\n",
                "title": "To remove a storage policy"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-storage-policies.html"
    },
    {
        "title": "How to use Milvus and Kubernetes for reverse image search",
        "content": "How to use Milvus and Kubernetes for reverse image searchThis guide explains how to use Milvus, an open-source vector database, and Managed Kubernetes on Virtuozzo Hybrid Infrastructure to build a reverse image search engine.About reverse image searchReverse image search (RIS) helps you search for similar or related images given an input image. Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a query image that it will then base its search upon.The example described in this guide is based on the Milvus vector database, which includes everything you need to perform image search. To learn more about similarity search, refer to the Milvus RIS guide and Milvus Bootcamp.Milvus architectureFor more details, refer to the Milvus documentation.Prerequisites1. Deploy a Virtuozzo Hybrid Infrastructure cluster.2. Create the compute cluster with the Kubernetes and load balancing services.3. Configure a storage policy named standard for boot volumes on Kubernetes master nodes. Ensure that the selected policy is available for all projects where you are planning to deploy Kubernetes.4. Create a Kubernetes cluster.5. Create the default storage class with the storage policy standard. The storage policy must be available in your project. 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# cat > storage-class.yaml <<\\EOT\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: default\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"true\"\nprovisioner: cinder.csi.openstack.org\nparameters:\n  type: standard\nEOT\nApply the configuration file:1\n# kubectl create -f storage-class.yaml\n6. Create a storage policy with ReadWriteMany (RWX) support to store Milvus logs. In this example, we recommend deploying an NFS server and NFS external provisioner as the easiest way to get such a storage policy.7. Ensure that you have the credentials (the access key and secret key) to the object storage service. In this guide, we will use the S3 object storage and a bucket provided by Virtuozzo Hybrid Infrastructure named milvus.Important: We recommend using a separate Python virtual environment to run the required Jupiter notebook, as it installs multiple Python modules with specific versions and may break other applications you develop. You will need Python version 3.11.To learn how to manage virtual environments for Visual Studio Code, refer to Python environments in VS Code.Deploying the Milvus cluster using Helm1. Download the example configuration file for Milvus cluster deployment:1\n# wget https://virtuozzo-k8s-demo.s3.amazonaws.com/milvus-virtuozzo.yaml\n2. Connect to your Kubernetes cluster:1\n# export KUBECONFIG=<your_k8s_kubeconfig_file>\n3. Install and configure Helm.4. Change the Helm configuration file according to your environment. You can edit the milvus-virtuozzo.yaml file obtained in step 1 or create your own by using the command helm show values milvus/milvus > milvus.yaml.In the configuration file:service.type: LoadBalancer as we recommend using load balancers instead of ingress controllers for this setupservice.loadBalancerSourceRanges: 0.0.0.0/24 limits the number of CIDRs to access your Milvus cluster endpoint to the specified IP rangelog.persistence.enabled: true enables persistent storage for logslog.persistence.persistentVolumeClaim.storageClass: nfs specifies the nfs storage policy to store logsattu.enabled: true installs Attu, a management tool for Milvusattu.service.type: LoadBalancer as we recommend using load balancers instead of ingress controllers for this setupminio.enabled: false as we are going to use a third-party S3 storage instead of MinIOexternalS3.enabled: true enables an external S3 connectionexternalS3.host: \"<s3_server_dns_name>\" uses your S3 server DNS name as the S3 access pointexternalS3.port: \"443\" uses TCP port 443 to access the S3 serverexternalS3.accessKey: \"access_key\" uses your S3 access key to access the S3 dataexternalS3.secretKey: \"secret_key\" to your S3 secret key to access the S3 dataexternalS3.useSSL: true enables SSLexternalS3.bucketName: \"milvus\" uses the bucket named milvus5. Deploy the Milvus cluster by using the Helm chart:1\n# helm install -f milvus-virtuozzo.yaml milvus milvus/milvus\nThe deployment takes minimum 5 minutes.6. Once the deployment is complete, check the pods in your Kubernetes cluster. You should have the following pods up and running: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n# kubectl get pod\nNAME                                         READY   STATUS        RESTARTS        AGE\nmilvus-attu-5dd7bdcf75-2jw9p                 1/1     Running       0               12m\nmilvus-datacoord-bc75c755c-hsgjf             1/1     Running       0               12m\nmilvus-datanode-7c569bb566-hf2x5             1/1     Running       1 (7m55s ago)   12m\nmilvus-etcd-0                                1/1     Running       0               12m\nmilvus-etcd-1                                1/1     Running       0               12m\nmilvus-etcd-2                                1/1     Running       0               12m\nmilvus-indexcoord-5d4d9db856-wmhxl           1/1     Running       0               12m\nmilvus-indexnode-58f5f7fc8c-dgslk            1/1     Running       0               12m\nmilvus-proxy-66f78bd4dd-bnncx                1/1     Running       1 (7m54s ago)   12m\nmilvus-pulsar-bookie-0                       1/1     Running       0               12m\nmilvus-pulsar-bookie-1                       1/1     Running       0               12m\nmilvus-pulsar-bookie-2                       1/1     Running       0               12m\nmilvus-pulsar-bookie-init-lmml4              0/1     Completed     0               12m\nmilvus-pulsar-broker-0                       1/1     Running       0               12m\nmilvus-pulsar-proxy-0                        1/1     Running       0               12m\nmilvus-pulsar-pulsar-init-f2spk              0/1     Completed     0               12m\nmilvus-pulsar-recovery-0                     1/1     Running       0               12m\nmilvus-pulsar-zookeeper-0                    1/1     Running       0               12m\nmilvus-pulsar-zookeeper-1                    1/1     Running       0               11m\nmilvus-pulsar-zookeeper-2                    1/1     Running       0               10m\nmilvus-querycoord-7856c67b47-k65xv           1/1     Running       0               12m\nmilvus-querynode-84ccf646b5-5rwsf            1/1     Running       0               12m\nmilvus-rootcoord-d754b8f7c-8vd8z             1/1     Running       0               12m\n7. Find out the endpoints for the Milvus services: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# kubectl get service\nNAME                      TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                               AGE\nkubernetes                ClusterIP      10.254.0.1       <none>           443/TCP                               172d\nmilvus                    LoadBalancer   10.254.71.213    <milvus_address> 19530:30116/TCP,9091:30672/TCP        5m49s\nmilvus-attu               LoadBalancer   10.254.61.197    <attu_address>   3000:30474/TCP                        5m49s\nmilvus-datacoord          ClusterIP      10.254.128.226   <none>           13333/TCP,9091/TCP                    5m49s\nmilvus-datanode           ClusterIP      None             <none>           9091/TCP                              5m49s\nmilvus-etcd               ClusterIP      10.254.89.143    <none>           2379/TCP,2380/TCP                     5m49s\nmilvus-etcd-headless      ClusterIP      None             <none>           2379/TCP,2380/TCP                     5m49s\nmilvus-indexcoord         ClusterIP      10.254.17.32     <none>           31000/TCP,9091/TCP                    5m49s\nmilvus-indexnode          ClusterIP      None             <none>           9091/TCP                              5m49s\nmilvus-pulsar-bookie      ClusterIP      None             <none>           3181/TCP,8000/TCP                     5m49s\nmilvus-pulsar-broker      ClusterIP      None             <none>           8080/TCP,6650/TCP                     5m49s\nmilvus-pulsar-proxy       ClusterIP      10.254.213.2     <none>           80/TCP,6650/TCP                       5m49s\nmilvus-pulsar-recovery    ClusterIP      None             <none>           8000/TCP                              5m49s\nmilvus-pulsar-zookeeper   ClusterIP      None             <none>           8000/TCP,2888/TCP,3888/TCP,2181/TCP   5m49s\nmilvus-querycoord         ClusterIP      10.254.141.63    <none>           19531/TCP,9091/TCP                    5m49s\nmilvus-querynode          ClusterIP      None             <none>           9091/TCP                              5m49s\nmilvus-rootcoord          ClusterIP      10.254.157.20    <none>           53100/TCP,9091/TCP                    5m49s\nYou need two endpoints:The external IP address of the milvus service, <milvus_address>, is the endpoint of Milvus cluster that you will use later for testing.The external IP address of the milvus-attu service, <attu_address>, is the Attu IP address.8. Access Attu at http://<attu_address>:3000/ under the default user root with the password Milvus and check that your Milvus cluster is up and running.Testing Milvus1. Download the Jupyter notebook files:1\n2\n# wget https://virtuozzo-k8s-demo.s3.amazonaws.com/1_build_image_search_engine.ipynb\n# wget https://virtuozzo-k8s-demo.s3.amazonaws.com/2_deep_dive_image_search_attu.ipynb\nThese files are adapted for the Virtuozzo deployment described above. You can also check the original notebooks. The main difference between the original and Virtuozzo files is that we use the updated versions of Milvus and Gradio with the correct code to run your demo website.2. Open the Jupyter notebooks by using your favorite IDE, for example, Visual Studio Code or JupyterLab.3. Change the IP address of the Milvus cluster in both notebooks. To do this, find the Configuration part, and then set HOST to the obtained milvus_address.Enjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/reverse-image-search-with-milvus/"
    },
    {
        "title": "Arrosoft CloudAny Migration from VMware",
        "content": "Arrosoft CloudAny Migration from VMwareThis guide describes how to migrate workloads from VMware to Virtuozzo Hybrid Infrastructure using the Arrosoft CloudAny migration solution.About CloudAnyArrosoft CloudAny (CA) is a cloud migration tool that allows you to migrate any Windows or Linux virtual machine from any hypervisor or bare-metal server, to any private or public cloud. In all environments, except for VMware, CloudAny uses agent-based cloud migration, which comprises of two primary components:The CASource agent is installed on the source server or virtual machine (VM). The agent tracks changes in input/output (IO) operations and replicates these changes to the target CAServer.The CAServer receives replicated data from the source server and manages the replication process. Additionally, CAServer serves as the management console for centralized control and coordination of replication and recovery processes.For VMware workloads, CloudAny supports agent-less migration thanks to seamless integration with VMware vCenter using VADP (vStorage API for Data Protection).CloudAny diagramNetwork ports requirementsCloudAny ports: TCP 443/20443, 20000,20001,20005, 20005Virtuozzo Hybrid Infrastructure ports:ServiceDefault portProtocolIdentity API v35000TCPnoVNC Websocket Proxy6080TCPOrchestration Service API v18004TCPCompute API8774TCPBlock Storage API v38776TCPImage Service API v29292TCPKey Manager API v19313TCPNetworking API v29696TCPPreparing the environment1. Deploy Target CAServer with the management console in Virtuozzo Hybrid Infrastructure.2. Register the target cloud connection and Target CAServer in the management console.3. Deploy Source CAServer without the management console in VMware.4. Register the source cloud connection and Source CAServer in the management console.Deploying Target CAServer in Virtuozzo Hybrid Infrastructure1. In the Virtuozzo Hybrid Infrastructure admin panel, create a virtual machine with the following parameters:Name: CAServer_targetCPU: minimum 4 vCPUs, recommended 8 vCPUsRAM: minimum 8 GB, recommended 16 GBOS disk size: 50 GBData disk size: 50 GB (the CAServer cache and installation location)Public IP address: requiredOperating system: Windows Server 2019 or newer2. Log in to the CAServer_target virtual machine by clicking Console on the VM right pane.3. Download CAServerInstallation.exe and LinuxConverter.exe.4. Run CAServerInstallation.exe. In the CAServer Setup Wizard, follow the installation steps:4.1. On the Optional features to install step, select Management.4.2. On the Select installation folder step, specify the installation path on any drive other than C:\\.4.3. Click Install to start the installation, and then Finish once the installation is complete.5. Run and install LinuxConverter.exe.6. In a browser, access the CloudAny management console at https://<MGMT_IP_address> and log in to it with the default credentials admin/admin.7. On the Setup Wizard screen, Click Skip.8. Access the login interface and click System settings in the upper right corner. Change the timezone to that of the source machine. Then, click Settings.9. On the Settings screen, click the License tab, and then Activate to activate your license.Registering Virtuozzo cloud connection in CloudAny1. In the CloudAny management console, click Resources in the left menu, click Cloud, and then click Add.2. On the Add cloud connection screen, select OpenStack.3. On the Verify connection step, specify the following parameters in the Access control section:Protocol: HTTPSAddress: IP address of the Virtuozzo Hybrid Infrastructure admin panelPort: 5000Username and Password: credentials of the administrator user (admin)Domain: Default4. Click Verify connection.5. On the Add cloud step, select your project in the Project field, and then click Submit.Once added, your Virtuozzo Cloud will appear on the Cloud screen.Registering Target CAServer in CloudAny1. In the CloudAny management console, click CAServer in the left menu, and then click Add.2. On the Add CAServer screen, select Cloud.3. On the Select cloud connection screen, select your Virtuozzo Cloud.4. On the Select server screen, select your CAServer.5. On the Verify connection step, click Verify server.6. On the Add CAServer step, click Submit.Once added, your CAServer will appear on the CAServer screen.Deploying and registering Source CAServer1. In VMware, create a virtual machine with the following parameters:Name: CAServer_sourceCPU: 4 vCPUsRAM: 8 GBDisk size: 50 GBPublic IP address: requiredOperating system: Windows Server 2019 or newer2. Inside the CAServer_source virtual machine, download and run CAServerInstallation.exe. In the CAServer Setup Wizard, follow the installation steps:2.1. On the Optional features to install step, uncheck Management.2.2. On the Select installation folder step, specify the installation path on the C:\\ drive. For example: C:\\Program Files\\Arrosoft\\CAServer.2.3. Click Install to start the installation, and then Finish once the installation is complete.3. Go to C:\\Program Files\\Arrosoft\\CAServer and run RegistrationTool.exe.4. In the CloudAny management console, obtain the security code for your CAServer:4.1. On the CAServer screen, click Settings.4.2. Copy the code displayed in the Security code field.5. In the Registration Tool window, specify the IP address of your management console and the obtained security code, and then click Connect. Once added, your Source CAServer will appear on the CAServer screen in the CloudAny management console.Registering VMware cloud connection in CloudAny1. In the CloudAny management console, click Cloud in the left menu, and then click Add.2. On the Add cloud connection screen, select VMware.3. On the Verify connection step, specify the following parameters in the Access control section:CAServer: your Source CAServer that will serve as a proxy to connect to the vCenter or ESXi hostIP/Name: internal IP address of the vCenter or ESXi hostUsername and Password: credentials of the administrator user4. Click Verify connection.5. On the Add cloud step, click Submit.Performing a VM migration1. Register a VMware VM that you want to migrate.2. Create a replication job for the VMware VM.3. Migrate the VMware virtual machine to Virtuozzo Hybrid Infrastructure.Registering VMware VM in CloudAny1. In the CloudAny management console, click CASource in the left menu, and then click Add.2. On the Add source machine screen, select VMware server.3. In the Select server drop-down menu, select your Source CAServer.4. From the list of hosts that appear on the left, select your ESXi host.5. From the list of virtual machines that appear on the right, select your VM, and then click Submit.Once added, your VMware virtual machine will appear on the CASource screen.Creating a replication job1. In the CloudAny management console, click Replication in the left menu, and then click Add.2. On the Source machine screen, select your VMware virtual machine.3. On the Protection process selection screen, select Standard protection.4. On the Server selection screen, select your Virtuozzo Cloud as Target server.5. On the Specifications screen, click Next.6. On the Process configurations screen, specify the appropriate IP address for communication between the source and target servers in the WebDav address field, and then click Run.The replication process will appear and start on the Replication screen.Migrating the virtual machine1. In the CloudAny management console, click Provision in the left menu, and then click Add.2. On the Provision process selection screen, select a VM to provision.3. On the Provisioning type selection screen, select DevTest by snapshot to create a test environment from the selected snapshot.4. On the Specifications screen, select your snapshot point in time.5. On the Process configurations screen, specify the following parameters in the Provision settings section:Instance flavor: select a flavorInstance name: specify a name or keep the default nameSecurity group: defaultSubnet network: select a subnetIP address: leave it empty as it will be automatically assigned by the DHCP serverConvert option: Perform system conversion6. Click Submit.The conversion process will appear and start on the Provision screen.Once the system is converted, the disk will be detached and used to create a new VM in Virtuozzo Hybrid Infrastructure. On the Virtual machines screen, click the newly appeared VM. On its right pane, click Console and log in to the virtual machine, to check that it is successfully migrated.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/arrosoft-cloudany-migration-from-vmware/"
    },
    {
        "title": "Disabling and enabling S3 users via CLI",
        "content": "Disabling and enabling S3 users via CLI\nYou can disable a user with the ostor-s3-admin disable-user command. You need to specify either the user email (-e) or S3 ID (-i). For example:# ostor-s3-admin disable-user -e user@email.com -V 0100000000000002\r\n\nTo enable a disabled user, use the ostor-s3-admin enable-user command. You need to specify either the user email (-e) or S3 ID (-i). For example:# ostor-s3-admin enable-user -e user@email.com -V 0100000000000002\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/disabling-and-enabling-s3-users-via-cli.html"
    },
    {
        "title": "Management",
        "content": "Management\nAfter the infrastructure setup, you can manage nodes, networks, users, the self service, and security, as well as install the license and configure email notifications. In addition, after provisioning backup, block, object, file storage, or compute resources, you can manage them in the admin panel.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/management.html"
    },
    {
        "title": "Creating host aggregates",
        "content": "Creating host aggregatesPOST /os-aggregates\r\n\nCreate a host aggregate.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=create-aggregate-detail#create-aggregate\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\naggregate\n\nbody\nobject\nThe host aggregate object.\n\nname\n\nbody\nstring\nThe name of the host aggregate.\n\navailability_zone (Optional)\nbody\nstring\nThe availability zone of the host aggregate. You should use a custom\r\navailability zone rather than the default returned by the\r\nos-availability-zone API. The availability zone must not include \u00e2\u0080\u0098:\u00e2\u0080\u0099\r\nin its name.\n\nExamplecurl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"aggregate\": {\r\n    \"name\": \"CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\"\r\n}' https://<node_IP_addr>:8774/v2.1/6ef5371261ea42008e3d1d41ba051977/os-aggregates\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\naggregate\n\nbody\nobject\nThe host aggregate object.\n\nname\n\nbody\nstring\nThe name of the host aggregate.\n\navailability_zone\n\nbody\nstring\nThe availability zone of the host aggregate.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted_at\n\nbody\nstring\n\nThe date and time when the resource was deleted. If the resource has\r\nnot been deleted yet, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted\n\nbody\nboolean\nA boolean indicates whether this aggregate is deleted or not, if it has\r\nnot been deleted, false will appear.\n\nid\n\nbody\ninteger\nThe ID of the host aggregate.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nuuid\n\nbody\nstring\n\nThe UUID of the host aggregate.\nNew in version 2.41\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"aggregate\": {\r\n    \"name\": \"CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\",\r\n    \"availability_zone\": null,\r\n    \"deleted\": false,\r\n    \"created_at\": \"2020-04-19T12:56:10.191466\",\r\n    \"updated_at\": null,\r\n    \"deleted_at\": null,\r\n    \"id\": 4\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-host-aggregates.html"
    },
    {
        "title": "Deleting users",
        "content": "Deleting usersDELETE /v3/users/{user_id}\r\n\nDelete a user with the specified ID.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=delete-user-detail#delete-user\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nuser_id\n\npath\nstring\nThe user ID.\n\nExample# curl -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/users/785ddfee5005496ab9a332f4de2f30b6\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-users.html"
    },
    {
        "title": "Signing in through identity providers",
        "content": "Signing in through identity providers\nAfter connecting to an identity provider, you can obtain the direct link to the self-service login page and share it with federated users. On this login page, federated users need to click Sign in with <identity_provider> to be redirected to their identity provider for authentication. Upon successful authentication, federated users are redirected back to the self-service panel.\n\nIf the Implicit Flow is used for authorization, the AD FS authorization endpoint must support the Form Post Response Mode.\n\nIf federated users are added to a domain group within the Default domain with the System administrator permissions, they will also be able to log in to the admin panel through their identity provider.\nPrerequisites\n\nIdentity providers are added to the admin panel, as described in Adding  identity providers.\n\nTo share the self-service panel URL with federated users\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, and then click the arrow icon next to the identity provider, to expand the detailed information.\nIn Self-service panel URL, copy the direct link to the self-service panel, and then share it with the federated users.\n\nSee also\n\nEditing and deleting identity providers",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/signing-in-through-identity-providers.html"
    },
    {
        "title": "Managing compute nodes",
        "content": "Managing compute nodes\nCompute nodes run the compute services and virtual machines. You can deploy the compute cluster on top of the storage cluster, thus, making a hyperconverged infrastructure. Alternatively, you can separate the compute services from the core storage services by running the compute services on other infrastructure nodes. Keep in mind that deploying the compute services increases resource consumption and may affect storage cluster performance.\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-compute-nodes.html"
    },
    {
        "title": "Changing security group assignment",
        "content": "Changing security group assignment\nWhen you create a VM, you select security groups for the VM\u00a0network interfaces. You can also change assigned security groups later.\nLimitations\n\nYou cannot configure security groups if spoofing protection is disabled or IP address management is disabled for the selected network.\n\nTo view virtual machines assigned to a security group\n\nOn the Security groups screen, click the required security group.\nOn the group right pane, navigate to the Assigned VMs tab. All the assigned virtual machines will be shown along with their status.\n\nYou can click the VM name to go to the VM Overview pane and change the security group assignment for its network interfaces.\nTo assign a security group to a virtual machine\n\nOn the Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Networks section. \nClick the ellipsis icon next to the network interface to assign a security group to, and then click Edit.\nIn the Edit network interface window, go to the Security groups tab.\nSelect one or more security groups from the drop-down list, and then click Save.\n\nThe rules from chosen security groups will be applied at runtime.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/changing-security-group-assignment.html"
    },
    {
        "title": "Creating placements",
        "content": "Creating placements\nThough you can create and configure placements only in the admin panel, they are also applied in the  self-service panel. Self-service users can use placements by creating VMs from images and flavors with assigned placements. After uploading an image in the self-service panel, a user cannot assign any placements to it. A VM created from such an image can only be placed on nodes that have placements in the soft mode or on nodes without any placements. When creating placements, ensure that you have either placements in the soft mode or some unassigned nodes. Otherwise self-service users will not be able to create VMs from their custom images.\nLimitations\n\nAfter adding a node to a placement, VMs already hosted on the node will not be automatically assigned this placement.\n\nA virtual machine that is assigned a placement can only be migrated between nodes in this placement. When adding nodes to placements, make sure to provide migration options for various scenarios, including high availability and maintenance. Avoid situations when VMs cannot migrate because of limitations imposed by placements. In this case, a VM placement can be edited, as described in Managing virtual machines in placements.\n\nIf you create a placement after creating a project, the placement is not automatically enabled in the project quotas.\n\nPrerequisites\n\nA clear understanding of the placement modes, which are explained in Placement modes.\n\nTo create a placement\n\nAdmin panel\n\nOpen the Compute > Nodes > Placements tab, and then click Create placement.\n\nSelect the placement mode:\n\nIn the Soft mode, a VM can be placed on a node that is assigned at least the same placements as the VM. This mode allows placing a VM without assigned placements on any node.\nIn the Hard mode, a VM can be placed on a node that is assigned exactly the same placements as the VM.\n\nSpecify a name for the new placement and, optionally, a description. The name should clearly state the distinctive feature of nodes in the placement. For example, Microsoft Windows Server license.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nIn the Nodes section, click Add, and then select the nodes to assign the placement to. The same node can be added to several placements.\n\nIn the Images and Flavors sections, click Add, and then select images and flavors to assign the placement to. VMs created from such images or flavors will automatically be assigned this placement.\n\nClick Create.\n\nThe new placement will appear in the list. To allow self-service users to create virtual machines from the images that are assigned this placement, include the placement into your project quotas.\n\nCommand-line interface\nUse the following command:vinfra service compute placement create [--isolated | --non-isolated] [--description <description>]\r\n                                        [--nodes <nodes>] [--images <images>] [--flavors <flavors>]\r\n                                        <placement-name>\r\n\n\n--isolated\n\nCreate an isolated placement (hard policy, default)\n--non-isolated\n\nCreate a non-isolated placement (soft policy)\n--description <description>\n\nPlacement description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--nodes <nodes>\n\nA comma-separated list of compute node IDs or hostnames to assign to a compute placement\n--images <images>\n\nA comma-separated list of image IDs or names to assign to a compute placement\n--flavors <flavors>\n\nA comma-separated list of flavor IDs or names to assign to a compute placement\n<placement-name>\n\nPlacement name\n\nFor example, to create a placement called placement1 with the hard policy and assign it to the nodes node001, node002, node003, as well as to the flavor with the ID 101, run:# vinfra service compute placement create placement1 --nodes node001,node002,node003 --flavors 101\r\n+-------------+--------------------------------------+\r\n| Field       | Value                                |\r\n+-------------+--------------------------------------+\r\n| description |                                      |\r\n| flavors     | 1                                    |\r\n| id          | e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| images      | 0                                    |\r\n| name        | placement1                           |\r\n| nodes       | 3                                    |\r\n| servers     | 0                                    |\r\n+-------------+--------------------------------------+\r\n\nThe new placement will appear in the vinfra service compute placement list output:# vinfra service compute placement list -c id -c name -c nodes -c images -c flavors -c isolated\r\n+---------------------+------------+-------------+-------+--------+---------+---------+----------+\r\n| id                  | name       | description | nodes | images | servers | flavors | isolated |\r\n+---------------------+------------+-------------+-------+--------+---------+---------+----------+\r\n| e4230b75-a858-<...> | placement1 |             | 3     | 0      | 0       | 1       | True     |\r\n+---------------------+------------+-------------+-------+--------+---------+---------+----------+\r\n\n\nSee also\n\nManaging virtual machines in placements\n\nChanging placement assignment\n\nEditing and deleting placements",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute placement create [--isolated | --non-isolated] [--description <description>]\r\n                                        [--nodes <nodes>] [--images <images>] [--flavors <flavors>]\r\n                                        <placement-name>\r\n\n\n--isolated\n\nCreate an isolated placement (hard policy, default)\n--non-isolated\n\nCreate a non-isolated placement (soft policy)\n--description <description>\n\n\nPlacement description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--nodes <nodes>\n\nA comma-separated list of compute node IDs or hostnames to assign to a compute placement\n--images <images>\n\nA comma-separated list of image IDs or names to assign to a compute placement\n--flavors <flavors>\n\nA comma-separated list of flavor IDs or names to assign to a compute placement\n<placement-name>\n\nPlacement name\n\nFor example, to create a placement called placement1 with the hard policy and assign it to the nodes node001, node002, node003, as well as to the flavor with the ID 101, run:# vinfra service compute placement create placement1 --nodes node001,node002,node003 --flavors 101\r\n+-------------+--------------------------------------+\r\n| Field       | Value                                |\r\n+-------------+--------------------------------------+\r\n| description |                                      |\r\n| flavors     | 1                                    |\r\n| id          | e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| images      | 0                                    |\r\n| name        | placement1                           |\r\n| nodes       | 3                                    |\r\n| servers     | 0                                    |\r\n+-------------+--------------------------------------+\r\n\nThe new placement will appear in the vinfra service compute placement list output:# vinfra service compute placement list -c id -c name -c nodes -c images -c flavors -c isolated\r\n+---------------------+------------+-------------+-------+--------+---------+---------+----------+\r\n| id                  | name       | description | nodes | images | servers | flavors | isolated |\r\n+---------------------+------------+-------------+-------+--------+---------+---------+----------+\r\n| e4230b75-a858-<...> | placement1 |             | 3     | 0      | 0       | 1       | True     |\r\n+---------------------+------------+-------------+-------+--------+---------+---------+----------+\r\n\n",
                "title": "To create a placement"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen the Compute > Nodes > Placements tab, and then click Create placement.\n\nSelect the placement mode:\n\nIn the Soft mode, a VM can be placed on a node that is assigned at least the same placements as the VM. This mode allows placing a VM without assigned placements on any node.\nIn the Hard mode, a VM can be placed on a node that is assigned exactly the same placements as the VM.\n\n\n\nSpecify a name for the new placement and, optionally, a description. The name should clearly state the distinctive feature of nodes in the placement. For example, Microsoft Windows Server license.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\nIn the Nodes section, click Add, and then select the nodes to assign the placement to. The same node can be added to several placements.\n\nIn the Images and Flavors sections, click Add, and then select images and flavors to assign the placement to. VMs created from such images or flavors will automatically be assigned this placement.\n\nClick Create.\n\nThe new placement will appear in the list. To allow self-service users to create virtual machines from the images that are assigned this placement, include the placement into your project quotas.\n",
                "title": "To create a placement"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-placements.html"
    },
    {
        "title": "Attaching external NFS storage",
        "content": "Attaching external NFS storage\nThe Generic NFS Reference Driver allows you to mount multiple NFS shares to your compute cluster and use them as external NFS storages.\nTo attach an external NFS storage\nUse the following command:vinfra service compute storage add <storage_name> --nfs --params nas_host=<nas_ip_address>,nas_share_path=<share_path>\r\n                                   [--nfs-mount-options <options>] --enable\r\n\nWhere:\n\n<storage_name> is a custom name of your external storage. The name may only contain letters, numbers, and underscores, and must be 3 to 64 characters long.\nnas_host=<nas_ip_address> is the IP address of the external storage to connect to.\nnas_share_path=<share_path> is the root export path of the NFS share.\n\n--nfs-mount-options <options> is a comma-separated list of mount options for NFS compute storages, with additional flags separated by spaces. For example: lookupcache=none,nfsvers=4,minorversion=0,timeo=150,retrans=3 -m -s. To see a full list of mount options, refer to the mount and nfs man pages.\nNote that if nfs_shares_config is used, these mount options are applied to every share listed in the configuration file, unless they are overwritten in the configuration file.\n\nSetting the lookupcache policy to all is not recommended as it leads to issues with accessing volume .info files.\n\nWhen the --nfs option is specified, it automatically sets the following parameters required for NFS storage:\n\nvolume_backend_name to the external storage name specified by <storage_name>.\nvolume_driver to the name of the OpenStack volume driver, which is cinder.volume.drivers.nfs.NfsDriver.\nnfs_mount_options to lookupcache=pos to ensure that the NFS client revalidates negative entries in the directory entry cache.\nnfs_mount_point_base to the directory to mount the NFS share to, which is /mnt/compute/storages.\nnas_secure_file_permissions to False to create volumes with open permissions.\nnfs_qcow2_volumes to True to create volumes as QCOW2 files.\nnfs_snapshot_support to True and nas_secure_file_operations to False to enable support for snapshots.\nnfs_sparsed_volumes to True to create volumes as sparsed files, which take no space.\n\nFor example, to add the external storage nfs_storage with the IP address 10.10.10.12 and the share path /myshare, run:# vinfra service compute storage add nfs_storage --nfs --params nas_host=10.10.10.12,nas_share_path=/myshare --enable\r\n\n\nEnsure that the data specified is valid. An incorrectly configured storage will lead to the critical state of the cinder-volume service and the node itself. However, all other operations on the node will not be affected.\n\nThe added external storage will appear in the vinfra service compute storage list output:# vinfra service compute storage list\r\n+-------------+----------------------------------------------------+---------------+---------+------------+\r\n| name        | params                                             | secret_params | enabled | configured |\r\n+-------------+----------------------------------------------------+---------------+---------+------------+\r\n| nfs_storage | nas_host: 10.10.10.12                              |               | True    | True       |\r\n|             | nas_secure_file_operations: 'False'                |               |         |            |\r\n|             | nas_secure_file_permissions: 'False'               |               |         |            |\r\n|             | nas_share_path: /myshare                           |               |         |            |\r\n|             | nfs_mount_options: lookupcache=pos                 |               |         |            |\r\n|             | nfs_mount_point_base: /mnt/compute/storages        |               |         |            |\r\n|             | nfs_qcow2_volumes: 'True'                          |               |         |            |\r\n|             | nfs_snapshot_support: 'True'                       |               |         |            |\r\n|             | nfs_sparsed_volumes: 'True'                        |               |         |            |\r\n|             | volume_backend_name: nfs-storage                   |               |         |            |\r\n|             | volume_driver: cinder.volume.drivers.nfs.NfsDriver |               |         |            |\r\n+-------------+----------------------------------------------------+---------------+---------+------------+\nSee also\n\nAttaching external iSCSI storage\n\nDetaching external storages\n\nWhat's next\n\nCreating external storage policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/attaching-external-nfs-storage.html"
    },
    {
        "title": "Listing S3 accounts via CLI",
        "content": "Listing S3 accounts via CLI\nYou can list all accounts of an S3 user with the ostor-s3-admin list-user-accounts command. Information for each account can take one or more sequential rows in the table. Additional rows are used to lists S3 access key pairs associated with the account. If the account does not have any active key pairs, they are not shown in the output. You need to specify either the user email (-e) or S3 ID (-i). For example:# ostor-s3-admin list-user-accounts -V 0100000000000002 -e user@email.com\r\nNAME      USER_ID           EMAIL           S3AccessKeyId        S3SecretAccessKey\r\naccount1  b09693b73b3c7686  user@email.com  b09693b73b3c768613NV ***\r\naccount2  b09693b73b3c7686  user@email.com  b09693b73b3c7686LCZ5 ***\r\n                                            b09693b73b3c76866NI2 ***\r\naccount3  b09693b73b3c7686  user@email.com",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/listing-s3-accounts-via-cli.html"
    },
    {
        "title": "Listing backups for a project",
        "content": "Listing backups for a projectGET /v3/{project_id}/backups\nList backups to which the project has access.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/#list-backups-for-project\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nall_tenants (Optional)\nquery\nstring\nShows details for all project. Admin only.\n\nsort (Optional)\nquery\nstring\nComma-separated list of sort keys and optional sort directions in the form of <key>[:<direction>]. A valid sort key value is name, status, container_format, disk_format, size, id, created_at, or updated_at. Default is created_at. A valid direction is asc (ascending) or desc (descending).\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number of items up to a limit value. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request.\n\noffset (Optional)\nquery\ninteger\nUsed in conjunction with limit to return a slice of items. offset specifies where to start in the list.\n\nmarker (Optional)\nquery\r\n\nstring\nThe ID of the last-seen item. Use the limit parameter to make an initial limited request and use the ID of the last-seen item from the response as the marker parameter value in a subsequent limited request.\n\nwith_count (Optional)\r\n\nquery\r\n\nboolean\n\nWhether to show count in the API response or not, default is False.\nNew in version 3.45\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nbackups\n\nbody\narray\n\r\nA list of backup objects.\n\nid\n\nbody\nstring\nThe UUID of the backup.\n\nlinks\n\nbody\narray\nLinks for the backup.\n\nname\n\nbody\nstring\nThe backup name.\n\ncount (Optional)\nbody\ninteger\n\nThe total count of requested resource before pagination is applied.\nNew in version 3.45\n\nbackup_links (Optional)\nbody\narray\nAn array containing an object with the following fields: rel with the value next and href, whose value is a link to the next page of backups. Only appears when there are more backups than are listed in the current response.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\nExample{\r\n  \"backups\": [\r\n    {\r\n      \"id\": \"1e49d21e-44e1-401c-acc5-59115c12f0c4\",\r\n      \"name\": \"vm2/cirros/Boot volume-2024-05-09T10:41:13\",\r\n      \"links\": [\r\n        {\r\n          \"rel\": \"self\",\r\n          \"href\": \"https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/1e49d21e-44e1-401c-acc5-59115c12f0c4\"\r\n        },\r\n        {\r\n          \"rel\": \"bookmark\",\r\n          \"href\": \"https://<node_IP_addr>:8776/3046fb2c2a314a0fbb32607caa1e5277/backups/1e49d21e-44e1-401c-acc5-59115c12f0c4\"\r\n        }\r\n      ]\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-backups-for-project.html"
    },
    {
        "title": "Monitoring node performance",
        "content": "Monitoring node performance\nTo monitor the performance of an infrastructure node\n Open the Infrastructure > Nodes screen and click the required node line. On the right pane, the Monitoring tab displays the performance statistics:\n\nCPU/RAM: CPU usage in percent over time, and RAM usage, in GiB over time\nNetwork: the rate of transmitted (TX) and received (RX) traffic over time\nDisks read: node read activity over time\nDisks write: node write activity over time\nPhysical space: the current usage of the node physical space\n\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.\nFor advanced monitoring, click Grafana dashboard.\nSee also\n\nMonitoring node disks\n\nMonitoring node network interfaces",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-node-performance.html"
    },
    {
        "title": "Deleting host aggregates",
        "content": "Deleting host aggregatesDELETE /os-aggregates/{aggregate_id}\r\n\nDelete an aggregate.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=delete-aggregate-detail#delete-aggregate\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\naggregate_id\n\npath\ninteger\nThe aggregate ID.\n\nExamplecurl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/6ef5371261ea42008e3d1d41ba051977/os-aggregates/4\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-host-aggregates.html"
    },
    {
        "title": "9.3. Changing Default Admin Password\u00c2\u00b6",
        "content": "9.3. Changing Default Admin Password | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n9.3. Changing Default Admin Password\u00c2\u00b6\nFor security reasons, change the default administrator password the first time you use your Connection Broker. To change the administrator password, log in to the Connection Broker as the default administrator and go to the Sign in > My Options page, shown in the following figure.\n\nEnter a new password in the Password edit field.\nReenter the new password in the Re-type password edit field.\nClick Save.\n\nImportant\nThe Connection Broker cannot remind you of your password. If you forget your administrator password, reset it using the Connection Broker virtual machine console. See \u00e2\u0080\u009cResetting the Default admin Password\u00e2\u0080\u009d in the Connection Broker Security Review document for complete instructions.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/configuring-broker/changing-default-password.html"
    },
    {
        "title": "3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\u00c2\u00b6",
        "content": "3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\u00c2\u00b6\nSuch an appliance is a pre-configured virtual machine that you deploy in Virtuozzo Hybrid Infrastructure. It contains a protection agent that enables you to administer cyber protection of all virtual machines in a Virtuozzo Hybrid Infrastructure cluster.\nBefore you proceed to deploy one or more agents, take note of the following:\n\nAgent system requirements.\nWhen deploying the agent virtual appliance(s), you can choose between different predefined combinations of vCPUs and RAM, i.e. flavors. You can also create your own flavors.\nThe medium flavor with 2 vCPUs and 4 GB of RAM is optimal and sufficient for most operations. It is recommended, however, to let an agent have 8 GB of RAM and 4 vCPUs to improve backup performance if the backup traffic exceeds 100 MB/s (in 10 Gbps networks, for example).\n\nThe number of agents.\nEven though one agent can protect the entire cluster, you can deploy more if you need to distribute the backup traffic bandwidth load.\nIf you have more than one agent in a cluster, the virtual machines are automatically evenly distributed between the agents, so that each agent manages an equal number of machines.\nAutomatic redistribution takes place when a load imbalance among the agents reaches 20%. This may happen, for example, when a machine or an agent is added or removed. For example, you may realize that you need more agents to help with throughput and deploy an additional virtual appliance to the cluster. The management server will assign the most appropriate machines to the new agent. The load on older agents will be reduced. When you remove an agent from the management server, the machines assigned to the agent are distributed among the remaining agents. This, however, will not happen if an agent gets corrupted or is deleted manually from a Virtuozzo Hybrid Infrastructure node. Redistribution will start only after you remove such an agent from the Cyber Protection web interface.\nYou can view the result of the automatic distribution:\n\nIn the Agent column for each virtual machine in the All devices section\nIn the Assigned virtual machines section of the Details panel when an agent is selected in Settings > Agents\n\nLimitations\n\nVirtuozzo Hybrid Infrastructure appliances cannot be deployed remotely.\nApplication-aware backup of virtual machines is not supported.\n\nIn this chapter:\n\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-agent-for-virtuozzo-hybrid-infrastructure-from-qcow2-template/index.html"
    },
    {
        "title": "Enabling S3 access for the self service",
        "content": "Enabling S3 access for the self service\nTo allow self-service users to manage S3 resources, you need to enable S3 access for the domains. By default, S3 access is disabled for all domains.\nLimitations\n\nOnly domain administrators can manage S3 resources.\n\nPrerequisites\n\nThe S3 cluster is created, as described in Creating the S3 cluster.\nDomains, projects, and users are created, as described in Configuring multitenancy.\n\nTo enable S3 access  for a domain\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > S3 access screen, and then enable S3 access.\n\nCommand-line interface\nUse the following command:vinfra service s3 self-service domain enable --domain <domain>\n\n--domain <domain>\n\nDomain name or ID\n\nFor example, to enable S3 access for the domain mydomain, run:# vinfra service s3 self-service domain enable --domain mydomain\nThe updated domain setting will appear in the vinfra service s3 self-service domain show output:# vinfra service s3 self-service domain show --domain mydomain\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| Enabled | True  |\r\n+---------+-------+\r\n\n\nTo disable S3 access for a domain\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > S3 access screen, and then disable S3 access.\n\nCommand-line interfacevinfra service s3 self-service domain disable --domain <domain>\n\n--domain <domain>\n\nDomain name or ID\n\nFor example, to disable S3 access for the domain mydomain, run:# vinfra service s3 self-service domain disable --domain mydomain\nThe updated domain setting will appear in the vinfra service s3 self-service domain show output:# vinfra service s3 self-service domain show --domain mydomain\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| Enabled | False |\r\n+---------+-------+\n\nSee also\n\nCreating S3 users\n\nWhat's next\n\nManaging object storage\n\nMonitoring object storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 self-service domain enable --domain <domain>\n\n--domain <domain>\n\nDomain name or ID\n\nFor example, to enable S3 access for the domain mydomain, run:# vinfra service s3 self-service domain enable --domain mydomain\nThe updated domain setting will appear in the vinfra service s3 self-service domain show output:# vinfra service s3 self-service domain show --domain mydomain\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| Enabled | True  |\r\n+---------+-------+\r\n\n",
                "title": "To enable S3 access  for a domain"
            },
            {
                "example": "\nCommand-line interfacevinfra service s3 self-service domain disable --domain <domain>\n\n--domain <domain>\n\nDomain name or ID\n\nFor example, to disable S3 access for the domain mydomain, run:# vinfra service s3 self-service domain disable --domain mydomain\nThe updated domain setting will appear in the vinfra service s3 self-service domain show output:# vinfra service s3 self-service domain show --domain mydomain\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| Enabled | False |\r\n+---------+-------+\n",
                "title": "To disable S3 access for a domain"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > S3 access screen, and then enable S3 access.\n\n",
                "title": "To enable S3 access  for a domain"
            },
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > S3 access screen, and then disable S3 access.\n\n",
                "title": "To disable S3 access for a domain"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-s3-access-for-self-service.html"
    },
    {
        "title": "Editing and deleting backup plans",
        "content": "Editing and deleting backup plans\nYou can edit a backup plan's name and description, change its schedule, and delete it when it is no longer needed.\nPrerequisites\n\nA backup plan is created, as described in Creating backup plans.\n\nTo edit a backup plan\n\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, click Edit.\n\nIn the Edit backup plan window, make the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nCommand-line interface\nUse the following command:vinfra service compute backup-plan set [--name <name>] [--description <description>] [--schedule-minute <minutes>]\r\n                                       [--schedule-hour <hours>] [--schedule-day <days>] [--schedule-day-of-week <days-of-week>]\r\n                                       [--schedule-week <weeks>] [--schedule-month <months>] [--schedule-interval <interval>]\r\n                                       [--schedule-disable] [--recovery-points-rotation <amount>] [--disabled] [--enabled]\r\n                                       <backup-plan>\n\n<backup-plan>\n\nBackup plan ID or name\n--name <name>\n\nA new name for the backup plan\n--description <description>\n\nBackup plan description\n--schedule-minute <minutes>\n\nComma-separated list of minutes. Specify '*' to schedule backup every minute.\n--schedule-hour <hours>\n\nComma-separated list of hours. Specify '*' to schedule backup every hour.\n--schedule-day <days>\n\nComma-separated list of days of the month. Specify '*' to schedule backup every day.\n--schedule-day-of-week <days-of-week>\n\nComma-separated list of days of the week. Specify '*' to schedule backup every week day.\n--schedule-week <weeks>\n\nComma-separated list of weeks. Specify '*' to schedule backup every week.\n--schedule-month <months>\n\nComma-separated list of months. Specify '*' to schedule backup every mouth.\n--schedule-interval <interval>\n\nInterval between backups, in hours. You can also specify the following units: h for hours, d for days, and w for weeks. Only one unit can be used at a time.\n--schedule-disable\n\nErase backup schedule.\n--recovery-points-rotation <amount>\n\nAmount of full recovery points to preserve.\n--disabled\n\nDisable backup plan.\n--enabled\n\nEnable backup plan.\n\nFor example, to schedule the backup plan myplan to run every Monday and set the maximum recovery points to 7, run:# vinfra service compute backup-plan set myplan --schedule-day-of-week 0 --recovery-points-rotation 7\n\nTo delete a backup plan\n\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, click Delete.\nIf the backup plan has recovery points, you can delete them along with the backup plan. To do this, select Delete recovery points.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute backup-plan delete <backup-plan>\n\n<backup-plan>\n\nBackup plan ID or name\n\nFor example, to delete the backup plan myplan, run:# vinfra service compute backup-plan delete myplan\n\nSee also\n\nManaging volumes in backup plans\n\nViewing backup plan history\n\nRestoring volumes from backups\n\nRestoring virtual machines from backups\n\nCreating and deleting backups manually",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute backup-plan set [--name <name>] [--description <description>] [--schedule-minute <minutes>]\r\n                                       [--schedule-hour <hours>] [--schedule-day <days>] [--schedule-day-of-week <days-of-week>]\r\n                                       [--schedule-week <weeks>] [--schedule-month <months>] [--schedule-interval <interval>]\r\n                                       [--schedule-disable] [--recovery-points-rotation <amount>] [--disabled] [--enabled]\r\n                                       <backup-plan>\n\n<backup-plan>\n\nBackup plan ID or name\n--name <name>\n\nA new name for the backup plan\n--description <description>\n\nBackup plan description\n--schedule-minute <minutes>\n\nComma-separated list of minutes. Specify '*' to schedule backup every minute.\n--schedule-hour <hours>\n\nComma-separated list of hours. Specify '*' to schedule backup every hour.\n--schedule-day <days>\n\nComma-separated list of days of the month. Specify '*' to schedule backup every day.\n--schedule-day-of-week <days-of-week>\n\nComma-separated list of days of the week. Specify '*' to schedule backup every week day.\n--schedule-week <weeks>\n\nComma-separated list of weeks. Specify '*' to schedule backup every week.\n--schedule-month <months>\n\nComma-separated list of months. Specify '*' to schedule backup every mouth.\n--schedule-interval <interval>\n\nInterval between backups, in hours. You can also specify the following units: h for hours, d for days, and w for weeks. Only one unit can be used at a time.\n--schedule-disable\n\nErase backup schedule.\n--recovery-points-rotation <amount>\n\nAmount of full recovery points to preserve.\n--disabled\n\nDisable backup plan.\n--enabled\n\nEnable backup plan.\n\nFor example, to schedule the backup plan myplan to run every Monday and set the maximum recovery points to 7, run:# vinfra service compute backup-plan set myplan --schedule-day-of-week 0 --recovery-points-rotation 7\n",
                "title": "To edit a backup plan"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute backup-plan delete <backup-plan>\n\n<backup-plan>\n\nBackup plan ID or name\n\nFor example, to delete the backup plan myplan, run:# vinfra service compute backup-plan delete myplan\n",
                "title": "To delete a backup plan"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, click Edit.\n\nIn the Edit backup plan window, make the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n",
                "title": "To edit a backup plan"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Backup plans tab, click the required backup plan.\nOn the plan right pane, click Delete.\nIf the backup plan has recovery points, you can delete them along with the backup plan. To do this, select Delete recovery points.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a backup plan"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/editing-and-deleting-backup-plans.html"
    },
    {
        "title": "High availability for services",
        "content": "High availability for services\nVirtuozzo Hybrid Infrastructure provides additional high availability for the following services:\n\n\r\n                Admin panel. If the management node fails or becomes unreachable over the network, an admin panel instance on another node takes over the panel\u00e2\u0080\u0099s service so that it remains accessible at the same dedicated IP address. The relocation of the service can take several minutes. Admin panel HA is enabled manually along with management node HA.\r\n            \nVirtual machines. If a compute node fails or becomes unreachable over the network, virtual machines hosted on it are evacuated to other healthy compute nodes based on their free resources. The compute cluster can survive the failure of only one node. By default, high availability for virtual machines is enabled automatically after creating the compute cluster and can be disabled manually, if required.\niSCSI service. If the active path to volumes exported via iSCSI fails (for example, a storage node with active iSCSI targets fails or becomes unreachable over the network), the active path is rerouted via targets located on healthy nodes. Volumes exported via iSCSI remain accessible as long as there is at least one path to them.\nS3 service. If an S3 node fails or becomes unreachable over the network, the name server and object server components hosted on it are automatically balanced and migrated between other S3 nodes. S3 gateways are not automatically migrated; their high availability is based on load balancing. We recommend using an external load balancer to balance traffic between S3 nodes with gateways. High availability for the S3 service is enabled automatically after enabling management node HA and creating an S3 cluster from three or more nodes. The S3 cluster of three nodes may lose one node and remain operational.\nBackup Gateway service. If a node included in the Backup Gateway cluster fails or becomes unreachable over the network, other nodes in the Backup Gateway cluster continue to provide access to the chosen storage backend. Backup gateways are not automatically migrated; their high availability is based on the DNS records. You need to maintain the DNS records manually when adding or removing backup gateways. High availability for the backup gateway is enabled automatically after creating a Backup Gateway cluster from two or more nodes. Access to the storage backend remains until at least one node in the Backup Gateway cluster is healthy.\nNFS shares. If a storage node fails or becomes unreachable over the network, the NFS volumes located on it are migrated between other NFS nodes. High availability for NFS volumes on a storage node is enabled automatically after creating an NFS cluster.\n\nSee also\n\nHigh availability and the compute cluster\n\nEnabling management node high availability\n\nConfiguring virtual machine high availability",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/ha-for-services.html"
    },
    {
        "title": "Monitoring",
        "content": "Monitoring\nVirtuozzo Hybrid Infrastructure uses the Prometheus monitoring system to monitor performance and availability of the storage cluster, infrastructure nodes, and the deployed services. It also generates alerts, which you can configure to be sent as notifications via email.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring.html"
    },
    {
        "title": "Concepts and features",
        "content": "Concepts and features\nThis section explains key concepts and features of Virtuozzo Hybrid Infrastructure. This information could be useful for understanding how the product works.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/concepts-and-features.html"
    },
    {
        "title": "Creating VPN connections",
        "content": "Creating VPN connections\nPrerequisites\n\nYou have a virtual router created, as described in Managing virtual routers.\nThe virtual router connects the physical network with virtual networks that you want to be exposed.\nNetworks that will be connected via a VPN tunnel must have non-overlapping IP ranges.\n\n[For Virtuozzo Hybrid Infrastructure 5.4 Update 1 and earlier versions] If a virtual machine has a floating IP address assigned to its private network interface, configure static routes of a virtual router, for the VM traffic to be routed through a VPN tunnel.\n\nIn this case, you need to add static routes to your virtual router for remote subnets that you want to access via a VPN tunnel. The next hop IP address will be the IP address of the internal SNAT router interface. To find out this IP address, run:\n# openstack --insecure port list --device-id <router_id> --device-owner network:router_centralized_snat -c fixed_ips\r\n+-------------------------------------------------------------------------------+\r\n| Fixed IP Addresses                                                            |\r\n+-------------------------------------------------------------------------------+\r\n| ip_address='192.168.128.69', subnet_id='c33e75f3-8ede-4899-a6cb-6f9d87a61714' |\r\n+-------------------------------------------------------------------------------+\n\nIn this example, 192.168.128.69 is the IP address of the internal SNAT router interface. A router, however, may have multiple internal SNAT router interfaces. You can specify any of them as the next hop IP address. For more details on adding static routes, refer to Managing static routes.\n\nTo create a VPN connection\n\nOn the VPN screen, click Create VPN.\n\nOn the Configure IKE step, specify parameters for the IKE policy that will be used to establish a VPN connection. You can choose to use an existing IKE policy or create a new one. For the new IKE policy, do the following:\n\nSpecify a custom name for the IKE policy.\nSpecify the key lifetime, in seconds, that will define the rekeying interval. The IKE key lifetime must be greater than that of the IPsec key.\nSelect the authentication algorithm that will be used to verify the data integrity and authenticity.\nSelect the encryption algorithm that will be used to ensure that data is not viewable while in transit.\nSelect the IKE version 1 or 2. Version 1 has limitations, for example, it does not support multiple subnets.\nSelect the Diffie-Hellman (DH) group that will be used to build the encryption key for the key exchange process. Higher group numbers are more secure but require additional time for the key to compute.\nClick Next.\n\nOn the Configure IPsec step, specify parameters for the IPsec policy that will be used to encrypt the VPN traffic. You can choose to use an existing IPsec policy or create a new one. For the new IPsec policy, do the following:\n\nSpecify a custom name for the IPsec policy.\nSpecify the key lifetime, in seconds, that will define the rekeying interval. The IPsec key lifetime must not be greater than that of the IKE key.\nSelect the authentication algorithm that will be used to verify the data integrity and authenticity.\nSelect the encryption algorithm that will be used to ensure that data is not viewable while in transit.\nSelect the Diffie-Hellman (DH) group that will be used to build the encryption key for the key exchange process. Higher group numbers are more secure but require additional time for the key to compute.\nClick Next.\n\nOn the Create endpoint groups step, select a virtual router and specify local and remote subnets that will be connected by the VPN tunnel. You can choose to use existing local and remote endpoints, or create new ones. For the new endpoints, do the following:\n\nSpecify a custom name for the local endpoint, and then select local subnets.\nSpecify a custom name for the remote endpoint, and then add remote subnets in the CIDR format.\nClick Next.\n\nOn the Configure VPN step, specify parameters to establish the VPN connection with a remote gateway:\n\nSpecify a custom name for the VPN connection.\nSpecify the public IPv4 address of the remote gateway, that is, peer IP address.\nGenerate the pre-shared key that will be used for the peer authentication.\n\nIf necessary, you can also configure additional settings by selecting Advanced settings and specifying the following parameters:\n\nThe peer ID for authentication and the mode for establishing a connection.\nThe Dead Peer Detection (DPD) policy, interval, and timeout, in seconds.\n\nClick Next.\n\nOn the Summary step, review the configuration, and then click Create.\n\nWhen the VPN connection is created, its status will change from \"Pending creation\" to \"Down\". The connection will become active once the VPN tunnel is configured by the other VPN party and the IKE authorization is successful.\n\nThe IKE and IPsec configuration must match for both communicating parties. Otherwise, the VPN connection between them will not be established.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-vpn-connections.html"
    },
    {
        "title": "Setting up the benchmark for S3",
        "content": "Setting up the benchmark for S3\nTo set up the benchmark for the S3 resource, install and configure the GOSBench tool.\nPrerequisites\n\nThe load generator VMs are deployed, as described in Deploying virtual machines with load generators.\nThe target storage is created, as described in Creating the target storage.\n\nTo install and configure GOSBench\n\nDownload and extract the tool from GitHub on each load generator and the coordinator node:# curl -OL https://github.com/mulbc/gosbench/releases/download/v0.4/gosbench_0.4_Linux_x86_64.tar.gz\r\n# tar -xzf gosbench_0.4_Linux_x86_64.tar.gz\n\nOn the coordinator node, create the file gosbench_script.yaml with  the following configuration:s3_config:\r\n  - access_key: <ACCESS_KEY>\r\n    secret_key: <SECRET_KEY>\r\n    region: eu-central-1\r\n    endpoint: <S3_ENDPOINT_URL>\r\n    skipSSLverify: true\r\n\r\ngrafana_config:\r\n  endpoint: https://<GRAFANA_ENDPOINT>\r\n  username: admin\r\n  password: <ADMIN_PASSWORD>\r\n\r\ntests:\r\n  - name: write test\r\n    read_weight: 0\r\n    existing_read_weight: 0\r\n    write_weight: 100\r\n    delete_weight: 0\r\n    list_weight: 0\r\n    objects:\r\n      size_min: 1\r\n      size_max: 100000\r\n      part_size: 0\r\n      size_distribution: random\r\n      unit: KB\r\n      number_min: 10\r\n      number_max: 10\r\n      number_distribution: constant\r\n    buckets:\r\n      number_min: 1\r\n      number_max: 10\r\n      number_distribution: constant\r\n    bucket_prefix: 1255gosbenchobject_\r\n    prefix: obj\r\n    stop_with_runtime: 900s\r\n    stop_with_ops:\r\n    workers: <NUMBER_OF_WORKERS>\r\n    workers_share_buckets: True\r\n    parallel_clients: 3\r\n    clean_after: True\r\n\r\n  - name: read test\r\n    read_weight: 100\r\n    existing_read_weight: 0\r\n    write_weight: 0\r\n    delete_weight: 0\r\n    list_weight: 0\r\n    objects:\r\n      size_min: 1\r\n      size_max: 100000\r\n      part_size: 0\r\n      size_distribution: random\r\n      unit: KB\r\n      number_min: 10\r\n      number_max: 10\r\n      number_distribution: constant\r\n    buckets:\r\n      number_min: 1\r\n      number_max: 10\r\n      number_distribution: constant\r\n    bucket_prefix: 1255gosbenchobject_\r\n    prefix: obj\r\n    stop_with_runtime: 900s\r\n    stop_with_ops:\r\n    workers: <NUMBER_OF_WORKERS>\r\n    workers_share_buckets: True\r\n    parallel_clients: 3\r\n    clean_after: True\n\nUpdate the required fields accordingly, in particular, these fields:\n\naccess_key is the S3 access key to access the resource.\nsecret_key is the S3 secret key to access the resource,\nendpoint in the s3_config section is the S3 endpoint URL to access the resource.\nendpoint in the grafana_config section is the Grafana dashboard URL, which is https://<admin_panel_IP>:8888/grafana/d/dashboard-directory-en-US/.\npassword is the Grafana administrator password.\nworkers is the number of load generators. Note that there are multiple occurrences of this parameter that need to be set to the same value.\n\nFor more details, refer to the GOSBench documentation.\nSee also\n\nSetting up the benchmark for NFS and iSCSI\n\nWhat's next\n\nRunning the benchmark for S3",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-benchmark-for-s3.html"
    },
    {
        "title": "Creating and deleting security groups",
        "content": "Creating and deleting security groups\nLimitations\n\nYou cannot delete the default security group.\nYou cannot delete a security group if it is assigned to a VM.\n\nTo create a security group\n\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click Add security group.\n\nIn the Add security group window, specify a name and description for the group, and then click Add.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nBy default, the new security group will deny all incoming traffic and allow only outgoing traffic to assigned virtual machines.\n\nCommand-line interface\nUse the following command:vinfra service compute security-group create [--description <description>]\r\n                                             <name>\n\n--description <description>\n\nSecurity group description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n<name>\n\nSecurity group name\n\nFor example, to create a security group mygroup, run:# vinfra service compute security-group create mygroup\r\n+----------------------+---------------------------------------------------+\r\n| Field                | Value                                             |\r\n+----------------------+---------------------------------------------------+\r\n| description          |                                                   |\r\n| id                   | 12e6b260-0b61-4551-8168-3e59602a2433              |\r\n| name                 | mygroup                                           |\r\n| project_id           | e215189c0472482f93e71d10e1245253                  |\r\n| security_group_rules | - description: null                               |\r\n|                      |   direction: egress                               |\r\n|                      |   ethertype: IPv4                                 |\r\n|                      |   id: ce854e2b-537f-4618-bea9-e9ec3d8616ac        |\r\n|                      |   port_range_max: null                            |\r\n|                      |   port_range_min: null                            |\r\n|                      |   project_id: e215189c0472482f93e71d10e1245253    |\r\n|                      |   protocol: null                                  |\r\n|                      |   remote_group_id: null                           |\r\n|                      |   remote_ip_prefix: null                          |\r\n|                      |   security_group_id: 12e6b260-0b61-4551-8168<...> |\r\n|                      | - description: null                               |\r\n|                      |   direction: egress                               |\r\n|                      |   ethertype: IPv6                                 |\r\n|                      |   id: a7c65861-df3d-47f2-bec3-089747141936        |\r\n|                      |   port_range_max: null                            |\r\n|                      |   port_range_min: null                            |\r\n|                      |   project_id: e215189c0472482f93e71d10e1245253    |\r\n|                      |   protocol: null                                  |\r\n|                      |   remote_group_id: null                           |\r\n|                      |   remote_ip_prefix: null                          |\r\n|                      |   security_group_id: 12e6b260-0b61-4551-8168<...> |\r\n| tags                 | []                                                |\r\n+----------------------+---------------------------------------------------+\nThe created security group will appear in the vinfra service compute security-group list output:# vinfra service compute security-group list -c id -c name\r\n+--------------------------------------+---------+\r\n| id                                   | name    |\r\n+--------------------------------------+---------+\r\n| 062f75cf-abc0-419d-bb1a-92989ad9383f | default |\r\n| 12e6b260-0b61-4551-8168-3e59602a2433 | mygroup |\r\n+--------------------------------------+---------+\r\n\n\nTo delete a security group\n\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click the required security group.\nOn the group right pane, click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute security-group delete <security-group>\n\n<security-group>\n\nSecurity group name or ID\n\nFor example, to delete the security group mygroup, run:# vinfra service compute security-group delete mygroup\n\nSee also\n\nChanging security group assignment\n\nWhat's next\n\nManaging security group rules",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute security-group create [--description <description>]\r\n                                             <name>\n\n--description <description>\n\n\nSecurity group description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n<name>\n\nSecurity group name\n\nFor example, to create a security group mygroup, run:# vinfra service compute security-group create mygroup\r\n+----------------------+---------------------------------------------------+\r\n| Field                | Value                                             |\r\n+----------------------+---------------------------------------------------+\r\n| description          |                                                   |\r\n| id                   | 12e6b260-0b61-4551-8168-3e59602a2433              |\r\n| name                 | mygroup                                           |\r\n| project_id           | e215189c0472482f93e71d10e1245253                  |\r\n| security_group_rules | - description: null                               |\r\n|                      |   direction: egress                               |\r\n|                      |   ethertype: IPv4                                 |\r\n|                      |   id: ce854e2b-537f-4618-bea9-e9ec3d8616ac        |\r\n|                      |   port_range_max: null                            |\r\n|                      |   port_range_min: null                            |\r\n|                      |   project_id: e215189c0472482f93e71d10e1245253    |\r\n|                      |   protocol: null                                  |\r\n|                      |   remote_group_id: null                           |\r\n|                      |   remote_ip_prefix: null                          |\r\n|                      |   security_group_id: 12e6b260-0b61-4551-8168<...> |\r\n|                      | - description: null                               |\r\n|                      |   direction: egress                               |\r\n|                      |   ethertype: IPv6                                 |\r\n|                      |   id: a7c65861-df3d-47f2-bec3-089747141936        |\r\n|                      |   port_range_max: null                            |\r\n|                      |   port_range_min: null                            |\r\n|                      |   project_id: e215189c0472482f93e71d10e1245253    |\r\n|                      |   protocol: null                                  |\r\n|                      |   remote_group_id: null                           |\r\n|                      |   remote_ip_prefix: null                          |\r\n|                      |   security_group_id: 12e6b260-0b61-4551-8168<...> |\r\n| tags                 | []                                                |\r\n+----------------------+---------------------------------------------------+\nThe created security group will appear in the vinfra service compute security-group list output:# vinfra service compute security-group list -c id -c name\r\n+--------------------------------------+---------+\r\n| id                                   | name    |\r\n+--------------------------------------+---------+\r\n| 062f75cf-abc0-419d-bb1a-92989ad9383f | default |\r\n| 12e6b260-0b61-4551-8168-3e59602a2433 | mygroup |\r\n+--------------------------------------+---------+\r\n\n",
                "title": "To create a security group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute security-group delete <security-group>\n\n<security-group>\n\nSecurity group name or ID\n\nFor example, to delete the security group mygroup, run:# vinfra service compute security-group delete mygroup\n",
                "title": "To delete a security group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click Add security group.\n\nIn the Add security group window, specify a name and description for the group, and then click Add.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n\n\n\n\nBy default, the new security group will deny all incoming traffic and allow only outgoing traffic to assigned virtual machines.\n",
                "title": "To create a security group"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click the required security group.\nOn the group right pane, click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a security group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-and-deleting-security-groups.html"
    },
    {
        "title": "Creating virtIO disks for virtual machines",
        "content": "Creating virtIO disks for virtual machines\nTo improve I/O performance of virtual machines, you can use virtIO disks with them. By default, virtual machines are created with disks attached to the SCSI bus, which cannot be changed later.\nYou can create a volume for a VM and attach this volume to the virtIO bus during the VM deployment via the vinfra tool. This method works for creating boot volumes from both ISO images and templates (QCOW2). You can also use it to attach non-boot volumes. Note that you need to run the vinfra command each time you create a virtual machine.\nAlternatively, it is possible to apply the virtIO bus property to an image via the OpenStack command-line tool. This property allows you to create multiple VMs from configured images in the command-line interface, as well as in the admin and self-service panels. However, it only works for templates. \nPrerequisites\n\nYou have an image uploaded to the compute cluster, as described in Preparing boot media for virtual machines.\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo create a virtual machine with virtIO volume\nUse the --volume bus=virtio option with the vinfra service compute server create command.\nExample 1. To create a VM from the mytemplate QCOW2 image, run:# vinfra service compute server create myvm1 --network id=private,fixed-ip=192.168.128.100 --flavor medium\\\r\n--volume source=image,id=mytemplate,bus=virtio,size=100\nExample 2. To create a VM from the myiso ISO image, run:# vinfra service compute server create myvm2 --network id=private,fixed-ip=192.168.128.100 --flavor medium\\\r\n--volume source=blank,size=100,bus=virtio,boot-index=0,type=disk \\\r\n--volume source=image,id=myiso,size=5,boot-index=1,type=cdrom\nAfter the VM is created, all volumes that you add to it will be attached to the virtIO bus.\nTo create a virtual machine with virtIO template\n\nApply the virtIO bus property to a template. For example:# openstack --insecure image set mytemplate --property hw_disk_bus=virtio\n\nCreate a volume from the virtIO template. For example:# openstack --insecure volume create --image=mytemplate --size=10 myvolume\n\nCreate a VM from the new volume. For example:# openstack --insecure server create myvm --volume=myvolume --flavor small --network public\n\nAfter the VM is created, all volumes that you add to it will be attached to the virtIO bus.\nSee also\n\nCreating virtual machines\n\nConfiguring virtual machine volumes",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtio-disks-for-virtual-machines.html"
    },
    {
        "title": "Deleting S3 users in WHMCS",
        "content": "Deleting S3 users in WHMCS\nYou can delete users with the ostor-users service and parameter emailAddress specifying the user email address. WHMCS removes the user from S3 cluster when you click Delete User. Create a file S3_deleteUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_delClientNote.php');\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Delete s3 user.\r\nfunction S3_deleteUser($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Get s3 user id.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'],\r\n        \"GET\"\r\n    );\r\n\r\n    // Delete s3 user.\r\n    S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'],\r\n        \"DELETE\"\r\n    );\r\n\r\n    // Delete note with the s3 access key and s3 secret.\r\n    S3_delClientNote(\r\n        $s3_whmcs['userid'],\r\n        $s3_config['whmcs_username'],\r\n        $s3_client['UserId'],\r\n        \"\"\r\n    );\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_deleteUser($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-s3-users-in-whmcs.html"
    },
    {
        "title": "2.1. Example Overview\u00c2\u00b6",
        "content": "2.1. Example Overview | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n2.1. Example Overview\u00c2\u00b6\nIn this integration guide, our goal will be to explain how to integrate Leostream with Virtuozzo Hybrid Infrastructure. We will be using a Windows 2019 image as a master image/blueprint to create desktops on the VDI pool. We will configure a basic pool; we\u00e2\u0080\u0099ll define the concept of pools later. This pool will be in charge of automatically provisioning virtual desktops in order to meet the demand (users logging in to the Gateway). We will also define the minimum/maximum number of virtual desktops our pool will be able to deliver. Leostream, will also be configured to use Active Directory as an authentication method to grant access to our desktop pool resources, every time an Active Directory user logs in to the gateway, it will be forwarded to the Leostream Connection Broker, if the user is a valid AD user, they will be offered a floating desktop (roaming profiles will be used) from the available desktops in the pool. Every time the user logs out from the virtual desktop, the desktop will be freed and offered to another user on login, if there are not enough resources our Leostream Connection Broker will provision them until it hits the provisioning limit.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-leostream/example-overview.html"
    },
    {
        "title": "No redundancy",
        "content": "No redundancy\n\nDanger of data loss!\n\nWithout redundancy, singular chunks are stored on failure domains, one per failure domain. If the node or disk fails, the data may be lost. Having no redundancy is highly not recommended no matter the scenario, unless you only want to evaluate Virtuozzo Hybrid Infrastructure on a single server.\nSee also\n\nRedundancy by replication\n\nRedundancy by erasure coding\n\nRedundancy modes\n\nFailure domains\n\nStorage tiers\n\n\u00d0\u00a1luster rebuilding",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/no-redundancy.html"
    },
    {
        "title": "About S3 clusters",
        "content": "About S3 clusters\nVirtuozzo Hybrid Infrastructure allows you to export cluster disk space to customers in the form of an S3-like object-based storage.\nVirtuozzo Hybrid Infrastructure is implemented as an Amazon S3-like API, which is one of the most common object storage APIs. End users can work with Virtuozzo Hybrid Infrastructure as they work with Amazon S3. You can use the usual applications for S3 and continue working with them after the data migration from Amazon S3 to Virtuozzo Hybrid Infrastructure.\nMore details on S3 clusters are provided in the Administrator Guide.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/about-s3-clusters.html"
    },
    {
        "title": "5.3. Package Dependencies\u00c2\u00b6",
        "content": "5.3. Package Dependencies | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n5.3. Package Dependencies\u00c2\u00b6\nRefer to the official documentation: https://doc.bitninja.io/docs/Installation/system_requirements#package-dependencies.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/bitninja-agent-requirements/package-dependencies.html"
    },
    {
        "title": "Configuring Kubernetes load balancers",
        "content": "Configuring Kubernetes load balancers\nKubernetes clusters have two types of load balancers:\n\nThe API load balancer is created when the Kubernetes master node has high availability enabled and is used by the Kubernetes API.\nThe external load balancer is created by Kubernetes users and used by Kubernetes applications.\n\nBy default, these two load balancers use the preconfigured flavor that makes the load balancing service highly available.\nAfter updating the load balancer flavors, the changes will be applied only in new Kubernetes clusters. Existing Kubernetes clusters will retain their previous parameters.\n\nTo improve the stability of Kubernetes clusters, it is highly recommended to select a load balancer flavor that provides high availability.\n\nPrerequisites\n\nA custom load balancer flavor is created, as described in Creating custom load balancer flavors.\n\nTo change the load balancer flavor\nUse the following command:vinfra service compute k8saas defaults set --labels octavia_api_lb_flavor=<mode>,octavia_default_flavor=<mode> <version>\n\n--labels <key1=value1,key2=value2,key3=value3...>\n\nArbitrary labels in the form of key=value pairs to associate with a cluster:\n\noctavia_api_lb_flavor=<mode>: set the load balancer flavor for Kubernetes master nodes:\n\nSINGLE: create only one load balancer for Kubernetes master nodes\nACTIVE_STANDBY: create two load balancers that will work in the Active/Standby mode\n\noctavia_default_flavor=<mode>: set the load balancer flavor for Kubernetes applications:\n\nSINGLE: create only one load balancer for Kubernetes applications\nACTIVE_STANDBY: create two load balancers that will work in the Active/Standby mode\n\n<version>\n\nKubernetes version to apply new defaults for.\n\nFor example, to create only one load balancer for highly available Kubernetes master nodes and apply this change for all of the supported Kubernetes versions, run:# vinfra service compute k8saas defaults set --labels octavia_default_flavor=SINGLE\nTo set this flavor only for version 1.24.3, append the version number to the command:# vinfra service compute k8saas defaults set --labels octavia_default_flavor=SINGLE v1.24.3\nSee also\n\nConfiguring the Kubernetes system volume\n\nChanging Kubernetes node flavors\n\nConfiguring Kubernetes DNS and discovery parameters",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-kubernetes-load-balancers.html"
    },
    {
        "title": "Authorizing NFS export users via LDAP",
        "content": "Authorizing NFS export users via LDAP\n\nThis feature is experimental and not intended for use in production environments.\n\nBy configuring access to a user directory via LDAP, you can control which users can access which NFS exports. \nPrerequisites\n\nNFS exports are created, as described in Creating NFS exports.\nAuthentication via Kerberos is enabled, as instructed in Authenticating NFS share users via Kerberos.\nA directory of user accounts with desired NFS access parameters is prepared.\n\nTo configure access to an LDAP server\n\nGo to the Storage services > NFS > Settings tab, and then click LDAP.\n\nTurn on the toggle switch LDAP authorization, and then specify the following information:\n\nIn Address, specify the IP address of the LDAP server.\nIn Base DN, specify the distinguished name of the search starting point.\nIn Bind DN and Bind password, specify the credentials of an LDAP authentication database user.\n\nClick Save to enable access to the LDAP server.\n\nSee also\n\nManaging NFS exports",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/authorizing-nfs-users-via-ldap.html"
    },
    {
        "title": "Querying user limits in WHMCS",
        "content": "Querying user limits in WHMCS\nYou can display the current limits with the ostor-limits service and parameter emailAddress specifying the email address. WHMCS displays the user limits in S3 cluster when you click the Get button. Create a file S3_getLimitsForUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Get s3 user limits.\r\nfunction S3_getLimitsForUser($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Get s3 user limits.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-limits&emailAddress=\" . $s3_whmcs['email'],\r\n        \"GET\"\r\n    );\r\n\r\n    // Store s3 result.\r\n    $_SESSION['s3_limits_user'] = $s3_client;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_getLimitsForUser($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-user-limits-in-whmcs.html"
    },
    {
        "title": "Replication management",
        "content": "Replication management\nThis sections describes how to manage S3 cross-region replication (CRR) that enables copying of objects across S3 buckets in different regions.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/replication-management.html"
    },
    {
        "title": "Setting memory parameters per cluster",
        "content": "Setting memory parameters per cluster\nTo change per-cluster memory parameters\nUse the following command:vinfra memory-policy vstorage-services per-cluster change [--guarantee <guarantee>] [--swap <swap>]\r\n                                                          [--cache-ratio <cache-ratio> --cache-minimum <cache-minimum>\r\n                                                          --cache-maximum <cache-maximum>]\r\n\n\n--guarantee <guarantee>\n\nGuarantee, in bytes\n--swap <swap>\n\nSwap size, in bytes, or -1 if unlimited\n--cache-ratio <cache-ratio>\n\nCache ratio from 0 to 1 inclusive\n--cache-minimum <cache-minimum>\n\nMinimum cache, in bytes\n--cache-maximum <cache-maximum>\n\nMaximum cache, in bytes\n\nFor example, to set the storage memory parameters for all nodes in the storage cluster, run:# vinfra memory-policy vstorage-services per-cluster change --guarantee 8796093022208 --swap 1099511627776 \\\r\n--cache-ratio 0.5 --cache-minimum 1099511627776 --cache-maximum 3298534883328\nThis command sets the memory parameters as follows:\n\nThe memory guarantee to 8 GB\nThe swap size to 1 GB\nThe page cache limits: the minimum to 1 GB, the maximum to 3 GB, and the cache ratio to 0.5\n\nYou can view the updated per-cluster memory parameters in the vinfra memory-policy vstorage-services per-cluster show output:# vinfra memory-policy vstorage-services per-cluster show\r\n+-----------+------------------------+\r\n| Field     | Value                  |\r\n+-----------+------------------------+\r\n| cache     | maximum: 3298534883328 |\r\n|           | minimum: 1099511627776 |\r\n|           | ratio: 0.5             |\r\n| guarantee | 8796093022208          |\r\n| swap      | 1099511627776          |\r\n+-----------+------------------------+\r\n\nTo reset per-cluster parameters to default\nUse the following command:vinfra memory-policy vstorage-services per-cluster reset [--guarantee] [--swap] [--cache]\r\n\n\n--guarantee\n\nReset only the guarantee.\n--swap\n\nReset only the swap size.\n--cache\n\nReset only cache values.\n\nFor example, to reset the manually configured page cache limits to default for all nodes in the storage cluster, run:# vinfra memory-policy vstorage-services per-cluster reset --cache\nSee also\n\nSetting memory parameters per node",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-memory-parameters-per-cluster.html"
    },
    {
        "title": "Attaching network interfaces to virtual machines",
        "content": "Attaching network interfaces to virtual machinesPOST /servers/{server_id}/os-interface\r\n\nCreate a network interface and attach it to the given virtual machine.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=create-interface-detail#create-interface\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\ninterfaceAttachmentEx\n\nbody\nstring\nSpecify the interfaceAttachmentEx action in the request body.\n\nport_id (Optional)\nbody\nstring\nThe ID of the port for which you want to create an interface.  The net_id\r\nand port_id parameters are mutually exclusive.  If you do not specify the\r\nport_id parameter, the OpenStack Networking API v2.0 allocates a port and\r\ncreates an interface for it on the network.\n\nnet_id (Optional)\nbody\nstring\nThe ID of the network for which you want to create a port interface.  The net_id\r\nand port_id parameters are mutually exclusive.  If you do not specify the\r\nnet_id parameter, the OpenStack Networking API v2.0 uses the network information\r\ncache that is associated with the instance.\n\nfixed_ips (Optional)\nbody\narray\nFixed IP addresses.  If you request a specific fixed IP address without\r\na network\u00e2\u0080\u0099s uuid or net_id, the request returns a Bad Request (400) \r\nresponse code.\n\nip_address (Optional)\nbody\nstring\nThe IP address.\n\nip_version (Optional)\nbody\ninteger\nThe IP protocol version. Valid value is 4 or\r\n6. Default is 4.\n\ntag (Optional)\nbody\nstring\n\nA device role tag that can be applied to a network interface when attaching\r\nit to the VM. The guest OS of a server that has devices tagged in this\r\nmanner can access hardware metadata about the tagged devices from the\r\nmetadata API and on the config\r\ndrive, if enabled.\nNew in version 2.49\n\nExample 1\nCreate a network interface in the specified network, assign the IP address automatically from the IPv4 subnet, and attach it to a VM with the specified ID.# curl -ks -H 'Content-Type: application/json' -H 'X-OpenStack-Nova-API-Version: 2.67' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"interfaceAttachment\": {\r\n    \"net_id\": \"a1d8d6ae-c89d-4307-8a0c-3cc2ee55d7e3\",\r\n    \"fixed_ips\": [{\"ip_version\": 4}],\r\n    \"port_security_enabled\": true,\r\n    \"security_groups\": [\"5e2db579-c3a0-468b-aecd-b7930bf1507e\"]\r\n  }\r\n}' https://<node_IP_addr>:8774/v2.1/b906404c55bb44729da99987536ac5bc/servers/0785ee80-1eca-426b-b8c4-5b499fc7f614/os-interface\r\n\nExample 2\nCreate a network interface in the specified network, assign the IP address manually, and attach it to a VM with the specified ID.# curl -ks -H 'Content-Type: application/json' -H 'X-OpenStack-Nova-API-Version: 2.67' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"interfaceAttachment\": {\r\n    \"net_id\": \"0bb6b7a7-da8d-432c-b8d5-12139f7924d1\",\r\n    \"fixed_ips\": [{\"ip_address\": \"192.168.128.20\"}],\r\n    \"port_security_enabled\": true,\r\n    \"security_groups\": [\"5e2db579-c3a0-468b-aecd-b7930bf1507e\"]\r\n  }\r\n}' https://<node_IP_addr>:8774/v2.1/b906404c55bb44729da99987536ac5bc/servers/0785ee80-1eca-426b-b8c4-5b499fc7f614/os-interface\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ninterfaceAttachment\n\nbody\nobject\nThe interface attachment.\n\nport_state\n\nbody\nstring\nThe port state.\n\nfixed_ips\n\nbody\narray\nFixed IP addresses with subnet IDs.\n\nsubnet_id\n\nbody\nstring\nThe UUID of the subnet.\n\nip_address\n\nbody\nstring\nThe IP address.\n\nport_id\n\nbody\nstring\nThe port ID.\n\nnet_id\n\nbody\nstring\nThe network ID.\n\nmac_addr\n\nbody\nstring\nThe MAC address.\n\ntag\n\nbody\nstring\n\nThe device tag applied to the virtual network interface or null.\nNew in version 2.70\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n501 - Not Implemented\n\nThe server either does not recognize the request method, or it lacks the ability to fulfill the request.\n\nExample{\r\n  \"interfaceAttachment\": {\r\n    \"port_state\": \"ACTIVE\",\r\n    \"fixed_ips\": [\r\n      {\r\n        \"subnet_id\": \"d52aa9f4-6a4b-4268-a71d-1a50f9b60aa9\", \r\n        \"ip_address\": \"10.136.18.138\"\r\n      }\r\n    ],\r\n    \"port_id\": \"bfc3228d-384e-4864-a583-54157225a4ef\",\r\n    \"net_id\": \"a1d8d6ae-c89d-4307-8a0c-3cc2ee55d7e3\",\r\n    \"mac_addr\": \"fa:16:3e:3b:0b:c3\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/attaching-network-interfaces-to-virtual-machines.html"
    },
    {
        "title": "How to mirror the Virtuozzo Hybrid Infrastructure repository",
        "content": "How to mirror the Virtuozzo Hybrid Infrastructure repositoryThis guide describes how to deploy an HTTP server that will act as a repository mirror for Virtuozzo Hybrid Infrastructure (VHI). This will allow you to manage VHI clusters without direct Internet access.Creating a virtual machineCreate a virtual machine with the following parameters:OS: CentOS 9 (recommended and tested) or any RPM-based OS that runs on Linux kernel 5.xvCPU: 2RAM: 4 GBStorage: 100 GBAccess to https://repo.virtuozzo.com/Connect to the virtual machine using SSH. We recommend using sudo.Installing prerequisites1. Install the httpd server, createrepo, reposync tools, and the xml editor:1\n# sudo yum install httpd createrepo_c yum-utils xmlstarlet -y\n2. Download and copy these RPM GPG keys to the keys directory /etc/pki/rpm-gpg/:VZLINUX9_GPG_KEYRPM-GPG-KEY-Virtuozzo-93. Import the RPM GPG keys:1\n2\n# sudo rpm --import /etc/pki/rpm-gpg/VZLINUX9_GPG_KEY\n# sudo rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-Virtuozzo-9\nConfiguring the repositoryWe will be using the following variables:<REPO-NAME> is the repository name, for example: hci-6.1<UPGRADE-REPO-NAME> is the name of the upgrade repository, for example: hci-6.2<BUILD-NUMBER> is the build number, for example: 6.1.1-52<REPOMD-BUILD-NUMBER> is the build number that will be displayed in the admin panel, for example: 6.1.1 (52)<MAJOR-BUILD-NUMBER> is the major release version, for example: 6.1<UPGRADE-MAJOR-BUILD-NUMBER> is the version of a major release to upgrade to, for example: 6.2<HTTP-SERVER_IP-OR-DNS_NAME> is the IP address or resolvable DNS name of your mirror server1. Create the directory structure:1\n# sudo mkdir -p /var/www/html/repos/<REPO-NAME>\n2. Create the mirrorlists directory:1\n# sudo mkdir -p /var/www/html/vz-platform/mirrorlists/<MAJOR-BUILD-NUMBER>/\n3. In the mirrorlists directory, create the releases-os.mirrorlist and releases-updates.mirrorlist files with the following content:1\nhttp://<HTTP-SERVER_IP-OR-DNS_NAME>/repos/<REPO-NAME>/\n4. Synchronize the public repository to the directory <REPO-NAME>:4.1. Create the repos directory:1\n# sudo mkdir /root/repos\n4.2. Create the /root/repos/<REPO-NAME>.repo file with the following content:1\n2\n3\n4\n5\n6\n[<REPO-NAME>]\nname=<REPO-NAME>\nbaseurl=http://repo.virtuozzo.com/vz-platform/releases/<MAJOR-BUILD-NUMBER>/x86_64/os/\nenabled=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-Virtuozzo-9\n       file:///etc/pki/rpm-gpg/VZLINUX9_GPG_KEY\n4.3. Synchronize the repository:1\n# sudo reposync --setopt=reposdir=/root/repos --download-metadata --gpgcheck --repoid=<REPO-NAME> -p /var/www/html/repos/<REPO-NAME> --norepopath 2>&1 | tee /root/sync.log\n4.4. Create the repository metadata:1\n# sudo createrepo -q /var/www/html/repos/<REPO-NAME> --distro=\"cpe:/o:virtuozzohci:vz:2,hci-<REPOMD-BUILD-NUMBER>\"\n4.5. Place the release notes file to the repo directory:1\n# sudo curl -s http://repo.virtuozzo.com/vz-platform/releases/<MAJOR-BUILD-NUMBER>/x86_64/os/repodata/release_notes.md -o /var/www/html/repos/<REPO-NAME>/repodata/release_notes.md\n4.6. Inject the Virtuozzo upgrade registry into the system repository metadata (major upgrade only):1\n# sudo xmlstarlet ed -L -N 's=http://linux.duke.edu/metadata/repo' -s \"//s:tags\" -t elem -n hci_registry -i //hci_registry -t attr -n upgrade_mirrorlist -v \"http://repo.virtuozzo.com/vz-platform/mirrorlists/<UPGRADE-MAJOR-BUILD-NUMBER>/releases-os.mirrorlist\" -i //hci_registry -t attr -n release_notes -v \"http://<HTTP-SERVER_IP-OR-DNS_NAME>/repos/<UPGRADE-REPO-NAME>/repodata/release_notes.md\" /var/www/html/repos/<REPO-NAME>/repodata/repomd.xml\n5. Adjust ownership:1\n# sudo chown -R apache:apache /var/www/html/repos\n6. Restart the httpd service:1\n# sudo systemctl restart httpd\nConfiguring DNSWe highly recommend adding a new A record to your own DNS server:1\nrepo.virtuozzo.com A <HTTP-SERVER_IP>\nIf you do not have your own DNS server, you can add the following record to the /etc/hosts file on all Virtuozzo Hybrid Infrastructure servers:1\n<HTTP-SERVER_IP> repo.virtuozzo.com\nUpdating to the next major versionTo update to a new major Virtuozzo Hybrid Infrastructure version, repeat the step Configuring the repository.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/repository-mirror-for-vhi/"
    },
    {
        "title": "Setting up networks",
        "content": "Setting up networks\nBy default, you have two preconfigured networks named Public and Private, according to their type. They can be considered templates, which you can customize to create the desired (recommended) configuration.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-networks.html"
    },
    {
        "title": "Releasing nodes from object storage",
        "content": "Releasing nodes from object storage\nLimitations\n\nWhen the last node in the S3 cluster is removed, the cluster is destroyed and all of the data is deleted.\n\nPrerequisites\n\nThe S3 cluster is created, as described in Creating the S3 cluster.\nThe cluster has enough nodes running name and object servers, as well as gateways left.\n\nTo release a node from the S3 cluster\n\nAdmin panel\n\nGo to the Storage services > S3 > Nodes screen.\nClick a node to release, and then on the node right pane, click Release.\nClick Release in the confirmation window.\n\nCommand-line interface\n\nTo release not the last node from the S3 cluster, run:# vinfra service s3 node release --nodes <nodes>\n\nTo release the last node and destroy the S3 cluster, run:# vinfra service s3 cluster delete [--force]\n\nSee also\n\nSupported Amazon S3 features\n\nMonitoring object storage\n\nAdding nodes to object storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nTo release not the last node from the S3 cluster, run:# vinfra service s3 node release --nodes <nodes>\n\n\nTo release the last node and destroy the S3 cluster, run:# vinfra service s3 cluster delete [--force]\n\n\n",
                "title": "To release a node from the S3 cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > S3 > Nodes screen.\nClick a node to release, and then on the node right pane, click Release.\nClick Release in the confirmation window.\n\n",
                "title": "To release a node from the S3 cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/releasing-s3-nodes.html"
    },
    {
        "title": "Calculating disk health",
        "content": "Calculating disk health\nYou can monitor node disks by using the vstorage-disks-monitor service. This service runs on every  management node and queries chunk server (CS) metrics from the Prometheus service for further analysis.\r\n\r\n vstorage-disks-monitor detects CSes that are not responding and marks them as ill (unresponsive). To avoid degrading the cluster performance, such CSes are fenced from the cluster I/O.\r\n\nThe service also calculates disk health, in percent, based on each metric weight. Weights can be configured in the /etc/disks-monitor/analyzers.yml\r\n\r\nconfiguration file. The service logs are stored in /var/log/disks-monitor/disks-monitor.log.\nThe service can work in two modes:\n\nAs a daemon if you use the vstorage-disks-monitor sidecar command\nAs a tool for listing disk statuses and alerts if you run vstorage-disks-monitor health and vstorage-disks-monitor alerts\n\nYou can disable fencing ill CSes by running the vstorage-disks-monitor sidecar \u2011\u2011fencing.enable command.\nLimitations\n\nDetection of unresponsive disks is disabled in clusters deployed on virtual machines.\n\nWhat's next\n\nTroubleshooting node disks",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/calculating-disk-health.html"
    },
    {
        "title": "Changing the redundancy scheme for S3 data",
        "content": "Changing the redundancy scheme for S3 data\nIf you use redundancy by replication for your S3 data, you can update the chosen redundancy scheme by changing the storage policy. Such a configurable redundancy scheme ensures high scalability and maximum efficiency of object storage. With redundancy by erasure coding, however, changing the redundancy scheme used for S3 data is disabled.\nLimitations\n\nChanging the encoding redundancy scheme is disabled, because it may decrease cluster performance. Re-encoding demands a significant amount of cluster resources for a long period of time. If you still want to change the redundancy scheme, contact the technical support team. \n\nPrerequisites\n\nA clear understanding of the concept Storage policies.\nThe S3 cluster is created, as described in Creating the S3 cluster.\n\nTo change the storage policy for S3 data\n\nAdmin panel\n\n Open the Storage services > S3 > Settings screen, and then click Storage policies.\nIn the Data storage policy section, select the desired storage tier, failure domain, or data redundancy mode.\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra service s3 cluster change [--tier {0,1,2,3}] [--replicas <norm>]\r\n                                 [--failure-domain {0,1,2,3,4}]\r\n\n\n--tier {0,1,2,3}\n\nStorage tier\n\n--replicas <norm>\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n\nFor example, to change the storage tier to 0, the replica scheme to 3, and the failure domain to host, run:# vinfra service s3 cluster change --tier 0 --replicas 3 --failure-domain 1\nThe updated parameters will be shown in the vinfra service s3 show output:# vinfra service s3 show\r\n+-----------------+--------------------------------------------+\r\n| Field           | Value                                      |\r\n+-----------------+--------------------------------------------+\r\n| failure_domain  | 1                                          |\r\n| id              | 0100000000000002                           |\r\n| metadata_policy | failure_domain: 1                          |\r\n|                 | redundancy:                                |\r\n|                 |   m: 1                                     |\r\n|                 |   n: 2                                     |\r\n|                 |   type: raid6                              |\r\n|                 | tier: 1                                    |\r\n| name            | cluster1                                   |\r\n| nodes           | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                 | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n|                 | - id: 8d362265-3009-c548-087d-bad7a466bf1e |\r\n| np              |                                            |\r\n| nusers          | 0                                          |\r\n| protocol        | scheme: https                              |\r\n| redundancy      | m: 3                                       |\r\n|                 | type: raid1                                |\r\n| s3gw_domain     | dns.example.com                            |\r\n| tier            | 0                                          |\r\n+-----------------+--------------------------------------------+\n\nSee also\n\nAdding nodes to object storage\n\nChanging the storage tier for S3 metadata\n\nChanging S3 protocol settings\n\nReleasing nodes from object storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 cluster change [--tier {0,1,2,3}] [--replicas <norm>]\r\n                                 [--failure-domain {0,1,2,3,4}]\r\n\n\n--tier {0,1,2,3}\n\nStorage tier\n\n--replicas <norm>\n\n\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n\nFor example, to change the storage tier to 0, the replica scheme to 3, and the failure domain to host, run:# vinfra service s3 cluster change --tier 0 --replicas 3 --failure-domain 1\nThe updated parameters will be shown in the vinfra service s3 show output:# vinfra service s3 show\r\n+-----------------+--------------------------------------------+\r\n| Field           | Value                                      |\r\n+-----------------+--------------------------------------------+\r\n| failure_domain  | 1                                          |\r\n| id              | 0100000000000002                           |\r\n| metadata_policy | failure_domain: 1                          |\r\n|                 | redundancy:                                |\r\n|                 |   m: 1                                     |\r\n|                 |   n: 2                                     |\r\n|                 |   type: raid6                              |\r\n|                 | tier: 1                                    |\r\n| name            | cluster1                                   |\r\n| nodes           | - id: ca334b1d-20a1-1241-96a5-eb9acadb8ecd |\r\n|                 | - id: ab36b523-91dc-e78d-53a7-88baed44541e |\r\n|                 | - id: 8d362265-3009-c548-087d-bad7a466bf1e |\r\n| np              |                                            |\r\n| nusers          | 0                                          |\r\n| protocol        | scheme: https                              |\r\n| redundancy      | m: 3                                       |\r\n|                 | type: raid1                                |\r\n| s3gw_domain     | dns.example.com                            |\r\n| tier            | 0                                          |\r\n+-----------------+--------------------------------------------+\n",
                "title": "To change the storage policy for S3 data"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n Open the Storage services > S3 > Settings screen, and then click Storage policies.\nIn the Data storage policy section, select the desired storage tier, failure domain, or data redundancy mode.\nClick Save to apply your changes.\n\n",
                "title": "To change the storage policy for S3 data"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-s3-data-redundancy-scheme.html"
    },
    {
        "title": "Creating the storage cluster",
        "content": "Creating the storage cluster\nTo create the storage cluster, do the following:\n\nOpen the Infrastructure > Nodes screen, and then click Create storage cluster.\nIn the Create storage cluster window, enter a name for the cluster. The cluster name may only contain Latin letters (a-z, A-Z), numbers (0-9), and hyphens (\"-\"). It must start with a letter and end with a letter or number.\n\nEnable disk encryption for tiers. You can also enable it later.\n\nSelect one node to create the storage cluster from, and then click Next.\n\nIn the next window, check the default disk configuration. If it is correct, proceed to create the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks.\n\nOnce you finish configuring the disks, click Create, to create the storage cluster.\n\nYou can monitor cluster creation on the Infrastructure > Nodes screen. The creation might take some time, depending on the number of disks to be configured. Once the configuration is complete, the cluster is created.\nTo add more nodes to the storage cluster, do the following:\n\nOn the Infrastructure > Nodes screen, click an unassigned node.\nOn the node right pane, click Join to cluster.\n\nIn the Join node to storage cluster window, check the default disk configuration. If it is correct, proceed to join the node to the storage cluster.\nAlso, you can assign roles to your disks manually or use Disk actions to work with the disks. Alternatively, you can copy the disk configuration from another node by clicking Copy configuration from and selecting the desired node.\n\nOnce you finish configuring the disks, click Join, to add the node to the storage cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/creating-the-storage-cluster.html"
    },
    {
        "title": "Storage cluster best practices",
        "content": "Storage cluster best practices\nUsing similar hardware\nAll cluster nodes must have identical or very similar hardware. Otherwise, the cluster will be imbalanced in terms of performance, because the cluster performance is limited by the slowest node in the cluster. This includes CPU, the amount of RAM, network cards, storage devices, controllers, etc.\nMoreover, it is strongly recommended that:\n\nAll cluster nodes have the same number of disks in each storage tier.\nAll disks assigned to the same storage tier and role are identical in technology and size.\n\nFor example, if you have different HDD disks in the same storage tier, it will lead to unpredictable performance results, because the cluster speed is constrained by the slowest device in the tier. Also, with HDDs of a different size, the physical storage space is used inefficiently, resulting in unused resources.\nUsing different hardware can also be a problem for reasons unrelated to performance. For example, using different CPUs may block migration of virtual machines between nodes.\nUsing the same software version\nWe recommend using the same software version on all cluster nodes, to avoid both performance issues and issues that may occur during maintenance operations such as adding new nodes.\nUsing different storage tiers for different performance goals\nStorage tiers allow you to create groups of disks. As a best practice, it is preferable to group storage devices based on their technology, and group data based on its performance goals. For example, separating data with high-priority access from data with low-priority access helps to optimize data access performance for both of these data types. Generally, it is also advised to separate hot data from cold data, and replicated data from encoded data.\nKeep in mind that switching from replication to erasure coding may degrade storage performance. To avoid changing the redundancy method, we recommend planning it in advance.\nA typical scenario of using storage tiers is to use disks of different technology as capacity devices in the same cluster, for example, HDDs and SSDs. Also note that faster drives should be assigned to higher storage tiers. For details on storage tiers, refer to Storage tiers.\nEnabling NVMe performance\nEnable NVMe performance to boost the performance of very fast devices such as NVMes. For details on enabling and configuring this feature, refer to Configuring NVMe performance.\nExternal caching\nIf your cluster has HDD disks, some workloads might benefit from an additional caching layer of fast devices, such as SSDs or NVMes. Keep in mind that such a configuration is only optimal for some workloads, but when possible, the gained performance completely justifies the added costs. For details on storage cache configuration, refer to Cache configuration.\nEnabling RDMA\nEnabling RDMA reduces network latency and improves overall throughput, especially with random workloads.\nTo enable RDMA, every storage node in your cluster must be equipped with RDMA-capable network cards, and the network switch must support RDMA.\nNote that RDMA must be enabled before the storage cluster is created. For details on enabling RDMA, refer to Enabling RDMA.\nUsing jumbo frames\nIf your cluster has 10+ Gbit/s network adapters, you can configure them to use jumbo frames (9000-byte MTU) on storage network switch ports and node interfaces, to achieve full performance.\nTo test if jumbo frames are working correctly, ping all other node interfaces in the storage network from each node:# ping -s 8972 -M do <HOST>\r\n\nChoosing the cluster size, redundancy, and network bandwidth\nWhen choosing between building one large cluster and multiple small clusters, with an equal number of nodes in total, similar network latency between nodes, and with no other size limits reached (such as the limit on the number of files or chunks), it is always preferable to have a single large cluster. The larger the cluster, the better its performance, efficiency, and redundancy. A large cluster can afford to lose more nodes while still being able to heal itself automatically, avoid cluster degradation, and use more efficient erasure coding schemes.\nWhile choosing between erasure coding schemes, you need to consider multiple factors. With the same number of parity chunks, using a higher number of data chunks increases storage efficiency, but decreases system reliability and performance.\nThe chosen redundancy scheme also affects the number of failure domains in a cluster. The general recommendation is to always plan at least one more failure domain in a cluster than required.\nTo calculate the optimal number of storage disks for each node, you need to consider network bandwidth as an upper limit of the available storage bandwidth each node can provide. The table below shows the maximum number of devices that can be hosted on each node before network bandwidth becomes a bottleneck.\n\nNetwork bandwidth\nMaximum number of disks per node based on device speed\n\n100 MB/s\n300 MB/s\n1000 MB/s\n\n10 GbE\n12\n4\n1\n\n2x10 GbE\n21\n7\n2\n\n25 GbE\n31\n10\n3\n\n2x 25GbE\n53\n17\n5\n\n50GbE\n62\n20\n6\n\n2x 50GbE\n106\n35\n10\n\n100GbE\n125\n41\n12\n\n2x 100GbE\n212\n70\n21\n\nDepending on capabilities of a network switch, its total available bandwidth can be saturated and not allow further scaling after a certain number of nodes is reached. Refer to your network switch specifications to understand if this can become a bottleneck.\nSeparating internal and external networks\nNetwork bandwidth is used not only to deliver data services to network clients, but also for internode communication. Moreover, different data redundancy schemes have different network overhead. For example, when using replication with 3 replicas, serving a certain amount of write requests from applications needs at least double the amount of internal network bandwidth.\nSeparating internal and external data networks helps to increase available bandwidth and avoid bottlenecks.\nVirtual machines performance\nWhen trying to optimize performance of virtual machines, consider the following:\n\nVirtIO disks are typically more performant than disks with the default SCSI bus. Note that VirtIO disks must be thick.\nSnapshots have an impact on performance. If snapshots are not necessary, use volumes without snapshots, to improve performance.\n\nSee also\n\nConfiguration examples\n\nBenchmarking disks\n\nBenchmarking the network\n\nBenchmarking virtual machines\n\nBenchmarking NFS, iSCSI, and S3\n\nTroubleshooting performance issues",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/storage-cluster-best-practices.html"
    },
    {
        "title": "Adding nodes to the NFS cluster",
        "content": "Adding nodes to the NFS cluster\nYou can add more NFS nodes   for high availability and scalability of your file storage.\nPrerequisites\n\nThe NFS cluster is created, as described in Creating the NFS cluster.\n\nTo add nodes to the NFS cluster\n\nAdmin panel\n\nGo to the Storage services > NFS > Nodes screen.\nClick Add node.\nSelect one or more nodes to add to the NFS cluster, and then click Add. \n\nThe nodes will be added to your NFS cluster.\n\nCommand-line interface\nUse the following command:vinfra service nfs node add --nodes <nodes>[:<ip_address>]\n\n--nodes <nodes>[:<ip_address>]\n\nA comma-separated list of node hostnames or IDs, and optionally their IP addresses\n\nFor example, to add the node node002 to the NFS cluster, run:# vinfra service nfs node add --nodes node002\nThe added node will appear in the vinfra service nfs node list output:# vinfra service nfs node list\r\n+--------------------------------------+------------------------+-------------+\r\n| id                                   | ip_address             | has_configd |\r\n+--------------------------------------+------------------------+-------------+\r\n| 923926da-a879-5f56-1b24-1462917ed335 | node001.vstoragedomain | True        |\r\n| ef24c47c-620d-8726-2677-ed94d853de2e | node002.vstoragedomain | True        |\r\n+--------------------------------------+------------------------+-------------+\n\nSee also\n\nMonitoring file storage\n\nSetting up user authentication and authorization\n\nReleasing nodes from the NFS cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs node add --nodes <nodes>[:<ip_address>]\n\n--nodes <nodes>[:<ip_address>]\n\nA comma-separated list of node hostnames or IDs, and optionally their IP addresses\n\nFor example, to add the node node002 to the NFS cluster, run:# vinfra service nfs node add --nodes node002\nThe added node will appear in the vinfra service nfs node list output:# vinfra service nfs node list\r\n+--------------------------------------+------------------------+-------------+\r\n| id                                   | ip_address             | has_configd |\r\n+--------------------------------------+------------------------+-------------+\r\n| 923926da-a879-5f56-1b24-1462917ed335 | node001.vstoragedomain | True        |\r\n| ef24c47c-620d-8726-2677-ed94d853de2e | node002.vstoragedomain | True        |\r\n+--------------------------------------+------------------------+-------------+\n",
                "title": "To add nodes to the NFS cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Nodes screen.\nClick Add node.\nSelect one or more nodes to add to the NFS cluster, and then click Add. \n\nThe nodes will be added to your NFS cluster.\n",
                "title": "To add nodes to the NFS cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-nfs-nodes.html"
    },
    {
        "title": "Attaching an IPMI virtual drive",
        "content": "Attaching an IPMI virtual drive\nTo attach an IPMI virtual drive\n\nDownload IPMIView, if required, and launch it.\nEnsure that the server  is turned on.\n\nIn the IPMIView window, click File > New\u00e2\u0080\u00a6 > System and enter the server\u00e2\u0080\u0099s IPMI IP address. Optionally, change the system name and add a description.\n\nIn the IPMI Domain section, double-click the newly added system name.\n\nAfter the connection is established, navigate to the system KVM console tab and click Launch KVM console.\n\nOn the system Login tab, specify the login ID and password to access the server. Then, click Login.\n\nIn the Java iKVM Viewer window, attach the image to the server as a virtual CD-ROM:\n\nClick Virtual Media > Virtual Storage.\nIn the Virtual Storage window, select ISO File in Local Drive Type, click Open Image, and then select the distribution image from your local machine.\n\nClick OK.\n\nReboot the server by clicking Power Control > Set Power Reset.\n\nWhat's next\n\nInstalling in the attended mode",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/attaching-an-ipmi-virtual-drive.html"
    },
    {
        "title": "Obtaining usage statistics in WHMCS",
        "content": "Obtaining usage statistics in WHMCS\nThis section describes how to obtain usage statistics via in WHMCS for billing or other purposes.\n\r\n                Delete statistics objects after collecting the required data.\r\n            ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/obtaining-usage-statistics-in-whmcs.html"
    },
    {
        "title": "Managing user assignment to domain groups",
        "content": "Managing user assignment to domain groups\nOnce you create a domain group, you can assign users to it. You can choose from users that are added to the infrastructure either manually or automatically from external identity providers. Users assigned to a domain group inherit the role set to this domain group, regardless of their original roles. For example, if you assign a user with the role Project member to a domain group with the role Domain administrator, the user will act as the domain administrator within this domain.\nPrerequisites\n\nDomain groups are created, as described in Creating domain groups.\nUsers are created locally, as outlined in Configuring multitenancy or Managing admin panel users, or added from external identity providers, as described in Adding  identity providers.\n\nTo manage users of a domain group\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a domain group.\nGo to the Domain groups tab, click the ellipsis icon next to the group, and then click Manage users.\nIn the Manage users window, select users to assign to the group, or deselect them to unassign from the group, and then click Save.\n\nCommand-line interface\n\nTo add a user to a domain group, use the following command:vinfra domain group user add --domain <domain> <group> <user>\n\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n<user>\n\nUser ID or name\n\nFor example, to add the user myuser to the domain group users within the domain mydomain, run:# vinfra domain group user add --domain mydomain users myuser\n\nTo remove a user from a domain group, use the following command:vinfra domain group user remove --domain <domain> <group> <user>\n\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n<user>\n\nUser ID or name\n\nFor example, to remove the user myuser from the domain group users within the domain mydomain, run:# vinfra domain group user remove --domain mydomain users myuser\n\nSee also\n\nManaging project assignment to domain groups\n\nEditing and deleting domain groups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nTo add a user to a domain group, use the following command:vinfra domain group user add --domain <domain> <group> <user>\n\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n<user>\n\nUser ID or name\n\nFor example, to add the user myuser to the domain group users within the domain mydomain, run:# vinfra domain group user add --domain mydomain users myuser\n\n\nTo remove a user from a domain group, use the following command:vinfra domain group user remove --domain <domain> <group> <user>\n\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n<user>\n\nUser ID or name\n\nFor example, to remove the user myuser from the domain group users within the domain mydomain, run:# vinfra domain group user remove --domain mydomain users myuser\n\n\n",
                "title": "To manage users of a domain group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a domain group.\nGo to the Domain groups tab, click the ellipsis icon next to the group, and then click Manage users.\nIn the Manage users window, select users to assign to the group, or deselect them to unassign from the group, and then click Save.\n\n",
                "title": "To manage users of a domain group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-user-assignment-to-domain-groups.html"
    },
    {
        "title": "Compute cluster network requirements",
        "content": "Compute cluster network requirements\n\nGeneral requirements and recommendations are listed in Network requirements and Network recommendations.\n\nYou can create a minimum network configuration for evaluation purposes, or expand it to an advanced network configuration, which is recommended for production. Both these network configurations have the following requirements:\n\n10+ Gbit/s network adapters must be configured to use MTU 9000, to achieve full performance.\nFor pulling VM backups by third-party backup management systems, the VM backups traffic type must be assigned together with VM public on a separate isolated network due to security reasons.\nFor RDMA, a separate physical interface must be used for the Storage traffic type.\n\nMinimum network configuration for the compute cluster\nThe minimum configuration includes two networks, for internal and external traffic:\n\nRecommended network configuration for the compute cluster\nThe recommended configuration expands to five networks connected to the following logical network interfaces:\n\nOne private bonded connection with a single VLAN (or a native interface) for internal management and storage traffic with the Storage and Internal management traffic types.\n\nOne public bonded connection with at least three VLANs over it:\n\nThe trunk interface assigned the VM public traffic type, to automatically create VLAN-based networks for external (public) traffic of virtual machines.\n\nOne VLAN for overlay network traffic between VMs with the VM private traffic type.\n\nStarting from the version 5.2, we support data-in-transit encryption between nodes. Enabling encryption decreases the VXLAN payload by 37 bytes, thus increasing the default overhead for virtual networks from 50 to 87 bytes.\n\nOne VLAN for service delivery via the admin and self-service panels, compute API, and for management  via SSH, with these traffic types: Compute API, Admin panel, Self-service panel, and SSH.\nThis VLAN can also be used for public export of iSCSI, NFS, S3, Backup Gateway data, and accessing cluster monitoring statistics via the SNMP protocol.\n\nOne or more VLANs for external VM traffic with the VM public traffic type.\n\nThe table below includes the full list of network recommendations for the compute cluster:\n\nBond\nVLAN\nNetwork\nTraffic types\nMTU\n\nSpecifics\n\nBond0\n101 or native\nPrivate\nStorage, Internal management1 If you use the Backup Gateway or S3 service in your cluster, include the Backup (ABGW) private or OSTOR private traffic type.\n\nTo achieve the maximum performance, these networks must have the MTU size close to 9000 bytes.2 The maximum supported MTU of your physical network.\n\nThe bond must be built on top of a high-performance network, as storage traffic requires low latency and high throughput. We recommend using 25  or 40 Gbit/s network adapters. Using 10 Gbit/s adapters is also possible, but not recommended.\nFor this network, we also recommend using RDMA (over Infiniband or RoCEv2),  as it significantly increases storage performance for IOPS-intensive workloads.\n\nBond1\nTrunk\nTrunk\nVM public\n\nThe bond must be built on top of 10+ Gbit/s network, as it includes internal traffic between virtual machines in private virtual networks (VXLAN).\n\n102\nOverlay\nVM private\nIncludes the 87-byte overhead due to VXLAN (50 bytes) and encryption (37 bytes).\n\n103\nServices\nCompute API, Admin panel, Self-service panel, SSH3 If you use NFS, iSCSI, S3, or other services, assign their associated traffic types to this network.\n\nThe self-service panel traffic should be exposed to public networks via NAT.\nFurthermore, we do not recommend exposing such services as the admin panel and SSH to the Internet. For managing your cluster, use a secure VPN. If you need to provide end users access to the OpenStack API, expose the compute API traffic via NAT and configure the OpenStack endpoints.\n\n104\nPublic\nVM public\n\u00e2\u0080\u0094\n\nSee also\n\nCompute cluster requirements\n\nKubernetes-as-a-Service network requirements\n\nNetwork recommendations\n\nNetwork ports\n\nSetting up networks for the compute cluster",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/compute-network-requirements.html"
    },
    {
        "title": "Making Kubernetes deployments highly available",
        "content": "Making Kubernetes deployments highly available\nIf a node that hosts a Kubernetes pod fails or becomes unreachable over the network, the pod is stuck in a transitional state. In this case, the pod's persistent volumes are not automatically detached, and it prevents the pod redeployment on another worker node. To make your Kubernetes applications highly available, you need to enforce the pod termination in the event of node\u00a0failure by adding rules to the pod deployment. \nTo terminate a stuck pod\nAdd the following lines to the spec section of the deployment configuration file:terminationGracePeriodSeconds: 0\r\ntolerations:\r\n- effect: NoExecute\r\nkey: node.kubernetes.io/unreachable\r\noperator: Exists\r\ntolerationSeconds: 2\r\n- effect: NoExecute\r\nkey: node.kubernetes.io/not-ready\r\noperator: Exists\r\ntolerationSeconds: 2\nIf the node's state changes to \"NotReady\" or \"Unreachable\", the pod will be automatically terminated in 2 seconds.\nThe entire YAML file of a deployment may look as follows:apiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: nginx\r\nspec:\r\n  replicas: 1\r\n  selector:\r\n    matchLabels:\r\n      app: nginx\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: nginx\r\n    spec:\r\n      terminationGracePeriodSeconds: 0\r\n      tolerations:\r\n      - effect: NoExecute\r\n        key: node.kubernetes.io/unreachable\r\n        operator: Exists\r\n        tolerationSeconds: 2\r\n      - effect: NoExecute\r\n        key: node.kubernetes.io/not-ready\r\n        operator: Exists\r\n        tolerationSeconds: 2\r\n      containers:\r\n      - image: nginx\r\n        imagePullPolicy: IfNotPresent\r\n        name: nginx\r\n        ports:\r\n        - containerPort: 80\r\n          protocol: TCP\r\n        volumeMounts:\r\n          - mountPath: /var/lib/www/html\r\n            name: mydisk\r\n      volumes:\r\n        - name: mydisk\r\n          persistentVolumeClaim:\r\n            claimName: mypvc\nThe manifest above describes the deployment nginx with one pod that uses the persistent volume claim mypvc and will be automatically terminated in 2 seconds in the event of node\u00a0failure.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/making-kubernetes-deployments-highly-available.html"
    },
    {
        "title": "Troubleshooting virtual machines",
        "content": "Troubleshooting virtual machines\nIf a virtual machine fails to deploy\nReview the error message on the VM right pane. One of the possible root causes is that compute nodes lack free RAM or CPU resources to host the VM.\nIf a virtual machine is in the error state\n\nAdmin panel\nExamine the VM history in the History tab on the VM right pane. The event log will contain all of the VM management operations performed by users in the user or command-line interface. You can expand each log entry to view operation details by clicking the arrow icon next to it. The details include the operation name, date and time, status, initiator, and request ID.\n\nCommand-line interface\nUse the following command:vinfra service compute server event list [--long] --server <server>\n\n--long\n\nEnable access and listing of all fields of objects\n--server <server>\n\nVirtual machine ID or name\n\nFor example, to view the event log of the virtual machine myvm, run:# vinfra service compute server event list --server myvm\r\n+--------------+------------------+----------------------+----------------+---------------------+-------------+----------+---------+\r\n| project_id   | server_id        | request_id           | action         | start_time          | user_id     | username | status  |\r\n+--------------+------------------+----------------------+----------------+---------------------+-------------+----------+---------+\r\n| 231f2740c<\u00e2\u0080\u00a6> | 0ad154ad-aa52<\u00e2\u0080\u00a6> | req-fbdacb0a-55f3<\u00e2\u0080\u00a6> | live-migration | 2022-07-22T11:43<\u00e2\u0080\u00a6> | effbd0f0<\u00e2\u0080\u00a6> | admin    | Error   |\r\n| 231f2740c<\u00e2\u0080\u00a6> | 0ad154ad-aa52<\u00e2\u0080\u00a6> | req-8145f911-02a6<\u00e2\u0080\u00a6> | reboot         | 2022-07-22T09:11<\u00e2\u0080\u00a6> | effbd0f0<\u00e2\u0080\u00a6> | admin    | Success |\r\n| 42166f19e<\u00e2\u0080\u00a6> | 0ad154ad-aa52<\u00e2\u0080\u00a6> | req-aff9b796-0378<\u00e2\u0080\u00a6> | create         | 2022-07-21T17:48<\u00e2\u0080\u00a6> | 646f5793<\u00e2\u0080\u00a6> | admin1   | Success |\r\n+--------------+------------------+----------------------+----------------+---------------------+-------------+----------+---------+\nThe details of a particular event are shown in the vinfra service compute server event show output:# vinfra service compute server event show --server myvm req-fbdacb0a-55f3-4670-8af0-3465f2abd64f\r\n+------------+------------------------------------------+\r\n| Field      | Value                                    |\r\n+------------+------------------------------------------+\r\n| action     | live-migration                           |\r\n| project_id | 231f2740c2704c6c8c06d0626d51346e         |\r\n| request_id | req-fbdacb0a-55f3-4670-8af0-3465f2abd64f |\r\n| server_id  | 0ad154ad-aa52-4b23-a780-7ecc96adcbb8     |\r\n| start_time | 2022-07-22T11:43:51.172315Z              |\r\n| status     | Error                                    |\r\n| user_id    | effbd0f037714ff7886586d34e4d2a95         |\r\n| username   | admin                                    |\r\n+------------+------------------------------------------+\r\n\n\nIf a virtual machine is stuck in a failed or transitional state\n\nAdmin panel\n Reset the VM to its last stable state: active, shut down or shelved:\n\n Click the stuck VM.\nOn the VM right pane, click Reset state.\n\nCommand-line interface\nUse the following command:vinfra service compute server reset-state [--state-error] <server>\r\n\n\n--state-error\n\nReset virtual machine to \u00e2\u0080\u0098ERROR\u00e2\u0080\u0099 state\n<server>\n\nVirtual machine ID or name\n\nFor example, to reset the transitional state of the virtual machine myvm to the previous one, run:# vinfra service compute server reset-state myvm\n\nIf a virtual machine is stuck with the \u00e2\u0080\u009cPowering off\u00e2\u0080\u009d task state\nIn this case, a VM will have the \u00e2\u0080\u009cActive (Powering off)\u00e2\u0080\u009d status on its right pane.\nYou can cancel this task by using the following command:vinfra service compute server cancel-stop <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to cancel shutdown for the virtual machine myvm if it has the \u00e2\u0080\u009cpowering-off\u00e2\u0080\u009d task state, run:# vinfra service compute server cancel-stop myvm\nIf a virtual machine fails to boot\n\nAdmin panel\nExamine the VM console log by clicking Download console log on the VM right pane. The log will contain log messages only if logging is enabled inside the VM.\n\nCommand-line interface\nUse the following command:vinfra service compute server log <server>\t\t\t\t\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to print the log of the virtual machine myvm to the file myvm.log, run:# vinfra service compute server log myvm > myvm.log\t\t\t\nThe log will contain log messages only if logging is enabled inside the VM, otherwise the log will be empty. \n\nSee also\n\nEnabling logging for virtual machines\n\nManaging virtual machine power state\n\nRunning commands in virtual machines without network connectivity\n\nMonitoring virtual machines\n\nRescuing virtual machines\n\nDeleting virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server event list [--long] --server <server>\n\n--long\n\nEnable access and listing of all fields of objects\n--server <server>\n\nVirtual machine ID or name\n\nFor example, to view the event log of the virtual machine myvm, run:# vinfra service compute server event list --server myvm\r\n+--------------+------------------+----------------------+----------------+---------------------+-------------+----------+---------+\r\n| project_id   | server_id        | request_id           | action         | start_time          | user_id     | username | status  |\r\n+--------------+------------------+----------------------+----------------+---------------------+-------------+----------+---------+\r\n| 231f2740c<\u00e2\u0080\u00a6> | 0ad154ad-aa52<\u00e2\u0080\u00a6> | req-fbdacb0a-55f3<\u00e2\u0080\u00a6> | live-migration | 2022-07-22T11:43<\u00e2\u0080\u00a6> | effbd0f0<\u00e2\u0080\u00a6> | admin    | Error   |\r\n| 231f2740c<\u00e2\u0080\u00a6> | 0ad154ad-aa52<\u00e2\u0080\u00a6> | req-8145f911-02a6<\u00e2\u0080\u00a6> | reboot         | 2022-07-22T09:11<\u00e2\u0080\u00a6> | effbd0f0<\u00e2\u0080\u00a6> | admin    | Success |\r\n| 42166f19e<\u00e2\u0080\u00a6> | 0ad154ad-aa52<\u00e2\u0080\u00a6> | req-aff9b796-0378<\u00e2\u0080\u00a6> | create         | 2022-07-21T17:48<\u00e2\u0080\u00a6> | 646f5793<\u00e2\u0080\u00a6> | admin1   | Success |\r\n+--------------+------------------+----------------------+----------------+---------------------+-------------+----------+---------+\nThe details of a particular event are shown in the vinfra service compute server event show output:# vinfra service compute server event show --server myvm req-fbdacb0a-55f3-4670-8af0-3465f2abd64f\r\n+------------+------------------------------------------+\r\n| Field      | Value                                    |\r\n+------------+------------------------------------------+\r\n| action     | live-migration                           |\r\n| project_id | 231f2740c2704c6c8c06d0626d51346e         |\r\n| request_id | req-fbdacb0a-55f3-4670-8af0-3465f2abd64f |\r\n| server_id  | 0ad154ad-aa52-4b23-a780-7ecc96adcbb8     |\r\n| start_time | 2022-07-22T11:43:51.172315Z              |\r\n| status     | Error                                    |\r\n| user_id    | effbd0f037714ff7886586d34e4d2a95         |\r\n| username   | admin                                    |\r\n+------------+------------------------------------------+\r\n\n",
                "title": "If a virtual machine is in the error state"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server reset-state [--state-error] <server>\r\n\n\n--state-error\n\nReset virtual machine to \u00e2\u0080\u0098ERROR\u00e2\u0080\u0099 state\n<server>\n\nVirtual machine ID or name\n\nFor example, to reset the transitional state of the virtual machine myvm to the previous one, run:# vinfra service compute server reset-state myvm\n",
                "title": "If a virtual machine is stuck in a failed or transitional state"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server log <server>\t\t\t\t\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to print the log of the virtual machine myvm to the file myvm.log, run:# vinfra service compute server log myvm > myvm.log\t\t\t\nThe log will contain log messages only if logging is enabled inside the VM, otherwise the log will be empty. \n",
                "title": "If a virtual machine fails to boot"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nExamine the VM history in the History tab on the VM right pane. The event log will contain all of the VM management operations performed by users in the user or command-line interface. You can expand each log entry to view operation details by clicking the arrow icon next to it. The details include the operation name, date and time, status, initiator, and request ID.\n",
                "title": "If a virtual machine is in the error state"
            },
            {
                "example": "\nAdmin panel\n Reset the VM to its last stable state: active, shut down or shelved:\n\n Click the stuck VM.\nOn the VM right pane, click Reset state.\n\n",
                "title": "If a virtual machine is stuck in a failed or transitional state"
            },
            {
                "example": "\nAdmin panel\nExamine the VM console log by clicking Download console log on the VM right pane. The log will contain log messages only if logging is enabled inside the VM.\n",
                "title": "If a virtual machine fails to boot"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/troubleshooting-virtual-machines.html"
    },
    {
        "title": "Reconfiguring virtual machines",
        "content": "Reconfiguring virtual machines\nOnce you create a virtual machine, you can manage its CPU and RAM resources, as well as network interfaces and volumes.\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/reconfiguring-virtual-machines.html"
    },
    {
        "title": "High availability and the compute cluster",
        "content": "High availability and the compute cluster\nManagement node high availability (HA) and the compute cluster are tightly coupled, so changing nodes in one usually affects the other. Take note of the following:\n\nEach node in the HA configuration must meet the requirements for the management node listed in the Server requirements. If the compute cluster is to be created, its hardware requirements must be added as well.\nIf the HA configuration has been created before the compute cluster, all nodes in it will be added to the compute cluster. This applies to both three-node and five-node HA configurations.\nIf the compute cluster has been created before the HA configuration, only nodes in the compute cluster can be added to the three-node configuration. Additionally, such nodes must be connected to all networks with the VM public traffic type. To be able to create the HA configuration with a particular node, add this node to the compute cluster first. However, once the HA configuration is created, it can be expanded with two more nodes, with or without the compute role.\nIf the HA configuration and compute cluster include exactly the same nodes, single nodes cannot be removed from the compute cluster. In such a case, the compute cluster can be destroyed completely, but the HA configuration will remain. This is also true vice versa, the HA configuration can be destroyed, but the compute cluster will continue working.\nWith the five-node HA configuration, up to two nodes can be removed from the management node HA without destroying it. After this, these two nodes can be removed from the compute cluster.\n\nSee also\n\nHigh availability for services\n\nCreating the compute cluster\n\nManaging compute nodes",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/ha-and-compute.html"
    },
    {
        "title": "About file storage",
        "content": "About file storage\nFile storage is a storage architecture that uses the Network File System (NFS) protocol to manage data as files. Virtuozzo Hybrid Infrastructure allows you to organize nodes into a highly available NFS cluster in which you can create NFS shares. An NFS share is an access point for a volume and it can be assigned an IP address or a DNS name. The volume, in turn, can be assigned a redundancy scheme, a tier, and a failure domain. In each share, you can create multiple NFS exports that are actual exported directories for user data. Each export has, among other properties, a path that, combined with share\u00e2\u0080\u0099s IP address, uniquely identifies the export on the network and allows you to mount it using standard tools.\nOn the technical side, NFS volumes are based on object storage. Aside from offering high availability and scalability, object storage eliminates the limit on the amount of files and the size of data you can keep in the NFS cluster. Each share is perfect for keeping billions of files of any size. However, such scalability implies I/O overhead that is wasted on file size changes and rewrites. For this reason, an NFS cluster makes a perfect cold and warm file storage, but is not recommended for hot and high performance, and data that is often rewritten (like running virtual machines). Integration of Virtuozzo Hybrid Infrastructure with solutions from VMware, for example, is best done via iSCSI to achieve better performance.\n\nVirtuozzo Hybrid Infrastructure only supports NFS version 4 and newer. Starting with Virtuozzo Hybrid Infrastructure 4.0, pNFS is no longer supported.\n\nSee also\n\nProvisioning file storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/about-file-storage.html"
    },
    {
        "title": "Traffic types",
        "content": "Traffic types\nTo balance and optimize networking in Virtuozzo Hybrid Infrastructure, you can assign different types of traffic to separate networks. Assigning a traffic type to a network means that a firewall is configured on nodes connected to this network, specific ports are opened on node network interfaces, and the necessary iptables rules are set. For example, nodes connected to a network with only the S3 public traffic type will accept incoming connections only on ports 80 and 443.\nThe next three subsections describe all of the traffic types that can be assigned to networks.\nExclusive traffic types\nExclusivity means that such a traffic type can be added only to one network.\n\nInternal management\n\nInternal cluster management and transfers of node monitoring data to the admin panel. Without this traffic type, the administrator cannot control and monitor the cluster. The cluster, however, continues working. Uses any available port.\nStorage\n\nInternal transfers of data chunks, high availability service heartbeats, as well as data self-healing. This is the most critical traffic type that defines storage performance and enables cluster high availability. Uses any available port.\nOSTOR private\n\nInternal data exchange between multiple S3/NFS services. Uses any available port.\nBackup (ABGW) private\n\nInternal management of and data exchange between multiple backup storage services. Uses any available port.\nVM private\n\nNetwork traffic between VMs in private virtual networks and VNC console traffic. Virtual networks are implemented as VXLAN, overlay networking fully isolated on L2. Opens UDP port 4789 and TCP ports from 15900 to 16900.\nCompute API\n\nExternal access to standard OpenStack API endpoints. Opens the following ports:\n\nTCP 5000\u00e2\u0080\u0094Identity API v3\nTCP 6080\u00e2\u0080\u0094noVNC Websocket Proxy\nTCP 8004\u00e2\u0080\u0094Orchestration Service API v1\nTCP 8041\u00e2\u0080\u0094Gnocchi API (billing metering service)\nTCP 8774\u00e2\u0080\u0094Compute API\nTCP 8776\u00e2\u0080\u0094Block Storage API v3\nTCP 8780\u00e2\u0080\u0094Placement API\nTCP 9292\u00e2\u0080\u0094Image Service API v2\nTCP 9313\u00e2\u0080\u0094Key Manager API v1\nTCP 9513\u00e2\u0080\u0094Container Infrastructure Management API (Kubernetes service)\nTCP 9696\u00e2\u0080\u0094Networking API v2\nTCP 9888\u00e2\u0080\u0094Octavia API v2 (load balancer service)\n\nVM backups\n\nExternal access to NBD endpoints. Third-party backup management systems can pull VM backups by using this traffic type. To be able to access backup agents installed in virtual machines, assign this traffic type along with VM public. Opens TCP ports from 49300 to 65535.\n\nRegular traffic types\nRegular traffic types traffic types can be added to multiple networks.\n\nS3 public\n\nExternal data exchange with the S3 access point. Uses TCP ports 80 and 443.\niSCSI\n\nExternal data exchange with the iSCSI access point. Uses TCP port 3260.\nNFS\n\nExternal data exchange with the NFS access point. Uses TCP/UDP ports 111, 892, and 2049.\nBackup (ABGW) public\n\nExternal data exchange with Acronis Cyber Protect agents and Acronis Cyber Protect Cloud. Uses TCP ports 40440 and 44445.\nAdmin panel\n\nExternal access to the admin panel. Uses TCP port 8888.\nVM public\n\nExternal data exchange between VMs and public networks (for example, the Internet). When a node network interface is assigned to a network with this traffic type, an Open vSwitch bridge is created on that network interface.\nSSH\n\nRemote access to nodes via SSH. Uses TCP port 22.\nSNMP\n\nExternal access to storage cluster monitoring statistics via the SNMP protocol. Opens UDP port 161.\nSelf-service panel\n\nExternal access to the self-service panel. Opens TCP port 8800.\n\nCustom traffic types\nCustom traffic types are created by system administrators to open required TCP ports.\nSee also\n\nManaging traffic types",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/traffic-types.html"
    },
    {
        "title": "Adding external DNS servers",
        "content": "Adding external DNS servers\nVirtuozzo Hybrid Infrastructure features a built-in DNS server that enables discovery of all of its internal services. For resolving external domain names, you can add DNS servers that already exist in your network infrastructure.\nLimitations\n\nSpecify a DNS server that belongs to a public network to be able to reach external locations like the updates repository, as well as any public networks.\n\nTo add external DNS servers\n\nAdmin panel\n\nGo to Settings > System settings > Cluster DNS.\n\nClick Add and select the IP address type:\n\nSelect Static, and then specify a static DNS IP address.\nSelect DHCP, and then select a DHCP-provided DNS IP address from the list.\n\nClick Add multiple times to specify multiple external DNS servers.\n\nClick Save to save your changes.\n\nCommand-line interface\nUse the following command:vinfra cluster settings dns set --nameservers <nameservers>\r\n\n\n--nameservers <nameservers>\n\nA comma-separated list of DNS servers\n\nFor example, to set the external DNS server to 8.8.8.8, run:# vinfra cluster settings dns set --nameservers 8.8.8.8\r\n+------------------+---------------+\r\n| Field            | Value         |\r\n+------------------+---------------+\r\n| dhcp_nameservers | - 10.10.0.10  |\r\n|                  | - 10.10.0.11  |\r\n|                  | - 10.37.130.2 |\r\n| nameservers      | - 8.8.8.8     |\r\n+------------------+---------------+\r\n\nThe added DNS server will appear in the vinfra cluster settings dns show output:# vinfra cluster settings dns show\r\n+------------------+-----------------------------------+\r\n| Field            | Value                             |\r\n+------------------+-----------------------------------+\r\n| dhcp_nameservers | 10.10.0.10,10.10.0.11,10.37.130.2 |\r\n| nameservers      | 10.10.0.11,10.10.0.10             |\r\n+------------------+-----------------------------------+\r\n\n\nWhat's next\n\nConfiguring NVMe performance",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings dns set --nameservers <nameservers>\r\n\n\n--nameservers <nameservers>\n\nA comma-separated list of DNS servers\n\nFor example, to set the external DNS server to 8.8.8.8, run:# vinfra cluster settings dns set --nameservers 8.8.8.8\r\n+------------------+---------------+\r\n| Field            | Value         |\r\n+------------------+---------------+\r\n| dhcp_nameservers | - 10.10.0.10  |\r\n|                  | - 10.10.0.11  |\r\n|                  | - 10.37.130.2 |\r\n| nameservers      | - 8.8.8.8     |\r\n+------------------+---------------+\r\n\nThe added DNS server will appear in the vinfra cluster settings dns show output:# vinfra cluster settings dns show\r\n+------------------+-----------------------------------+\r\n| Field            | Value                             |\r\n+------------------+-----------------------------------+\r\n| dhcp_nameservers | 10.10.0.10,10.10.0.11,10.37.130.2 |\r\n| nameservers      | 10.10.0.11,10.10.0.10             |\r\n+------------------+-----------------------------------+\r\n\n",
                "title": "To add external DNS servers"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Cluster DNS.\n\nClick Add and select the IP address type:\n\nSelect Static, and then specify a static DNS IP address.\nSelect DHCP, and then select a DHCP-provided DNS IP address from the list.\n\nClick Add multiple times to specify multiple external DNS servers.\n\n\n\n\n\nClick Save to save your changes.\n\n",
                "title": "To add external DNS servers"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-external-dns-servers.html"
    },
    {
        "title": "Deleting traits",
        "content": "Deleting traitsDELETE /traits/{name}\r\n\nDelete a custom trait with the specified name.\nSource: https://docs.openstack.org/api-ref/placement/?expanded=delete-traits-detail#delete-traits\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nname\n\npath\nstring\nThe name of a trait.\n\nExamplecurl -ks -X DELETE -H 'Content-Type: application/json' -H 'OpenStack-API-Version: placement 1.32' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8780/traits/CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-traits.html"
    },
    {
        "title": "Enabling PCI passthrough and vGPU support",
        "content": "Enabling PCI passthrough and vGPU support\nTo enable PCI passthrough and vGPU support for the compute cluster, you need to create a configuration file in the YAML format, and then use it to reconfigure the compute cluster.\nPrerequisites\n\nThe compute nodes are prepared for GPU passthrough, vGPU support, or SR-IOV, as described in Preparing nodes for GPU passthrough, Preparing nodes for GPU virtualization, and Preparing nodes for SR-IOV.\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo create the PCI passthrough and vGPU configuration file\nSpecify the identifier of a compute node that hosts PCI devices, and then add host devices that you want to pass through or virtualize:\n\nTo create virtual functions for a network adapter, add these lines:- device_type: sriov\r\n  device: enp2s0\r\n  physical_network: sriovnet\r\n  num_vfs: 8\nwhere:\n\nsriov is the device type for a network adapter\nenp2s0 is the device name of a network adapter\nsriovnet is an arbitrary name that will be used as an alias for a network adapter\nnum_vfs is the number of virtual functions to create for a network adapter\n\nThe maximum number of virtual functions supported by a PCI device is specified in the /sys/class/net/<device_name>/device/sriov_totalvfs file. For example:# cat /sys/class/net/enp2s0/device/sriov_totalvfs\r\n63\n\nTo enable GPU passthrough, add these lines:- device_type: generic\r\n  device: 1b36:0100\r\n  alias: gpu\nwhere:\n\ngeneric is the device type for a physical GPU that will be passed through\n1b36:0100 is the VID and PID of a physical GPU\ngpu is an arbitrary name that will be used as an alias for a physical GPU\n\nTo enable a vGPU, with or without SR-IOV support, add these lines:- device_type: pgpu\r\n  device: \"0000:c1:00.0\"\r\n  vgpu_type: nvidia-558\nwhere:\n\npgpu is the device type for a physical GPU that will be virtualized\n\"0000:c1:00.0\" is the PCI address of a physical GPU\nnvidia-558 is the vGPU type that will be enabled for a physical GPU\n\nThe entire configuration file may look as follows:# cat config.yaml\r\n- node_id: c3b2321a-7c12-8456-42ce-8005ff937e12\r\n  devices:\r\n    - device_type: sriov\r\n      device: enp2s0\r\n      physical_network: sriovnet\r\n      num_vfs: 8\r\n    - device_type: generic\r\n      device: 1b36:0100\r\n      alias: gpu\r\n    - device_type: pgpu\r\n      device: \"0000:01:00.0\"\r\n      vgpu_type: nvidia-232\r\n- node_id: 1d6481c2-1fd5-406b-a0c7-330f24bd0e3d\r\n  devices:\r\n    - device_type: generic\r\n      device: 10de:1eb8\r\n      alias: gpu\r\n    - device_type: pgpu\r\n      device: \"0000:03:00.0\"\r\n      vgpu_type: nvidia-224\r\n    - device_type: pgpu\r\n      device: \"0000:c1:00.0\"\r\n      vgpu_type: nvidia-558\r\n\nTo configure the compute cluster for PCI passthrough and vGPU support\nPass the configuration file to the vinfra service compute set command. For example:# vinfra service compute set --pci-passthrough-config config.yaml\nIf the compute configuration fails\nCheck whether the following error appears in /var/log/vstorage-ui-backend/ansible.log:2021-09-23 16:42:59,796 p=32130 u=vstoradmin | fatal: [32c8461b-92ec-48c3-ae02-\r\n4d12194acd02]: FAILED! => {\"changed\": true, \"cmd\": \"echo 4 > /sys/class/net/\r\nenp103s0f1/device/sriov_numvfs\", \"delta\": \"0:00:00.127417\", \"end\": \"2021-09-23 \r\n19:42:59.784281\", \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2021-09-23 \r\n19:42:59.656864\", \"stderr\": \"/bin/sh: line 0: echo: write error: Cannot allocate \r\nmemory\", \"stderr_lines\": [\"/bin/sh: line 0: echo: write error: Cannot allocate memory\"], \r\n\"stdout\": \"\", \"stdout_lines\": []}\nIn this case, run the the pci-helper.py script, and reboot the node:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py enable-iommu --pci-realloc\r\n# reboot\nWhen the node is up again, repeat the vinfra service compute set command.\nTo check that a node has vGPU resources for allocation\nList resource providers in the compute cluster to obtain their IDs. For example:# openstack --insecure resource provider list\r\n+--------------------------------------+-----------------------------------------+------------+--------------------------------------+--------------------------------------+\r\n| uuid                                 | name                                    | generation | root_provider_uuid                   | parent_provider_uuid                 |\r\n+--------------------------------------+-----------------------------------------+------------+--------------------------------------+--------------------------------------+\r\n| 359cccf7-9c64-4edc-a35d-f4673e485a04 | node001.vstoragedomain_pci_0000_01_00_0 |          1 | 4936695a-4711-425a-b0e4-fdab5e4688d6 | 4936695a-4711-425a-b0e4-fdab5e4688d6 |\r\n| b8443d1b-b941-4bf5-ab4b-2dc7c64ac7d1 | node001.vstoragedomain_pci_0000_81_00_0 |          1 | 4936695a-4711-425a-b0e4-fdab5e4688d6 | 4936695a-4711-425a-b0e4-fdab5e4688d6 |\r\n| 4936695a-4711-425a-b0e4-fdab5e4688d6 | node001.vstoragedomain                  |        823 | 4936695a-4711-425a-b0e4-fdab5e4688d6 | None                                 |\r\n+--------------------------------------+-----------------------------------------+------------+--------------------------------------+--------------------------------------+\r\n\nIn this output, the resource provider with the ID 4936695a-4711-425a-b0e4-fdab5e4688d6 has two child resource providers for two physical GPUs with PCI addresses 0000_01_00_0 and 0000_81_00_0.\nUse the obtained ID of a child resource provider to list its inventory. For example:# openstack --insecure resource provider inventory list 359cccf7-9c64-4edc-a35d-f4673e485a04\r\n+----------------+------------------+----------+----------+-----------+----------+-------+\r\n| resource_class | allocation_ratio | max_unit | reserved | step_size | min_unit | total |\r\n+----------------+------------------+----------+----------+-----------+----------+-------+\r\n| VGPU           |              1.0 |        8 |        0 |         1 |        1 |     8 |\r\n+----------------+------------------+----------+----------+-----------+----------+-------+\nThe child resource provider has vGPU resources that can be allocated to virtual machines.\nSee also\n\nChanging the vGPU type for physical GPUs\n\nSwitching between GPU passthrough and vGPU\n\nDisabling PCI passthrough and vGPU support\n\nWhat's next\n\nCreating virtual machines with physical GPUs\n\nCreating virtual machines with virtual GPUs\n\nCreating virtual machines with different vGPU types\n\nCreating virtual machines with SR-IOV network ports",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-pci-passthrough-and-vgpu-support.html"
    },
    {
        "title": "Setting up authentication in the appliance virtual machine",
        "content": "Setting up authentication in the appliance virtual machine\nPrerequisites\n\nThe virt-v2v appliance VM is deployed, as instructed in Deploying the appliance virtual machine.\n\nTo configure authentication in the appliance VM\n\nLog in to the appliance VM as the admin user with the SSH key.\nGet root privileges, for example, with sudo -i.\n\nCreate a bash script that will export OpenStack credentials:# cat > user-openrc.sh << EOF\r\nexport OS_PROJECT_DOMAIN_NAME=Domain_name\r\nexport OS_USER_DOMAIN_NAME=Domain_name\r\nexport OS_PROJECT_NAME=Project_name\r\nexport OS_USERNAME=user_name\r\nexport OS_PASSWORD=Password\r\nexport OS_AUTH_URL=https://<admin_panel_IP_addr>:5000/v3\r\nexport OS_IDENTITY_API_VERSION=3\r\nexport OS_INSECURE=true\r\nexport NOVACLIENT_INSECURE=true\r\nexport NEUTRONCLIENT_INSECURE=true\r\nexport CINDERCLIENT_INSECURE=true\r\nexport LIBGUESTFS_BACKEND=direct\r\nEOF\r\n\n\nYou will need the administrator credentials for the project that the appliance VM belongs to.\n\nCopy the OpenStack root CA certificate and CA keys from the Virtuozzo Hybrid Infrastructure management node:# scp root@<MN_IP>:/usr/libexec/vstorage-ui-backend/ca/ca.* /etc/pki/ca-trust/source/anchors/\r\n# update-ca-trust extract\r\n\nWhere <MN_IP> is the management node IP address. For more information, refer to Securing OpenStack API traffic with SSL.\n\nCreate a file with the VMware vCenter password to supply to virt-v2v. For example:# echo $vCenterPass > password.txt\r\n\nAlternatively, you can enter the password during migration or supply it to virt-v2v with the --password-file option.\n\nWhat's next\n\nMigrating virtual machines to Virtuozzo Hybrid Infrastructure online\n\nMigrating virtual machines to Virtuozzo Hybrid Infrastructure offline",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-authentication-in-the-appliance-vm.html"
    },
    {
        "title": "Managing backups",
        "content": "Managing backups\nA backup, or recovery point (these terms are used interchangeably), is a full copy of a compute volume made at a specified time. With the backup service, you can create backups automatically by using backup plans or initiate backups manually. Backup plans define what data to back up, how frequently to create backups, and how long to keep them.\nThe backup service also allows you to restore virtual machines and volumes by creating new intances from backups.\nLimitations\n\nOnly full backups of compute volumes are supported.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-backups.html"
    },
    {
        "title": "Managing volume snapshots",
        "content": "Managing volume snapshots\nYou can save the current state of a VM file system or user data by creating a snapshot of a volume. A snapshot of a boot volume may be useful, for example, before updating VM software. If anything goes wrong, you will be able to revert the VM to a working state at any time. A snapshot of a data volume can be used for backing up user data and testing purposes.\nPrerequisites\n\nTo create a consistent snapshot of a running VM\u00e2\u0080\u0099s volume, the guest tools must be installed in the VM, as described in Installing guest tools. The QEMU guest agent included in the guest tools image automatically quiesces the filesystem during snapshotting.\n\nTo create a snapshot of a volume\n\nOn the Volumes screen, click a volume.\n\nIn the volume right pane, switch to Snapshots, and then click Create snapshot.\n\nTo manage a volume snapshot\n\nSelect a volume and open the Snapshots tab on its right pane.\n\nYou can do the following:\n\nCreate a new volume from the snapshot.\nCreate a template from the snapshot.\n\nDiscard all changes that have been made to the volume since the snapshot was taken. This action is available only for VMs with the \"Shut down\" and \"Shelved offloaded\" statuses.\n\nAs each volume has only one snapshot branch, all snapshots created after the snapshot you are reverting to will be deleted. If you want to save a subsequent snapshot before reverting, create a volume or an image from it first.\n\nChange the snapshot name and description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nReset the snapshot stuck in an \"Error\" state or transitional state to the \"Available\" state. \nRemove the snapshot.\n\nTo perform these actions, click the ellipsis button next to a snapshot, and then click the corresponding action.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-volume-snapshots.html"
    },
    {
        "title": "Monitoring virtual machines",
        "content": "Monitoring virtual machines\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo monitor virtual machine\u00e2\u0080\u0099s CPU, storage, and network usage\nSelect a virtual machine and open the Monitoring tab. The following performance charts are available for virtual machines:\n\nCPU\n\nCPU usage by the VM.\nRAM\n\nRAM usage by the VM.\nNetwork interface: <network_name> / MAC: <mac_address>\n\nThe VM interface parameters:\n\nSpeed: the port transmit (TX) and receive (RX) speed, in bytes per second.\nPackets: the number of TX and RX packets per second on the port.\nDrop rate: the number of TX and RX packets dropped per second on the port.\n\nTo see a list of VM interfaces and hide all other charts, click Only network interfaces above the charts.\n\nVolume: <volume_name> / <volume_id>\n\nThe VM disk parameters:\n\nStorage read: the amount of data being read by the VM, in bytes and operations per second.\nStorage write: the amount of data being written by the VM, in bytes and operations per second.\nRead latency: the disk latency while reading data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\nWrite latency: the disk latency while writing data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\nFlush latency: the disk latency while flushing data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\n\nTo see a list of VM disks and hide all other charts, click Only volumes above the charts.\n\nAveraged values are calculated every five minutes.\n\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/monitoring-virtual-machines.html"
    },
    {
        "title": "Managing S3 user and bucket limits in WHMCS",
        "content": "Managing S3 user and bucket limits in WHMCS\nThis section describes limits you can define for users and buckets in WHMCS. You can apply the limits according to specific options that can be a part of your service plan.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-user-and-bucket-limits-in-whmcs.html"
    },
    {
        "title": "Adding registrations",
        "content": "Adding registrations\nLimitations\n\nWith geo-replication enabled, new registrations are not automatically replicated to the secondary backup storage. To import such registrations, follow the instructions from Importing registrations to the secondary cluster.\n\nPrerequisites\n\nThe backup storage cluster is created and registered in the Cloud Management Panel, as described in Provisioning Acronis Backup Storage space.\nEnsure that two-factor authentication (2FA) is disabled for your partner account. You can also disable it for a specific user within a 2FA-enabled tenant, as described in the Acronis Cyber Protect Cloud documentation, and specify the user credentials.\n\nIf you have enabled login control for the Acronis Cyber Protect Cloud web interface, ensure that the public IP address of your backup storage cluster is specified among the allowed IP addresses, as instructed in the Acronis Cyber Protect Cloud documentation.\n\nTo add more registrations\n\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Registrations tab, and then click Add registration.\n\nIn the Add registration window, specify a registration name and a unique DNS name for backup storage (for example, newregistration.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data. Then, click Next.\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\nSpecify the following information for your Acronis product:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\nClick Add to create the registration.\n\nCommand-line interface\nUse the following command:vinfra service backup registration add --name <name> --address <address> --username <username>\r\n                                       --account-server <account_server> [--stdin] [--location <location>]\r\n                                       [--primary-storage-id] [--failback-storage-id]\n\n--name <name>\n\n       Backup registration name.\n--address <address>\n\nBackup registration domain name.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--stdin\n\nUse for setting registration password from stdin.\n--location <location>\n\nBackup registration location.\n--primary-storage-id\n\nThe ID of the replica storage.\n--failback-storage-id\n\nThe ID of the failback storage which will become primary after failback procedure is completed.\n\nFor example, to create the backup storage registration registration2 in Acronis Cyber Protect, run:# vinfra service backup registration add --name registration2 --address backupstorage2.example.com \\\r\n--username account@example.com --account-server https://cloud.acronis.com --stdin\nSpecify the registration password when prompted.\nThe new backup storage registration will appear in the vinfra service backup registration list output:# vinfra service backup registration list\r\n+-------------+---------------+----------------------------+------+\r\n| id          | name          | address                    | type |\r\n+-------------+---------------+----------------------------+------+\r\n| be526718<\u00e2\u0080\u00a6> | registration1 | backupstorage.example.com  | ABC  |\r\n| 028adb6b<\u00e2\u0080\u00a6> | registration3 | backupstorage3.example.com | ABC  |\r\n| 300d379f<\u00e2\u0080\u00a6> | registration2 | backupstorage2.example.com | ABC  |\r\n+-------------+---------------+----------------------------+------+\r\n\n\nSee also\n\nUpdating registration certificates\n\nDeleting registrations",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup registration add --name <name> --address <address> --username <username>\r\n                                       --account-server <account_server> [--stdin] [--location <location>]\r\n                                       [--primary-storage-id] [--failback-storage-id]\n\n--name <name>\n\n       Backup registration name.\n--address <address>\n\nBackup registration domain name.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--stdin\n\nUse for setting registration password from stdin.\n--location <location>\n\nBackup registration location.\n--primary-storage-id\n\nThe ID of the replica storage.\n--failback-storage-id\n\nThe ID of the failback storage which will become primary after failback procedure is completed.\n\nFor example, to create the backup storage registration registration2 in Acronis Cyber Protect, run:# vinfra service backup registration add --name registration2 --address backupstorage2.example.com \\\r\n--username account@example.com --account-server https://cloud.acronis.com --stdin\nSpecify the registration password when prompted.\nThe new backup storage registration will appear in the vinfra service backup registration list output:# vinfra service backup registration list\r\n+-------------+---------------+----------------------------+------+\r\n| id          | name          | address                    | type |\r\n+-------------+---------------+----------------------------+------+\r\n| be526718<\u00e2\u0080\u00a6> | registration1 | backupstorage.example.com  | ABC  |\r\n| 028adb6b<\u00e2\u0080\u00a6> | registration3 | backupstorage3.example.com | ABC  |\r\n| 300d379f<\u00e2\u0080\u00a6> | registration2 | backupstorage2.example.com | ABC  |\r\n+-------------+---------------+----------------------------+------+\r\n\n",
                "title": "To add more registrations"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Registrations tab, and then click Add registration.\n\nIn the Add registration window, specify a registration name and a unique DNS name for backup storage (for example, newregistration.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data. Then, click Next.\n\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\n\n\n\n\n\n\n\nSpecify the following information for your Acronis product:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\n\n\n\n\n\nClick Add to create the registration.\n\n",
                "title": "To add more registrations"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-registrations.html"
    },
    {
        "title": "Reconfiguring virtual machines",
        "content": "Reconfiguring virtual machines\nOnce you create a virtual machine, you can manage its CPU and RAM resources, as well as network interfaces and volumes.\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/reconfiguring-virtual-machines.html"
    },
    {
        "title": "8. Installing Leostream Connection Broker\u00c2\u00b6",
        "content": "8. Installing Leostream Connection Broker | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n8. Installing Leostream Connection Broker\u00c2\u00b6\nPrior to installing your Connection Broker or Leostream Gateway, install the latest updates on both operating systems. After the updates are applied, if your Connection Broker instance has access to the internet, you can install the Connection Broker by logging into the instance\u00e2\u0080\u0099s console and executing the following command:\ncurl http://downloads.leostream.com/broker.prod.sh | bash\n\n\nIf your Connection Broker instance does not have internet access, download the Connection Broker package from the following location and copy the file into the Connection Broker instance.\nhttps://www.leostream.com/resource/leostream-connection-broker-9-0/\nAfter the installation is complete, ensure that your Connection Broker can access the OpenStack API endpoint in order to manage Virtuozzo Hybrid Infrastructure. You can do this by running the following command, and shown by example in the following figure.\ncurl -k https://external_openstack_ip:5000/v3.0 ; echo\n\n\nThe Connection Broker uses the private IP address assigned by Virtuozzo Hybrid Infrastructure on the network you selected when creating the VM. To access the Connection Broker Administrator Web interface, you must be able to access the Connection Broker from a Web browser, which you can do by enabling Connection Broker forwarding on the Leostream Gateway, as described in the following section.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/installing-broker.html"
    },
    {
        "title": "POST service ostor-users",
        "content": "POST service ostor-users\nDescription\nGenerates or revokes access key pairs of existing users or accounts.\r\n\r\n\nRequests\nSyntaxPOST /?ostor-users&emailAddress=<value>&genKey HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>POST /?ostor-users&emailAddress=<value>&revokeKey=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>POST /?ostor-users&emailAddress=<value>&accountName=<value>&genKey HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>POST /?ostor-users&emailAddress=<value>&accountName=<value>&revokeKey=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nPOST service ostor-users parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes\n\naccountName\n\nAccount name.\n\r\nType: string.\n\r\nDefault value: none.\n\nNo\n\ngenKey\n\nGenerates a new access key pair for the user or account. A user or an account can only have two key pairs.\nType: flag.\nDefault value: none.\n\nNo*\n\nrevokeKey\n\nRemoves the access key pair that corresponds to the specified access key.\n\r\nType: string.\n\r\nDefault value: none.\n\nNo*\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nIf a key is generated, the body is a JSON dictionary with user information.{\r\n\"UserEmail\" : \"<email>\"\r\n\"UserId\" : \"<id>\",\r\n\"AWSAccessKeys : [\r\n{\r\n\"AWSAccessKeyId\" : \"<access_key>\",\r\n\"AWSSecretAccessKey\" : \"<secret_key>\"\r\n}]\r\n}\nIf a key is revoked, the body is empty.\nExamples\nSample request #1\nGenerates a new key pair for the user with the email user1@email.com.POST /?ostor-users&emailAddress=user1@email.com&genKey HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 15:51:13 GMT +3:00\r\nAuthorization: <authorization_string>\nSample response #1HTTP/1.1 200 OK\r\nx-amz-req-time-micros : 384103\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : closed\r\nx-amz-request-id : 8000000000000003000374603639905b\r\nDate : Thu, 07 Apr 2016 12:51:09 GMT\r\nContent-type : application/json\r\n{\r\n  \"UserEmail\": \"user1@email.com\",\r\n  \"UserId\": \"8eaa6ab4749a29b4\",\r\n  \"AWSAccessKeys\": [\r\n    {\r\n      \"AWSAccessKeyId\": \"8eaa6ab4749a29b4034G\",\r\n      \"AWSSecretAccessKey\": \"7spuMfShCIl2tX6dFtSl7TEP7ZQbIGl1GgE0Emdy\"\r\n    },\r\n    {\r\n      \"AWSAccessKeyId\": \"8eaa6ab4749a29b4EJUY\",\r\n      \"AWSSecretAccessKey\": \"ELzQ8CTMFcYQCGSP5lnGvmJxFC9xXrEJ4CjBAA2k\"\r\n    }\r\n  ]\r\n}\nSample request #2\nGenerates a new key pair for the account account1 of the user with the email user1@email.com.POST /?ostor-users&emailAddress=user1@email.com&accountName=account1&genKey HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 24 Mar 2021 17:32:41 +0200\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 200 OK\r\nServer: nginx\r\nContent-Type: application/json\r\nTransfer-Encoding: chunked\r\nConnection: keep-alive\r\nDate: Wed, 24 Mar 2021 15:32:42 GMT\r\nx-amz-req-time-micros: 51835\r\nx-amz-request-id: 8000000000000016000060d7e970100a\r\n{\r\n  \"UserEmail\": \"user2@email.com\",\r\n  \"UserId\": \"bc6265392b818465\",\r\n  \"AWSAccessKeys\": [\r\n    {\r\n      \"AWSAccessKeyId\": \"bc6265392b818465YQ0R\",\r\n      \"AWSSecretAccessKey\": \"D6dSND8MZFSsKxp4bJFRXsCFEz3bC32nhpEzFpvP\"\r\n    }\r\n  ]\r\n}\nSample request #3\nRevokes the key pair with the ID 8eaa6ab4749a29b4034G for the user with the email user1@email.com.POST /?ostor-users&emailAddress=user1@email.com&revokeKey=8eaa6ab4749a29b4034G HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 24 Mar 2021 17:36:57 +0200\r\nAuthorization: <authorization_string>\nSample response #3HTTP/1.1 200 OK\r\nServer: nginx\r\nContent-Type: application/json\r\nTransfer-Encoding: chunked\r\nConnection: keep-alive\r\nDate: Wed, 24 Mar 2021 15:36:58 GMT\r\nx-amz-req-time-micros: 43652\r\nx-amz-request-id: 8000000000000016000060d7f8b178be",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/post-service-ostor-users.html"
    },
    {
        "title": "Deleting virtual routers",
        "content": "Deleting virtual routersDELETE /v2.0/routers/{router_id}\r\n\nDelete a logical router and, if present, its external gateway interface.\nThis operation fails if the router has attached internal interfaces. Find their IDs, as explained in Listing virtual router interfaces, and delete them, according to Deleting virtual router interfaces. After deleting all of router\u00e2\u0080\u0099s internal interfaces, delete the router itself.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=delete-router-detail#delete-router\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/routers/ce996632-45a2-4c6b-a951-a624eba74621\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n412 - Precondition Failed\n\nThe server does not meet one of the preconditions that the requester put on the request header fields.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-virtual-routers.html"
    },
    {
        "title": "Using metering service",
        "content": "Using metering service",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/using-metering-service.html"
    },
    {
        "title": "Managing compute volumes",
        "content": "Managing compute volumes\nA volume in Virtuozzo Hybrid Infrastructure is a virtual disk drive that can be attached to a virtual machine. The integrity of data in volumes is protected by the redundancy mode specified in the storage policy.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-compute-volumes.html"
    },
    {
        "title": "Mounting NFS exports on macOS",
        "content": "Mounting NFS exports on macOS\nYou can mount an NFS export created in Virtuozzo Hybrid Infrastructure like any other directory exported via NFS. You will need the share IP address (or hostname) and the volume identifier.\nYou can use the command-line prompt or Finder:\n\nIn console, run the following commands:# mkdir /mnt/nfs\r\n# mount -t nfs -o vers=4.0 <share_IP>:/<share_name>/ /mnt/nfs\r\n\nwhere:\n\n-o vers=4.0 is the NFS version to use.\nVirtuozzo Hybrid Infrastructure supports NFS versions 4.0 and 4.1.\n\n<share_IP> is the share IP address. You can also use the share hostname.\n/<share_name>/ is the root export path, like share1. For user exports, specify their full path, for example: /<share_name>/export1.\n/mnt/nfs is an existing local directory to mount the export to.\n\nIn Finder, do the following:\n\nSet the NFS version to 4.0. To do this, add the nfs.client.mount.options = vers=4.0 line to the /etc/nfs.conf file.\n\nIn the Finder > Go > Connect to server window, specify nfs://192.168.0.51:/<share_name>/\nwhere:\n\n192.168.0.51 is the share IP address. You can also use the share hostname.\n/<share_name>/ is the root export path. For user exports, specify their full path, for example: /<share_name>/export1.\n\nClick Connect.\n\nThe Finder will mount the export to /Volumes/<share_name>/.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/mounting-nfs-exports-on-macos.html"
    },
    {
        "title": "Failure domains",
        "content": "Failure domains\nThe idea behind failure domains is to define a scope (for example, a rack) which can fail, while its data will still be available. If we choose the rack failure domain, the cluster data will tolerate a failure of one rack: the other racks will provide for the data availability. If we choose the host failure domain, the loss of an entire server would not result in the loss of data availability.\nTo provide high availability, Virtuozzo Hybrid Infrastructure spreads data replicas evenly across failure domains, according to a replica placement policy. The following policies are available:\n\nDisk, the smallest possible failure domain. Under this policy, Virtuozzo Hybrid Infrastructure never places more than one data replica per disk. While protecting against disk failure, this option may still result in data loss if data replicas happen to be on different disks of the same host and it fails. This policy should be used with one-node clusters.\nHost as a failure domain. Under this policy, Virtuozzo Hybrid Infrastructure never places more than one data replica per host. So if a storage node fails (an operating system crash) and all its disks become unavailable, the data is still accessible from the healthy nodes.\nRack as a failure domain. Under this policy, Virtuozzo Hybrid Infrastructure never places more than one data replica per rack. So if a single rack fails (a failure of top-of-rack switch) and all the nodes in it become unavailable, the data is still accessible from the other racks.\nRow as a failure domain. Under this policy, Virtuozzo Hybrid Infrastructure never places more than one data replica per row. So if a single row fails (a failure of a single power source) and all the racks in it become unavailable, the data is still accessible from the other rows.\nRoom as a failure domain. Under this policy, Virtuozzo Hybrid Infrastructure never places more than one data replica per room. So if a single room fails (a power outage) and all the rows in it become unavailable, the data is still accessible from the other rooms.\n\nWhen selecting a failure domain, consider the following recommendations:\n\nMake sure the metadata services are distributed among the locations. For example, if you choose a room as the failure domain, and distribute the data across several rooms evenly, you must distribute metadata services too. If you put all the metadata services in one room and it fails due to a power outage, the cluster will not function properly.\nTo select a location as the failure domain, you need to have several locations of the kind so that a service or the data can move from one failure domain to another, such as from one rack to another. For example, if you want to choose the rack failure domain with the redundancy 2 replicas or encoding 1+1, make sure you have at least two racks with healthy nodes assigned to the cluster.\nThe disk space should be distributed evenly between the failure domains. For example, if you select the rack failure domain, equal disk space should be available on each of the racks. The allocatable disk space in each rack is set to the disk space on the smallest rack. The reason is that each rack should store one replica for a data chunk. So once the disk space on the smallest rack runs out, no more chunks in the cluster can be created until a new rack is added or the replication factor is decreased. Huge failure domains are more sensitive to total disk space imbalance. For example, if a domain has 5 racks, with 10 TB, 20 TB, 30 TB, 100 TB, and 100 TB total disk space, it will not be possible to allocate (10+20+30+100+100)/3 = 86 TB of data in 3 replicas. Instead, only 60 TB will be allocatable, as the low-capacity racks will be exhausted sooner. At that, the largest racks (the 100 TB ones) will still have free unallocatable space.\n\nSee also\n\nStorage policies\n\nData redundancy\n\nStorage tiers\n\n\u00d0\u00a1luster rebuilding",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/failure-domains.html"
    },
    {
        "title": "Creating QoS policies",
        "content": "Creating QoS policies\nPrerequisites\n\nA clear understanding of QoS policy rules, which are explained in QoS policy rules.\nTo create a QoS policy as a system or domain administrator, ensure that the environment file for this user is created, as described in Connecting to OpenStack command-line interface.\n\nTo create a QoS policy with rules\n\nCreate a QoS policy:\n\n If you are creating a policy as a system administrator\n\nUse the environment file for the system administrator:# source /etc/kolla/admin-openrc.sh\r\n\n\nCreate a QoS policy within a project it will be applied to. For example:# openstack --insecure network qos policy create --project 3823a2d908ea4dd6909a8f93a6f66018 policy1\n\nIf you are creating a policy as a domain administrator\n\nUse the environment file for the domain administrator. For example:# source domain-admin.sh\n\nUse the project name variable for the project where you want to create a QoS policy. For example:# export OS_PROJECT_NAME=testproject\n\nCreate a QoS policy. For example:# openstack --insecure network qos policy create policy1\n\nCreate a rule for the QoS policy:\n\n To create a bandwidth limit, specify bandwidth-limit for the --type option and specify rule parameters. For example, to limit the egress traffic to 3 Mbps, run:# openstack --insecure network qos rule create --type bandwidth-limit \\\r\n--max-kbps 3000 --max-burst-kbits 2400 --egress policy1\r\n+----------------+--------------------------------------------------+\r\n| Field          | Value                                            |\r\n+----------------+--------------------------------------------------+\r\n| direction      | egress                                           |\r\n| id             | 6f036f09-d952-420d-986b-27c7eb14b2da             |\r\n| location       | Munch({'project': Munch({'domain_name': Default, |\r\n|                | 'domain_id': None, 'name': admin,                |\r\n|                | 'id': u'e215189c0472482f93e71d10e1245253'}),     |\r\n|                | 'cloud': '', 'region_name': '', 'zone': None})   |\r\n| max_burst_kbps | 2400                                             |\r\n| max_kbps       | 3000                                             |\r\n| name           | None                                             |\r\n| project_id     |                                                  |\r\n+----------------+--------------------------------------------------+\n\nTo create a minimum bandwidth guarantee, specify minimum-bandwidth for the --type option and specify rule parameters. For example, to guarantee the minimum of 100 Kbps to the ingress traffic, run:# openstack --insecure network qos rule create --type minimum-bandwidth \\\r\n--min-kbps 1000 --ingress policy1\r\n+------------+--------------------------------------------------+\r\n| Field      | Value                                            |\r\n+------------+--------------------------------------------------+\r\n| direction  | ingress                                          |\r\n| id         | 4eb79c67-e2b7-4ee7-845c-4cbe39f095cd             |\r\n| location   | Munch({'project': Munch({'domain_name': Default, |\r\n|            | 'domain_id': None, 'name': admin,                |\r\n|            | 'id': u'e215189c0472482f93e71d10e1245253'}),     |\r\n|            | 'cloud': '', 'region_name': '', 'zone': None})   |\r\n| min_kbps   | 1000                                             |\r\n| name       | None                                             |\r\n| project_id |                                                  |\r\n+------------+--------------------------------------------------+\n\nSee also\n\nModifying QoS policy rules\n\nWhat's next\n\nSetting the default QoS policy\n\nAssigning QoS policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-qos-policies.html"
    },
    {
        "title": "Managing CHAP users",
        "content": "Managing CHAP users\nThe Challenge-Handshake Authentication Protocol (CHAP) provides a way to restrict access to targets and their LUNs by requiring a user name and a password from the initiator. CHAP accounts apply to entire target groups.\nLimitations\n\nYou can only delete CHAP users that do not apply to any target group.\n\nTo enable CHAP authentication for a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, and then click the desired target group in the list (anywhere except group\u00e2\u0080\u0099s name).\n\nOn the group right pane, open the Access control tab, and then click the pencil icon.\n\nIn the Access control window, select CHAP, and then click Create user.\n\nIn the Create CHAP user window, enter a user name and a password (12 to 16 characters long), and then click Create.\n\nBack on the Access control screen, select the desired CHAP user, and then click Save.\n\nCommand-line interface\n\nCreate a CHAP user:vinfra service block-storage user create [--description <description>] <name>\n\n--description <description>\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n<name>\n\nUser name\n\nFor example, to create the CHAP user user1 with the description A new user, run:# vinfra service block-storage user create user1 --description \"A new user\"\nSpecify the user password when prompted. The password must be 12-16 characters long.\n\nEnable CHAP authentication for the target group and the created CHAP user:vinfra service block-storage target-group set --enable-chap --chap-user <user-name> <target-group>\n\n--enable-chap\n\nEnable CHAP authentication\n--chap-user <user-name>\n\nCHAP user name\n<target-group>\n\nTarget group name or ID\n\nFor example, to enable CHAP authentication for the target group tg1 and the CHAP user user1, run:# vinfra service block-storage target-group set --enable-chap --chap-user user1 tg1\n\nTo change the password of a CHAP user\n\nAdmin panel\n\nOpen Storage services > Block storage > CHAP users, click a user to open details, and then click the pencil icon. \nIn the Edit CHAP user window, specify a new password, and then click Apply.\n\nCommand-line interface\nUse the following command:vinfra service block-storage user set [--description <description>] [--password] <user>\n\n--description <description>\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--password\n\nChange the user password\n<user>\n\nUser name\n\nFor example, to change the password of the CHAP user user1, run:# vinfra service block-storage user set user1 --password\nWhen prompted, enter a new password, which will replace the old one. The password must be 12-16 characters long.\n\nTo disable CHAP authentication for a target group\n\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon in the CHAP authentication section.\n\nIn the Access control window, clear CHAP, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group set --disable-chap <target-group>\n\n--disable-chap\n\nDisable CHAP authentication\n<target-group>\n\nTarget group name or ID\n\nFor example, to disable CHAP authentication for the target group tg1, run:# vinfra service block-storage target-group set --disable-chap tg1\n\nTo delete a CHAP user\n\nAdmin panel\n\nOpen Storage services > Block storage > CHAP users. \nClick the ellipsis icon of the user, and then click Delete.\n\nCommand-line interface\nUse the following command:vinfra service block-storage user delete <user>\n\n<user>\n\nUser name\n\nFor example, to delete the CHAP user user1, run:# vinfra service block-storage user delete user1\n\nSee also\n\nManaging access control lists",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nCreate a CHAP user:vinfra service block-storage user create [--description <description>] <name>\n\n--description <description>\n\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n<name>\n\nUser name\n\nFor example, to create the CHAP user user1 with the description A new user, run:# vinfra service block-storage user create user1 --description \"A new user\"\nSpecify the user password when prompted. The password must be 12-16 characters long.\n\n\nEnable CHAP authentication for the target group and the created CHAP user:vinfra service block-storage target-group set --enable-chap --chap-user <user-name> <target-group>\n\n--enable-chap\n\nEnable CHAP authentication\n--chap-user <user-name>\n\nCHAP user name\n<target-group>\n\nTarget group name or ID\n\nFor example, to enable CHAP authentication for the target group tg1 and the CHAP user user1, run:# vinfra service block-storage target-group set --enable-chap --chap-user user1 tg1\n\n\n",
                "title": "To enable CHAP authentication for a target group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage user set [--description <description>] [--password] <user>\n\n--description <description>\n\n\nUser description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--password\n\nChange the user password\n<user>\n\nUser name\n\nFor example, to change the password of the CHAP user user1, run:# vinfra service block-storage user set user1 --password\nWhen prompted, enter a new password, which will replace the old one. The password must be 12-16 characters long.\n",
                "title": "To change the password of a CHAP user"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group set --disable-chap <target-group>\n\n--disable-chap\n\nDisable CHAP authentication\n<target-group>\n\nTarget group name or ID\n\nFor example, to disable CHAP authentication for the target group tg1, run:# vinfra service block-storage target-group set --disable-chap tg1\n",
                "title": "To disable CHAP authentication for a target group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage user delete <user>\n\n<user>\n\nUser name\n\nFor example, to delete the CHAP user user1, run:# vinfra service block-storage user delete user1\n",
                "title": "To delete a CHAP user"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, and then click the desired target group in the list (anywhere except group\u00e2\u0080\u0099s name).\n\nOn the group right pane, open the Access control tab, and then click the pencil icon.\n\n\n\n\n\n\nIn the Access control window, select CHAP, and then click Create user.\n\n\n\n\n\n\nIn the Create CHAP user window, enter a user name and a password (12 to 16 characters long), and then click Create.\n\n\n\n\n\n\nBack on the Access control screen, select the desired CHAP user, and then click Save.\n\n\n\n\n\n\n",
                "title": "To enable CHAP authentication for a target group"
            },
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > CHAP users, click a user to open details, and then click the pencil icon. \nIn the Edit CHAP user window, specify a new password, and then click Apply.\n\n",
                "title": "To change the password of a CHAP user"
            },
            {
                "example": "\nAdmin panel\n\nOn the target group right pane, open the Access control tab, and then click the pencil icon in the CHAP authentication section.\n\nIn the Access control window, clear CHAP, and then click Save.\n\n\n\n\n\n\n",
                "title": "To disable CHAP authentication for a target group"
            },
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > CHAP users. \nClick the ellipsis icon of the user, and then click Delete.\n\n",
                "title": "To delete a CHAP user"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-chap-users.html"
    },
    {
        "title": "Backup storage metrics",
        "content": "Backup storage metrics\nMetrics used for monitoring backup storage are configured in the Prometheus recording rules and can be found in the /var/lib/prometheus/rules/abgw.rules file on any node in the cluster. The most important of these metrics are described in the table:\n\nMetric\nDescription\n\nFES object counters\n\nabgw_accounts\n\nNumber of accounts backup storage is currently working with (that is, number of accounts with open backup archives)\n\nabgw_files\n\nNumber of currently open backup archives. Backup archives are open for reading and writing only during a backup operation. Other operations, such as restoring, browsing, and validation, open backup archives only for reading.\n\nabgw_conns[proto]\n\nNumber of current connections between backup storage and clients. The value is an array of counters. Details of the backup storage protocol (V1/V2) are available.\n\nConnection counters\n\nabgw_conns_total\n\nTotal number of connections between backup storage and clients since the service startup\n\nabgw_client_conns_cur[name]\n\nNumber of currently connected clients, divided by type\n\nabgw_client_conns_total[name]\n\nTotal number of clients since the service startup, divided by type\n\nCertificate errors and expiration times\n\nabgw_verify_certs_errors_total[err]\n\nTotal number of certificate verification errors since the service startup, divided by error type\n\nabgw_next_certificate_expiration[path]\n\nExpiration date of backup storage certificates\n\nabgw_cert_update_fail_total\n\nNumber of failed attempts to update the certificate revocation list. The list is required to correctly apply a new quota in Acronis Cyber Protect Cloud, when the current customer certificate is revoked and a new certificate is requested.\n\nabgw_crl_download_fail_total\n\nNumber of failed attempts to download the certificate revocation list. The list is required to correctly apply a new quota in Acronis Cyber Protect Cloud, when the current customer certificate is revoked and a new certificate is requested.\n\nBackup storage protocol V1 request histograms and counters\n\nabgw_read_reqs_total\n\nNumber of read requests since the service startup\n\nabgw_write_reqs_total\n\nNumber of write requests since the service startup\n\nabgw_req_errs_total[req][err]\n\nArray with request errors, divided by request type and error codes\n\nabgw_req_latency_ms[req]\n\nHistogram with request latency\n\nBackup storage protocol V2 request histograms and counters\n\nabgw_v2_ireq_errs_total[req][err]\n\nNumber of read requests since the service startup\n\nabgw_v2_ireq_latency_ms[req][lat]\n\nNumber of write requests since the service startup\n\nabgw_v2_ereq_errs_total[req][err]\n\nArray with request errors, divided by request type and error codes\n\nabgw_v2_ereq_latency_ms[req][err]\n\nHistogram with request latency\n\nByte counters\n\nabgw_read_bytes_total[proxied]\n\nNumber of bytes read from a disk since the service startup. The proxied parameter shows data read via a reverse proxy.\n\nabgw_write_bytes_total[proxied]\n\nNumber of bytes written to a disk since the service startup. The proxied parameter shows data written via a reverse proxy.\n\nabgw_write_rollback_bytes_total\n\n Size of data overwritten by backup storage per client's request when backup storage could not confirm to the client that data was already written. The metric is used only for the backup storage protocol V1 and legacy backup clients.\n\nFile operation and I/O operation metrics\n\nabgw_file_lookup_errs_total[err]\n\nNumber of failed attempts to open files or find already open files, divided by error codes\n\nabgw_fop_latency_ms_bucket[fop][proxied][err]\n\nHistogram with the sum of file operation latency, divided by operation type (read, write, sync, stat), proxied or not, by error number, and other file operations\n\nabgw_iop_latency_ms_bucket[iop][proxied][err]\n\nHistogram with I/O operation latency, divided by operation type, proxied or not, and by error number\n\nabgw_io_limiting_failures_total[type]\n\nNumber of failed I/O requests to backup storage since the service startup, due to poor performance of the underlying storage\n\nabgw_iop_wd_timeouts[iop]\n\nNumber of file operations that take more than two minutes, divided by operation type\n\nMigration metrics\n\nabgw_account_pull_errs_total[err]\n\nNumber of failed attempts to retrieve the account list by the destination backup storage from the source backup storage before the migration start\n\nabgw_nr_files_to_pull\n\nNumber of files to migrate from the source backup storage to the destination backup storage (includes all files for which migration is not completed)\n\nabgw_pull_backlog_bytes\n\nNumber of bytes on the source backup storage that are not yet migrated to the destination backup storage\n\nabgw_pull_progress_bytes_total\n\nNumber of bytes on the destination backup storage that are already migrated from the source backup storage since the service startup\n\nabgw_file_migration_source_open_errs_total[err]\n\nNumber of failed attempts to open files for migration on the source backup storage since the service startup\n\nabgw_file_migration_source_read_errs_total[err]\n\nNumber of failed attempts to read files  for migration on the source backup storage since the service startup\n\nabgw_nr_accounts_pull_pending\n\nNumber of accounts that are awaiting migration\n\nabgw_nr_accounts_pull_started\n\nNumber of accounts that are in the process of migration\n\nabgw_nr_accounts_pull_errors\n\nNumber of accounts that have migration errors in at least one file\n\nObject storage and geo-replication metrics\n\nabgw_push_backlog_bytes[ostor, replica]\n\nNumber of bytes to be written to the object destination storage, or to the secondary cluster in case of geo-replication\n\nabgw_push_progress_bytes_total[ostor, replica]\n\nNumber of bytes written to the object destination storage, or to the secondary cluster in case of geo-replication. This metric helps to understand the speed of data replication or copying.\n\nabgw_push_replica_errs_total[err]\n\nNumber of failed attempts to write files to the object destination storage, or to the secondary cluster in case of geo-replication, since the service startup, divided by error type\n\nabgw_replica_integrity_checks_fail_total\n\nNumber of corrupted replicas on the secondary cluster since the service startup\n\nabgw_file_replica_auto_errs_total[err]\n\nNumber of geo-replication errors for new files (created after configuring geo-replication) since the service startup, divided by error type\n\nabgw_file_replica_open_errs_total[err]\n\nNumber of failed attempts by the primary cluster to open files for writing on the secondary cluster since the service startup, divided by error code\n\nabgw_rm_file_push_errs_total[err]\n\nNumber of errors occurred when removing files from the secondary cluster since the service startup, divided by error type. A secondary replica is deleted after disabling replication on the primary cluster.\n\nabgw_push_replica_total_size_by_brand[brand]\n\nTotal disk space occupied by replication-enabled files on the primary cluster, grouped by brand ID.\n\nabgw_push_progress_by_brand[brand]\n\nCurrent number of bytes successfully replicated from the primary cluster to the secondary one, grouped by brand ID.\n\nObject destination storage metrics\n\nabgw_ostor_used_space_bytes\n\nSpace size used by all backup archives, including data and unused space, on the object destination storage\n\nabgw_nr_ostor_sequence_mismatch_total\n\nNumber of files failed to be opened by backup storage due to their version mismatch on the object destination storage\n\nabgw_ostor_garbage_bytes\n\nUnused space size inside all backup archives that is not yet physically cleaned up on the object destination storage\n\nContainer archive validation results\n\nabgw_containers_validate_segments_fail_total\n\nNumber of archives with failed validation (segments) on the NFS and object destination storage\n\nabgw_containers_validate_trees_fail_total\n\nNumber of archives with failed validation (trees) on the NFS and object destination storage\n\nOther metrics\n\nabgw_append_throttle_delay_ms_total\n\nTotal sum of delays injected since the service startup. The metric helps to understand if throttling is enabled for backup storage.\n\nabgw_iop_ebusy\n\nNumber of I/O errors for open file operations since the service startup\n\nHistogram metrics with the \"_bucket\" suffix have corresponding metrics ending with \"_sum\" and \"_counter\", for example: \n\nabgw_iop_latency_ms_bucket shows the current measurement for I/O operation latency per bucket\nabgw_iop_latency_ms_count shows the total sum of all measurements for I/O operation latency per bucket\nabgw_iop_latency_ms_sum shows the number of stored measurements for I/O operation latency per bucket\n\nSee also\n\nCore storage metrics\n\nObject storage metrics\n\nCompute metrics\n\nCluster update metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup-storage-metrics.html"
    },
    {
        "title": "Updating Kubernetes clusters",
        "content": "Updating Kubernetes clusters\nWhen a new Kubernetes version becomes available, you can update your Kubernetes cluster to it. An update is non-disruptive for Kubernetes worker nodes, which means that these nodes are updated one by one, with the data availability unaffected. The Kubernetes API will be unavailable during an update, unless high availability is enabled for the master node.\nStarting from a Kubernetes cluster update to version 1.24.3, Kubernetes virtual machines are re-created based on a newer Fedora CoreOS image. Such a rolling update is used to preserve the cluster data. Before starting the update, you need to make sure that the compute cluster has enough resources and quotas for at least one extra VM of the largest flavor used by your Kubernetes cluster. If the master and worker node flavors differ, then you should take into account the largest one of them.\nLimitations\n\nYou cannot update Kubernetes clusters with versions 1.15.x\u00e2\u0080\u00931.17.x to newer versions.\nYou can update Kubernetes clusters only to the next minor version in one iteration. For example, to update a cluster from version 1.25 to 1.27, you need to update it to version 1.26 first.\nKubernetes clusters can have only one minor version difference between node groups (for example, 1.26 and 1.27).\nYou cannot manage Kubernetes clusters in the admin panel during an update.\n\nTo update a Kubernetes cluster\n\nAdmin panel\n\nClick a Kubernetes cluster that is marked with the Update available tag.\nOn the Kubernetes cluster pane, click Update in the Kubernetes version field.\n\nIn the Update window, do the following:\n\nSelect a Kubernetes version to update to and follow the provided link to read about API resources that are deprecated or obsoleted in the selected version. Then, click Next.\n\nChoose how to proceed:\n\nSelect Update all to update all of the node groups in the Kubernetes cluster.\nSelect Custom update to update only specific node groups. The master node group is selected automatically and is mandatory for an update.\n\nIn the confirmation window, click Confirm. The update process will start.\n\nDo not manage Kubernetes virtual machines during the update as it may lead to disruption of the update process and cluster inoperability.\n\nWhen node groups in a Kubernetes cluster have different versions, the cluster tag changes to Partially updated. In this case, new worker groups will be created with the version of the master node group. To finish the Kubernetes cluster upgrade, you need to repeat the update procedure for worker groups with an older version.\n\nCommand-line interface\nUse the following command:vinfra service compute k8saas upgrade [--nodegroups <nodegroups>] <cluster> <version>\n\n--nodegroups <nodegroups>\n\nA comma-separated list of node group IDs to upgrade\n<cluster>\n\nCluster ID or name\n<version>\n\nKubernetes version (v1.29.3, v1.28.4, v1.27.8, v1.26.11, v1.25.7, and v1.24.3)\n\nFor example, to upgrade the worker group with the ID 3c71ca36-3505-4c58-b077-36d118835364 in the Kubernetes cluster k8s1 from version v1.28.4 to version v1.29.3, run:# vinfra service compute k8saas upgrade --nodegroups 3c71ca36-3505-4c58-b077-36d118835364 k8s1 v1.29.3\n\nSee also\n\nChanging Kubernetes service parameters\n\nTroubleshooting Kubernetes clusters",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute k8saas upgrade [--nodegroups <nodegroups>] <cluster> <version>\n\n--nodegroups <nodegroups>\n\nA comma-separated list of node group IDs to upgrade\n<cluster>\n\nCluster ID or name\n<version>\n\nKubernetes version (v1.29.3, v1.28.4, v1.27.8, v1.26.11, v1.25.7, and v1.24.3)\n\nFor example, to upgrade the worker group with the ID 3c71ca36-3505-4c58-b077-36d118835364 in the Kubernetes cluster k8s1 from version v1.28.4 to version v1.29.3, run:# vinfra service compute k8saas upgrade --nodegroups 3c71ca36-3505-4c58-b077-36d118835364 k8s1 v1.29.3\n",
                "title": "To update a Kubernetes cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nClick a Kubernetes cluster that is marked with the Update available tag.\nOn the Kubernetes cluster pane, click Update in the Kubernetes version field.\n\nIn the Update window, do the following:\n\nSelect a Kubernetes version to update to and follow the provided link to read about API resources that are deprecated or obsoleted in the selected version. Then, click Next.\n\nChoose how to proceed:\n\nSelect Update all to update all of the node groups in the Kubernetes cluster.\nSelect Custom update to update only specific node groups. The master node group is selected automatically and is mandatory for an update.\n\n\n\n\n\n\n\nIn the confirmation window, click Confirm. The update process will start.\n\nDo not manage Kubernetes virtual machines during the update as it may lead to disruption of the update process and cluster inoperability.\n\n\n\nWhen node groups in a Kubernetes cluster have different versions, the cluster tag changes to Partially updated. In this case, new worker groups will be created with the version of the master node group. To finish the Kubernetes cluster upgrade, you need to repeat the update procedure for worker groups with an older version.\n",
                "title": "To update a Kubernetes cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/updating-kubernetes-clusters.html"
    },
    {
        "title": "Creating backup storage on an external NFS share",
        "content": "Creating backup storage on an external NFS share\nLimitations\n\nVirtuozzo Hybrid Infrastructure does not provide data redundancy on top of NFS volumes. Depending on the implementation, NFS shares may use their own hardware or software redundancy.\nOnly one node can work as a backup gateway for an NFS share.\nEach NFS export is used by only one gateway. In particular, do not connect two Virtuozzo Hybrid Infrastructure installations to the same NFS export for backup storage.\nMultiple full backups stored on an NFS share may consume additional storage space due to the delay of automatic compaction, which is performed for one backup at a time.\nBackup storage with the NFS destination that is based on the ext4 file system cannot work with backup archives larger than 16 TB. For such large files, consider using other backup storage destinations, for example, the local Virtuozzo Hybrid Infrastructure cluster.\n\nPrerequisites\n\nThe storage cluster has at least one disk with the Storage role.\nThe destination storage has enough space for both existing and new backups.\nEnsure that each node to join the backup storage cluster has the TCP port 44445 open for outgoing Internet connections, as well as for incoming connections from Acronis backup software.\nEnsure that the node to join the backup storage has access to external NFS storage.\nEnsure that the external NFS share to be used as the backup destination is completely empty.\n\nTo select an external NFS share as the backup destination\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the Backup (ABGW) private and Backup (ABGW) public traffic types are added to the networks you intend to use.\nOpen the Storage services > Backup storage screen, and then click Create backup storage.\nOn the Backup destination step, select Network File System (NFS) share.\n\nOn the Nodes step, select one node to add to the backup storage cluster, and then click Next.\n\nOn the NFS share step, specify the hostname or IP address of the NFS share, the export name, and select the NFS version. Then, click Next.\nNFS version 4 is recommended, as it provides better scalability and performance compared to NFS version 3, which has limitations in the protocol.\n\nOn the DNS step, do one of the following:\n\nSelect Register now, and then specify an external DNS name for backup storage (for example, backupstorage.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data.\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\nSelect Register later to add registrations for your backup storage later or configure it as the secondary cluster for geo-replication.\n\nIf you selected Register now, specify the following information for your Acronis product on the Acronis account step:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\nOn the Summary step, review the configuration, and then click Create.\n\nAfter creating the backup storage, you can increase its storage capacity at any time by adding space to the NFS share.\n\nCommand-line interface\nUse the following command:vinfra service backup cluster deploy-standalone --nodes <nodes> > --name <name> --address <address>\r\n                                                [--location <location>] --username <username>\r\n                                                --account-server <account-server>\r\n                                                --tier {0,1,2,3} --encoding <M>+<N> \r\n                                                --failure-domain {0,1,2,3,4} --storage-type nfs\r\n                                                --nfs-host <host> --nfs-export <export>\r\n                                                --nfs-version <version> [--stdin]\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--name <name>\n\nBackup registration name.\n--address <address>\n\nBackup registration address.\n--location <location>\n\nBackup registration location.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--storage-type {local,nfs,s3,swift,azure,google}\n\nStorage type\n--stdin\n\nUse for setting registration password from stdin.\n\nStorage parameters for the nfs storage type:\n\n--nfs-host <host>\n\nNFS hostname or IP address\n--nfs-export <export>\n\nFull path to the NFS export\n--nfs-version <version>\n\nNFS version (3 or 4)\n\nFor example, to create the backup cluster from the node node001 on the NFS storage, run:# vinfra service backup cluster deploy-standalone --nodes node001 --name registration1 --address backupstorage.example.com \\\r\n--storage-type nfs --tier 0 --encoding 1+2 --failure-domain host --nfs-host 10.136.18.149 --nfs-version 4 \\\r\n--nfs-export /share1/export1 --username account@example.com --account-server https://cloud.acronis.com/ --stdin\nThis command also specifies the registration name and address, tier, failure domain, registration account and server, as well as the required NFS parameters.\nYou can view the backup storage details in the vinfra service backup cluster show output:# vinfra service backup cluster show\r\n+-----------------+---------------------------------------------+\r\n| Field           | Value                                       |\r\n+-----------------+---------------------------------------------+\r\n| dc_uid          | 966ac53e-a92c-11ec-be79-fa163ea9f01a        |\r\n| deployment_mode | - standalone                                |\r\n| geo_replication |                                             |\r\n| hosts           | - hostname: node001.vstoragedomain          |\r\n|                 |   id: 24a953ce-b50e-40c2-bf44-0668aafb421d  |\r\n|                 |   systemd: active                           |\r\n| registrations   | - account_server: https://cloud.acronis.com |\r\n|                 |   address: backupstorage.example.com        |\r\n|                 |   expires: '2025-03-20T15:20:59+00:00'      |\r\n|                 |   id: be526718-d9f8-4f2c-9bd3-04a987f7e4c4  |\r\n|                 |   name: registration1                       |\r\n|                 |   type: ABC                                 |\r\n|                 |   username: account@example.com             |\r\n| status          | deployed                                    |\r\n| storage_params  |                                             |\r\n| storage_type    | local                                       |\r\n| upstreams       | []                                          |\r\n+-----------------+---------------------------------------------+\r\n\n\nWhat's next\n\nAdding backup locations to Acronis Cyber Protect and Acronis Cyber Protect Cloud",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup cluster deploy-standalone --nodes <nodes> > --name <name> --address <address>\r\n                                                [--location <location>] --username <username>\r\n                                                --account-server <account-server>\r\n                                                --tier {0,1,2,3} --encoding <M>+<N> \r\n                                                --failure-domain {0,1,2,3,4} --storage-type nfs\r\n                                                --nfs-host <host> --nfs-export <export>\r\n                                                --nfs-version <version> [--stdin]\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n--name <name>\n\nBackup registration name.\n--address <address>\n\nBackup registration address.\n--location <location>\n\nBackup registration location.\n--username <username>\n\nPartner account in the cloud or of an organization administrator on the local management server.\n--account-server <account-server>\n\nURL of the cloud management portal or the hostname/IP address and port of the local management server.\n--tier {0,1,2,3}\n\nStorage tier\n--encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--storage-type {local,nfs,s3,swift,azure,google}\n\nStorage type\n--stdin\n\nUse for setting registration password from stdin.\n\nStorage parameters for the nfs storage type:\n\n--nfs-host <host>\n\nNFS hostname or IP address\n--nfs-export <export>\n\nFull path to the NFS export\n--nfs-version <version>\n\nNFS version (3 or 4)\n\nFor example, to create the backup cluster from the node node001 on the NFS storage, run:# vinfra service backup cluster deploy-standalone --nodes node001 --name registration1 --address backupstorage.example.com \\\r\n--storage-type nfs --tier 0 --encoding 1+2 --failure-domain host --nfs-host 10.136.18.149 --nfs-version 4 \\\r\n--nfs-export /share1/export1 --username account@example.com --account-server https://cloud.acronis.com/ --stdin\nThis command also specifies the registration name and address, tier, failure domain, registration account and server, as well as the required NFS parameters.\nYou can view the backup storage details in the vinfra service backup cluster show output:# vinfra service backup cluster show\r\n+-----------------+---------------------------------------------+\r\n| Field           | Value                                       |\r\n+-----------------+---------------------------------------------+\r\n| dc_uid          | 966ac53e-a92c-11ec-be79-fa163ea9f01a        |\r\n| deployment_mode | - standalone                                |\r\n| geo_replication |                                             |\r\n| hosts           | - hostname: node001.vstoragedomain          |\r\n|                 |   id: 24a953ce-b50e-40c2-bf44-0668aafb421d  |\r\n|                 |   systemd: active                           |\r\n| registrations   | - account_server: https://cloud.acronis.com |\r\n|                 |   address: backupstorage.example.com        |\r\n|                 |   expires: '2025-03-20T15:20:59+00:00'      |\r\n|                 |   id: be526718-d9f8-4f2c-9bd3-04a987f7e4c4  |\r\n|                 |   name: registration1                       |\r\n|                 |   type: ABC                                 |\r\n|                 |   username: account@example.com             |\r\n| status          | deployed                                    |\r\n| storage_params  |                                             |\r\n| storage_type    | local                                       |\r\n| upstreams       | []                                          |\r\n+-----------------+---------------------------------------------+\r\n\n",
                "title": "To select an external NFS share as the backup destination"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the Backup (ABGW) private and Backup (ABGW) public traffic types are added to the networks you intend to use.\nOpen the Storage services > Backup storage screen, and then click Create backup storage.\nOn the Backup destination step, select Network File System (NFS) share.\n\nOn the Nodes step, select one node to add to the backup storage cluster, and then click Next.\n\n\nOn the NFS share step, specify the hostname or IP address of the NFS share, the export name, and select the NFS version. Then, click Next.\nNFS version 4 is recommended, as it provides better scalability and performance compared to NFS version 3, which has limitations in the protocol.\n\n\n\n\n\n\nOn the DNS step, do one of the following:\n\n\nSelect Register now, and then specify an external DNS name for backup storage (for example, backupstorage.example.com). Backup agents will use this DNS name and the TCP port 44445 to upload backup data.\n\n\nConfigure your DNS server according to the example suggested in the admin panel.\nEach time you change the network configuration of nodes in the backup storage cluster, adjust the DNS records accordingly.\n\n\n\n\n\n\n\n\nSelect Register later to add registrations for your backup storage later or configure it as the secondary cluster for geo-replication.\n\n\n\n\nIf you selected Register now, specify the following information for your Acronis product on the Acronis account step:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\n\n\n\n\n\nOn the Summary step, review the configuration, and then click Create.\n\nAfter creating the backup storage, you can increase its storage capacity at any time by adding space to the NFS share.\n",
                "title": "To select an external NFS share as the backup destination"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-backup-storage-on-an-nfs-share.html"
    },
    {
        "title": "Managing S3 buckets",
        "content": "Managing S3 buckets\nAll objects in an Amazon S3-like storage are stored in containers called buckets. Buckets are addressed by names that are unique in the given object storage, so an S3 user of that object storage cannot create a bucket that has the same name as a different bucket in the same object storage. Buckets are used to:\n\nGroup and isolate objects from those in other buckets\nProvide ACL management mechanisms for objects in them\nSet per-bucket access policies for tasks such as versioning in the bucket\n\nYou can list S3 buckets and monitor the space used by them on the Storage services > S3 > Buckets screen. You cannot create and manage S3 buckets from the Virtuozzo Hybrid Infrastructure admin panel. However, you can access your S3 data in several ways:\n\nIn the self-service panel, as described in the Self-Service Guide.\nIn the legacy user panel or by using a third-party application, as described in the Storage User\u00e2\u0080\u0099s Guide.\n\nThird-party applications listed below allow you to perform the following actions:\n\nIn CyberDuck, you can create and manage buckets, and their contents.\nIn Mountain Duck, you can mount an object storage as a disk drive, manage buckets and their contents.\n\nPrerequisites\n\nS3 users are created, as described in Creating S3 users.\nA clear understanding of the best S3 practices, listed in Best practices for using S3 in Virtuozzo Hybrid Infrastructure.\n\nTo list bucket contents with a web browser\n\nVisit the URL that consists of the external DNS name for the S3 endpoint that you specified when creating the S3 cluster and the bucket name. For example, s3.example.com/mybucket or mybucket.s3.example.com (depending on DNS configuration).\nCopy the link to the bucket contents by right-clicking it in CyberDuck, and then selecting Copy URL.\n\nSee also\n\nSupported Amazon S3 features\n\nReplicating S3 data between datacenters\n\nChanging S3 protocol settings\n\nDefining object storage classes\n\nConfiguring bucket notifications\n\nMonitoring object storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-s3-buckets.html"
    },
    {
        "title": "Managing security group rules",
        "content": "Managing security group rules\nYou can modify security groups by adding and removing rules. Editing rules is not available. If you need to change the existing rule, remove it and re-create with the required parameters.\nPrerequisites\n\nYou have a security group created, as described in Creating and deleting security groups.\n\nTo add a rule to a security group\n\nOn the Security groups screen, click the security group to add a rule to.\nOn the group right pane, click Add in the Inbound or Outbound section to create a rule for incoming or outgoing traffic.\nSpecify the rule parameters:\r\n\t\t\tSelect a protocol from the list or enter a number from 0 to 255.Enter a single port or a port range. Some protocols already have a predefined port range. For example, the port for SSH is 22.Select a predefined subnet CIDR or an existing security group.\nClick the check mark to save the changes.\n\nAs soon as the rule is created, it is applied to all of the virtual machines assigned to the security group.\n\nTo remove a rule from a security group\n\nOn the Security groups screen, click the required security group.\nOn the group right pane, click the bin icon next to a rule you want to remove.\n\nAs soon as the rule is removed, this change is applied to all of the virtual machines assigned to the security group.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-security-group-rules.html"
    },
    {
        "title": "Enabling S3 users in WHMCS",
        "content": "Enabling S3 users in WHMCS\nYou can enable a previously disabled user with the ostor-users service and parameter emailAddress specifying the user email address. WHMCS enables read and write access to S3 cluster for user when you click Enable User. Create a file S3_enableUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Enable user.\r\nfunction S3_enableUser($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Enable user.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'] . \"&enable\",\r\n        \"POST\"\r\n    );\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_enableUser($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/enabling-s3-users-in-whmcs.html"
    },
    {
        "title": "1. What is Leostream?\u00c2\u00b6",
        "content": "1. What is Leostream? | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n1. What is Leostream?\u00c2\u00b6\nLeostream is a VDI/DaaS management solution which enables cloud service providers and managed service providers to create, secure and manage multi-tenant Virtual Desktop Infrastructure (VDI)environments and offer Desktop as a Service, running on top of Virtuozzo Hybrid Infrastructure Platform.\nIn this integration Virtuozzo Hybrid Infrastructure will act as an Infrastructure service provider (IaaS) for Leostream, which will:\n\nIntegrate with Identity Providers such as Active Directory and LDAP to authenticate users accessing the VDI environment and provide domain authentication to your Virtual Desktops.\nSupport Multi Factor Authentication (MFA) providers such as Duo, Ping ID and Okta.\nLeverage your corporate Identity Provider (IdP) for authentication into your Leostream environment, using Leostream\u00e2\u0080\u0099s support for the SAML protocol.\nCreate pools of virtual desktops based on a golden image.\nAutomatically scale up and scale down your virtual desktop pools.\nAutomatically join provisioned virtual desktops to your Active Directory domain.\nManage multiple virtual desktop infrastructure tenants.\nManage the lifecycle of virtual desktops in your pools, including power state and termination.\nManage multiple clouds or infrastructure as a service (IaaS) providers from a single console.\nGranularly define virtual desktop access control rules and assignment by leveraging, Leostream policies, plans, and assignments.\nClientless access and multiple display protocol support for HTML5-based RDP, VNC, and SSH viewer.\nMonitor Leostream environments using SMTP and get updates via e-mail.\nManage user access based on location, for example internal vs external network.\nGenerate reports for resource usage, login history, assignment, and Leostream Connection Broker metrics.\n\n1.1. Leostream Platform Components\u00c2\u00b6\nThe Leostream Connection Broker: The backbone of the Leostream platform. From the Leostream Connection Broker you can manage and configure your virtual desktop infrastructure. The Leostream Connection Broker is also responsible for authenticating the user, offering resources (Desktops), assigning virtual desktops, and managing their lifecycle when they are returned to the pool by applying release and power policies.\nThe Leostream Gateway: A secure gateway that provides access to Virtual Desktops behind a secured zone. Clients, can access remote desktops via the gateway using the HTML5-based web interface which has support for SSH, RDP or VNC protocols and allows you to access remote desktops via the web interface and without the Leostream Connect App. If using the Leostream Connect App clients can connect to the remote desktops using the following protocols RDP, VNC, NoMachine or Mechdyne GTX amongst others.\nThe Leostream Agent: This component is installed on the Virtual Desktops and provides information to the Leostream Connection Broker about, connected users, actions such as login, reboot etc. This information is used by the Leostream Connection Broker to understand the status of a remote Virtual Desktop, also enables features such as USB device passthrough and network printer redirection. The agent is available for Linux, Windows, and MacOS Operating Systems. For more details see Leostream Agent Administrator\u00e2\u0080\u0099s Guide.\nThe Leostream Connect App: The connect software is a client provided by Leostream that allows users to connect to Remote Desktops. For more details, see the Leostream Connect Administrator\u00e2\u0080\u0099s Guide.\nDatabase: The Leostream Connection Broker stores all the information on a Database and for large scale deployments an external Database is recommended. PostgreSQL, Azure SQL, or Microsoft SQL Server are supported.\nArchitectural Overview\nThe following figure shows a high-level architecture overview for a typical Leostream deployment on Virtuozzo Hybrid Infrastructure.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/what-is-leostream.html"
    },
    {
        "title": "DELETE service ostor-limits",
        "content": "DELETE service ostor-limits\nDescription\nSets a limit of the selected type to 0.0 (unlimited) for the specified user or bucket.\nRequests\nSyntaxDELETE /?ostor-limits&emailAddress=<value>&ops HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>DELETE /?ostor-limits&id=<value>&ops HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>DELETE /?ostor-limits&bucket=<value>&bandwidth HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nDELETE service ostor-limits parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nYes*\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes*\n\nops\n\nRemoves operations limits.\n\nNo\n\nbandwidth\n\nRemoves bandwidth limits.\n\nNo\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nIf limits are successfully removed, Status204NoContent will be returned.\nExamples\nSample request #1\nDeletes all operations limits for a user with the email user1@email.com.DELETE /?ostor-limits&emailAddress=user1@email.com&ops HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample response #1HTTP/1.1 204 No Content\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/json\nSample request #2\nRemoves bandwidth limits for the bucket testbucket.DELETE /?ostor-limits&bucket=testbucket&bandwidth HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 204 No Content\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/json",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/delete-service-ostor-limits.html"
    },
    {
        "title": "Managing S3 users and listing buckets via REST API",
        "content": "Managing S3 users and listing buckets via REST API\nThis section describes how to manage users via the REST API in a service provider scenario. New customers will sign up for the service during purchase in your online store and you will need to create users for them in the S3 cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-users-and-listing-buckets-via-rest-api.html"
    },
    {
        "title": "Updating volume names",
        "content": "Updating volume namesPUT /v3/{project_id}/volumes/{volume_id}\r\n\nUpdate the name of a volume with the specified ID.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=update-a-volume-detail#update-a-volume\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nvolume_id\n\npath\nstring\nThe UUID of the volume.\n\nvolume\n\nbody\nobject\nA volume object.\n\nname (Optional)\nbody\nstring\nThe volume name.\n\ndescription (Optional)\nbody\nstring\nThe volume description.\n\nmetadata (Optional)\nbody\nobject\nOne or more metadata key and value pairs to be associated\r\nwith the new volume.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"volume\": {\r\n    \"name\": \"vol3\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvolume\n\nbody\nobject\nA volume object.\n\nmigration_status (Optional)\nbody\nstring\nThe volume migration status. Admin only.\n\nattachments\n\nbody\narray\n\nInstance attachment information.  If this volume\r\nis attached to a server instance, the attachments list includes\r\nthe UUID of the attached server, an attachment UUID, the name of\r\nthe attached host, if any, the volume UUID, the device, and the\r\ndevice UUID.  Otherwise, this list is empty. For example:\n\n[\r\n  {\r\n    'server_id': '6c8cf6e0-4c8f-442f-9196-9679737feec6',\r\n    'attachment_id': '3dafcac4-1cb9-4b60-a227-d729baa10cf6',\r\n    'attached_at': '2019-09-30T19:30:34.000000',\r\n    'host_name': null,\r\n    'volume_id': '5d95d5ee-4bdd-4452-b9d7-d44ca10d3d53',\r\n    'device': '/dev/vda',\r\n    'id': '5d95d5ee-4bdd-4452-b9d7-d44ca10d3d53'\r\n  }\r\n]\r\n\n\nid\n\nbody\nstring\nThe UUID of the volume.\n\nlinks\n\nbody\narray\nThe volume links.\n\nname\n\nbody\nstring\nThe volume name.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\nbootable\n\nbody\nstring\nEnables or disables the bootable attribute. You\r\ncan boot an instance from a bootable volume.\n\nstatus\n\nbody\nstring\nThe volume status.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\navailability_zone (Optional)\nbody\nstring\nThe name of the availability zone.\n\ndescription\n\nbody\nstring\nThe volume description.\n\nmultiattach\n\nbody\nboolean\nIf true, this volume can attach to more than one\r\ninstance.\n\nsource_volid (Optional)\nbody\nstring\nThe UUID of the source volume. The API creates a new volume with the same\r\nsize as the source volume unless a larger size is requested.\n\nvolume_type\n\nbody\nstring\nThe associated volume type name for the volume.\n\nencrypted\n\nbody\nboolean\nIf true, this volume is encrypted.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nreplication_status\n\nbody\nstring\nThe volume replication status.\n\nsnapshot_id (Optional)\nbody\nstring\nTo create a volume from an existing snapshot,\r\nspecify the UUID of the volume snapshot. The volume is created in\r\nsame availability zone and with same size as the snapshot.\n\nuser_id\n\nbody\nstring\nThe UUID of the user.\n\nmetadata\n\nbody\nobject\nA metadata object. Contains one or more\r\nmetadata key and value pairs that are associated with the volume.\n\nconsistencygroup_id\n\nbody\nstring\nThe UUID of the consistency group.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nExample{\r\n  \"volume\": {\r\n    \"status\": \"available\",\r\n    \"migration_status\": null,\r\n    \"user_id\": \"eb481bff7b7c4ec6a686646957d8064b\",\r\n    \"attachments\": [],\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8776/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"availability_zone\": \"nova\",\r\n    \"bootable\": \"false\",\r\n    \"encrypted\": false,\r\n    \"created_at\": \"2020-03-11T12:15:14.476003\",\r\n    \"description\": \"Volume 2\",\r\n    \"updated_at\": \"2020-03-11T12:15:19.108340\",\r\n    \"volume_type\": \"policy1\",\r\n    \"name\": \"vol3\",\r\n    \"replication_status\": null,\r\n    \"consistencygroup_id\": null,\r\n    \"source_volid\": null,\r\n    \"snapshot_id\": null,\r\n    \"multiattach\": false,\r\n    \"metadata\": {},\r\n    \"id\": \"de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n    \"size\": 1\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-volume-names.html"
    },
    {
        "title": "3. Providing Access to Hystax Acura Portal\u00c2\u00b6",
        "content": "3. Providing Access to Hystax Acura Portal | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nPrev\nNext\n\n3. Providing Access to Hystax Acura Portal\u00c2\u00b6\nIn order to allow users to manage their migration workloads, we can create a user with project scope from the Hystax Acura web interface.\n\nLogin to the Hystax Acura Solution web interface and click on the Settings tab on the left-hand side. Then click on Roles and click Add.\n\nAssign the necessary permissions to the role. We will provide full access to the TriangleCakes target cloud.\n\nNow we will add a new user. Click Users and then click Add. Fill in all the information and select the Customer:Customer name as Organization.\n\nClick on the newly create user in order to assign a role to the user.\n\nClick Add in the Role section and add the role.\n\nThe user, at this point, will be able to login to the Hystax Acura web interface and perform and the Migration as a Service (self-service migration).\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/portal-access.html"
    },
    {
        "title": "GET service ostor-limits",
        "content": "GET service ostor-limits\nDescription\nLists information about limits on operations and bandwidth for the specified user or bucket.\nRequests\nSyntaxGET /?ostor-limits&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-limits&bucket=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nGET service ostor-limits parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nYes*\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes*\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nA JSON dictionary with information about limits for a user or bucket in the following format:{\r\n\"ops:default\" : \"<default_limit_value_in_ops/sec>\",\r\n\"ops:get\" : \"<get_ops_limit_value_in_ops/sec>\",\r\n\"ops:put\" : \"<put_ops_limit_value_in_ops/sec>\",\r\n\"ops:list\" : \"<list_ops_limit_value_in_ops/sec>\",\r\n\"ops:delete\" : \"<delete_ops_limit_value_in_ops/sec>\",\r\n\"bandwidth:out\" : \"<bandwidth_limit_value_in_kb/sec>\",\r\n}\nZero value means \u00e2\u0080\u009cunlimited\u00e2\u0080\u009d.\nErrors\nReturns Error Code 400 if multiple parameters are set at once.\nThe limits are disabled by default. If limits for a user/bucket requested are disabled, an error will be returned. Use PUT ostor-limits to enable limits.\nExamples\nSample request #1\nReturns information about limits for the user with the email user1@email.com.GET /?ostor-limits&emailAddress=user1@email.com HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 07 Apr 2016 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample response #1HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/json\r\n{\r\n\"ops:default\" : \"0.50\",\r\n\"ops:get\" : \"0.50\",\r\n\"ops:put\" : \"0.50\",\r\n\"ops:list\" : \"0.50\",\r\n\"ops:delete\" : \"0.50\",\r\n\"bandwidth:out\" : \"0\"\r\n}\nSample request #2\nReturns information about limits for the bucket bucket-1.GET /?ostor-limits&bucket=bucket-1 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 30 Apr 2016 22:32:00 GMT\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : closed\r\nx-amz-request-id : 80000000000000030003c6b538eedd95\r\nDate: Wed, 30 Apr 2016 22:32:00 GMT\r\nContent-type : application/json\r\n{\r\n\"ops:default\" : \"0\",\r\n\"ops:get\" : \"0\",\r\n\"ops:put\" : \"0\",\r\n\"ops:list\" : \"0\",\r\n\"ops:delete\" : \"0\",\r\n\"bandwidth:out\" : \"3.33\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/get-service-ostor-limits.html"
    },
    {
        "title": "Adding SSH keys for virtual machines",
        "content": "Adding SSH keys for virtual machines\nUse of SSH keys allows you to secure SSH access to virtual machines. You can generate a key pair on a client from which you will connect to VMs via SSH. The private key will be stored on the client and you will be able to copy it to other nodes. The public key will need to be uploaded to Virtuozzo Hybrid Infrastructure and specified during VM creation. It will be injected into the VM by cloud-init and used for OpenSSH authentication. Keys injection is supported for both Linux and Windows virtual machines.\nLimitations\n\nYou can specify an SSH key only if you deploy a VM from a template or boot volume (not an ISO image).\nIf a key has been injected into one or more VMs, it will remain inside those VMs even if you delete it from the panel.\n\nPrerequisites\n\nThe cloud-init utility and OpenSSH Server are installed in a VM template or boot volume, as instructed in Preparing templates.\n\nTo add a public key\n\nAdmin panel\n\nGenerate an SSH key pair on a client by using the ssh-keygen utility:# ssh-keygen -t rsa\n\nOn the Compute > Virtual machines > SSH keys tab, click Add key.\n\nIn the Add SSH key window, specify a key name and copy the key value from the generated public key located in /root/.ssh/id_rsa.pub. Optionally, you can add a key description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nCommand-line interface\n\nGenerate an SSH key pair on a client by using the ssh-keygen utility:# ssh-keygen -t rsa\r\n\n\nUpload the public key to the compute cluster. For example, to create a public SSH key called mykey, run:# vinfra service compute key create --public-key /root/.ssh/id_rsa.pub mykey\r\n\n\nThe new SSH key will appear in the vinfra service compute key list output:# vinfra service compute key list\r\n+-------+-------------+----------------------------------+\r\n| name  | description | created_at                       |\r\n+-------+-------------+----------------------------------+\r\n| mykey |             | 2021-06-15T12:24:27.814043+00:00 |\r\n+-------+-------------+----------------------------------+\r\n\n\nTo delete a public key\n\nAdmin panel\n\nOn the Compute > Virtual machines > SSH keys tab, select the SSH key you want to delete, and then click Delete.\nClick Delete in the confirmation window.\n\nIf this key has been injected into one or more virtual machines, it will remain inside those virtual machines.\n\nCommand-line interface\nUse the following command:vinfra service compute key delete <ssh-key>\r\n\n\n<ssh-key>\n\nSSH key name\n\nFor example, to delete the SSH key mykey, run:# vinfra service compute key delete mykey\n\nSee also\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nGenerate an SSH key pair on a client by using the ssh-keygen utility:# ssh-keygen -t rsa\r\n\n\n\nUpload the public key to the compute cluster. For example, to create a public SSH key called mykey, run:# vinfra service compute key create --public-key /root/.ssh/id_rsa.pub mykey\r\n\n\n\nThe new SSH key will appear in the vinfra service compute key list output:# vinfra service compute key list\r\n+-------+-------------+----------------------------------+\r\n| name  | description | created_at                       |\r\n+-------+-------------+----------------------------------+\r\n| mykey |             | 2021-06-15T12:24:27.814043+00:00 |\r\n+-------+-------------+----------------------------------+\r\n\n",
                "title": "To add a public key"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute key delete <ssh-key>\r\n\n\n<ssh-key>\n\nSSH key name\n\nFor example, to delete the SSH key mykey, run:# vinfra service compute key delete mykey\n",
                "title": "To delete a public key"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nGenerate an SSH key pair on a client by using the ssh-keygen utility:# ssh-keygen -t rsa\n\nOn the Compute > Virtual machines > SSH keys tab, click Add key.\n\nIn the Add SSH key window, specify a key name and copy the key value from the generated public key located in /root/.ssh/id_rsa.pub. Optionally, you can add a key description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n\n\n\n\n",
                "title": "To add a public key"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > SSH keys tab, select the SSH key you want to delete, and then click Delete.\nClick Delete in the confirmation window.\n\nIf this key has been injected into one or more virtual machines, it will remain inside those virtual machines.\n",
                "title": "To delete a public key"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-ssh-keys.html"
    },
    {
        "title": "Listing Kubernetes clusters",
        "content": "Listing Kubernetes clustersGET /v1/clusters\r\n\nList all Kubernetes clusters.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=list-all-clusters-detail#list-all-clusters\nRequest\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAAB<...>' \\\r\nhttps://<node_IP_addr>:9513/v1/clusters\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nclusters\n\nbody\narray\nThe list of all clusters in Magnum.\n\nstatus\n\nbody\nstring\nThe current state of the bay/cluster.\n\nuuid\n\nbody\nUUID\nThe UUID of the cluster.\n\nlinks\n\nbody\narray\nLinks to the resources in question.\n\nstack_id\n\nbody\nUUID\nThe reference UUID of orchestration stack from Heat orchestration service.\n\nname\n\nbody\nstring\nName of the resource.\n\nmaster_count\n\nbody\ninteger\nThe number of servers that will serve as master for the bay/cluster. The\r\ndefault is 1. Set to more than 1 master to enable High Availability. If\r\nthe option master-lb-enabled is specified in the baymodel/cluster\r\ntemplate, the master servers will be placed in a load balancer pool.\n\ncluster_template_id\n\nbody\nUUID\nThe UUID of the cluster template.\n\nnode_count\n\nbody\ninteger\nThe number of servers that will serve as node in the bay/cluster. The\r\ndefault is 1.\n\nkeypair\n\nbody\nstring\nThe name of the SSH keypair to configure in the bay/cluster servers\r\nfor ssh access. Users will need the key to be able to ssh to the servers in\r\nthe bay/cluster. The login name is specific to the bay/cluster driver, for\r\nexample with fedora-atomic image, default login name is fedora.\n\ncreate_timeout\n\nbody\ninteger\nThe timeout for cluster creation in minutes. The value expected is a\r\npositive integer and the default is 60 minutes. If the timeout is reached\r\nduring cluster creation process, the operation will be aborted and the\r\ncluster status will be set to CREATE_FAILED.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"clusters\": [\r\n    {\r\n      \"status\": \"CREATE_COMPLETE\",\r\n      \"cluster_template_id\": \"4aceb259-3799-4a6a-85ef-7f9857b41462\",\r\n      \"uuid\": \"01d0583d-e8b3-483f-896f-08d2260b0dea\",\r\n      \"docker_volume_size\": 10,\r\n      \"stack_id\": \"dbfad3ec-2caf-43ef-839b-3c8dc0bdb1f8\",\r\n      \"template_delete_on_termination\": false,\r\n      \"health_status\": \"HEALTHY\",\r\n      \"labels\": {\r\n        \"cloud_provider_enabled\": \"true\",\r\n        \"cloud_provider_tag\": \"v1.15.0\",\r\n        \"heat_container_agent_tag\": \"hci-3.5-latest\",\r\n        \"kube_version\": \"v1.15.6\",\r\n        \"boot_volume_type\": \"default\",\r\n        \"flannel_tag\": \"v0.11.0-amd64\",\r\n        \"boot_volume_size\": \"10\",\r\n        \"kube_tag\": \"v1.15.6\",\r\n        \"docker_volume_type\": \"default\"\r\n      },\r\n      \"keypair\": \"key1\",\r\n      \"links\": [\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:9513/v1/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea\",\r\n          \"rel\": \"self\"\r\n        },\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:9513/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea\",\r\n          \"rel\": \"bookmark\"\r\n        }\r\n      ],\r\n      \"master_count\": 2,\r\n      \"flavor_id\": \"small\",\r\n      \"node_count\": 1,\r\n      \"master_flavor_id\": \"medium\",\r\n      \"create_timeout\": 60,\r\n      \"name\": \"k8s1\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-kubernetes-clusters.html"
    },
    {
        "title": "Preparing the bootable media",
        "content": "Preparing the bootable media\nYou can install Virtuozzo Hybrid Infrastructure  from the following bootable media:\n\nUSB drives, if you can access the server physically\nIntelligent Platform Management Interface (IPMI) virtual drives, if the server  is configured for remote out-of-band management via the IPMI ports\nPreboot execution environment (PXE) server, if you want to boot over a network",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-the-bootable-media.html"
    },
    {
        "title": "Changing virtual machine resources",
        "content": "Changing virtual machine resources\nYou can change amount of CPU and RAM resources used by a virtual machine by applying another flavor to it. To be able to resize a running VM, you need to enable CPU and RAM hot plug for it first. You can change the hot plug settings for both new and existing VMs.\nA running virtual machine has a resize limit, which defines the maximum number of vCPUs and the maximum amount of RAM you can allocate to the VM. The resize limit on vCPUs is static and equal to 64 for all VMs. The resize limit on RAM, on the contrary, is dynamic and depends on the amount of RAM a running VM is currently using. This limit is updated on a VM startup, and its values are listed in the table below.\n\nCurrent RAM size, in GiB\nRAM size limit, in GiB\n\n1-4\n16\n\n5-8\n32\n\n9-16\n64\n\n17-32\n128\n\n33-64\n256\n\n65-128\n512\n\n129-256\n1024\n\nFor example, you can resize a running VM with a flavor that has 16 GiB to a flavor with 256 GiB in two iterations:\n\nResize the VM to a flavor with 64 GiB.\nRestart the VM to update the RAM size limit.\nResize the VM to a flavor with 256 GiB.\n\nLimitations\n\nYou cannot change the flavor for shelved VMs. To resize such a VM, unshelve it first.\nYou cannot decrease the number of CPUs and the amount of RAM for running VMs.\n\n[For all Linux guests] If a VM has no guest tools installed, new cores may be offline after CPU hot plugging\n\nYou can verify which CPU cores are online by using the command:# cat /sys/devices/system/cpu/online\nTo activate offline CPU cores, run:# echo 1 > /sys/devices/system/cpu/cpu<cpu_number>/online\n\nPrerequisites\n\nBefore changing a flavor, ensure that the node hosting the VM has at least as much free CPU and RAM resources as the new VM size. For example, to resize a VM to the large flavor, the host must have at least 4 vCPUs and 8 GiB of RAM free.\nCPU and RAM hot plug is enabled by the system administrator.\nBefore resizing a running VM, ensure that the guest operating system supports CPU and RAM hot plug (refer to Supported guest operating systems). Note that otherwise the guest operating system may become unstable after a resize. To increase CPU or RAM resources for such a guest operating system, you need to stop the virtual machine first.\nBefore resizing a running VM, ensure that the guest operating system has the latest updates installed.\n\nTo enable or disable CPU and RAM hot plug for a virtual machine\n\nOn the Virtual machines screen, ensure that the required virtual machine in the \"Shut down\" state, and then click it.\n\nOn the Overview tab, click the pencil icon in the CPU and RAM hot plug field.\n\nIf you do not see this field, CPU and RAM hot plug is disabled in your project. To enable it, contact your system administrator.\n\nSelect or clear the Enable hot plug check box, and then click the tick icon to save the changes.\n\nWith CPU and RAM hot plug enabled, you can change the flavor of a running VM.\n\nTo change the virtual machine flavor\n\nOn the Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Flavor field.\nIn the Flavor window, select a new flavor, and then click Done.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/changing-vm-resources.html"
    },
    {
        "title": "Releasing nodes from the compute cluster",
        "content": "Releasing nodes from the compute cluster\nIf you need to release compute nodes, you can start with regular (non-management) nodes. When all of the regular compute nodes are released, you can proceed to remove the management nodes. The management nodes can only be released together. Their release destroys the compute cluster.\nLimitations\n\nThe compute cluster must have at least three nodes to allow self-service users to enable high availability for Kubernetes master nodes.\n\nPrerequisites\n\nA clear understanding of the limitations listed in High availability and the compute cluster.\nIf the node hosts virtual machines, they should be migrated to other nodes, as described in Migrating virtual machines.\nTo destroy the compute cluster, all virtual machines must be deleted.\n\nTo release nodes from the compute cluster\n\nAdmin panel\n\nOn the Compute > Nodes screen, do one of the following:Select the nodes, and then click Release nodes above the list.Click the ellipsis icon next to a node and select Release.Click a node to open its details, and then click Release node on the node right pane.\nIn the Release node window, confirm the action by clicking Release.\n\nThe selected nodes will disappear from the Nodes screen. If you selected all of the compute nodes, the compute cluster will be destroyed.\n\nCommand-line interface\nUse the following command:vinfra service compute node release [--compute] [--controller] <node>\r\n\n\n--compute\n\nCompute node role\n--controller\n\nCompute controller node role\n<node>\n\nNode ID or hostname\n\nFor example, to release the node node005.vstoragedomain from the compute cluster, run:# vinfra service compute node release node005.vstoragedomain\nThe removed node will disappear from the vinfra service compute node list output:# vinfra service compute node list\r\n+------------------+------------------------+---------+--------------+\r\n| id               | host                   | state   | roles        |\r\n+------------------+------------------------+---------+--------------+\r\n| 7ffa9540-5a20<\u00e2\u0080\u00a6> | node001.vstoragedomain | healthy | - controller |\r\n|                  |                        |         | - compute    |\r\n| 6e8afc28-7f71<\u00e2\u0080\u00a6> | node002.vstoragedomain | healthy | - compute    |\r\n| 02ff64ae-5800<\u00e2\u0080\u00a6> | node003.vstoragedomain | healthy | - compute    |\r\n| 827a1f4e-56e5<\u00e2\u0080\u00a6> | node004.vstoragedomain | healthy | - compute    |\r\n+------------------+------------------------+---------+--------------+\nTo release all nodes from the compute cluster, use the following command:vinfra service compute delete\r\n\n\nSee also\n\nAdding nodes to the compute cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute node release [--compute] [--controller] <node>\r\n\n\n--compute\n\nCompute node role\n--controller\n\nCompute controller node role\n<node>\n\nNode ID or hostname\n\nFor example, to release the node node005.vstoragedomain from the compute cluster, run:# vinfra service compute node release node005.vstoragedomain\nThe removed node will disappear from the vinfra service compute node list output:# vinfra service compute node list\r\n+------------------+------------------------+---------+--------------+\r\n| id               | host                   | state   | roles        |\r\n+------------------+------------------------+---------+--------------+\r\n| 7ffa9540-5a20<\u00e2\u0080\u00a6> | node001.vstoragedomain | healthy | - controller |\r\n|                  |                        |         | - compute    |\r\n| 6e8afc28-7f71<\u00e2\u0080\u00a6> | node002.vstoragedomain | healthy | - compute    |\r\n| 02ff64ae-5800<\u00e2\u0080\u00a6> | node003.vstoragedomain | healthy | - compute    |\r\n| 827a1f4e-56e5<\u00e2\u0080\u00a6> | node004.vstoragedomain | healthy | - compute    |\r\n+------------------+------------------------+---------+--------------+\nTo release all nodes from the compute cluster, use the following command:vinfra service compute delete\r\n\n",
                "title": "To release nodes from the compute cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Nodes screen, do one of the following:Select the nodes, and then click Release nodes above the list.Click the ellipsis icon next to a node and select Release.Click a node to open its details, and then click Release node on the node right pane.\nIn the Release node window, confirm the action by clicking Release.\n\nThe selected nodes will disappear from the Nodes screen. If you selected all of the compute nodes, the compute cluster will be destroyed.\n",
                "title": "To release nodes from the compute cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/releasing-compute-nodes.html"
    },
    {
        "title": "Managing traffic types",
        "content": "Managing traffic types\nYou can manage three groups of traffic types: two default groups, exclusive and regular, created with the infrastructure and custom traffic types created by users. The available actions depend on the traffic type group.\nPrerequisites\n\nA clear understanding of the concept Traffic types.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-traffic-types.html"
    },
    {
        "title": "Supported Amazon S3 REST operations",
        "content": "Supported Amazon S3 REST operations\nThe following Amazon S3 REST operations are currently supported by the Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol:\nSupported service operations: GET Service.\n\nSupported bucket operations\n\nResource\nDescription\nMethod\n\nCreation\nCreates a new S3 bucket\nCreateBucket (PUT)\n\nDeletion\nDeletes an existing S3 bucket\nDeleteBucket (DELETE)\n\nListing\nLists all buckets owned by the authenticated sender\nListBuckets (GET)\n\nListing\nLists some or all of the objects in a bucket\nListObjects (GET)\n\nACL\nReturns the access control list (ACL) of a bucket\nGetBucketAcl (GET)\n\nACL\nSets the access control list (ACL) permissions for a bucket\nPutBucketAcl (PUT)\n\nPolicy\nRetrieves the policy for a specified bucket\nGetBucketPolicy (GET)\n\nPolicy\nSets the policy for a specified bucket\nPutBucketPolicy (PUT)\n\nPolicy\nDeletes the policy of a bucket\nDeleteBucketPolicy (DELETE)\n\nCORS\nRetrieves the CORS configuration for a bucket\nGetBucketCors (GET)\n\nCORS\nSets the CORS configuration for a bucket\nPutBucketCors (PUT)\n\nCORS\nDeletes the CORS configuration from a bucket\nDeleteBucketCors (DELETE)\n\nLocation\nReturns the region where the bucket resides\nGetBucketLocation (GET)\n\nLogging\nReturns the logging status of a bucket\nGetBucketLogging (GET)\n\nLogging\nSets the logging parameters for a bucket\nPutBucketLogging (PUT)\n\nVersioning\nReturns the versioning state of a bucket\nGetBucketVersioning (GET)\n\nVersioning\nSets the versioning state of a bucket\nPutBucketVersioning (PUT)\n\nLifecycle\nSets lifecycle configuration for your bucket\nPutBucketLifecycle (PUT)\n\nLifecycle\nReturns the lifecycle configuration information set on the bucket\nGetBucketLifecycle (GET)\n\nLifecycle\nDeletes the lifecycle configuration from the bucket\nDeleteBucketLifecycle (DELETE)\n\nNotification\nEnables notifications of specified events for a bucket\nPutBucketNotification (PUT)\n\nNotification\nReturns the notification configuration of a bucket\nGetBucketNotification (GET)\n\nReplication\nSets the replication configuration for a bucket\nPutBucketReplication (PUT)\n\nReplication\nRetrieves the replication configuration of a bucket\nGetBucketReplication (GET)\n\nReplication\nDeletes the replication configuration from the bucket\nDeleteBucketReplication (DELETE)\n\nLock\nPlaces an object lock configuration on a bucket\nPutObjectLockConfiguration (PUT)\n\nLock\nRetrieves the object lock configuration for a bucket\nGetObjectLockConfiguration (GET)\n\nSupported object operations\n\nResource\nDescription\nMethod\n\nStorage\nAdds an object to a bucket\nPutObject (PUT)\n\nRetrieval\nRetrieves objects from a bucket\nGetObject (GET)\n\nDeletion\nRemoves an object from a bucket\nDeleteObject (DELETE)\n\nCopying\nCreates a copy of an object that is already stored in Amazon S3\nCopyObject (PUT)\n\nMetadata\nRetrieves metadata from an object without returning the object\nHeadObject (HEAD)\n\nACL\nReturns the access control list (ACL) of an object\nGetObjectAcl (GET)\n\nACL\nSets the access control list (ACL) permissions for an object\nPutObjectAcl (PUT)\n\nMultipart\nInitiates a multipart upload and returns an upload ID\nInitiateMultipartUpload (POST)\n\nMultipart\nUploads a part in a multipart upload\nUploadPart (PUT)\n\nMultipart\nCompletes a multipart upload by assembling previously uploaded parts\nCompleteMultipartUpload (POST)\n\nMultipart\nAborts a multipart upload\nAbortMultipartUpload (DELETE)\n\nMultipart\nLists in-progress multipart uploads\nListMultipartUploads (GET)\n\nMultipart\nLists the parts that have been uploaded for a specific multipart upload\nListParts (GET)\n\nRetention\nPlaces retention settings on an object\nPutObjectRetention (PUT)\n\nRetention\nRetrieves retention settings for an object\nGetObjectRetention (GET)\n\nLegal Hold\nApplies a legal hold on an object\nPutObjectLegalHold (PUT)\n\nLegal Hold\nRetrieves the legal hold status of an object\nGetObjectLegalHold (GET)\n\nRestoration\nRestores an archived copy of an object\nRestoreObject (POST)\n\nFor more information about Amazon S3 REST error response headers, refer to Amazon S3 REST API documentation.\n\nSee also\n\nSupported Amazon request headers\n\nSupported Amazon response headers\n\nSupported Amazon error response headers\n\nSupported authentication schemes\n\nAmazon S3 features supported by bucket policies\n\nSupported Amazon S3 object expiration actions",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-s3-rest-operations.html"
    },
    {
        "title": "12.1. Creating Pools\u00c2\u00b6",
        "content": "12.1. Creating Pools | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n12.1. Creating Pools\u00c2\u00b6\nWhen using Leostream to provision new instances in Virtuozzo Hybrid Infrastructure, the key is to construct your pool in a way that ensures that newly provisioned desktops become members of that pool. One method is to set the pool to contain all instances in the Virtuozzo Hybrid Infrastructure project associated with the center you created in the previous chapter.\nIf that pool definition is too broad, another easy way to ensure that new desktops become part of a pool is to define the pool based on the instance name, which you set during provisioning, for example:\n\nGo to the Configuration > Pools page.\nClick the Create Pool link. The Create Pool form opens.\nEnter a name for the pool in the Name edit field.\nIn the first row of the Desktop Attribute Selection section:\n\nSelect Name from the Desktop attribute drop-down menu.\nSelect begins with from the Conditional drop-down menu.\nIn the Text value field, enter the name you will use for all the instances in this pool. For example, the following form looks for virtual machines with a name that contains the text desktop.\n\nClick Save to save the pool.\n\nFor a complete description of creating pools, see the \u00e2\u0080\u009cCreating Desktop Pools\u00e2\u0080\u009d chapter in the Connection Broker Administrator\u00e2\u0080\u0099s Guide.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/pooling-and-provisioning/creating-pools.html"
    },
    {
        "title": "Attaching and detaching volumes",
        "content": "Attaching and detaching volumes\nLimitations\n\nYou can only attach and detach non-boot volumes.\n\nPrerequisites\n\nA volume is created, as described in Creating and deleting volumes.\nTo be able to use volumes attached to VMs, they must be initialized inside the guest OS by standard means.\n\nTo attach a volume to a virtual machine\n\nAdmin panel\n\nOn the Compute > Storage > Volumes screen, click an unused volume.\nOn the volume right pane, click Attach.\n\nIn the Attach volume window, select the VM from the drop-down list, and then click Done.\n\nCommand-line interface\nUse the following command:vinfra service compute server volume attach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to attach the available volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba to the virtual machine myvm, run:# vinfra service compute server volume attach e4cb5363-1fb2-41f5-b24b-18f98a388cba --server myvm\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/vdb                             |\r\n| id     | e4cb5363-1fb2-41f5-b24b-18f98a388cba |\r\n+--------+--------------------------------------+\r\n\nThe name of the new device will be shown in the command output. To see all of the VM volumes, run:# vinfra service compute server volume list --server myvm\r\n+--------------------------------------+----------+\r\n| id                                   | device   |\r\n+--------------------------------------+----------+\r\n| e4cb5363-1fb2-41f5-b24b-18f98a388cba | /dev/vdb |\r\n| b325cc6e-8de1-4b6c-9807-5a497e3da7e3 | /dev/vda |\r\n+--------------------------------------+----------+\r\n\n\nTo detach a volume from a virtual machine\n\nAdmin panel\n\nOn the Compute > Storage > Volumes screen, click a volume that is in use.\nIf the VM is stopped, click Detach on the volume right pane.\n\nIf the VM is running, click Force detach on the volume right pane.\n\nThere is a risk of data loss.\n\nCommand-line interface\nUse the following command:vinfra service compute server volume detach [--force] --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n--force\n\nDetach a volume without checking if either the volume or server exists. When specifying the volume and server, use their IDs. No name lookup is performed.\n<volume>\n\nVolume ID or name\n\nFor example, to detach the volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba from the virtual machine myvm, run:# vinfra service compute server volume detach e4cb5363-1fb2-41f5-b24b-18f98a388cba \\\r\n--server 871fef54-519b-4111-b18d-d2039e2410a8\n\nSee also\n\nResizing volumes\n\nChanging the storage policy for volumes\n\nCloning volumes\n\nManaging volume snapshots",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server volume attach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to attach the available volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba to the virtual machine myvm, run:# vinfra service compute server volume attach e4cb5363-1fb2-41f5-b24b-18f98a388cba --server myvm\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/vdb                             |\r\n| id     | e4cb5363-1fb2-41f5-b24b-18f98a388cba |\r\n+--------+--------------------------------------+\r\n\nThe name of the new device will be shown in the command output. To see all of the VM volumes, run:# vinfra service compute server volume list --server myvm\r\n+--------------------------------------+----------+\r\n| id                                   | device   |\r\n+--------------------------------------+----------+\r\n| e4cb5363-1fb2-41f5-b24b-18f98a388cba | /dev/vdb |\r\n| b325cc6e-8de1-4b6c-9807-5a497e3da7e3 | /dev/vda |\r\n+--------------------------------------+----------+\r\n\n",
                "title": "To attach a volume to a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server volume detach [--force] --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n--force\n\nDetach a volume without checking if either the volume or server exists. When specifying the volume and server, use their IDs. No name lookup is performed.\n<volume>\n\nVolume ID or name\n\nFor example, to detach the volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba from the virtual machine myvm, run:# vinfra service compute server volume detach e4cb5363-1fb2-41f5-b24b-18f98a388cba \\\r\n--server 871fef54-519b-4111-b18d-d2039e2410a8\n",
                "title": "To detach a volume from a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes screen, click an unused volume.\nOn the volume right pane, click Attach.\n\nIn the Attach volume window, select the VM from the drop-down list, and then click Done.\n\n\n\n\n\n\n",
                "title": "To attach a volume to a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes screen, click a volume that is in use.\nIf the VM is stopped, click Detach on the volume right pane.\n\nIf the VM is running, click Force detach on the volume right pane.\n\nThere is a risk of data loss.\n\n\n\n",
                "title": "To detach a volume from a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/attaching-and-detaching-volumes.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Quick Start Guide\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nQuick Start Guide\n\nHome\n\nContents\n\nIndex\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureQuick Start Guide\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/index.html"
    },
    {
        "title": "4. Migrating Virtual Machines\u00c2\u00b6",
        "content": "4. Migrating Virtual Machines | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n4. Migrating Virtual Machines\u00c2\u00b6\nMigrating virtual machines from VMware vSphere to Virtuozzo Hybrid Infrastructure involves two major steps:\n\nBackup the virtual machines.\nRecover them to Virtuozzo Hybrid Infrastructure.\n\nThese steps are described in detail in the next sections.\n\nIn this chapter:\n\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/migrating-virtual-machines/index.html"
    },
    {
        "title": "Securing OpenStack API traffic with SSL",
        "content": "Securing OpenStack API traffic with SSL\nTraffic to and from the public endpoint that listens to OpenStack API requests can be secured with an SSL certificate. However, as domain names are not used by default, the certificate will need a subjectAltName field containing the aforementioned management node IP address. If it does not have such a field, you will need to modify the public endpoint to use a domain name that you have a certificate for.\nLimitations\n\nOnly one SSL certificate can be added and applied for both the admin panel and OpenStack API.\n\nTo secure public OpenStack API traffic with SSL\n\nIn the admin panel, upload the SSL certificate and private key on the Settings > System settings > SSL certificate screen.\n\nOn the client side, place the CA certificate file to the operating system\u00e2\u0080\u0099s trusted bundle:# cp ca.pem /etc/pki/ca-trust/source/anchors/\r\n# update-ca-trust extract\r\n\nAlternatively, you can append the --os-cacert ca.pem option to each OpenStack client call.\n\nIf your certificate does not have the subjectAltName field, modify all public endpoints to use the domain name for which you have the certificate for, as described in Setting a DNS name for the compute API. This domain name must resolve to the management node IP address (or to its virtual IP address if high availability is enabled).\n\nIn your OpenRC script, change OS_AUTH_URL to the same domain name and remove all parameters related to insecure access. For example:export OS_PROJECT_DOMAIN_NAME=Default\r\nexport OS_USER_DOMAIN_NAME=Default\r\nexport OS_PROJECT_NAME=admin\r\nexport OS_USERNAME=admin\r\nexport OS_PASSWORD=<ADMIN_PASSWORD>\r\nexport OS_AUTH_URL=https://<DOMAIN_NAME>:5000/v3\r\nexport OS_IDENTITY_API_VERSION=3\r\n\n\nNow you can run OpenStack commands without the --insecure option.\nWhat's next\n\nProvisioning Kubernetes clusters",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/securing-openstack-api-traffic-with-ssl.html"
    },
    {
        "title": "Enabling geo-replication",
        "content": "Enabling geo-replication\nPrerequisites\n\nTwo backup storage clusters are deployed, as described in Provisioning Acronis Backup Storage space.\nBefore you configure geo-replication for the secondary cluster, delete all of its registrations, as explained in Deleting registrations.\nAll storage clusters are updated to the latest version.\nAll storage clusters can reach each other via domain names on TCP port 44445.\nEach storage cluster can reach itself via its own domain name on TCP port 44445. This is especially important if the clusters are situated behind NAT.\n\nTo set up geo-replication between two storage clusters\n\nAdmin panel\n\nOn the cluster that will be configured as secondary, go to Storage services > Backup storage > Geo-replication. Click the copy icon next to the UID field to copy its UID to clipboard.\n\nOn the cluster that will be configured as primary, go to Storage services > Backup storage > Geo-replication. Click Configure replication, and then do the following in the Configure replication window:\n\nSpecify external DNS names for the primary and secondary backup storage clusters, and then paste the UID of the secondary cluster. Click Next.\n\nIt is recommended to provide DNS names different from those of backup storage registrations. Otherwise, once you reconfigure the backup storage DNS name, the clusters will be unable to communicate and geo-replication will be stopped. If you cannot provide a dedicated DNS name, specify the DNS name used for backup storage creation.\n\nSpecify the following information for your Acronis product:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\nClick Configure.\n\nThe primary cluster is now configured and ready to be connected to the secondary one, which needs to be configured next. The configuration file of the primary cluster will be automatically downloaded to your local server. Alternatively, you can do it manually by clicking Download configuration file.\n\nOn the secondary cluster, click Configure replication, and then do the following in the Configure replication window:\n\nSelect the Secondary cluster configuration type.\n\nUpload the configuration file of the primary cluster from your local server.\n\nClick Configure.\n\nThe secondary cluster is now also configured and ready to be connected to the primary one.\n\nBack on the primary cluster, click Connect to enable replication between the two datacenters.\n\nCommand-line interface\n\nOn the cluster that will be configured as secondary, run vinfra service backup geo-replication show to learn its UID. For example:# vinfra service backup geo-replication show\r\n+-------+-----------------------------+\r\n| Field | Value                       |\r\n+-------+-----------------------------+\r\n| self  | address: no address         |\r\n|       | datacenter_uid: e63a6738<\u00e2\u0080\u00a6> |\r\n+-------+-----------------------------+\r\n\n\nOn the cluster that will be configured as primary, run vinfra service backup geo-replication primary setup, using the DNS names for the primary cluster, as well as the DNS name and UID of the secondary cluster. Additionally, specify the URL of the cloud management portal or the hostname/IP address and port of the local management server and the account credentials for the registration. For example:# vinfra service backup geo-replication primary setup --primary-cluster-address \r\nprimary.example.com \\\r\n--secondary-cluster-address secondary.example.com --secondary-cluster-uid e63a6738<\u00e2\u0080\u00a6> \\\r\n--username account@example.com --account-server https://cloud.acronis.com --stdin\n\nOn the primary cluster, run vinfra service backup geo-replication primary download-configs to generate the configuration file of the primary cluster. For example:# vinfra service backup geo-replication primary download-configs --conf-file-path primary_dc.conf\r\n\n\nMove the configuration file of the primary cluster to the secondary cluster using the standard Linux command-line tool. For example, by using scp:# scp primary_dc.conf <secondary_cluster_IP_address>:/root/primary_dc.conf\r\n\n\nOn the secondary cluster, run vinfra service backup geo-replication secondary setup to upload the configuration file of the primary cluster. For example:# vinfra service backup geo-replication secondary setup --dc-config-file primary_dc.conf\n\nIf for some reason, you need to cancel geo-replication, run vinfra service backup geo-replication primary cancel on the primary cluster and vinfra service backup geo-replication secondary cancel on the secondary cluster.\n\nOn the primary cluster, run vinfra service backup geo-replication primary establish to establish a connection between the primary and secondary clusters. For example:# vinfra service backup geo-replication primary establish\r\n\n\nSee also\n\nMonitoring Acronis Backup Storage\n\nImporting registrations to the secondary cluster\n\nPerforming a failover\n\nDisabling geo-replication",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nOn the cluster that will be configured as secondary, run vinfra service backup geo-replication show to learn its UID. For example:# vinfra service backup geo-replication show\r\n+-------+-----------------------------+\r\n| Field | Value                       |\r\n+-------+-----------------------------+\r\n| self  | address: no address         |\r\n|       | datacenter_uid: e63a6738<\u00e2\u0080\u00a6> |\r\n+-------+-----------------------------+\r\n\n\n\nOn the cluster that will be configured as primary, run vinfra service backup geo-replication primary setup, using the DNS names for the primary cluster, as well as the DNS name and UID of the secondary cluster. Additionally, specify the URL of the cloud management portal or the hostname/IP address and port of the local management server and the account credentials for the registration. For example:# vinfra service backup geo-replication primary setup --primary-cluster-address \r\nprimary.example.com \\\r\n--secondary-cluster-address secondary.example.com --secondary-cluster-uid e63a6738<\u00e2\u0080\u00a6> \\\r\n--username account@example.com --account-server https://cloud.acronis.com --stdin\n\n\nOn the primary cluster, run vinfra service backup geo-replication primary download-configs to generate the configuration file of the primary cluster. For example:# vinfra service backup geo-replication primary download-configs --conf-file-path primary_dc.conf\r\n\n\n\nMove the configuration file of the primary cluster to the secondary cluster using the standard Linux command-line tool. For example, by using scp:# scp primary_dc.conf <secondary_cluster_IP_address>:/root/primary_dc.conf\r\n\n\n\nOn the secondary cluster, run vinfra service backup geo-replication secondary setup to upload the configuration file of the primary cluster. For example:# vinfra service backup geo-replication secondary setup --dc-config-file primary_dc.conf\n\n\nIf for some reason, you need to cancel geo-replication, run vinfra service backup geo-replication primary cancel on the primary cluster and vinfra service backup geo-replication secondary cancel on the secondary cluster.\n\n\nOn the primary cluster, run vinfra service backup geo-replication primary establish to establish a connection between the primary and secondary clusters. For example:# vinfra service backup geo-replication primary establish\r\n\n\n\n",
                "title": "To set up geo-replication between two storage clusters"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOn the cluster that will be configured as secondary, go to Storage services > Backup storage > Geo-replication. Click the copy icon next to the UID field to copy its UID to clipboard.\n\n\n\n\n\n\nOn the cluster that will be configured as primary, go to Storage services > Backup storage > Geo-replication. Click Configure replication, and then do the following in the Configure replication window:\n\n\nSpecify external DNS names for the primary and secondary backup storage clusters, and then paste the UID of the secondary cluster. Click Next.\n\nIt is recommended to provide DNS names different from those of backup storage registrations. Otherwise, once you reconfigure the backup storage DNS name, the clusters will be unable to communicate and geo-replication will be stopped. If you cannot provide a dedicated DNS name, specify the DNS name used for backup storage creation.\n\n\n\n\n\n\n\nSpecify the following information for your Acronis product:\n\nThe URL of the cloud management portal (for example, https://cloud.acronis.com/) or the hostname/IP address and port of the local management server (for example, http://192.168.1.2:9877).\nThe credentials of a partner account in the cloud or of an organization administrator on the local management server. Note that the account must be converted to a service account in the Acronis Cyber Protect Cloud management portal. You can do this on the Company management screen in the Users section.\n\n\n\n\n\n\nClick Configure.\n\nThe primary cluster is now configured and ready to be connected to the secondary one, which needs to be configured next. The configuration file of the primary cluster will be automatically downloaded to your local server. Alternatively, you can do it manually by clicking Download configuration file.\n\n\nOn the secondary cluster, click Configure replication, and then do the following in the Configure replication window:\n\nSelect the Secondary cluster configuration type.\n\nUpload the configuration file of the primary cluster from your local server.\n\n\n\n\n\nClick Configure.\n\nThe secondary cluster is now also configured and ready to be connected to the primary one.\n\n\nBack on the primary cluster, click Connect to enable replication between the two datacenters.\n\n\n\n\n\n\n",
                "title": "To set up geo-replication between two storage clusters"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-geo-replication.html"
    },
    {
        "title": "Updating images",
        "content": "Updating imagesPATCH /v2/images/{image_id}\r\n\nChange image name, OS distribution, minimal disk size, placement, and shared status of an image with the specified ID.\nUse the media type application/openstack-images-v2.1-json-patch.\nThe OS distribution parameter os_distro can be one of the following:\n\nLinux distributions:\n\ngenericlinux\u00e2\u0080\u0094Generic Linux\ncentos8\u00e2\u0080\u0094CentOS 8\ncentos7\u00e2\u0080\u0094CentOS 7\ncentos6\u00e2\u0080\u0094CentOS 6\nrhel9\u00e2\u0080\u0094Red Hat Enterprise Linux 9\nrhel8\u00e2\u0080\u0094Red Hat Enterprise Linux 8\nrhel7\u00e2\u0080\u0094Red Hat Enterprise Linux 7\nubuntu22.04\u00e2\u0080\u0094Ubuntu 22.04\nubuntu20.04\u00e2\u0080\u0094Ubuntu 20.04\nubuntu18.04\u00e2\u0080\u0094Ubuntu 18.04\nubuntu16.04\u00e2\u0080\u0094Ubuntu 16.04\ndebian10\u00e2\u0080\u0094Debian 10\ndebian9\u00e2\u0080\u0094Debian 9\nrockylinux9\u00e2\u0080\u0094Rocky Linux 9\nrockylinux8\u00e2\u0080\u0094Rocky Linux 8\nalmalinux9\u00e2\u0080\u0094AlmaLinux 9\nalmalinux8\u00e2\u0080\u0094AlmaLinux 8\n\nWindows distributions:\n\ngenericwindows\u00e2\u0080\u0094Generic Windows\nwin2k22\u00e2\u0080\u0094Windows Server 2022\nwin2k19\u00e2\u0080\u0094Windows Server 2019\nwin2k16\u00e2\u0080\u0094Windows Server 2016\nwin2k12r2\u00e2\u0080\u0094Windows Server 2012 R2\nwin2k12\u00e2\u0080\u0094Windows Server 2012\nwin2k8r2\u00e2\u0080\u0094Windows Server 2008 R2\nwin10\u00e2\u0080\u0094Windows 10\nwin81\u00e2\u0080\u0094Windows 8.1\nwin7\u00e2\u0080\u0094Windows 7\n\nSource: https://docs.openstack.org/api-ref/image/v2/index.html?expanded=update-image-detail#update-image\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nContent-Type\n\nheader\nstring\nThe media type descriptor for the request body.  Use\r\napplication/openstack-images-v2.1-json-patch.  (You can also use\r\napplication/openstack-images-v2.0-json-patch, but keep in mind that\r\nit\u00e2\u0080\u0099s deprecated.)\n\nimage_id\n\npath\nstring\nThe UUID of the image.\n\nExample# curl -ks -X PATCH -H 'Content-Type: application/openstack-images-v2.1-json-patch' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n[\r\n    {\r\n        \"op\": \"replace\",\r\n        \"path\": \"/name\",\r\n        \"value\": \"cirros2\"\r\n    },\r\n    {\r\n        \"op\": \"replace\",\r\n        \"path\": \"/os_distro\",\r\n        \"value\": \"centos8\"\r\n    },\r\n    {\r\n        \"op\": \"replace\",\r\n        \"path\": \"/min_disk\",\r\n        \"value\": 3\r\n    },\r\n    {\r\n        \"op\": \"replace\",\r\n        \"path\": \"/visibility\",\r\n        \"value\": \"public\"\r\n    },\r\n    {\r\n        \"op\": \"add\",\r\n        \"path\": \"/trait:CUSTOM_HCI_122E856B9E9C4D80A0F8C21591B5AFCB\",\r\n        \"value\": \"required\"\r\n    }\r\n]' https://<node_IP_addr>:9292/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nchecksum\n\nbody\nstring\nHash that is used over the image data. The Image\r\nservice uses this value for verification.  The value might be\r\nnull (JSON null data type).\n\ncontainer_format\n\nbody\nenum\n\nFormat of the image container.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud.\nExample formats are: ami, ari, aki, bare,\r\novf, ova, or docker.\nThe value might be null (JSON null data type).\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndisk_format\n\nbody\nenum\n\nThe format of the disk.\nValues may vary based on the configuration available in a\r\nparticular OpenStack cloud. See the Image Schema\r\nresponse from the cloud itself for the valid values available.\nExample formats are: ami, ari, aki, vhd,\r\nvhdx, vmdk, raw, qcow2, vdi, ploop or\r\niso.\nThe value might be null (JSON null data type).\n\nfile\n\nbody\nstring\nThe URL for the virtual machine image file.\n\nid\n\nbody\nstring\n\nA unique, user-defined image UUID, in the format:nnnnnnnn-nnnn-nnnn-nnnn-nnnnnnnnnnnn\r\n\nWhere n is a hexadecimal digit from 0 to f, or F.\nFor example:b2173dd3-7ad6-4362-baa6-a68bce3565cb\r\n\nIf you omit this value, the API generates a UUID for the image.\n\nmin_disk\n\nbody\ninteger\nAmount of disk space in GB that is required to boot the image.\r\nThe value might be null (JSON null data type).\n\nmin_ram\n\nbody\ninteger\nAmount of RAM in MB that is required to boot the image.\r\nThe value might be null (JSON null data type).\n\nname\n\nbody\nstring\nThe name of the image.  Value might be null (JSON null data type).\n\nos_hash_algo\n\nbody\nstring\n\nThe algorithm used to compute a secure hash of the image data for this\r\nimage.  The result of the computation is displayed as the value of the\r\nos_hash_value property.  The value might be null (JSON null\r\ndata type).  The algorithm used is chosen by the cloud operator; it\r\nmay not be configured by end users.\nNew in version 2.7\n\nos_hash_value\n\nbody\nstring\n\nThe hexdigest of the secure hash of the image data computed using the\r\nalgorithm whose name is the value of the os_hash_algo property.\r\nThe value might be null (JSON null data type) if data has not\r\nyet been associated with this image, or if the image was created using\r\na version of the Image Service API prior to version 2.7.\nNew in version 2.7\n\nos_hidden\n\nbody\nboolean\n\nThis field controls whether an image is displayed in the default\r\nimage-list response.  A \u00e2\u0080\u009chidden\u00e2\u0080\u009d image is out of date somehow (for\r\nexample, it may not have the latest updates applied) and hence should\r\nnot be a user\u00e2\u0080\u0099s first choice, but it\u00e2\u0080\u0099s not deleted because it may be\r\nneeded for server rebuilds.  By hiding it from the default image list,\r\nit\u00e2\u0080\u0099s easier for end users to find and use a more up-to-date version of\r\nthis image.\nNew in version 2.7\n\nowner\n\nbody\nstring\nAn identifier for the owner of the image, usually the project (also\r\ncalled the \u00e2\u0080\u009ctenant\u00e2\u0080\u009d) ID.\r\nThe value might be null (JSON null data type).\n\nprotected\n\nbody\nboolean\nA boolean value that must be false or the image cannot be deleted.\n\nschema\n\nbody\nstring\nThe URL for the schema describing a virtual machine image.\n\nself\n\nbody\nstring\nThe URL for the virtual machine image.\n\nsize\n\nbody\ninteger\nThe size of the image data, in bytes.  The value\r\nmight be null (JSON null data type).\n\nstatus\n\nbody\nstring\nThe image status.\n\ntags\n\nbody\narray\nList of tags for this image, possibly an empty list.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvirtual_size\n\nbody\ninteger\nThe virtual size of the image.  The value might\r\nbe null (JSON null data type).\n\nvisibility\n\nbody\nstring\nImage visibility, that is, the access permission for the image.\n\ndirect_url (Optional)\nbody\nstring\n\nThe URL to access the image file kept in external store.  It is present\r\nonly if the show_image_direct_url option is true in the Image\r\nservice\u00e2\u0080\u0099s configuration file.\n\nAs it presents a security risk, this\r\noption is disabled by default.\n\nlocations (Optional)\nbody\narray\n\nA list of objects, each of which describes an image location.  Each object\r\ncontains a url key, whose value is a URL specifying a location, and a\r\nmetadata key, whose value is a dict of key:value pairs containing\r\ninformation appropriate to the use of whatever external store is indicated\r\nby the URL.  This list appears only if the show_multiple_locationsoption is set to true in the Image service\u00e2\u0080\u0099s configuration file.\n\nAs it presents a security risk, this option is disabled by\r\ndefault.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n415 - Unsupported Media Type\n\nThe request entity has a media type which the server or resource does not support.\n\nExample{\r\n  \"image_validated\": \"yes\",\r\n  \"container_format\": \"bare\",\r\n  \"min_ram\": 0,\r\n  \"updated_at\": \"2020-02-11T11:52:02Z\",\r\n  \"file\": \"/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67/file\",\r\n  \"owner\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n  \"id\": \"c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n  \"size\": 12716032,\r\n  \"os_distro\": \"centos8\",\r\n  \"self\": \"/v2/images/c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n  \"disk_format\": \"qcow2\",\r\n  \"os_hash_algo\": \"sha512\",\r\n  \"direct_url\": \"file:///mnt/vstorage/vols/datastores/glance/c92d820c-50dc-4fd1-a0bc-2f1071487b67\",\r\n  \"hw_disk_bus\": \"virtio\",\r\n  \"schema\": \"/v2/schemas/image\",\r\n  \"status\": \"active\",\r\n  \"tags\": [],\r\n  \"trait:CUSTOM_HCI_122E856B9E9C4D80A0F8C21591B5AFCB\": \"required\",\r\n  \"visibility\": \"public\",\r\n  \"min_disk\": 3,\r\n  \"virtual_size\": null,\r\n  \"name\": \"cirros2\",\r\n  \"checksum\": \"443b7623e27ecf03dc9e01ee93f67afe\",\r\n  \"created_at\": \"2020-01-28T12:58:17Z\",\r\n  \"os_hidden\": false,\r\n  \"protected\": false,\r\n  \"os_hash_value\": \"6513f21e44aa3da349f248188a<...>\",\r\n  \"os_type\": \"linux\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-images.html"
    },
    {
        "title": "General considerations",
        "content": "General considerations\n\nTo improve the validity of results, you need to perform 3-5 iterations of the same test.\nFor file tests, each test should take at least 60 seconds. The recommended time, however, is 120-300 seconds, which can negate the benefits of fast cache on some SSD drives.\nFor S3 tests, the recommended run time is at least 900 seconds, which provides more stable results.\nWhen using erasure coding, throughput is usually limited at 500-800 MB/s per node, for both reading and writing (depending on specific hardware and workload). If you reach this limit, you may improve your results by spreading the load across a larger number of nodes or by adding more nodes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/general-considerations.html"
    },
    {
        "title": "Deleting S3 users via CLI",
        "content": "Deleting S3 users via CLI\nYou can delete existing object storage users with the ostor-s3-admin delete-user command. Users who own any buckets cannot be deleted, so delete user\u00e2\u0080\u0099s buckets first. You need to specify either the user email (-e) or S3 ID (-i). For example:# ostor-s3-admin delete-user -i bf0b3b15eb7c9019 -V 0100000000000002\r\nDeleted user: user id=bf0b3b15eb7c9019\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-s3-users-via-cli.html"
    },
    {
        "title": "Backing up and restoring management database",
        "content": "Backing up and restoring management database\nThe product database is stored on the management node (the one with the admin panel) and backed up automatically. It is also replicated to the nodes included in the HA configuration, if high availability is enabled for the management node.\nThis management database contains the cluster configuration, service management and monitoring parameters, and metadata of compute objects, such as projects, domains, users, virtual machines, images, flavors, volumes, networks, and other. The database does not contain user data located on storage disks (for example, volumes, volume snapshots, and compute images), as well as data stored on local root disks (for example, logs, metrics data, and service internal data).\nBackups of the management database are created automatically via a daily cron job that starts at 3:00 a.m. If the management node is not highly available, restoring such a backup recovers the node in case of failure or database corruption. Backup files are stored in the /mnt/vstorage/webcp/backup/ directory. The retention policy for management node backups is the following:\n\nAll backups created within the last day are kept.\nFrom backups created within the last 7 days, the newest for each day is kept.\nFrom backups created within the last 7-14 days, the oldest one is kept.\nFrom backups created within the last 14-45 days, the oldest one for each week is kept.\nBackups older than 45 days are deleted.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backing-up-and-restoring-management-database.html"
    },
    {
        "title": "Installing guest tools",
        "content": "Installing guest tools\n\nCreate a compute volume from the vz-guest-tools-win or vz-guest-tools-lin image, depending on the VM operating system:\nIf you do not have these images in your project, obtain them from the official repository and upload them to your project, as described in Uploading images.\n\nOn the Images screen, click the vz-guest-tools-win or vz-guest-tools-lin image.\nOn the image right pane, click Create volume.\nIn the Create volume from image window, specify a name for the volume, and then click Create.\n\nAttach the volume with the guest tools to the virtual machine:\n\nOn the Virtual machines screen, click the required VM.\nOn the VM right pane, click the pencil icon in the Volumes field.\nIn the Volumes window, click Attach.\nIn the Attach volume window, select the created volume with the guest tools, and then click Attach. The attached volume will be marked as ISO.\nIn the Volumes window, click Done, to save your changes.\n\nLog in to the virtual machine.\n\nInside the VM, do the following:\n\nInside a Windows VM, go to the mounted optical drive in Explorer and install the guest tools by running setup.exe. After the installation is complete, restart the VM.\n\nInside a Linux VM, create a mount point for the optical drive with the guest tools image and run the installer:# mkdir /mnt/cdrom\r\n# mount <path_to_guest_tools_iso> /mnt/cdrom\r\n# bash /mnt/cdrom/install\t\t\t\t\t\t\t\t",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/installing-guest-tools.html"
    },
    {
        "title": "Creating virtual machines with SR-IOV network ports",
        "content": "Creating virtual machines with SR-IOV network ports\nLimitations\n\nVirtual machines with attached PCI devices cannot be live migrated.\n\nPrerequisites\n\nThe compute cluster is reconfigured for PCI passthrough, as described in Enabling PCI passthrough and vGPU support.\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo create a virtual machine with an SR-IOV network port\n\nCreate a physical compute network specifying the network adapter alias from the pci-passthrough.yaml file and the default vNIC type direct. You also need to disable the built-in DHCP server and specify the desired IP address range. For example, to create the sriov-network network with the 10.10.10.0/24 CIDR, run:# vinfra service compute network create sriov-network --physical-network sriovnet --default-vnic-type direct \\\r\n--no-dhcp --cidr 10.10.10.0/24\n\nCreate a virtual machine specifying the new network. For example, to create the VM sriov-vm from the template centos7 and with the large flavor, run:# vinfra service compute server create sriov-vm --network id=sriov-network --volume source=image,size=11,id=centos7 --flavor large\n\nIf the VM creation fails\nCheck whether the following error appears in /var/log/hci/nova/nova-compute.log:2021-08-27 17:56:21.349 6 ERROR nova.compute.manager [instance: 9fb738bf-afe5-40ef-943c-\r\n22e43696bfd9] libvirtError: internal error: qemu unexpectedly closed the monitor: \r\n2021-08-27T14:56:20.294985Z qemu-kvm: -device vfio-pci,host=01:00.3,id=hostdev0,\r\nbus=pci.0,addr=0x6: vfio error: 0000:01:00.3: group 1 is not viable\r\n2021-08-27 17:56:21.349 6 ERROR nova.compute.manager [instance: 9fb738bf-afe5-40ef-943c-\r\n22e43696bfd9] Please ensure all devices within the iommu_group are bound to their vfio \r\nbus driver.\nIn this case, the physical and virtual functions of the network adapter might belong to the same IOMMU group. You can check this by using the virsh nodedev-dumpxml command and specifying the device names of physical and virtual functions. For example:# virsh nodedev-dumpxml pci_0000_00_03_0 | grep iommuGroup\r\n    <iommuGroup number='1'>\r\n    </iommuGroup>\r\n# virsh nodedev-dumpxml pci_0000_00_03_1 | grep iommuGroup\r\n    <iommuGroup number='1'>\r\n    </iommuGroup>\nThe device names have the format pci_0000_<bus_number>_<device_number>_<function_number>. These numbers can be obtained via the lspci command:# lspci -nn | grep Ethernet\r\n00:03.0 Ethernet controller [0200]: Mellanox Technologies MT27800 Family [ConnectX-5] [15b3:1017]\r\n...\nIn this output, 00 is the bus number, 03 is the device number, and 0 is the function number.\nIf the physical and virtual functions belong to the same IOMMU group, you need to detach the physical function from the node by running the pci-helper.py script and specifying its VID and PID. For example:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py detach 15b3:1017\nSee also\n\nCreating virtual machines with physical GPUs\n\nCreating virtual machines with virtual GPUs\n\nCreating virtual machines with different vGPU types\n\nCreating virtual machines\n\nDisabling PCI passthrough and vGPU support",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtual-machines-with-sr-iov-network-ports.html"
    },
    {
        "title": "Configuring virtual machine high availability",
        "content": "Configuring virtual machine high availability\nHigh availability keeps virtual machines operational if the node they are located on fails due to a kernel crash, power outage, or becomes unreachable over the network. Graceful shutdown is not considered a failure event.\nIn the event of failure, the system will attempt to evacuate the affected VMs automatically, that is, migrate them offline with auto-scheduling to other healthy compute nodes in the following order:\n\nVMs with the \u00e2\u0080\u009cActive\u00e2\u0080\u009d status are evacuated first and automatically started.\nVMs with the \u00e2\u0080\u009cShut down\u00e2\u0080\u009d status are evacuated next and remain stopped.\nAll other VMs are ignored and left on the failed node.\n\nIf something blocks the evacuation, for example, the destination compute nodes lack the resources to host the affected VMs, these VMs remain on the failed node and receive the \u00e2\u0080\u009cError\u00e2\u0080\u009d status. You can evacuate them manually after solving the issue (providing sufficient resources, joining new nodes to the cluster, etc.).\nBy default, high availability for virtual machines is enabled automatically after creating the compute cluster. If required, you can disable it manually. Keep in mind that virtual machines with disabled high availability will not be evacuated to healthy nodes in the case of a failover.\nLimitations\n\nIn a single-node and two-node clusters, it is not possible to restart virtual machines by using VM high availability.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo disable high availability for virtual machines\n\nAdmin panel\n\nClick the virtual machine for which you wish to disable high availability.\nOn the VM right pane, click the pencil icon next to the High availability parameter.\nIn the High availability window, disable high availability for the VM, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra service compute server set <server> --ha-enabled {true,false}\n\n--ha-enabled {true,false}\n\nEnable or disable HA for the virtual machine.\n<server>\n\nVirtual machine ID or name\n\nFor example, to disable high availability for the virtual machine myvm, run:# vinfra service compute server set myvm --ha-enabled false\n\nTo evacuate virtual machines manually\n\nAdmin panel\n\nClick a virtual machine in the \u00e2\u0080\u009cError\u00e2\u0080\u009d status.\n\nClick Evacuate on the VM right pane.\n\nCommand-line interface\nUse the following command:vinfra service compute server evacuate <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to evacuate the stopped VM myvm from its node to a healthy compute node, run:# vinfra service compute server evacuate myvm\r\n\n\nSee also\n\nFencing compute nodes\n\nManaging virtual machine power state\n\nMigrating virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server set <server> --ha-enabled {true,false}\n\n--ha-enabled {true,false}\n\nEnable or disable HA for the virtual machine.\n<server>\n\nVirtual machine ID or name\n\nFor example, to disable high availability for the virtual machine myvm, run:# vinfra service compute server set myvm --ha-enabled false\n",
                "title": "To disable high availability for virtual machines"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server evacuate <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to evacuate the stopped VM myvm from its node to a healthy compute node, run:# vinfra service compute server evacuate myvm\r\n\n",
                "title": "To evacuate virtual machines manually"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nClick the virtual machine for which you wish to disable high availability.\nOn the VM right pane, click the pencil icon next to the High availability parameter.\nIn the High availability window, disable high availability for the VM, and then click Save.\n\n\n\n\n\n",
                "title": "To disable high availability for virtual machines"
            },
            {
                "example": "\nAdmin panel\n\nClick a virtual machine in the \u00e2\u0080\u009cError\u00e2\u0080\u009d status.\n\nClick Evacuate on the VM right pane.\n\n\n\n\n\n\n",
                "title": "To evacuate virtual machines manually"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-virtual-machine-ha.html"
    },
    {
        "title": "Managing VPN connections",
        "content": "Managing VPN connections",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-vpn-connections.html"
    },
    {
        "title": "Kubernetes-as-a-Service network requirements",
        "content": "Kubernetes-as-a-Service network requirements\nTo be able to deploy Kubernetes clusters in the compute cluster and work with them, make sure your network configuration allows the compute and Kubernetes services to send the following network requests:\n\nThe request to bootstrap the etcd cluster in the public discovery service - from all management nodes to https://discovery.etcd.io via the public network.\nThe request to obtain the \u00e2\u0080\u009ckubeconfig\u00e2\u0080\u009d file - from all management nodes via the public network:If high availability (HA) for the master VM is enabled, the request is sent to the public or floating IP address of the load balancer VM associated with Kubernetes API on port 6443.If HA for the master VM is disabled, the request is sent to the public or floating IP address of the Kubernetes master VM on port 6443.\nRequests from Kubernetes master VMs to the compute APIs (the Compute API traffic type) via the network with the VM public traffic type (via a publicly available VM network interface or a virtual router with enabled SNAT). By default, the compute API is exposed via the IP address of the management node (or to its virtual IP address if high availability is enabled). But you can also access the compute API via a DNS name.\nThe request to update the etcd cluster member state in the public discovery service - from Kubernetes master VMs to https://discovery.etcd.io via the network with the VM public traffic type (via a publicly available VM network interface or a virtual router with enabled SNAT).\nThe request to download container images from the public Docker Hub repository - from Kubernetes master VMs to https://registry-1.docker.io via the network with the VM public traffic type (via a publicly available VM network interface or a virtual router with enabled SNAT).\n\nIt is also required that the network where you create a Kubernetes cluster does not overlap with these default networks:\n\n10.100.0.0/16\u00e2\u0080\u0094Used for pod-level networking\n10.254.0.0/16\u00e2\u0080\u0094Used for allocating Kubernetes cluster IP addresses\n\nSee also\n\nNetwork recommendations\n\nNetwork ports\n\nSetting a DNS name for the compute API\n\nProvisioning Kubernetes clusters",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/kubernetes-network-requirements.html"
    },
    {
        "title": "Aggregating used floating IP addresses",
        "content": "Aggregating used floating IP addressesPOST /v1/aggregates?details=False&needed_overlap=0.0&start={start_date}&stop={stop_date}\r\n\nAggregate the number of used floating IP addresses per project for a specific period of time.\n\nIf the start or stop date is not specified, the missing value will be set to the first or last timestamp common across the time series.\n\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\noperation\n\nbody\nstring\nOperations to apply to the time series. For aggregation across metrics, use the following syntax: aggregate <aggregation_method> ((metric <metric_id> <aggregation_method>), ...). Supported aggregation methods are: mean, median, std, min, max, sum, var, count.\n\nsearch\n\nbody\nstring\nA query to filter resources. The syntax includes an attribute, operator, and value. For example, the query id=90d58eea-70d7-4294-a49a-170dcdf44c3c will filter a resource with the specified ID. You can use more complex queries, for example, not (flavor_id!=\u00e2\u0080\u009d1\u00e2\u0080\u009d and memory>=24). Use \u00e2\u0080\u009c\u00e2\u0080\u009d to interpret data as a string. Supported operators are: not, and, \u00e2\u0088\u00a7 or, \u00e2\u0088\u00a8, >=, <=, !=, >, <, =, ==, eq, ne, lt, gt, ge, le, in, like, \u00e2\u0089\u00a0, \u00e2\u0089\u00a5, \u00e2\u0089\u00a4, like, in.\n\nresource_type\n\nbody\nstring\n\nA resource type that a metric is associated with. For example, these metrics are bound to:\n\nvCPU and RAM metrics\u00e2\u0080\u0094the instance resource type\nStorage metrics\u00e2\u0080\u0094the volume resource type\nFloating IP addresses\u00e2\u0080\u0094the network resource type\nLoad balancers\u00e2\u0080\u0094the loadbalancer resource type\nKubernetes clusters\u00e2\u0080\u0094the coe_cluster resource type\n\nExample\nAggregate the number of used floating IP addresses for the project with the ID 75521ab61d1f4e9090aac5836c219492 from 12:00 PM July 18, 2021, to 13:00 PM July 19, 2021.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"operations\":\"(aggregate sum (metric ip.floating mean))\",\r\n    \"search\":\"project_id=75521ab61d1f4e9090aac5836c219492\",\r\n    \"resource_type\":\"network\"\r\n}' https://<node_IP_addr>:8041/v1/aggregates?details=False&needed_overlap=0.0&\\\r\nstart=2021-07-18T12:00:00&stop=2021-07-19T12:00:00\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nmeasures\n\nbody\nstring\nA list of measures for a metric.\n\naggregated\n\nbody\narray\nA number of aggregates, each consisting of a timestamp, granularity, and value.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"measures\": {\r\n    \"aggregated\": [\r\n      [\r\n        \"2021-07-18T12:00:00+00:00\",\r\n        300.0,\r\n        2\r\n      ],\r\n      <...>\r\n      [\r\n        \"2021-07-19T11:55:00+00:00\",\r\n        300.0,\r\n        2\r\n      ] \r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/aggregating-used-floating-ip-addresses.html"
    },
    {
        "title": "Creating snapshots",
        "content": "Creating snapshotsPOST /v3/{project_id}/snapshots\r\n\nCreates a volume snapshot, which is a point-in-time, complete copy of a volume.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=create-a-snapshot-detail#create-a-snapshot\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nsnapshot\n\nbody\nobject\nA snapshot object.\n\nvolume_id\n\nbody\nstring\nThe UUID of the volume.\n\nname\n\nbody\nstring\nThe name of the snapshot.\n\ndescription (Optional)\nbody\nstring\nA description for the snapshot. Default is\r\nNone.\n\nforce (Optional)\nbody\nboolean\nIndicates whether to backup, even if the volume\r\nis attached. Default is false.\n\nmetadata (Optional)\nbody\nobject\nOne or more metadata key and value pairs for the\r\nsnapshot.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"snapshot\": {\r\n    \"name\": \"snapshot1\",\r\n    \"volume_id\": \"cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n    \"force\": true\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/snapshots\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nsnapshot\n\nbody\nobject\nA snapshot object.\n\nuser_id\n\nbody\nstring\n\nThe UUID of the user.\nNew in version 3.41\n\nvolume_id\n\nbody\nstring\nIf the snapshot was created from a volume, the\r\nvolume ID.\n\nname\n\nbody\nstring\nThe name of the snapshot.\n\nstatus\n\nbody\nstring\nThe status for the snapshot.\n\ndescription\n\nbody\nstring\nA description for the snapshot.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nmetadata\n\nbody\nobject\nOne or more metadata key and value pairs for the\r\nsnapshot, if any.\n\nid\n\nbody\nstring\nThe snapshot UUID.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\ncount (Optional)\nbody\ninteger\n\nThe total count of requested resource before pagination is applied.\nNew in version 3.45\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nExample{\r\n  \"snapshot\": {\r\n    \"status\": \"creating\",\r\n    \"size\": 2,\r\n    \"metadata\": {},\r\n    \"name\": \"snapshot1\",\r\n    \"volume_id\": \"cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n    \"created_at\": \"2020-03-11T14:42:02.823364\",\r\n    \"description\": null,\r\n    \"id\": \"a370cf02-f469-4acc-be91-2b27a856806d\",\r\n    \"updated_at\": null\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-snapshots.html"
    },
    {
        "title": "Accessing NFS shares",
        "content": "Accessing NFS shares\nThis section describes ways to mount Virtuozzo Hybrid Infrastructure NFS shares on Linux and macOS.\n\nVirtuozzo Hybrid Infrastructure currently does not support the Windows built-in NFS client.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/accessing-nfs-shares.html"
    },
    {
        "title": "Managing Kubernetes clusters",
        "content": "Managing Kubernetes clusters\nKubernetes clusters are created and managed by self-service users, as described in \"Managing Kubernetes clusters\" in the Self-Service Guide. In the admin panel, you can view Kubernetes cluster details, view master and worker groups, change service parameters, update the Kubernetes version, and delete Kubernetes clusters.\nVirtuozzo Hybrid Infrastructure uses the soft anti-affinity policy for Kubernetes cluster nodes. According to this policy, Kubernetes nodes are distributed across compute nodes by groups: master nodes are distributed separately from workers. In this case, a compute node can host both a master node and a worker node. However, if there are not enough compute nodes to evenly distribute Kubernetes nodes from the same group, some of them can be placed on one compute node.\n\nFor Kubernetes service users to be able to use cluster autoscaling, the cluster must have a valid certificate issued by a trusted certificate authority, instead of a self-signed certificate.\n\nLimitations\n\nKubernetes versions 1.15.x\u00e2\u0080\u00931.22.x are no longer supported. Kubernetes clusters created with these versions are marked with the Deprecated tag.\n\nWhen a Kubernetes cluster is created, its configuration files contain the IP address or DNS name of the compute API endpoint. Modifying this IP address or DNS name will lead to inability to perform Kubernetes management operations. You can have one of the following scenarios:\n\nIf the high availability for the management node is disabled\n\nThe compute API is accessed via the IP address of the management node. In this case, changing this IP address or creating the management node HA is prohibited.\n\nIf the high availability for the management node is enabled\n\nThe compute API is accessed via the virtual IP address. In this case, changing this virtual IP address or destroying the management node HA is prohibited.\n\nIf a DNS name for the compute API is configured\n\nChanging the DNS name is prohibited.\n\nKubernetes cluster certificates are issued for five years. To renew the certificates, use the vinfra service compute k8saas rotate-ca command. Alternatively, you can use the openstack coe ca rotate command, as described in the OpenStack documentation.\nThe default Kubernetes network plugin does not support network policies. Starting with version 1.29.3, Kubernetes clusters can be created with the Cilium network plugin.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\nThe Kubernetes service is installed during the compute cluster deployment or later, as described in Provisioning Kubernetes clusters.\n\nTo view the details of a Kubernetes cluster\n\nAdmin panel\nOn the Compute > Kubernetes screen, click a Kubernetes cluster to open its right pane. \n\nCommand-line interface\nUse the following command:vinfra service compute k8saas show <cluster>\r\n\n\n<cluster>\n\nCluster ID or name\n\nFor example, to view the details of the Kubernetes cluster k8s1, run:# vinfra service compute k8saas show k8s1\r\n+----------------------------------+--------------------------------------------+\r\n| Field                            | Value                                      |\r\n+----------------------------------+--------------------------------------------+\r\n| action_status                    | CREATE_COMPLETE                            |\r\n| boot_volume_size                 | 10                                         |\r\n| boot_volume_storage_policy       | default                                    |\r\n| containers_volume_size           | 10                                         |\r\n| containers_volume_storage_policy | default                                    |\r\n| create_timeout                   | 60                                         |\r\n| external_network_id              | 10cc4d59-adac-4ec1-8e0a-df5015b82c64       |\r\n| id                               | 749737ae-2452-4a98-a057-b59b1c579a85       |\r\n| key_name                         | key1                                       |\r\n| master_flavor                    | medium                                     |\r\n| master_node_count                | 1                                          |\r\n| name                             | k8s1                                       |\r\n| network_id                       | d037623b-0db7-40c2-b38a-9ac34fbd1cc5       |\r\n| nodegroups                       | - action_status: CREATE_COMPLETE           |\r\n|                                  |   flavor: medium                           |\r\n|                                  |   id: c3b4ec41-b8c1-4dae-9e1c-aa586b99a62c |\r\n|                                  |   is_default: true                         |\r\n|                                  |   name: default-master                     |\r\n|                                  |   node_count: 1                            |\r\n|                                  |   role: master                             |\r\n|                                  |   status: ACTIVE                           |\r\n|                                  |   version: v1.22.2                         |\r\n|                                  | - action_status: CREATE_COMPLETE           |\r\n|                                  |   flavor: small                            |\r\n|                                  |   id: 65b80f19-0920-48b7-84e0-d0c63c46e99f |\r\n|                                  |   is_default: true                         |\r\n|                                  |   name: default-worker                     |\r\n|                                  |   node_count: 3                            |\r\n|                                  |   role: worker                             |\r\n|                                  |   status: ACTIVE                           |\r\n|                                  |   version: v1.22.2                         |\r\n| project_id                       | d8a72d59539c431381989af6cb48b05d           |\r\n| status                           | ACTIVE                                     |\r\n| user_id                          | 5846f988280f42199ed030a22970d48e           |\r\n| worker_pools                     | - flavor: small                            |\r\n|                                  |   node_count: 3                            |\r\n+----------------------------------+--------------------------------------------+\r\n\n\nTo view master and worker groups\n\nOn the Compute > Kubernetes screen, click a Kubernetes cluster.\n On the cluster right pane, navigate to the Groups tab.\nList all of the nodes in a group by clicking the arrow icon next to the required node group.\n\nTo renew the Kubernetes cluster certificates\nUse the following command:vinfra service compute k8saas rotate-ca <cluster>\r\n\n\n<cluster>\n\nCluster ID or name\n\nFor example, to renew the CA certificates for the Kubernetes cluster k8s1, run:# vinfra service compute k8saas rotate-ca k8s1\nTo delete a Kubernetes cluster\n\nAdmin panel\n\nOn the Compute > Kubernetes screen, click a Kubernetes cluster.\n On the cluster right pane, click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute k8saas delete <cluster>\r\n\n\n<cluster>\n\nCluster ID or name\n\nFor example, to delete the Kubernetes cluster k8s1, run:# vinfra service compute k8saas delete k8s1",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute k8saas show <cluster>\r\n\n\n<cluster>\n\nCluster ID or name\n\nFor example, to view the details of the Kubernetes cluster k8s1, run:# vinfra service compute k8saas show k8s1\r\n+----------------------------------+--------------------------------------------+\r\n| Field                            | Value                                      |\r\n+----------------------------------+--------------------------------------------+\r\n| action_status                    | CREATE_COMPLETE                            |\r\n| boot_volume_size                 | 10                                         |\r\n| boot_volume_storage_policy       | default                                    |\r\n| containers_volume_size           | 10                                         |\r\n| containers_volume_storage_policy | default                                    |\r\n| create_timeout                   | 60                                         |\r\n| external_network_id              | 10cc4d59-adac-4ec1-8e0a-df5015b82c64       |\r\n| id                               | 749737ae-2452-4a98-a057-b59b1c579a85       |\r\n| key_name                         | key1                                       |\r\n| master_flavor                    | medium                                     |\r\n| master_node_count                | 1                                          |\r\n| name                             | k8s1                                       |\r\n| network_id                       | d037623b-0db7-40c2-b38a-9ac34fbd1cc5       |\r\n| nodegroups                       | - action_status: CREATE_COMPLETE           |\r\n|                                  |   flavor: medium                           |\r\n|                                  |   id: c3b4ec41-b8c1-4dae-9e1c-aa586b99a62c |\r\n|                                  |   is_default: true                         |\r\n|                                  |   name: default-master                     |\r\n|                                  |   node_count: 1                            |\r\n|                                  |   role: master                             |\r\n|                                  |   status: ACTIVE                           |\r\n|                                  |   version: v1.22.2                         |\r\n|                                  | - action_status: CREATE_COMPLETE           |\r\n|                                  |   flavor: small                            |\r\n|                                  |   id: 65b80f19-0920-48b7-84e0-d0c63c46e99f |\r\n|                                  |   is_default: true                         |\r\n|                                  |   name: default-worker                     |\r\n|                                  |   node_count: 3                            |\r\n|                                  |   role: worker                             |\r\n|                                  |   status: ACTIVE                           |\r\n|                                  |   version: v1.22.2                         |\r\n| project_id                       | d8a72d59539c431381989af6cb48b05d           |\r\n| status                           | ACTIVE                                     |\r\n| user_id                          | 5846f988280f42199ed030a22970d48e           |\r\n| worker_pools                     | - flavor: small                            |\r\n|                                  |   node_count: 3                            |\r\n+----------------------------------+--------------------------------------------+\r\n\n",
                "title": "To view the details of a Kubernetes cluster"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute k8saas delete <cluster>\r\n\n\n<cluster>\n\nCluster ID or name\n\nFor example, to delete the Kubernetes cluster k8s1, run:# vinfra service compute k8saas delete k8s1\n",
                "title": "To delete a Kubernetes cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nOn the Compute > Kubernetes screen, click a Kubernetes cluster to open its right pane. \n",
                "title": "To view the details of a Kubernetes cluster"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Kubernetes screen, click a Kubernetes cluster.\n On the cluster right pane, click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a Kubernetes cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-kubernetes-clusters.html"
    },
    {
        "title": "Managing external storages",
        "content": "Managing external storages\nBesides the local compute storage, you can integrate your compute cluster with a third-party storage compatible with OpenStack. This will allow you to use an enterprise-grade storage solution, as well as isolate storage from your compute nodes.\nOpenStack provides multiple drivers for different storages. A set of available operations on volumes is limited by the driver capabilities and can be checked in the Cinder Driver Support Matrix.\nLimitations\n\nThe currently supported storages only include those that have the OpenStack Cinder iSCSI driver and use the Generic NFS Reference Driver (any storage with NFS support). For the full list of available iSCSI drivers, refer to the Cinder Driver Support Matrix.\nVolumes with external storage cannot be reverted from snapshots.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-external-storages.html"
    },
    {
        "title": "Block storage alerts",
        "content": "Block storage alerts\nThe following block storage alerts are generated and displayed in the admin panel:\n\n Redundancy warning\n\niSCSI LUN <lun_id> of target group \u00e2\u0080\u009c<target_group>\u00e2\u0080\u009d is set to failure domain \u00e2\u0080\u009cdisk\u00e2\u0080\u009d even though <number_of_nodes> nodes are available. It is recommended to set the failure domain to \u00e2\u0080\u009chost\u00e2\u0080\u009d so that the LUN can survive host failures in addition to disk failures.\n\n iSCSI major upgrade failed\n\niSCSI major upgrade failed. Will be retried\u00e2\u0080\u00a6\n\n iSCSI has failed volumes\n\nThe volume <volume_id> has failed. Please contact the technical support.\n\nWhat's next\n\nGetting technical support\n\nSee also\n\nInfrastructure alerts\n\nCore storage alerts\n\nBackup storage alerts\n\nObject storage alerts\n\nCompute alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/iscsi-alerts.html"
    },
    {
        "title": "Uploading images",
        "content": "Uploading images\nTo upload an image\n\n\r\n                On the Images screen, click Add image.\n\nIn the Add image window, do the following:\n\n\r\n                        Click Browse and select a file in one of the supported formats: .iso, .img, .qcow2, .raw.\r\n                    \n\r\n                        Specify an image name to be shown in the admin panel.\r\n                    \n\nSelect the correct OS type from the drop-down list.\n\nThe OS type affects VM parameters such as hypervisor settings. VMs created from an image with an incorrect OS type may not work correctly, for example, they may crash.\n\nIf you have chosen an image in the QCOW2, RAW, or IMG format, select the UEFI boot check box, to mark the image as UEFI bootable. This option cannot be configured after the image is uploaded.\n\n\r\n                Click Add to start uploading the image. The upload progress will be shown in the bottom right corner.\r\n            \n\nYou can hide the pop-up window without interrupting the upload process. The upload progress will be available in the notification center.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/uploading-images.html"
    },
    {
        "title": "Checking the RDMA network",
        "content": "Checking the RDMA network\nYou can check the RDMA network state via vendor-provided command line tools.\nTo check the network hardware\nLists the RDMA devices available for use:# ibv_devices\r\n    device          \t   node GUID\r\n    ------          \t----------------\r\n    rdmao1          \t5e6f69fffe27b644\r\n    rdmao2          \t5e6f69fffe27b645\r\n\nTo check the network connectivity\nStart the RDMA-ping server on any node:# rping -s -C 10 -v\nThen, start the RDMA-ping client on any other node:# rping -c -a <server_IP> -C 10 -v\nWhere <server_IP> is the IP address of the RDMA-ping server.\nThe tool will have an output similar to this:ping data: rdma-ping-0: ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqr\r\nping data: rdma-ping-1: BCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrs\r\nping data: rdma-ping-2: CDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrst\r\nping data: rdma-ping-3: DEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstu\r\nping data: rdma-ping-4: EFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuv\r\nping data: rdma-ping-5: FGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvw\r\nping data: rdma-ping-6: GHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwx\r\nping data: rdma-ping-7: HIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxy\r\nping data: rdma-ping-8: IJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz\r\nping data: rdma-ping-9: JKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyzA\r\nclient DISCONNECT EVENT...\r\n\nTo check the network bandwidth\nStart the benchmark server on any node:# ib_send_bw -d mlx4_0 -i 1 -F --report_gbits\nThen, start the benchmark client on any other node:# ib_send_bw -d mlx4_0 -i 1 -F --report_gbits <server_IP>\nWhere <server_IP> is the IP address of the benchmark server.\nThe tool will have an output similar to this:Send BW Test\r\nDual-port : OFF Device : mlx4_0\r\nNumber of qps : 1 Transport type : IB\r\nConnection type : RC\r\nRX depth : 512\r\nCQ Moderation : 100\r\nMtu : 1024[B]\r\nLink type : Ethernet\r\nGid index : 0\r\nMax inline data : 0[B]\r\nrdma_cm QPs : OFF\r\nData ex. method : Ethernet\r\n--------------------------------------------------------------------------\r\nlocal address: LID 0000 QPN 0x0065 PSN 0xc8f367\r\nGID: 254:128:00:00:00:00:00:00:246:82:20:255:254:23:27:129\r\nremote address: LID 0000 QPN 0x005d PSN 0x884d7d\r\nGID: 254:128:00:00:00:00:00:00:246:82:20:255:254:23:31:225\r\n--------------------------------------------------------------------------\r\n#bytes #iterations BW peak[Gb/sec] BW average[Gb/sec] MsgRate[Mpps]\r\n65536  1000        0.00            36.40              0.069428\r\n\nWhat's next\n\nConfiguring RDMA automatically",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/checking-the-rdma-network.html"
    },
    {
        "title": "Managing S3 users",
        "content": "Managing S3 users\nThe concept of an S3 user is one of the base concepts of object storage along with those of an object and a bucket (a container for storing objects). The Amazon S3 protocol uses a permission model based on access control lists (ACLs), where each bucket and each object are assigned an ACL that lists all users with access to the given resource and the type of this access (read, write, read ACL, or write ACL). The list of users includes the entity owner assigned to every object and bucket at creation. The entity owner has extra rights compared to other users. For example, the bucket owner is the only one who can delete that bucket.\nUser model and access policies implemented in Virtuozzo Hybrid Infrastructure comply with the Amazon S3 user model and access policies.\nUser management scenarios in Virtuozzo Hybrid Infrastructure are largely based on the Amazon Web Services user management and include the following operations: create, query, and delete users, as well as generate and revoke user access key pairs.\nEach S3 user has one or two key pairs (access key and secret key) for accessing the S3 cloud. You can think of the access key as the login and the secret key as the password. (For more information about S3 key pairs, refer to the Amazon documentation.) The access keys are generated and stored locally in the storage cluster on S3 name servers.\nEach self-service user that has enabled access to the S3 storage is mapped to an S3 user with an automatically generated name. The user name format is user_id@generated.com. Such an S3 user is also assigned a unique Amazon Resource Name (ARN). The ARN is generated as follows: arn:aws:iam::<domain_id>:<user_id>.\nTo access a bucket, a user needs the following information:\n\nAdmin panel IP address\nDNS name of the S3 cluster specified during configuration\nS3 access key ID\nS3 secret access key\nSSL certificate if the HTTPS protocol was chosen during configuration (the certificate file can be found in the /etc/nginx/ssl/ directory on any node hosting the S3 gateway service)\n\nPrerequisites\n\nS3 users are created, as described in Creating S3 users.\nA clear understanding of the best S3 practices, listed in Best practices for using S3 in Virtuozzo Hybrid Infrastructure.\n\nSee also\n\nManaging S3 buckets\n\nManaging S3 accounts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-s3-users.html"
    },
    {
        "title": "Enabling logging for virtual machines",
        "content": "Enabling logging for virtual machines\nThe console log of a virtual machine can be used for troubleshooting boot issues. The log contains messages only if logging is enabled inside the VM, otherwise the log is empty.\nThe logging can be turned on by enabling the TTY1 and TTYS0 logging levels in Linux VMs and Emergency Management Services (EMS) console redirection in Windows VMs. You may also enable driver status logging in Windows VMs, to see the list of loaded drivers. This can be useful for troubleshooting a faulty driver or long boot process.\nTo enable TTY1 and TTYS0 logging in Linux virtual machines\n\nAdd the line GRUB_CMDLINE_LINUX_DEFAULT=\"console=tty1 console=ttyS0\" to the file /etc/default/grub.\n\nDepending on the boot loader, run either# grub-mkconfig -o /boot/grub/grub.cfg\r\n\nor# grub2-mkconfig -o /boot/grub2/grub.cfg\r\n\n\nReboot the VM.\n\nTo enable EMS console redirection in Windows virtual machines\n\nStart Windows PowerShell by using administrator privileges.\n\nIn the PowerShell console, set the COM port and baud rate for EMS console redirection. As Windows VMs have only the COM1 port with the transmission rate of 9600 bps, run:bcdedit /emssettings EMSPORT:1\r\n\n\nEnable EMS for the current boot entry:bcdedit /ems on\r\n\n\nTo enable driver status logging in Windows virtual machines\n\nStart System Configuration by using administrator privileges.\nIn the System Configuration windows, open the Boot tab, and select the check boxes OS boot information and Make all boot settings permanent.\nConfirm the changes and restart the system.\n\nWhat's next\n\nCreating templates",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-logging-for-vms.html"
    },
    {
        "title": "Managing targets",
        "content": "Managing targets\nPrerequisites\n\nA target group is created, as described in Creating target groups.\n\nTo add a target to a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\nOn the Targets tab, click Add target. The Create target wizard will open.\n\nOn Nodes, select nodes to add to the target group. On these nodes, iSCSI targets will run. You can only choose nodes with network interfaces that are assigned the iSCSI traffic type. It is recommended to have at least two nodes in the target group to achieve high availability. If you plan to use multiple iSCSI initiators, you should have as many nodes in the target group. The optimal way is to create a single target per node.\nIf the node network interfaces are not configured, click the cogwheel icon, select the networks as required, and then click Apply.\n\nOn Targets, select iSCSI interfaces to add to the target group. You can choose from a list of network interfaces that are assigned the iSCSI traffic type. If you plan to use multiple iSCSI initiators, you should select as many interfaces per node. One interface can be added to multiple target groups, although it may reduce performance.\n\nOn Summary, review the target details. You can go back to change them if necessary. Click Next.\n\nThe created target will appear on the Targets tab.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group target create --node <node> --ip <ip> <target-group> <name>\n\n--node <node>\n\nNode ID or hostname\n--ip <ip>\n\nTarget IP address\n<target-group>\n\nTarget group name or ID\n<name>\n\nTarget name\n\nFor example, to add the target target3 to the target group tg1 that will run on the node node003 with the IP address 10.10.10.13, run:# vinfra service block-storage target-group target create --node node003 --ip 10.10.10.13 tg1 target3\nThe added target will appear in the vinfra service block-storage target-group target list output:# vinfra service block-storage target-group target list tg1\r\n+------------------+----------------------------------+---------+-----------------------+\r\n| node_id          | iqn                              | state   | portals               |\r\n+------------------+----------------------------------+---------+-----------------------+\r\n| 7a8f9a2f-fd11<\u00e2\u0080\u00a6> | iqn.2014-06.com.vstorage:target1 | offline | - ipaddr: 10.10.10.11 |\r\n|                  |                                  |         |   port: 3260          |\r\n| a32ba24a-2473<\u00e2\u0080\u00a6> | iqn.2014-06.com.vstorage:target2 | offline | - ipaddr: 10.10.10.12 |\r\n|                  |                                  |         |   port: 3260          |\r\n| 2cef3925-51dc<\u00e2\u0080\u00a6> | iqn.2014-06.com.vstorage:target3 | offline | - ipaddr: 10.10.10.13 |\r\n|                  |                                  |         |   port: 3260          |\r\n+------------------+----------------------------------+---------+-----------------------+\r\n\n\nTo start or stop all targets in a target group\n\nAdmin panel\n\n Open Storage services > Block storage > Target groups. \nClick the ellipsis icon of the desired target group, and then click Start targets or Stop targets.\n\nCommand-line interface\nUse the following commands:\n\nTo start all targets in your target group:vinfra service block-storage target-group start <target-group>\n\nTo stop all targets in your target group:vinfra service block-storage target-group stop <target-group>\n\nTo delete a target from a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\nOn the Targets tab, click the ellipsis button of the desired target, and then click Delete.\nIf the target has active connections, select Force.\nClick Delete in the confirmation window.\n\nIf you delete a target on the Active/Optimized path (indicated in LUN details), said path will switch to another target.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group target delete [--force] <target-group> <target>\n\n--force\n\nForcibly remove a target\n<target-group>\n\nTarget group name or ID\n<target>\n\nTarget IQN\n\nFor example, to remove the target with the IQN iqn.2014-06.com.vstorage:target3 from the target group tg1, run:# vinfra service block-storage target-group target delete tg1 iqn.2014-06.com.vstorage:target3\n\nSee also\n\nManaging volumes\n\nRestricting access to target groups\n\nMonitoring block storage\n\nDeleting target groups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group target create --node <node> --ip <ip> <target-group> <name>\n\n--node <node>\n\nNode ID or hostname\n--ip <ip>\n\nTarget IP address\n<target-group>\n\nTarget group name or ID\n<name>\n\nTarget name\n\nFor example, to add the target target3 to the target group tg1 that will run on the node node003 with the IP address 10.10.10.13, run:# vinfra service block-storage target-group target create --node node003 --ip 10.10.10.13 tg1 target3\nThe added target will appear in the vinfra service block-storage target-group target list output:# vinfra service block-storage target-group target list tg1\r\n+------------------+----------------------------------+---------+-----------------------+\r\n| node_id          | iqn                              | state   | portals               |\r\n+------------------+----------------------------------+---------+-----------------------+\r\n| 7a8f9a2f-fd11<\u00e2\u0080\u00a6> | iqn.2014-06.com.vstorage:target1 | offline | - ipaddr: 10.10.10.11 |\r\n|                  |                                  |         |   port: 3260          |\r\n| a32ba24a-2473<\u00e2\u0080\u00a6> | iqn.2014-06.com.vstorage:target2 | offline | - ipaddr: 10.10.10.12 |\r\n|                  |                                  |         |   port: 3260          |\r\n| 2cef3925-51dc<\u00e2\u0080\u00a6> | iqn.2014-06.com.vstorage:target3 | offline | - ipaddr: 10.10.10.13 |\r\n|                  |                                  |         |   port: 3260          |\r\n+------------------+----------------------------------+---------+-----------------------+\r\n\n",
                "title": "To add a target to a target group"
            },
            {
                "example": "\nCommand-line interface\nUse the following commands:\n\n\nTo start all targets in your target group:vinfra service block-storage target-group start <target-group>\n\n\nTo stop all targets in your target group:vinfra service block-storage target-group stop <target-group>\n\n\n",
                "title": "To start or stop all targets in a target group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group target delete [--force] <target-group> <target>\n\n--force\n\nForcibly remove a target\n<target-group>\n\nTarget group name or ID\n<target>\n\nTarget IQN\n\nFor example, to remove the target with the IQN iqn.2014-06.com.vstorage:target3 from the target group tg1, run:# vinfra service block-storage target-group target delete tg1 iqn.2014-06.com.vstorage:target3\n",
                "title": "To delete a target from a target group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\n\n\n\n\nOn the Targets tab, click Add target. The Create target wizard will open.\n\nOn Nodes, select nodes to add to the target group. On these nodes, iSCSI targets will run. You can only choose nodes with network interfaces that are assigned the iSCSI traffic type. It is recommended to have at least two nodes in the target group to achieve high availability. If you plan to use multiple iSCSI initiators, you should have as many nodes in the target group. The optimal way is to create a single target per node.\nIf the node network interfaces are not configured, click the cogwheel icon, select the networks as required, and then click Apply.\n\n\n\n\n\n\nOn Targets, select iSCSI interfaces to add to the target group. You can choose from a list of network interfaces that are assigned the iSCSI traffic type. If you plan to use multiple iSCSI initiators, you should select as many interfaces per node. One interface can be added to multiple target groups, although it may reduce performance.\n\n\n\n\n\nOn Summary, review the target details. You can go back to change them if necessary. Click Next.\n\nThe created target will appear on the Targets tab.\n",
                "title": "To add a target to a target group"
            },
            {
                "example": "\nAdmin panel\n\n Open Storage services > Block storage > Target groups. \nClick the ellipsis icon of the desired target group, and then click Start targets or Stop targets.\n\n",
                "title": "To start or stop all targets in a target group"
            },
            {
                "example": "\nAdmin panel\n\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\n\n\n\n\nOn the Targets tab, click the ellipsis button of the desired target, and then click Delete.\nIf the target has active connections, select Force.\nClick Delete in the confirmation window.\n\nIf you delete a target on the Active/Optimized path (indicated in LUN details), said path will switch to another target.\n",
                "title": "To delete a target from a target group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-targets.html"
    },
    {
        "title": "Required external access",
        "content": "Required external access\nFor non-disruptive cluster operation, the cluster must have network access to the following resources:\n\nDestination port\nAddress\nPurpose\n\nTCP 80, 443\nrepo.virtuozzo.com\nProduct repository\n\nTCP 80, 443\ndocker.io\nProduct repository\n\nTCP 80, 443\ndiscovery.etcd.io\nProduct repository\n\nTCP 80, 443\nregistry-1.docker.io\nProduct repository\n\nTCP 5224\nka.virtuozzo.com\nLicensing server\n\nTCP 22\nsftpe.virtuozzo.com\nSupport server\n\nUDP 123 (optional)\n*.pool.ntp.org\nNTP",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/required-external-access.html"
    },
    {
        "title": "Managing security group rules",
        "content": "Managing security group rules\nYou can modify security groups by adding and removing rules. Editing rules is not available. If you need to change the existing rule, remove it and re-create with the required parameters.\nPrerequisites\n\nYou have a security group created, as described in Creating and deleting security groups.\n\nTo add a rule to a security group\n\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click the security group to add a rule to.\nOn the group right pane, click Add in the Inbound or Outbound section to create a rule for incoming or outgoing traffic.\nSpecify the rule parameters:\r\n\t\t\tSelect a protocol from the list or enter a number from 0 to 255.Enter a single port or a port range. Some protocols already have a predefined port range. For example, the port for SSH is 22.Select a predefined subnet CIDR or an existing security group.\nClick the check mark to save the changes.\n\nAs soon as the rule is created, it is applied to all of the virtual machines assigned to the security group.\n\nCommand-line interface\nUse the following command:vinfra service compute security-group rule create [--remote-group <remote-group>]\r\n                                                  [--remote-ip <ip-address>]\r\n                                                  [--ethertype <ethertype>]\r\n                                                  [--protocol <protocol>]\r\n                                                  [--port-range-max <port-range-max>]\r\n                                                  [--port-range-min <port-range-min>]\r\n                                                  (--ingress | --egress)\r\n                                                  <security-group>\n\n--remote-group <remote-group>\n\nRemote security group name or ID\n--remote-ip <ip-address>\n\nRemote IP address block in CIDR notation\n--ethertype <ethertype>\n\nEthertype of network traffic: IPv4 or IPv6\n--protocol <protocol>\n\nIP protocol: tcp, udp, icmp, vrrp and others\n--port-range-max <port-range-max>\n\nThe maximum port number in the port range that satisfies the security group rule\n--port-range-min <port-range-min>\n\nThe minimum port number in the port range that satisfies the security group rule\n--ingress\n\nRule for incoming network traffic\n--egress\n\nRule for outgoing network traffic\n<security-group>\n\nSecurity group name or ID to create the rule in\n\nFor example, to create a rule in the security group mygroup to allow incoming IPv4 network traffic on TCP port 22, run:# vinfra service compute security-group rule create mygroup \\\r\n--ethertype IPv4 --protocol tcp --port-range-max 22 --port-range-min 22 --ingress\r\n+-------------------+--------------------------------------+\r\n| Field             | Value                                |\r\n+-------------------+--------------------------------------+\r\n| description       |                                      |\r\n| direction         | ingress                              |\r\n| ethertype         | IPv4                                 |\r\n| id                | 0f395e2f-a8ab-47f4-b670-64399461393c |\r\n| port_range_max    | 22                                   |\r\n| port_range_min    | 22                                   |\r\n| project_id        | e215189c0472482f93e71d10e1245253     |\r\n| protocol          | tcp                                  |\r\n| remote_group_id   |                                      |\r\n| remote_ip_prefix  |                                      |\r\n| security_group_id | 12e6b260-0b61-4551-8168-3e59602a2433 |\r\n+-------------------+--------------------------------------+\nThis rule will appear in the vinfra service compute security-group rule list output:# vinfra service compute security-group rule list mygroup -c id -c direction -c protocol\r\n+--------------------------------------+-----------+----------+\r\n| id                                   | direction | protocol |\r\n+--------------------------------------+-----------+----------+\r\n| 0f395e2f-a8ab-47f4-b670-64399461393c | ingress   | tcp      |\r\n| a7c65861-df3d-47f2-bec3-089747141936 | egress    |          |\r\n| ce854e2b-537f-4618-bea9-e9ec3d8616ac | egress    |          |\r\n+--------------------------------------+-----------+----------+\r\n\n\nTo remove a rule from a security group\n\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click the required security group.\nOn the group right pane, click the bin icon next to a rule you want to remove.\n\nAs soon as the rule is removed, this change is applied to all of the virtual machines assigned to the security group.\n\nCommand-line interface\nUse the following command:vinfra service compute security-group rule delete <security-group-rule>\r\n\n\n<security-group-rule>\n\nSecurity group rule  ID\n\nFor example, to delete the security group rule with the ID\u00a00f395e2f-a8ab-47f4-b670-64399461393c, run:# vinfra service compute security-group rule delete 0f395e2f-a8ab-47f4-b670-64399461393c\n\nSee also\n\nCreating virtual machines\n\nWhat's next\n\nChanging security group assignment",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute security-group rule create [--remote-group <remote-group>]\r\n                                                  [--remote-ip <ip-address>]\r\n                                                  [--ethertype <ethertype>]\r\n                                                  [--protocol <protocol>]\r\n                                                  [--port-range-max <port-range-max>]\r\n                                                  [--port-range-min <port-range-min>]\r\n                                                  (--ingress | --egress)\r\n                                                  <security-group>\n\n--remote-group <remote-group>\n\nRemote security group name or ID\n--remote-ip <ip-address>\n\nRemote IP address block in CIDR notation\n--ethertype <ethertype>\n\nEthertype of network traffic: IPv4 or IPv6\n--protocol <protocol>\n\nIP protocol: tcp, udp, icmp, vrrp and others\n--port-range-max <port-range-max>\n\nThe maximum port number in the port range that satisfies the security group rule\n--port-range-min <port-range-min>\n\nThe minimum port number in the port range that satisfies the security group rule\n--ingress\n\nRule for incoming network traffic\n--egress\n\nRule for outgoing network traffic\n<security-group>\n\nSecurity group name or ID to create the rule in\n\nFor example, to create a rule in the security group mygroup to allow incoming IPv4 network traffic on TCP port 22, run:# vinfra service compute security-group rule create mygroup \\\r\n--ethertype IPv4 --protocol tcp --port-range-max 22 --port-range-min 22 --ingress\r\n+-------------------+--------------------------------------+\r\n| Field             | Value                                |\r\n+-------------------+--------------------------------------+\r\n| description       |                                      |\r\n| direction         | ingress                              |\r\n| ethertype         | IPv4                                 |\r\n| id                | 0f395e2f-a8ab-47f4-b670-64399461393c |\r\n| port_range_max    | 22                                   |\r\n| port_range_min    | 22                                   |\r\n| project_id        | e215189c0472482f93e71d10e1245253     |\r\n| protocol          | tcp                                  |\r\n| remote_group_id   |                                      |\r\n| remote_ip_prefix  |                                      |\r\n| security_group_id | 12e6b260-0b61-4551-8168-3e59602a2433 |\r\n+-------------------+--------------------------------------+\nThis rule will appear in the vinfra service compute security-group rule list output:# vinfra service compute security-group rule list mygroup -c id -c direction -c protocol\r\n+--------------------------------------+-----------+----------+\r\n| id                                   | direction | protocol |\r\n+--------------------------------------+-----------+----------+\r\n| 0f395e2f-a8ab-47f4-b670-64399461393c | ingress   | tcp      |\r\n| a7c65861-df3d-47f2-bec3-089747141936 | egress    |          |\r\n| ce854e2b-537f-4618-bea9-e9ec3d8616ac | egress    |          |\r\n+--------------------------------------+-----------+----------+\r\n\n",
                "title": "To add a rule to a security group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute security-group rule delete <security-group-rule>\r\n\n\n<security-group-rule>\n\nSecurity group rule  ID\n\nFor example, to delete the security group rule with the ID\u00a00f395e2f-a8ab-47f4-b670-64399461393c, run:# vinfra service compute security-group rule delete 0f395e2f-a8ab-47f4-b670-64399461393c\n",
                "title": "To remove a rule from a security group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click the security group to add a rule to.\nOn the group right pane, click Add in the Inbound or Outbound section to create a rule for incoming or outgoing traffic.\nSpecify the rule parameters:\r\n\t\t\tSelect a protocol from the list or enter a number from 0 to 255.Enter a single port or a port range. Some protocols already have a predefined port range. For example, the port for SSH is 22.Select a predefined subnet CIDR or an existing security group.\nClick the check mark to save the changes.\n\nAs soon as the rule is created, it is applied to all of the virtual machines assigned to the security group.\n",
                "title": "To add a rule to a security group"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Security groups tab, click the required security group.\nOn the group right pane, click the bin icon next to a rule you want to remove.\n\nAs soon as the rule is removed, this change is applied to all of the virtual machines assigned to the security group.\n",
                "title": "To remove a rule from a security group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-security-group-rules.html"
    },
    {
        "title": "Restarting and deleting VPN connections",
        "content": "Restarting and deleting VPN connections\nYou can forcefully re-initiate a VPN connection by manually restarting it. When you delete a VPN connection, you also delete the IKE and IPsec policies and endpoint groups that were created during the VPN creation.\nPrerequisites\n\nA VPN connection is created, as described in Creating VPN connections.\n\nTo restart a VPN connection\n\nOn the VPN screen, click a VPN connection to restart.\nOn the connection right pane, click Restart.\nClick Restart VPN in the confirmation window.\n\nTo delete a VPN connection\n\nOn the VPN screen, click a VPN connection to delete.\nOn the connection right pane, click Delete.\nClick Delete in the confirmation window.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/restarting-and-deleting-vpn-connections.html"
    },
    {
        "title": "Updating backups",
        "content": "Updating backupsPUT /v3/{project_id}/backups/{backup_id}\nUpdate settings in a backup.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/#update-a-backup\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nbackup_id\n\npath\nstring\nThe UUID for a backup.\n\nbackup\n\nbody\nobject\nA backup object.\n\ndescription (Optional)\nbody\nstring\nThe backup description or null.\n\nname (Optional)\nbody\nstring\nThe name of the volume backup.\n\nmetadata (Optional)\nbody\nobject\n\nThe backup metadata key value pairs.\nNew in version 3.43\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'OpenStack-API-Version: volume 3.66' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"backup\":{\r\n        \"name\":\"mybackup\",\r\n        \"description\": \"My new backup\"\r\n    }\r\n}' https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nbackup\n\nbody\nobject\nA backup object.\n\nid\n\nbody\nstring\nThe UUID of the backup.\n\nlinks\n\nbody\narray\nLinks for the backup.\n\nname\n\nbody\nstring\nThe backup name.\n\nmetadata (Optional)\nbody\nobject\n\nThe backup metadata key value pairs.\nNew in version 3.43\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\nExample{\r\n  \"backup\": {\r\n    \"id\": \"bcb8fc88-a0ba-4cd0-801a-e9face1eac88\",\r\n    \"name\": \"mybackup\",\r\n    \"links\": [\r\n      {\r\n        \"rel\": \"self\",\r\n        \"href\": \"https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\"\r\n      },\r\n      {\r\n        \"rel\": \"bookmark\",\r\n        \"href\": \"https://<node_IP_addr>:8776/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88\"\r\n      }\r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-backups.html"
    },
    {
        "title": "Aggregating Kubernetes clusters",
        "content": "Aggregating Kubernetes clustersPOST /v1/aggregates?details=False&needed_overlap=0.0&start={start_date}&stop={stop_date}\r\n\nAggregate the number of Kubernetes clusters per project for a specific period of time.\n\nIf the start or stop date is not specified, the missing value will be set to the first or last timestamp common across the time series.\n\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\noperation\n\nbody\nstring\nOperations to apply to the time series. For aggregation across metrics, use the following syntax: aggregate <aggregation_method> ((metric <metric_id> <aggregation_method>), ...). Supported aggregation methods are: mean, median, std, min, max, sum, var, count.\n\nsearch\n\nbody\nstring\nA query to filter resources. The syntax includes an attribute, operator, and value. For example, the query id=90d58eea-70d7-4294-a49a-170dcdf44c3c will filter a resource with the specified ID. You can use more complex queries, for example, not (flavor_id!=\u00e2\u0080\u009d1\u00e2\u0080\u009d and memory>=24). Use \u00e2\u0080\u009c\u00e2\u0080\u009d to interpret data as a string. Supported operators are: not, and, \u00e2\u0088\u00a7 or, \u00e2\u0088\u00a8, >=, <=, !=, >, <, =, ==, eq, ne, lt, gt, ge, le, in, like, \u00e2\u0089\u00a0, \u00e2\u0089\u00a5, \u00e2\u0089\u00a4, like, in.\n\nresource_type\n\nbody\nstring\n\nA resource type that a metric is associated with. For example, these metrics are bound to:\n\nvCPU and RAM metrics\u00e2\u0080\u0094the instance resource type\nStorage metrics\u00e2\u0080\u0094the volume resource type\nFloating IP addresses\u00e2\u0080\u0094the network resource type\nLoad balancers\u00e2\u0080\u0094the loadbalancer resource type\nKubernetes clusters\u00e2\u0080\u0094the coe_cluster resource type\n\nExample\nAggregate the number of Kubernetes clusters for the project with the ID 75521ab61d1f4e9090aac5836c219492 from 12:00 PM July 18, 2021, to 13:00 PM July 19, 2021.\n\nKubernetes clusters may be created with an empty project ID. In this case, specify None for the project_id attribute.\n# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"operations\":\"(aggregate sum (metric magnum.cluster mean))\",\r\n    \"search\":\"project_id=75521ab61d1f4e9090aac5836c219492\",\r\n    \"resource_type\":\"coe_cluster\"\r\n}' https://<node_IP_addr>:8041/v1/aggregates?details=False&needed_overlap=0.0&\\\r\nstart=2021-07-18T12:00:00&stop=2021-07-19T12:00:00\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nmeasures\n\nbody\nstring\nA list of measures for a metric.\n\naggregated\n\nbody\narray\nA number of aggregates, each consisting of a timestamp, granularity, and value.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"measures\": {\r\n    \"aggregated\": [\r\n      [\r\n        \"2021-07-18T12:00:00+00:00\",\r\n        300.0,\r\n        1\r\n      ],\r\n      <...>\r\n      [\r\n        \"2021-07-19T11:00:00+00:00\",\r\n        300.0,\r\n        1\r\n      ] \r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/aggregating-kubernetes-clusters.html"
    },
    {
        "title": "5. BitNinja Full-Stack Server Protection Agent Requirements\u00c2\u00b6",
        "content": "5. BitNinja Full-Stack Server Protection Agent Requirements | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\u00c2\u00b6\nThe following section describes, what are the minimum requirements needed for the BitNinja agent, what Operating Systems are supported and also information about required ports for BitNinja and compatibility matrix for the interoperation of BitNinja with other tools in the market. We will also look at how to protect a workload by installing the BitNinja Full-stack server protection agent.\n\nIn this chapter:\n\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/bitninja-agent-requirements/index.html"
    },
    {
        "title": "Creating virtual machines with physical GPUs",
        "content": "Creating virtual machines with physical GPUs\nLimitations\n\nVirtual machines with attached physical GPUs cannot be live migrated.\n\nPrerequisites\n\nThe compute cluster is reconfigured for GPU passthrough, as described in Enabling PCI passthrough and vGPU support.\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo create a virtual machine with an attached physical GPU\n\nCreate a flavor with the pci_passthrough property specifying the GPU alias from the pci-passthrough.yaml file and the number of GPUs to use. For example, to create the gpu-flavor flavor with 8 vCPUs and 16 GiB of RAM, run:# openstack --insecure flavor create --ram 16384 --vcpus 8 --property \"pci_passthrough:alias\"=\"gpu:1\" \\\r\n--public gpu-flavor\n\nSome drivers may require to hide the hypervisor signature. To do this, add the hide_hypervisor_id property to the flavor:# openstack --insecure flavor set gpu-flavor --property hide_hypervisor_id=true\n\nCreate a virtual machine specifying the gpu-flavor flavor. For example, to create the gpu-vm from the vol2 volume, run:# openstack --insecure server create --volume vol2 --flavor gpu-flavor gpu-vm\n\nSee also\n\nCreating virtual machines with virtual GPUs\n\nCreating virtual machines with different vGPU types\n\nCreating virtual machines with SR-IOV network ports\n\nCreating virtual machines\n\nDisabling PCI passthrough and vGPU support",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtual-machines-with-physical-gpus.html"
    },
    {
        "title": "Creating floating IPs",
        "content": "Creating floating IPsPOST /v2.0/floatingips\r\n\nCreate a floating IP.\nYou can obtain the required floating_network_id and subnet_id from a request to v2.0/networks?provider:physical_network=Public.\nThe status will change to ACTIVE after a while.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-floating-ip-detail#create-floating-ip\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingip\n\nbody\nobject\nA floatingip object. When you associate a\r\nfloating IP address with a VM, the instance has the same public IP\r\naddress each time that it boots, basically to maintain a\r\nconsistent IP address for maintaining DNS assignment.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource.\r\nDefault is an empty string.\n\ndns_domain (Optional)\nbody\nstring\nA valid DNS domain.\n\ndns_name (Optional)\nbody\nstring\nA valid DNS name.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nfloating_network_id\n\nbody\nstring\nThe ID of the network associated with the\r\nfloating IP.\n\nfixed_ip_address (Optional)\nbody\nstring\nThe fixed IP address that is associated with the floating IP.\r\nIf an internal port has multiple associated IP addresses,\r\nthe service chooses the first IP address unless you explicitly\r\ndefine a fixed IP address in the fixed_ip_address parameter.\n\nfloating_ip_address (Optional)\nbody\nstring\nThe floating IP address.\n\nport_id (Optional)\nbody\nstring\nThe ID of a port associated with the floating IP.\r\nTo associate the floating IP with a fixed IP at creation time,\r\nyou must specify the identifier of the internal port.\n\nsubnet_id (Optional)\nbody\nstring\nThe subnet ID on which you want to create the floating IP.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"floatingip\": {\r\n        \"floating_network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n        \"port_id\": \"165d5ff3-d015-4361-9bce-d59054c585cf\",\r\n        \"subnet_id\": \"351884c7-ee37-4a7d-9dcb-4cff4a1bba27\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/floatingips\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingip\n\nbody\nobject\nA floatingip object. When you associate a\r\nfloating IP address with a VM, the instance has the same public IP\r\naddress each time that it boots, basically to maintain a\r\nconsistent IP address for maintaining DNS assignment.\n\nid\n\nbody\nstring\nThe ID of the floating IP address.\n\nrouter_id\n\nbody\nstring\nThe ID of the router for the floating IP.\n\nstatus\n\nbody\nstring\nThe status of the floating IP. Values are\r\nACTIVE, DOWN and ERROR.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\ndns_name\n\nbody\nstring\nA valid DNS name.\n\nport_details\n\nbody\nstring\nThe information of the port that this floating IP associates with.\r\nIn particular, if the floating IP is associated with a port, this field\r\ncontains some attributes of the associated port, including name,\r\nnetwork_id, mac_address, admin_state_up, status,\r\ndevice_id and device_owner. If the floating IP is not associated\r\nwith a port, this field is null.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nfloating_network_id\n\nbody\nstring\nThe ID of the network associated with the\r\nfloating IP.\n\nfixed_ip_address\n\nbody\nstring\nThe fixed IP address that is associated with the\r\nfloating IP address.\n\nfloating_ip_address\n\nbody\nstring\nThe floating IP address.\n\nport_id\n\nbody\nstring\n\nThe ID of a port associated with the floating IP.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\nport_forwardings\n\nbody\narray\nThe associated port forwarding resources for the floating IP. If the\r\nfloating IP has multiple port forwarding resources, this field has\r\nmultiple entries. Each entry consists of network IP protocol\r\n(protocol), the fixed IP address of internal neutron port\r\n(internal_ip_address), the TCP or UDP port used by internal\r\nneutron port (internal_port) and the TCP or UDP port used by\r\nfloating IP (external_port).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nThe operation returns the Bad Request (400) response code for one of\r\nreasons:\n\nThe network is not external, such as router:external=False.\nThe internal OpenStack Networking port is not associated with the\r\nfloating IP address.\nThe requested floating IP address does not fall in the subnet\r\nrange for the external network.\nThe fixed IP address is not valid.\n\nIf the port ID is not valid, this operation returns 404 response code.\nThe operation returns the Conflict (409) response code for one of\r\nreasons:\n\nThe requested floating IP address is already in use.\nThe internal OpenStack Networking port and fixed IP address are\r\nalready associated with another floating IP.\n\nExample{\r\n  \"floatingip\": {\r\n    \"router_id\": \"02542148-44cb-470d-a551-58f370c47b83\",\r\n    \"status\": \"DOWN\",\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-03-05T11:40:28Z\",\r\n    \"updated_at\": \"2020-03-05T11:40:28Z\",\r\n    \"floating_network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n    \"port_details\": {\r\n      \"status\": \"ACTIVE\",\r\n      \"name\": \"\",\r\n      \"admin_state_up\": true,\r\n      \"network_id\": \"c4e2f31b-fe3b-402b-ac1b-b182693f72f7\",\r\n      \"device_owner\": \"compute:nova\",\r\n      \"mac_address\": \"fa:16:3e:66:ab:b3\",\r\n      \"device_id\": \"e1ae6f7e-c35d-4656-a4fd-2371f9a791d4\"\r\n    },\r\n    \"fixed_ip_address\": \"192.168.0.112\",\r\n    \"floating_ip_address\": \"10.94.139.174\",\r\n    \"revision_number\": 0,\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"port_id\": \"165d5ff3-d015-4361-9bce-d59054c585cf\",\r\n    \"id\": \"f32947e7-8844-4eb2-a496-ef5653380584\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-floating-ips.html"
    },
    {
        "title": "Managing static routes",
        "content": "Managing static routes\nYou can also configure static routes of a router by manually adding entries into its routing table. This can be useful, for example, if you do not need a mutual connection between two virtual networks and want only one virtual network to be accessible from the other.\nConsider the following example:\n\nThe virtual machine VM1 is connected to the virtual network private1 (192.168.128.0/24) via the network interface with IP address 192.168.128.10.\nThe virtual machine VM2 is connected to the virtual network private2 (192.168.30.0/24) via the network interface with IP address 192.168.30.10.\nThe router router1 connects the network private1 to the physical network via the external gateway with the IP address 10.94.129.73.\nThe router router2 connects the network private2 to the physical network via the external gateway with the IP address 10.94.129.74.\n\nTo be able to access VM2 from VM1, you need to add a static route for router1, specifying the CIDR of private2, that is 192.168.30.0/24, as the destination subnet and the external gateway IP address of router2, that is 10.94.129.74, as the next hop IP address. In this case, when an IP packet for 192.168.30.10 reaches router1, it will be forwarded to router2 and then to VM2.\nPrerequisites\n\nYou have a virtual router created, as described in Creating virtual routers.\n\nTo create a static route for a router\n\nAdmin panel\n\nOn the Routers screen, click the router name. Open the Static routes tab, and then click Add on the right pane. If there are no routes to show, click Add static route.\n\nIn the Add static route window, specify the destination subnet range and mask in CIDR notation and the next hop\u00e2\u0080\u0099s IP address. The next hop\u00e2\u0080\u0099s IP address must belong to one of the networks that the router is connected to.\n\nClick Add.\n\nCommand-line interface\nUse the following command:vinfra service compute router set --route <destination=destination,\r\n                                  nexthop=nexthop> <router>\r\n\n\n--route <destination=destination,nexthop=nexthop>\n\nA static route for the router. This option can be used multiple times.\n\ndestination: destination subnet range in CIDR notation.\nnexthop: next hop IP address from one of the networks that the router is connected to.\n\n<router>\n\nVirtual router name or ID\n\nFor example, to create a static route for the virtual router myrouter with the destination subnet 192.128.30.0/24 and the next top IP address 10.94.129.74, run:# vinfra service compute router set myrouter --route destination=192.128.30.0/24,nexthop=10.94.129.74\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | - destination: 192.128.30.0/24                   |\r\n|                       |   nexthop: 10.94.129.74                          |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\n\nTo edit a static route\n\nAdmin panel\n\nClick the ellipsis icon next to the required static route, and then click Edit. \nIn the Edit static route window, change the desired parameters, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra service compute router set --route <destination=destination,\r\n                                  nexthop=nexthop> <router>\r\n\n\n--route <destination=destination,nexthop=nexthop>\n\nA static route for the router. This option can be used multiple times.\n\ndestination: destination subnet range in CIDR notation.\nnexthop: next hop IP address from one of the networks that the router is connected to.\n\n<router>\n\nVirtual router name or ID\n\nFor example, to edit the destination subnet to 192.168.30.0/24 and the next top IP address 10.94.129.15 for the virtual router myrouter, run:# vinfra service compute router set myrouter --route destination=192.168.30.0/24,nexthop=10.94.129.15\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | - destination: 192.168.30.0/24                   |\r\n|                       |   nexthop: 10.94.129.15                          |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\n\nTo remove a static route\n\nAdmin panel\nClick the ellipsis icon next to the static route you want to remove, and then click Delete. \n\nCommand-line interface\nUse the following command:vinfra service compute router set --no-route <router>\r\n\n\n--no-route\n\nClear routes associated with the router\n<router>\n\nVirtual router name or ID\n\nFor example, to delete all of the static routes for the virtual router myrouter, run:# vinfra service compute router set myrouter --no-route\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | []                                               |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\n\nSee also\n\nManaging router interfaces\n\nViewing router ports",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router set --route <destination=destination,\r\n                                  nexthop=nexthop> <router>\r\n\n\n--route <destination=destination,nexthop=nexthop>\n\n\nA static route for the router. This option can be used multiple times.\n\ndestination: destination subnet range in CIDR notation.\nnexthop: next hop IP address from one of the networks that the router is connected to.\n\n\n<router>\n\nVirtual router name or ID\n\nFor example, to create a static route for the virtual router myrouter with the destination subnet 192.128.30.0/24 and the next top IP address 10.94.129.74, run:# vinfra service compute router set myrouter --route destination=192.128.30.0/24,nexthop=10.94.129.74\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | - destination: 192.128.30.0/24                   |\r\n|                       |   nexthop: 10.94.129.74                          |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\n",
                "title": "To create a static route for a router"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router set --route <destination=destination,\r\n                                  nexthop=nexthop> <router>\r\n\n\n--route <destination=destination,nexthop=nexthop>\n\n\nA static route for the router. This option can be used multiple times.\n\ndestination: destination subnet range in CIDR notation.\nnexthop: next hop IP address from one of the networks that the router is connected to.\n\n\n<router>\n\nVirtual router name or ID\n\nFor example, to edit the destination subnet to 192.168.30.0/24 and the next top IP address 10.94.129.15 for the virtual router myrouter, run:# vinfra service compute router set myrouter --route destination=192.168.30.0/24,nexthop=10.94.129.15\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | - destination: 192.168.30.0/24                   |\r\n|                       |   nexthop: 10.94.129.15                          |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\n",
                "title": "To edit a static route"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router set --no-route <router>\r\n\n\n--no-route\n\nClear routes associated with the router\n<router>\n\nVirtual router name or ID\n\nFor example, to delete all of the static routes for the virtual router myrouter, run:# vinfra service compute router set myrouter --no-route\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: false                               |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | []                                               |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\n",
                "title": "To remove a static route"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Routers screen, click the router name. Open the Static routes tab, and then click Add on the right pane. If there are no routes to show, click Add static route.\n\nIn the Add static route window, specify the destination subnet range and mask in CIDR notation and the next hop\u00e2\u0080\u0099s IP address. The next hop\u00e2\u0080\u0099s IP address must belong to one of the networks that the router is connected to.\n\n\n\n\n\n\nClick Add.\n\n\n",
                "title": "To create a static route for a router"
            },
            {
                "example": "\nAdmin panel\n\nClick the ellipsis icon next to the required static route, and then click Edit. \nIn the Edit static route window, change the desired parameters, and then click Save.\n\n",
                "title": "To edit a static route"
            },
            {
                "example": "\nAdmin panel\nClick the ellipsis icon next to the static route you want to remove, and then click Delete. \n",
                "title": "To remove a static route"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-static-routes.html"
    },
    {
        "title": "5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\u00c2\u00b6",
        "content": "5.2. Creating Leostream Infrastructure VMs (Broker and Gateway) | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\u00c2\u00b6\nThe Connection Broker and Leostream Gateway install on the latest 64-bit CentOS 7 or Red Hat Enterprise Linux 7. Each component requires a unique VM.\n\nNote\nNeither the Connection Broker nor the Leostream Gateway can be deployed on CentOS 8, Red Hat Enterprise Linux version 8, or any other Linux distribution.\n\nWhen creating a virtual machine for the Connection Broker installation, ensure that the VM has, at least, the following resources:\n\n4 vCPUs\n8.0 GB of RAM\nAt least 20 GB of hard drive space\nOne NIC, ideally with internet connectivity\n\nAt a minimum, create a virtual machine for your Leostream Gateway with the following resources.\n\n2 or more CPUs or vCPUs at 2.5GHz or higher\n4 GB of RAM, more if using the built-in Leostream HTML5 viewer.\n4 GB of swap space\n20 GB of free disk\n\nTo create virtual machines using the VM creation wizard. Go to Compute > Virtual Machines and click Create Virtual Machine. For complete instructions, see Creating virtual machines. The following figure shows an example creating a VM for the Connection Broker from your CentOS 7 image and using a large flavor.\n\nWhen creating the VMs ensure that the Connection Broker VM has access to the Broker-Network and the Gateway VM has access to the Gateway-Network by attaching the network during the VM creation wizard. If you forget to do so, you can attach the network once the VM has been created.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/installing-leostream/creating-infrastructure-vms.html"
    },
    {
        "title": "Showing load balancer details",
        "content": "Showing load balancer detailsGET /v2/lbaas/loadbalancers/{loadbalancer_id}\r\n\nShow the details of a load balancer with the specified ID.\nIf you are not an administrative user and the load balancer object does not\r\nbelong to your project, the service returns the HTTP Forbidden (403)\r\nresponse code.\nSource: https://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=show-load-balancer-details-detail#show-load-balancer-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nloadbalancer_id\n\npath\nuuid\nThe ID of the load balancer to query.\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9888/v2/lbaas/loadbalancers/601be015-0753-4221-931c-d26d81248551\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nloadbalancer\n\nbody\nobject\nA loadbalancer object.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\nflavor_id\n\nbody\nuuid\nThe ID of the flavor.\n\nid\n\nbody\nuuid\nThe ID of the load balancer.\n\nlisteners\n\nbody\narray\nThe associated listener IDs, if any.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\noperating_status\n\nbody\nstring\nThe operating status of the resource.\n\npools\n\nbody\narray\nThe associated pool IDs, if any.\n\nproject_id\n\nbody\nstring\nThe ID of the project owning this resource.\n\nprovider\n\nbody\nstring\nProvider name for the load balancer.\n\nprovisioning_status\n\nbody\nstring\nThe provisioning status of the resource.\n\ntags\n\nbody\nlist\n\nA list of simple strings assigned to the resource.\nNew in version 2.5\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvip_address\n\nbody\nstring\nThe IP address of the Virtual IP (VIP).\n\nvip_network_id\n\nbody\nuuid\nThe ID of the network for the Virtual IP (VIP).\n\nvip_port_id\n\nbody\nuuid\nThe ID of the Virtual IP (VIP) port.\n\nvip_qos_policy_id\n\nbody\nuuid\nThe ID of the QoS Policy which will apply to the Virtual IP (VIP).\n\nvip_subnet_id\n\nbody\nuuid\nThe ID of the subnet for the Virtual IP (VIP).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\nExample{\r\n  \"loadbalancer\": {\r\n    \"provider\": \"amphora\",\r\n    \"description\": \"\",\r\n    \"admin_state_up\": true,\r\n    \"pools\": [\r\n      {\r\n        \"id\": \"e7ac20f9-a4f9-4bf7-9333-ae96e1d34e0c\"\r\n      }\r\n    ],\r\n    \"created_at\": \"2020-03-19T18:04:56.378183\",\r\n    \"provisioning_status\": \"ACTIVE\",\r\n    \"updated_at\": \"2020-03-19T18:09:33.467099\",\r\n    \"vip_qos_policy_id\": null,\r\n    \"vip_network_id\": \"15f7dc0a-712c-422f-bfd3-31dc351d9026\",\r\n    \"listeners\": [\r\n      {\r\n        \"id\": \"ab110967-fd83-4a41-b3c5-4083395bdc86\"\r\n      }\r\n    ],\r\n    \"tags\": [],\r\n    \"vip_port_id\": \"c39af70f-a725-4b2b-b876-16ad636868ac\",\r\n    \"flavor_id\": null,\r\n    \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"vip_address\": \"192.168.10.46\",\r\n    \"vip_subnet_id\": \"fd2de462-f93b-43a6-9b5c-254f1e690bf1\",\r\n    \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"id\": \"601be015-0753-4221-931c-d26d81248551\",\r\n    \"operating_status\": \"ONLINE\",\r\n    \"name\": \"lb1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-load-balancer-details.html"
    },
    {
        "title": "Managing S3 users in WHMCS",
        "content": "Managing S3 users in WHMCS\nThis section describes how to manage users in WHMCS in a service provider scenario. New customers will sign up for the service during purchase in your online store and you will need to create users for them in the S3 cluster.\nCreate all files mentioned further in the directory whmcs/admin/staas_scripts.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-users-in-whmcs.html"
    },
    {
        "title": "Managing volume backups",
        "content": "Managing volume backups\nA backup is a full copy of a compute volume stored in an external service. A backup can subsequently be restored from the external service to a new volume.\nYou can create backups automatically by using backup plans or initiate backups manually. Every backup plan contains set of actions that carry out the backup job.\nWhen you create, list, or delete backups, these status values are possible:\n\nCREATING\n\nThe backup is being created.\nAVAILABLE\n\nThe backup is ready to restore to a volume.\nDELETING\n\nThe backup is being deleted.\nERROR\n\nA backup error occurred.\nRESTORING\n\nThe backup is being restored to a volume.\nERROR_DELETING\n\nAn error occurred while deleting the backup.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-volume-backups.html"
    },
    {
        "title": "Attaching and detaching volumes",
        "content": "Attaching and detaching volumes\nLimitations\n\nYou can only attach and detach non-boot volumes.\n\nPrerequisites\n\nA volume is created, as described in Creating and deleting volumes.\nTo be able to use volumes attached to VMs, they must be initialized inside the guest OS by standard means.\n\nTo attach a volume to a virtual machine\n\nOn the  Volumes screen, click an unused volume. \nOn the volume right pane, click Attach.\n\nIn the Attach volume window, select the VM from the drop-down list, and then click Done.\n\nTo detach a volume from a virtual machine\n\nOn the  Volumes screen, click a volume that is in use.\nIf the VM is stopped, click Detach on the volume right pane.\n\nIf the VM is running, click Force detach on the volume right pane.\n\nThere is a risk of data loss.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/attaching-and-detaching-volumes.html"
    },
    {
        "title": "Changing the default project quotas",
        "content": "Changing the default project quotas\nThe default quotas are applied when creating a project via the OpenStack API. You can modify the following default quotas:\n\nParameter\nConfiguration file\nDescription\nValue\n\ndefault_trait_quota\n\n/etc/kolla/placement-api/placement.conf\n\nSets the maximum number of placements per project.\nValid values are integer. The default value is set to 0. To make the parameter unlimited, set the value to -1.\n\ndefault_load_balancer_quota\n\n/etc/kolla/octavia-api/octavia.conf\n\nSets the maximum number of load balancers per project.\n\nmax_clusters_per_project\n\n/etc/kolla/magnum-api/magnum.conf\n\nSets the maximum number of Kubernetes clusters per project.\n\nIf required, you can also change default quotas for other compute resources. To do this, refer to the official OpenStack documentation.\nTo change the default project quota\nUse the following command:vinfra service compute set [--custom-param <service_name> <config_file> <section> <property> <value>]\r\n                           [--load-balancer-default-quota <value>] [--k8s-default-quota <value>]\r\n                           [--placement-default-quota <value>]\n\n--custom-param <service_name> <config_file> <section> <property> <value>\n\nSet custom parameters for OpenStack configuration files:\n\nservice_name is the service name: octavia-api, magnum-api, or placement-api\nconfig_file specifies the service configuration file: octavia.conf for octavia-api, magnum.conf for magnum-api, or placement.conf for placement-api\nsection specifies the section in the service configuration file where the parameter is defined: quotas in octavia.conf and magnum.conf, or quota in placement.conf\nproperty is the parameter to be changed: default_load_balancer_quota in octavia.conf, max_clusters_per_project in magnum.conf, or default_trait_quota in placement.conf\nvalue is a new parameter value\n\n--load-balancer-default-quota <value>\n\nShortcut for --custom-param octavia-api octavia.conf quotas default_load_balancer_quota <value>\n--k8s-default-quota <value>\n\nShortcut for --custom-param magnum-api magnum.conf quotas max_clusters_per_project <value>\n--placement-default-quota <value>\n\nShortcut for --custom-param placement-api placement.conf quota default_trait_quota <value>\n\nFor example, to make the number of placements per project unlimited, but limit the maximum number of load balancers to 100 and Kubernetes clusters to 10 per project, run:# vinfra service compute set --placement-default-quota -1 --load-balancer-default-quota 100 --k8s-default-quota 10\r\n\nTo check that the default project quotas are successfully modified, run:# vinfra service compute show\r\n+--------------+-----------------------------------------+\r\n| Field        | Value                                   |\r\n+--------------+-----------------------------------------+\r\n| <...>        | <...>                                   |\r\n| options      | cpu_model: ''                           |\r\n|              | custom_params:                          |\r\n|              | - config_file: octavia.conf             |\r\n|              |   property: default_load_balancer_quota |\r\n|              |   section: quotas                       |\r\n|              |   service_name: octavia-api             |\r\n|              |   value: 100                            |\r\n|              | - config_file: magnum.conf              |\r\n|              |   property: max_clusters_per_project    |\r\n|              |   section: quotas                       |\r\n|              |   service_name: magnum-api              |\r\n|              |   value: 10                             |\r\n|              | - config_file: placement.conf           |\r\n|              |   property: default_trait_quota         |\r\n|              |   section: quota                        |\r\n|              |   service_name: placement-api           |\r\n|              |   value: -1                             |\r\n|              | notification_forwarding: disabled       |\r\n| status       | active                                  |\r\n+--------------+-----------------------------------------+\nSee also\n\nChanging parameters in OpenStack configuration files",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-the-default-project-quotas.html"
    },
    {
        "title": "Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "Hystax Acura Integration for Virtuozzo Hybrid Infrastructure | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nNext\n\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\u00c2\u00b6\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/index.html"
    },
    {
        "title": "9.1. Enabling Connection Broker Forwarding\u00c2\u00b6",
        "content": "9.1. Enabling Connection Broker Forwarding | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n9.1. Enabling Connection Broker Forwarding\u00c2\u00b6\nThe Leostream Gateway can be used to forward user login traffic from Leostream client devices to the Leostream Connection Broker. With Connection Broker forwarding enabled, the Connection Broker does not need to be accessible from the user\u00e2\u0080\u0099s client device and, instead, can be isolated in the same network as your desktops.\nTo enable Connection Broker forwarding, log into your Leostream Gateway and execute the following command:\nsudo leostream-gateway --broker <your-broker-address>\n\n\nThe following figure shows an example of enabling Connection Broker forwarding:\n\nYou can now access the Connection Broker Administrator Web interface using the public floating IP address of your Leostream Gateway.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/configuring-broker/enabling-forwarding.html"
    },
    {
        "title": "Enabling management node high availability",
        "content": "Enabling management node high availability\nTo make your infrastructure more resilient and redundant, you can create a high availability (HA) configuration of three nodes. After it is created, you can expand it up to five nodes. With a five-node HA configuration, the cluster can tolerate a simultaneous failure of two management nodes.\nPrerequisites\n\nA clear understanding of the concept High availability.\nA clear understanding of the limitations listed in High availability and the compute cluster.\nEach node to be added to the high availability configuration is connected to a network with the Admin panel and Internal management traffic types.\nThe storage cluster is created by following the instructions in Deploying the storage cluster.\n\nTo create the high availability configuration\n\nAdmin panel\n\nGo to Settings > System settings > Management node high availability, and then click Create HA configuration.\nIn the Create HA configuration window, select three nodes, and then click Next.\n\nDepending on your network configuration, specify one or multiple unique static IP addresses for the highly available admin panel, compute API endpoint, and interservice messaging.\n\nClick Create.\n\nOnce the high availability of the management node is enabled, you can log in to the admin panel at the specified static IP address (on the same port 8888).\n\nCommand-line interface\nUse the following command:vinfra cluster ha create --virtual-ip <network:ip> --nodes <nodes> [--force]\r\n\n--virtual-ip <network:ip>\n\nHA configuration mapping in the format:\n\nnetwork: network to include in the HA configuration (must include at least one of these traffic types: Internal management, Admin panel, Self-service panel, or Compute API).\nip: virtual IP address that will be used in the HA configuration.\n\nSpecify this option multiple times to create a HA configuration for multiple networks.\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--force\n\nSkip checks for minimal hardware requirements\nFor example, to create a management node HA cluster from nodes node001, node002, and node003, run:# vinfra cluster ha create --virtual-ip Private:10.37.130.200 \\\r\n--virtual-ip Public:10.94.129.79 --nodes node001,node002,node003\nThe command specifies the network Private with the traffic type Internal management and the network Public with the traffic type Admin panel.\nYou can view the HA configuration in the vinfra cluster ha show output:# vinfra cluster ha show\r\n+-----------------------+---------------------------------------------------+\r\n| Field                 | Value                                             |\r\n+-----------------------+---------------------------------------------------+\r\n| ha_cluster_location   | - https://10.94.129.79:8888                       |\r\n| nodes                 | - id: 94d58604-6f30-4339-8578-adb7903b7277        |\r\n|                       |   ipaddr: 10.37.130.118                           |\r\n|                       |   is_primary: false                               |\r\n|                       | - id: f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4        |\r\n|                       |   ipaddr: 10.37.130.134                           |\r\n|                       |   is_primary: true                                |\r\n|                       | - id: 4b83a87d-9adf-472c-91f0-782c47b2d5f1        |\r\n|                       |   ipaddr: 10.37.130.127                           |\r\n|                       |   is_primary: false                               |\r\n| primary_node_location | https://10.94.62.243:8888                         |\r\n| virtual_ips           | - ip: 10.37.130.200                               |\r\n|                       |   roles_set: 5a0401b5-9b42-4d8b-8372-71c747230033 |\r\n|                       | - ip: 10.94.129.79                                |\r\n|                       |   roles_set: 5f0adc1d-c10f-46c1-b7b8-dd1aacab613b |\r\n+-----------------------+---------------------------------------------------+\r\n\n\nAfter the HA cluster is created, the admin panel will only be accessible at the provided public IP address. Log in to said address via SSH to continue managing Virtuozzo Hybrid Infrastructure with the vinfra CLI tool. You may also need to set the VINFRA_PASSWORD environment variable again, because you will access different HA cluster nodes on each login where it may not have been set.\n\nSee also\n\nManaging high availability configuration\n\nManaging the infrastructure\n\nMaintenance\n\nWhat's next\n\nConfiguring multitenancy",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster ha create --virtual-ip <network:ip> --nodes <nodes> [--force]\r\n\n--virtual-ip <network:ip>\n\n\nHA configuration mapping in the format:\n\nnetwork: network to include in the HA configuration (must include at least one of these traffic types: Internal management, Admin panel, Self-service panel, or Compute API).\nip: virtual IP address that will be used in the HA configuration.\n\nSpecify this option multiple times to create a HA configuration for multiple networks.\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--force\n\nSkip checks for minimal hardware requirements\nFor example, to create a management node HA cluster from nodes node001, node002, and node003, run:# vinfra cluster ha create --virtual-ip Private:10.37.130.200 \\\r\n--virtual-ip Public:10.94.129.79 --nodes node001,node002,node003\nThe command specifies the network Private with the traffic type Internal management and the network Public with the traffic type Admin panel.\nYou can view the HA configuration in the vinfra cluster ha show output:# vinfra cluster ha show\r\n+-----------------------+---------------------------------------------------+\r\n| Field                 | Value                                             |\r\n+-----------------------+---------------------------------------------------+\r\n| ha_cluster_location   | - https://10.94.129.79:8888                       |\r\n| nodes                 | - id: 94d58604-6f30-4339-8578-adb7903b7277        |\r\n|                       |   ipaddr: 10.37.130.118                           |\r\n|                       |   is_primary: false                               |\r\n|                       | - id: f59dabdb-bd1c-4944-8af2-26b8fe9ff8d4        |\r\n|                       |   ipaddr: 10.37.130.134                           |\r\n|                       |   is_primary: true                                |\r\n|                       | - id: 4b83a87d-9adf-472c-91f0-782c47b2d5f1        |\r\n|                       |   ipaddr: 10.37.130.127                           |\r\n|                       |   is_primary: false                               |\r\n| primary_node_location | https://10.94.62.243:8888                         |\r\n| virtual_ips           | - ip: 10.37.130.200                               |\r\n|                       |   roles_set: 5a0401b5-9b42-4d8b-8372-71c747230033 |\r\n|                       | - ip: 10.94.129.79                                |\r\n|                       |   roles_set: 5f0adc1d-c10f-46c1-b7b8-dd1aacab613b |\r\n+-----------------------+---------------------------------------------------+\r\n\n\nAfter the HA cluster is created, the admin panel will only be accessible at the provided public IP address. Log in to said address via SSH to continue managing Virtuozzo Hybrid Infrastructure with the vinfra CLI tool. You may also need to set the VINFRA_PASSWORD environment variable again, because you will access different HA cluster nodes on each login where it may not have been set.\n\n",
                "title": "To create the high availability configuration"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Management node high availability, and then click Create HA configuration.\nIn the Create HA configuration window, select three nodes, and then click Next.\n\nDepending on your network configuration, specify one or multiple unique static IP addresses for the highly available admin panel, compute API endpoint, and interservice messaging.\n\n\n\n\n\nClick Create.\n\nOnce the high availability of the management node is enabled, you can log in to the admin panel at the specified static IP address (on the same port 8888).\n",
                "title": "To create the high availability configuration"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-management-node-ha.html"
    },
    {
        "title": "Viewing and editing project quotas",
        "content": "Viewing and editing project quotas\nEach project is allocated a certain amount of compute resources by means of quotas. Any domain administrator can view project quotas on the  project details screen. If granted the required permission, a domain administrator can also edit project quotas.\nPrerequisites\n\nA domain administrator must have the Project and quota management permission granted, to be able to edit project quotas.\n\nTo view quotas of a project\n\nSelect the domain in the drop-down list in the top right corner.\nOpen the Projects screen, click the desired project in the list, and then switch to the Quotas tab.\n\nTo edit quotas of a project\n\nSelect the domain in the drop-down list in the top right corner.\nOn the Projects screen, click the ellipsis icon next to the project, and then click Edit quotas.\nMake the required changes, and then click Save. ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/viewing-and-editing-project-quotas.html"
    },
    {
        "title": "Enabling statistics",
        "content": "Enabling statistics\nYou need to have statistics collection enabled on your S3 gateway. The S3 gateway will save the statistics as regular storage objects. On each S3 storage node, create a file /var/lib/ostor/local/gw.conf with the following contents:# Enable usage statistics collection.\r\nS3_GW_COLLECT_STAT=1\r\n\nRestart the S3 storage service to apply the configuration changes. Run the following command on all S3 storage nodes:# systemctl restart ostor-agentd.service\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/enabling-statistics.html"
    },
    {
        "title": "12.2. Provisioning New Instances\u00c2\u00b6",
        "content": "12.2. Provisioning New Instances | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n12.2. Provisioning New Instances\u00c2\u00b6\nProvisioning allows you to generate new Virtuozzo Hybrid Infrastructure instances when the number of desktops in a pool reaches a specified lower threshold.\n\nNote\nYour Connection Broker license determines if provisioning is enabled in your Connection Broker.\n\nThe Provisioning section of the Edit Pool page allows you to configure when and how the Connection Broker creates new instances in your Virtuozzo Hybrid Infrastructure project. To begin, check the Provisioning enabled checkbox, as shown in the following figure.\n\nThe Connection Broker determines when to create new instances by comparing the thresholds specified in the Provisioning Limits section to the current contents of the pool. If you edit an existing pool, the Connection Broker displays the current contents of the pool size to the right of the Edit Pool form, for example:\n\nThe number entered into the Start provisioning when unassigned desktops in pool drops below field specifies a lower bound on the number of unassigned desktops in the pool, where the number of unassigned desktops is the total number of desktops minus the number of assigned desktops.\nFor example, the previous figure shows one assigned desktop and 46 total desktops. Therefore, there are 45 unassigned desktops. An unassigned desktop can have a desktop status of either available or unavailable.\nThe Connection Broker checks the provisioning limits, and creates new instances, at the following times:\n\nWhen the pool is saved\nWhen a user is assigned to a desktop in this pool\nWhen any pool_stats or pool_history_stats job runs\n\nThe Connection Broker continues to provision new desktops whenever the lower threshold is crossed, until the upper threshold specified in the Stop provisioning when total desktops in pool reaches field is reached, indicated by the Total value in the pool size information.\nUse the Provisioning Parameters section to configure how Leostream provisions new instances in your Virtuozzo Hybrid Infrastructure project, as follows.\n\nSelect the center associated with your Virtuozzo Hybrid Infrastructure project from the Provision in center drop-down menu. The remainder of the form updates based on the contents of your selection. The following figure shows an example of the Provisioning Parameters section.\n\nEnter a name for the virtual machine in the Virtual Machine Name edit field. If the pool is defined using names that begin with a certain string, ensure that the Virtual Machine Name field starts with that string, as shown in the previous figure for a pool that is composed of all desktops with a name that contains the string desktop.\nOptionally enter a user-friendly display name into the Display name edit field. You can specify in the user\u00e2\u0080\u0099s policy if the Connection Broker should display the desktop to the user with its display name instead of virtual machine name.\nIf either of the names contains a {SEQUENCE} dynamic tag, enter the starting number for the sequence in the Optional sequence number for virtual machine name edit field. The Connection Broker starts naming virtual machines at this number and increments the number for each machine created.\nSelect the availability zone to provision the new instance into from the Availability zone drop-down menu. When using Virtuozzo Hybrid Infrastructure, set the Availability zone to nova.\nSelect the instance size from the Flavor drop-down menu. This selection determines the resources allocated to the newly created virtual machines in the pool in regards to vCPU, RAM and Swap. Check your Virtuozzo Hybrid Infrastructure project to view your available flavors or create new flavors that suits your needs.\nSelect the master image to use from the Deploy from image drop-down menu. This menu contains all the images available in the Virtuozzo Hybrid Infrastructure project associated with the selected center.\nBy default, the Connection Broker creates an instance with ephemeral storage. When provisioning into Virtuozzo Hybrid Infrastructure, indicate that the Connection Broker should create a new volume from the image by selecting the Create new volume checkbox. The form expands to show the fields in the following figure.\n\nIf you are provisioning non-persistent virtual machines, select the Delete volume on instance delete checkbox to have the Connection Broker delete the volume along with the instance, when instructed to do so by the user\u00e2\u0080\u0099s Release Plan.\nIn the Volume size edit field, Indicate the size of the volume to create if different than that of the selected flavor.\nSelect the default volume type from the Volume type drop-down menu.\n\nSelect the network for the new instance from the Network drop-down menu. This example adds virtual machines to the VDI-Network.\n\nThis example adds virtual machines to a private network without associating a public IP address. The Leostream Gateway provides connections to the VMs from clients that are outside of the private network.\n\nIn the Available security groups field, select the security groups to assign to the new instance. Click the Add item button to place them into the Selected security groups field.\nIf you are provisioning non-persistent virtual machines, select the Initialize newly provisioned desktops as deletable option to indicate that the Connection Broker is allowed to delete these instances. When this option selected, the Edit Desktop page for the newly provisioned VM has the Allow this desktop to be deleted from disk option selected. Use release plans to schedule VM deletion.\n\nFor more information on using release plans to terminate virtual machines, see the example on deleting virtual machines see Chapter 11 of the Connection Broker Administrator\u00e2\u0080\u0099s Guide.\n\nClick Save.\n\nAs soon as you save the pool, the Connection Broker checks the Provisioning Limits and will launch virtual machines as required to meet the minimum threshold. You can see the virtual machines in the Virtuozzo Hybrid Infrastructure self-service portal, as shown in the following figure.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/pooling-and-provisioning/provisioning-instances.html"
    },
    {
        "title": "Managing the infrastructure",
        "content": "Managing the infrastructure\nThis section outlines common administrator's tasks for the infrastructure: the license, networks, nodes, security, and the self service.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-the-infrastructure.html"
    },
    {
        "title": "Backup storage alerts",
        "content": "Backup storage alerts\nThe following backup storage alerts are generated and displayed in the admin panel:\n\n Backup storage SSL certificate will expire in 21 days\n\nThe <type> certificate will expire in 21 days. Path: <path>. Registration name: <reg_name>.\n\nUpdate the certificate, as described in Updating registration certificates.\n\nBackup storage SSL certificate will expire in 14 days\n\nThe <type> certificate will expire in 14 days. Path: <path>. Registration name: <reg_name>.\n\nUpdate the certificate, as described in Updating registration certificates.\n\nBackup storage SSL certificate will expire in 7 days\n\nThe <type> certificate will expire in 7 days. Path: <path>. Registration name: <reg_name>.\n\nUpdate the certificate, as described in Updating registration certificates.\n\n Backup storage SSL certificate has expired\n\nThe <type> certificate has expired. Path: <path>. Registration name: <reg_name>.\n\nUpdate the certificate, as described in Updating registration certificates.\n\nBackup storage CRL is not up to date\n\nThe CRL has not been updated for more than 2 days. Path: <path>. Registration name: <reg_name>.\n\nThe URI to the CRL is not accessible, check the CRL distribution points as follows:# cd /mnt/vstorage/vols/acronis-backup/certs.<reg_name>\r\n# openssl x509 -in reg.crt -text -noout | grep URI\r\n# openssl x509 -in dc.crt -text -noout | grep URI\r\n# openssl x509 -in abgw.pem -text -noout | grep URI\nOne distribution point can be used for several or even for all certificates.\nIf you cannot troubleshoot the problem, contact the technical support team.\n\n Backup storage throttling is activated\n\nBackup storage started to throttle write operations due to the lack of free space. Visit https://kb.acronis.com/content/62823 to learn how to troubleshoot this issue.\n\nCheck the Storage services > Backup storage > Overview > Append throttle chart, as described in Monitoring Acronis Backup Storage.\nAdd more space to the backup storage.\n\nFor more details, refer to the Knowledge Base article \"Throttling on backup storage\".\n\n Different number of collaborating backup storage services\n\nSome backup storage services report a different number of collaborating services. Please contact the technical support.\n\n Attempt to use migrated accounts\n\nOne or more attempts to use migrated accounts detected for the last 24 hours. Please contact the technical support.\n\n Storage I/O error\n\nOne or more errors detected during storage I/O operations for the last 24 hours. Please contact the technical support.\n\n Backup storage has high replica open error rate\n\nBackup storage has the error rate when opening replica files \"<error label>\" higher than 5%.\n\nCheck the backup storage logs at /var/log/abgw/abgw.log.zst on the primary geo-replication cluster.\n\n Backup storage has high replica write error rate\n\nBackup storage has the error rate when writing replica files \"<error label>\" higher than 5%.\n\nCheck the backup storage logs at /var/log/abgw/abgw.log.zst on the primary geo-replication cluster.\n\n Backup storage has high replica removal error rate\n\nBackup storage has the error rate when removing secondary replica files \"<error label>\" higher than 5%.\n\nCheck the backup storage logs at /var/log/abgw/abgw.log.zst on the primary geo-replication cluster.\n\nWhat's next\n\nGetting technical support\n\nSee also\n\nInfrastructure alerts\n\nCore storage alerts\n\nObject storage alerts\n\nBlock storage alerts\n\nCompute alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup-storage-alerts.html"
    },
    {
        "title": "Backup storage in a virtual machine",
        "content": "Backup storage in a virtual machine\nVMware vSphere is the only officially supported hypervisor for running Virtuozzo Hybrid Infrastructure. Do not use other virtualization platforms as it may result in data corruption.\nTo be able to run the Virtuozzo Hybrid Infrastructure on VMware vSphere, make sure the following requirements are met:\n\nVMware vSphere version: 6.7 and newer\nVM version: 14 and newer\nThe host should have enough memory. At least 8 GB of RAM is required for a node with one storage disk running Backup Gateway.\n\nThe vSphere datastore should have enough free storage space. Each virtual machine occupies at least 425 GB (two 200 GB storage disks and a 25 GB system disk). The Virtuozzo Hybrid Infrastructure template also takes up about 35 GB. The maximum recommended size for one virtual disk is 16 TB.\n\nSee also\n\nBackup storage in a public cloud\n\nAcronis Backup Storage network requirements\n\nProvisioning Acronis Backup Storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup-storage-in-a-virtual-machine.html"
    },
    {
        "title": "Supported guest operating systems",
        "content": "Supported guest operating systems\nThe guest operating systems listed below have been tested and are supported in virtual machines.\nOnly the x64 architecture is supported.\n\nWindows\n\nVersion\nEdition\nCPU hot plug support\nRAM hot plug support\n\nWindows Server 2022\nEssentials\nNo\nNo\n\nStandard, Datacenter\nYes\nYes\n\nWindows Server 2019\nEssentials\nNo\nNo\n\nStandard, Datacenter\nYes\nYes\n\nWindows Server 2016\nEssentials\nNo\nNo\n\nStandard, Datacenter\nYes*\nYes\n\nWindows Server 2012 R2\nEssentials, Standard, Datacenter\nYes\nYes\n\nWindows Server 2012\nStandard, Datacenter\nYes\nYes\n\nWindows Server 2008 R2\nStandard, Datacenter\nNo\nNo\n\nWindows 10\nHome, Professional, Enterprise,\r\nEnterprise 2016 LTSB\nNo\nNo\n\nWindows 8.1\nHome, Professional, Enterprise\nNo\nNo\n\n* CPU hot plug does not work properly due to a Windows bug with a wrongly installed driver. To fix the issue, refer to this solution.\n\nFor a Windows in-place upgrade to work, install the guest tools inside a virtual machine and restart it, as described in Installing guest tools.\n\nLinux\n\nDistribution\nVersion\nCPU hot plug support\nRAM hot plug support\n\nRocky Linux\n9.x, 8.x\nYes\nYes\n\nAlmaLinux\n9.x, 8.x\nYes\nYes\n\nCentOS\n8.x, 7.x\nYes\nYes\n\n6.x\nNo\nNo\n\nRed Hat Enterprise Linux \n9.x, 8.x, 7.x\nYes\nYes\n\nDebian\n10.x, 9.x\nYes\nYes\n\nUbuntu\n22.04.x, 20.04.x, 18.04.x\nYes\nYes\n\nOracle Linux\n7.3, 7.9\nYes\nYes\n\nSUSE Linux Enterprise\n15.x (SP3, SP4, SP5) \nYes\nYes",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/supported-guest-oses.html"
    },
    {
        "title": "Aggregating load balancers",
        "content": "Aggregating load balancersPOST /v1/aggregates?details=False&needed_overlap=0.0&start={start_date}&stop={stop_date}\r\n\nAggregate the number of load balancers per project for a specific period of time.\n\nIf the start or stop date is not specified, the missing value will be set to the first or last timestamp common across the time series.\n\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\noperation\n\nbody\nstring\nOperations to apply to the time series. For aggregation across metrics, use the following syntax: aggregate <aggregation_method> ((metric <metric_id> <aggregation_method>), ...). Supported aggregation methods are: mean, median, std, min, max, sum, var, count.\n\nsearch\n\nbody\nstring\nA query to filter resources. The syntax includes an attribute, operator, and value. For example, the query id=90d58eea-70d7-4294-a49a-170dcdf44c3c will filter a resource with the specified ID. You can use more complex queries, for example, not (flavor_id!=\u00e2\u0080\u009d1\u00e2\u0080\u009d and memory>=24). Use \u00e2\u0080\u009c\u00e2\u0080\u009d to interpret data as a string. Supported operators are: not, and, \u00e2\u0088\u00a7 or, \u00e2\u0088\u00a8, >=, <=, !=, >, <, =, ==, eq, ne, lt, gt, ge, le, in, like, \u00e2\u0089\u00a0, \u00e2\u0089\u00a5, \u00e2\u0089\u00a4, like, in.\n\nresource_type\n\nbody\nstring\n\nA resource type that a metric is associated with. For example, these metrics are bound to:\n\nvCPU and RAM metrics\u00e2\u0080\u0094the instance resource type\nStorage metrics\u00e2\u0080\u0094the volume resource type\nFloating IP addresses\u00e2\u0080\u0094the network resource type\nLoad balancers\u00e2\u0080\u0094the loadbalancer resource type\nKubernetes clusters\u00e2\u0080\u0094the coe_cluster resource type\n\nExample\nAggregate the number of load balancers for the project with the ID 75521ab61d1f4e9090aac5836c219492 from 12:00 PM July 18, 2021, to 13:00 PM July 19, 2021.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"operations\":\"(aggregate sum (metric network.services.lb.loadbalancer mean))\",\r\n    \"search\":\"project_id=75521ab61d1f4e9090aac5836c219492\",\r\n    \"resource_type\":\"loadbalancer\"\r\n}' https://<node_IP_addr>:8041/v1/aggregates?details=False&needed_overlap=0.0&\\\r\nstart=2021-07-18T12:00:00&stop=2021-07-19T12:00:00\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nmeasures\n\nbody\nstring\nA list of measures for a metric.\n\naggregated\n\nbody\narray\nA number of aggregates, each consisting of a timestamp, granularity, and value.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"measures\": {\r\n    \"aggregated\": [\r\n      [\r\n        \"2021-07-18T12:00:00+00:00\",\r\n        300.0,\r\n        2\r\n      ],\r\n      <...>\r\n      [\r\n        \"2021-07-19T11:55:00+00:00\",\r\n        300.0,\r\n        2\r\n      ] \r\n    ]\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/aggregating-load-balancers.html"
    },
    {
        "title": "Changing virtual machine resources",
        "content": "Changing virtual machine resources\nYou can change amount of CPU and RAM resources used by a virtual machine by applying another flavor to it. To be able to resize a running VM, you need to enable CPU and RAM hot plug for it first. You can change the hot plug settings for both new and existing VMs.\nA running virtual machine has a resize limit, which defines the maximum number of vCPUs and the maximum amount of RAM you can allocate to the VM. The resize limit on vCPUs is static and equal to 64 for all VMs. The resize limit on RAM, on the contrary, is dynamic and depends on the amount of RAM a running VM is currently using. This limit is updated on a VM startup, and its values are listed in the table below.\n\nCurrent RAM size, in GiB\nRAM size limit, in GiB\n\n1-4\n16\n\n5-8\n32\n\n9-16\n64\n\n17-32\n128\n\n33-64\n256\n\n65-128\n512\n\n129-256\n1024\n\nFor example, you can resize a running VM with a flavor that has 16 GiB to a flavor with 256 GiB in two iterations:\n\nResize the VM to a flavor with 64 GiB.\nRestart the VM to update the RAM size limit.\nResize the VM to a flavor with 256 GiB.\n\nLimitations\n\nYou cannot change the flavor for shelved VMs. To resize such a VM, unshelve it first.\nYou cannot decrease the number of CPUs and the amount of RAM for running VMs.\n\n[For all Linux guests] If a VM has no guest tools installed, new cores may be offline after CPU hot plugging\n\nYou can verify which CPU cores are online by using the command:# cat /sys/devices/system/cpu/online\nTo activate offline CPU cores, run:# echo 1 > /sys/devices/system/cpu/cpu<cpu_number>/online\n\nPrerequisites\n\nBefore changing a flavor, ensure that the node hosting the VM has at least as much free CPU and RAM resources as the new VM size. For example, to resize a VM to the large flavor, the host must have at least 4 vCPUs and 8 GiB of RAM free.\nBefore resizing a running VM, ensure that the guest operating system supports CPU and RAM hot plug (refer to Supported guest operating systems). Note that otherwise the guest operating system may become unstable after a resize. To increase CPU or RAM resources for such a guest operating system, you need to stop the virtual machine first.\nBefore resizing a running VM, ensure that the guest operating system has the latest updates installed.\n\nTo enable or disable CPU and RAM hot plug for a virtual machine\n\nAdmin panel\n\n On the Compute > Virtual machines > Virtual machines screen, ensure that the required virtual machine in the \"Shut down\" state, and then click it.\n\nOn the Overview tab, click the pencil icon in the CPU and RAM hot plug field.\n\nSelect or clear the Enable hot plug check box, and then click the tick icon to save the changes.\n\nWith CPU and RAM hot plug enabled, you can change the flavor of a running VM.\n\nCommand-line interface\nUse the following command:vinfra service compute server set <server> {--allow-live-resize | --deny-live-resize}\n\n--allow-live-resize\n\nAllow online resize for the virtual machine.\n--deny-live-resize\n\nDeny online resize for the virtual machine.\n<server>\n\nVirtual machine ID or name\n\nFor example, to enable CPU and RAM hot plug for the virtual machine myvm, run:# vinfra service compute server set myvm --allow-live-resize\n\nTo change the virtual machine flavor\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Flavor field.\nIn the Flavor window, select a new flavor, and then click Done.\n\nCommand-line interface\nUse the following command:vinfra service compute server resize --flavor <flavor> <server>\r\n\n\n--flavor <flavor>\n\nApply flavor with ID or name\n<server>\n\nVirtual machine ID or name\n\nFor example, to change the flavor of the virtual machine myvm to small, run:# vinfra service compute server resize myvm --flavor small\n\nSee also\n\nMonitoring virtual machines\n\nConfiguring network interfaces of virtual machines\n\nConfiguring virtual machine volumes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server set <server> {--allow-live-resize | --deny-live-resize}\n\n--allow-live-resize\n\nAllow online resize for the virtual machine.\n--deny-live-resize\n\nDeny online resize for the virtual machine.\n<server>\n\nVirtual machine ID or name\n\nFor example, to enable CPU and RAM hot plug for the virtual machine myvm, run:# vinfra service compute server set myvm --allow-live-resize\n",
                "title": "To enable or disable CPU and RAM hot plug for a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server resize --flavor <flavor> <server>\r\n\n\n--flavor <flavor>\n\nApply flavor with ID or name\n<server>\n\nVirtual machine ID or name\n\nFor example, to change the flavor of the virtual machine myvm to small, run:# vinfra service compute server resize myvm --flavor small\n",
                "title": "To change the virtual machine flavor"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n On the Compute > Virtual machines > Virtual machines screen, ensure that the required virtual machine in the \"Shut down\" state, and then click it.\n\nOn the Overview tab, click the pencil icon in the CPU and RAM hot plug field.\n\nSelect or clear the Enable hot plug check box, and then click the tick icon to save the changes.\n\nWith CPU and RAM hot plug enabled, you can change the flavor of a running VM.\n",
                "title": "To enable or disable CPU and RAM hot plug for a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Flavor field.\nIn the Flavor window, select a new flavor, and then click Done.\n\n",
                "title": "To change the virtual machine flavor"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-vm-resources.html"
    },
    {
        "title": "Deleting bucket limits in WHMCS",
        "content": "Deleting bucket limits in WHMCS\nYou can delete the current limits with the ostor-limits service and parameter bucket specifying the bucket name. WHMCS removes the bucket limits from S3 cluster when you click the Delete button. Create a file S3_deleteLimitsForBucket.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Delete s3 bucket limits.\r\nfunction S3_deleteLimitsForBucket($bucket) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Delete s3 bucket limits.\r\n    S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-limits&bucket=\" . $bucket,\r\n        \"DELETE\"\r\n    );\r\n\r\n    // Clear array.\r\n    $_SESSION['s3_limits_bucket'] = null;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_deleteLimitsForBucket($_GET['bucket']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-bucket-limits-in-whmcs.html"
    },
    {
        "title": "Data redundancy",
        "content": "Data redundancy\nVirtuozzo Hybrid Infrastructure protects every piece of data by making it redundant. It means that copies of each piece of data are stored across different failure domains, to ensure that the data is available even if some of the failure domains are inaccessible.\nVirtuozzo Hybrid Infrastructure automatically maintains a required number of copies within the cluster and ensures that all the copies are up to date. If a storage node becomes inaccessible when the host failure domain is used, copies from this node are replaced by new ones that are distributed among healthy storage nodes. If a storage node becomes accessible again after downtime, the out-of-date copies on it are updated.\nThe redundancy is achieved by one of two methods: replication or erasure coding. The chosen method affects the size of one piece of data and the number of its copies that will be maintained in the cluster. In general, replication offers better performance, while erasure coding leaves more storage space available for data.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/data-redundancy.html"
    },
    {
        "title": "Supported Amazon error response headers",
        "content": "Supported Amazon error response headers\nThe following Amazon S3 REST error response headers are currently supported by the Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol:\n\nCode\n\nThe error code is a string that uniquely identifies an error condition.\nError\n\nContainer for all error elements.\nMessage\n\nThe error message contains a generic description of the error condition.\n\nThe following Amazon S3 REST error response headers are not supported:\n\nRequestId (not used)\nID of the request associated with the error.\nResource\n\nThe bucket or object that is involved in the error.\n\nFor more information about Amazon S3 REST error response headers, refer to the Amazon S3 REST API documentation.\n\nSee also\n\nSupported Amazon S3 REST operations\n\nSupported Amazon request headers\n\nSupported Amazon response headers\n\nSupported authentication schemes\n\nAmazon S3 features supported by bucket policies\n\nSupported Amazon S3 object expiration actions",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-error-response-headers.html"
    },
    {
        "title": "Acronis Cyber Cloud Migration from VMware\u00c2\u00b6",
        "content": "Acronis Cyber Cloud Migration from VMware | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nNext\n\nAcronis Cyber Cloud Migration from VMware\u00c2\u00b6\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n4. Migrating Virtual Machines\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/index.html"
    },
    {
        "title": "Enabling management node high availability",
        "content": "Enabling management node high availability\nTo make your infrastructure more resilient and redundant, you can create a high availability (HA) configuration of three nodes.\nManagement node HA and compute cluster are tightly coupled, so changing nodes in one usually affects the other. Take note of the following:\n\nAll nodes in the HA configuration will be added to the compute cluster.\nSingle nodes cannot be removed from the compute cluster as they are included in the HA configuration. In such a case, the compute cluster can be destroyed completely, but the HA configuration will remain. This is also true vice versa, the HA configuration can be deleted, but the compute cluster will continue working.\n\nTo enable high availability for the management node and admin panel, do the following:\n\nGo to Settings > System settings > Management node high availability, and then click Create HA configuration.\nIn the Create HA configuration window, select three nodes, and then click Next.\n\nDepending on your network configuration, specify one or multiple unique static IP addresses for the highly available admin panel, compute API endpoint, and interservice messaging.\n\nClick Create.\n\nOnce the high availability of the management node is enabled, you can log in to the admin panel at the specified static IP address (on the same port 8888).",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/enabling-management-node-high-availability.html"
    },
    {
        "title": "Obtaining usage statistics via REST API",
        "content": "Obtaining usage statistics via REST API\nThis section describes how to obtain usage statistics via REST API for billing or other purposes.\n\r\n                Delete statistics objects after collecting the required data.\r\n            ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/obtaining-usage-statistics-via-rest-api.html"
    },
    {
        "title": "Unassigning QoS policies",
        "content": "Unassigning QoS policies\nPrerequisites\n\nA QoS policy is assigned to a resource, as described in Assigning QoS policies.\nEnsure that a a QoS policy is not used by networks, ports, or IP addresses.\n\nTo unassign a QoS policy from a network port\nDetach the network port from the policy with openstack port unset --qos-policy. For example:# openstack --insecure port unset --qos-policy c0ea690f-4993-4467-afd5-5389016a0658\nTo unassign a policy from a floating IP address\nDetach the floating IP from the policy with openstack floating ip unset --qos-policy. For example:# openstack --insecure floating ip unset --qos-policy 866203a2-4e1c-459f-807f-14ed563409f1\n To unassign a policy from a network\nDetach the network from the policy with openstack network set --no-qos-policy. For example:# openstack --insecure network set --no-qos-policy public",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/unassigning-qos-policies.html"
    },
    {
        "title": "3.3. Performing Test Migration\u00c2\u00b6",
        "content": "3.3. Performing Test Migration | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n3.3. Performing Test Migration\u00c2\u00b6\nIn this section we will perform a test migration. Let\u00e2\u0080\u0099s first define specific Hystax Acura concepts before we start with the test migration.\n\nCloud/Target Clouds on the Hystax Acura portal are objects that contain information about things like, where should workloads be migrated? What user and password Hystax Acura must be used authenticate via Keystone API? What is the URL for the Keystone API? Which is the service network? Basically, all the information provided on step 3 of the installation wizard is used to populate this Hystax Acura entity. Once you login for the first time you will see this resource by clicking on the \u00e2\u0080\u009cManage Clouds\u00e2\u0080\u009d button. You can add more \u00e2\u0080\u009cCloud/Target Clouds\u00e2\u0080\u009d to manage more migration projects on Virtuozzo Hybrid Infrastructure Platform.\n\nCustomers are entities that we create which logically associate a customer with migrated instances, migration plans, cloud sites, cloud/target cloud and target project ID*. We will select this \u00e2\u0080\u009cCustomer\u00e2\u0080\u009d entity in order to start a migration. You can create multiple customers that belong to different projects (target project) as long as the user defined on the \u00e2\u0080\u009cCloud/Target cloud\u00e2\u0080\u009d is a project member. This is the first configuration resource you will need to create in order to start planning the migration. Note that in this case the Target Project ID* is the same as the one defined in the original Cloud/Target Cloud.\n\nMachine Groups are ways to group instances, you could create a machine group for Windows instances, another machine group for Linux instances, etc. There is a default group and will be the one we will use in this example.\nMigration Plans are a way to define what the migrated instance will look like when migrated e.g., what network should be the new replicated instance part of? What flavor should be used to create the new instance (flavors define how much RAM and CPU should be assigned to the new instance)? If we migrate more than one instance, we could even define how to orchestrate the migration, by defining for example what instance should start first and what instance should wait until the other instance is up.\n\nTo perform a test migration, do the following:\n\nLogin to the Hystax Acura portal by going to https://floating-ip-acura-instace.\n\nAdd a customer. Click on the Hystax logo on the top left and you\u00e2\u0080\u0099ll see the Add button to add a customer click that button. Fill in the information relevant to your customer. Click Save.\n\nThe new customer will be available after creation. Click on the customer and review the smart migration wizard. We will follow these steps to run a test migration.\n\nClick on install agents, choose the install agent you wish to deploy on the source remote instance, that you wish to replicate. In our example I will be migrating an Ubuntu 16 web server instance, hosted currently on amazon EC2. To do it, select the Linux agent and then click Next. If the migration was from VMware, it would be possible to install a HRVAgent image on each ESXi Hypervisor to perform the migration. For more details on the migration from VMware to Virtuozzo Hybrid Infrastructure, refer to the Hystax Acura Migration Guide for VMware.\n\nSelect the machine group, in our example this will be the Default group, then the target Linux distribution (Debian/Ubuntu). Check the supported kernel list, if the kernel of your instance is not supported, then you need to build the drivers and use the DKMS as the snapshot driver deployment type, in this example we will follow this path. Otherwise, you could choose Snapshot driver deployment type (pre-built). If you have any issues building the drivers, please contact us.\n\nFollow the steps provided by the Hystax Acura wizard, and copy and paste the instructions in order to install the agent on the instance that will be replicated.\n\nClick on the Hystax logo on the top left. You will see now the customer and the machine count will be 1.\n\nClick on the name of the customer and you\u00e2\u0080\u0099ll see the new instance.\n\nClick on Start Replication. If everything is correctly configured, replication of the remote instance will start on your target cloud. Replication will take some time, depending on how much data will be replicated and the connection between your source and target clouds.\n\nWait until the instance is synced.\n\nWhile the image is being synced, let\u00e2\u0080\u0099s create a target network (the network that will be used by our instance on the replicated target cloud). Go to your VHI self-service portal on \u00e2\u0080\u009cvhi-admin-panel-fqdn:8800\u00e2\u0080\u009d and login to the target project.\n\nOnce you\u00e2\u0080\u0099ve logged in, check the Virtual machines tab and you will see that the Acura cloud agent has been deployed automatically.\n\nNow go to Networks, create virtual network and follow the steps. I will create the network using exactly the same CIDR (172.31.32.0/20) as the instance being replicated. You could use any other network CIDR, this is just to show an example of a migration with exactly the same IP address source and remote.\nAdd a migration plan, step 1. Add a machine. Click on the ellipsis icon \u00e2\u0080\u009c\u00e2\u0080\u00a6\u00e2\u0080\u009d, select Add machine > Default > the machine discovered.\n\nAdd a migration plan, step 2.  Configure the subnets for your new instance. Expand the view for your instance. You will see information regarding Machine ID, Flavor, and Port (network). Also, on the left you\u00e2\u0080\u0099ll see information regarding the network to be used.\n\nWe will replace the Flavor name with one that is available on our cloud. You can check available flavors by going to Virtual machines and Flavors. Also, we will find the subnet ID for our newly created network and paste it there.\n\nSource the information regarding the subnet ID:\n\nLogin to your Virtuozzo Hybrid Infrastructure Admin panel via SSH.\nSource the admin-openrc.sh file.\n\n# source /etc/kolla/admin-openrc.sh\n\n\nRun the command openstack network list --insecure and identify the subnet ID.\n\nAdd a secondary Port. Add a subnet by clicking the \u00e2\u0080\u009c+\u00e2\u0080\u009d button on the Subnets section.\n\nClick on the Subnet ID* drop down menu for your new subnet and select the Public IP you wish to use. By leaving the Port IP field blank you are specifying DHCP. Provide a name for the plan and click Save.\n\nClick on Run test migration and select the migration plan.\n\nCreate a cloud site by giving a name, a cloud site is a way to logically group a migration plan with a snapshot to be used for the migration. Give the Cloud Site a name, select a snapshot and click on Run migration.\n\nIf all went well, you will see your replicated instance available on your target cloud. When you are done reviewing the migration test, you can delete the resources by deleting the cloud site.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/installation-steps/test-migration.html"
    },
    {
        "title": "Showing domain details",
        "content": "Showing domain detailsGET /v3/domains/{domain_id}\r\n\nShows details of a domain with the specified ID.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=show-domain-details-detail#show-domain-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ndomain_id\n\npath\nstring\nThe domain ID.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ndomain\n\nbody\nobject\nA domain object.\n\ndescription\n\nbody\nstring\nThe description of the domain.\n\nenabled\n\nbody\nstring\nIf set to true, domain is enabled. If set to\r\nfalse, domain is disabled.\n\nid\n\nbody\nstring\nThe ID of the domain.\n\nlinks\n\nbody\nobject\nThe links to the domain resource.\n\nname\n\nbody\nstring\nThe name of the domain.\n\noptions\n\nbody\nobject\nThe resource options for the role. Available resource options are\r\nimmutable.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n405 - Method Not Allowed\n\nMethod is not valid for this endpoint.\n\n413 - Request Entity Too Large\n\nThe request is larger than the server is willing or able to process.\n\n503 - Service Unavailable\n\nService is not available. This is mostly caused by service configuration\r\nerrors which prevents the service from successful start up.\n\nExample{\r\n  \"domain\": {\r\n    \"description\": \"Domain description\",\r\n    \"links\": {\r\n      \"self\": \"https://<node_IP_addr>:5000/v3/domains/f2eeaaf15c254d4fa10255796122c8ec\"\r\n    },\r\n    \"tags\": [],\r\n    \"enabled\": true,\r\n    \"id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"name\": \"domain1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-domain-details.html"
    },
    {
        "title": "Deleting user limits via CLI",
        "content": "Deleting user limits via CLI\nYou can delete the current limits with the rm-limits command and parameter -e specifying the email address:# ostor-s3-admin rm-limits -e client@example.com\r\nops:default=0.00ops/s\r\nops:get=0.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=0kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-user-limits-via-cli.html"
    },
    {
        "title": "Creating S3 users in WHMCS",
        "content": "Creating S3 users in WHMCS\nYou can create a user with the ostor-users service and parameter emailAddress specifying the user email address. WHMCS creates the user in S3 cluster when you click Create User. Create a file S3_createUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_addClientNote.php');\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Create s3 user.\r\nfunction S3_createUser($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Create s3 user.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-users&emailAddress=\" . $s3_whmcs['email'],\r\n        \"PUT\"\r\n    );\r\n\r\n    // Add note with the s3 access key and s3 secret.\r\n    S3_addClientNote(\r\n        $s3_whmcs['userid'],\r\n        $s3_config['whmcs_username'],\r\n        $s3_client['UserId'],\r\n        $s3_client['AWSAccessKeys']['0']['AWSAccessKeyId'],\r\n        $s3_client['AWSAccessKeys']['0']['AWSSecretAccessKey']\r\n    );\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_createUser($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/creating-s3-users-in-whmcs.html"
    },
    {
        "title": "Deleting user limits via REST API",
        "content": "Deleting user limits via REST API\nYou can delete the current limits with the ostor-limits service and parameter emailAddress specifying the email address:# s3_curl DELETE \"http://s3.example.com/?ostor-limits&emailAddress=client@example.com\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-user-limits-via-rest-api.html"
    },
    {
        "title": "Managing floating IP addresses",
        "content": "Managing floating IP addresses\nA virtual machine connected to a virtual network can be accessed from public networks, such as the Internet, by means of a floating IP address. Such an address is picked from a physical network and mapped to the VM\u00e2\u0080\u0099s private IP address. The floating and private IP addresses are used at the same time on the VM\u00e2\u0080\u0099s network interface. The private IP address is used to communicate with other VMs on the virtual network. The floating IP address is used to access the VM from public networks. The VM guest operating system is unaware of the assigned floating IP address.\nPrerequisites\n\nYou have a virtual router created, as described in Managing virtual routers.\nThe virtual machine to assign a floating IP to has a fixed private IP address.\nThe virtual router connects the physical network, from which a floating IP will be picked, with the VM\u00e2\u0080\u0099s virtual network.\n\nTo create a floating IP address and assign it to a virtual machine\n\nOn the Floating IPs screen, click Add floating IP.\n\nIn the Add floating IP address, select a physical network, from which a floating IP will be picked, and a VM network interface with a fixed private IP address.\n\nClick Add.\n\nTo re-assign a floating IP address to another virtual machine\n\nClick the ellipsis icon next to the floating IP address, and then click Unassign.\nOnce the VM name disappears in the Assigned to column, click the ellipsis icon again, and then select Assign.\nIn the Assign floating IP address window, select a VM network interface with a fixed private IP address.\nClick Assign.\n\nTo remove a floating IP address\n\nUnassign it from a virtual machine. Click the ellipsis icon next to the floating IP address, and then click Unassign.\nClick the ellipsis icon again, and then select Delete.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-floating-ip-addresses.html"
    },
    {
        "title": "Listing virtual router interfaces",
        "content": "Listing virtual router interfacesGET /v2.0/ports\r\n\nLists ports to which the user has access.\nYou can use this call to find out port IDs of a virtual router with the specified ID.\nDefault policy settings return only those ports that are owned by\r\nthe project of the user who submits the request, unless the request is submitted\r\nby a user with administrative rights.\nIf the ip-substring-filtering extension is enabled, the Neutron API\r\nsupports IP address substring filtering on the fixed_ips attribute.\r\nIf you specify an IP address substring (ip_address_substr) in\r\nan entry of the fixed_ips attribute, the Neutron API will list all\r\nports that have an IP address matching the substring.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-ports-detail#list-ports\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nadmin_state_up (Optional)\nquery\nboolean\nFilter the list result by the administrative state of the resource,\r\nwhich is up (true) or down (false).\n\nbinding:host_id (Optional)\nquery\nstring\nFilter the port list result by the ID of the host where the port resides.\n\ndescription (Optional)\nquery\nstring\nFilter the list result by the human-readable description of the port.\n\ndevice_id (Optional)\nquery\nstring\nFilter the port list result by the ID of the device that uses this port.\r\nFor example, a server instance or a logical router.\n\ndevice_owner (Optional)\nquery\nstring\nFilter the port result list by the entity type that uses this port.\r\nFor example, compute:nova (server instance), network:dhcp\r\n(DHCP agent) or network:router_interface (router interface).\n\nfixed_ips (Optional)\nquery\narray\nFilter the port list result by the IP addresses for the port.\r\nThis field has one or multiple entries.\r\nEach entry consists of IP address (ip_address), IP address substring\r\n(ip_address_substr) and/or the subnet ID from which\r\nthe IP address is assigned (subnet_id).\n\nid (Optional)\nquery\nstring\nFilter the list result by the ID of the resource.\n\nip_allocation (Optional)\nquery\nstring\nFilter the port list result based on if the ports use deferred,\r\nimmediate or no IP allocation (none).\n\nmac_address (Optional)\nquery\nstring\nFilter the port list result by the MAC address of the port.\n\nname (Optional)\nquery\nstring\nFilter the list result by the human-readable name of the resource.\n\nnetwork_id (Optional)\nquery\nstring\nFilter the list result by the ID of the attached network.\n\nproject_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\nrevision_number (Optional)\nquery\ninteger\nFilter the list result by the revision number of the resource.\n\nsort_dir (Optional)\nquery\nstring\nSort direction. A valid value is asc (ascending) or desc\r\n(descending). You can specify multiple pairs of sort key and\r\nsort direction query parameters.\n\nsort_key (Optional)\nquery\nstring\n\nSorts by a port attribute. You can specify multiple pairs of sort key\r\nand sort direction query parameters. The sort keys are limited to:\n\nadmin_state_up\n\ndevice_id\n\ndevice_owner\n\nid\n\nip_allocation\n\nmac_address\n\nname\n\nnetwork_id\n\nproject_id\n\nstatus\n\ntenant_id\n\nstatus (Optional)\nquery\nstring\nFilter the port list result by the port status.\r\nValues are ACTIVE, DOWN, BUILD and ERROR.\n\ntenant_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\ntags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be returned.\r\nTags in query must be separated by comma.\n\ntags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be returned.\r\nTags in query must be separated by comma.\n\nnot-tags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be excluded.\r\nTags in query must be separated by comma.\n\nnot-tags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be excluded.\r\nTags in query must be separated by comma.\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nmac_learning_enabled (Optional)\nquery\nboolean\nFilter the list result by the mac_learning_enabled state of the resource,\r\nwhich is enabled (true) or disabled (false).\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/ports?device_id=ce996632-45a2-4c6b-a951-a624eba74621\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nports\n\nbody\narray\nA list of port objects.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\n\nallowed_address_pairs\n\nbody\narray\nA set of zero or more allowed address pair objects each where address pair\r\nobject contains an ip_address and mac_address. While the\r\nip_address is required, the mac_address will be taken from the\r\nport if not specified. The value of ip_address can be an IP Address\r\nor a CIDR (if supported by the underlying extension plugin).\r\nA server connected to the port can send a packet with source address which\r\nmatches one of the specified allowed address pairs.\n\nbinding:host_id\n\nbody\nstring\nThe ID of the host where the port resides.\n\nbinding:profile\n\nbody\nobject\nA dictionary that enables the application running on the specific host to\r\npass and receive vif port information specific to the networking back-end.\r\nThe networking API does not define a specific format of this field.\n\nbinding:vif_details\n\nbody\nobject\nA dictionary which contains additional information on the port.\r\nCurrently the following fields are defined: port_filter and\r\novs_hybrid_plug.\r\nport_filter is a boolean indicating the networking service\r\nprovides port filtering features such as security group and/or\r\nanti MAC/IP spoofing.\r\novs_hybrid_plug is a boolean used to inform an API consumer\r\nlike nova that the hybrid plugging strategy for OVS should be used.\n\nbinding:vif_type\n\nbody\nstring\nThe type of which mechanism is used for the port.\r\nAn API consumer like nova can use this to determine an appropriate way to\r\nattach a device (for example an interface of a virtual server) to the port.\r\nAvailable values currently defined includes\r\novs, bridge, macvtap, hw_veb, hostdev_physical,\r\nvhostuser, distributed and other.\r\nThere are also special values: unbound and binding_failed.\r\nunbound means the port is\r\nnot bound to a networking back-end. binding_failed means an error\r\nthat the port failed to be bound to a networking back-end.\n\nbinding:vnic_type\n\nbody\nstring\nThe type of vNIC which this port should be attached to. This is used to\r\ndetermine which mechanism driver(s) to be used to bind the port.\r\nThe valid values are normal, macvtap, direct, baremetal,\r\ndirect-physical, virtio-forwarder and smart-nic.\r\nWhat type of vNIC is actually available depends on deployments.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndata_plane_status\n\nbody\nstring\nStatus of the underlying data plane of a port.\n\ndescription\n\nbody\nstring\nA human-readable description for the port.\n\ndevice_id\n\nbody\nstring\nThe ID of the device that uses this port.\r\nFor example, a server instance or a logical router.\n\ndevice_owner\n\nbody\nstring\nThe entity type that uses this port.\r\nFor example, compute:nova (server instance), network:dhcp\r\n(DHCP agent) or network:router_interface (router interface).\n\ndns_assignment\n\nbody\nobject\nData assigned to a port by the Networking internal DNS including the\r\nhostname, ip_address and fqdn.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\ndns_name\n\nbody\nstring\nA valid DNS name.\n\nextra_dhcp_opts\n\nbody\narray\nA set of zero or more extra DHCP option pairs. An\r\noption pair consists of an option value and name.\n\nfixed_ips\n\nbody\narray\nThe IP addresses for the port. If the port has multiple IP addresses,\r\nthis field has multiple entries. Each entry consists of IP address\r\n(ip_address) and the subnet ID from which the IP address\r\nis assigned (subnet_id).\n\nid\n\nbody\nstring\nThe ID of the resource.\n\nip_allocation\n\nbody\nstring\nIndicates when ports use either deferred, immediate or no IP\r\nallocation (none).\n\nmac_address\n\nbody\nstring\nThe MAC address of the port.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\nnetwork_id\n\nbody\nstring\nThe ID of the attached network.\n\nport_security_enabled\n\nbody\nboolean\nThe port security status. A valid value is\r\nenabled (true) or disabled (false).\r\nIf port security is enabled for the port,\r\nsecurity group rules and anti-spoofing rules are applied to\r\nthe traffic on the port. If disabled, no such rules are applied.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nqos_network_policy_id\n\nbody\nstring\nThe ID of the QoS policy of the network where this port is plugged.\n\nqos_policy_id\n\nbody\nstring\nThe ID of the QoS policy associated with the port.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nresource_request (Optional)\nbody\nobject\nExpose Placement resources (i.e.: minimum-bandwidth) and\r\ntraits (i.e.: vnic-type, physnet) requested by a port to\r\nNova and Placement. A resource_request object contains a\r\nrequired key for the traits (generated from the vnic_type\r\nand the physnet) required by the port, and a resources key\r\nfor ingress and egress minimum-bandwidth need for the port.\n\nsecurity_groups\n\nbody\narray\nThe IDs of security groups applied to the port.\n\nstatus\n\nbody\nstring\nThe port status. Values are ACTIVE, DOWN,\r\nBUILD and ERROR.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\npropagate_uplink_status\n\nbody\nboolean\nThe uplink status propagation of the port. Valid values are\r\nenabled (true) and disabled (false).\n\nmac_learning_enabled (Optional)\nbody\nboolean\nA boolean value that indicates if MAC Learning is enabled on the\r\nassociated port.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"ports\": [\r\n    {\r\n      \"allowed_address_pairs\": [],\r\n      \"extra_dhcp_opts\": [],\r\n      \"updated_at\": \"2020-03-04T15:22:48Z\",\r\n      \"device_owner\": \"network:router_gateway\",\r\n      \"revision_number\": 4,\r\n      \"port_security_enabled\": false,\r\n      \"binding:profile\": {},\r\n      \"fixed_ips\": [\r\n        {\r\n          \"subnet_id\": \"351884c7-ee37-4a7d-9dcb-4cff4a1bba27\",\r\n          \"ip_address\": \"10.94.139.172\"\r\n        }\r\n      ],\r\n      \"id\": \"0e9413cf-34f5-456f-851e-b2f1027b71bd\",\r\n      \"security_groups\": [],\r\n      \"binding:vif_details\": {\r\n        \"port_filter\": true,\r\n        \"bridge_name\": \"br-int\",\r\n        \"datapath_type\": \"system\",\r\n        \"ovs_hybrid_plug\": false\r\n      },\r\n      \"binding:vif_type\": \"ovs\",\r\n      \"mac_address\": \"fa:16:3e:b6:fd:c4\",\r\n      \"project_id\": \"\",\r\n      \"status\": \"ACTIVE\",\r\n      \"binding:host_id\": \"node1.vstoragedomain\",\r\n      \"description\": \"\",\r\n      \"tags\": [],\r\n      \"device_id\": \"ce996632-45a2-4c6b-a951-a624eba74621\",\r\n      \"name\": \"\",\r\n      \"admin_state_up\": true,\r\n      \"network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n      \"tenant_id\": \"\",\r\n      \"created_at\": \"2020-03-04T15:22:41Z\",\r\n      \"binding:vnic_type\": \"normal\"\r\n    },\r\n    {\r\n      \"allowed_address_pairs\": [],\r\n      \"extra_dhcp_opts\": [],\r\n      \"updated_at\": \"2020-03-04T15:22:56Z\",\r\n      \"device_owner\": \"network:router_interface\",\r\n      \"revision_number\": 5,\r\n      \"port_security_enabled\": false,\r\n      \"binding:profile\": {},\r\n      \"fixed_ips\": [\r\n        {\r\n          \"subnet_id\": \"112f9b9c-7be2-41c9-8c31-903b263353e7\",\r\n          \"ip_address\": \"192.168.0.1\"\r\n        }\r\n      ],\r\n      \"id\": \"5374d25d-edfe-40dd-ae1e-bef883d8e72d\",\r\n      \"security_groups\": [],\r\n      \"binding:vif_details\": {\r\n        \"port_filter\": true,\r\n        \"bridge_name\": \"br-int\",\r\n        \"datapath_type\": \"system\",\r\n        \"ovs_hybrid_plug\": false\r\n      },\r\n      \"binding:vif_type\": \"ovs\",\r\n      \"mac_address\": \"fa:16:3e:13:20:14\",\r\n      \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"status\": \"ACTIVE\",\r\n      \"binding:host_id\": \"node1.vstoragedomain\",\r\n      \"description\": \"\",\r\n      \"tags\": [],\r\n      \"device_id\": \"ce996632-45a2-4c6b-a951-a624eba74621\",\r\n      \"name\": \"\",\r\n      \"admin_state_up\": true,\r\n      \"network_id\": \"c4e2f31b-fe3b-402b-ac1b-b182693f72f7\",\r\n      \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"created_at\": \"2020-03-04T15:22:44Z\",\r\n      \"binding:vnic_type\": \"normal\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-virtual-router-interfaces.html"
    },
    {
        "title": "Deleting user limits in WHMCS",
        "content": "Deleting user limits in WHMCS\nYou can delete the current limits with the ostor-limits service and parameter emailAddress specifying the email address. WHMCS removes the user limits from S3 cluster when you click the Delete button. Create a file S3_deleteLimitsForUser.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getClient.php');\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Delete s3 user limits.\r\nfunction S3_getLimitsForUser($userid) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get whmcs user email.\r\n    $s3_whmcs = S3_getClient($userid, $s3_config['whmcs_username']);\r\n\r\n    // Delete s3 user limits.\r\n    S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-limits&emailAddress=\" . $s3_whmcs['email'],\r\n        \"DELETE\"\r\n    );\r\n\r\n    // Clear array.\r\n    $_SESSION['s3_limits_user'] = null;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_getLimitsForUser($_GET['userid']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-user-limits-in-whmcs.html"
    },
    {
        "title": "Showing user details",
        "content": "Showing user detailsGET /v3/users/{user_id}\r\n\nShow details of a user with the specified ID.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=show-user-details-detail#show-user-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nuser_id\n\npath\nstring\nThe user ID.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/users/2973892bee384ca6b8c9886f0c4a8815\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nuser\n\nbody\nobject\nA user object.\n\ndefault_project_id (Optional)\nbody\nstring\n\nThe ID of the default project for the user.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain.\n\nenabled\n\nbody\nboolean\nIf the user is enabled, this value is true.\r\nIf the user is disabled, this value is false.\n\nid\n\nbody\nstring\nThe user ID.\n\nlinks\n\nbody\nobject\nThe links for the user resource.\n\nname\n\nbody\nstring\nThe user name. Must be unique within the owning domain.\n\npassword_expires_at\n\nbody\nstring\n\nThe date and time when the password expires. The time zone\r\nis UTC.\nThis is a response object attribute; not valid for requests.\r\nA null value indicates that the password never expires.\nNew in version 3.7\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"user\": {\r\n    \"name\": \"user1_renamed\",\r\n    \"links\": {\r\n      \"self\": \"https://<node_IP_addr>:5000/v3/users/2973892bee384ca6b8c9886f0c4a8815\"\r\n    },\r\n    \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"enabled\": true,\r\n    \"email\": \"user1@example.com\",\r\n    \"options\": {},\r\n    \"id\": \"2973892bee384ca6b8c9886f0c4a8815\",\r\n    \"password_expires_at\": null\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-user-details.html"
    },
    {
        "title": "Monitoring management services",
        "content": "Monitoring management services\nThe management services in Virtuozzo Hybrid Infrastructure include the following:\n\nvstorage-ui-keystone-admin provides user identity and authentication for internal services, as well as service discovery for internal compute services. The service runs on the management node.\nvstorage-ui-keystone-public provides user identity and authentication for external services, as well as service discovery for external compute services. The service runs on the management node.\nvstorage-ui-backend provides API for the management panel (admin and self-service) and command-line interface, as well as orchestrates all cluster management tasks. The service runs on the management node.\nvstorage-ui-agent is a worker service that executes tasks from the backend service. The service runs on each cluster node.\n\nTo monitor the management services, go to the Monitoring > Dashboard screen, and then click Grafana dashboard. A separate browser tab will open with preconfigured Grafana dashboards, one of which is dedicated to the management services and is called Backend service status. To see a detailed description for each chart, click the i icon on its left corner.\nThe Backend task state chart shows the state of management tasks over time. Management tasks include all tasks related to the infrastructure management. You can see the full list of tasks in the Task name drop-down menu above the chart and sort the displayed tasks by selecting them. The state can be one of the following: pending, running, success, or failed.\n\nThe Backend services status and Backend services list charts show the list of the management services and their availability over time. Time periods when the services have not been available will be highlighted in red. In this case, you will need to look into the following logs:\n\nFor the keystone-admin service on the management node:# less /var/log/vstorage-ui-backend/uwsgi-keystone-admin.log\n\nFor the keystone-public service on the management node:# less /var/log/vstorage-ui-backend/uwsgi-keystone-public.log\n\nFor the backend service on the management node:# less /var/log/vstorage-ui-backend/messages.log\r\n# less /var/log/vstorage-ui-backend/celery*.log\n\nFor the agent service on the affected cluster node:# less /var/log/vstorage-ui-agent/*\n\nOther charts on the dashboard show the rate of successful and failed requests for the keystone and backend services, as well as the 95th and 99th percentiles of response time, per 10-minute intervals. The most important charts here are those of error request rate and response time. If you see spikes on them, you need to check the status of the corresponding services.\n\nSee also\n\nManaging the infrastructure\n\nViewing cluster logs",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-management-services.html"
    },
    {
        "title": "7. Support and Documentation\u00c2\u00b6",
        "content": "7. Support and Documentation | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\n\n7. Support and Documentation\u00c2\u00b6\n\nBitNinja CloudFlare integration - https://doc.bitninja.io/docs/cdnintegration\nBitNinja CLI - https://doc.bitninja.io/docs/command_line_interface\nIncident Reports explained - https://doc.bitninja.io/docs/investigations\nBitNinja Slack integration - https://doc.bitninja.io/docs/slack_integration\nBitNinja Rest API - https://doc.bitninja.io/docs/REST%20Api/apiv2\nBitNinja Roadmap - https://doc.bitninja.io/docs/Roadmap\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/support-and-documentation.html"
    },
    {
        "title": "QoS policy rules",
        "content": "QoS policy rules\nYou can create two rule types to define a QoS policy:\n\nBandwidth limit provides bandwidth limitations on networks, ports or floating IPs. Any VM traffic that exceeds the specified rate will be dropped. \nMinimum bandwidth provides minimum bandwidth guarantees on networks, ports or floating IPs. VM traffic will use no less than the specified bandwidth.\n\nRules of different types can be combined in one QoS policy. For example, you can create a bandwidth limit rule and a minimum bandwidth rule. Additionally, you can add rules of one type to a policy if the traffic direction of each rule is different. For example, you can create two bandwidth limit rules, one for egress traffic and one for ingress traffic.\nLimitations\n\nA QoS policy with minimum bandwidth cannot be applied to entire virtual networks.\n\nTo define a bandwidth limit\nSpecify the following parameters:\n\nmax_kbps: The maximum rate, in Kbps, that the VM can send.\n\nmax_burst_kbps: The maximum amount of data, in kbits, that the port can send in a VM if the token buffer is full. The token buffer replenishes at a max_kbps rate.\n\nIf the burst value is set too low, bandwidth usage will be throttled even with a proper bandwidth limit setting, resulting in a lower than expected bandwidth. \nIf the configured burst value is too high, too few packets could be limited, resulting in a higher than expected bandwidth limit.\n\nIf you omit this parameter, the recommended burst value for TCP traffic will be applied, which defaults to 80% of the bandwidth limit. For example, if the bandwidth limit is  1000 kbps, then a burst value of 800 kbps is enough.\n\ningress or egress: The direction of traffic the rule is applied to. For a VM, ingress indicates download, and egress indicates upload.\n\nTo define minimum  bandwidth\nSpecify the following parameters:\n\nmin-kbps: The minimum bandwidth, in Kbps, guaranteed to a VM.\ningress or egress: The direction of traffic the rule is applied to. For a VM, ingress indicates download, and egress indicates upload.\n\nWhat's next\n\nCreating QoS policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/qos-policy-rules.html"
    },
    {
        "title": "Creating virtual routers",
        "content": "Creating virtual routers\nPrerequisites\n\nCompute networks are created, as described in Creating physical compute networks and Creating virtual compute networks.\nThe compute networks that are to be connected to a router have a gateway specified.\n\nTo create a virtual router\n\nAdmin panel\n\nOn the Compute > Network > Routers tab, click Add router.\n\nIn the Add router window:\n\nSpecify a router name.\nFrom the Network drop-down menu, select a physical network through which external access will be provided via an external gateway. The new external gateway will pick an unused IP address from the selected physical network.\nIn the Add internal interfaces section, select one or more virtual networks to connect to a router via internal interfaces. The new internal interfaces will attempt to use the gateway IP address of the selected virtual networks by default.\n\nSelect or deselect the SNAT check box to enable or disable SNAT on the external gateway of the router. With SNAT enabled, the router replaces VM private IP addresses with the public IP address of its external gateway.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra service compute router create [--external-gateway <network>]\r\n                                     [--enable-snat | --disable-snat]\r\n                                     [--fixed-ip <fixid-ip>]\r\n                                     [--internal-interface <network=network,ip-addr=ip-addr> |\r\n                                     <network>] <router-name>\r\n\n\n--external-gateway <network>\n\nSpecify a physical network to be used as the router\u00e2\u0080\u0099s external gateway (name or ID)\n--enable-snat\n\nEnable source NAT on the external gateway\n--disable-snat\n\nDisable source NAT on the external gateway\n--fixed-ip <fixid-ip>\n\nDesired IP on the external gateway\n--internal-interface <network=network,ip-addr=ip-addr>|<network>\n\nSpecify an internal interface. This option can be used multiple times.\n\nnetwork: name of a virtual network.\nip-addr: an unused IP address from the selected virtual network to assign to the interface; specify if the default gateway of the selected virtual network is in use.\n\n<router-name>\n\nVirtual router name\n\nFor example, to create a router myrouter between the physical network public and the virtual network private with enabled SNAT on the external gateway, run:# vinfra service compute router create myrouter --external-gateway public \\\r\n--internal-interface private --enable-snat\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: true                                |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | []                                               |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\r\n\nThe created router will appear in the vinfra service compute router list output:# vinfra service compute router list -c id -c external_gateway_info -c name -c status\r\n+---------------------+---------------------------------+----------+--------+\r\n| id                  | external_gateway_info           | name     | status |\r\n+---------------------+---------------------------------+----------+--------+\r\n| b9d8b000-5d06-<...> | enable_snat: true               | myrouter | ACTIVE |\r\n|                     | ip_addresses:                   |          |        |\r\n|                     | - 10.94.129.76                  |          |        |\r\n|                     | network_id: 720e45bc-4225-<...> |          |        |\r\n+---------------------+---------------------------------+----------+--------+\r\n\n\nSee also\n\nViewing router ports\n\nManaging router interfaces\n\nManaging static routes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute router create [--external-gateway <network>]\r\n                                     [--enable-snat | --disable-snat]\r\n                                     [--fixed-ip <fixid-ip>]\r\n                                     [--internal-interface <network=network,ip-addr=ip-addr> |\r\n                                     <network>] <router-name>\r\n\n\n--external-gateway <network>\n\nSpecify a physical network to be used as the router\u00e2\u0080\u0099s external gateway (name or ID)\n--enable-snat\n\nEnable source NAT on the external gateway\n--disable-snat\n\nDisable source NAT on the external gateway\n--fixed-ip <fixid-ip>\n\nDesired IP on the external gateway\n--internal-interface <network=network,ip-addr=ip-addr>|<network>\n\n\nSpecify an internal interface. This option can be used multiple times.\n\nnetwork: name of a virtual network.\nip-addr: an unused IP address from the selected virtual network to assign to the interface; specify if the default gateway of the selected virtual network is in use.\n\n\n<router-name>\n\nVirtual router name\n\nFor example, to create a router myrouter between the physical network public and the virtual network private with enabled SNAT on the external gateway, run:# vinfra service compute router create myrouter --external-gateway public \\\r\n--internal-interface private --enable-snat\r\n+-----------------------+--------------------------------------------------+\r\n| Field                 | Value                                            |\r\n+-----------------------+--------------------------------------------------+\r\n| external_gateway_info | enable_snat: true                                |\r\n|                       | ip_addresses:                                    |\r\n|                       | - 10.94.129.76                                   |\r\n|                       | network_id: 720e45bc-4225-49de-9346-26513d8d1262 |\r\n| id                    | b9d8b000-5d06-4768-9f65-2715250cda53             |\r\n| name                  | myrouter                                         |\r\n| project_id            | 894696133031439f8aaa7e4868dcbd4d                 |\r\n| routes                | []                                               |\r\n| status                | ACTIVE                                           |\r\n+-----------------------+--------------------------------------------------+\r\n\nThe created router will appear in the vinfra service compute router list output:# vinfra service compute router list -c id -c external_gateway_info -c name -c status\r\n+---------------------+---------------------------------+----------+--------+\r\n| id                  | external_gateway_info           | name     | status |\r\n+---------------------+---------------------------------+----------+--------+\r\n| b9d8b000-5d06-<...> | enable_snat: true               | myrouter | ACTIVE |\r\n|                     | ip_addresses:                   |          |        |\r\n|                     | - 10.94.129.76                  |          |        |\r\n|                     | network_id: 720e45bc-4225-<...> |          |        |\r\n+---------------------+---------------------------------+----------+--------+\r\n\n",
                "title": "To create a virtual router"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Routers tab, click Add router.\n\nIn the Add router window:\n\nSpecify a router name.\nFrom the Network drop-down menu, select a physical network through which external access will be provided via an external gateway. The new external gateway will pick an unused IP address from the selected physical network.\nIn the Add internal interfaces section, select one or more virtual networks to connect to a router via internal interfaces. The new internal interfaces will attempt to use the gateway IP address of the selected virtual networks by default.\n\nSelect or deselect the SNAT check box to enable or disable SNAT on the external gateway of the router. With SNAT enabled, the router replaces VM private IP addresses with the public IP address of its external gateway.\n\n\n\n\n\n\n\n\nClick Create.\n\n\n",
                "title": "To create a virtual router"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-virtual-routers.html"
    },
    {
        "title": "Creating IPsec connections",
        "content": "Creating IPsec connectionsPOST /v2.0/vpn/ipsec-site-connections\nCreate a site-to-site IPsec connection for a service.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-ipsec-connection-detail#create-ipsec-connection\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nipsec_site_connection\n\nbody\nobject\nAn ipsec_site_connection object.\n\nauth_mode (Optional)\nbody\nstring\nThe authentication mode. A valid value is psk, which is the default.\n\nikepolicy_id (Optional)\nbody\nstring\nThe ID of the IKE policy.\n\nvpnservice_id (Optional)\nbody\nstring\nThe ID of the VPN service.\n\nlocal_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private subnets for the local side of the connection. You must specify this parameter with the peer_ep_group_id parameter.\n\npeer_address\n\nbody\nstring\nThe peer gateway public IPv4 or IPv6 address or FQDN.\n\nroute_mode (Optional)\nbody\nstring\nThe route mode. A valid value is static, which is the default.\n\nipsecpolicy_id (Optional)\nbody\nstring\nThe ID of the IPsec policy.\n\npeer_id\n\nbody\nstring\nThe peer router identity for authentication. A valid value is an IPv4 address, IPv6 address, e-mail address, key ID, or FQDN. Typically, this value matches the peer_address value.\n\npsk\n\nbody\nstring\nThe pre-shared key. A valid value is any string.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ninitiator (Optional)\nbody\nstring\nIndicates whether this VPN can only respond to connections or both respond to and initiate connections. A valid value is response-only or bi-directional. Default is bi-directional.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ninterval (Optional)\nbody\ninteger\nThe dead peer detection (DPD) interval, in seconds. A valid value is a positive integer. Default is 30.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6.\n\npeer_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private CIDRs in the form <net_address>/<prefix> for the peer side of the connection. You must specify this parameter with the local_ep_group_id parameter.\n\ndpd (Optional)\nbody\nobject\nA dictionary with dead peer detection (DPD) protocol controls.\n\ntimeout\n\nbody\ninteger\nThe dead peer detection (DPD) timeout in seconds. A valid value is a positive integer that is greater than the DPD interval value. Default is 120.\n\naction\n\nbody\nstring\nThe dead peer detection (DPD) action. A valid value is clear, hold, restart, disabled, or restart-by-peer. Default value is hold.\n\nlocal_id (Optional)\nbody\nstring\nAn ID to be used instead of the external IP address for a virtual router used in traffic between instances on different networks in east-west traffic. Most often, local ID would be domain name, email address, etc. If this is not configured then the external IP address will be used as the ID.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"ipsec_site_connection\": {\r\n        \"psk\": \"secret\",\r\n        \"initiator\": \"bi-directional\",\r\n        \"ipsecpolicy_id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n        \"admin_state_up\": true,\r\n        \"mtu\": \"1500\",\r\n        \"peer_ep_group_id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n        \"ikepolicy_id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n        \"vpnservice_id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n        \"local_ep_group_id\": \"646938a8-322e-44b3-ac35-60deadcd4252\",\r\n        \"peer_address\": \"10.136.18.138\",\r\n        \"peer_id\": \"10.136.18.138\",\r\n        \"name\": \"vpnconnection1\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/ipsec-site-connections\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nipsec_site_connection\n\nbody\nobject\nAn ipsec_site_connection object.\n\nauth_mode (Optional)\nbody\nstring\nThe authentication mode. A valid value is psk, which is the default.\n\nikepolicy_id\n\nbody\nstring\nThe ID of the IKE policy.\n\nvpnservice_id\n\nbody\nstring\nThe ID of the VPN service.\n\nlocal_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private subnets for the local side of the connection. You must specify this parameter with the peer_ep_group_id parameter.\n\npeer_address\n\nbody\nstring\nThe peer gateway public IPv4 or IPv6 address or FQDN.\n\nid (Optional)\nbody\nstring\nThe ID of the IPsec site-to-site connection.\n\nroute_mode (Optional)\nbody\nstring\nThe route mode. A valid value is static, which is the default.\n\nipsecpolicy_id\n\nbody\nstring\nThe ID of the IPsec policy.\n\npeer_id\n\nbody\nstring\nThe peer router identity for authentication. A valid value is an IPv4 address, IPv6 address, e-mail address, key ID, or FQDN. Typically, this value matches the peer_address value.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec connection is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\npsk\n\nbody\nstring\nThe pre-shared key. A valid value is any string.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ninitiator (Optional)\nbody\nstring\nIndicates whether this VPN can only respond to connections or both respond to and initiate connections. A valid value is response-only or bi-directional. Default is bi-directional.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ninterval (Optional)\nbody\ninteger\nThe dead peer detection (DPD) interval, in seconds. A valid value is a positive integer. Default is 30.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6.\n\npeer_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private CIDRs in the form <net_address>/<prefix> for the peer side of the connection. You must specify this parameter with the local_ep_group_id parameter.\n\ndpd (Optional)\nbody\nobject\nA dictionary with dead peer detection (DPD) protocol controls.\n\ntimeout\n\nbody\ninteger\nThe dead peer detection (DPD) timeout in seconds. A valid value is a positive integer that is greater than the DPD interval value. Default is 120.\n\naction\n\nbody\nstring\nThe dead peer detection (DPD) action. A valid value is clear, hold, restart, disabled, or restart-by-peer. Default value is hold.\n\nlocal_id (Optional)\nbody\nstring\nAn ID to be used instead of the external IP address for a virtual router used in traffic between instances on different networks in east-west traffic. Most often, local ID would be domain name, email address, etc. If this is not configured then the external IP address will be used as the ID.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"ipsec_site_connection\": {\r\n    \"id\": \"324dc68b-bdee-4a78-9d14-3484d8ee97a9\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"vpnconnection1\",\r\n    \"description\": \"\",\r\n    \"peer_address\": \"10.136.18.138\",\r\n    \"peer_id\": \"10.136.18.138\",\r\n    \"local_id\": \"\",\r\n    \"route_mode\": \"static\",\r\n    \"mtu\": 1500,\r\n    \"auth_mode\": \"psk\",\r\n    \"psk\": \"secret\",\r\n    \"initiator\": \"bi-directional\",\r\n    \"dpd\": {\r\n      \"action\": \"hold\",\r\n      \"interval\": 30,\r\n      \"timeout\": 120\r\n    },\r\n    \"admin_state_up\": true,\r\n    \"status\": \"PENDING_CREATE\",\r\n    \"vpnservice_id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n    \"ikepolicy_id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n    \"ipsecpolicy_id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n    \"peer_cidrs\": [],\r\n    \"local_ep_group_id\": \"646938a8-322e-44b3-ac35-60deadcd4252\",\r\n    \"peer_ep_group_id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n    \"split_selector\": false,\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-ipsec-connections.html"
    },
    {
        "title": "Monitoring Kubernetes clusters",
        "content": "Monitoring Kubernetes clusters\n\nThis feature is experimental and not intended for use in production environments.\n\nIf you have enabled integrated monitoring during your Kubernetes cluster deployment, that means that the cluster has the monitoring_enabled=true label and the following components installed:\n\nPrometheus for data collection, storage, and search:\n\nnode-exporter exposes various server-level and OS-level metrics.\nkube-state-metrics generates metrics on the state of Kubernetes objects.\n\nAlertmanager for alarm aggregation, processing, and dispatch.\nGrafana server for metrics visualization.\n\nFor instructions on how to create and configure Alertmanager and Prometheus instances, refer to the kube-prometheus documentation.\nThe Grafana server is accessible from within a Kubernetes cluster at the magnum-grafana.kube-system.svc.cluster.local DNS name and TCP port 80.\nThe metrics on the state of Kubernetes objects are exported at the /metrics HTTP endpoint on the listening port: magnum-kube-state-metrics.kube-system.svc.cluster.local:8080/metrics. The metrics can be consumed either by Prometheus itself or by a scraper that is able to scrape a Prometheus client endpoint. For the list of exposed metrics, refer to kube-state-metrics documentation.\nPrerequisites\n\nA Kubernetes cluster with enabled integrated monitoring is created, as described in Creating and deleting Kubernetes clusters.\n\nTo access the Kubernetes Grafana dashboards\n\nOn the Kubernetes clusters screen, click a Kubernetes cluster.\nOn the cluster right pane, click Download kubeconfig. The .kubeconfig file will be downloaded to your client machine.\nOn your client machine, install and set up the kubectl tool, to be able to run commands against Kubernetes clusters, as described in the official documentation.\n\nSpecify the path to your Kubernetes configuration file in the KUBECONFIG environment variable:# export KUBECONFIG=<path_to_kubeconfig>\n\nCheck that the kube-prometheus stack is installed:# kubectl --namespace kube-system get pods -l \"release=magnum\"\r\nNAME                                                  READY  STATUS   RESTARTS  AGE\r\nmagnum-kube-prometheus-sta-operator-85f757c5dc-ckllb  1/1    Running  0         3d17h\r\nmagnum-kube-state-metrics-5cc46cbc5f-tclcv            1/1    Running  0         3d17h\r\nmagnum-prometheus-node-exporter-99kfc                 1/1    Running  0         3d3h\r\nmagnum-prometheus-node-exporter-gwgzr                 1/1    Running  0         3d17h\r\nmagnum-prometheus-node-exporter-q2pm2                 1/1    Running  0         3d17h\r\nmagnum-prometheus-node-exporter-sqsl7                 1/1    Running  0         2d22h\n\nObtain the password of the admin user:# kubectl get secret --namespace kube-system magnum-grafana \\\r\n-o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n\nConfigure the port forwarding for the Grafana pod:# kubectl --namespace kube-system port-forward service/magnum-grafana 3000:80\n\nLog in to http://localhost:3000 under the admin user by specifying its username and password obtained in step 6.\n\nIn the left menu, click Dashboards > Browse, and then select the dashboard you want to view.\n\nTo access the Prometheus user interface\n\nOn the Kubernetes clusters screen, click a Kubernetes cluster.\nOn the cluster right pane, click Download kubeconfig. The .kubeconfig file will be downloaded to your client machine.\nOn your client machine, install and set up the kubectl tool, to be able to run commands against Kubernetes clusters, as described in the official documentation.\n\nSpecify the path to your Kubernetes configuration file in the KUBECONFIG environment variable:# export KUBECONFIG=<path_to_kubeconfig>\n\nConfigure the port forwarding for the Prometheus pod:\r\n# kubectl --namespace kube-system port-forward service/magnum-kube-prometheus-sta-prometheus 9090\n\nVisit http://localhost:9090/graph to use the Prometheus expression browser and to graph expressions. You can also navigate to http://localhost:9090/metrics to view the list of exported metrics, or http://localhost:9090/alerts to view the alerting rules.\n\nTo access the Alertmanager user interface\n\nOn the Kubernetes clusters screen, click a Kubernetes cluster.\nOn the cluster right pane, click Download kubeconfig. The .kubeconfig file will be downloaded to your client machine.\nOn your client machine, install and set up the kubectl tool, to be able to run commands against Kubernetes clusters, as described in the official documentation.\n\nSpecify the path to your Kubernetes configuration file in the KUBECONFIG environment variable:# export KUBECONFIG=<path_to_kubeconfig>\n\nConfigure the port forwarding for the Alertmanager pod:\r\n# kubectl --namespace kube-system port-forward service/magnum-kube-prometheus-sta-alertmanager 9093\n\nVisit http://localhost:9093 to access the Alertmanager user interface.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/monitoring-kubernetes-clusters.html"
    },
    {
        "title": "Managing VPN connections",
        "content": "Managing VPN connections\nWith Virtual Private Network (VPN) as a service, self-service users can extend virtual networks across public networks, such as the Internet. To connect two or more remote endpoints, VPNs use virtual connections tunneled through physical networks. To secure VPN communication, the traffic that flows between remote endpoints is encrypted. The VPN implementation uses the Internet Key Exchange (IKE) and IP Security (IPsec) protocols to establish secure VPN connections and is based on the strongSwan IPsec solution.\nVPN as a service can be used to establish a Site-to-Site VPN connection between a virtual network configured in Virtuozzo Hybrid Infrastructure and any other network with a VPN gateway that uses the IPsec and IKE protocols. With VPN as a service, you can connect the following workloads:\n\nOn-premises workloads with workloads hosted in Virtuozzo Hybrid Infrastructure\nWorkloads hosted in other clouds with workloads hosted in Virtuozzo Hybrid Infrastructure\nWorkloads hosted in different Virtuozzo Hybrid Infrastructure clusters\n\nAdditionally, VPN as a service provides high availability to VPN connections in clusters with enabled HA. If a node that hosts a virtual router fails, a VPN connection re-initiates after the virtual router relocates to a healthy node.\nVPN connections are created and managed by self-service users, as described in \"Managing VPN connections\" in the Self-Service Guide. In the admin panel, you can view VPN connection details and delete VPN connections.\nLimitations\n\nCurrently, we support only Site-to-Site VPN connections. Point-to-Site VPN connections are not supported.\nVPN connections cannot be tunneled through IPv6 and dual-stack physical networks.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\n\nTo view the details of a VPN connection\n\nAdmin panel\nOn the Compute > Network > VPN screen, click a VPN connection to open its right pane. \n\nCommand-line interface\nUse the following command:vinfra service compute vpn connection show <connection>\r\n\n\n<connection>\n\nVPN connection ID or name\n\nFor example, to view the details of the VPN connection vpn1, run:# vinfra service compute vpn connection show vpn1\r\n+-------------------+--------------------------------------+\r\n| Field             | Value                                |\r\n+-------------------+--------------------------------------+\r\n| dpd               | action: hold                         |\r\n|                   | interval: 30                         |\r\n|                   | timeout: 120                         |\r\n| id                | 9848fd7c-ac1c-4412-bf8d-7616b13a3d03 |\r\n| ikepolicy_id      | 1d70c833-4a8b-455b-9a1b-a86a61159123 |\r\n| initiator         | bi-directional                       |\r\n| ipsecpolicy_id    | 2e1edf17-2874-41ba-9faa-0cb879d09c97 |\r\n| local_ep_group_id | cc8959d8-7274-44b3-b76c-373b19b1ca32 |\r\n| local_id          |                                      |\r\n| mtu               | 1500                                 |\r\n| name              | vpn1                                 |\r\n| peer_address      | 10.136.18.134                        |\r\n| peer_ep_group_id  | deb02fcd-6e24-46e8-b3db-bf41b9ec2564 |\r\n| peer_id           | 10.136.18.134                        |\r\n| project_id        | bba7c2edf544432c9177e2b63b755e10     |\r\n| route_mode        | static                               |\r\n| router_id         | 1da614a7-3fe7-42e0-9494-864d1e890135 |\r\n| status            | ACTIVE                               |\r\n| vpnservice_id     | 01a4ee33-2192-4575-9b01-629144093712 |\r\n+-------------------+--------------------------------------+\n\nTo delete a VPN connection\n\nAdmin panel\n\nOn the Compute > Network > VPN screen, click a VPN connection.\n On the right pane, click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service compute vpn connection delete <connection>\r\n\n\n<connection>\n\nVPN connection ID or name\n\nFor example, to delete the VPN connection vpn1, run:# vinfra service compute vpn connection delete vpn1\r\n\n\nSee also\n\nManaging compute networks\n\nManaging virtual routers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute vpn connection show <connection>\r\n\n\n<connection>\n\nVPN connection ID or name\n\nFor example, to view the details of the VPN connection vpn1, run:# vinfra service compute vpn connection show vpn1\r\n+-------------------+--------------------------------------+\r\n| Field             | Value                                |\r\n+-------------------+--------------------------------------+\r\n| dpd               | action: hold                         |\r\n|                   | interval: 30                         |\r\n|                   | timeout: 120                         |\r\n| id                | 9848fd7c-ac1c-4412-bf8d-7616b13a3d03 |\r\n| ikepolicy_id      | 1d70c833-4a8b-455b-9a1b-a86a61159123 |\r\n| initiator         | bi-directional                       |\r\n| ipsecpolicy_id    | 2e1edf17-2874-41ba-9faa-0cb879d09c97 |\r\n| local_ep_group_id | cc8959d8-7274-44b3-b76c-373b19b1ca32 |\r\n| local_id          |                                      |\r\n| mtu               | 1500                                 |\r\n| name              | vpn1                                 |\r\n| peer_address      | 10.136.18.134                        |\r\n| peer_ep_group_id  | deb02fcd-6e24-46e8-b3db-bf41b9ec2564 |\r\n| peer_id           | 10.136.18.134                        |\r\n| project_id        | bba7c2edf544432c9177e2b63b755e10     |\r\n| route_mode        | static                               |\r\n| router_id         | 1da614a7-3fe7-42e0-9494-864d1e890135 |\r\n| status            | ACTIVE                               |\r\n| vpnservice_id     | 01a4ee33-2192-4575-9b01-629144093712 |\r\n+-------------------+--------------------------------------+\n",
                "title": "To view the details of a VPN connection"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute vpn connection delete <connection>\r\n\n\n<connection>\n\nVPN connection ID or name\n\nFor example, to delete the VPN connection vpn1, run:# vinfra service compute vpn connection delete vpn1\r\n\n",
                "title": "To delete a VPN connection"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nOn the Compute > Network > VPN screen, click a VPN connection to open its right pane. \n",
                "title": "To view the details of a VPN connection"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > VPN screen, click a VPN connection.\n On the right pane, click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a VPN connection"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-vpn-connections.html"
    },
    {
        "title": "Configuring scheduling of virtual machines",
        "content": "Configuring scheduling of virtual machines\nIn the compute cluster, the nova-scheduler service manages scheduling of virtual machines, that is, determines on which compute node to launch a VM. Each scheduling request goes through the following steps:\n\nPrefilters. The scheduler uses the Placement service to filter  compute nodes and excludes those that do not satisfy the request parameters.\n\nFilters. The scheduler applies filters to the list of candidate nodes, to determine which nodes are suitable for launching a VM. A node is either passed through by the filters or excluded from the list. These filters include:\n\nAvailabilityZoneFilter: Passes all nodes that match the availability zone specified in the VM properties.\nComputeFilter: Passes all compute nodes that are operational and enabled.\nComputeCapabilitiesFilter: Passes all nodes that satisfy the flavor extra specs.\nImagePropertiesFilter: Passes all nodes that satisfy the requested image properties.\nPciPassthroughFilter: Passes all nodes that have requested PCI devices.\nServerGroupAntiAffinityFilter: Passes all nodes that are not hosting virtual machines in a specified group.\nServerGroupAffinityFilter: Passes all nodes that are already hosting virtual machines in a specified group.\nSameHostFilter: Passes the node that is hosting all other VMs in a set of VMs.\n\nWeights. The scheduler weighs the filtered compute nodes by using the enabled weighers and their multipliers, to decide which node has the highest priority for launching a VM. The following weighers are available:\n\nRAMWeigher: Weighs nodes based on the available RAM. It accounts for the physical RAM on a node with the overcommitment ratio, excluding the RAM reserved for system and storage services, and provisioned for VMs.\nCPUWeigher: Weighs nodes based on the available virtual CPUs. It accounts for the physical CPU cores on a node with the overcommitment ratio, excluding the vCPUs reserved for system and storage services, and provisioned for VMs\nServerGroupSoftAntiAffinityWeigher: Weighs nodes based on the number of VMs running on them from the same VM group in increasing order.\nPCIWeigher: Weighs nodes based on the number of available PCI devices and the number of PCI devices requested by a VM.\nMetricsWeigher: Weighs nodes based on their real-time metrics.\n\nFirst, each weight is normalized to a value between 0.0 and 1.0, depending on the availability of a resource. Then, a multiplier is applied to each weight. The weight multiplier defines the weigher priority compared to other weighers. The final weight for a node is calculated by using this formula:node_weight = weight1_multiplier * norm(weight1) + weight2_multiplier * norm(weight2) + ...\nThe node with the highest weight is considered by the scheduler the most suitable for launching a VM.\n\nTo change the default VM scheduling behavior in the compute cluster, you need to create a configuration file in the YAML format, and then use it to reconfigure the compute cluster.\nTo create the scheduler configuration file\nSet custom weight multipliers to any of the enabled weighers. Valid values are float. The following weight multipliers can be defined in the configuration file:\n\nram_weight_multiplier\n\nIf set to a positive value, the scheduler will place VMs on nodes with more available RAM, and thus, spread them evenly across all compute nodes. In this case, however, you may end up unable to launch large VMs on particular nodes while having plenty of free RAM in the entire cluster.\nIf set to a negative value, the scheduler will place VMs on nodes with less available RAM, which will optimize VMs distribution and fill up nodes as much as possible.\nThe default value is 1.0.\n\ncpu_weight_multiplier\n\nIf set to a positive value, the scheduler will place VMs on nodes with more available vCPUs, and thus, spread them evenly across all compute nodes. In this case, however, you may end up unable to launch large VMs on particular nodes while having plenty of free vCPUs in the entire cluster.\nIf set to a negative value, the scheduler will place VMs on nodes with less available vCPUs, which will optimize VMs distribution and fill up nodes as much as possible.\nThe default value is 1.0.\n\nsoft_anti_affinity_weight_multiplier\n\nThe multiplier only accepts positive values. The default value is 5.0.\n\npci_weight_multiplier\n\nThe multiplier only accepts positive values. The default value is 1.0.\n\nmetrics_weight_multiplier\n\nIf set to a value greater than 1.0, the weight of the metrics specified by the metrics_weight_setting parameter will be increased.\nIf set to a value between 0.0 and 1.0, the weight of the metrics specified by the metrics_weight_setting parameter will be reduced.\nIf set to a negative value, the node with lower metrics specified by the metrics_weight_setting parameter will have a higher weight.\nThe default value is 1.0.\n\nmetrics_weight_setting\n\nSpecifies the node metrics and their multipliers to use for weighing.\nValid metric names are the following:\n\ncpu_percent\n\ncpu_frequency\n\ncpu_kernel_time\n\ncpu_kernel_percent\n\ncpu_user_time\n\ncpu_user_percent\n\ncpu_idle_time\n\ncpu_idle_percent\n\ncpu_iowait_time\n\ncpu_iowait_percent\n\nmem.free.mb\n\nmem.free.percent\n\nmem.cached.mb\n\nmem.cached.percent\n\nmem.buffers.mb\n\nmem.buffers.percent\n\nThe default metric multiplier is 1.0.\n\nThe scheduler configuration file may look like this:\n\n\r\ncpu_weight_multiplier: -1.0\nThe scheduler will consolidate virtual machines on nodes with less available vCPUs.\n\n\r\nram_weight_multiplier: 2.0\r\nmetrics_weight_multiplier: 2.5\r\nmetrics_weight_setting: \r\n   cpu_user_time: 3.0\r\n   cpu_kernel_time: 1.5\nThe final node weight will be calculated as follows:node_weight = 2.0 * norm(free_ram_mb) + 2.5 * (3.0 * norm(cpu_user_time) + 1.5 * norm(cpu_kernel_time))\nWhen placing virtual machines, the scheduler will prefer nodes with more available RAM and real-time CPU usage.\n\nTo apply new VM scheduling parameters\nPass the scheduler configuration file to the vinfra service compute set command. For example:# cat scheduler.yaml\r\nram_weight_multiplier: 2.0\r\nmetrics_weight_multiplier: 2.5\r\nmetrics_weight_setting: \r\n   cpu_user_time: 3.0\r\n   cpu_kernel_time: 1.5\r\n# vinfra service compute set --scheduler-config scheduler.yaml\nTo check that the scheduler parameters are successfully modified, run:# vinfra service compute show\r\n+--------------+---------------------------------------------+\r\n| Field        | Value                                       |\r\n+--------------+---------------------------------------------+\r\n| <...>        | <...>                                       |\r\n|              | scheduler:                                  |\r\n|              |   cpu_weight_multiplier: 1.0                |\r\n|              |   metrics_weight_multiplier: 2.5            |\r\n|              |   metrics_weight_setting:                   |\r\n|              |     cpu_kernel_time: 1.5                    |\r\n|              |     cpu_user_time: 3.0                      |\r\n|              |   pci_weight_multiplier: 1.0                |\r\n|              |   ram_weight_multiplier: 2.0                |\r\n|              |   soft_anti_affinity_weight_multiplier: 5.0 |\r\n| status       | active                                      |\r\n| storages     | - vstorage                                  |\r\n+--------------+---------------------------------------------+\nThe applied changes are consistent on all compute nodes and not overwritten after product updates and upgrades.\nSee also\n\nConfiguring compute parameters\n\nConfiguring memory for virtual machines\n\nChanging virtual CPU overcommitment\n\nConfiguring CPU features for virtual machines",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-vm-scheduling.html"
    },
    {
        "title": "Obtaining Linux templates",
        "content": "Obtaining Linux templates\nAs all Linux guests have OpenSSH Server preinstalled by default, you only need to make sure a Linux template has cloud-init installed.\nThe easiest way to get a Linux template with cloud-init installed is to obtain it from its official repository or build one with the diskimage-builder tool. You can also create a Linux template from an existing boot volume.\nLimitations\n\nThe disk image is created with only the root user that has neither password nor SSH keys. You can use the user data and cloud-init methods to perform initial configuration tasks on VMs that will be deployed from the disk image, for example, create custom user accounts. For more options to customize a VM during boot, refer to the cloud-init documentation.\n\nTo build a Linux template\n\nInstall the diskimage-builder package:# yum install diskimage-builder\r\n\n\nFor the RHEL 7 guest OS, download the cloud image from the Red Hat Customer Portal (login required) and execute:# export DIB_LOCAL_IMAGE=<path_to_rhel7_image>\r\n\n\nExecute the disk-image-create command to build a disk image with installed cloud-init for the desired Linux guest. For example:# disk-image-create vm centos7 -t qcow2 -o centos7\r\n\nwhere\n\ncentos7 is the name of a guest OS. Can be one of the following: centos6, centos7, debian, rhel7, or ubuntu.\nBy default, using the ubuntu element will create a disk image for Ubuntu 16.04. To build the Ubuntu 18.04 disk image, add the DIB_RELEASE=bionic to the command: DIB_RELEASE=bionic disk-image-create vm ubuntu -t qcow2 -o ubuntu18.\n\n-o sets the name for the resulting disk image file.\n\nUpload the created disk image by using the vinfra tool to the compute cluster:# vinfra service compute image create centos7-image --os-distro centos7 \\\r\n--disk-format qcow2 --file centos7.qcow2\r\n\nwhere\n\ncentos7-image is the name of a new image.\ncentos7 is the OS distribution. Can be one of the following: centos6, centos7, debian9, rhel7, ubuntu16.04, and ubuntu18.04.\ncentos7.qcow2 is the QCOW2-image created on step 3.\n\nTo deploy a virtual machine from the uploaded template\n\nCreate the user-data configuration file with a custom user account:# cat <<EOF > user-data\r\n#cloud-config\r\nuser: myuser\r\npassword: password\r\nchpasswd: {expire: False}\r\nssh_pwauth: True\r\nEOF\r\n\nwhere myuser is the name of a custom user and password is a password for the account.\n\nLaunch the deployment of a VM from the disk image by using the configuration file as user data:# vinfra service compute server create centos7-vm --flavor medium \\\r\n--network public --user-data user-data --volume source=image,\\id=centos7-image,size=10\r\n\nwhere\n\ncentos7-vm is the name of a new VM.\nuser-data is the configuration file created in step 5.\ncentos7-image is the image added to the compute cluster in step 4.\n\nWhat's next\n\nEnabling logging for virtual machines\n\nCreating templates\n\nCreating virtual machines\n\nRescuing virtual machines\n\nManaging images",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/obtaining-linux-templates.html"
    },
    {
        "title": "Network requirements and recommendations",
        "content": "Network requirements and recommendations\nWhen planning the network for your cluster, ensure that it meets the general network requirements and recommendations. Additional network requirements depend on the services you will deploy.\n\nKeep in mind that the 10.100.0.0/16 and 10.254.0.0/16 subnets should be avoided if you plan to deploy Kubernetes clusters.\n\nSee also\n\nHardware recommendations\n\nServer requirements\n\nDisk requirements\n\nAdmin panel requirements",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/network-requirements-and-recommendations.html"
    },
    {
        "title": "PUT service ostor-quotas",
        "content": "PUT service ostor-quotas\nDescription\nSets a quota value for the specified user/bucket or for all users/buckets.\nRequests\nSyntaxPUT /?ostor-quotas&emailAddress=<value>&quota-size=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>PUT /?ostor-quotas&bucket=<value>&quota-size=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>PUT /?ostor-quotas&default=<value>&quota-size=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nPUT Service ostor-limits parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nYes*\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes*\n\nquota-size\n\nSets the storage usage limit per user or bucket, as well as for all users or buckets, in gigabytes.\nType: integer.\r\n\nDefault: 0.\n\nYes\n\ndefault\n\nSets the default value for quotas. If set to user, defines the default quotas for all users. If set to bucket, defines the default quotas for all buckets.\nType: string.\nDefault: none.\n\nNo\n\n* Only one of the required parameters can be set in a single request.\nZero value means \u00e2\u0080\u009cunlimited\u00e2\u0080\u009d.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nErrors\nReturns Error Code 400 if a wrong set of parameters is specified.\nExamples\nSample request #1\nSets a quota for the user with the email user1@email.com to 1024 GB.PUT /?ostor-quotas&emailAddress=user1@email.com&ops&quota-size=1024 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:21:35 GMT\r\nAuthorization: <authorization_string>\nSample response #1HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate: Thu, 09 Sep 2021 20:21:40 GMT\r\nContent-type : application/json\nSample request #2\nSets a quota for the bucket bucket1 to 256 GB.PUT /?ostor-quotas&bucket=bucket1&quota-size=256 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:22:57 GMT\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 20:23:02 GMT\r\nContent-type : application/json\nSample request #3\nSets the default user quotas to 1024 GB.PUT /?ostor-quotas&default=user&quota-size=1024 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:24:15 GMT\r\nAuthorization: <authorization_string>\nSample response #3HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 20:24:19 GMT\r\nContent-type : application/json\nSample request #4\nSets the default bucket quotas to 256 GB.PUT /?ostor-quotas&default=bucket&quota-size=256 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:25:31\r\nAuthorization: <authorization_string>\nSample response #4HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 20:25:36 GMT\r\nContent-type : application/json",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/put-service-ostor-quotas.html"
    },
    {
        "title": "Deploying the compute cluster",
        "content": "Deploying the compute cluster\nBefore creating a compute cluster, make sure the following requirements are met:\n\nThe traffic types VM private, VM public, Compute API, and VM backups are assigned to networks. The full recommended network configuration is described in \"Setting up networks for the compute cluster\" in the Administrator Guide.\nThe nodes to be added to the compute cluster are connected to these networks and to the same network with the VM public traffic type.\nThe nodes to be added to the compute cluster have the same CPU model (refer to \"Setting virtual machine CPU model\" in the Administrator Guide).\n(Recommended) High availability for the management node is enabled (refer to Enabling management node high availability).\n\nTo create the compute cluster, do the following:\n\nOn the Infrastructure > Networks screen, make sure that these traffic types are added to the networks you intend to use: VM private, VM public, Compute API, VM backups.\nOpen the Compute screen, and then click Create compute cluster.\n\nOn the Nodes step, select the nodes to add to the compute cluster. You can only select nodes with the Configured network state. Nodes in the management node high availability cluster are automatically selected to join the compute cluster. Then, click Next.\n\nOn the Physical network step, do the following:\n\nEnable or disable IP address management:\n\nWith IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.\nWith IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.\n\nIn any case, you will be able to manually assign static IP addresses from inside the VMs.\n\nProvide the required details for the physical network:\n\nSelect an infrastructure network to connect the physical network to.\nSelect the physical network type: select VLAN and specify a VLAN ID to create a VLAN-based network, or select Untagged to create a flat physical network.\nThe network MTU is set to 1500 by default. If required, you can adjust this value according to the MTU of the underlying network interface.\nIf you enabled IP address management, the subnet IP range in the CIDR format will be filled in automatically. Optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\nClick Next.\n\nThe selected physical network will appear in the list of compute networks on compute cluster\u00e2\u0080\u0099s Network tab. By default, it will be shared between all future projects. You can disable the network access on the network right pane later.\n\nIf you enabled IP address management, you will move on to the DHCP and DNS step, where you can configure the network settings for IP address management:\n\nEnable or disable the built-in DHCP server:\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\nOn the Add-on services step, enable the additional services that will be installed during the compute cluster deployment. You can also install these services later. Then, click Next.\n\nInstalling Kubernetes automatically installs the load balancer service as well.\n\nOn the Storage policy step, select a redundancy mode, storage tier, and failure domain for the default policy, which will be applied to uploaded images and base volumes created from these images. You can also use the default parameters, which include the first available storage tier, the host failure domain, and the best replication scheme allowed by the number of nodes in the storage cluster:\n\nThe 3 replicas mode is used if the storage cluster has three or more nodes.\nThe 2 replicas mode is used if the storage cluster has two nodes.\nThe No redundancy mode is used for a single-node deployment.\n\nTo discard your changes to the storage policy parameters and reset them to their defaults, click Reset to default parameters.\nThen, click Next.\n\nOn the Summary step, review the configuration, and then click Create cluster.\n\nYou can monitor compute cluster deployment on the Compute screen.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_quick_start_guide/deploying-the-compute-cluster.html"
    },
    {
        "title": "Changing network interface parameters",
        "content": "Changing network interface parameters\nChanging network interface configuration after deploying storage or compute services includes network migration of this interface.\nPrerequisites\n\nA network interface is configured, as described in Configuring node network interfaces.\n\nTo change network interface parameter\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface. \nOn the interface right pane, click Edit.\n\nIn the Edit network interface window, change the required network settings. For example, you can change the IP address or infrastructure network assignment.\n\nClick Save to apply your changes. \nIf you have already deployed storage or compute services, you will see the migration wizard. Wait until the new configuration is created, and then click Apply.\n\nCommand-line interface\nUse the following command:vinfra node iface set [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                      [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                      [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                      [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                      [--network <network> | --no-network] [--connected-mode | --datagram-mode]\r\n                      [--ifaces <ifaces>] [--bond-type <bond-type>] [--node <node>] <iface>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--no-network\n\nRemove a network from the interface\n--connected-mode\n\nEnable connected mode (InfiniBand interfaces only)\n--datagram-mode\n\nEnable datagram mode (InfiniBand interfaces only)\n--ifaces <ifaces>\n\nA comma-separated list of network interface names, for example, iface1,iface2,...,ifaceN\n--bond-type <bond-type>\n\nBond type (balance-rr, balance-xor, broadcast, 802.3ad, balance-tlb, balance-alb)\nBond type for an OVS interface (balance-tcp, active-backup)\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nFor example, to change the IP address of the eth1 network interface located on the node node002 to 192.168.128.91/24, run:# vinfra node iface set eth1 --node node002 --ipv4 192.168.128.91/24\r\n+----------------------------+-----------------------------------------------------------------------+\r\n| Field                      | Value                                                                 |\r\n+----------------------------+-----------------------------------------------------------------------+\r\n| configuration              | network_id: f50605a3-64f4-4f0c-b50e-9481ec221c72                      |\r\n| link                       | href: /api/v2/network/migration/ba7854ed-167e-4d6b-ab19-7244371a1b27/ |\r\n|                            | method: GET                                                           |\r\n|                            | rel: network-migration-details                                        |\r\n| operation                  | network-migration                                                     |\r\n| progress                   | 0.0                                                                   |\r\n| single_interface_migration | True                                                                  |\r\n| state                      | preparing                                                             |\r\n| task_id                    | ba7854ed-167e-4d6b-ab19-7244371a1b27                                  |\r\n| transitions                | 0                                                                     |\r\n+----------------------------+-----------------------------------------------------------------------+\nIf you have already deployed storage or compute services, you will see the output above. Wait until the new network configuration is tested, and then apply it:# vinfra cluster network migration show | state\r\n| state                      | test-passed                                  |\r\n# vinfra cluster network migration apply\n\nSee also\n\nChanging network configuration\n\nManaging network interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface set [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                      [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                      [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                      [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                      [--network <network> | --no-network] [--connected-mode | --datagram-mode]\r\n                      [--ifaces <ifaces>] [--bond-type <bond-type>] [--node <node>] <iface>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--no-network\n\nRemove a network from the interface\n--connected-mode\n\nEnable connected mode (InfiniBand interfaces only)\n--datagram-mode\n\nEnable datagram mode (InfiniBand interfaces only)\n--ifaces <ifaces>\n\nA comma-separated list of network interface names, for example, iface1,iface2,...,ifaceN\n--bond-type <bond-type>\n\n\nBond type (balance-rr, balance-xor, broadcast, 802.3ad, balance-tlb, balance-alb)\nBond type for an OVS interface (balance-tcp, active-backup)\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nFor example, to change the IP address of the eth1 network interface located on the node node002 to 192.168.128.91/24, run:# vinfra node iface set eth1 --node node002 --ipv4 192.168.128.91/24\r\n+----------------------------+-----------------------------------------------------------------------+\r\n| Field                      | Value                                                                 |\r\n+----------------------------+-----------------------------------------------------------------------+\r\n| configuration              | network_id: f50605a3-64f4-4f0c-b50e-9481ec221c72                      |\r\n| link                       | href: /api/v2/network/migration/ba7854ed-167e-4d6b-ab19-7244371a1b27/ |\r\n|                            | method: GET                                                           |\r\n|                            | rel: network-migration-details                                        |\r\n| operation                  | network-migration                                                     |\r\n| progress                   | 0.0                                                                   |\r\n| single_interface_migration | True                                                                  |\r\n| state                      | preparing                                                             |\r\n| task_id                    | ba7854ed-167e-4d6b-ab19-7244371a1b27                                  |\r\n| transitions                | 0                                                                     |\r\n+----------------------------+-----------------------------------------------------------------------+\nIf you have already deployed storage or compute services, you will see the output above. Wait until the new network configuration is tested, and then apply it:# vinfra cluster network migration show | state\r\n| state                      | test-passed                                  |\r\n# vinfra cluster network migration apply\n",
                "title": "To change network interface parameter"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface. \nOn the interface right pane, click Edit.\n\nIn the Edit network interface window, change the required network settings. For example, you can change the IP address or infrastructure network assignment.\n\n\n\n\n\nClick Save to apply your changes. \nIf you have already deployed storage or compute services, you will see the migration wizard. Wait until the new configuration is created, and then click Apply.\n\n\n\n\n\n",
                "title": "To change network interface parameter"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-network-interface-parameters.html"
    },
    {
        "title": "Preparing templates",
        "content": "Preparing templates\nYou may need to create a template in these cases:\n\nTo rescue a virtual machine\nTo create a VM accessible via SSH\nTo create a VM customizable with user data\n\nPreparation overview\n\nInstall cloud-init and OpenSSH Server in the virtual machine.\n\nEnable logging for virtual machines that will be created from the template.\n\nConvert the VM boot volume to the template, as described in Creating images from volumes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/preparing-templates.html"
    },
    {
        "title": "Troubleshooting",
        "content": "Troubleshooting\nTroubleshooting integration issues\nIf you have encountered an integration issue, log in to the CentOS 7 virtual machine and check the status of the cloudblue-fulfillments service. It should be enabled and active. For example:\n# systemctl status cloudblue-fulfillments\u00e2\u0097\u008f cloudblue-fulfillments.service - Connect to backend, fulfillments serviceLoaded: loaded (/usr/lib/systemd/system/cloudblue-fulfillments.service; enabled; vendor preset: disabled)Active: active (running) since Fri 2020-07-17 07:58:21 EDT; 10s ago\n\nFor the pay-as-you-go model, also check the cloudblue-usage service.\nThe service logs can be viewed by using the journalctl utility.\nTroubleshooting asset issues\nIf you have problems with assets  in the vendor portal, you can check the corresponding failed requests. Do the following:\n\nGo to the Requests tab on the asset page and click the request with the Failed status. \n\nOn the request details page, check the Notes panel for the problem root cause. For example:",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/troubleshooting.html"
    },
    {
        "title": "Listing load balancers",
        "content": "Listing load balancersGET /v2/lbaas/loadbalancers\r\n\nList all load balancers in the specified project.\nAdministrative users can specify a project ID that is different than their own\r\nto list load balancers for other projects.\nSource: https://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=list-load-balancers-detail#list-load-balancers\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id (Optional)\nquery\nstring\nThe ID of the project to query.\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9888/v2/lbaas/loadbalancers\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nloadbalancers\n\nbody\narray\nA list of loadbalancer objects.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\nflavor_id\n\nbody\nuuid\nThe ID of the flavor.\n\nid\n\nbody\nuuid\nThe ID of the load balancer.\n\nlisteners\n\nbody\narray\nThe associated listener IDs, if any.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\noperating_status\n\nbody\nstring\nThe operating status of the resource.\n\npools\n\nbody\narray\nThe associated pool IDs, if any.\n\nproject_id\n\nbody\nstring\nThe ID of the project owning this resource.\n\nprovider\n\nbody\nstring\nProvider name for the load balancer.\n\nprovisioning_status\n\nbody\nstring\nThe provisioning status of the resource.\n\ntags\n\nbody\nlist\n\nA list of simple strings assigned to the resource.\nNew in version 2.5\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvip_address\n\nbody\nstring\nThe IP address of the Virtual IP (VIP).\n\nvip_network_id\n\nbody\nuuid\nThe ID of the network for the Virtual IP (VIP).\n\nvip_port_id\n\nbody\nuuid\nThe ID of the Virtual IP (VIP) port.\n\nvip_qos_policy_id\n\nbody\nuuid\nThe ID of the QoS Policy which will apply to the Virtual IP (VIP).\n\nvip_subnet_id\n\nbody\nuuid\nThe ID of the subnet for the Virtual IP (VIP).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.\n\nExample{\r\n  \"loadbalancer\": {\r\n    \"provider\": \"amphora\",\r\n    \"description\": \"\",\r\n    \"admin_state_up\": true,\r\n    \"pools\": [\r\n      {\r\n        \"id\": \"e7ac20f9-a4f9-4bf7-9333-ae96e1d34e0c\"\r\n      }\r\n    ],\r\n    \"created_at\": \"2020-03-19T18:04:56.378183\",\r\n    \"provisioning_status\": \"ACTIVE\",\r\n    \"updated_at\": \"2020-03-19T18:09:33.467099\",\r\n    \"vip_qos_policy_id\": null,\r\n    \"vip_network_id\": \"15f7dc0a-712c-422f-bfd3-31dc351d9026\",\r\n    \"listeners\": [\r\n      {\r\n        \"id\": \"ab110967-fd83-4a41-b3c5-4083395bdc86\"\r\n      }\r\n    ],\r\n    \"tags\": [],\r\n    \"vip_port_id\": \"c39af70f-a725-4b2b-b876-16ad636868ac\",\r\n    \"flavor_id\": null,\r\n    \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"vip_address\": \"192.168.10.46\",\r\n    \"vip_subnet_id\": \"fd2de462-f93b-43a6-9b5c-254f1e690bf1\",\r\n    \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"id\": \"601be015-0753-4221-931c-d26d81248551\",\r\n    \"operating_status\": \"ONLINE\",\r\n    \"name\": \"lb1\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-load-balancers.html"
    },
    {
        "title": "2. Installation Requirements\u00c2\u00b6",
        "content": "2. Installation Requirements | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n2. Installation Requirements\u00c2\u00b6\n\nVirtuozzo Hybrid Infrastructure version 4.7.1 (50).\nGolden image with Hystax Acura. Provided on request - contact your account manager or email migrations@virtuozzo.com\nA Hystax Acura Solution License. Provided on request - contact your account manager or email migrations@virtuozzo.com\nResources to launch a virtual machine with 8 vCPUs, 16 GB RAM, 100 GB disk created from the Hystax Acura Golden image.\nResources to launch a VM with 2 vCPUs, 4 GB RAM, 20 GB disk for the Hystax Cloud Agent. Created in each target / failover Virtuozzo Hybrid Infrastructure project.\nSMTP server with TLS/SSL encryption.\n\nSecurity groups allowing the following traffic:\n\nHystax Acura host:\nIngress - tcp/443\nIngress - tcp/4443\nIngress - udp/12201\n\nHystax Cloud Agent (spawned automatically in the Target Project):\nIngress - tcp/80\nIngress - tcp/3260\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/installation-requirements.html"
    },
    {
        "title": "GET service ostor-quotas",
        "content": "GET service ostor-quotas\nDescription\nLists information about quotas on storage usage for the specified user/bucket or for all users/buckets.\nRequests\nSyntaxGET /?ostor-quotas&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-quotas&bucket=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-quotas&default=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nGET service ostor-limits parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nYes*\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes*\n\ndefault\n\nShows the default value for quotas. If set to user, shows the default quotas for all users. If set to bucket, shows the default quotas for all buckets.\nType: string.\nDefault value: none.\n\nNo\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nA JSON dictionary with information about limits for a user or bucket in the following format:{\r\n\"version\" : \"<quota_version>\",\r\n\"type\" : \"{0|1}\",\r\n\"size\" : \"<usage_limit_value_in_bytes>\"\r\n}\nFor the type parameter, 0 means \"user\" and 1 means \"bucket\".\nFor the size parameter, zero value means \u00e2\u0080\u009cunlimited\u00e2\u0080\u009d.\nErrors\nReturns Error Code 400 if multiple parameters are set at once.\nExamples\nSample request #1\nReturns information about quotas for the user with the email user1@email.com.GET /?ostor-quotas&emailAddress=user1@email.com HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:53:41 GMT\r\nAuthorization: <authorization_string>\nSample response #1HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 20:53:46 GMT\r\nContent-type : application/json\r\n{\r\n\"version\" : \"1\",\r\n\"type\" : \"0\",\r\n\"size\" : \"1024\"\r\n}\nSample request #2\nReturns information about quotas for the bucket bucket1.GET /?ostor-quotas&bucket=bucket1 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:54:34 GMT\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : closed\r\nx-amz-request-id : 80000000000000030003c6b538eedd95\r\nDate: Thu, 09 Sep 2021 20:54:37 GMT\r\nContent-type : application/json\r\n{\r\n\"version\" : \"1\",\r\n\"type\" : \"1\",\r\n\"size\" : \"256\"\r\n}\nSample request #3\nReturns information about the default user quotas.GET /?ostor-quotas&default=user HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:57:48 GMT\r\nAuthorization: <authorization_string>\nSample response #3HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 20:57:51 GMT\r\nContent-type : application/json\r\n{\r\n\"version\" : \"1\",\r\n\"type\" : \"0\",\r\n\"size\" : \"1024\"\r\n}\nSample request #4\nReturns information about the default bucket quotas.GET /?ostor-quotas&default=bucket HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 20:58:05 GMT\r\nAuthorization: <authorization_string>\nSample response #4HTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : closed\r\nx-amz-request-id : 80000000000000030003c6b538eedd95\r\nDate: Thu, 09 Sep 2021 20:58:09 GMT\r\nContent-type : application/json\r\n{\r\n\"version\" : \"1\",\r\n\"type\" : \"1\",\r\n\"size\" : \"256\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/get-service-ostor-quotas.html"
    },
    {
        "title": "Defining object storage classes",
        "content": "Defining object storage classes\nYou can use up to four object storage classes for applications with different performance and redundancy requirements. The first storage class is set automatically during the S3 cluster creation. The other three classes you can define manually by using the ostor-ctl set-storage-class command.\nOnce a storage class is created, use the ostor-ctl cfg-storage command to change its redundancy settings. With this command, you can modify all storage classes, including the first one. Note that the redundancy scheme can only be changed if you use redundancy by replication. With redundancy by erasure coding, however, changing the redundancy scheme is disabled.\nLimitations\n\nChanging the encoding redundancy scheme is disabled, because it may decrease cluster performance. Re-encoding demands a significant amount of cluster resources for a long period of time. If you still want to change the redundancy scheme, contact the technical support team.\n\nPrerequisites\n\nThe S3 cluster is created, as described in Creating the S3 cluster.\n\nTo create a storage class\n\nObtain the password for your storage cluster. For example:# vinfra cluster password show\r\n+----------+---------+\r\n| Field    | Value   |\r\n+----------+---------+\r\n| id       | 1       |\r\n| name     | cluster |\r\n| password | W3HMNq  |\r\n+----------+---------+\r\n\n\nFind out the ID of the object storage volume. For example:# ostor-ctl get-config -V\r\nVOL_ID             TYPE     STATE\r\n0100000000000002   OBJ     READY\n\nDefine a storage class specifying its numeric ID, the number of object servers it will include, and the required redundancy settings. When prompted, enter the password obtained in step 1. For example, to create the storage class 1 with 2 object servers  and the redundancy scheme of 2 replicas for tier 1, run:# ostor-ctl set-storage-class -s /mnt/vstorage/vols/ostor/ -V 0100000000000002 \\\r\n-C 1 -O 2 --vstorage-attr \"replicas=2:1 tier=1\"\r\nPlease enter password for 'ostor-private.svc.vstoragedomain.':\r\nStorage 1 class is successfully assigned to services\nThis command requires the following parameters:\n\n-s, --storage <path>\nThe path to the object storage directory\n-V, --vol <id>\nThe volume ID obtained in step 2\n-C, --storage-class {1,2,3}\nThe storage class ID. Can accept the following values: 1, 2, 3. \n-O, --os-count <number>\nThe number of object servers to create\n--vstorage-attr <attribute>\n\nRedundancy settings, where you can specify the desired tier, failure domain, and data redundancy scheme. Refer to the vstorage set-attr help message.\n\nThe S3 APIs that use the x-amz-storage-class header can specify one of the following storage classes: standard, type_1, type_2, or type_3.\n\nCheck that the new storage class is set. For example, for the storage class 1, run:# vstorage get-attr /mnt/vstorage/vols/ostor/0100000000000002/services/sc1/\r\nconnected to MDS#1\r\nPath: 'vstorage://hciHeat/vols/ostor/0100000000000002/services/sc1'\r\nAttributes:\r\n  directory\r\n  client-ssd-cache=1\r\n  replicas=2:1\r\n  failure-domain=host\r\n  failure-domain.int=1\r\n  tier=1\r\n  chunk-size=268435456\r\n\n\nTo change redundancy settings of a storage class\nUse the ostor-ctl cfg-storage command. For example:# ostor-ctl cfg-storage -r /mnt/vstorage/vols/ostor/0100000000000002/ -C 1 \\\r\n--vstorage-attr \"replicas=3:2 tier=0\"\nThis command requires the following parameters:\n\n-r, --root <path>\nThe path to the initialized shared storage\n-C, --storage-class {0,1,2,3}\nThe storage class ID. Can accept the following values: 0, 1, 2, 3. The default value is 0.\n--vstorage-attr <attributes>\n\nRedundancy settings, where you can specify the desired tier, failure domain, and data redundancy scheme. Refer to the vstorage set-attr help message.\n\nSee also\n\nSupported Amazon S3 features\n\nManaging S3 users\n\nManaging S3 buckets\n\nMonitoring object storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/defining-object-storage-classes.html"
    },
    {
        "title": "PUT service replication",
        "content": "PUT service replication\nDescription\nSets replication configuration for the specified bucket.\nRequests\nSyntaxPUT /?replication HTTP/1.1\r\nHost: <bucket>.<host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nPUT service replication parameters\n\nParameter\t\nDescription\t\nRequired\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes\n\nuser_id\n\nID of the user that is used to replicate objects on your behalf.\nType: string.\nDefault: none.\n\nYes\n\ndestination_bucket\n\nThe name of the bucket where you want to store the results.\nType: string.\nDefault: none.\n\nYes\n\nBody\nAn XML replication configuration in the following format:<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<ReplicationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\r\n   <Role>arn:aws:iam::<user_id>:role/s3-replication-role</Role>\r\n   <Rule>\r\n      <Status>Enabled|Disabled</Status>\r\n      <Priority>1</Priority>\r\n      <DeleteMarkerReplication>\r\n         <Status>Enabled|Disabled</Status>\r\n      </DeleteMarkerReplication>\r\n      <Filter>\r\n         <Prefix />\r\n      </Filter>\r\n      <Destination>\r\n         <Bucket>arn:aws:s3:::<destination_bucket></Bucket>\r\n      </Destination>\r\n   </Rule>\r\n</ReplicationConfiguration>\nHeaders\n\nHeader\nDescription\t\n\nx-amz-geo-endpoint\n\nEndpoint of the remote region where to replicate objects to.\n\nx-amz-geo-access-key\n\nAccess key of a user of the remote region used to replicate objects.\n\nx-amz-geo-access-secret\n\nAccess secret of a user of the remote region used to replicate objects.\n\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nExamples\nSample request\nSets replication configuration for the bucket.\u00a0test.PUT/?replication HTTP/1.1\r\nHost: test.s3.example.com\r\nDate: Tu, 18 Jan 2021 14:08:55 GMT\r\nAuthorization: <authorization_string>\r\n<ReplicationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\r\n   <Role>arn:aws:iam::850b4943d62191a5:role/s3-replication-role</Role>\r\n   <Rule>\r\n      <Status>Enabled</Status>\r\n      <Priority>1</Priority>\r\n      <DeleteMarkerReplication>\r\n         <Status>Disabled</Status>\r\n      </DeleteMarkerReplication>\r\n      <Filter>\r\n         <Prefix />\r\n      </Filter>\r\n      <Destination>\r\n         <Bucket>arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET2</Bucket>\r\n      </Destination>\r\n   </Rule>\r\n</ReplicationConfiguration>\nSample responseHTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Tu, 21 Jan 2021 14:08:56 GMT",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/put-service-replication.html"
    },
    {
        "title": "Using external Prometheus for monitoring",
        "content": "Using external Prometheus for monitoring\nYou can use Prometheus federation to collect metrics from the built-in Prometheus server and store them on an external server. To configure federation, install an external Prometheus server, as described in the official documentation, and then connect it to your cluster via the open Prometheus API port.\nTo open a port for the Prometheus API\n\nOn the Infrastructure > Networks screen, click Edit and then Create traffic type.\n\nIn the Create traffic type window, specify a custom name in the Name field and 9090 in the Port field. Then, click Create.\n\nClick Assign to networks next to the Custom traffic types section, and then add the created traffic type to your public network by selecting the corresponding check box.\nClick Save to apply the changes.\n\nYou can now connect to the built-in Prometheus server at http://<admin_panel_IP_address>:9090.\nTo connect your cluster to the external Prometheus\nOn the external Prometheus server, create the federation configuration file. For example:scrape_configs:\r\n  - job_name: 'federate'\r\n    scrape_interval: 15s\r\n\r\n    honor_labels: true\r\n    metrics_path: '/federate'\r\n\r\n    params:\r\n      'match[]':\r\n        - '{job=\"ostor\"}'\r\n        - '{__name__=~\"job:.*\"}'\r\n\r\n    static_configs:\r\n      - targets:\r\n        - '<admin_panel_IP_address>:9090'\nwhere:\n\nmetrics_path is the  endpoint of the source Prometheus server to collect metrics from. /federate is the default endpoint for retrieving current values for selected time series.\nhonor_labels is the scape option that allows (false) or prohibits (true) overwriting any labels exposed by the source Prometheus server.\n\nmatch[] defines time series to be scraped. You need to specify at least one match[] URL parameter and an instant vector selector like up or {job=\"ostor\"} for each match[] argument.\nIn the given example, the external Prometheus server will collect any series with the label job=\"ostor\" or a metric name starting with job:.\n\ntargets points to the source Prometheus server.\n\nSee also\n\nUsing built-in Prometheus for monitoring\n\nConfiguring retention policy for Prometheus metrics\n\nPrometheus metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-external-prometheus.html"
    },
    {
        "title": "5.1. Security Groups Requirements\u00c2\u00b6",
        "content": "5.1. Security Groups Requirements | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n5.1. Security Groups Requirements\u00c2\u00b6\nBefore creating your Connection Broker and Leostream Gateway instances, ensure that you have the appropriate security groups configured in Virtuozzo Hybrid Infrastructure. Leostream requires the following ports be open for incoming traffic to the specified component. Consider three separate security groups:\n\nConnection Broker\nLeostream Gateway\nVDI instances\n\nPort\nRequired By\nPurpose\n\n22\nConnection Broker, Leostream Gateway\nFor SSH access to the Connection Broker or Leostream Gateway, if required.\n\n443\nConnection Broker, Leostream Gateway\nFor access to the Connection Broker Web interface, and communications from the Leostream Agents and Leostream Connect.\nOn the Leostream Gateway, for communication from Leostream Connect and to use the Leostream HTML5 viewer.\n\n20001-22000\nLeostream Gateway\nThe Leostream Gateway uses this default port range to forward display protocol traffic from the user\u00e2\u0080\u0099s client device to an instance isolated in a private VHI network. You may optionally change this port range using the Leostream Gateway CLI.\nNOTE: You do not need to open this range if you use the display protocol port for forwarding desktop connection traffic. For that scenario, open the display protocol port in the Leostream Gateway security group, instead.\n\n8080\nVDI instances\nPort for communications from the Connection Broker to the Leostream Agent.\n* The Leostream Agent port may be changed using the Leostream Agent Control Panel dialog. If you change the default Leostream Agent port, ensure that you open the associated port in the security group\n\n3389**\nVDI instances, Leostream Gateway\nFor RDP access to the VDI/DaaS instances\n** This port is dependent on the display protocol you plan to use. If you use a display protocol other than RDP, ensure that you open the ports required by that display protocol.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/installing-leostream/security-groups-requirements.html"
    },
    {
        "title": "Performance issues and symptoms",
        "content": "Performance issues and symptoms\nDisks IOPS saturation\nA common root cause of performance issues is the disk throughput limit. To understand if a disk has reached its limit, you can check the state of its I/O queue. If this queue is constantly full, this means that the disk is at its peak performance capacity. To investigate the state of the I/O queue for all disks, use the following command:# iostat -x 10\nThe command output will be similar to this:avg-cpu:  %user   %nice %system %iowait  %steal   %idle\r\n           4.08    0.00    1.11    0.03    0.03   94.76\r\n\r\nDevice:  rrqm/s  wrqm/s   r/s   w/s  rkB/s  wkB/s ... %util\r\nsda        0.00    8.30  0.00  3.20   0.00  46.40 ...  0.20\r\nsdb        0.00    0.00  0.00  0.00   0.00   0.00 ...  0.00\r\nsdc        0.00    0.00  0.00  0.00   0.00   0.00 ...  0.00\r\nscd0       0.00    0.00  0.00  0.00   0.00   0.00 ...  0.00\nYou need to pay attention to the following metrics:\n\n%iowait is the percentage of time the CPU was idle while requests were in the I/O queue. If this value is well above zero, this might mean that the node I/O is constrained by the disks speed.\n%idle is the percentage of time the CPU was idle while there were no requests in the I/O queue. If this value is close to zero, this means that the node I/O is constrained by the CPU speed.\n%util is the percentage of time the device I/O queue was not empty. If this value is close to 100%, this means that the disk throughput is reaching its limit.\n\niSCSI LUNs performance\niSCSI LUNs served via Virtuozzo Hybrid Infrastructure may experience reduced performance, especially when accessing data with a high number of threads. In this case, it is generally preferable to split the load across multiple smaller iSCSI LUNs, or if possible, avoid iSCSI by accessing storage devices directly. If it is not possible to reduce the size of LUNs, you can consider deploying an LVM RAID0 group over multiple smaller LUNs.\nJournal size and location\nIf your cluster was deployed from an old product version, it is possible that the journal configuration is not optimal. Specifically, if the journal is configured as \u00e2\u0080\u009cinner cache,\u00e2\u0080\u009d that is, stored on the same physical device as data, the recommended size is 256 MB.\nAlso, consider moving the journals to a faster device such as an SSD or NVMe, if it is applicable to your workload. For more details on storage cache configuration, refer to Cache configuration.\nMake sure the journal settings are the same for all journals in the same tier.\nTo check the current size and location of journals, run the following command and specify the desired disk:# vinfra node disk show <DISK>\nFor example:# vinfra node disk show sdc\nThe command output will be similar to this:| service_params | journal_data_size: 270532608\r\n|                | journal_disk_id: 5EE99654-4D5E-4E00-8AF6-7E83244C5E6B\r\n|                | journal_path: /vstorage/94aebe68/journal/journal-cs-b8efe751-96a6ff460b80\r\n|                | journal_type: inner_cache\nThe journal size and location will be reported as highlighted in this example.\nRAM and swap usage\nThough the system may operate at nearly 100 percent RAM consumption, it should not aggressively swap virtual memory to and from a disk.\nYou can check the state of the swap space by running:# free -hm\r\n            total      used      free      shared  buff/cache   available\r\nMem:         7,7G      2,2G      498M        3,7G        5,0G        1,5G\r\nSwap:        3,9G      352M      3,6G\nIn the command output, the Swap row shows the current swap space size. If the reported size is zero, it means swapping is disabled, which may be done intentionally in some configurations.\nYou can also check the use of swap space by running:# vmstat 1\r\nprocs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------\r\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\r\n 3  1 244208  10312   1552  62636    4   23    98   249   44  304 28  3 68  1  0\r\n 0  2 244920   6852   1844  67284    0  544  5248   544  236 1655  4  6  0 90  0\r\n 1  2 256556   7468   1892  69356    0 3404  6048  3448  290 2604  5 12  0 83  0\r\n 0  2 263832   8416   1952  71028    0 3788  2792  3788  140 2926 12 14  0 74  0\r\n 0  3 274492   7704   1964  73064    0 4444  2812  5840  295 4201  8 22  0 69  0\r\n\nIn the command output, the si and so columns show the amount of memory swapped from and to a disk, in KB/s. Swap usage may be considered acceptable as long as it well below the device maximum throughput, that is, it does not interfere with the device performance.\nS3 service performance\nS3 load balancing\nWe recommend using load balancing at all times. The only scenario that does not benefit from load balancing is when there is a single client. For recommendations on setting up load balancing, refer to the Administrator Guide.\nS3 gateways\nBy default, the S3 service runs with four S3 gateways per node. However, you can increase the number of S3 gateways to improve the overall performance if you notice the following signs:\n\nThe CPU usage of the S3 gateway is near 100 percent.\nThe latency of the S3 service is very high (for example, the average latency of more than two seconds).\n\nYou can change the number of S3 gateways per node by using one of the following commands:\n\nTo set the number of S3 gateways on all nodes in the S3 cluster:vinfra service s3 cluster change --s3gw-count <count>\n\n--s3gw-count <count>\n\nNumber of S3 gateways per node\n\nFor example, to increase the number of S3 gateways per node to 5, run:# vinfra service s3 cluster change --s3gw-count 5\n\nTo set the number of S3 gateways on a particular S3 node:vinfra service s3 node change --nodes <node_id> --s3gw-count <count>\n\n--nodes <node_id>\n\nA comma-separated list of node hostnames or IDs\n--s3gw-count <count>\n\nNumber of S3 gateways\n\nFor example, to reduce the number of S3 gateways on the node node003 to 3, run:# vinfra service s3 node change --nodes node003 --s3gw-count 3\n\nWhen removing a gateway, keep in mind that all ongoing connections to this gateway will be dropped and all ongoing operations may result in a connection error on the client side.\nSee also\n\nPerformance-related system alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/performance-issues-and-symptoms.html"
    },
    {
        "title": "Showing SSH key details",
        "content": "Showing SSH key detailsGET /os-keypairs/{keypair_name}\r\n\nShows the details of a key pair with the specified name that is associated with the account.\nSource: https://docs.openstack.org/api-ref/compute/index.html?expanded=show-keypair-details-detail#show-keypair-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nkeypair_name\n\npath\nstring\nThe key pair name.\n\nuser_id (Optional)\nbody\nstring\n\nThe user ID for a key pair. This allows administrative users to\r\nupload keys for other users than themselves.\nNew in version 2.10\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/os-keypairs/key1\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nkeypair\n\nbody\nobject\nThe keypair object.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted\n\nbody\nboolean\nA boolean indicates whether this key pair is deleted or not.\r\nThe value is always false (not deleted).\n\ndeleted_at\n\nbody\nnone\nIt is always null.\n\nid\n\nbody\ninteger\nThe key pair ID.\n\nname\n\nbody\nstring\nA name for the key pair which will be used to reference it later.\n\npublic_key\n\nbody\nstring\nThe key pair public key.\n\nfingerprint\n\nbody\nstring\nThe fingerprint for the key pair.\n\nupdated_at\n\nbody\nnone\nIt is always null.\n\nuser_id\n\nbody\nstring\nThe user ID for a key pair.\n\ntype\n\nbody\nstring\n\nThe type of the key pair. Allowed values are ssh or x509.\nNew in version 2.2\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"keypair\": {\r\n    \"public_key\": \"ssh-rsa AAAA<...> VSTOR-KEY-DESC:Key description\",\r\n    \"user_id\": \"eb481bff7b7c4ec6a686646957d8064b\",\r\n    \"name\": \"key1\",\r\n    \"deleted\": false,\r\n    \"created_at\": \"2020-01-31T12:56:51.515306\",\r\n    \"updated_at\": null,\r\n    \"fingerprint\": \"36:2e:c4:95:95:1a:4d:9d:81:82:3a:da:46:93:e1:1d\",\r\n    \"deleted_at\": null,\r\n    \"id\": 1\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-ssh-key-details.html"
    },
    {
        "title": "Creating domain groups",
        "content": "Creating domain groups\nLimitations\n\nYou can only create domain groups with the role System administrator within the Default domain. For details, refer to Managing admin panel users.\n\nPrerequisites\n\nA clear understanding of user roles described in Multitenancy.\n\nTo create a domain group\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click a domain within which a domain group will be created.\nGo to the Domain groups tab, and then click Create domain group.\n\nIn the Create domain group window, specify the group name and optionally description. The group name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nSelect the user role:\n\nTo create a group of domain administrators\n\nSelect the Domain administrator role.\n\nEnable Image uploading to allow the user to upload images and configure this permission for other domain users.\n\nEnable Project and quota management to allow the user to manage projects and quotas, as well as configure this permission for other domain administrators.\n\nTo create a group of system administrators\n\nSelect the System administrator role.\n\nSelect the permissions to be granted to the user account from the System permission set section:\n\nFull (System administrator): has all permissions and can perform all management operations, including creating projects and managing other users.\nCompute: can create and manage the compute cluster.\nISCSI: can create and manage iSCSI targets, LUNs, and CHAP users.\nS3: can create and manage the S3 cluster.\nABGW: can create and manage the Backup Gateway cluster.\nNFS: can create and manage NFS shares and exports.\nCluster: can create the storage cluster, join nodes to it, and manage (assign and release) disks.\nNetwork: can modify networks and traffic types.\nUpdate: can install updates.\nSSH: can add and remove SSH keys for cluster nodes access.\n\nThe view permission is always enabled.\n\nEnable the full Domain permissions set to allow the user to manage virtual objects in all projects within the Default domain and other users in the self-service panel.\n\nEnable Image uploading to allow the user to upload images.\n\nTo create a group of project administrators\n\nSelect the Project member role.\n\nEnable Image uploading to allow the user to upload images.\n\nClick Manage in the Projects section and select a project to assign the user to. Then, click Save.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra domain group create [--description <description>] [--assign <project> <role>]\r\n                           [--domain-permissions <domain_permissions>]\r\n                           [--system-permissions <system_permissions>]\r\n                           --domain <domain> <name>\n\n--description <description>\n\nGroup description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--assign <project> <role>\n\nAssign a group to a project with one or more permission sets. Specify this option multiple times to assign the group to multiple projects.\n\n<project>: project ID or name\n<role>: group role in the project (project_admin)\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--system-permissions <system_permissions>\n\nA comma-separated list of system permissions. View the list of available system permissions using vinfra domain user list-available-roles | grep system.\n--domain <domain>\n\nDomain name or ID\n<name>\n\nGroup name\n\nExample 1. To create a group of domain administrators called domain_admins within the domain mydomain, run:# vinfra domain group create domain_admins --domain mydomain --domain-permissions domain_admin\nExample 2. To create a group of system administrators called sys_admins within the domain Default, to manage the compute cluster, run:# vinfra domain group create mysysadmin --domain Default --system-permissions compute\nExample 3. To create a group of project members called users for the project myproject within the domain mydomain and grant this user group the permission to upload images, run:# vinfra domain group create myusers --domain mydomain --assign myproject project_admin --domain-permissions image_upload\nThe created groups will appear in the vinfra domain group list output:# vinfra domain group list --domain mydomain\r\n+-------------+---------------+-------------+--------------------+---------------------------+\r\n| id          | name          | description | domain_permissions | assigned_projects         |\r\n+-------------+---------------+-------------+--------------------+---------------------------+\r\n| 1670fbc6<\u00e2\u0080\u00a6> | domain_admins |             | - domain_admin     | []                        |\r\n| d2fb8a2d<\u00e2\u0080\u00a6> | myusers       |             | - image_upload     | - project_id: db49fd71<\u00e2\u0080\u00a6> |\r\n|             |               |             |                    |   role: project_admin     |\r\n+-------------+---------------+-------------+--------------------+---------------------------+\n\nWhat's next\n\nManaging user assignment to domain groups\n\nEditing and deleting domain groups\n\nSee also\n\nAdding  identity providers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain group create [--description <description>] [--assign <project> <role>]\r\n                           [--domain-permissions <domain_permissions>]\r\n                           [--system-permissions <system_permissions>]\r\n                           --domain <domain> <name>\n\n--description <description>\n\n\nGroup description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--assign <project> <role>\n\n\nAssign a group to a project with one or more permission sets. Specify this option multiple times to assign the group to multiple projects.\n\n<project>: project ID or name\n<role>: group role in the project (project_admin)\n\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--system-permissions <system_permissions>\n\nA comma-separated list of system permissions. View the list of available system permissions using vinfra domain user list-available-roles | grep system.\n--domain <domain>\n\nDomain name or ID\n<name>\n\nGroup name\n\nExample 1. To create a group of domain administrators called domain_admins within the domain mydomain, run:# vinfra domain group create domain_admins --domain mydomain --domain-permissions domain_admin\nExample 2. To create a group of system administrators called sys_admins within the domain Default, to manage the compute cluster, run:# vinfra domain group create mysysadmin --domain Default --system-permissions compute\nExample 3. To create a group of project members called users for the project myproject within the domain mydomain and grant this user group the permission to upload images, run:# vinfra domain group create myusers --domain mydomain --assign myproject project_admin --domain-permissions image_upload\nThe created groups will appear in the vinfra domain group list output:# vinfra domain group list --domain mydomain\r\n+-------------+---------------+-------------+--------------------+---------------------------+\r\n| id          | name          | description | domain_permissions | assigned_projects         |\r\n+-------------+---------------+-------------+--------------------+---------------------------+\r\n| 1670fbc6<\u00e2\u0080\u00a6> | domain_admins |             | - domain_admin     | []                        |\r\n| d2fb8a2d<\u00e2\u0080\u00a6> | myusers       |             | - image_upload     | - project_id: db49fd71<\u00e2\u0080\u00a6> |\r\n|             |               |             |                    |   role: project_admin     |\r\n+-------------+---------------+-------------+--------------------+---------------------------+\n",
                "title": "To create a domain group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click a domain within which a domain group will be created.\nGo to the Domain groups tab, and then click Create domain group.\n\nIn the Create domain group window, specify the group name and optionally description. The group name must be unique within a domain.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\nSelect the user role:\n\n\nTo create a group of domain administrators\n\n\nSelect the Domain administrator role.\n\nEnable Image uploading to allow the user to upload images and configure this permission for other domain users.\n\n\nEnable Project and quota management to allow the user to manage projects and quotas, as well as configure this permission for other domain administrators.\n\n\n\n\n\n\n\n\n\n\nTo create a group of system administrators\n\n\nSelect the System administrator role.\n\nSelect the permissions to be granted to the user account from the System permission set section:\n\nFull (System administrator): has all permissions and can perform all management operations, including creating projects and managing other users.\nCompute: can create and manage the compute cluster.\nISCSI: can create and manage iSCSI targets, LUNs, and CHAP users.\nS3: can create and manage the S3 cluster.\nABGW: can create and manage the Backup Gateway cluster.\nNFS: can create and manage NFS shares and exports.\nCluster: can create the storage cluster, join nodes to it, and manage (assign and release) disks.\nNetwork: can modify networks and traffic types.\nUpdate: can install updates.\nSSH: can add and remove SSH keys for cluster nodes access.\n\n\nThe view permission is always enabled.\n\n\n\nEnable the full Domain permissions set to allow the user to manage virtual objects in all projects within the Default domain and other users in the self-service panel.\n\n\nEnable Image uploading to allow the user to upload images.\n\n\n\n\n\n\n\n\n\n\nTo create a group of project administrators\n\n\nSelect the Project member role.\n\nEnable Image uploading to allow the user to upload images.\n\nClick Manage in the Projects section and select a project to assign the user to. Then, click Save.\n\n\n\n\n\n\n\n\n\n\nClick Create.\n\n",
                "title": "To create a domain group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-domain-groups.html"
    },
    {
        "title": "About Acronis Backup Storage",
        "content": "About Acronis Backup Storage\nBackup storage uses Backup Gateway as a storage access point. It is intended for service providers who use Acronis Cyber Protect Cloud and end customers who use Acronis Cyber Protect. \nBackup storage enables a service provider to easily configure storage for the proprietary deduplication-friendly data format used by Acronis. In addition,  the backup storage data can be geo-replicated.\nBackup storage supports the following backup destinations:\n\nVirtuozzo Hybrid Infrastructure storage clusters with erasure coding providing for data redundancy\nNFS shares\nPublic clouds, including a number of S3 solutions, as well as Microsoft Azure, OpenStack Swift, and Google Cloud Platform\n\nWhile your choice should depend on the scenario and requirements, it is recommended to keep Acronis backup data in the Virtuozzo Hybrid Infrastructure local storage cluster. In this case, you can have the best performance due to WAN optimizations and data locality. Keeping backups in an NFS share or a public cloud implies the unavoidable data transfer and other overhead, which reduces overall performance. Besides, with external backup destinations, redundancy has to be provided by the external storage. Backup storage does not provide data redundancy or perform data deduplication itself.\nBackup storage architecture\nBackup Gateway, the backup storage access point, runs as a  service on the Virtuozzo Hybrid Infrastructure nodes. It is recommended to deploy it on two or more nodes for high availability.\n\nSee also\n\nProvisioning Acronis Backup Storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/about-backup-storage.html"
    },
    {
        "title": "Cache configuration",
        "content": "Cache configuration\nSupported device types\nCurrently supported drives include HDD, SSD, and NVMe devices. Their characteristics are described in the table below.\n\nType\nCost\nPerformance\nInterface and form-factor\n\nHard disk drives\r\n(HDD)\nLow\n\nUp to 200 MB/s\nTens/hundreds IOPS\n\nSAS or SATA\n\nSolid-state drives (SSD)\nAverage\n\nUp to 600 MB/s\nTens of thousands IOPS\n\nSAS or SATA\n\nNon-volatile memory express (NVMe)\nHigh\n\n\tFrom 1 to 10 GB/s\nHundreds of thousands IOPS\n\n2.5\" U.2, PCIe Add-In-Card (AIC), or M.2\n\nPMem or NVRAM devices are not officially supported.\n\nThe amount and type of cache devices supported in your cluster should be checked on each cluster node. In order to provide performance benefits, devices that provide acceleration must be faster than the underlying devices in terms of throughput, latency, or IOPS. For this reason, the possible combinations of cache and capacity devices are generally the following:\n\nCache devices configured in RAID1 mirroring are not officially supported.\n\nIt is recommended that all capacity devices in the same storage tier should be identical in terms of technology and size. Otherwise, there may be unpredictable performance and behavior in case of a hardware failure. Moreover, all cluster nodes should offer the same amount of storage. If this requirement is not met, the storage space in the cluster will be limited by the smallest node.\nA similar recommendation applies to cache devices. As the writing speed is constrained by the slowest device in the cluster, we strongly recommend using cache devices of the same technology and size.\nChoosing a cache device\nAs all the data ingested in the system goes through cache devices, the choice of a cache device should be based not only on speed, but also on device endurance. Device endurance is measured in two ways:\n\nDrive Writes per Day (DWPD) measures the number of times the device can be completely overwritten each day, to reach the expected device end-of-life (usually five years).\nTerabytes Written (TBW) measures the expected amount of data that can be written before the device fails.\n\nBoth parameters are equivalent and should be carefully evaluated. For example, you have a 1-TB flash drive with 1 DPWD, that means you can write 1 TB into it every day over its lifetime. If its warranty period is five years, that works out to 1 TB per day * 365 days/year * 5 years = 1825 TB of cumulative writes, after which the drive usually will have to be replaced. Thus, the drive\u00e2\u0080\u0099s TBW will be 1825.\nThe DWPD of a typical consumer-grade SSD drive can be as low as 0.1, while a high-end datacenter-grade flash drive can have up to 60 DWPD. For a cache device, the recommended minimum is 10 DWPD.\nAnother parameter to consider is power loss protection of the device. Some consumer-grade flash drives are known to silently ignore data flushing requests, which may lead to data loss in case of a power outage. Examples of such drives include OCZ Vertex 3, Intel 520, Intel X25-E, and Intel X-25-M G2. We recommend avoiding these drives (or test them with the vstorage-hwflush-check tool), and using enterprise-grade or datacenter-grade devices instead. For more information on checking power loss protection, refer to Checking disk data flushing capabilities.\nProvisioning cache devices\nThe minimum number of cache devices per node is one. However, note that in this case, if caching is used for all capacity devices, the cache device becomes a single point of failure, which may make the entire node unavailable. In order to avoid this, at least three cache devices per node are recommended.\nUsing multiple cache devices also provides the following improvements:\n\nMore capacity. This can be helpful if data is written in long bursts or if the cache fails in offloading to the underlying device.\nPerformance boost. If there is enough parallelism on the client side, the workload can be split among several cache devices, thus increasing the overall throughput.\nHigh availability. With fewer capacity devices per cache device or with RAID mirroring, you can lower the probability of a downtime or its impact.\n\nIt is generally recommended to provision one cache device to every 4-12 capacity devices. Keep in mind that the speed of a cache device should be at least twice as high as that of the underlying capacity devices combined. Otherwise, the cache device may be a performance bottleneck. In this case, however, using cache can still improve latency and even performance in systems with lower parallelism.\nTo calculate the optimal number of cache devices for your cluster, consider the following formula:N = 0.8 * (cache_speed / capacity_speed)\nWhere:\n\nN is the maximum number of capacity devices for each cache device.\ncache_speed is the sustained write speed of a cache device.\ncapacity_speed is the sustained write speed of a capacity device.\n\nThis formula must also take into account the amount of RAM, as explained below.\nFor more accurate results, the device speed should be determined experimentally with real workloads. For evaluation purposes, you may use the sustained speed of sequential or random workloads, depending on the type of a workload.\nTo avoid performance degradation, the resulting number of capacity devices for each cache device (N) should be considered as an upper bound. In some cases, explained below, this number should at least be halved, in order to give any performance benefit.\nJournal sizing\nRegardless of a cache device size, its journal size can be different, depending on the available space and number of chunk services that share the cache device. There are scenarios when using a journal smaller than the available capacity leads to performance improvements.\nOn one hand, if the size of all journals is less than the amount of available RAM, then the journal is only used to write temporary data and guarantee consistency. Its small size allows the system to keep the journal in RAM, avoiding all reads from the journal and resulting in fewer I/O operations. Ultimately, this reduces the load on the device and in some cases may improve the overall performance (for example, when the performance of a cache and capacity devices is the same or similar).\nOn the other hand, if the size of all journals is more than the amount of available RAM, then the journal also serves as a read and write cache. This boosts the performance of both read and write requests, but in order to achieve such benefits, the cache device must be at least twice as fast as all of the underlying capacity devices combined, and the number of capacity devices per each cache device must at least be halved compared to the N value in the formula above. If this is not the case, it is preferable to have a smaller journal. As speed is also largely dependent on the workload, this might not be obvious.\nCache sizing\nTo decide on a cache device size, consider the endurance factor of a particular device and its journal size.\nIf you use cache for user data, then the cache device should be able to withstand sustained high throughput for as long as needed without filling up. The cache must offload its contents to the underlying device periodically, and this process depends on the speed of the underlying device. If the cache device becomes full, the system performance will degrade to the speed of the underlying devices, thus negating the caching benefits. Therefore, if the expected workload comes in bursts of a certain duration (for example, during office hours), the cache should be able to store at least the amount of data written during that period of time.\nNote that 0.1% of the size of the capacity devices combined is reserved for checksums on the cache device. For example, with the recommended number of up to 12 capacity devices per cache device and HDDs of 20 TB each, the reserved space may be calculated as 0.1% * 20 TB * 12 = 240 GB. A small margin of about 5% of the device size is always kept free. All other space of the cache device is reserved for journals (read/write cache).\nRisks and possible failures\nThough cache devices may significantly improve the cluster performance, you need to consider their possible failures. Flash devices generally have a shorter lifespan and their use in this context exposes them to greater wear, when compared to capacity devices.\nAlso, keep in mind that as one cache device can be used to store multiple journals, all capacity devices associated with a cache device will become unavailable if this cache device fails.\nConsider the following possible issues when using cache devices:\n\nData loss. A cache device failure may lead to data loss if the data has no replicas or RAID mirroring is not configured.\nPerformance degradation. If a cache device fails, the system will use other devices for storing data, which may result in a performance bottleneck or trigger the data rebalancing process to restore the data redundancy. This, in turn, will lead to increased disk and network usage and reduce the cluster performance.\nLow availability. With a failed cache device, data redundancy may be degraded, which may result in a read-only or unreadable cluster in severe cases.\nLess capacity. If a cache device fails, several capacity devices may become unavailable, leading to a lack of disk space available for writing new data.\n\nTo prevent these issues, use optimal redundancy policies and multiple cache devices in your system. Additionally, you can consider the possibility of using local replication (for example, RAID1) on top of distributed replication, especially in systems with low replication factors (1 replica or 1+0 encoding).\nSee also\n\nStorage cache architecture\n\nQuantity of disks per node\n\nHDD/SSD configuration\n\nServer requirements\n\nNetwork requirements and recommendations",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/cache-configuration.html"
    },
    {
        "title": "Monitoring virtual machines",
        "content": "Monitoring virtual machines\nTo monitor a virtual machine\n\nAdmin panel\nSelect a virtual machine and open the Monitoring tab. The following performance charts are available for virtual machines:\n\nCPU\n\nCPU usage by the VM.\nRAM\n\nRAM usage by the VM.\nNetwork interface: <network_name> / MAC: <mac_address>\n\nThe VM interface parameters:\n\nSpeed: the port transmit (TX) and receive (RX) speed, in bytes per second.\nPackets: the number of TX and RX packets per second on the port.\nDrop rate: the number of TX and RX packets dropped per second on the port.\n\nTo see a list of VM interfaces and hide all other charts, click Only network interfaces above the charts.\n\nVolume: <volume_name> / <volume_id>\n\nThe VM disk parameters:\n\nStorage read: the amount of data being read by the VM, in bytes and operations per second.\nStorage write: the amount of data being written by the VM, in bytes and operations per second.\nRead latency: the disk latency while reading data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\nWrite latency: the disk latency while writing data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\nFlush latency: the disk latency while flushing data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\n\nTo see a list of VM disks and hide all other charts, click Only volumes above the charts.\n\nAveraged values are calculated every five minutes.\n\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.\n\nCommand-line interface\nUse the following command:vinfra service compute server stat <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to view the statistics for the virtual machine myvm, run:# vinfra service compute server stat myvm\r\n+----------+----------------------------------+\r\n| Field    | Value                            |\r\n+----------+----------------------------------+\r\n| datetime | 2019-05-29T11:39:46.429000+00:00 |\r\n| metrics  | block_capacity: 1073741824       |\r\n|          | block_usage: 268435456           |\r\n|          | cpu_usage: 1                     |\r\n|          | mem_usage: 149876736             |\r\n+----------+----------------------------------+\r\n\n\nSee also\n\nMonitoring compute nodes\n\nMonitoring load balancers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server stat <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to view the statistics for the virtual machine myvm, run:# vinfra service compute server stat myvm\r\n+----------+----------------------------------+\r\n| Field    | Value                            |\r\n+----------+----------------------------------+\r\n| datetime | 2019-05-29T11:39:46.429000+00:00 |\r\n| metrics  | block_capacity: 1073741824       |\r\n|          | block_usage: 268435456           |\r\n|          | cpu_usage: 1                     |\r\n|          | mem_usage: 149876736             |\r\n+----------+----------------------------------+\r\n\n",
                "title": "To monitor a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nSelect a virtual machine and open the Monitoring tab. The following performance charts are available for virtual machines:\n\nCPU\n\nCPU usage by the VM.\nRAM\n\nRAM usage by the VM.\nNetwork interface: <network_name> / MAC: <mac_address>\n\n\nThe VM interface parameters:\n\nSpeed: the port transmit (TX) and receive (RX) speed, in bytes per second.\nPackets: the number of TX and RX packets per second on the port.\nDrop rate: the number of TX and RX packets dropped per second on the port.\n\nTo see a list of VM interfaces and hide all other charts, click Only network interfaces above the charts.\n\nVolume: <volume_name> / <volume_id>\n\n\nThe VM disk parameters:\n\nStorage read: the amount of data being read by the VM, in bytes and operations per second.\nStorage write: the amount of data being written by the VM, in bytes and operations per second.\nRead latency: the disk latency while reading data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\nWrite latency: the disk latency while writing data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\nFlush latency: the disk latency while flushing data. Hovering the mouse cursor over a point on the chart, you can also see the average and maximum latency for that moment, as well as the 95 and 99 percentiles.\n\nTo see a list of VM disks and hide all other charts, click Only volumes above the charts.\n\n\n\nAveraged values are calculated every five minutes.\n\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.\n",
                "title": "To monitor a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-virtual-machines.html"
    },
    {
        "title": "Using persistent volumes for Kubernetes pods",
        "content": "Using persistent volumes for Kubernetes pods\nKubernetes allows using compute volumes as persistent storage for pods. Persistent volumes (PV) exist independently of pods, meaning that such a volume persists after the pod it is mounted to is deleted. This PV can be mounted to other pods for accessing data stored on it. You can provision PVs dynamically, without having to create them manually, or statically, using volumes that exist in the compute cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/using-persistent-volumes-for-kubernetes-pods.html"
    },
    {
        "title": "Viewing resource usage reports",
        "content": "Viewing resource usage reports\nAssets created for the pay-as-you-go model generate daily usage reports and send them in the .xlsx format. You can view these reports as follows:\n\nGo to the Usage page and click the needed report\n\nOn the report details page, download the processed usage file by clicking its name.\n\nOpen the file and go to the records tab. Review the usage statistics.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/viewing-resource-usage-reports.html"
    },
    {
        "title": "Accessing S3 buckets",
        "content": "Accessing S3 buckets\nTo access S3 buckets, get the following information (credentials) from your system administrator:\n\nUser panel IP address\nDNS name of the S3 endpoint\nAccess key ID\nSecret access key\n\nVirtuozzo Hybrid Infrastructure allows you to access your S3 data in several ways:\n\nVia the Virtuozzo Hybrid Infrastructure user panel\nVia a third-party S3 application like Cyberduck, Mountain Duck, etc.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/accessing-s3-buckets.html"
    },
    {
        "title": "Deleting bucket quotas via REST API",
        "content": "Deleting bucket quotas via REST API\nYou can delete the current quotas per bucket with the ostor-quotas service and parameter bucket specifying the bucket name:# s3_curl DELETE \"http://s3.example.com/?ostor-quotas&bucket=bucket1\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-bucket-quotas-via-rest-api.html"
    },
    {
        "title": "Creating target groups",
        "content": "Creating target groups\nPrerequisites\n\nThe storage cluster has at least one disk with the Storage role.\n\nTo create a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, and then click Create target group. The Create target group wizard will open.\n\nOn Name, enter a name for the iSCSI target group.\n\nOn Nodes, select nodes to add to the target group. On these nodes, iSCSI targets will run. You can only choose nodes with network interfaces that are assigned the iSCSI traffic type. It is recommended to have at least two nodes in the target group to achieve high availability. If you plan to use multiple iSCSI initiators, you should have as many nodes in the target group. The optimal way is to create a single target per node.\nIf the node network interfaces are not configured, click the cogwheel icon, select the networks as required, and then click Apply.\n\nOn Targets, select iSCSI interfaces to add to the target group. You can choose from a list of network interfaces that are assigned the iSCSI traffic type. If you plan to use multiple iSCSI initiators, you should select as many interfaces per node. One interface can be added to multiple target groups, although it may reduce performance.\n\nOn Volumes, select volumes to attach to target group LUNs. You can select from a list of volumes that are not attached to any target groups. If no volumes are available, you can create them on this step so they are attached to the target group automatically, or attach them manually later.\n\nOn Access control, configure access to the target group. It is recommended to use CHAP or ACL in untrusted public networks. Without access control, any connections to the target group are allowed.\n\nOn Summary, review the target group details. You can go back to change them if necessary. Click Create.\n\nThe created target group will appear on the Target groups tab. Its targets will start automatically.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group create --type <type> --target <name:node:ip1,ip2...> <name>\n\n--type <type>\n\nType of targets in the target group: iscsi or fc.\n--target <name:node:ip1,ip2...>\n\nTarget name, node ID or hostname, and the IP addresses of the node network interfaces assigned the iSCSI traffic type\n<name>\n\nTarget group name\n\nFor example, to create the target group tg1 with two iSCSI targets target1 and target2 that will run on the node node001 with the IP address 10.10.10.11 and on the node node002 with the IP address 10.10.10.12, run:# vinfra service block-storage target-group create tg1 --type iscsi --target target1:node001:10.10.10.11 \\\r\n--target target2:node002:10.10.10.12\nThe created target group will appear in the vinfra service block-storage target-group list output:# vinfra service block-storage target-group list\r\n+--------------------------------------+------+-------+-------+---------+\r\n| id                                   | name | type  | state | running |\r\n+--------------------------------------+------+-------+-------+---------+\r\n| 1b661da7-cb4d-4b81-9f09-f8ad54fa631e | tg1  | iscsi | ok    | False   |\r\n+--------------------------------------+------+-------+-------+---------+\r\n\n\nSee also\n\nManaging block storage\n\nMonitoring block storage\n\nWhat's next\n\nCreating volumes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group create --type <type> --target <name:node:ip1,ip2...> <name>\n\n--type <type>\n\nType of targets in the target group: iscsi or fc.\n--target <name:node:ip1,ip2...>\n\nTarget name, node ID or hostname, and the IP addresses of the node network interfaces assigned the iSCSI traffic type\n<name>\n\nTarget group name\n\nFor example, to create the target group tg1 with two iSCSI targets target1 and target2 that will run on the node node001 with the IP address 10.10.10.11 and on the node node002 with the IP address 10.10.10.12, run:# vinfra service block-storage target-group create tg1 --type iscsi --target target1:node001:10.10.10.11 \\\r\n--target target2:node002:10.10.10.12\nThe created target group will appear in the vinfra service block-storage target-group list output:# vinfra service block-storage target-group list\r\n+--------------------------------------+------+-------+-------+---------+\r\n| id                                   | name | type  | state | running |\r\n+--------------------------------------+------+-------+-------+---------+\r\n| 1b661da7-cb4d-4b81-9f09-f8ad54fa631e | tg1  | iscsi | ok    | False   |\r\n+--------------------------------------+------+-------+-------+---------+\r\n\n",
                "title": "To create a target group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, and then click Create target group. The Create target group wizard will open.\n\nOn Name, enter a name for the iSCSI target group.\n\n\n\n\n\n\nOn Nodes, select nodes to add to the target group. On these nodes, iSCSI targets will run. You can only choose nodes with network interfaces that are assigned the iSCSI traffic type. It is recommended to have at least two nodes in the target group to achieve high availability. If you plan to use multiple iSCSI initiators, you should have as many nodes in the target group. The optimal way is to create a single target per node.\nIf the node network interfaces are not configured, click the cogwheel icon, select the networks as required, and then click Apply.\n\n\n\n\n\n\nOn Targets, select iSCSI interfaces to add to the target group. You can choose from a list of network interfaces that are assigned the iSCSI traffic type. If you plan to use multiple iSCSI initiators, you should select as many interfaces per node. One interface can be added to multiple target groups, although it may reduce performance.\n\n\n\n\n\n\nOn Volumes, select volumes to attach to target group LUNs. You can select from a list of volumes that are not attached to any target groups. If no volumes are available, you can create them on this step so they are attached to the target group automatically, or attach them manually later.\n\n\n\n\n\n\nOn Access control, configure access to the target group. It is recommended to use CHAP or ACL in untrusted public networks. Without access control, any connections to the target group are allowed.\n\n\n\n\n\n\nOn Summary, review the target group details. You can go back to change them if necessary. Click Create.\n\n\nThe created target group will appear on the Target groups tab. Its targets will start automatically.\n",
                "title": "To create a target group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-target-groups.html"
    },
    {
        "title": "Creating flavors",
        "content": "Creating flavorsPOST /flavors\r\n\nCreate a flavor.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=create-flavor-detail#create-flavor\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nflavor\n\nbody\nobject\nThe ID and links for the flavor for your server instance. A flavor is a combination\r\nof memory, disk size, and CPUs.\n\nname\n\nbody\nstring\nThe display name of a flavor.\n\ndescription (Optional)\nbody\nstring\n\nA free form description of the flavor. Limited to 65535 characters\r\nin length. Only printable characters are allowed.\nNew in version 2.55\n\nid (Optional)\nbody\nstring\nThe ID of the flavor. While it may look like an integer, this\r\nis really a string. If not provided, it defaults to a UUID.\n\nram\n\nbody\ninteger\nThe amount of RAM a flavor has, in MiB.\n\ndisk\n\nbody\ninteger\n\nThe size of the root disk that will be created in GiB. If 0 the\r\nroot disk will be set to exactly the size of the image used to\r\ndeploy the instance. However, in this case filter scheduler cannot\r\nselect the compute host based on the virtual image size. Therefore,\r\n0 should only be used for volume-booted instances or for testing\r\npurposes. Volume-backed instances can be enforced for flavors with\r\nzero root disk via the os_compute_api:servers:create:zero_disk_flavor\r\npolicy rule.\n\nThis platform supports only volume-booted instances, so this \r\nparameter value should be 0.\n\nvcpus\n\nbody\ninteger\nThe number of virtual CPUs that will be allocated to the server.\n\nOS-FLV-EXT-DATA:ephemeral (Optional)\nbody\ninteger\nThe size of the ephemeral disk that will be created, in\r\nGiB. Ephemeral disks may be written over on server state\r\nchanges. So should only be used as a scratch space for\r\napplications that are aware of its limitations. Defaults to 0.\n\nswap (Optional)\nbody\ninteger\nThe size of a dedicated swap disk that will be allocated, in\r\nMiB. If 0 (the default), no dedicated swap disk will be created.\n\nrxtx_factor (Optional)\nbody\nfloat\nThe receive / transmit factor (as a float) that will be set on\r\nports if the network backend supports the QOS extension.\r\nOtherwise it will be ignored. It defaults to 1.0.\n\nos-flavor-access:is_public (Optional)\nbody\nboolean\nWhether the flavor is public (available to all projects) or scoped\r\nto a set of projects. Default is True if not specified.\n\nExample# curl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"flavor\": {\r\n        \"name\": \"flavor1\",\r\n        \"ram\": 1024,\r\n        \"vcpus\": 2,\r\n        \"disk\": 0\r\n    }\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/flavors\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nflavor\n\nbody\nobject\nThe ID and links for the flavor for your server instance. A flavor is a combination\r\nof memory, disk size, and CPUs.\n\nname\n\nbody\nstring\nThe display name of a flavor.\n\ndescription\n\nbody\nstring\n\nThe description of the flavor.\nNew in version 2.55\n\nid\n\nbody\nstring\nThe ID of the flavor. While it may look like\r\nan integer, this is really a string.\n\nram\n\nbody\ninteger\nThe amount of RAM a flavor has, in MiB.\n\ndisk\n\nbody\ninteger\n\nThe size of the root disk that will be created in GiB. If 0 the\r\nroot disk will be set to exactly the size of the image used to\r\ndeploy the instance. However, in this case filter scheduler cannot\r\nselect the compute host based on the virtual image size. Therefore,\r\n0 should only be used for volume-booted instances or for testing\r\npurposes. Volume-backed instances can be enforced for flavors with\r\nzero root disk via the os_compute_api:servers:create:zero_disk_flavor\r\npolicy rule.\n\nThis platform supports only volume-booted instances, so this \r\nparameter value should be 0.\n\nvcpus\n\nbody\ninteger\nThe number of virtual CPUs that will be allocated to the server.\n\nlinks\n\nbody\narray\nLinks to the resources in question. See API Guide / Links and\r\nReferences\r\nfor more info.\n\nOS-FLV-EXT-DATA:ephemeral\n\nbody\ninteger\nThe size of the ephemeral disk that will be created, in\r\nGiB. Ephemeral disks may be written over on server state\r\nchanges. So should only be used as a scratch space for\r\napplications that are aware of its limitations. Defaults to 0.\n\nOS-FLV-DISABLED:disabled (Optional)\nbody\nboolean\nWhether or not the flavor has been administratively disabled.\r\nThis is typically only visible to administrative users.\n\nswap\n\nbody\ninteger\nThe size of a dedicated swap disk that will be allocated, in\r\nMiB. If 0 (the default), no dedicated swap disk will be created.\r\nCurrently, the empty string (\u00e2\u0080\u0098\u00e2\u0080\u0099) is used to represent 0.\r\nAs of microversion 2.75 default return value of swap is 0\r\ninstead of empty string.\n\nrxtx_factor\n\nbody\nfloat\nThe receive / transmit factor (as a float) that will be set on\r\nports if the network backend supports the QOS extension.\r\nOtherwise it will be ignored. It defaults to 1.0.\n\nos-flavor-access:is_public\n\nbody\nboolean\nWhether the flavor is public (available to all projects) or scoped\r\nto a set of projects. Default is True if not specified.\n\nextra_specs (Optional)\nbody\nobject\n\nA dictionary of the flavor\u00e2\u0080\u0099s extra-specs key-and-value pairs.  This will\r\nonly be included if the user is allowed by policy to index flavor\r\nextra_specs.\nNew in version 2.61\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"flavor\": {\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/flavors/2ff017d3-55f0-4906-8908-8a1bb4e00e6d\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/flavors/2ff017d3-55f0-4906-8908-8a1bb4e00e6d\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"ram\": 1024,\r\n    \"OS-FLV-DISABLED:disabled\": false,\r\n    \"os-flavor-access:is_public\": true,\r\n    \"rxtx_factor\": 1,\r\n    \"disk\": 0,\r\n    \"id\": \"2ff017d3-55f0-4906-8908-8a1bb4e00e6d\",\r\n    \"name\": \"flavor1\",\r\n    \"vcpus\": 2,\r\n    \"swap\": \"\",\r\n    \"OS-FLV-EXT-DATA:ephemeral\": 0\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-flavors.html"
    },
    {
        "title": "Editing and deleting domain groups",
        "content": "Editing and deleting domain groups\nYou can edit the following parameters of a domain group: its name, description, user role, system and domain permissions. When you delete a domain group, all of the assigned users are automatically logged out of the management panel.\nPrerequisites\n\nDomain groups are created, as described in Creating domain groups.\n\nTo edit a domain group\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a group.\nGo to the Domain groups tab, click the ellipsis icon next to the group, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nCommand-line interface\nUse the following command:vinfra domain group set [--name <name>] [--description <description>]\r\n                        [--domain-permissions <domain_permissions>]\r\n                        [--system-permissions <system_permissions>]\r\n                        --domain <domain> <group>\r\n\n\n--name <name>\n\nNew name for a group\n--description <description>\n\nGroup description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--system-permissions <system_permissions>\n\nA comma-separated list of system permissions. View the list of available system permissions using vinfra domain user list-available-roles | grep system.\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n\nFor example, to change the name of the domain group users to myusers, run:# vinfra domain group set users --domain mydomain --name myusers\n\nTo delete a domain group\n\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to delete a domain group.\nGo to the Domain groups tab, click the ellipsis icon next to the group, and then click Delete.\nClick Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra domain group delete --domain <domain> <group>\r\n\n\n--domain <domain>\n\nDomain ID or name\n<group>\n\nGroup ID or name\n\nFor example, to delete the group users from the domain mydomain:# vinfra domain group delete users --domain mydomain\n\nSee also\n\nManaging user assignment to domain groups\n\nManaging project assignment to domain groups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain group set [--name <name>] [--description <description>]\r\n                        [--domain-permissions <domain_permissions>]\r\n                        [--system-permissions <system_permissions>]\r\n                        --domain <domain> <group>\r\n\n\n--name <name>\n\nNew name for a group\n--description <description>\n\n\nGroup description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--domain-permissions <domain_permissions>\n\nA comma-separated list of domain permissions. View the list of available domain permissions using vinfra domain user list-available-roles | grep domain.\n--system-permissions <system_permissions>\n\nA comma-separated list of system permissions. View the list of available system permissions using vinfra domain user list-available-roles | grep system.\n--domain <domain>\n\nDomain name or ID\n<group>\n\nGroup ID or name\n\nFor example, to change the name of the domain group users to myusers, run:# vinfra domain group set users --domain mydomain --name myusers\n",
                "title": "To edit a domain group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain group delete --domain <domain> <group>\r\n\n\n--domain <domain>\n\nDomain ID or name\n<group>\n\nGroup ID or name\n\nFor example, to delete the group users from the domain mydomain:# vinfra domain group delete users --domain mydomain\n",
                "title": "To delete a domain group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to edit a group.\nGo to the Domain groups tab, click the ellipsis icon next to the group, and then click Edit.\n\nMake the required changes, and then click Save.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n\n",
                "title": "To edit a domain group"
            },
            {
                "example": "\nAdmin panel\n\nOn the Settings > Projects and users screen, click the domain, within which you want to delete a domain group.\nGo to the Domain groups tab, click the ellipsis icon next to the group, and then click Delete.\nClick Delete in the confirmation window.\n\n",
                "title": "To delete a domain group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/editing-and-deleting-domain-groups.html"
    },
    {
        "title": "Deleting S3 users and buckets via REST API",
        "content": "Deleting S3 users and buckets via REST API\nYou can delete an existing user by sending a DELETE request to the ostor-users service along with the user email address:# s3_curl DELETE \"http://s3.example.com/?ostor-users&emailAddress=user@example.com\"\r\n\nUsers who own buckets cannot be removed until their buckets are deleted. To get a list of user\u00e2\u0080\u0099s buckets, send a GET request to the ostor-buckets service along with the user email address:# s3_curl GET \"http://s3.example.com/?ostor-buckets&emailAddress=user@example.com\"\r\n{\r\n\"Buckets\": [\r\n    {\r\n        \"size\": {\r\n            \"current\": 12288,\r\n            \"h_integral\": 7360512,\r\n            \"hmax\": 12288,\r\n            \"last_ts\": 424241\r\n        },\r\n        \"epoch\": 0,\r\n        \"owner_id\": \"ba7eba06129464c5\",\r\n        \"name\": \"bucketname\",\r\n        \"creation_date\": \"2018-05-25T17:12:00.000Z\"\r\n    }]\r\n }\r\n\nYou can then delete buckets by name:# s3_curl DELETE \"http://s3.example.com/bucketname\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-s3-users-and-buckets-via-rest-api.html"
    },
    {
        "title": "Redundancy modes",
        "content": "Redundancy modes\nVirtuozzo Hybrid Infrastructure supports a number of modes for each redundancy method. Only predefined redundancy modes are available in the admin panel. The following table illustrates data overhead of various redundancy modes. The first three lines are replication and the rest are erasure coding.\nThe numbers of failure domains listed in the table indicate only the requirements of each redundancy method but not the number of failure domains needed for the Virtuozzo Hybrid Infrastructure cluster. The general recommendation is to always have at least one more failure domain in a cluster than required by the chosen redundancy scheme. For example, a cluster using replication with 3 replicas and the host failure domain should have four nodes, and a cluster that works in the 7+2 erasure coding mode with the disk failure domain should have ten disks. Such a cluster configuration has the following advantages:\n\nThe cluster will not be exposed to additional failures when in the degraded state. With one failure domain down, the cluster may not survive another even single-disk failure without data loss.\nYou will be able to perform maintenance on cluster nodes that may be needed to recover a failed node (for example, for installing software updates).\nIn most cases, the cluster will have enough nodes to rebuild itself. In a cluster with the host failure domain but without a spare node, each replica of user data is distributed to each cluster node for redundancy. If one or two nodes go down, the user data will not be lost, but the cluster will become degraded and will only start self-healing after the failed nodes are back online. During its rebuilding process, the cluster may be exposed to additional failures until all of its nodes are healthy again.\nYou can replace and upgrade a cluster node without adding a new node to the cluster. A graceful release of a storage node is only possible if the remaining nodes in the cluster can comply with the configured redundancy scheme. You can, however, release a node forcibly without data migration, but it will make the cluster degraded and trigger the cluster self-healing.\n\nThe minimum and recommended cluster configurations are described in Quantity of servers.\n\nRedundancy mode\nFailure domains required to store data copies\nHow many failure domains can\r\nfail without data loss\nStorage\r\noverhead, percent\nRaw space needed to\r\nstore 100 GB of data\n\n1 replica\r\n(no redundancy)\n1\n0\n0\n100 GB\n\n2 replicas\n2\n1\n100\n200 GB\n\n3 replicas\n3\n2\n200\n300 GB\n\nEncoding 1+0\r\n(no redundancy)\n1\n0\n0\n100 GB\n\nEncoding 1+1\n2\n1\n100\n200 GB\n\nEncoding 1+2\n3\n2\n200\n300 GB\n\nEncoding 3+1\n4\n1\n33\n133 GB\n\nEncoding 3+2\n5\n2\n67\n167 GB\n\nEncoding 5+2\n7\n2\n40\n140 GB\n\nEncoding 7+2\n9\n2\n29\n129 GB\n\nEncoding 17+3\n20\n3\n18\n118 GB\n\nThe 1+0, 1+1, 1+2, and 3+1 encoding modes are meant for small clusters that have insufficient nodes for other erasure coding modes but will grow in the future. As a redundancy type cannot be changed once chosen (from replication to erasure coding or vice versa), this mode allows you to choose erasure coding even if your cluster is smaller than recommended. Once the cluster has grown, more beneficial redundancy modes can be chosen.\n\nYou select a data redundancy mode when configuring storage services and creating storage volumes for virtual machines. No matter what redundancy mode you select, it is highly recommended to be protected against a simultaneous failure of two nodes, as that happens often in real-life scenarios.\nBy default, all encoding modes, except 1+0 and M+1, allow write operations when one failure domain (for example, a storage node or disk) is inaccessible. The cluster starts working in the read-only mode with disabled write operations in the following cases:\n\nWhen redundancy is 1, that is with the M+1 encoding mode, and one failure domain is inaccessible.\nWhen redundancy is 2, that is with the M+2 encoding mode, and two failure domains are inaccessible.\n\nIf the number of unavailable failure domains is higher than the redundancy factor, then data becomes unavailable even for reading and there is a high risk of data loss. Therefore, for production, it is strongly recommended to use redundancy modes with the redundancy factor 2 or 3, such as encoding M+2, encoding M+3, and 3 replicas.\nSee also\n\nRedundancy by replication\n\nRedundancy by erasure coding\n\nNo redundancy\n\nFailure domains\n\nStorage tiers\n\n\u00d0\u00a1luster rebuilding",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/redundancy-modes.html"
    },
    {
        "title": "2.2. Integration Overview\u00c2\u00b6",
        "content": "2.2. Integration Overview | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n2.2. Integration Overview\u00c2\u00b6\nThis integration guide aims to explain the steps to integrate Leostream and Virtuozzo Hybrid Infrastructure.\nHere is an overview of the steps we will follow:\n\nCheck Prerequisites.\nCreate the Domain, Users and Project on Virtuozzo Hybrid Infrastructure.\nCreate the necessary networks for the Leostream Infrastructure. (labeled VDI-network, AD-Network, Gateway-Network and Broker-Network).\nCreate a Router (we will enable SNAT on the above networks).\nCreate two CentOS 7 VMs, one for the Leostream Connection Broker the other for the Leostream Gateway.\nCreate a Floating IP. We will assign a floating IP to the Gateway VM.\nImport Master Windows images.\nInstall the Leostream Gateway and assign a floating IP.\nInstall the Leostream Connection Broker.\nConfigure the Leostream Gateway for Connection Broker forwarding.\nConfigure the Leostream Broker, including integration with Virtuozzo Hybrid Infrastructure, building pools that manage capacity in Virtuozzo Hybrid Infrastructure, defining Active Directory authentication servers, configuring plans and policies for user assignment to pools.\nUse the Leostream Connect Client to access the remote desktops.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-leostream/integration-overview.html"
    },
    {
        "title": "Deleting floating IPs",
        "content": "Deleting floating IPsDELETE /v2.0/floatingips/{floatingip_id}\r\n\nDelete a floating IP and, if present, its associated port.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=delete-floating-ip-detail#delete-floating-ip\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingip_id\n\npath\nstring\nThe ID of the floating IP address.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<..>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/floatingips/239fe333-b801-4096-a04f-20f33f6177c3\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n412 - Precondition Failed\n\nThe server does not meet one of the preconditions that the requester put on the request header fields.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-floating-ips.html"
    },
    {
        "title": "Welcome to Virtuozzo Hybrid Infrastructure Documentation",
        "content": "Virtuozzo Hybrid Infrastructure Documentation. Overview, Features, Tutorials | Virtuozzo Hybrid Infrastructure Docs\n\nDocs menuMENUProductsVirtuozzo Hybrid CloudVirtuozzo Hybrid InfrastructureVirtuozzo Application PlatformVirtuozzo Hybrid ServerSupportProduct SupportDocumentationProfessional ServicesPartnersIaaS ProvidersPaaS ProvidersTechnology PartnersDistributorsResellersPartner with usGet in touchDocumentation Portal for Virtuozzo Hybrid InfrastructureSearch\n\nGetting StartedQuick Start GuideInstallation GuideAdministrator GuideSelf-Service GuideStorage User GuideCompute API ReferenceObject Storage Orchestration API ReferenceRelease NotesProduct Lifecycle PolicyMigration GuidesAcronis Cyber Cloud Migration from VMwareHystax Acura Migration from VMwareArrosoft CloudAny Migration from VMwareCloudBase Coriolis Migration GuideIntegrationsHystax Acura IntegrationLeostream IntegrationBitNinja IntegrationCloudBlue Connect IntegrationStorware IntegrationStorage for Vertica in Eon ModeTutorialsHow to deploy WordPress in KubernetesHow to use Trilio for KubernetesHow to deploy Osie on KubernetesHow to customize OpenStack servicesHow to deploy VHI on OVHcloudHow to use Velero for KubernetesHow to use Milvus and Kubernetes for RISHow to use IaC tools on VHIInfrastructure management with TerraformHow to deploy nested VHI clustersHow to mirror the VHI repositoryWelcome to Virtuozzo Hybrid Infrastructure DocumentationVirtuozzo Hybrid Infrastructure is a managed OpenStack-based cloud platform for\u00c2\u00a0service providers, software vendors, system integrators and enterprises. The platform is fine-tuned for cloud-native applications and AI/ML projects ensuring optimized performance, rapid time-to-market, cost efficiency, and personalized support.This Infrastructure as a Service includes KVM\u00e2\u0080\u0093based virtualization, OpenStack orchestration, Kubernetes, software\u00e2\u0080\u0093defined and S3-compatible storage, built-in load balancing and backup as a service, easy\u00e2\u0080\u0093to\u00e2\u0080\u0093use cloud management and monitoring tools in a single hyperconverged solution with a self\u00e2\u0080\u0093service portal.Learn about Virtuozzo Hybrid Infrastructure features, supported technologies, services, products, and other specifics. Find out how to get your Virtuozzo IaaS up and running, and what use cases can be covered using this solution.get\nstarted nowProductsHybrid CloudHybrid InfrastructureApplication PlatformSelf-Service for vCenterHybrid ServerSolutionsVMware AlternativePlatform as a ServiceKubernetes OrchestrationDatabase ManagementHigh-Performance StorageMulti-CloudPartnersPaaS ProvidersIaaS ProvidersTechnology PartnersResellersDistributorsBecome a PartnerSupportDocumentationProduct SupportProfessional ServicesProduct UpdatesVideoCompanyAboutLeadershipCase studiesBlogEventsContact\u00c2\u00a9 Virtuozzo. All rights reserved. | Privacy & Legal\u00d7",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/"
    },
    {
        "title": "Setting memory parameters per node",
        "content": "Setting memory parameters per node\nTo change per-node memory parameters\nUse the following command:vinfra memory-policy vstorage-services per-node change [--guarantee <guarantee>] [--swap <swap>]\r\n                                                       [--cache-ratio <cache-ratio> --cache-minimum <cache-minimum>\r\n                                                       --cache-maximum <cache-maximum>] --node <node>\n\n--guarantee <guarantee>\n\nGuarantee, in bytes\n--swap <swap>\n\nSwap size, in bytes, or -1 if unlimited\n--cache-ratio <cache-ratio>\n\nCache ratio from 0 to 1 inclusive\n--cache-minimum <cache-minimum>\n\nMinimum cache, in bytes\n--cache-maximum <cache-maximum>\n\nMaximum cache, in bytes\n--node <node>\n\nNode ID or hostname\n\nFor example, to set the storage memory parameters for the node node001, run:# vinfra memory-policy vstorage-services per-node change --guarantee 8796093022208 --swap 1099511627776 --cache-ratio 0.5 \\\r\n--cache-minimum 1099511627776 --cache-maximum 3298534883328 --node node001\nThis command sets the memory parameters as follows:\n\nThe memory guarantee to 8 GB\nThe swap size to 1 GB\nThe page cache limits: the minimum to 1 GB, the maximum to 3 GB, and the cache ratio to 0.5\n\nYou can view the updated per-node memory parameters in the vinfra memory-policy vstorage-services per-node show output:# vinfra memory-policy vstorage-services per-node show --node node001\r\n+-----------+-------------------------+\r\n| Field     | Value                   |\r\n+-----------+-------------------------+\r\n| cache     | maximum: 13194139533312 |\r\n|           | minimum: 8796093022208  |\r\n|           | ratio: 0.7              |\r\n| guarantee | 8796093022208           |\r\n| swap      | 1099511627776           |\r\n+-----------+-------------------------+\r\n\nTo reset per-node parameters to default\nUse the following command:vinfra memory-policy vstorage-services per-node reset [--guarantee] [--swap] [--cache] --node <node>\n\n--guarantee\n\nReset only the guarantee.\n--swap\n\nReset only the swap size.\n--cache\n\nReset only cache values.\n--node <node>\n\nNode ID or hostname\n\nFor example, to reset the manually configured page cache limits to default for the node node001, run:# vinfra memory-policy vstorage-services per-node reset --cache --node node001\nSee also\n\nSetting memory parameters per cluster",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-memory-parameters-per-node.html"
    },
    {
        "title": "3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nTo create an appliance with the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 template, do the following:\n\nLog in to your Cyber Protection account.\nClick Devices > All devices > Add > Virtuozzo Hybrid Infrastructure. The ZIP archive will be downloaded to your machine. Unpack it to get the QCOW2 template.\nLog in to your Virtuozzo Hybrid Infrastructure account.\nAdd the QCOW2 image file to the Virtuozzo Hybrid Infrastructure compute cluster:\n\nOn the Compute > Virtual machines > Images tab, click Add image.\n\nIn the Add image window, click Browse, and then select the QCOW2 file.\nSpecify the image name, select the Generic Linux OS type, and then click Add.\n\nIn the Compute > Virtual machines > Virtual machines tab, click Create virtual machine.\n\nA window will open where you will need to specify a name for the new virtual machine.\n\nIn Deploy from, choose Image.\nIn the Images window, select the QCOW2 image file of the appliance, and then click Done.\n\nIn the Volumes window, do not add any volumes. The volume that is added automatically for the system disk is sufficient.\nIn the Flavor window, choose a desired combination of vCPUs and RAM, and then click Done. See the agent system requirements in Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template.\nIn the Network interfaces window, click Add, select a public virtual network, and then click Add. It will appear in the Network interfaces list.\nIf you use a setup with more than one physical network (and thus with more than one public virtual network), repeat this step and select the virtual networks that you need.\n\nClick Done.\nBack in the Create virtual machine window, click Deploy to create and boot the virtual machine.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-agent-for-virtuozzo-hybrid-infrastructure-from-qcow2-template/creating-appliance-with-agent-for-virtuozzo-hybrid-infrastructure.html"
    },
    {
        "title": "Releasing nodes from backup storage",
        "content": "Releasing nodes from backup storage\nBackup storage is connected to one specific backup destination. If you need to switch the destination, for example, from a public cloud to a local storage cluster or one public cloud bucket to another, you need to delete the backup storage by releasing all of its nodes from the backup storage cluster and create a new one. Keep in mind that by destroying backup storage you also delete all backup data on the storage cluster and cannot restore it later.\nPrerequisites\n\nThe backup storage cluster is created and registered in the Cloud Management Panel, as described in Provisioning Acronis Backup Storage space.\nAll of the backup storage registrations are deleted, as explained in Deleting registrations.\n\nTo release a node from backup storage\n\nAdmin panel\n\nGo to the Storage services > Backup storage > Nodes screen.\nClick a node to release, and then on the node right pane, click Release. \nClick Release in the confirmation window.\n\nThe backup storage will remain operational until there is at least one node in it.\n\nCommand-line interface\nUse the following command:vinfra service backup node release --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n\nFor example, to release the node node003 from the backup storage, run:# vinfra service backup node release --nodes node003\n\nTo destroy backup storage\n\nAdmin panel\n\nGo to the Storage services > Backup storage > Nodes screen.\nSelect all of the backup nodes or click the only node in the backup storage cluster, and then click Release. \nEnter Delete in the confirmation window, and then click Delete.\n\nCommand-line interface\nUse the following command:vinfra service backup cluster release\n\nSee also\n\nAdding nodes to backup storage\n\nChanging the redundancy scheme for backup storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup node release --nodes <nodes>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of node hostnames or IDs\n\nFor example, to release the node node003 from the backup storage, run:# vinfra service backup node release --nodes node003\n",
                "title": "To release a node from backup storage"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup cluster release\n",
                "title": "To destroy backup storage"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > Backup storage > Nodes screen.\nClick a node to release, and then on the node right pane, click Release. \nClick Release in the confirmation window.\n\nThe backup storage will remain operational until there is at least one node in it.\n",
                "title": "To release a node from backup storage"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > Backup storage > Nodes screen.\nSelect all of the backup nodes or click the only node in the backup storage cluster, and then click Release. \nEnter Delete in the confirmation window, and then click Delete.\n\n",
                "title": "To destroy backup storage"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/releasing-nodes-from-backup-storage.html"
    },
    {
        "title": "Best practices for cluster security",
        "content": "Best practices for cluster security\nTo secure your Virtuozzo Hybrid Infrastructure cluster and prevent possible compromise of the system, follow these guidelines:\n\nUse a strong password for the default admin user. You can change the existing password after the product installation, as described in Resetting the admin user password.\n\nUse a strong password for the root user on each cluster node. You can change the existing password for a node by using the passwd command. For example:# passwd\r\nChanging password for user root.\r\nNew password:\r\nRetype new password:\r\npasswd: all authentication tokens updated successfully.\n\nUse a separate and isolated network for the admin panel and SSH access. You can assign traffic types to infrastructure networks and assign networks to node network interfaces, as described in Managing traffic types and Changing network interface parameters.\nConfigure inbound firewall rules to limit the admin panel and SSH access, as described in Configuring inbound firewall rules.\n\nProhibit password authentication for SSH access. You can add an SSH key, as described in Securing root access to cluster nodes over SSH.\nOnce the key is added, you can access nodes via SSH and disable password authentication in the sshd configuration file:\n\nOpen the /etc/ssh/sshd_config file for editing and set PasswordAuthentication to no:\r\n# vi /etc/ssh/sshd_config\r\n\n\nCheck that your changes are successfully applied:# grep ^PasswordAuthentication /etc/ssh/sshd_config\r\nPasswordAuthentication no\r\n\n\nRestart the service:# systemctl restart sshd\n\nFor more information, refer to the sshd_config manual page.\n\n[For backup storage] Configure the latest TLS version and only desired ciphers to be used for connections to backup storage, as described in Changing TLS configuration for backup storage.\n[For object storage] Configure desired TLS version and ciphers to be used for connections to object storage, as described in Changing the TLS configuration for S3.\n\nUse only necessary traffic types in a public network, according to the deployed services. You can reassign traffic types, as described in Managing traffic types.\nFor more information about network ports used for different services and associated with traffic types, refer to Network ports.\n\nSee also\n\nAccessing the admin panel via SSL\n\nEnabling data encryption",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/best-practices-for-cluster-security.html"
    },
    {
        "title": "Monitoring cluster objects via SNMP",
        "content": "Monitoring cluster objects via SNMP\nYou can monitor cluster objects via the Simple Network Management Protocol (SNMP). The implementation conforms to the same Structure of Management Information (SMI) rules as the data in the standard SNMP context: all objects are organized in a tree; each object identifier (OID) is a series of integers corresponding to tree nodes and separated by dots.\nGeneral information:\n\nThe OID of the root subtree with all of the objects you can monitor is 1.3.6.1.4.1.8072.161.1.\nThe VSTORAGE-MIB.txt information base file is required to monitor the objects. You can download the file at https://<admin_panel_IP>:8888/api/v2/snmp/mibs/?x-session-id=0.\n\nSNMP monitoring overview\n\nEnable SNMP access.\nAccess cluster information objects with SNMP tools, for example, Net-SNMP or Zabbix.\nIf you need to listen to SNMP traps, configure settings and send a test SNMP trap.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-cluster-objects-via-snmp.html"
    },
    {
        "title": "Adding hosts to aggregates",
        "content": "Adding hosts to aggregatesPOST /os-aggregates/{aggregate_id}/action\r\n\nAdds a host to an aggregate.\nSpecify the add_host action and host name in the request body.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=add-host-detail#add-host\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\naggregate_id\n\npath\ninteger\nThe aggregate ID.\n\nadd_host\n\nbody\nobject\nThe add_host object used to add host to aggregate.\n\nhost\n\nbody\nstring\nThe name of the host.\n\nExamplecurl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"add_host\": {\r\n        \"host\": \"node1.vstoragedomain\"\r\n    }\r\n}' https://<node_IP_addr>:8774/v2.1/6ef5371261ea42008e3d1d41ba051977/os-aggregates/4/action\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\naggregate\n\nbody\nobject\nThe host aggregate object.\n\nname\n\nbody\nstring\nThe name of the host aggregate.\n\navailability_zone\n\nbody\nstring\nThe availability zone of the host aggregate.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted_at\n\nbody\nstring\n\nThe date and time when the resource was deleted. If the resource has\r\nnot been deleted yet, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted\n\nbody\nboolean\nA boolean indicates whether this aggregate is deleted or not, if it has\r\nnot been deleted, false will appear.\n\nhosts\n\nbody\narray\nAn array of host information.\n\nid\n\nbody\ninteger\nThe ID of the host aggregate.\n\nmetadata\n\nbody\nobject\nMetadata key and value pairs associated with the aggregate.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nuuid\n\nbody\nstring\n\nThe UUID of the host aggregate.\nNew in version 2.41\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"aggregate\": {\r\n    \"name\": \"CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\",\r\n    \"availability_zone\": null,\r\n    \"deleted\": false,\r\n    \"created_at\": \"2020-04-19T12:56:10.191466\",\r\n    \"updated_at\": null,\r\n    \"hosts\": [\r\n      \"node1.vstoragedomain\"\r\n    ],\r\n    \"deleted_at\": null,\r\n    \"id\": 4,\r\n    \"metadata\": {}\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/adding-hosts-to-aggregates.html"
    },
    {
        "title": "Deployment and configuration",
        "content": "Deployment and configuration\nThe Virtuozzo Hybrid Infrastructure workflow  includes the infrastructure setup and service provisioning. After the infrastructure setup, you will have a storage cluster with configured network and the highly available management node. On top of the storage cluster, you can deploy and configure different services for provisioning to end users. You can provision backup, block, object, and file storage space, as well as compute resources. All these tasks can be performed either in the admin panel or via the vinfra command-line tool.\nPrerequisites\n\nVirtuozzo Hybrid Infrastructure is installed on each server, as described in Installation.\n\nInfrastructure setup overview\n\nIf you plan to use the command-line interface, provide your credentials to the vinfra tool.\nSet up your networks, depending on the service you wish to provision. \nConfigure your node network interfaces.\nConfigure an external DNS server.\nEnable RDMA, if supported.\nIf your infrastructure nodes are equipped with NVMe or SSD disks, enable NVMe performance.\nCreate and configure new locations, if required, and move nodes to them.\nDeploy the storage cluster.\nIf you have three and more cluster nodes, enable high availability of the management node.\nTo be able to manage compute or S3 resources in the self-service panel, create domains, projects, and self-service users, and then provide access to the self-service panel.\n\nAfter the infrastructure is set up, you can proceed to provision backup, block, object, file storage space, or compute resources.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/deployment-and-configuration.html"
    },
    {
        "title": "Kickstart scripts",
        "content": "Kickstart scripts\nAfter setting the options, add scripts to the kickstart file that will install the mandatory package group and cluster components:\nInstall the required packages\nIn the body of the %packages script, specify the package group hci to be installed on the server:%packages@^hci%end\r\n\nInstall the required components on the primary node\nTo deploy the primary node, you need the admin panel and storage components. You can configure these components during the product installation. However, this will expose the superadmin password and storage token in the kickstart file. In this case, add the %addon com_vstorage script to the kickstart file as follows:%addon com_vstorage --management --internal-iface=<private_iface> --external-iface=<public_iface> --password=<password>%end\nwhere\n\n<password> is the password of the superadmin account for the admin panel.\n<private_iface> is the name of the private network interface (the one you would select for the management network during attended installation).\n<public_iface> is the name of the public network interface (the one you would select for the admin panel network during attended installation).\n\nIf you do not want to expose the sensitive information in the kickstart file, you can configure the components after the installation. In this case, add the %addon com_vstorage script to the kickstart file as follows:%addon com_vstorage --management --bare%end\r\n\nInstall the required components on a secondary node\nTo deploy secondary nodes, you need only the storage component, which is installed by default. However, you will need the storage token and management node IP address to add the node to the infrastructure. \n\nObtain the token and management node address in the admin panel:\n\nLog in to the admin panel on port 8888. The panel\u00e2\u0080\u0099s IP address is shown in the console after deploying the primary node. Use the default user name shown on the login screen and the primary node\u00e2\u0080\u0099s root password.\nIf prompted, add the security certificate to the browser\u00e2\u0080\u0099s exceptions.\n\nIn the admin panel, open Infrastructure > Nodes, and then click Connect node to invoke a screen with the management node address and the token.\n\nWith the token and management node address, you can proceed to registering the node in the admin panel. You can do this during the product installation. However, this will expose the storage token in the kickstart file. In this case, add the %addon com_vstorage script to the kickstart file as follows:%addon com_vstorage --storage --token=<token> --mgmt-node-addr=<MN_IP_address>%end\r\n\nwhere:\n\n<token> is the obtained token. \n<MN_IP_address> is the obtained management node address.\n\nIf you do not want to expose the sensitive information in the kickstart file, you can register the node after the installation. ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/kickstart-scripts.html"
    },
    {
        "title": "Logical space chart",
        "content": "Logical space chart\n\nAdmin panel\nThe Logical space chart represents all the space allocated to different services for storing user data. This includes the space occupied exclusively by user data. Replicas and erasure coding metadata are not taken into account.\n\nCommand-line interface\nUse the following command:vinfra cluster overview\nFor example, to view the logical space usage in the cluster cluster1, take a look at these lines from the command output:\r\n+-------------------+-------------------------+\r\n| Field             | Value                   |\r\n+-------------------+-------------------------+\r\n| ...               | ...                     |\r\n| logic_space       | free: 1078130163512     |\r\n|                   | total: 1099511627776    |\r\n|                   | used: 21381464264       |\r\n| ...               | ...                     |\r\n| space_per_service | abgw: 0                 |\r\n|                   | compute: 20477967791    |\r\n|                   | iscsi: 0                |\r\n|                   | nfs: null               |\r\n|                   | other: 903496473        |\r\n|                   | s3: 0                   |\r\n+-------------------+-------------------------+\r\n\n\nHow logical space is calculated\nWhen monitoring disk space information in the cluster, keep in mind that logical space is the amount of free disk space that can be used for storing user data in the form of data chunks and all their replicas. Once this space runs out, no data can be written to the cluster.\nTo better understand how logical disk space is calculated, consider the following example:\n\nThe cluster has three disks with the storage role. The first disk has 200 GB of space, the second one has 500 GB, and the third one has 1 TB.\nIf the redundancy mode is set to three replicas, each data chunk must be stored as three replicas on three different disks with the storage role.\n\nIn this example, the available logical disk space will be 200 GB, that is, equal to the capacity of the smallest disk with the storage role. The reason is that each replica must be stored on a different disk. So once the space on the smallest disk (that is, 200 GB) runs out, no new chunk replicas can be created unless a new disk with the storage role is added or the redundancy mode is changed to two replicas.\nWith the two replicas redundancy mode, the available logical disk space would be 700 GB, because the two smallest disks combined can hold 700 GB of data.\nHow compute and iSCSI logical space is calculated\nBlock storage space used by iSCSI LUNs and compute volumes is not fully thin provisioned. Though storage space is not allocated when you create a block volume, the volume usage grows on demand and cannot be reduced. In this case, used logical space is the space actually used by data. At most, used logical space can reach the volume size. After user data removal, unused storage space is not reclaimed and is reported as actual used space.\nTo better understand how compute and iSCSI logical space is calculated, consider the following example:\n\nA user creates an iSCSI LUN with 100 TB.\nThe user connects the LUN to VMware as a datastore.\nThe user fills up this datastore with data/VMs. The used logical space grows to 100 TB.\nThe user deletes the data, emptying the datastore. But the block storage space is not reclaimed and the used logical space remains 100 TB.\n\nSee also\n\nI/O activity charts\n\nServices chart\n\nChunks chart\n\nPhysical space chart",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/logical-space-chart.html"
    },
    {
        "title": "Managing volumes",
        "content": "Managing volumes\nPrerequisites\n\nA block volume is created, as described in Creating volumes.\nThe volume is attached to the target group by following the instructions in Attaching volumes to target groups.\n\nTo set a read/write limit for a volume attached as a LUN\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\nOn the LUNs tab, click the desired LUN to open its details, then click the pencil icon in the Limits field.\n\nIn the Set LUN limit window, enter limit values, and then click Save.\n\nThe set limits will be shown in LUN details.\n\nCommand-line interface\nUse the following command:vinfra service block-storage volume set [--read-ops-limit <iops>] [--write-ops-limit <iops>]\r\n                                        [--read-bps-limit <MiB/s>] [--write-bps-limit <MiB/s>] <volume>\n\n--read-ops-limit <iops>\n\nNumber of read operations per second\n--write-ops-limit <iops>\n\nNumber of write operations per second\n--read-bps-limit <MiB/s>\n\nNumber of mebibytes read per second\n--write-bps-limit <MiB/s>\n\nNumber of mebibytes written per second\n<volume>\n\nVolume name or ID\n\nFor example, to limit the IOPS and throughput of the volume vol1 to 100 IOPS and 100 MiB/s, run:# vinfra service block-storage volume set vol1 --read-ops-limit 100 --read-bps-limit 100 \\\r\n--write-ops-limit 100 --write-bps-limit 100\nYou can check that the limits are successfully applied in the vinfra service block-storage volume show output:# vinfra service block-storage volume show vol1\r\n+---------------+--------------------------------------+\r\n| Field         | Value                                |\r\n+---------------+--------------------------------------+\r\n| grp_id        | 1b661da7-cb4d-4b81-9f09-f8ad54fa631e |\r\n| grp_name      | tg1                                  |\r\n| id            | 9841d72f-5d68-4659-82d5-cd96cf1031b6 |\r\n| limits        | read:                                |\r\n|               |   bps: 104857600                     |\r\n|               |   ops: 100                           |\r\n|               | write:                               |\r\n|               |   bps: 104857600                     |\r\n|               |   ops: 100                           |\r\n| lun           | 0                                    |\r\n| name          | vol1                                 |\r\n| serial        | cd96cf1031b6                         |\r\n| size          | 107374182400                         |\r\n| used_size     | 1048576                              |\r\n| volume_params | failure_domain: host                 |\r\n|               | redundancy:                          |\r\n|               |   m: 1                               |\r\n|               |   type: raid1                        |\r\n|               | tier: 0                              |\r\n+---------------+--------------------------------------+\r\n\n\nTo detach a volume from a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\nOn the LUNs tab, click the ellipsis button of the desired LUN, and then click Detach.\n\nAlternatively, you can open Storage services > Block storage > Volumes, click the ellipsis icon of the desired volume, and then click Detach.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group volume detach <target-group> <volume>\n\n<target-group>\n\nTarget group name or ID\n<volume>\n\nVolume name or ID\n\nFor example, to detach the volume vol1 from the target group tg1, run:# vinfra service block-storage target-group volume detach tg1 vol1\n\nTo delete a volume that is not attached to a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Volumes. \nClick the ellipsis icon of the desired volume, and then click Delete.\n\nCommand-line interface\nUse the following command:vinfra service block-storage volume delete <volume>\n\n<volume>\n\nVolume name or ID\n\nFor example, to delete the volume vol1, run:# vinfra service block-storage volume delete vol1\n\nSee also\n\nManaging targets\n\nRestricting access to target groups\n\nMonitoring block storage\n\nDeleting target groups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage volume set [--read-ops-limit <iops>] [--write-ops-limit <iops>]\r\n                                        [--read-bps-limit <MiB/s>] [--write-bps-limit <MiB/s>] <volume>\n\n--read-ops-limit <iops>\n\nNumber of read operations per second\n--write-ops-limit <iops>\n\nNumber of write operations per second\n--read-bps-limit <MiB/s>\n\nNumber of mebibytes read per second\n--write-bps-limit <MiB/s>\n\nNumber of mebibytes written per second\n<volume>\n\nVolume name or ID\n\nFor example, to limit the IOPS and throughput of the volume vol1 to 100 IOPS and 100 MiB/s, run:# vinfra service block-storage volume set vol1 --read-ops-limit 100 --read-bps-limit 100 \\\r\n--write-ops-limit 100 --write-bps-limit 100\nYou can check that the limits are successfully applied in the vinfra service block-storage volume show output:# vinfra service block-storage volume show vol1\r\n+---------------+--------------------------------------+\r\n| Field         | Value                                |\r\n+---------------+--------------------------------------+\r\n| grp_id        | 1b661da7-cb4d-4b81-9f09-f8ad54fa631e |\r\n| grp_name      | tg1                                  |\r\n| id            | 9841d72f-5d68-4659-82d5-cd96cf1031b6 |\r\n| limits        | read:                                |\r\n|               |   bps: 104857600                     |\r\n|               |   ops: 100                           |\r\n|               | write:                               |\r\n|               |   bps: 104857600                     |\r\n|               |   ops: 100                           |\r\n| lun           | 0                                    |\r\n| name          | vol1                                 |\r\n| serial        | cd96cf1031b6                         |\r\n| size          | 107374182400                         |\r\n| used_size     | 1048576                              |\r\n| volume_params | failure_domain: host                 |\r\n|               | redundancy:                          |\r\n|               |   m: 1                               |\r\n|               |   type: raid1                        |\r\n|               | tier: 0                              |\r\n+---------------+--------------------------------------+\r\n\n",
                "title": "To set a read/write limit for a volume attached as a LUN"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group volume detach <target-group> <volume>\n\n<target-group>\n\nTarget group name or ID\n<volume>\n\nVolume name or ID\n\nFor example, to detach the volume vol1 from the target group tg1, run:# vinfra service block-storage target-group volume detach tg1 vol1\n",
                "title": "To detach a volume from a target group"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage volume delete <volume>\n\n<volume>\n\nVolume name or ID\n\nFor example, to delete the volume vol1, run:# vinfra service block-storage volume delete vol1\n",
                "title": "To delete a volume that is not attached to a target group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\n\n\n\n\nOn the LUNs tab, click the desired LUN to open its details, then click the pencil icon in the Limits field.\n\nIn the Set LUN limit window, enter limit values, and then click Save.\n\n\n\n\n\n\nThe set limits will be shown in LUN details.\n",
                "title": "To set a read/write limit for a volume attached as a LUN"
            },
            {
                "example": "\nAdmin panel\n\n\nOpen Storage services > Block storage > Target groups, click the name of the desired target group to open it.\n\n\n\n\n\nOn the LUNs tab, click the ellipsis button of the desired LUN, and then click Detach.\n\nAlternatively, you can open Storage services > Block storage > Volumes, click the ellipsis icon of the desired volume, and then click Detach.\n",
                "title": "To detach a volume from a target group"
            },
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > Volumes. \nClick the ellipsis icon of the desired volume, and then click Delete.\n\n",
                "title": "To delete a volume that is not attached to a target group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-volumes.html"
    },
    {
        "title": "Creating load balancers",
        "content": "Creating load balancers\nLimitations\n\nThe forwarding rule and protocol cannot be changed after the load balancer pool is added.\n\nIf an IPv6 subnet where a load balancer will operate works in the SLAAC or DHCPv6 stateless mode, the load balancer will receive an IPv6 address automatically.\n\nPrerequisites\n\nA network where a load balancer will operate has IP management enabled.\nAll VMs that will be added in balancing pools have fixed IP addresses.\n\nTo create a load balancer with balancing pools\n\n\r\n                On the Load balancers screen, click Create load balancer.\r\n            \n\nIn the Create load balancer window, do the following:\n\nSpecify a name and, optionally, description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nEnable or disable high availability:With high availability enabled, two load balancer instances will be created. They will work in the Active/Standby mode according to the Virtual Router Redundancy Protocol (VRRP).With high availability disabled, a single load balancer instance will be created.\n\nSelect a flavor for the load balancer:\n\nIf high availability is enabled, you can only choose between load balancer flavors that will create two instances, one active and one standby. If the active instance becomes unhealthy, the instance automatically fails over to the standby instance, making it active.\nIf high availability is disabled, you can only choose between load balancer flavors that will create a standalone instance.\n\nIn the Network settings section, select the network that the load balancer will operate in and, optionally, specify an IP address that will be allocated to the load balancer.\n\nIf you selected a virtual network that is connected to a physical network via a router\n\nIn this case, you can assign a floating IP address to the load balancer. To do it, select Use a floating IP address, and then choose either to use an available floating IP address or to create a new one.\n\nIf you selected a shared physical network with both IPv4 and IPv6 subnets\n\nIn this case, you need to choose the IP version that will be used for the load balancer.\n\nIn the Balancing pools section, create a balancing pool to forward traffic from the load balancer to virtual machines by clicking Add. In the Create balancing pool window that opens, do the following:\n\nIn the Forwarding rule section, select a forwarding rule from the load balancer to the backend protocol:\n\nWith the HTTPS -> HTTPS rule\n\nSpecify ports for incoming and destination connections.\nEnsure that all virtual machines have the same SSL certificate (or a certificate chain).\n\nEnable the PROXY protocol version 1 to add a human-readable header with connection information (the source IP address, destination IP address, and port numbers) as a part of the request header.\n\nWith the HTTPS -> HTTP rule\n\nSpecify ports for incoming and destination connections.\nUpload an SSL certificate (or a certificate chain) in the PEM format and a private key in the PEM format.\n\nChoose HTTP headers to insert into the request.\n\nEnable the TLS encryption to re-encrypt traffic from the load balancer to its members.\n\nEnable the PROXY protocol version 1 to add a human-readable header with connection information (the source IP address, destination IP address, and port numbers) as a part of the request header.\n\nWith the HTTP -> HTTP rule\n\nSpecify ports for incoming and destination connections.\n\nChoose HTTP headers to insert into the request.\n\nEnable the TLS encryption to re-encrypt traffic from the load balancer to its members.\n\nEnable the PROXY protocol version 1 to add a human-readable header with connection information (source IP address, destination IP address, and port numbers) as a part of the request header.\n\nWith the TCP -> TCP rule\n\nSpecify ports for incoming and destination connections.\n\nEnable the TLS encryption to re-encrypt traffic from the load balancer to its members.\n\nWith the UDP -> UDP rule\n\nSpecify ports for incoming and destination connections.\n\nIn the Balancing settings section, do the following:\n\nSelect the balancing algorithm:\n\nLeast connections. Requests will be forwarded to the VM with the least number of active connections.\nRound robin. All VMs will receive requests in the round-robin manner.\nSource IP. Requests from a unique source IP address will be directed to the same VM.\n\nSelect Sticky session to enable session persistence. The load balancer will generate a cookie that will be inserted into each response. The cookie will be used to send future requests to the same VM.\n\nThis option is not available in the SSL passthrough mode.\n\nIn the Members section, add members, that is, virtual machines, to the balancing pool by clicking Add. Each VM can be included to multiple balancing pools. In the Add members window that opens, select the desired VMs, and then click Add.\n\nYou can select only between VMs that are connected to the chosen network.\n\nIn the Allowed CIDRs section, specify IP address ranges in the CIDR format that will be allowed to interact with the balancing pool. This will limit incoming traffic to the specified IP addresses, any other incoming traffic will be rejected. For example:\n\nTo limit traffic from the IP address 10.10.10.10, add the /32 suffix: 10.10.10.10/32.\nTo limit traffic from the subnet range 10.10.10.0\u00e2\u0080\u009310.10.10.255, add the /24 suffix: 10.10.10.10/24.\nTo limit traffic from the subnet range 10.10.0.0 - 10.10.255.255, add the /16 suffix: 10.10.10.10/16.\n\nIn the Health monitor section, select the protocol that will be used for monitoring members availability:\n\nHTTP/HTTPS. The HTTP/HTTPS method GET will be used to check for the response status code 200. Additionally, specify the URL path to the health monitor.\nTCP/UDP. The health monitor will check the TCP/UDP connection on the backend port.\nPING. The health monitor will check members\u00e2\u0080\u0099 IP addresses.\n\nBy default, the health monitor removes a member from a balancing pool if it fails three consecutive health checks of five-second intervals. When a member returns to operation and responds successfully to three consecutive health checks, it is added to the pool again. You can manually set the health monitor parameters, such as the interval after which VM health is checked, the time after which the monitor times out, healthy and unhealthy thresholds. To change the default parameters, click Edit parameters, enter the desired values, and then click Save.\n\n\r\n                                Click Create.\r\n                     \n\n\r\n                        Add more balancing pools, as described above.\r\n                    \n\nClick Create.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-load-balancers.html"
    },
    {
        "title": "Showing floating IP details",
        "content": "Showing floating IP detailsGET /v2.0/floatingips/{floatingip_id}\r\n\nShows details of a floating IP.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-floating-ip-details-detail#show-floating-ip-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingip_id\n\npath\nstring\nThe ID of the floating IP address.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/floatingips/239fe333-b801-4096-a04f-20f33f6177c3\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingip\n\nbody\nobject\nA floatingip object. When you associate a\r\nfloating IP address with a VM, the instance has the same public IP\r\naddress each time that it boots, basically to maintain a\r\nconsistent IP address for maintaining DNS assignment.\n\nid\n\nbody\nstring\nThe ID of the floating IP address.\n\nrouter_id\n\nbody\nstring\nThe ID of the router for the floating IP.\n\nstatus\n\nbody\nstring\nThe status of the floating IP. Values are\r\nACTIVE, DOWN and ERROR.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\ndns_name\n\nbody\nstring\nA valid DNS name.\n\nport_details\n\nbody\nstring\nThe information of the port that this floating IP associates with.\r\nIn particular, if the floating IP is associated with a port, this field\r\ncontains some attributes of the associated port, including name,\r\nnetwork_id, mac_address, admin_state_up, status,\r\ndevice_id and device_owner. If the floating IP is not associated\r\nwith a port, this field is null.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nfloating_network_id\n\nbody\nstring\nThe ID of the network associated with the\r\nfloating IP.\n\nfixed_ip_address\n\nbody\nstring\nThe fixed IP address that is associated with the\r\nfloating IP address.\n\nfloating_ip_address\n\nbody\nstring\nThe floating IP address.\n\nport_id\n\nbody\nstring\n\nThe ID of a port associated with the floating IP.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\nport_forwardings\n\nbody\narray\nThe associated port forwarding resources for the floating IP. If the\r\nfloating IP has multiple port forwarding resources, this field has\r\nmultiple entries. Each entry consists of network IP protocol\r\n(protocol), the fixed IP address of internal neutron port\r\n(internal_ip_address), the TCP or UDP port used by internal\r\nneutron port (internal_port) and the TCP or UDP port used by\r\nfloating IP (external_port).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"floatingip\": {\r\n    \"router_id\": \"02542148-44cb-470d-a551-58f370c47b83\",\r\n    \"status\": \"ACTIVE\",\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-03-04T16:37:27Z\",\r\n    \"updated_at\": \"2020-03-04T16:37:32Z\",\r\n    \"floating_network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n    \"port_details\": {\r\n      \"status\": \"ACTIVE\",\r\n      \"name\": \"\",\r\n      \"admin_state_up\": true,\r\n      \"network_id\": \"c4e2f31b-fe3b-402b-ac1b-b182693f72f7\",\r\n      \"device_owner\": \"compute:nova\",\r\n      \"mac_address\": \"fa:16:3e:66:ab:b3\",\r\n      \"device_id\": \"e1ae6f7e-c35d-4656-a4fd-2371f9a791d4\"\r\n    },\r\n    \"fixed_ip_address\": \"192.168.0.112\",\r\n    \"floating_ip_address\": \"10.94.139.170\",\r\n    \"revision_number\": 1,\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"port_id\": \"165d5ff3-d015-4361-9bce-d59054c585cf\",\r\n    \"id\": \"239fe333-b801-4096-a04f-20f33f6177c3\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-floating-ip-details.html"
    },
    {
        "title": "Adding swap space",
        "content": "Adding swap space\nTo support the RAM overcommitment ratio, you need to add swap space. The swap size depends on the chosen RAM overcommitment ratio and  can be calculated by using the following formula:(total RAM \u00e2\u0080\u0093 RAM used for system) * (RAM overcommitment ratio \u00e2\u0080\u0093 1)\nTo better understand how the minimum swap size is calculated, consider the following example:\n\nThe total amount of physical RAM on a compute node is 24 GiB\n8 GiB of RAM is reserved for the system\nThe desired RAM overcommitment ratio is 1.5\n\nAccording to the formula, the minimum required swap size will be 8 GiB. After calculating the required swap size, proceed to configuring swap space by creating a swap file.\nLimitations\n\nAfter the swap file is created, its size cannot be modified.\n\nPrerequisites\n\nTo be able to create a swap file, the root directory must have 100 GiB of free space after the swap file creation. For example, to create a swap file of 8 GiB, ensure that at least 108 GiB is available in the root directory.\n\nTo create a swap file\nOn a compute node, execute the configure-swap.sh script specifying the desired swap size:# /usr/libexec/vstorage-ui-agent/bin/configure-swap.sh -s 8192\nThe script creates a swap file, prepares the swap space, and adds the swap mount point to /etc/fstab.\nTo enable RAM overcommitment for the entire compute cluster, execute this script on each compute node.\nTo check that the swap file is successfully created, run:# swapon -s\r\nFilename               Type         Size    Used    Priority\r\n/dev/sda3              partition    8258556    0    -2\r\n/swapfile0             file         8389628    0    -3\nTo increase the swap size\nAdd another swap file by running:# /usr/libexec/vstorage-ui-agent/bin/configure-swap.sh -s 8192 --append\nFor the entire compute cluster, execute this script on each compute node.\nWhat's next\n\nEnabling and disabling RAM overcommitment",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-swap-space.html"
    },
    {
        "title": "Updating IPsec policies",
        "content": "Updating IPsec policiesPUT /v2.0/vpn/ipsecpolicies/{ipsecpolicy_id}\nUpdate policy settings in an IPsec policy.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=update-ipsec-policy-detail#update-ipsec-policy\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicy_id\n\npath\nstring\nThe ID of the IPsec policy.\n\nipsecpolicy\n\nbody\nobject\nAn ipsecpolicy object.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencapsulation_mode (Optional)\nbody\nstring\nThe encapsulation mode. A valid value is tunnel or transport. Default is tunnel.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\ntransform_protocol (Optional)\nbody\nstring\nThe transform protocol. A valid value is ESP, AH, or AH- ESP. Default is ESP.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"ipsecpolicy\": {\r\n        \"pfs\": \"group14\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/ipsecpolicies/805ab779-e91c-42db-b6b9-591156d9634e\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicies\n\nbody\narray\nA list of ipsecpolicy objects.\n\nipsecpolicy\n\nbody\nobject\nAn ipsecpolicy object.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencapsulation_mode (Optional)\nbody\nstring\nThe encapsulation mode. A valid value is tunnel or transport. Default is tunnel.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\ntransform_protocol (Optional)\nbody\nstring\nThe transform protocol. A valid value is ESP, AH, or AH- ESP. Default is ESP.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IPsec policy.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"ipsecpolicy\": {\r\n    \"id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"ipsecpolicy1\",\r\n    \"description\": \"\",\r\n    \"transform_protocol\": \"esp\",\r\n    \"auth_algorithm\": \"sha1\",\r\n    \"encryption_algorithm\": \"aes-128\",\r\n    \"encapsulation_mode\": \"tunnel\",\r\n    \"lifetime\": {\r\n      \"units\": \"seconds\",\r\n      \"value\": 7200\r\n    },\r\n    \"pfs\": \"group14\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-ipsec-policies.html"
    },
    {
        "title": "Changing TLS configuration for backup storage",
        "content": "Changing TLS configuration for backup storage\nTo filter connections to backup storage, an administrator can configure allowed TLS protocol versions and ciphers. By default, only TLS protocol version 1.2 is accepted and recommended to use for connections to backup storage.\nTo change the default TLS protocol version\nSpecify the appropriate value in the advanced.min_tls_version parameter in the /etc/vstorage/abgw.config file. The following values are available:\r\n\n\n0: Allows 1.0, 1.1, and 1.2 TLS protocol versions\n1: Allows 1.1 and 1.2 TLS protocol versions\n2: Allows only 1.2 TLS protocol version\n\nFor example, to allow using the 1.1 and 1.2 TLS protocol versions, do the following:\n\nIn /etc/vstorage/abgw.config, set the advanced.min_tls_version parameter to 1:advanced.min_tls_version=1\n\nRestart the service:# systemctl restart vstorage-abgw\n\nThis operation should be performed on all backup storage nodes.\nTo accept connections to backup storage only with particular TLS ciphers\nSpecify them in the advanced.tls_ciphers parameter in the /etc/vstorage/abgw.config file. For the cipher format and full set, refer to the cipher list section in the ciphers manual page.\n\nAfter changing the allowed TLS ciphers, you may need to regenerate certificates.\n\nIf a client has none of the specified ciphers, the connection will fail and the client will not be able to reach the service. \n\nBy default, the following ciphers are used:\n\nECDHE-ECDSA-CHACHA20-POLY1305\nECDHE-RSA-CHACHA20-POLY1305\nECDHE-ECDSA-AES256-GCM-SHA384\nECDHE-RSA-AES256-GCM-SHA384\nECDHE-ECDSA-AES128-GCM-SHA256\nECDHE-RSA-AES128-GCM-SHA256\nECDHE-ECDSA-AES128-SHA256\nECDHE-RSA-AES128-SHA256\nDHE-RSA-AES128-GCM-SHA256\nDHE-RSA-AES128-SHA256\nECDHE-RSA-AES256-SHA\nECDHE-ECDSA-AES128-SHA\nECDHE-RSA-AES128-SHA\nDHE-RSA-AES128-SHA\nAES128-GCM-SHA256\nAES128-SHA256\nAES128-SHA\n\nNote the following:\n\nIf you specify one cipher (for example, RSA-AES128) and it is not supported, the connection will fail. \nIf you specify two ciphers (for example, CAMELIA and RSA-AES128) and only one of them is supported (for example, CAMELIA), the connection will be established based on the supported cipher (in this case, CAMELIA).\nIf you specify an empty value, all connections will fail.\n\nFor example, to limit the allowed TLS ciphers only to ECDHE-ECDSA-CHACHA20-POLY1305 and ECDHE-RSA-CHACHA20-POLY1305, do the following:\n\nIn /etc/vstorage/abgw.config, specify the required ciphers, separated by colons, in the advanced.tls_ciphers parameter:\r\nadvanced.tls_ciphers=ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305\n\nRestart the service:# systemctl restart vstorage-abgw\n\nThis operation should be performed on all backup storage nodes.\nSee also\n\nChanging the redundancy scheme for backup storage\n\nManaging registrations for backup storage\n\nManaging geo-replication for backup storage\n\nReleasing nodes from backup storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-tls-configuration-for-backup-storage.html"
    },
    {
        "title": "Showing Kubernetes cluster details",
        "content": "Showing Kubernetes cluster detailsGET /v1/clusters/{cluster_ident}\r\n\nShow details of a Kubernetes cluster with the specified ID.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=show-details-of-a-cluster-detail#show-details-of-a-cluster\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ncluster_ident\n\npath\nstring\nThe UUID or name of clusters in Magnum.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<..>' \\\r\nhttps://<node_IP_addr>:9513/v1/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nstatus\n\nbody\nstring\nThe current state of the bay/cluster.\n\nuuid\n\nbody\nUUID\nThe UUID of the cluster.\n\nlinks\n\nbody\narray\nLinks to the resources in question.\n\nstack_id\n\nbody\nUUID\nThe reference UUID of orchestration stack from Heat orchestration service.\n\nname\n\nbody\nstring\nName of the resource.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\napi_address\n\nbody\nstring\nThe endpoint URL of COE API exposed to end users.\n\ndiscovery_url\n\nbody\nstring\n\nThe custom discovery URL for node discovery. This is used by the COE to\r\ndiscover the servers that have been created to host the containers. The\r\nactual discovery mechanism varies with the COE. In some cases, Magnum fills\r\nin the server info in the discovery service. In other cases, if the\r\ndiscovery_url is not specified, Magnum will use the public discovery\r\nservice at:https://discovery.etcd.io\r\n\nIn this case, Magnum will generate a unique URL here for each bay and\r\nstore the info for the servers.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nmaster_count\n\nbody\ninteger\nThe number of servers that will serve as master for the bay/cluster. The\r\ndefault is 1. Set to more than 1 master to enable High Availability. If\r\nthe option master-lb-enabled is specified in the baymodel/cluster\r\ntemplate, the master servers will be placed in a load balancer pool.\n\ncoe_version\n\nbody\nstring\nVersion info of chosen COE in bay/cluster for helping client in picking\r\nthe right version of client.\n\ncluster_template_id\n\nbody\nUUID\nThe UUID of the cluster template.\n\nnode_count\n\nbody\ninteger\nThe number of servers that will serve as node in the bay/cluster. The\r\ndefault is 1.\n\nkeypair\n\nbody\nstring\nThe name of the SSH keypair to configure in the bay/cluster servers\r\nfor ssh access. Users will need the key to be able to ssh to the servers in\r\nthe bay/cluster. The login name is specific to the bay/cluster driver, for\r\nexample with fedora-atomic image, default login name is fedora.\n\nmaster_addresses\n\nbody\narray\nList of floating IP of all master nodes.\n\nnode_addresses\n\nbody\narray\nList of floating IP of all servers that serve as node.\n\nstatus_reason\n\nbody\nstring\nThe reason of bay/cluster current status.\n\ncreate_timeout\n\nbody\ninteger\nThe timeout for cluster creation in minutes. The value expected is a\r\npositive integer and the default is 60 minutes. If the timeout is reached\r\nduring cluster creation process, the operation will be aborted and the\r\ncluster status will be set to CREATE_FAILED.\n\nlabels (Optional)\nbody\narray\nArbitrary labels in the form of key=value pairs. The accepted keys and\r\nvalid values are defined in the bay/cluster drivers. They are used as a way\r\nto pass additional parameters that are specific to a bay/cluster driver.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"create_timeout\": 60,\r\n  \"links\": [\r\n    {\r\n      \"href\": \"https://<node_IP_addr>:9513/v1/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea\",\r\n      \"rel\": \"self\"\r\n    },\r\n    {\r\n      \"href\": \"https://<node_IP_addr>:9513/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea\",\r\n      \"rel\": \"bookmark\"\r\n    }\r\n  ],\r\n  \"labels\": {\r\n    \"kube_tag\": \"v1.15.6\",\r\n    \"cloud_provider_enabled\": \"true\",\r\n    \"cloud_provider_tag\": \"v1.15.0\",\r\n    \"kube_version\": \"v1.15.6\",\r\n    \"boot_volume_type\": \"default\",\r\n    \"flannel_tag\": \"v0.11.0-amd64\",\r\n    \"boot_volume_size\": \"10\",\r\n    \"heat_container_agent_tag\": \"hci-3.5-latest\",\r\n    \"docker_volume_type\": \"default\"\r\n  },\r\n  \"updated_at\": \"2020-04-11T20:17:49+00:00\",\r\n  \"keypair\": \"key1\",\r\n  \"master_flavor_id\": \"medium\",\r\n  \"health_status_reason\": {\r\n    \"k8s1-fwhg7cuxplnc-master-1.Ready\": \"True\",\r\n    \"api\": \"ok\",\r\n    \"k8s1-fwhg7cuxplnc-master-0.Ready\": \"True\",\r\n    \"k8s1-fwhg7cuxplnc-minion-0.Ready\": \"True\"\r\n  },\r\n  \"user_id\": \"2a55cfc7747b4383b0856a0a622914dd\",\r\n  \"uuid\": \"01d0583d-e8b3-483f-896f-08d2260b0dea\",\r\n  \"api_address\": \"https://10.94.129.74:6443\",\r\n  \"master_addresses\": [\r\n    \"10.94.129.77\",\r\n    \"10.94.129.75\"\r\n  ],\r\n  \"node_count\": 1,\r\n  \"project_id\": \"888ea5e76b284d83a18b3bfaa6fdde16\",\r\n  \"status\": \"CREATE_COMPLETE\",\r\n  \"docker_volume_size\": 10,\r\n  \"template_delete_on_termination\": true,\r\n  \"master_count\": 2,\r\n  \"node_addresses\": [\r\n    \"10.94.129.79\"\r\n  ],\r\n  \"status_reason\": \"Stack CREATE completed successfully\",\r\n  \"coe_version\": \"v1.15.6\",\r\n  \"cluster_template_id\": \"4aceb259-3799-4a6a-85ef-7f9857b41462\",\r\n  \"name\": \"k8s1\",\r\n  \"stack_id\": \"dbfad3ec-2caf-43ef-839b-3c8dc0bdb1f8\",\r\n  \"created_at\": \"2020-04-11T19:54:55+00:00\",\r\n  \"discovery_url\": \"https://discovery.etcd.io/ffc39d4a95a6ca0abec545a506fd298d\",\r\n  \"health_status\": \"HEALTHY\",\r\n  \"flavor_id\": \"small\",\r\n  \"container_version\": \"1.12.6\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-kubernetes-cluster-details.html"
    },
    {
        "title": "Managing S3 user and bucket limits via REST API",
        "content": "Managing S3 user and bucket limits via REST API\nThis section describes limits you can define for users and buckets via REST API. You can apply the limits according to specific options that can be a part of your service plan.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-user-and-bucket-limits-via-rest-api.html"
    },
    {
        "title": "Updating virtual machines configuration",
        "content": "Updating virtual machines configurationPUT /servers/{server_id}\r\n\nUpdate the editable attributes of a VM with the specified ID. One parameter at a time.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=update-server-detail#update-server\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nserver\n\nbody\nobject\nA server object.\n\nname (Optional)\nbody\nstring\nThe server name.\n\naccessIPv4 (Optional)\nbody\nstring\nIPv4 address that should be used to access this server.\n\naccessIPv6 (Optional)\nbody\nstring\nIPv6 address that should be used to access this server.\n\nOS-DCF:diskConfig (Optional)\nbody\nstring\n\nControls how the API partitions the disk when you create, rebuild, or resize servers.\r\nA server inherits the OS-DCF:diskConfig value from the image from which it\r\nwas created, and an image inherits the OS-DCF:diskConfig value from the server\r\nfrom which it was created. To override the inherited setting, you can include\r\nthis attribute in the request body of a server create, rebuild, or resize request.  If\r\nthe OS-DCF:diskConfig value for an image is MANUAL, you cannot create\r\na server from that image and set its OS-DCF:diskConfig value to AUTO.\r\nA valid value is:\n\nAUTO. The API builds the server with a single partition the size of the\r\ntarget flavor disk. The API automatically adjusts the file system to fit the\r\nentire partition.\nMANUAL. The API builds the server by using whatever partition scheme and\r\nfile system is in the source image. If the target flavor disk is larger, the API\r\ndoes not partition the remaining disk space.\n\ndescription (Optional)\nbody\nstring\n\nA free form description of the server. Limited to 255 characters\r\nin length. Before microversion 2.19 this was set to the server\r\nname.\nNew in version 2.19\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"server\": {\r\n    \"name\": \"vm1-renamed\"\r\n  }\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/642b7726-bc3b-4824-872b-124097d2d20c\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nserver\n\nbody\nobject\nA server object.\n\nid\n\nbody\nstring\nThe UUID of the server.\n\nlinks\n\nbody\narray\nLinks to the resources in question. See API Guide / Links and\r\nReferences\r\nfor more info.\n\nname\n\nbody\nstring\nThe server name.\n\naccessIPv4\n\nbody\nstring\nIPv4 address that should be used to access this server. May be\r\nautomatically set by the provider.\n\naccessIPv6\n\nbody\nstring\nIPv6 address that should be used to access this server. May be\r\nautomatically set by the provider.\n\naddresses\n\nbody\nobject\nThe addresses for the server.  Servers with status BUILD hide their\r\naddresses information.\n\nsecurity_groups (Optional)\nbody\narray\n\nOne or more security groups objects.\nNew in version 2.75\n\nsecurity_groups.name\n\nbody\nstring\n\nThe security group name.\nNew in version 2.75\n\nconfig_drive\n\nbody\nstring\nIndicates whether or not a config drive was used for this server.\r\nThe value is True or an empty string. An empty string stands for\r\nFalse.\n\ncreated\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nflavor\n\nbody\nobject\n\nBefore microversion 2.47 this contains the ID and links for the flavor\r\nused to boot the server instance. This can be an empty object in case\r\nflavor information is no longer present in the system.\nAs of microversion 2.47 this contains a subset of the actual flavor\r\ninformation used to create the server instance, represented as a nested\r\ndictionary.\n\nflavor.id\n\nbody\nstring\n\nThe ID of the flavor. While people often make this look like\r\nan int, this is really a string.\nAvailable until version 2.46\n\nflavor.links\n\nbody\narray\n\nLinks to the flavor resource. See API Guide / Links and\r\nReferences\r\nfor more details.\nAvailable until version 2.46\n\nflavor.vcpus\n\nbody\ninteger\n\nThe number of virtual CPUs that were allocated to the server.\nNew in version 2.47\n\nflavor.ram\n\nbody\ninteger\n\nThe amount of RAM a flavor has, in MiB.\nNew in version 2.47\n\nflavor.disk\n\nbody\ninteger\n\nThe size of the root disk that was created in GiB.\nNew in version 2.47\n\nflavor.ephemeral\n\nbody\ninteger\n\nThe size of the ephemeral disk that was created, in GiB.\nNew in version 2.47\n\nflavor.swap\n\nbody\ninteger\n\nThe size of a dedicated swap disk that was allocated, in MiB.\nNew in version 2.47\n\nflavor.original_name\n\nbody\nstring\n\nThe display name of a flavor.\nNew in version 2.47\n\nflavor.extra_specs (Optional)\nbody\nobject\n\nA dictionary of the flavor\u00e2\u0080\u0099s extra-specs key-and-value pairs.  This will\r\nonly be included if the user is allowed by policy to index flavor\r\nextra_specs.\nNew in version 2.47\n\nflavor.extra_specs.key\n\nbody\nstring\n\nThe extra spec key of a flavor.\nNew in version 2.47\n\nflavor.extra_specs.value\n\nbody\nstring\n\nThe extra spec value of a flavor.\nNew in version 2.47\n\nhostId\n\nbody\nstring\nAn ID string representing the host. This is a hashed value so will not actually look like\r\na hostname, and is hashed with data from the project_id, so the same physical host as seen\r\nby two different project_ids, will be different. It is useful when within the same project you\r\nneed to determine if two instances are on the same or different physical hosts for the\r\npurposes of availability or performance.\n\nhost_status (Optional)\nbody\nstring\n\nThe host status. Values where next value in list can override the previous:\n\nUP if nova-compute up.\nUNKNOWN if nova-compute not reported by servicegroup driver.\nDOWN if nova-compute forced down.\nMAINTENANCE if nova-compute is disabled.\nEmpty string indicates there is no host for server.\n\nThis attribute appears in the response only if the policy permits.\r\nBy default, only administrators can get this parameter.\nNew in version 2.75\n\nimage\n\nbody\nobject\nThe UUID and links for the image for your server instance. The image object\r\nwill be an empty string when you boot the server from a volume.\n\nkey_name\n\nbody\nstring\n\nThe name of associated key pair, if any.\nNew in version 2.75\n\nlocked\n\nbody\nboolean\n\nTrue if the instance is locked otherwise False.\nNew in version 2.9\n\nlocked_reason\n\nbody\nstring\n\nThe reason behind locking a server.\nNew in version 2.73\n\nmetadata\n\nbody\nobject\nA dictionary of metadata key-and-value pairs, which is maintained for backward\r\ncompatibility.\n\nOS-DCF:diskConfig\n\nbody\nstring\n\nDisk configuration. The value is either:\n\nAUTO: The API builds the server with a single partition the size of\r\nthe target flavor disk. The API automatically adjusts the file system to\r\nfit the entire partition.\nMANUAL: The API builds the server by using the partition scheme and\r\nfile system that is in the source image. If the target flavor disk is\r\nlarger, The API does not partition the remaining disk space.\n\nOS-EXT-AZ:availability_zone\n\nbody\nstring\nThe availability zone name.\n\nOS-EXT-SRV-ATTR:host\n\nbody\nstring\nThe name of the compute host on which this instance is running.\r\nAppears in the response for administrative users only.\n\nOS-EXT-SRV-ATTR:hostname (Optional)\nbody\nstring\n\nThe hostname set on the instance when it is booted.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.75\n\nOS-EXT-SRV-ATTR:hypervisor_hostname\n\nbody\nstring\nThe hypervisor host name provided by the Nova virt driver. For the Ironic driver,\r\nit is the Ironic node UUID. Appears in the response for administrative users only.\n\nOS-EXT-SRV-ATTR:instance_name\n\nbody\nstring\nThe instance name. The Compute API generates the instance name from the instance\r\nname template. Appears in the response for administrative users only.\n\nOS-EXT-SRV-ATTR:kernel_id (Optional)\nbody\nstring\n\nThe UUID of the kernel image when using an AMI. Will be null if not.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.75\n\nOS-EXT-SRV-ATTR:launch_index (Optional)\nbody\ninteger\n\nWhen servers are launched via multiple create, this is the\r\nsequence in which the servers were launched.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.75\n\nOS-EXT-SRV-ATTR:reservation_id (Optional)\nbody\nstring\n\nThe reservation id for the server. This is an id that can\r\nbe useful in tracking groups of servers created with multiple\r\ncreate, that will all have the same reservation_id.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.75\n\nOS-EXT-SRV-ATTR:ramdisk_id (Optional)\nbody\nstring\n\nThe UUID of the ramdisk image when using an AMI. Will be null if not.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.75\n\nOS-EXT-SRV-ATTR:root_device_name (Optional)\nbody\nstring\n\nThe root device name for the instance\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.75\n\nOS-EXT-SRV-ATTR:user_data (Optional)\nbody\nstring\n\nThe user_data the instance was created with.\r\nBy default, it appears in the response for administrative users only.\nNew in version 2.75\n\nOS-EXT-STS:power_state\n\nbody\ninteger\n\nThe power state of the instance. This is an enum value that is mapped as:\n\n0: NOSTATE\r\n1: RUNNING\r\n3: PAUSED\r\n4: SHUTDOWN\r\n6: CRASHED\r\n7: SUSPENDED\r\n8: SHUTDOWN_ACTIVE\r\n\n\nOS-EXT-STS:task_state\n\nbody\nstring\n\nThe task state of the instance.\nNew in version 2.75\n\nOS-EXT-STS:vm_state\n\nbody\nstring\n\nThe VM state.\nNew in version 2.75\n\nos-extended-volumes:volumes_attached\n\nbody\narray\n\nThe attached volumes, if any.\nNew in version 2.75\n\nos-extended-volumes:volumes_attached.id\n\nbody\nstring\n\nThe attached volume ID.\nNew in version 2.75\n\nos-extended-volumes:volumes_attached.delete_on_termination\n\nbody\nboolean\n\nA flag indicating if the attached volume will be deleted\r\nwhen the server is deleted. By default this is False.\nNew in version 2.75\n\nOS-SRV-USG:launched_at\n\nbody\nstring\n\nThe date and time when the server was launched.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nIf the deleted_at date and time stamp is not set, its value is null.\nNew in version 2.75\n\nOS-SRV-USG:terminated_at\n\nbody\nstring\n\nThe date and time when the server was deleted.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nIf the deleted_at date and time stamp is not set, its value is null.\nNew in version 2.75\n\ndescription\n\nbody\nstring\n\nThe description of the server.\r\nBefore microversion 2.19 this was set to the server name.\nNew in version 2.19\n\nserver_groups\n\nbody\narray\n\nThe UUIDs of the server groups to which the server belongs. Currently\r\nthis can contain at most one entry.\nNew in version 2.71\n\ntags\n\nbody\narray\n\nA list of tags. The maximum count of tags in this list is 50.\nNew in version 2.26\n\ntrusted_image_certificates\n\nbody\narray\n\nA list of trusted certificate IDs, that were used during image signature\r\nverification to verify the signing certificate. The list is restricted\r\nto a maximum of 50 IDs. The value is null if trusted certificate IDs\r\nare not set.\nNew in version 2.63\n\nprogress (Optional)\nbody\ninteger\nA percentage value of the operation progress.\r\nThis parameter only appears when the server status is ACTIVE,\r\nBUILD, REBUILD, RESIZE, VERIFY_RESIZE or MIGRATING.\n\nstatus\n\nbody\nstring\nThe server status.\n\ntenant_id\n\nbody\nstring\nThe UUID of the tenant in a multi-tenancy cloud.\n\nupdated\n\nbody\nstring\n\nThe date and time when the resource was updated.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nuser_id\n\nbody\nstring\nThe user ID of the user who owns the server.\n\nfault (Optional)\nbody\nobject\nA fault object. Only displayed when the server status is ERROR or\r\nDELETED and a fault occurred.\n\nfault.code\n\nbody\ninteger\nThe error response code.\n\nfault.created\n\nbody\nstring\n\nThe date and time when the exception was raised.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nfault.message\n\nbody\nstring\nThe error message.\n\nfault.details (Optional)\nbody\nstring\nThe stack trace. It is available if the response code is not 500 or\r\nyou have the administrator privilege\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"server\": {\r\n    \"status\": \"ACTIVE\",\r\n    \"updated\": \"2020-02-10T12:53:35Z\",\r\n    \"hostId\": \"07a515b19bd643cd2422089ea20d5043e1161004b62e297f4e52196f\",\r\n    \"user_id\": \"eb481bff7b7c4ec6a686646957d8064b\",\r\n    \"name\": \"vm1-renamed\",\r\n    \"links\": [\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/642b7726-bc3b-4824-872b-124097d2d20c\",\r\n        \"rel\": \"self\"\r\n      },\r\n      {\r\n        \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/servers/642b7726-bc3b-4824-872b-124097d2d20c\",\r\n        \"rel\": \"bookmark\"\r\n      }\r\n    ],\r\n    \"created\": \"2020-02-10T12:37:42Z\",\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"image\": \"\",\r\n    \"OS-DCF:diskConfig\": \"MANUAL\",\r\n    \"addresses\": {\r\n      \"public\": [\r\n        {\r\n          \"version\": 4,\r\n          \"addr\": \"10.94.139.172\"\r\n        }\r\n      ],\r\n      \"private\": [\r\n        {\r\n          \"version\": 4,\r\n          \"addr\": \"192.168.128.88\"\r\n        }\r\n      ]\r\n    },\r\n    \"accessIPv4\": \"\",\r\n    \"accessIPv6\": \"\",\r\n    \"progress\": 0,\r\n    \"flavor\": {\r\n      \"id\": \"100\",\r\n      \"links\": [\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8774/f5d834d636c642c7bfe8af86139c6f26/flavors/100\",\r\n          \"rel\": \"bookmark\"\r\n        }\r\n      ]\r\n    },\r\n    \"id\": \"642b7726-bc3b-4824-872b-124097d2d20c\",\r\n    \"metadata\": {\r\n      \"ha_enabled\": \"True\"\r\n    }\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-virtual-machines-configuration.html"
    },
    {
        "title": "Performing actions on virtual machines",
        "content": "Performing actions on virtual machinesPOST /servers/{server_id}/action\r\n\nPerform an action on a virtual machine with the specified ID.\nThe request parameters depend on the action. For the list of parameters, follow the source link below.\nSource: https://docs.openstack.org/api-ref/compute/#servers-run-an-action-servers-action\nRequest\nExample 1\nSuspend a VM with the specified ID.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"suspend\": null\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/c3f154f1-c656-49b4-a6c0-4dd1e088817c/action\r\n\nExample 2\nResume a VM with the specified ID.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"resume\": null\r\n}' https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/c3f154f1-c656-49b4-a6c0-4dd1e088817c/action\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/performing-actions-on-virtual-machines.html"
    },
    {
        "title": "Updating VPN services",
        "content": "Updating VPN servicesPUT /v2.0/vpn/vpnservices/{service_id}\nUpdate the attributes of a VPN service.\nYou cannot update a service with a PENDING_* status.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=update-vpn-service-detail#update-vpn-service\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nservice_id\n\npath\nstring\nThe ID of the VPN service.\n\nvpnservice\n\nbody\nobject\nA vpnservice object.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"vpnservice\": {\r\n        \"description\": \"VPN service\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/vpnservices/d6116b75-db78-4d07-9911-226b4655838a\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvpnservice\n\nbody\nobject\nA vpnservice object.\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec VPN service is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nexternal_v4_ip\n\nbody\nstring\nThe read-only external (public) IPv4 address that is used for the VPN service. The VPN plugin sets this address if an IPv4 interface is available.\n\nexternal_v6_ip\n\nbody\nstring\nThe read-only external (public) IPv6 address that is used for the VPN service. The VPN plugin sets this address if an IPv6 interface is available.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\nsubnet_id (Optional)\nbody\nstring\nIf you specify only a subnet UUID, the networking service allocates an available IP from that subnet to the port. If you specify both a subnet UUID and an IP address, the networking service tries to allocate the address to the port.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nflavor_id\n\nbody\nstring\nThe ID of the flavor.\n\nid\n\nbody\nstring\nThe ID of the VPN service.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"vpnservice\": {\r\n    \"id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n    \"name\": \"vpnservice\",\r\n    \"description\": \"VPN service\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"subnet_id\": null,\r\n    \"router_id\": \"923f2578-079e-40f1-b0a9-23c2b48dbdcd\",\r\n    \"flavor_id\": null,\r\n    \"admin_state_up\": true,\r\n    \"external_v4_ip\": \"10.136.18.148\",\r\n    \"external_v6_ip\": null,\r\n    \"status\": \"ACTIVE\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-vpn-services.html"
    },
    {
        "title": "Managing notifications",
        "content": "Managing notifications\nThe notification center stores and shows notifications about recent tasks of the current user in the management panel. Notifications are displayed only for tasks performed during the current user session and cleared out when the user logs out.\nA user is informed about each task by a pop-up notification in the bottom right corner of the screen. The same notification also appears in the notification center. After the pop-up window is closed, the notification is available in the notification center.\nThe following table describes all of the supported notification types:\n\nNotification type\nIcon\nDescription\nRetention period of a pop-up window\nRetention period in the notification center\n\nInfo\n\nNotifications about a task launch\n3 seconds\n10 minutes\n\nSuccess\n\nNotifications about successfully completed tasks\n3 seconds\n10 minutes\n\nError\n\nNotifications about failed tasks\n10 seconds\n50 minutes\n\nIn progress\n\nLong-running tasks, such as image upload or problem report creation\nTask time\nTask time\n\nTo view notifications\n\nOn any screen, click the bell icon in the top right corner. Next to the bell icon, you can see the notification counter, or the loading sign if you have a running task.\nTo view notifications of a particular type, click All types, and then select the notification type you wish to be displayed in the notification center.\n\nTo clear notifications\n\nOn any screen, click the bell icon in the top right corner.\nTo clear only one notification, click the cross icon next to it.\nTo clear all of the notifications, click Clear all above the notification list.\n\nTo configure pop-up notifications\n\nOn any screen, click the bell icon in the top right corner.\n\nClick the cogwheel icon, and then clear notification types that you do not wish to be shown in a pop-up window. Only the selected notification types will appear as pop-up messages.\n\nTo mute pop-up notifications\n\nOn any screen, click the bell icon in the top right corner.\n\nClick the cogwheel icon, and then turn on the Do not disturb mode.\n\nThe bell icon will be greyed out, and the notification counter will disappear. While this mode is on, pop-up notifications are disabled. However, all notifications are still available in the notification center.\nTo unmute pop-up notifications\n\nOn any screen, click the greyed out bell icon in the top right corner.\n\nClick Turn off, to turn off the Do not disturb mode.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-notifications.html"
    },
    {
        "title": "Showing VPN endpoint group details",
        "content": "Showing VPN endpoint group detailsGET /v2.0/vpn/endpoint-groups/{endpoint_group_id}\nShows details for a VPN endpoint group.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-vpn-endpoint-group-detail#show-vpn-endpoint-group\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nendpoint_group_id\n\npath\nstring\nThe ID of the VPN endpoint group.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/endpoint-groups/e3b89342-73ee-42b9-8ee9-fd91ec36aceb\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nendpoints\n\nbody\narray\nList of endpoints of the same type, for the endpoint group. The values will depend on the type.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ntype\n\nbody\nstring\nThe type of the endpoints in the group. A valid value is subnet, cidr, network, router, or vlan. Only subnet and cidr are supported at this moment.\n\nid\n\nbody\nstring\nThe ID of the VPN endpoint group.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"endpoint_group\": {\r\n    \"id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"peers\",\r\n    \"description\": \"\",\r\n    \"type\": \"cidr\",\r\n    \"endpoints\": [\r\n      \"10.2.0.0/24\",\r\n      \"10.3.0.0/24\"\r\n    ],\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-vpn-endpoint-group-details.html"
    },
    {
        "title": "Changing the vGPU type for physical GPUs",
        "content": "Changing the vGPU type for physical GPUs\nAfter enabling vGPU for the compute cluster, you can change the vGPU type specified for a physical GPU, if necessary.\nPrerequisites\n\nThe compute cluster is reconfigured for vGPU support, as described in Enabling PCI passthrough and vGPU support.\nEnsure that the compute cluster has no virtual machines with the current vGPU type.\n\nTo change the vGPU type for a physical GPU\n\nModify the configuration file. For example, replace nvidia-224 with nvidia-228 in the vgpu_type field:- device_type: pgpu\r\n  device: \"0000:01:00.0\"\r\n  vgpu_type: nvidia-228\n\nPass the configuration file to the vinfra service compute set command. For example:# vinfra service compute set --pci-passthrough-config config.yaml\n\nReboot the node with the physical GPU to apply changes:# reboot\n\nWhat's next\n\nCreating virtual machines with virtual GPUs\n\nCreating virtual machines with different vGPU types",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-the-vgpu-type-for-physical-gpus.html"
    },
    {
        "title": "Managing NFS shares",
        "content": "Managing NFS shares\nOnce an NFS share is created, it is started automatically. You can modify its size and redundancy scheme, stop it to change its IP address, and finally delete it.\nLimitations\n\nAfter creating an NFS share, you can change only the replication redundancy scheme. Changing the encoding redundancy scheme is disabled, because it may decrease cluster performance. Re-encoding demands a significant amount of cluster resources for a long period of time. If you still want to change the redundancy scheme, contact the technical support team.\nYou can change the IP address only for stopped NFS shares.\n\nPrerequisites\n\nNFS shares are created, as described in Creating NFS shares.\n\nTo stop an NFS share\n\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nClick the line with a running share, and then click Stop on the right pane.\n\nCommand-line interface\nUse the following command:vinfra service nfs share stop [--force] <name>\n\n--force\n\nStop the NFS share forcibly\n<name>\n\nNFS share name\n\nFor example, to stop the share share1, run:# vinfra service nfs share stop share1\n\nTo restart an NFS share\n\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nClick the line with a stopped share, and then click Run on the right pane.\n\nCommand-line interface\nUse the following command:vinfra service nfs share start <name>\n\n<name>\n\nNFS share name\n\nFor example, to start the share share1, run:# vinfra service nfs share start share1\n\nTo reconfigure an NFS share\n\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nIf you want to change the IP address of a share, stop the share first. To do it, click the line with the share, and then click Stop on the right pane.\nTo change the share parameters, click Edit on the right pane.\nIn the Edit window, change the IP address, size, or replication redundancy parameters, and then click Save. \n\nCommand-line interface\nUse the following command:vinfra service nfs share set [--tier {0,1,2,3}] [--replicas <norm>] [--failure-domain {0,1,2,3,4}]\r\n                             [--size <size>] <name>\n\n--tier {0,1,2,3}\n\nStorage tier\n--replicas <norm>\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--size <size>\n\nNFS share size, in bytes. You can also specify the following units: KiB for kibibytes, MiB for mebibytes, GiB for gibibytes, TiB for tebibytes, and PiB for pebibytes.\n<name>\n\nNFS share name\n\nFor example, to increase the size of the share share1 to 200 GiB, run:# vinfra service nfs share set share1 --size 200GiB\n\nTo delete an NFS share\n\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nClick the line with a share to remove, and then click Delete on the right pane.\nIf a share has exports, it can only be deleted after deleting all of them. To delete such a share, select Delete all exports in this share, and then click Delete in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra service nfs share delete <name>\n\n<name>\n\nNFS share name\n\nFor example, to delete the share share1, run:# vinfra service nfs share delete share1\n\nSee also\n\nAuthenticating NFS share users via Kerberos\n\nManaging NFS exports\n\nMonitoring file storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs share stop [--force] <name>\n\n--force\n\nStop the NFS share forcibly\n<name>\n\nNFS share name\n\nFor example, to stop the share share1, run:# vinfra service nfs share stop share1\n",
                "title": "To stop an NFS share"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs share start <name>\n\n<name>\n\nNFS share name\n\nFor example, to start the share share1, run:# vinfra service nfs share start share1\n",
                "title": "To restart an NFS share"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs share set [--tier {0,1,2,3}] [--replicas <norm>] [--failure-domain {0,1,2,3,4}]\r\n                             [--size <size>] <name>\n\n--tier {0,1,2,3}\n\nStorage tier\n--replicas <norm>\n\n\nStorage replication mapping in the format:\n\nnorm: the number of replicas to maintain\n\n\n--failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--size <size>\n\nNFS share size, in bytes. You can also specify the following units: KiB for kibibytes, MiB for mebibytes, GiB for gibibytes, TiB for tebibytes, and PiB for pebibytes.\n<name>\n\nNFS share name\n\nFor example, to increase the size of the share share1 to 200 GiB, run:# vinfra service nfs share set share1 --size 200GiB\n",
                "title": "To reconfigure an NFS share"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs share delete <name>\n\n<name>\n\nNFS share name\n\nFor example, to delete the share share1, run:# vinfra service nfs share delete share1\n",
                "title": "To delete an NFS share"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nClick the line with a running share, and then click Stop on the right pane.\n\n",
                "title": "To stop an NFS share"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nClick the line with a stopped share, and then click Run on the right pane.\n\n",
                "title": "To restart an NFS share"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nIf you want to change the IP address of a share, stop the share first. To do it, click the line with the share, and then click Stop on the right pane.\nTo change the share parameters, click Edit on the right pane.\nIn the Edit window, change the IP address, size, or replication redundancy parameters, and then click Save. \n\n",
                "title": "To reconfigure an NFS share"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Storage services > NFS > Shares tab.\nClick the line with a share to remove, and then click Delete on the right pane.\nIf a share has exports, it can only be deleted after deleting all of them. To delete such a share, select Delete all exports in this share, and then click Delete in the confirmation window.\n\n",
                "title": "To delete an NFS share"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-nfs-shares.html"
    },
    {
        "title": "Configuring bucket notifications",
        "content": "Configuring bucket notifications\nYou can use event notifications to receive notifications of certain bucket events. To enable event notifications for a bucket, you need to add a notification configuration that specifies which actions will trigger events and where these notifications will be delivered.\nThe following event types are supported:\n\nEvent\nDescription\n\ns3:ObjectCreated:*\nObject created event (all object create events)\n\ns3:ObjectCreated:Put\nObject created event (PUT request)\n\ns3:ObjectCreated:Post\nObject created event (POST request)\n\ns3:ObjectCreated:Copy\nObject created event (COPY request)\n\ns3:ObjectCreated:CompleteMultipartUpload\nObject created event (Multipart upload completed)\n\ns3:ObjectRemoved:*\nObject removal event (all object removal events)\n\ns3:ObjectRemoved:Delete\nObject removal event (DELETE request)\n\ns3:ObjectRemoved:DeleteMarkerCreated\nObject removal event (DELETE marker created)\n\ns3:ObjectLifecycle:Expiration:Current\t\nObject lifecycle event (current object expired)\n\ns3:ObjectLifecycle:Expiration:NonCurrent\nObject lifecycle event (noncurrent object expired)\n\ns3:ObjectLifecycle:Expiration:DeleteMarker\nObject lifecycle event (delete marker expired)\n\ns3:ObjectLifecycle:Expiration:AbortMultipartUpload\nObject lifecycle event (multipart upload aborted due to expiration)\n\ns3:LifecycleExpiration:*\nLifecycle expiration event (all lifecycle expiration events)\n\ns3:LifecycleExpiration:Delete\nLifecycle expiration event (DELETE request)\n\ns3:LifecycleExpiration:DeleteMarkerCreated\nLifecycle expiration event (DELETE marker created)\n\ns3:ObjectAcl:Put\nObject ACL event (PUT request)\n\ns3:Replication:OperationCompletedReplication\nCross-region replication event (replication operation completed)\n\ns3:Replication:OperationFailedReplication\r\n                    \n\nCross-region replication event (replication operation failed)\n\nThe event message structure has the JSON format.\nAmazon S3 event notifications supports two actions:\n\nPUT Bucket notification configuration enables notifications of specified events for a bucket. Use only the TopicConfiguration element in the request body. To disable notifications, specify an empty NotificationConfiguration element.\n\nGET Bucket notification configuration returns the current notification configuration of a bucket. If notifications are disabled for a bucket, the request returns an empty NotificationConfiguration element.\n\nThe Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol supports only the Simple Notification Service (SNS) topics as the destination type for event notifications. An SNS topic contains details about the target endpoint where to deliver notification messages. You can manage SNS topics by using the ostor-topic-cmd tool. The supported endpoint types include:\n\nHTTP/HTTPS\nKafka\nAdvanced Message Queuing Protocol (AMQP)\n\nEach topic has a unique Amazon Resource Name (ARN), which needs to be specified in the TopicConfiguration element when creating the bucket notification configuration.\n\nUndelivered messages are lost upon restart of the NDS service.\n\nTo create an SNS topic\nUse the following command:ostor-topic-cmd create --user <user_id> --name <topic_name> --endpoint <url> [--verify-ssl <true|false>]\r\n                       [--kafka-ack-level <none|broker>] [--use-ssl <true|false>] [--ca-location <file>]\r\n                       [--opaque-data <data>] [--persistent <true|false>] [--cloudevents <true|false>]\r\n                       [--amqp-exchange <exchange>] [--amqp-ack-level <none|broker|routable>]\r\n                       [--mechanism <scram-sha-512|scram-sha-256|plain>] [--retry <count>] [--delay <count>]\n\n--user <user_id>\n\nUser ID of the topic owner\n--name <topic_name>\n\nName of the topic\n--endpoint <url>\n\nThe URI of an endpoint to send push notifications to\n--verify-ssl <true|false>\n\nIndicates whether the server certificate is validated by the client (default: true).\n--kafka-ack-level <none|broker>\n\nMessages may persist in the broker before being delivered to their final destinations (default: broker).\n--use-ssl <true|false>\n\nUse a secure connection to connect to the broker (default: false).\n--ca-location <file>\n\nCA will be used instead of the default CA to authenticate the broker.\n--opaque-data <data>\n\nOpaque data is set in the topic configuration and added to all notifications that are triggered by the topic.\n--persistent <true|false>\n\nIndicates whether notifications to this endpoint are persistent (asynchronous) or not persistent (default: false).\n--cloudevents <true|false>\n\nIndicates whether the HTTP header should contain attributes according to the S3 CloudEvents Specification (default: false).\n--amqp-exchange <exchange>\n\nThe exchanges must exist and must be able to route messages based on topics.\n--amqp-ack-level <none|broker|routable>\n\nMessages may persist in the broker before being delivered to their final destinations (default: broker)\n--mechanism <scram-sha-512|scram-sha-256|plain>\n\nSASL mechanism\n--retry <count>\n\nRetry count in the range 1-65535 (default: 1)\n--delay <count>\n\nDelay between retries, in seconds, in the range 1-86400 (default: 5)\n\nFor example, to create a topic with the name mytopic from the user with the ID b3b1223261a29452, run:# ostor-topic-cmd create --user b3b1223261a29452 --name mytopic --endpoint http://example.com\r\narn:aws:sns::b3b1223261a29452:mytopic\nThe command output shows the ARN of the created topic.\nTo get more details about the topic, use the ostor-topic-cmd info command specifying the user ID and the obtained topic ARN:# ostor-topic-cmd info --user b3b1223261a29452 --arn arn:aws:sns::b3b1223261a29452:mytopic\r\n<InformationResponse>\r\n  <User>b3b1223261a29452</User>\r\n  <Name>mytopic</Name>\r\n  <EndPoint>\r\n    <EndpointAddress>http://example.com</EndpointAddress>\r\n    <EndpointArgs></EndpointArgs>\r\n    <EndpointTopic>mytopic</EndpointTopic>\r\n    <HasStoredSecret>false</HasStoredSecret>\r\n    <Persistent>true</Persistent>\r\n  </EndPoint>\r\n  <TopicArn>arn:aws:sns::b3b1223261a29452:mytopic</TopicArn>\r\n  <OpaqueData></OpaqueData>\nTo delete an SNS topic\nUse the following command:ostor-topic-cmd delete --user <user_id> --arn <arn>\n\n--user <user_id>\n\nUser ID of the topic owner\n--arn <arn>\n\n Topic ARN\n\nFor example, to delete the topic with the ARN, run:# ostor-topic-cmd delete --user b3b1223261a29452 --arn arn:aws:sns::b3b1223261a29452:mytopic\nSee also\n\nSupported Amazon S3 features\n\nManaging S3 users\n\nManaging S3 buckets",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-bucket-notifications.html"
    },
    {
        "title": "Managing regular traffic types",
        "content": "Managing regular traffic types\nYou can add a regular traffic type to multiple networks or remove it from any network.\nLimitations\n\nRegular traffic types cannot be edited or deleted.\nYou can unassign traffic types from networks only if the related services are not deployed. For example, you cannot unassign the VM public traffic type if the compute cluster is created.\nYou cannot manage access rules for the VM public traffic type.\nIf the management node high availability is enabled, you cannot reassign the Admin panel traffic type.\n\nTo assign, reassign, or unassign a regular traffic type\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Assign to networks next to the Regular traffic types section.\nAdd or remove the needed traffic type from your networks by selecting the corresponding check boxes.\nClick Save to apply the changes.\n\nCommand-line interface\nUse the following command:vinfra cluster network set [--traffic-types <traffic-types> | --add-traffic-types <traffic-types> |\r\n                           --del-traffic-types <traffic-types>] <network>\r\n\n\n--traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (overwrites network\u00e2\u0080\u0099s current traffic types)\n--add-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (adds the specified traffic types to the network)\n--del-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (removes the specified traffic types from the network)\n<network>\n\nNetwork ID or name\n\nFor example, to add the traffic type SNMP to the Public network, run:# vinfra cluster network set Public --add-traffic-types \"SNMP\"\n\nSee also\n\nManaging exclusive traffic types\n\nManaging custom traffic types\n\nConfiguring inbound firewall rules\n\nManaging networks",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network set [--traffic-types <traffic-types> | --add-traffic-types <traffic-types> |\r\n                           --del-traffic-types <traffic-types>] <network>\r\n\n\n--traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (overwrites network\u00e2\u0080\u0099s current traffic types)\n--add-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (adds the specified traffic types to the network)\n--del-traffic-types <traffic-types>\n\nA comma-separated list of traffic type names (removes the specified traffic types from the network)\n<network>\n\nNetwork ID or name\n\nFor example, to add the traffic type SNMP to the Public network, run:# vinfra cluster network set Public --add-traffic-types \"SNMP\"\n",
                "title": "To assign, reassign, or unassign a regular traffic type"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Assign to networks next to the Regular traffic types section.\nAdd or remove the needed traffic type from your networks by selecting the corresponding check boxes.\nClick Save to apply the changes.\n\n",
                "title": "To assign, reassign, or unassign a regular traffic type"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-regular-traffic-types.html"
    },
    {
        "title": "Deleting target groups",
        "content": "Deleting target groups\nPrerequisites\n\nA target group is created, as described in Creating target groups.\n\nTo delete a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups. \nClick the ellipsis icon of the desired target group, and then click Delete.\nIf the target group has active connections, select Force.\nClick Delete in the confirmation window. \n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group delete [--force] <target-group>\n\n--force\n\nForcibly remove a target group\n<target-group>\n\nTarget group name or ID\n\nFor example, to delete the target group tg1, run:# vinfra service block-storage target-group delete tg1",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group delete [--force] <target-group>\n\n--force\n\nForcibly remove a target group\n<target-group>\n\nTarget group name or ID\n\nFor example, to delete the target group tg1, run:# vinfra service block-storage target-group delete tg1\n",
                "title": "To delete a target group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > Target groups. \nClick the ellipsis icon of the desired target group, and then click Delete.\nIf the target group has active connections, select Force.\nClick Delete in the confirmation window. \n\n",
                "title": "To delete a target group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/deleting-target-groups.html"
    },
    {
        "title": "Enabling S3 geo-replication",
        "content": "Enabling S3 geo-replication\nVirtuozzo Hybrid Infrastructure can store replicas of S3 cluster data and keep them up to date in multiple geographically distributed datacenters. Geo-replication reduces the response time for local S3 users accessing the data in a remote S3 cluster, or remote S3 users accessing the data in a local S3 cluster, as they do not need an Internet connection. \nGeo-replication schedules the update of the replicas as soon as any data is modified. Its performance depends on the Internet connection speed, the redundancy mode, and cluster performance. \nIf you have multiple datacenters with enough free space, it is recommended to set up geo-replication between S3 clusters residing in these datacenters.\nPrerequisites\n\nS3 clusters are created, as described in Creating the S3 cluster.\nEach cluster has its own SSL certificate signed by a global certificate authority.\n\nTo set up geo-replication between S3 clusters\n\nAdmin panel\n\nIn the admin panel of a remote datacenter, open the Storage services > S3 > Geo-replication screen, and then click the home S3 storage.\nOn the right pane, click Get token.\n\nIn the Get token window, click Copy token below the Token section.\n\nIn the admin panel of the local datacenter, open the Storage services > S3 > Geo-replication screen, and then click Add datacenter.\n\nIn the Add datacenter window, enter the copied token, and then click Add.\n\nConfigure the remote S3 storage the same way.\n\nAfter you enable geo-replication for the clusters, you can replicate their data per bucket.\n\nCommand-line interface\n\nIn the remote datacenter, run vinfra service s3 replication show token to get its token, and then copy this token. For example:# vinfra service s3 replication show token --max-value-length -1\r\n+-------+---------------------------------------------------------------------------+\r\n| Field | Value                                                                     |\r\n+-------+---------------------------------------------------------------------------+\r\n| token | eyJyZWFkYWJsZV9uYW1lIjogImhjaUhlYXQiLCAiaXNfc2VsZiI6IHRydWUsICJ1c2VyX3NlY |\r\n|       | 3JldF9rZXkiOiAiTnM3eWZOcVJ1RGQxRzVUc0ZCZ0VlcjNtWGgyRGJIMG1wanB1NkhVNyIsIC |\r\n|       | J1aWQiOiAiZGQ3MTZjY2VmNDE5OTNiZiIsICJ1cmwiOiAiaHR0cHM6Ly9zM3N0b3JhZ2UuZXh |\r\n|       | hbXBsZS5jb206NDQzIiwgInVzZXJfa2V5X2lkIjogIjgyNmYwYmUyMWNjMDcwZjJGUDhRIn0= |\r\n+-------+---------------------------------------------------------------------------+\n\nIn the local datacenter, run vinfra service s3 replication add, using the token of the remote datacenter. For example:# vinfra service s3 replication add --token eyJ1c2VyX3<\u00e2\u0080\u00a6>\n\nConfigure the remote S3 storage the same way.\n\nTo check that S3 geo-replication is enabled, run vinfra service s3 replication list:# vinfra service s3 replication list\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| uid          | readable_name | url                           | is_self | user_key_id  | user_secret_key |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| dd716cc<...> | cluster1      | http://s3stor1.example.com:80 | True    | 826f0be<...> | Ns7yfNq<...>    |\r\n| eff4d48<...> | cluster2      | http://s3stor2.example.com:80 | False   | cd3f6ae<...> | UmSuxYI<...>    |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\n\nTo replicate a bucket\n\n Open the Storage services > S3 > Buckets screen, and then select the bucket.\nClick Enable geo-replication on the right pane. \n\nThe Geo-replication column for this bucket will display Enabled and the bucket will be copied to the connected cluster.\nTo disable geo-replication of a bucket\n\n Open the Storage services > S3 > Buckets screen, and then select the bucket.\nClick Disable geo-replication on the right pane. \n\n The Geo-replication column for this bucket will display Disabled. After geo-replication is disabled for a bucket, the data copied beforehand will remain, but the changes to it will no longer be replicated to the other S3 cluster.\nTo disable geo-replication between S3 clusters\n\nAdmin panel\n\nIn the admin panel of a local datacenter, open the Storage services > S3 > Geo-replication screen, and then click the remote S3 storage.\nOn the right pane, click Delete.\nClick Delete in the confirmation window.\nConfigure the remote S3 storage the same way.\n\nCommand-line interface\n\nIn the local datacenter, run vinfra service s3 replication delete using the UID of the remote datacenter. For example:# vinfra service s3 replication delete --id eff4d48<\u00e2\u0080\u00a6>\n\nConfigure the remote S3 storage the same way.\n\nTo check that S3 geo-replication is disabled, run vinfra service s3 replication list:# vinfra service s3 replication list\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| uid          | readable_name | url                           | is_self | user_key_id  | user_secret_key |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| dd716cc<...> | cluster1      | http://s3stor1.example.com:80 | True    | 826f0be<...> | Ns7yfNq<...>    |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\n\nSee also\n\nEnabling S3 cross-region replication",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nIn the remote datacenter, run vinfra service s3 replication show token to get its token, and then copy this token. For example:# vinfra service s3 replication show token --max-value-length -1\r\n+-------+---------------------------------------------------------------------------+\r\n| Field | Value                                                                     |\r\n+-------+---------------------------------------------------------------------------+\r\n| token | eyJyZWFkYWJsZV9uYW1lIjogImhjaUhlYXQiLCAiaXNfc2VsZiI6IHRydWUsICJ1c2VyX3NlY |\r\n|       | 3JldF9rZXkiOiAiTnM3eWZOcVJ1RGQxRzVUc0ZCZ0VlcjNtWGgyRGJIMG1wanB1NkhVNyIsIC |\r\n|       | J1aWQiOiAiZGQ3MTZjY2VmNDE5OTNiZiIsICJ1cmwiOiAiaHR0cHM6Ly9zM3N0b3JhZ2UuZXh |\r\n|       | hbXBsZS5jb206NDQzIiwgInVzZXJfa2V5X2lkIjogIjgyNmYwYmUyMWNjMDcwZjJGUDhRIn0= |\r\n+-------+---------------------------------------------------------------------------+\n\n\nIn the local datacenter, run vinfra service s3 replication add, using the token of the remote datacenter. For example:# vinfra service s3 replication add --token eyJ1c2VyX3<\u00e2\u0080\u00a6>\n\n\nConfigure the remote S3 storage the same way.\n\n\nTo check that S3 geo-replication is enabled, run vinfra service s3 replication list:# vinfra service s3 replication list\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| uid          | readable_name | url                           | is_self | user_key_id  | user_secret_key |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| dd716cc<...> | cluster1      | http://s3stor1.example.com:80 | True    | 826f0be<...> | Ns7yfNq<...>    |\r\n| eff4d48<...> | cluster2      | http://s3stor2.example.com:80 | False   | cd3f6ae<...> | UmSuxYI<...>    |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\n",
                "title": "To set up geo-replication between S3 clusters"
            },
            {
                "example": "\nCommand-line interface\n\n\nIn the local datacenter, run vinfra service s3 replication delete using the UID of the remote datacenter. For example:# vinfra service s3 replication delete --id eff4d48<\u00e2\u0080\u00a6>\n\n\nConfigure the remote S3 storage the same way.\n\n\nTo check that S3 geo-replication is disabled, run vinfra service s3 replication list:# vinfra service s3 replication list\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| uid          | readable_name | url                           | is_self | user_key_id  | user_secret_key |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\r\n| dd716cc<...> | cluster1      | http://s3stor1.example.com:80 | True    | 826f0be<...> | Ns7yfNq<...>    |\r\n+--------------+---------------+-------------------------------+---------+--------------+-----------------+\n",
                "title": "To disable geo-replication between S3 clusters"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nIn the admin panel of a remote datacenter, open the Storage services > S3 > Geo-replication screen, and then click the home S3 storage.\nOn the right pane, click Get token.\n\nIn the Get token window, click Copy token below the Token section.\n\n\n\n\n\nIn the admin panel of the local datacenter, open the Storage services > S3 > Geo-replication screen, and then click Add datacenter.\n\nIn the Add datacenter window, enter the copied token, and then click Add.\n\n\n\n\n\nConfigure the remote S3 storage the same way.\n\nAfter you enable geo-replication for the clusters, you can replicate their data per bucket.\n",
                "title": "To set up geo-replication between S3 clusters"
            },
            {
                "example": "\nAdmin panel\n\nIn the admin panel of a local datacenter, open the Storage services > S3 > Geo-replication screen, and then click the remote S3 storage.\nOn the right pane, click Delete.\nClick Delete in the confirmation window.\nConfigure the remote S3 storage the same way.\n\n",
                "title": "To disable geo-replication between S3 clusters"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-s3-geo-replication.html"
    },
    {
        "title": "Requirements for integration via REST API",
        "content": "Requirements for integration via REST API\nAny operation or management request must be authenticated with a signed request via Signature Version 2 or 4 of the Amazon S3 protocol of the corresponding S3 system user. To authenticate API requests, you need to create a system user. First, obtain the volume ID with the ostor-ctl get-config command. For example:# ostor-ctl get-config -n 10.94.97.195\r\nVOL_ID             TYPE     STATE\r\n0100000000000002   OBJ      READY\r\n...\r\n\nThen, create a system user on any storage node in the cluster with the ostor-s3-admin create-user -S -e <email> command. For example:# ostor-s3-admin create-user -S -e user@example.com -V 0100000000000002\r\nUserEmail:user@example.com\r\nUserId:a14040e0b2ef8b28\r\nKeyPair[0]:S3AccessKeyId:a14040e0b2ef8b28FZZ8\r\nKeyPair[0]:S3SecretAccessKey:dbwTnQTW602aAAdq8DQVFzB6yrTCFTNiGB8C8RFA\r\nFlags:system\r\n\nWith this user, you can now authenticate further API requests for managing the S3 cluster. You can create multiple system accounts for different types of management operations.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/requirements-for-integration-via-rest-api.html"
    },
    {
        "title": "Upgrading Kubernetes clusters",
        "content": "Upgrading Kubernetes clustersPOST /v1/clusters/{cluster_ident}/actions/upgrade\nUpgrade a Kubernetes cluster to a newer version.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=upgrade-a-cluster-detail#upgrade-a-cluster\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ncluster_ident\n\npath\nstring\nThe UUID or name of clusters in Magnum.\n\ncluster_template\n\nbody\nUUID\nThe UUID of the cluster template.\n\nmax_batch_size (Optional)\nbody\ninteger\nThe max batch size each time when doing upgrade, default value is 1.\n\nnodegroup (Optional)\nbody\nstring\nThe ID of node group. A node group is a subset of node instances within a cluster that all have the same configuration.\n\nExample# curl -ks -X POST -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{               \r\n    \"cluster_template\": \"b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n    \"max_batch_size\": 1\r\n}' https://<node_IP_addr>:9513/v1/clusters/01d0583d-e8b3-483f-896f-08d2260b0dea/actions/upgrade\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nuuid\n\nbody\nUUID\nThe UUID of the cluster.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"uuid\": \"01d0583d-e8b3-483f-896f-08d2260b0dea\"\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/upgrading-kubernetes-clusters.html"
    },
    {
        "title": "Showing Kubernetes cluster template details",
        "content": "Showing Kubernetes cluster template detailsGET /v1/clustertemplates/{clustertemplate_ident}\r\n\nGet the details of a cluster template in Magnum.\nSource: https://docs.openstack.org/api-ref/container-infrastructure-management/?expanded=show-details-of-a-cluster-template-detail#show-details-of-a-cluster-template\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nclustertemplate_ident\n\npath\nstring\nThe UUID or name of cluster templates in Magnum.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'OpenStack-API-Version: container-infra 1.8' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9513/v1/clustertemplates/b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ninsecure_registry\n\nbody\nstring\nThe URL pointing to users\u00e2\u0080\u0099s own private insecure docker registry to\r\ndeploy and run docker containers.\n\nlinks\n\nbody\narray\nLinks to the resources in question.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nfloating_ip_enabled\n\nbody\nboolean\nWhether enable or not using the floating IP of cloud provider. Some\r\ncloud providers used floating IP, some used public IP, thus Magnum\r\nprovide this option for specifying the choice of using floating IP.\n\nfixed_subnet (Optional)\nbody\nstring\nFixed subnet that are using to allocate network address for nodes in\r\nbay/cluster.\n\nmaster_flavor_id (Optional)\nbody\nstring\nThe flavor of the master node for this baymodel/cluster template.\n\nuuid\n\nbody\nUUID\nThe UUID of the cluster template.\n\nno_proxy (Optional)\nbody\nstring\nWhen a proxy server is used, some sites should not go through the proxy\r\nand should be accessed normally. In this case, users can specify these\r\nsites as a comma separated list of IPs. The default is None.\n\nhttps_proxy (Optional)\nbody\nstring\nThe IP address for a proxy to use when direct HTTPS access from the\r\nservers to sites on the external internet is blocked. This may happen in\r\ncertain countries or enterprises, and the proxy allows the servers and\r\ncontainers to access these sites. The format is a URL including a port\r\nnumber. The default is None.\n\ntls_disabled\n\nbody\nboolean\nTransport Layer Security (TLS) is normally enabled to secure the\r\nbay/cluster. In some cases, users may want to disable TLS in the\r\nbay/cluster, for instance during development or to troubleshoot certain\r\nproblems. Specifying this parameter will disable TLS so that users can\r\naccess the COE endpoints without a certificate. The default is TLS enabled.\n\nkeypair_id\n\nbody\nstring\nThe name of the SSH keypair to configure in the bay/cluster servers\r\nfor ssh access. Users will need the key to be able to ssh to the servers in\r\nthe bay/cluster. The login name is specific to the bay/cluster driver, for\r\nexample with fedora-atomic image, default login name is fedora.\n\npublic\n\nbody\nboolean\nAccess to a baymodel/cluster template is normally limited to the admin,\r\nowner or users within the same tenant as the owners. Setting this flag\r\nmakes the baymodel/cluster template public and accessible by other users.\r\nThe default is not public.\n\nlabels (Optional)\nbody\narray\nArbitrary labels in the form of key=value pairs. The accepted keys and\r\nvalid values are defined in the bay/cluster drivers. They are used as a way\r\nto pass additional parameters that are specific to a bay/cluster driver.\n\ndocker_volume_size\n\nbody\ninteger\nThe size in GB for the local storage on each server for the Docker daemon\r\nto cache the images and host the containers. Cinder volumes provide the\r\nstorage. The default is 25 GB. For the devicemapper storage driver,\r\nthe minimum value is 3 GB. For the overlay storage driver, the minimum\r\nvalue is 1 GB.\n\nserver_type\n\nbody\nstring\nThe servers in the bay/cluster can be vm or baremetal. This\r\nparameter selects the type of server to create for the bay/cluster.\r\nThe default is vm.\n\nexternal_network_id\n\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to the\r\nexternal internet for the bay/cluster. This network must be an external\r\nnetwork, i.e. its attribute router:external must be True. The\r\nservers in the bay/cluster will be connected to a private network and\r\nMagnum will create a router between this private network and the external\r\nnetwork. This will allow the servers to download images, access discovery\r\nservice, etc, and the containers to install packages, etc. In the opposite\r\ndirection, floating IPs will be allocated from the external network to\r\nprovide access from the external internet to servers and the container\r\nservices hosted in the bay/cluster.\n\ncluster_distro\n\nbody\nstring\nDisplay the attribute os_distro defined as appropriate metadata in\r\nimage for the bay/cluster driver.\n\nimage_id\n\nbody\nstring\nThe name or UUID of the base image in Glance to boot the servers for the\r\nbay/cluster. The image must have the attribute os_distro defined as\r\nappropriate for the bay/cluster driver.\n\nvolume_driver\n\nbody\nstring\nThe name of a volume driver for managing the persistent storage for the containers. The functionality supported are specific to the driver.\n\nregistry_enabled (Optional)\nbody\nboolean\nDocker images by default are pulled from the public Docker registry,\r\nbut in some cases, users may want to use a private registry. This option\r\nprovides an alternative registry based on the Registry V2: Magnum will\r\ncreate a local registry in the bay/cluster backed by swift to host the\r\nimages. The default is to use the public registry.\n\ndocker_storage_driver\n\nbody\nstring\nThe name of a driver to manage the storage for the images and the\r\ncontainer\u00e2\u0080\u0099s writable layer. The default is devicemapper.\n\napiserver_port\n\nbody\ninteger\nThe exposed port of COE API server.\n\nname\n\nbody\nstring\nName of the resource.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nnetwork_driver\n\nbody\nstring\nThe name of a network driver for providing the networks for the containers.\r\nNote that this is different and separate from the Neutron network for the\r\nbay/cluster. The operation and networking model are specific to the\r\nparticular driver.\n\nfixed_network (Optional)\nbody\nstring\nThe name or network ID of a Neutron network to provide connectivity to\r\nthe internal network for the bay/cluster.\n\ncoe\n\nbody\nstring\nSpecify the Container Orchestration Engine to use. Supported COEs\r\ninclude kubernetes, swarm, mesos. If your environment has\r\nadditional bay/cluster drivers installed, refer to the bay/cluster driver\r\ndocumentation for the new COE names.\n\nflavor_id\n\nbody\nstring\nThe nova flavor ID or name for booting the node servers. The default is\r\nm1.small.\n\nmaster_lb_enabled\n\nbody\nboolean\nSince multiple masters may exist in a bay/cluster, a Neutron load balancer\r\nis created to provide the API endpoint for the bay/cluster and to direct\r\nrequests to the masters. In some cases, such as when the LBaaS service is\r\nnot available, this option can be set to false to create a bay/cluster\r\nwithout the load balancer. In this case, one of the masters will serve as\r\nthe API endpoint. The default is true, i.e. to create the load\r\nbalancer for the bay.\n\ndns_nameserver\n\nbody\nstring\nThe DNS nameserver for the servers and containers in the bay/cluster to\r\nuse. This is configured in the private Neutron network for the bay/cluster.\r\nThe default is 8.8.8.8.\n\nhidden (Optional)\nbody\nboolean\nIndicates whether the ClusterTemplate is hidden or not, the default\r\nvalue is false.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"insecure_registry\": null,\r\n  \"links\": [\r\n    {\r\n      \"href\": \"https://<node_IP_addr>:9513/v1/clustertemplates/b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n      \"rel\": \"self\"\r\n    },\r\n    {\r\n      \"href\": \"https://<node_IP_addr>:9513/clustertemplates/b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n      \"rel\": \"bookmark\"\r\n    }\r\n  ],\r\n  \"http_proxy\": null,\r\n  \"updated_at\": null,\r\n  \"floating_ip_enabled\": true,\r\n  \"fixed_subnet\": \"43b25f61-657c-407f-935c-3a456aab7943\",\r\n  \"master_flavor_id\": null,\r\n  \"user_id\": \"2a55cfc7747b4383b0856a0a622914dd\",\r\n  \"uuid\": \"b5093d08-f9fd-4a7c-8f69-8cfeb3710e4e\",\r\n  \"no_proxy\": null,\r\n  \"https_proxy\": null,\r\n  \"tls_disabled\": false,\r\n  \"keypair_id\": null,\r\n  \"hidden\": false,\r\n  \"project_id\": \"888ea5e76b284d83a18b3bfaa6fdde16\",\r\n  \"public\": false,\r\n  \"labels\": {\r\n    \"cloud_provider_enabled\": \"true\",\r\n    \"kube_tag\": \"v1.15.6\",\r\n    \"heat_container_agent_tag\": \"hci-3.5-latest\",\r\n    \"kube_version\": \"v1.15.6\",\r\n    \"boot_volume_type\": \"default\",\r\n    \"flannel_tag\": \"v0.11.0-amd64\",\r\n    \"boot_volume_size\": \"10\",\r\n    \"cloud_provider_tag\": \"v1.15.0\",\r\n    \"docker_volume_type\": \"default\"\r\n  },\r\n  \"docker_volume_size\": 10,\r\n  \"server_type\": \"vm\",\r\n  \"external_network_id\": \"7cc2fa27-b387-4a67-8b89-94b608295623\",\r\n  \"cluster_distro\": \"fedora-atomic\",\r\n  \"image_id\": \"f1e62c6a-37d8-4e73-9729-ad957e509c11\",\r\n  \"volume_driver\": \"cinder\",\r\n  \"registry_enabled\": false,\r\n  \"docker_storage_driver\": \"devicemapper\",\r\n  \"apiserver_port\": null,\r\n  \"name\": \"kub1_template\",\r\n  \"created_at\": \"2020-04-14T13:26:01+00:00\",\r\n  \"network_driver\": \"flannel\",\r\n  \"fixed_network\": \"666d0a98-9de7-45df-9301-5ed12a7efea1\",\r\n  \"coe\": \"kubernetes\",\r\n  \"flavor_id\": null,\r\n  \"master_lb_enabled\": true,\r\n  \"dns_nameserver\": null\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-kubernetes-cluster-template-details.html"
    },
    {
        "title": "Adding  identity providers",
        "content": "Adding  identity providers\nBefore connecting to an identity provider and importing its users, you need to create domain groups for these users and assign respective roles to these groups.\nPrerequisites\n\nLocal domain groups are created, as described in Creating domain groups.\nThe redirection URL (redirect_uri) for the cluster must be https://<url>:8800/api/v2/login/idp/.\n\nTo add an identity provider\n\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, and then click Add.\n\nIn the Add identity provider window, specify the following parameters:\n\nA custom name of the identity provider that will be shown on the login screen.\nThe unique issuer ID provided by the OIDC provider. It usually appears as a URN.\nThe client identifier and secret to access the OIDC provider.\nThe metadata URL of the OIDC provider's discovery endpoint. The metadata URL is typically the issuer endpoint concatenated with the path /.well-known/openid-configuration. For example, if the issuer ID is https://idp.example.com/adfs/, the metadata URL will be https://idp.example.com/adfs/.well-known/openid-configuration.\n\nScopes that define what user identity data will be shared by the OIDC provider during authentication.\n\nThe scopes allatclaims and openid are mandatory for Microsoft AD FS providers.\n\nSelect Verify SSL if you want the client to validate the server's SSL/TLS certificate when establishing a connection.\n\nSpecify the timeout for sending requests to the identity provider, in seconds. The default value is 5.\n\nIn the Grant types section, choose between Implicit Flow and Authorization Code Flow:\n\nImplicit Flow with Form Post is a simplified version of the Authorization Code Flow. The communication with the OIDC provider API is performed on the client side. Virtuozzo Hybrid Infrastructure only validates the token's signature.\nThis grant type is recommended for login-only use cases. \n\nWith Authorization Code Flow, users obtain an access token to the OIDC provider API and use it to retrieve the user identity data with an extra backend call from Virtuozzo Hybrid Infrastructure.\nUse this grant type if the identity provider does not support Implicit Flow with Form Post.\n\nIn the Mapping section, you can either create mapping rules manually or automatically from a mapping file:\n\nTo manually create mapping rules\n\nSelect Create mapping rules, and then click Add.\n\nIn the Add rule window, create Mapping conditions by clicking Add and specifying the required parameters:\n\nIn Attribute, specify a user attribute that you obtain from the identity provider during authentication.\nIn Condition, specify a condition to apply to the attribute. With the condition Exists, all users with this attribute will be mapped. The condition Contains maps users if this attribute contains any of the specified values. The condition Does not contain maps users if this attribute does not contain any of the specified values.\nIn Value, specify the desired attribute value as a string, comma-separated list, or regular expression.\n\nSelect an existing domain group to assign federated users to.\nIf you have a mapping rule with the condition Exists, select attributes that the name of a local user will consist of. For example, with the mapping attribute email and mapping condition Exists, names of local users may be composed of their emails.\n\nTo automatically create mapping rules\n\nSelect Upload a mapping file in the JSON format with already configured mapping rules.\n\nWrite mapping rules in the JSON format in the Mapping data field. Alternatively, click Upload, and then browse a JSON file on your local server to load the mapping data from.\nA mapping file may look as follows:# cat mapping.json\r\n[\r\n    {\r\n        \"local\": [\r\n            {\r\n                \"user\": {\r\n                    \"name\": \"{0}\"\r\n                },\r\n                \"group\": {\r\n                    \"name\":\"users\"\r\n                }\r\n            }\r\n        ],\r\n        \"remote\": [{\"type\": \"email\"}]\r\n    }\r\n]\nIn this example, all users that have the attribute email will be mapped to the group users within the default domain. For details on creating a mapping file, refer to the OpenStack documentation.\n\nClick Add.\n\nCommand-line interface\nUse the following command:vinfra domain idp create --domain <domain> --issuer <issuer> --scope <scope>\r\n                         [--response-type <response-type>] [--metadata-url <metadata-url>]\r\n                         [--client-id <client-id>] [--client-secret <client-secret>]\r\n                         [--mapping <path>] [--enable] [--disable] [--request-timeout <seconds>]\r\n                         [--verify-ssl | --dont-verify-ssl] <name>\n\n--domain <domain>\n\nDomain name or ID\n--issuer <issuer>\n\nIdentity provider issuer\n--scope <scope>\n\nScope that define what user identity data will be shared by the identity provider during authentication.\n\nThe scopes allatclaims and openid are mandatory for Microsoft AD FS providers.\n\n--response-type <response-type>\n\nResponse type to be used in the authorization flow: \n\ncode: use the Authorization Code Flow\nid_token: use the Implicit Flow\n\n--metadata-url <metadata-url>\n\nMetadata URL of the identity provider's discovery endpoint\n--client-id <client-id>\n\nClient ID to access the identity provider\n--client-secret <client-secret>\n\nClient secret to access the identity provider\n--mapping <path>\n\nPath to the mapping configuration file.\nA mapping file may look as follows:# cat mapping.json\r\n[\r\n    {\r\n        \"local\": [\r\n            {\r\n                \"user\": {\r\n                    \"name\": \"{0}\"\r\n                },\r\n                \"group\": {\r\n                    \"name\":\"users\"\r\n                }\r\n            }\r\n        ],\r\n        \"remote\": [{\"type\": \"email\"}]\r\n    }\r\n]\nIn this example, all users that have the attribute email will be mapped to the group users within the default domain. For details on creating a mapping file, refer to the OpenStack documentation.\n\n--enable\n\nEnable identity provider\n--disable\n\nDisable identity provider\n--verify-ssl\n\nEnable identity provider endpoints SSL verification\n--dont-verify-ssl\n\nDisable identity provider endpoints SSL verification\n--request-timeout <seconds>\n\nIdentity provider API request timeout (default: 5)\n<name>\n\nIdentity provider name\n\nFor example, to add an identity provider with the name My ADFS within the mydomain domain, run:# vinfra domain idp create --domain mydomain --issuer https://idp.example.com/adfs/ \\\r\n--scope \"allatclaims openid email\" --client-id xxx --client-secret xxx --mapping mapping.json \"My ADFS\"\nThe added identity provider will appear in the vinfra domain idp list output:# vinfra domain idp list --domain mydomain\r\n+-------------+---------+-------------------------------+--------------------------+-----------+\r\n| id          | name    | issuer                        | scope                    | domain_id |\r\n+-------------+---------+-------------------------------+--------------------------+-----------+\r\n| df5a54ce<\u00e2\u0080\u00a6> | My ADFS | https://idp.example.com/adfs/ | allatclaims openid email | 36f454<\u00e2\u0080\u00a6> |\r\n+-------------+---------+-------------------------------+--------------------------+-----------+\n\nSee also\n\nEditing and deleting identity providers\n\nManaging user assignment to domain groups\n\nManaging project assignment to domain groups\n\nWhat's next\n\nSigning in through identity providers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra domain idp create --domain <domain> --issuer <issuer> --scope <scope>\r\n                         [--response-type <response-type>] [--metadata-url <metadata-url>]\r\n                         [--client-id <client-id>] [--client-secret <client-secret>]\r\n                         [--mapping <path>] [--enable] [--disable] [--request-timeout <seconds>]\r\n                         [--verify-ssl | --dont-verify-ssl] <name>\n\n--domain <domain>\n\nDomain name or ID\n--issuer <issuer>\n\nIdentity provider issuer\n--scope <scope>\n\n\nScope that define what user identity data will be shared by the identity provider during authentication.\n\nThe scopes allatclaims and openid are mandatory for Microsoft AD FS providers.\n\n\n--response-type <response-type>\n\n\nResponse type to be used in the authorization flow: \n\ncode: use the Authorization Code Flow\nid_token: use the Implicit Flow\n\n\n--metadata-url <metadata-url>\n\nMetadata URL of the identity provider's discovery endpoint\n--client-id <client-id>\n\nClient ID to access the identity provider\n--client-secret <client-secret>\n\nClient secret to access the identity provider\n--mapping <path>\n\n\nPath to the mapping configuration file.\nA mapping file may look as follows:# cat mapping.json\r\n[\r\n    {\r\n        \"local\": [\r\n            {\r\n                \"user\": {\r\n                    \"name\": \"{0}\"\r\n                },\r\n                \"group\": {\r\n                    \"name\":\"users\"\r\n                }\r\n            }\r\n        ],\r\n        \"remote\": [{\"type\": \"email\"}]\r\n    }\r\n]\nIn this example, all users that have the attribute email will be mapped to the group users within the default domain. For details on creating a mapping file, refer to the OpenStack documentation.\n\n--enable\n\nEnable identity provider\n--disable\n\nDisable identity provider\n--verify-ssl\n\nEnable identity provider endpoints SSL verification\n--dont-verify-ssl\n\nDisable identity provider endpoints SSL verification\n--request-timeout <seconds>\n\nIdentity provider API request timeout (default: 5)\n<name>\n\nIdentity provider name\n\nFor example, to add an identity provider with the name My ADFS within the mydomain domain, run:# vinfra domain idp create --domain mydomain --issuer https://idp.example.com/adfs/ \\\r\n--scope \"allatclaims openid email\" --client-id xxx --client-secret xxx --mapping mapping.json \"My ADFS\"\nThe added identity provider will appear in the vinfra domain idp list output:# vinfra domain idp list --domain mydomain\r\n+-------------+---------+-------------------------------+--------------------------+-----------+\r\n| id          | name    | issuer                        | scope                    | domain_id |\r\n+-------------+---------+-------------------------------+--------------------------+-----------+\r\n| df5a54ce<\u00e2\u0080\u00a6> | My ADFS | https://idp.example.com/adfs/ | allatclaims openid email | 36f454<\u00e2\u0080\u00a6> |\r\n+-------------+---------+-------------------------------+--------------------------+-----------+\n",
                "title": "To add an identity provider"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Projects and users screen, click the required domain.\nSwitch to the Settings > Identity provider screen, and then click Add.\n\nIn the Add identity provider window, specify the following parameters:\n\nA custom name of the identity provider that will be shown on the login screen.\nThe unique issuer ID provided by the OIDC provider. It usually appears as a URN.\nThe client identifier and secret to access the OIDC provider.\nThe metadata URL of the OIDC provider's discovery endpoint. The metadata URL is typically the issuer endpoint concatenated with the path /.well-known/openid-configuration. For example, if the issuer ID is https://idp.example.com/adfs/, the metadata URL will be https://idp.example.com/adfs/.well-known/openid-configuration.\n\nScopes that define what user identity data will be shared by the OIDC provider during authentication.\n\nThe scopes allatclaims and openid are mandatory for Microsoft AD FS providers.\n\n\n\n\n\n\n\nSelect Verify SSL if you want the client to validate the server's SSL/TLS certificate when establishing a connection.\n\n\nSpecify the timeout for sending requests to the identity provider, in seconds. The default value is 5.\n\n\n\n\nIn the Grant types section, choose between Implicit Flow and Authorization Code Flow:\n\n\nImplicit Flow with Form Post is a simplified version of the Authorization Code Flow. The communication with the OIDC provider API is performed on the client side. Virtuozzo Hybrid Infrastructure only validates the token's signature.\nThis grant type is recommended for login-only use cases. \n\n\nWith Authorization Code Flow, users obtain an access token to the OIDC provider API and use it to retrieve the user identity data with an extra backend call from Virtuozzo Hybrid Infrastructure.\nUse this grant type if the identity provider does not support Implicit Flow with Form Post.\n\n\n\n\nIn the Mapping section, you can either create mapping rules manually or automatically from a mapping file:\n\n\nTo manually create mapping rules\n\n\nSelect Create mapping rules, and then click Add.\n\nIn the Add rule window, create Mapping conditions by clicking Add and specifying the required parameters:\n\nIn Attribute, specify a user attribute that you obtain from the identity provider during authentication.\nIn Condition, specify a condition to apply to the attribute. With the condition Exists, all users with this attribute will be mapped. The condition Contains maps users if this attribute contains any of the specified values. The condition Does not contain maps users if this attribute does not contain any of the specified values.\nIn Value, specify the desired attribute value as a string, comma-separated list, or regular expression.\n\n\nSelect an existing domain group to assign federated users to.\nIf you have a mapping rule with the condition Exists, select attributes that the name of a local user will consist of. For example, with the mapping attribute email and mapping condition Exists, names of local users may be composed of their emails.\n\n\n\n\n\n\n\n\n\nTo automatically create mapping rules\n\n\nSelect Upload a mapping file in the JSON format with already configured mapping rules.\n\nWrite mapping rules in the JSON format in the Mapping data field. Alternatively, click Upload, and then browse a JSON file on your local server to load the mapping data from.\nA mapping file may look as follows:# cat mapping.json\r\n[\r\n    {\r\n        \"local\": [\r\n            {\r\n                \"user\": {\r\n                    \"name\": \"{0}\"\r\n                },\r\n                \"group\": {\r\n                    \"name\":\"users\"\r\n                }\r\n            }\r\n        ],\r\n        \"remote\": [{\"type\": \"email\"}]\r\n    }\r\n]\nIn this example, all users that have the attribute email will be mapped to the group users within the default domain. For details on creating a mapping file, refer to the OpenStack documentation.\n\n\n\n\n\n\n\n\nClick Add.\n\n\n",
                "title": "To add an identity provider"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-identity-providers.html"
    },
    {
        "title": "DELETE service ostor-quotas",
        "content": "DELETE service ostor-quotas\nDescription\nSets a quota value to 0 (unlimited) for the specified user/bucket or for all users/buckets.\nRequests\nSyntaxDELETE /?ostor-quotas&emailAddress=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>DELETE /?ostor-quotas&bucket=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>DELETE /?ostor-quotas&default=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nDELETE service ostor-limits parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nYes*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nYes*\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes*\n\ndefault\n\nRemoves the default value for quotas. If set to user, deletes the default quotas for all users. If set to bucket, deletes the default quotas for all buckets.\nType: string.\nDefault: none.\n\nNo\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nIf quotas are successfully deleted, Status204NoContent is returned.\nExamples\nSample request #1\nDeletes a quota for the user with the email user1@email.com.DELETE /?ostor-quotas&emailAddress=user1@email.com HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 21:13:49 GMT\r\nAuthorization: <authorization_string>\nSample response #1HTTP/1.1 204 No Content\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 21:14:03 GMT\r\nContent-type : application/json\nSample request #2\nDeletes a quota for the bucket bucket1.DELETE /?ostor-quotas&bucket=bucket1 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 21:14:35 GMT\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 204 No Content\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 21:14:39 GMT\r\nContent-type : application/json\nSample request #3\nRemoves the default user quotas.DELETE /?ostor-quotas&default=user HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 21:16:18 GMT\r\nAuthorization: <authorization_string>\nSample response #3HTTP/1.1 204 No Content\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 21:16:22 GMT\r\nContent-type : application/json\nSample request #4\nRemoves the default bucket quotas.DELETE /?ostor-quotas&default=bucket HTTP/1.1\r\nHost: s3.example.com\r\nDate: Thu, 09 Sep 2021 21:17:01 GMT\r\nAuthorization: <authorization_string>\nSample response #4HTTP/1.1 204 No Content\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 09 Sep 2021 21:17:05 GMT\r\nContent-type : application/json",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/delete-service-ostor-quotas.html"
    },
    {
        "title": "How to deploy nested Virtuozzo Hybrid Infrastructure clusters",
        "content": "How to deploy nested Virtuozzo Hybrid Infrastructure clustersThis guide describes how to deploy nested Virtuozzo Hybrid Infrastructure (VHI) clusters for testing or development purposes. You can deploy such clusters on top of a VHI cluster with enabled nested virtualization.You can find the original guide at https://github.com/virtuozzo/vhideploy.Prerequisites1. Deploy a Virtuozzo Hybrid Infrastructure cluster.2. Create the compute cluster.Preparing the physical Virtuozzo Hybrid Infrastructure cluster1. Enable nested virtualization on the physical server:1.1. Connect to your physical VHI server via SSH.1.2. Create the /etc/modprobe.d/dist.conf file as follows:[For Intel-based systems] Add the line options kvm_intel nested=y:1\n2\n3\n# cat > /etc/modprobe.d/dist.conf <<\\EOT\noptions kvm_intel nested=y\nEOT\n[For AMD-based systems] Add the line options kvm_amd nested=y:1\n2\n3\n# cat > /etc/modprobe.d/dist.conf <<\\EOT\noptions kvm_amd nested=y\nEOT\n1.3. [For AMD-based systems only] Add the svm flag to your CPU model. For example:1\n# vinfra service compute set --cpu-model EPYC-IBPB --cpu-features svm\n1.4. Reboot the server:1\n# reboot\n1.5. Repeat these steps on other cluster nodes. All virtual machines created after the configuration will support nested virtualization.1.6. Check that nested virtualization is successfully enabled:For a physical server:[For Intel-based systems] Run this command on the node:1\n2\n# cat /sys/module/kvm_intel/parameters/nested\nY\n[For AMD-based systems] Run this command on the node:1\n2\n# cat /sys/module/kvm_amd/parameters/nested\nY\nFor a virtual machine, run this command inside the VM:Note: The virtual machine should be created after enabling nested virtualization.1\n# cat /proc/cpuinfo | grep vmx\n2. Configure physical and virtual compute networks. Ensure that the private network does not have a default gateway.3. Create compute flavors named vhimaster (16 vCPUs, 42 GB of RAM) and vhislave (16 vCPUs, 32 GB of RAM) that we will be using by default. You can create your custom flavors with at least 8 vCPUs and 24 GB of RAM.4. Upload the latest VHI QCOW2 image to your cluster in the admin panel or command-line interface:4.1. Connect to your physical management node via SSH.4.2. Download the latest VHI QCOW2 image:1\n# wget https://virtuozzo.s3.amazonaws.com/vzlinux-iso-hci-latest.qcow2\n4.3. Upload this image to the compute cluster:1\n# vinfra service compute image create vhi-latest --disk-format qcow2 --container-format bare --file vzlinux-iso-hci-latest.qcow2 --public --wait\nConnecting to the OpenStack CLI remotely1. Install the OpenStack command-line client on your local machine. For example, for macOS, run:1\n# brew install openstackclient\n2. Download the deployment scripts to your local machine:1\n# git clone https://github.com/virtuozzo/vhideploy.git\n3. Create your OpenStack source file or edit project.sh as follows:OS_PROJECT_DOMAIN_NAME is the name of the domain where to deploy the stackOS_USER_DOMAIN_NAME is the name of the user domainOS_PROJECT_NAME is the name of the project where to deploy the stackOS_USERNAME is the user nameOS_PASSWORD is the user passwordOS_AUTH_URL is the OpenStack endpoint URL (the endpoint must be published and available)4. Load the source file:1\n# source project.sh\n5. Check that you can connect to the OpenStack API:1\n2\n# openstack --insecure server list\n// Use --insecure option if your cluster uses a self-signed certificate\nDeploying a nested VHI cluster1. Read about OpenStack Heat.2. Connect to the OpenStack CLI from your local machine.3. Deploy the Heat stack by using the following command:To create a VHI cluster with compute and high availability enabled (recommended configuration):1\n# openstack --insecure stack create <stack_name> -t vip.yaml --parameter image=\"vhi-latest\" --parameter stack_type=\"hacompute\" --parameter private_network=\"private\" --parameter slave_count=\"2\" --parameter compute_addons=\"k8saas,lbaas\" --parameter cluster_password=\"<password>\"\nTo create a VHI cluster with compute (minimum configuration):1\n# openstack --insecure stack create <stack_name> -t vip.yaml --parameter image=\"vhi-latest\" --parameter stack_type=\"compute\" --parameter private_network=\"private\" --parameter slave_count=\"2\" --parameter cluster_password=\"<password>\"\nWhere:<stack_name> is the name for your OpenStack Heat stackimage is the name of the source image in the QCOW2 formatprivate_network is the name of the virtual compute network (the virtual network must be connected to the physical compute network via a virtual router with SNAT)public_network is the name of the physical network (this network must have DHCP enabled and DNS configured, the default name is public)slave_count is the number of cluster nodes in addition to the management nodes (for the HA configuration, the minimum value must be 2; the default value is 4)stack_type is the VHI deployment mode:compute deploys a cluster with storage and compute roleshacompute deploys a cluster with storage and compute roles, management nodes with HAmaster_flavor is the name of the flavor to use for management nodes (the default flavor is vhimaster)slave_flavor is the name of the flavor to use for other cluster nodes (the default flavor is vhislave)storage_policy is the name of the storage policy to use (the default policy is default)compute_addons specifies add-on services to be automatically installed along with the compute clustercluster_password is the password of the admin user (the default password is Virtuozzo1)The stack deployment takes at least 10 minutes.4. Check the stack status:1\n# openstack --insecure stack list\n5. Once the deployment is complete, access the nested cluster by entering the public IP address of its management node https://<mn_node_ip>:8888 in your browser with the provided password. Check the status of the compute cluster and other services.6. Reconfigure the public network:6.1. In the admin panel, go to Compute \u00e2\u0086\u0092 Network.6.2. Delete the network public.6.3. Create a new network with the following parameters:Type: PhysicalName: publicInfrastructure network: PublicUntaggedSubnet: IPv4 with the configured CIDR, gateway, and DNSAccess: Full to All projectsEnjoy!Next steps1. Connect to the OpenStack CLI.2. [Optional] Configure the OpenStack endpoint.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/nested-vhi-deployment/"
    },
    {
        "title": "Managing balancing pools",
        "content": "Managing balancing pools\nOn the Compute > Network > Load balancers tab, click a load balancer name, to see a list of its balancing pools.\n\nTo manage balancing pools\n\nAdmin panel\n\nTo monitor pool performance and health, open the pool\u00e2\u0080\u0099s panel on the Overview tab.\nTo see the pool parameters, open the pool\u00e2\u0080\u0099s panel and go to the  Properties tab.\nTo manage the pool members, open the pool\u00e2\u0080\u0099s panel and go the Members tab.\nTo remove a balancing pool, click the ellipsis icon next to it, and then click Delete. \n\nCommand-line interface\n\nTo view the pool's details, use vinfra service compute load-balancer pool show. For example:# vinfra service compute load-balancer pool show mypool\r\n+-----------------------+--------------------------------------------+\r\n| Field                 | Value                                      |\r\n+-----------------------+--------------------------------------------+\r\n| backend_protocol      | HTTP                                       |\r\n| backend_protocol_port | 80                                         |\r\n| certificate           |                                            |\r\n| connection_limit      | -1                                         |\r\n| created_at            | 2019-11-18T13:11:27.982129                 |\r\n| description           |                                            |\r\n| enabled               | True                                       |\r\n| healthmonitor         |                                            |\r\n| id                    | fa40e282-b29a-465a-afaa-2c702d2bde17       |\r\n| lb_algorithm          | LEAST_CONNECTIONS                          |\r\n| listener_id           | 66cc714e-af7f-40eb-9db8-67b8b6b6d23c       |\r\n| loadbalancer_id       | 941bf637-2d55-40f0-92c0-e65d6567b468       |\r\n| members               | - address: 192.168.31.153                  |\r\n|                       |   compute_server_id: d51c10a7-6187-<...>   |\r\n|                       |   created_at: '2019-11-18T13:11:59.681101' |\r\n|                       |   enabled: true                            |\r\n|                       |   id: 3fd5dcc5-6e2c-4e22-8d0a-8e94e20a122f |\r\n|                       |   name: ''                                 |\r\n|                       |   pool_id: null                            |\r\n|                       |   status: HEALTHY                          |\r\n|                       |   updated_at: '2019-11-18T13:12:01.467306' |\r\n|                       |   weight: 1                                |\r\n|                       | - address: 192.168.31.22                   |\r\n|                       |   compute_server_id: 54603109-8963-<...>   |\r\n|                       |   created_at: '2019-11-18T13:12:10.176853' |\r\n|                       |   enabled: true                            |\r\n|                       |   id: ccb645b3-63c7-44f8-b861-b197c85506d4 |\r\n|                       |   name: ''                                 |\r\n|                       |   pool_id: null                            |\r\n|                       |   status: HEALTHY                          |\r\n|                       |   updated_at: '2019-11-18T13:12:12.281578' |\r\n|                       |   weight: 1                                |\r\n| name                  | mypool                                     |\r\n| private_key           |                                            |\r\n| project_id            | e4e059c67dee4736851df14d4519a5a5           |\r\n| protocol              | HTTP                                       |\r\n| protocol_port         | 80                                         |\r\n| status                | ACTIVE                                     |\r\n| sticky_session        | True                                       |\r\n| updated_at            | 2019-11-18T13:12:12.305509                 |\r\n+-----------------------+--------------------------------------------+\r\n\n\nTo edit the pool's members, use vinfra service compute load-balancer pool set. For example:# vinfra service compute load-balancer pool set mypool \\\r\n--member address=192.168.31.153 --member address=192.168.31.22 \\\r\n--member address=192.168.31.51\nThis command adds the third member to the balancing pool mypool.\n\nTo delete a balancing pool, use vinfra service compute load-balancer pool delete. For example:# vinfra service compute load-balancer pool delete mypool\n\nSee also\n\nChanging the default load balancer image\n\nChanging load balancer resources\n\nCreating custom load balancer flavors",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nTo view the pool's details, use vinfra service compute load-balancer pool show. For example:# vinfra service compute load-balancer pool show mypool\r\n+-----------------------+--------------------------------------------+\r\n| Field                 | Value                                      |\r\n+-----------------------+--------------------------------------------+\r\n| backend_protocol      | HTTP                                       |\r\n| backend_protocol_port | 80                                         |\r\n| certificate           |                                            |\r\n| connection_limit      | -1                                         |\r\n| created_at            | 2019-11-18T13:11:27.982129                 |\r\n| description           |                                            |\r\n| enabled               | True                                       |\r\n| healthmonitor         |                                            |\r\n| id                    | fa40e282-b29a-465a-afaa-2c702d2bde17       |\r\n| lb_algorithm          | LEAST_CONNECTIONS                          |\r\n| listener_id           | 66cc714e-af7f-40eb-9db8-67b8b6b6d23c       |\r\n| loadbalancer_id       | 941bf637-2d55-40f0-92c0-e65d6567b468       |\r\n| members               | - address: 192.168.31.153                  |\r\n|                       |   compute_server_id: d51c10a7-6187-<...>   |\r\n|                       |   created_at: '2019-11-18T13:11:59.681101' |\r\n|                       |   enabled: true                            |\r\n|                       |   id: 3fd5dcc5-6e2c-4e22-8d0a-8e94e20a122f |\r\n|                       |   name: ''                                 |\r\n|                       |   pool_id: null                            |\r\n|                       |   status: HEALTHY                          |\r\n|                       |   updated_at: '2019-11-18T13:12:01.467306' |\r\n|                       |   weight: 1                                |\r\n|                       | - address: 192.168.31.22                   |\r\n|                       |   compute_server_id: 54603109-8963-<...>   |\r\n|                       |   created_at: '2019-11-18T13:12:10.176853' |\r\n|                       |   enabled: true                            |\r\n|                       |   id: ccb645b3-63c7-44f8-b861-b197c85506d4 |\r\n|                       |   name: ''                                 |\r\n|                       |   pool_id: null                            |\r\n|                       |   status: HEALTHY                          |\r\n|                       |   updated_at: '2019-11-18T13:12:12.281578' |\r\n|                       |   weight: 1                                |\r\n| name                  | mypool                                     |\r\n| private_key           |                                            |\r\n| project_id            | e4e059c67dee4736851df14d4519a5a5           |\r\n| protocol              | HTTP                                       |\r\n| protocol_port         | 80                                         |\r\n| status                | ACTIVE                                     |\r\n| sticky_session        | True                                       |\r\n| updated_at            | 2019-11-18T13:12:12.305509                 |\r\n+-----------------------+--------------------------------------------+\r\n\n\n\nTo edit the pool's members, use vinfra service compute load-balancer pool set. For example:# vinfra service compute load-balancer pool set mypool \\\r\n--member address=192.168.31.153 --member address=192.168.31.22 \\\r\n--member address=192.168.31.51\nThis command adds the third member to the balancing pool mypool.\n\n\nTo delete a balancing pool, use vinfra service compute load-balancer pool delete. For example:# vinfra service compute load-balancer pool delete mypool\n\n\n",
                "title": "To manage balancing pools"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nTo monitor pool performance and health, open the pool\u00e2\u0080\u0099s panel on the Overview tab.\nTo see the pool parameters, open the pool\u00e2\u0080\u0099s panel and go to the  Properties tab.\nTo manage the pool members, open the pool\u00e2\u0080\u0099s panel and go the Members tab.\nTo remove a balancing pool, click the ellipsis icon next to it, and then click Delete. \n\n",
                "title": "To manage balancing pools"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-balancing-pools.html"
    },
    {
        "title": "Configuring notification forwarding to Kafka",
        "content": "Configuring notification forwarding to Kafka\nVirtuozzo Hybrid Infrastructure allows forwarding notifications to Apache Kafka, an open source platform for streaming events. You can configure the following security protocols to communicate with Kafka brokers:\n\nPLAINTEXT. This protocol provides no security and is used by default if no other security protocol is specified.\nSSL. The Secure Sockets Layer (SSL) protocol is used for traffic encryption and two-way authentication between the client and server. SSL uses private-key/certificates pairs, which are used during the SSL handshake process.\nSASL_PLAINTEXT. Simple Authentication and Security Layer (SASL) is used with PLAINTEXT as the transport layer, where requests are not encrypted.\nSASL_SSL. SASL is used with SSL as the transport layer, where encryption is enabled.\n\nVirtuozzo Hybrid Infrastructure supports SASL with Salted Challenge Response Authentication Mechanism (SCRAM) as the default authentication mechanism. You can choose between the SCRAM-SHA-256 and SCRAM-SHA-512 mechanisms, which use the SHA-256 and SHA-512 hashing functions, respectively. For details on how SASL/SCRAM works, see RFC 5802.\nTo enable Kafka notification forwarding\nUse the following command:vinfra service compute notification set [--transport-url <transport-url>]\r\n                                        [--kafka-security-protocol {PLAINTEXT,SASL_PLAINTEXT,SSL,SASL_SSL}]\r\n                                        [--kafka-sasl-mechanism {SCRAM-SHA-256,SCRAM-SHA-512}]\r\n                                        [--kafka-ssl-ca-cert <path>] [--kafka-ssl-client-cert <path>]\n\n--transport-url <transport-url>\n\nEnable notification forwarding through the specified transport URL in the format driver://[user:pass@]host:port[,[userN:passN@]hostN:portN], where:\n\ndriver is the supported transport driver (kafka, ampq, or rabbit)\nuser:pass are the username and password used for authentication with the messaging broker\nhost:port specifies the hostname or IP address and port number of the messaging broker\n\nMessages will be published to the \"notifications\" topic.\n\nExample: kafka://10.10.10.10:9092\n\n--kafka-security-protocol {PLAINTEXT,SASL_PLAINTEXT,SSL,SASL_SSL}\n\nProtocol used to communicate with brokers\n--kafka-sasl-mechanism {SCRAM-SHA-256,SCRAM-SHA-512}\n\nAuthentication mechanism to use for the SASL protocol\n--kafka-ssl-ca-cert <path>\n\nPath to a PEM file with the CA certificate that is used to verify the server\n--kafka-ssl-client-cert <path>\n\nPath to a PEM file with the SSL client certificate that is used for client authentication\n\nFor example, to configure notification forwarding to the Kafka server with the IP address 10.10.10.10 with the SASL_SSL security protocol and the SCRAM-SHA-512 authentication mechanism, run the following command specifying two PEM files:# vinfra service compute notification set --transport-url kafka://10.10.10.10:9092 --kafka-security-protocol SASL_SSL \\\r\n--kafka-sasl-mechanism SCRAM-SHA-512 --kafka-ssl-ca-cert kafka-server.pem --kafka-ssl-client-cert kafka-client.pem\nYou can check the notification forwarding options in the vinfra service compute notification show output:# vinfra service compute notification show\r\n+---------------+-------------------------------------------------+\r\n| Field         | Value                                           |\r\n+---------------+-------------------------------------------------+\r\n| kafka         | sasl_mechanism: SCRAM-SHA-512                   |\r\n|               | security_protocol: SASL_SSL                     |\r\n|               | ssl_ca_file: kafka_ssl_ca_cert.pem              |\r\n|               | ssl_client_cert_file: kafka_ssl_client_cert.pem |\r\n| transport_url | kafka://10.10.10.10:9092                        |\r\n+---------------+-------------------------------------------------+\nTo disable encryption of Kafka messaging\nRun the following command:# vinfra service compute notification disable --kafka-encryption\nThe Kafka security protocol will be set to the default value PLAINTEXT.\nYou can check that the encryption is successfully disabled in the vinfra service compute notification show output:# vinfra service compute notification show\r\n+---------------+--------------------------+\r\n| Field         | Value                    |\r\n+---------------+--------------------------+\r\n| transport_url | kafka://10.10.10.10:9092 |\r\n+---------------+--------------------------+\nTo disable Kafka notification forwarding\nRun the following command:# vinfra service compute notification disable --notification-forwarding\nSee also\n\nChanging parameters in OpenStack configuration files\n\nViewing alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-kafka-notification-forwarding.html"
    },
    {
        "title": "Deleting VPN endpoint groups",
        "content": "Deleting VPN endpoint groupsDELETE /v2.0/vpn/endpoint-groups/{endpoint_group_id}\nDelete a VPN endpoint group.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=remove-vpn-endpoint-group-detail#remove-vpn-endpoint-group\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nendpoint_group_id\n\npath\nstring\nThe ID of the VPN endpoint group.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/endpoint-groups/e3b89342-73ee-42b9-8ee9-fd91ec36aceb\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-vpn-endpoint-groups.html"
    },
    {
        "title": "Configuring network interfaces of virtual machines",
        "content": "Configuring network interfaces of virtual machines\nYou can add new network interfaces to your virtual machines, edit IP addresses and security groups for the existing interfaces, and remove network interfaces by detaching them.\nLimitations\n\nYou cannot manage network interfaces of shelved VMs.\nA VM that is connected to a dual-stack network always receives an IPv6 address, if the IPv6 subnet is in the SLAAC or DHCPv6 stateless mode.\n\nTo attach a network interface to a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click Add to attach a network interface.\n\nIn the Add network interface window, select a compute network to connect to, and then specify MAC address, IPv4 and/or IPv6 addresses, and security groups. By default, MAC and primary IP addresses are assigned automatically. To specify them manually, clear the Assign automatically check boxes, and enter the desired addresses. Optionally, assign additional IP addresses to the network interface in the Secondary IP addresses section. Note that a secondary IPv6 address is not available for an IPv6 subnet that works in the SLAAC or DHCPv6 stateless mode.\n\nSecondary IP addresses, unlike the primary one, will not be automatically assigned to the network interface inside the virtual machine guest OS. You should assign them manually.\n\nIf you selected a network with enabled IP address management\n\nIn this case, spoofing protection is enabled and the default security group is selected by default. This security group allows all incoming and outgoing traffic on all the VM ports. If required, you can select another security group or multiple security groups.\nTo disable spoofing protection, clear all of the check boxes and turn off the toggle switch. Security groups cannot be configured with disabled spoofing protection.\n\nIf you selected a network with disabled IP address management\nIn this case, spoofing protection is disabled by default and cannot be enabled. Security groups cannot be configured for such a network.\n\nAfter specifying the network interface parameters, click Add.\n\nClick Done to finish editing VM network interfaces and save your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute server iface attach [--fixed-ip <ip-address | ip-address=\r\n                                           <ip-address>,subnet=<subnet> | \r\n                                           ip-version=<ip-version>>]\r\n                                           [--spoofing-protection-enable | \r\n                                           --spoofing-protection-disable]\r\n                                           [--security-group <security-group> | \r\n                                           --no-security-groups]\r\n                                           --server <server>\r\n                                           --network <network> [--mac <mac>]\n\n--fixed-ip <ip-address|ip-address=<ip-address>,subnet=<subnet>|ip-version=<ip-version>>\n\nDesired IP address and/or subnet. This option can be used multiple times.\n--spoofing-protection-enable\n\nEnable spoofing protection for the network interface\n--spoofing-protection-disable\n\nDisable spoofing protection for the network interface\n--security-group <security-group>\n\nSecurity group ID or name. This option can be used multiple times.\n--no-security-groups\n\nDo not set security groups\n--server <server>\n\nVirtual machine ID or name\n--network <network>\n\nNetwork ID or name\n--mac <mac>\n\nMAC address\n\nFor example, to connect the virtual network myprivnet to the virtual machine myvm and allocate the IP address 192.168.129.8, run:# vinfra service compute server iface attach --network myprivnet --fixed-ip 192.168.129.8 --server myvm\nThe created network interface will appear in the vinfra service compute server iface list output:# vinfra service compute server iface list --server myvm\r\n+----------------+----------------+-------------------+-----------------+\r\n| id             | network_id     | mac_address       | fixed_ips       |\r\n+----------------+----------------+-------------------+-----------------+\r\n| 690ed3f2-<...> | 0710372e-<...> | fa:16:3e:54:59:08 | 192.168.129.8   |\r\n| a5b13bf3-<...> | 1bf2c9da-<...> | fa:16:3e:b9:33:bb | 192.168.128.100 |\r\n+----------------+----------------+-------------------+-----------------+\r\n\n\nTo edit a network interface of a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click the ellipsis button next to the interface you want to edit, and then click Edit.\n\nIn the Edit network interface window, modify the network interface parameters as follows:\n\nChange the primary IP address. To update the address inside the VM guest OS, restart the network interface.\nAdd or remove secondary IP addresses.\nModify security groups assigned to the VM.\n\nAfter updating the required parameters, click Save.\n\nClick Done to finish editing VM network interfaces and save your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute server iface set [--fixed-ip <ip-address | ip-address=\r\n                                        <ip-address>,subnet=<subnet> | \r\n                                        ip-version=<ip-version>>]\r\n                                        [--spoofing-protection-enable | \r\n                                        --spoofing-protection-disable]\r\n                                        [--security-group <security-group> | \r\n                                        --no-security-groups]\r\n                                        --server <server> <interface>\n\n--fixed-ip <ip-address|ip-address=<ip-address>,subnet=<subnet>|ip-version=<ip-version>>\n\nDesired IP address and/or subnet. This option can be used multiple times.\n--spoofing-protection-enable\n\nEnable spoofing protection for the network interface\n--spoofing-protection-disable\n\nDisable spoofing protection for the network interface\n--security-group <security-group>\n\nSecurity group ID or name. This option can be used multiple times.\n--no-security-groups\n\nDo not set security groups\n--server <server>\n\nVirtual machine ID or name\n<interface>\n\nNetwork interface ID\n\nFor example, to unassign security groups from the network interface with the ID \r\n611abc06-7557-44c9-bbf8-31fef817e802 attached to the virtual machine myvm, run:# vinfra service compute server iface set --server myvm --no-security-groups 611abc06-7557-44c9-bbf8-31fef817e802\r\n\n\nTo detach a network interface from a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click the ellipsis button next to the interface you want to detach, and then click Remove.\nClick Done to finish editing VM network interfaces and save your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute server iface detach --server <server> <interface>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<interface>\n\nNetwork interface ID\n\nFor example, to detach the network interface with the ID 471e37fd-13ae-4b8f-b70c-90ac02cc4386 from the VM myvm, run:# vinfra service compute server iface detach 471e37fd-13ae-4b8f-b70c-90ac02cc4386 --server myvm\n\nSee also\n\nChanging virtual machine resources\n\nConfiguring virtual machine volumes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server iface attach [--fixed-ip <ip-address | ip-address=\r\n                                           <ip-address>,subnet=<subnet> | \r\n                                           ip-version=<ip-version>>]\r\n                                           [--spoofing-protection-enable | \r\n                                           --spoofing-protection-disable]\r\n                                           [--security-group <security-group> | \r\n                                           --no-security-groups]\r\n                                           --server <server>\r\n                                           --network <network> [--mac <mac>]\n\n--fixed-ip <ip-address|ip-address=<ip-address>,subnet=<subnet>|ip-version=<ip-version>>\n\nDesired IP address and/or subnet. This option can be used multiple times.\n--spoofing-protection-enable\n\nEnable spoofing protection for the network interface\n--spoofing-protection-disable\n\nDisable spoofing protection for the network interface\n--security-group <security-group>\n\nSecurity group ID or name. This option can be used multiple times.\n--no-security-groups\n\nDo not set security groups\n--server <server>\n\nVirtual machine ID or name\n--network <network>\n\nNetwork ID or name\n--mac <mac>\n\nMAC address\n\nFor example, to connect the virtual network myprivnet to the virtual machine myvm and allocate the IP address 192.168.129.8, run:# vinfra service compute server iface attach --network myprivnet --fixed-ip 192.168.129.8 --server myvm\nThe created network interface will appear in the vinfra service compute server iface list output:# vinfra service compute server iface list --server myvm\r\n+----------------+----------------+-------------------+-----------------+\r\n| id             | network_id     | mac_address       | fixed_ips       |\r\n+----------------+----------------+-------------------+-----------------+\r\n| 690ed3f2-<...> | 0710372e-<...> | fa:16:3e:54:59:08 | 192.168.129.8   |\r\n| a5b13bf3-<...> | 1bf2c9da-<...> | fa:16:3e:b9:33:bb | 192.168.128.100 |\r\n+----------------+----------------+-------------------+-----------------+\r\n\n",
                "title": "To attach a network interface to a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server iface set [--fixed-ip <ip-address | ip-address=\r\n                                        <ip-address>,subnet=<subnet> | \r\n                                        ip-version=<ip-version>>]\r\n                                        [--spoofing-protection-enable | \r\n                                        --spoofing-protection-disable]\r\n                                        [--security-group <security-group> | \r\n                                        --no-security-groups]\r\n                                        --server <server> <interface>\n\n--fixed-ip <ip-address|ip-address=<ip-address>,subnet=<subnet>|ip-version=<ip-version>>\n\nDesired IP address and/or subnet. This option can be used multiple times.\n--spoofing-protection-enable\n\nEnable spoofing protection for the network interface\n--spoofing-protection-disable\n\nDisable spoofing protection for the network interface\n--security-group <security-group>\n\nSecurity group ID or name. This option can be used multiple times.\n--no-security-groups\n\nDo not set security groups\n--server <server>\n\nVirtual machine ID or name\n<interface>\n\nNetwork interface ID\n\nFor example, to unassign security groups from the network interface with the ID \r\n611abc06-7557-44c9-bbf8-31fef817e802 attached to the virtual machine myvm, run:# vinfra service compute server iface set --server myvm --no-security-groups 611abc06-7557-44c9-bbf8-31fef817e802\r\n\n",
                "title": "To edit a network interface of a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server iface detach --server <server> <interface>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<interface>\n\nNetwork interface ID\n\nFor example, to detach the network interface with the ID 471e37fd-13ae-4b8f-b70c-90ac02cc4386 from the VM myvm, run:# vinfra service compute server iface detach 471e37fd-13ae-4b8f-b70c-90ac02cc4386 --server myvm\n",
                "title": "To detach a network interface from a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click Add to attach a network interface.\n\nIn the Add network interface window, select a compute network to connect to, and then specify MAC address, IPv4 and/or IPv6 addresses, and security groups. By default, MAC and primary IP addresses are assigned automatically. To specify them manually, clear the Assign automatically check boxes, and enter the desired addresses. Optionally, assign additional IP addresses to the network interface in the Secondary IP addresses section. Note that a secondary IPv6 address is not available for an IPv6 subnet that works in the SLAAC or DHCPv6 stateless mode.\n\nSecondary IP addresses, unlike the primary one, will not be automatically assigned to the network interface inside the virtual machine guest OS. You should assign them manually.\n\n\n\nIf you selected a network with enabled IP address management\n\nIn this case, spoofing protection is enabled and the default security group is selected by default. This security group allows all incoming and outgoing traffic on all the VM ports. If required, you can select another security group or multiple security groups.\nTo disable spoofing protection, clear all of the check boxes and turn off the toggle switch. Security groups cannot be configured with disabled spoofing protection.\n\n\n\n\nIf you selected a network with disabled IP address management\nIn this case, spoofing protection is disabled by default and cannot be enabled. Security groups cannot be configured for such a network.\n\n\n\nAfter specifying the network interface parameters, click Add.\n\nClick Done to finish editing VM network interfaces and save your changes.\n\n",
                "title": "To attach a network interface to a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click the ellipsis button next to the interface you want to edit, and then click Edit.\n\nIn the Edit network interface window, modify the network interface parameters as follows:\n\nChange the primary IP address. To update the address inside the VM guest OS, restart the network interface.\nAdd or remove secondary IP addresses.\nModify security groups assigned to the VM.\n\nAfter updating the required parameters, click Save.\n\nClick Done to finish editing VM network interfaces and save your changes.\n\n",
                "title": "To edit a network interface of a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click Edit in the Network interfaces section.\nIn the Network interfaces window, click the ellipsis button next to the interface you want to detach, and then click Remove.\nClick Done to finish editing VM network interfaces and save your changes.\n\n",
                "title": "To detach a network interface from a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-vm-network-interfaces.html"
    },
    {
        "title": "Creating physical compute networks",
        "content": "Creating physical compute networks\nPhysical networks can host multiple IPv4, IPv6, and dual-stack subnets. IPv6 subnets support three IP address assignment modes: Stateless Address Autoconfiguration (SLAAC), DHCPv6 stateless, and DHCPv6 stateful. The modes are explained in the following table:\n\nIPv6 address mode\nVM address assignment\nExternal router configuration\nDHCP server configuration\n\nSLAAC\nA VM obtains an IPv6 address, the default gateway, and the subnet prefix via Router Advertisements (RA) from an external router. DNS servers and a hostname are not automatically configured.\nAn external router should send RA messages without the M (Managed address configuration) and O (Other configuration) flags. \nThe built-in DHCPv6 server is automatically disabled.\n\nDHCPv6 stateless\nA VM obtains an IPv6 address and the default gateway via RA messages from an external router and other information (the subnet prefix, DNS servers, a hostname) from the built-in DHCPv6 server.\nAn external router should send RA messages with the O flag. \nThe built-in DHCPv6 server is automatically enabled.\n\nDHCPv6 stateful\nA VM obtains an IPv6 address and other information (the subnet prefix, DNS servers, a hostname) from the built-in DHCPv6 server. The default gateway is received via RA messages from an external router.\nAn external router should send RA messages with the M flag. \nThe built-in DHCPv6 server is automatically enabled.\n\nIPv6 address assignment inside a virtual machine also depends on the network settings of a guest operating system.\n\nLimitations\n\nYou can create only one untagged physical network over an infrastructure network.\nWhen providing network access to an entire domain, it is configured only for the existing projects within this domain. Newly created projects will not have access to the network.\nYou cannot connect IPv6 subnets to routers. Therefore, floating IPv6 addresses are not supported.\nIPv6 addresses are not supported for Kubernetes clusters.\nA VM that is connected to a dual-stack network always receives an IPv6 address, if the IPv6 subnet is in the SLAAC or DHCPv6 stateless mode.\nTo be able to work in a SLAAC-enabled IPv6 subnet by using cloud-init, a VM guest operating system must have cloud-init version 19.4 or newer.\nA physical network MTU cannot exceed that of the underlying network interface.\n\nPrerequisites\n\nA clear understanding of the compute architecture, which is explained in Compute network architecture.\nFor VLAN-based networks, a virtual switch is connected to the trunk network interface, as described in Connecting virtual switches to trunk interfaces.\n\nTo add a physical compute network\n\nAdmin panel\n\nOn the Compute > Network > Networks tab, click Create network.\n\nOn the Network configuration step:\n\nEnable or disable IP address management:\n\nWith IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.\nWith IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.\n\nIn any case, you will be able to manually assign static IP addresses from inside the VMs.\n\nSelect the Physical network type.\n\nSpecify a network name, and then select an infrastructure network with the VM public traffic type.\n\nTo create a VLAN-based network, select VLAN and specify a VLAN ID. To create a flat physical network, select Untagged.\nThe network MTU is set to 1500 by default. If required, you can adjust this value according to the MTU of the underlying network interface.\nClick Next.\n\nIf you enabled IP address management, you will move on to the IP address management step, where you can add IPv4 and IPv6 subnets:\n\nTo add an IPv4 subnet\n\nIn the Subnets section, click Add and select IPv4 subnet.\nIn the Add IPv4 subnet window, specify the network\u00e2\u0080\u0099s IPv4 address range and, optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\nEnable or disable the built-in DHCP server:\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\nTo add an IPv6 subnet\n\nIn the Subnets section, click Add and select IPv6 subnet.\nIn the Add IPv6 subnet window, specify the network\u00e2\u0080\u0099s IPv6 address range and, optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\nSelect the desired IPv6 address mode, referring to the table above.\n\nIf you have selected the IPv6 address mode None, enable or disable the built-in DHCP server:\n\nWith the DHCP server enabled, a VM will automatically obtain an IPv6 address.\nWith the DHCP server disabled, you will need to assign an IPv6 address for a VM manually.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nIf you have selected the IPv6 address mode DHCPv6 stateless or DHCPv6 stateful, specify DNS servers that will be send to virtual machines via the built-in DHCP server.\nClick Add.\n\nOn the Network access step, you can configure the network access:\n\nSelect projects to provide network access to:\n\nIf you want the network to be accessed from all existing and new projects, select All projects.\nIf you want the network to be accessed from all existing projects within a domain, select Select projects, and then select the check box next to the required domain.\nIf you want the network to be accessed from a particular project within a domain, select Select projects, click the domain name, and then select the required project.\nIf you do not want to share the network, skip this step by clicking Next.\n\nSelect the access type:\n\nBy providing full access, you allow virtual machines in the selected projects to communicate with this network either directly or via virtual routers.\nBy providing routed access, you allow virtual machines in the selected projects to communicate with this network only via virtual routers.\nBy providing direct access, you only allow a direct connection of virtual machines in the selected projects to this network.\n\nClick Next.\n\nOn the Summary step, review the configuration, and then click Add network.\n\nCommand-line interface\nUse the following command:vinfra service compute network create [--dhcp | --no-dhcp] [--dns-nameserver <dns-nameserver>]\r\n                                      [--allocation-pool <allocation-pool>] [--gateway <gateway> | --no-gateway]\r\n                                      [--rbac-policies <rbac-policies>] [--physical-network <physical-network>]\r\n                                      [--vlan-network <vlan-network>] [--vlan <vlan>] [--mtu <mtu>]\r\n                                      [--cidr <cidr>] [--ipv6-address-mode <ipv6-address-mode>] <network-name>\r\n\n\n--dhcp\n\nEnable DHCP.\n--no-dhcp\n\nDisable DHCP.\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used  multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: ip_addr_start-ip_addr_end. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n--rbac-policies <rbac-policies>\n\nComma-separated list of RBAC policies in the format: <target>:<target_id>:<action> | none. Valid targets: project, domain. Valid actions: direct, full, routed. \u00e2\u0080\u0098*\u00e2\u0080\u0099 is valid target_id for all targets. Pass none to clear out all existing policies.\nExample: domain:default:routed,project:uuid1:full\n\n--physical-network <physical-network>\n\nAn infrastructure network to link to a physical network\n--vlan-network <vlan-network>\n\nA VLAN network to link\n--vlan <vlan>\n\nVirtual network VLAN ID\n--mtu <mtu>\n\nCustom MTU value\n--cidr <cidr>\n\nSubnet range in CIDR notation\n--ipv6-address-mode <ipv6-address-mode>\n\nIPv6 address mode: dhcpv6-stateful, dhcpv6-stateless, slaac\n<network-name>\n\nNetwork name\n\nExample 1. To create an untagged physical network over the Public infrastructure network, with enabled IP management, the specified network parameters, and full network access between all the projects within the specified domain, run:# vinfra service compute network create mypubnet --physical-network Public \\\r\n--cidr 10.136.16.0/22 --gateway 10.136.16.1 --dns-nameserver 10.35.11.7 \\\r\n--allocation-pool 10.136.18.141-10.136.18.148 \\\r\n--rbac-policies domain:cd421db9f3e84e3e8cd2c932c1f7a698:full\nExample 2. To create a VLAN-based physical network over the Public infrastructure network, with the VLAN ID 10, enabled IP management, the specified network parameters, and direct network access between all the projects in the infrastructure, run:# vinfra service compute network create mypubnet_vlan --vlan 10 \\\r\n--physical-network Public --cidr 10.136.16.0/22 --gateway 10.136.16.1 \\\r\n--dns-nameserver 10.35.11.7 --allocation-pool 10.136.18.131-10.136.18.138 \\--rbac-policies project:*:direct\nThe new compute network will appear in the vinfra service compute network list output:# vinfra service compute network list -c id -c name -c cidr -c allocation_pools\r\n+----------------+---------------+------------------+-------------------------------+\r\n| id             | name          | cidr             | allocation_pools              |\r\n+----------------+---------------+------------------+-------------------------------+\r\n| 22674f9d-<...> | mypubnet      | 10.136.16.0/22   | - 10.136.18.141-10.136.18.148   |\r\n| 8f0dc747-<...> | mypubnet_vlan | 10.136.16.0/22   | - 10.136.18.131-10.136.18.138   |\r\n| a0019b43-<...> | myprivnet     | 192.168.128.0/24 | - 192.168.128.2-192.168.128.254 |\r\n+----------------+---------------+------------------+-------------------------------+\n\nSee also\n\nCreating virtual compute networks\n\nEditing and deleting compute networks\n\nCreating virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute network create [--dhcp | --no-dhcp] [--dns-nameserver <dns-nameserver>]\r\n                                      [--allocation-pool <allocation-pool>] [--gateway <gateway> | --no-gateway]\r\n                                      [--rbac-policies <rbac-policies>] [--physical-network <physical-network>]\r\n                                      [--vlan-network <vlan-network>] [--vlan <vlan>] [--mtu <mtu>]\r\n                                      [--cidr <cidr>] [--ipv6-address-mode <ipv6-address-mode>] <network-name>\r\n\n\n--dhcp\n\nEnable DHCP.\n--no-dhcp\n\nDisable DHCP.\n--dns-nameserver <dns-nameserver>\n\nDNS server IP address. This option can be used  multiple times.\n--allocation-pool <allocation-pool>\n\nAllocation pool to create inside the network in the format: ip_addr_start-ip_addr_end. This option can be used multiple times.\n--gateway <gateway>\n\nGateway IP address\n--no-gateway\n\nDo not configure a gateway for this network.\n--rbac-policies <rbac-policies>\n\n\nComma-separated list of RBAC policies in the format: <target>:<target_id>:<action> | none. Valid targets: project, domain. Valid actions: direct, full, routed. \u00e2\u0080\u0098*\u00e2\u0080\u0099 is valid target_id for all targets. Pass none to clear out all existing policies.\nExample: domain:default:routed,project:uuid1:full\n\n--physical-network <physical-network>\n\nAn infrastructure network to link to a physical network\n--vlan-network <vlan-network>\n\nA VLAN network to link\n--vlan <vlan>\n\nVirtual network VLAN ID\n--mtu <mtu>\n\nCustom MTU value\n--cidr <cidr>\n\nSubnet range in CIDR notation\n--ipv6-address-mode <ipv6-address-mode>\n\nIPv6 address mode: dhcpv6-stateful, dhcpv6-stateless, slaac\n<network-name>\n\nNetwork name\n\nExample 1. To create an untagged physical network over the Public infrastructure network, with enabled IP management, the specified network parameters, and full network access between all the projects within the specified domain, run:# vinfra service compute network create mypubnet --physical-network Public \\\r\n--cidr 10.136.16.0/22 --gateway 10.136.16.1 --dns-nameserver 10.35.11.7 \\\r\n--allocation-pool 10.136.18.141-10.136.18.148 \\\r\n--rbac-policies domain:cd421db9f3e84e3e8cd2c932c1f7a698:full\nExample 2. To create a VLAN-based physical network over the Public infrastructure network, with the VLAN ID 10, enabled IP management, the specified network parameters, and direct network access between all the projects in the infrastructure, run:# vinfra service compute network create mypubnet_vlan --vlan 10 \\\r\n--physical-network Public --cidr 10.136.16.0/22 --gateway 10.136.16.1 \\\r\n--dns-nameserver 10.35.11.7 --allocation-pool 10.136.18.131-10.136.18.138 \\--rbac-policies project:*:direct\nThe new compute network will appear in the vinfra service compute network list output:# vinfra service compute network list -c id -c name -c cidr -c allocation_pools\r\n+----------------+---------------+------------------+-------------------------------+\r\n| id             | name          | cidr             | allocation_pools              |\r\n+----------------+---------------+------------------+-------------------------------+\r\n| 22674f9d-<...> | mypubnet      | 10.136.16.0/22   | - 10.136.18.141-10.136.18.148   |\r\n| 8f0dc747-<...> | mypubnet_vlan | 10.136.16.0/22   | - 10.136.18.131-10.136.18.138   |\r\n| a0019b43-<...> | myprivnet     | 192.168.128.0/24 | - 192.168.128.2-192.168.128.254 |\r\n+----------------+---------------+------------------+-------------------------------+\n",
                "title": "To add a physical compute network"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Network > Networks tab, click Create network.\n\nOn the Network configuration step:\n\n\nEnable or disable IP address management:\n\nWith IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.\nWith IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.\n\nIn any case, you will be able to manually assign static IP addresses from inside the VMs.\n\nSelect the Physical network type.\n\nSpecify a network name, and then select an infrastructure network with the VM public traffic type.\n\nTo create a VLAN-based network, select VLAN and specify a VLAN ID. To create a flat physical network, select Untagged.\nThe network MTU is set to 1500 by default. If required, you can adjust this value according to the MTU of the underlying network interface.\nClick Next.\n\n\n\n\n\n\n\nIf you enabled IP address management, you will move on to the IP address management step, where you can add IPv4 and IPv6 subnets:\n\n\nTo add an IPv4 subnet\n\n\nIn the Subnets section, click Add and select IPv4 subnet.\nIn the Add IPv4 subnet window, specify the network\u00e2\u0080\u0099s IPv4 address range and, optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\nEnable or disable the built-in DHCP server:\n\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\n\n\n\n\n\n\n\n\nTo add an IPv6 subnet\n\n\nIn the Subnets section, click Add and select IPv6 subnet.\nIn the Add IPv6 subnet window, specify the network\u00e2\u0080\u0099s IPv6 address range and, optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\nSelect the desired IPv6 address mode, referring to the table above.\n\nIf you have selected the IPv6 address mode None, enable or disable the built-in DHCP server:\n\nWith the DHCP server enabled, a VM will automatically obtain an IPv6 address.\nWith the DHCP server disabled, you will need to assign an IPv6 address for a VM manually.\n\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nIf you have selected the IPv6 address mode DHCPv6 stateless or DHCPv6 stateful, specify DNS servers that will be send to virtual machines via the built-in DHCP server.\nClick Add.\n\n\n\n\n\n\n\n\n\n\n\nOn the Network access step, you can configure the network access:\n\n\nSelect projects to provide network access to:\n\nIf you want the network to be accessed from all existing and new projects, select All projects.\nIf you want the network to be accessed from all existing projects within a domain, select Select projects, and then select the check box next to the required domain.\nIf you want the network to be accessed from a particular project within a domain, select Select projects, click the domain name, and then select the required project.\nIf you do not want to share the network, skip this step by clicking Next.\n\n\n\nSelect the access type:\n\nBy providing full access, you allow virtual machines in the selected projects to communicate with this network either directly or via virtual routers.\nBy providing routed access, you allow virtual machines in the selected projects to communicate with this network only via virtual routers.\nBy providing direct access, you only allow a direct connection of virtual machines in the selected projects to this network.\n\n\nClick Next.\n\n\n\n\n\n\nOn the Summary step, review the configuration, and then click Add network.\n\n",
                "title": "To add a physical compute network"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-physical-compute-networks.html"
    },
    {
        "title": "Removing specific volumes from backup plans",
        "content": "Removing specific volumes from backup plansPOST /v3/{project_id}/os-volume-backup-plan/disassociate\nRemove specific volumes from a backup plan.\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nbackup_plan_id\n\nbody\nstring\nThe backup plan UUID.\n\nbackup_plan_hash\n\nbody\nstring\nThe backup plan hash. It can be obtained from the details of a backup plan (refer to Showing backup plan details).\n\nvolume_ids\n\nbody\narray\nA list of volumes.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"backup_plan_id\": \"4f40774a4da945cda806d59ca7c74355\",\r\n    \"backup_plan_hash\": \"69932aac5f2e4468fe668e5166265485aa3f7cdf\",\r\n    \"volume_ids\": [\r\n        \"a0494a55-fdc0-4233-8c80-a3022ab8f4af\"\r\n    ]\r\n}' https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/os-volume-backup-plan/disassociate\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/removing-volumes-from-backup-plans.html"
    },
    {
        "title": "Setting operations per second for buckets via CLI",
        "content": "Setting operations per second for buckets via CLI\nYou can limit operations rate with the set-limits command and the following parameters: -b specifying the bucket name, -t ops specifying the limit type, and -L default=, get=, put=, list=, or delete= specifying the limit key:# ostor-s3-admin set-limits -b example -t ops -L get=3600\r\nops:default=0.00ops/s\r\nops:get=3600.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=0kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-operations-per-second-for-buckets-via-cli.html"
    },
    {
        "title": "Statistics",
        "content": "Statistics\nYou need to have statistics collection enabled on your S3 gateway. The S3 gateway will save the statistics as regular storage objects. On each S3 storage node, create a file /var/lib/ostor/local/gw.conf with the following contents:# Enable usage statistics collection.\r\nS3_GW_COLLECT_STAT=1\r\n\nRestart the S3 storage service to apply the configuration changes. Run the following command on all S3 storage nodes:# systemctl restart ostor-agentd.service\r\n\nNow you can login to WHMCS. Additional links and S3 management options will be shown in the Client Profile section.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/statistics.html"
    },
    {
        "title": "Listing VPN services",
        "content": "Listing VPN servicesGET /v2.0/vpn/vpnservices\nList VPN services.\nThe list might be empty.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-vpn-services-detail#list-vpn-services\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfields (Optional)\n\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/vpnservices\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvpnservices\n\nbody\narray\nA list of vpnservice objects.\n\nrouter_id\n\npath\nstring\nThe ID of the router.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec VPN service is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\nexternal_v4_ip\n\nbody\nstring\nThe read-only external (public) IPv4 address that is used for the VPN service. The VPN plugin sets this address if an IPv4 interface is available.\n\nexternal_v6_ip\n\nbody\nstring\nThe read-only external (public) IPv6 address that is used for the VPN service. The VPN plugin sets this address if an IPv6 interface is available.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\nsubnet_id (Optional)\nbody\nstring\nIf you specify only a subnet UUID, the networking service allocates an available IP from that subnet to the port. If you specify both a subnet UUID and an IP address, the networking service tries to allocate the address to the port.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nflavor_id\n\nbody\nstring\nThe ID of the flavor.\n\nid\n\nbody\nstring\nThe ID of the VPN service.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"vpnservices\": [\r\n    {\r\n      \"id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n      \"name\": \"vpnservice\",\r\n      \"description\": \"\",\r\n      \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n      \"subnet_id\": null,\r\n      \"router_id\": \"923f2578-079e-40f1-b0a9-23c2b48dbdcd\",\r\n      \"flavor_id\": null,\r\n      \"admin_state_up\": true,\r\n      \"external_v4_ip\": \"10.136.18.148\",\r\n      \"external_v6_ip\": null,\r\n      \"status\": \"PENDING_CREATE\",\r\n      \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-vpn-services.html"
    },
    {
        "title": "Resizing volumes",
        "content": "Resizing volumes\nYou can change volume size only by increasing it. Volumes can be extended for both running (online resizing) and stopped (offline resizing) virtual machines. Online volume resizing allows users to avoid downtime and enables scaling VM\u00a0storage capacity on the fly without service interruption.\nLimitations\n\nYou cannot shrink volumes.\nDuring volume resizing, the file system inside the guest OS is not extended.\nIf you revert a volume to a snapshot that was taken before the volume extension, the new volume size will be retained.\n\nPrerequisites\n\nA volume is created, as described in Creating and deleting volumes.\n\nTo extend a volume\n\nOn the Volumes screen, click a volume.\n Click the pencil icon in the Size field. \nEnter the desired volume capacity, and then click the tick icon.\n\n After the volume is extended, you will need to re-partition the disk inside the guest OS to allocate the added disk space.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/resizing-volumes.html"
    },
    {
        "title": "CloudBase Coriolis Migration Guide",
        "content": "CloudBase Coriolis Migration GuideThis guide describes how to migrate virtual machines from such cloud platforms as VMware and OpenStack to Virtuozzo Hybrid Infrastructure using the CloudBase Coriolis migration solution.Coriolis diagramNetwork ports requirementsOpenStackServiceDefault portProtocolKeystone5000TCPCinder8776TCPNova8774TCPGlance9292TCPNeutron9696TCPSwift8080TCPCeph6789TCPTemporary Migration Worker \u00e2\u0080\u0093 Source22, 4433TCPTemporary Migration Worker \u00e2\u0080\u0093 Destination22, 5986, 443, 5566TCPVMwareServiceDefault portProtocolManagement443TCPCBT Source443TCPTemporary Migration Worker \u00e2\u0080\u0093 Destination22, 4433, 5986, 5566TCPManagement (to all ESXi nodes)902TCPFor more details, refer to the full list of platform ports requirements.InstallationThe Coriolis appliance VM can be installed on any node that has communication with the source and target platforms. In this tutorial, we will install the Coriolis VM on Virtuozzo Hybrid Infrastructure. To do this:1. Create two projects:The coriolis project will be used for the appliance VM.The migration project will be used for the migration target.2. Create the vm-network virtual network and share it between your projects.3. Download the Coriolis VM image with the following credentials:Username: virtuozzoPassword: d2625fd91180511f44e8791f828d1526534d5238a31\n# wget --user=virtuozzo --password=d2625fd91180511f44e8791f828d1526534d5238a3 https://cloudbase.it/downloads/coriolis/coriolis-appliance-latest.ova\n4. Extract the image and convert it to the QCOW2 format:1\n2\n# tar -xvf coriolis-appliance-latest.ova\n# qemu-img convert -f vmdk -O qcow2 disk-0.vmdk coriolis-appliance-latest.qcow2\n5. Configure the OpenStack command-line client to authorize further OpenStack commands:1\n2\n3\n4\n# su - vstoradmin\n$ kolla-ansible post-deploy\n$ exit\n# source /etc/kolla/admin-openrc.sh\n6. Add the image to the compute cluster as Coriolis-appliance:1\n# openstack --insecure image create Coriolis-appliance --disk-format raw --container-format bare --file coriolis-appliance-latest.qcow2\n4. Create the Coriolis VM from the image with the following parameters:Name: Coriolis ApplianceImage: Coriolis-applianceVolume: 60 GBFlavor: large (4 vCPUs, 8 GiB of RAM)Network interfaces: public and vm-network5. Once the VM is created, open its console by clicking Console on the VM right pane.6. Obtain the password to the admin account of the Coriolis Web UI by selecting option 2 - Show UI Login Details.Note: If the environment where you deploy the Coriolis VM does not feature DHCP, you need to log in to the VM console and manually configure its static networking by selecting option 4 - Edit/Inspect Network Settings. It is recommended to reboot the VM after configuring its network settings.7. To access the Coriolis Web UI, open a new browser tab and type in the public IP address of your Coriolis VM. Log in to the Coriolis Web UI specifying the credentials obtained in the previous step.8. On the Dashboard screen, obtain the Appliance ID in the Current Licence section, and then contact the Cloudbase Solutions team to obtain a Coriolis license.Adding cloud endpointsCloud endpoints contain the connection details and credentials for the source and destination cloud platforms participating in VM migration.1. Add the OpenStack endpoint that will be used as a source:1.1. Click New in the top right corner on the screen, select Endpoint, and then select OpenStack.1.2. Specify the parameters of your OpenStack cluster. For example:2. Add the VHI target endpoint that will be used as a target:2.1. Click New in the top right corner on the screen, select Endpoint, and then select OpenStack.2.2. Specify the parameters of your Virtuozzo Hybrid Infrastructure cluster. For example:ReplicationReplication from OpenStack uses Swift backups, while replication from Virtuozzo Hybrid Infrastructure uses Coriolis backups.To start replication, you need to create a replica. Do as follows:1. Click New > Replica, and then specify the required options:Source options:Target options:Network mapping:Storage mapping:Note: The migration image should be a QCOW2 image with CentOS 7/8 and cloud-init installed.2. Click Execute to start the replication process.You will see the replica volume in the target project and a temporary Coriolis virtual machine.MigrationOnce the replication is complete, you can create migration from it:1. Click your replica, and then select Actions > Create Migration.You can choose to either clone the disk or use the replica volume directly.OS morphing is needed for migrating from different platforms, for example, from VMware to Virtuozzo Hybrid Infrastructure.2. Click Migrate to start the migration process.When all of the tasks are finished, the VM is successfully migrated.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/cloudbase-coriolis-migration-guide/"
    },
    {
        "title": "Listing users in a domain",
        "content": "Listing users in a domainGET /v3/users\r\n\nLists users in a domain.\nSource: https://docs.openstack.org/api-ref/identity/v3/index.html?expanded=list-users-detail#list-users\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\ndomain_id (Optional)\nquery\nstring\nFilters the response by a domain ID.\n\nenabled (Optional)\nquery\nstring\nFilters the response by either enabled (true)\r\nor disabled (false) users.\n\nidp_id (Optional)\nquery\nstring\nFilters the response by an identity provider ID.\n\nname (Optional)\nquery\nstring\nFilters the response by a user name.\n\npassword_expires_at (Optional)\nquery\nstring\n\nFilter results based on which user passwords have expired. The query should\r\ninclude an operator and a timestamp with a colon (:) separating\r\nthe two, for example:password_expires_at={operator}:{timestamp}\r\n\n\nValid operators:lt: expiration time lower than the timestamplte: expiration time lower than or equal to the timestampgt: expiration time higher than the timestampgte: expiration time higher than or equal to the timestampeq: expiration time equal to the timestampneq: expiration time not equal to the timestamp\nValid timestamps are of the form: YYYY-MM-DDTHH:mm:ssZ.\n\nFor example:/v3/users?password_expires_at=lt:2016-12-08T22:02:00Z\r\n\nThe example would return a list of users whose password expired before the\r\ntimestamp (2016-12-08T22:02:00Z).\n\nprotocol_id (Optional)\nquery\nstring\nFilters the response by a protocol ID.\n\nunique_id (Optional)\nquery\nstring\nFilters the response by a unique ID.\n\nTo find out domain IDs, send a GET request to /v3/domains (refer to Listing domains).\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/users?domain_id=f2eeaaf15c254d4fa10255796122c8ec\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nusers\n\nbody\narray\nA list of user objects.\n\ndefault_project_id (Optional)\nbody\nstring\n\nThe ID of the default project for the user.\n\ndomain_id\n\nbody\nstring\nThe ID of the domain.\n\nenabled\n\nbody\nboolean\nIf the user is enabled, this value is true.\r\nIf the user is disabled, this value is false.\n\nid\n\nbody\nstring\nThe user ID.\n\nlinks\n\nbody\nobject\nThe links for the user resource.\n\nname\n\nbody\nstring\nThe user name. Must be unique within the owning domain.\n\npassword_expires_at\n\nbody\nstring\n\nThe date and time when the password expires. The time zone\r\nis UTC.\nThis is a response object attribute; not valid for requests.\r\nA null value indicates that the password never expires.\nNew in version 3.7\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\nExample{\r\n  \"users\": [\r\n    {\r\n      \"password_expires_at\": null,\r\n      \"name\": \"admin1\",\r\n      \"links\": {\r\n        \"self\": \"https://<node_IP_addr>:5000/v3/users/ebb3fe534b6443acb8d4e7bb1aa28489\"\r\n      },\r\n      \"email\": \"admin1@example.com\",\r\n      \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n      \"enabled\": true,\r\n      \"id\": \"ebb3fe534b6443acb8d4e7bb1aa28489\",\r\n      \"options\": {}\r\n    },\r\n    {\r\n      \"password_expires_at\": null,\r\n      \"name\": \"user1\",\r\n      \"links\": {\r\n        \"self\": \"https://<node_IP_addr>:5000/v3/users/d74d88c8863048d79feae0f1e5ca2f52\"\r\n      },\r\n      \"email\": \"user1@example.com\",\r\n      \"options\": {\r\n        \"ignore_password_expiry\": true\r\n      },\r\n      \"domain_id\": \"f2eeaaf15c254d4fa10255796122c8ec\",\r\n      \"enabled\": true,\r\n      \"id\": \"d74d88c8863048d79feae0f1e5ca2f52\",\r\n      \"options\": {}\r\n    },\r\n    <...>\r\n  ],\r\n  \"links\": {\r\n    \"self\": \"https://<node_IP_addr>:5000/v3/users?domain_id=f2eeaaf15c254d4fa10255796122c8ec\",\r\n    \"previous\": null,\r\n    \"next\": null\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-users-in-a-domain.html"
    },
    {
        "title": "Technical Validation of Vertica in Eon Mode and Virtuozzo S3 Storage",
        "content": "Technical Validation of Vertica in Eon Mode and Virtuozzo S3 StorageThis document outlines the technical validation process to confirm compatibility between Vertica in Eon Mode and Virtuozzo Hybrid Infrastructure S3 storage. It is intended for customers seeking technical details about the integration, assuming a high level of technical knowledge regarding the described technologies. The document provides details about the technologies used, the environment setup, and the validation tests performed.Technology overviewVerticaVertica is a unified analytics data warehouse with a massively scalable architecture. It supports a wide range of analytical functions, including event and time-series analysis, pattern matching, geospatial analysis, and in-database machine learning. Vertica enables organizations to gain predictive business insights faster than other data warehouses by applying these powerful functions to large and demanding workloads. The platform operates across major public clouds and on-premises environments, integrating with cloud object storage and HDFS without requiring data migration.Vertica offers two deployment modes on a unified platform:Vertica in Enterprise Mode runs on industry-standard servers with tightly coupled storage for consistently high performance in use cases that demand predictable compute capacity.Vertica in Eon Mode has a cloud-native architecture that separates compute from storage, allowing flexible resource management for variable workloads. This architecture enables specific compute resources to be applied to shared storage for different use cases.In this validation, Vertica in Eon Mode leverages S3 API integration, ensuring compatibility with object storage solutions like Virtuozzo Hybrid Infrastructure S3.Virtuozzo Hybrid Infrastructure S3Virtuozzo Hybrid Infrastructure provides scalable, high-performance storage, capable of supporting analytics and machine learning workloads. With support for the widely used S3 API, Virtuozzo\u2019s S3 storage enables real-time analytics and accelerated machine learning training. It serves as a robust foundation for structured and unstructured data lakes with support for hundreds of petabytes (PBs) of data and hundreds of gigabytes (GB/s) of throughput.The key feature of Virtuozzo Hybrid Infrastructure for this validation is its S3 API protocol support that ensures full compatibility with Vertica in Eon Mode.Test environmentArchitecture overview & validation scopeThe validation process used the following technologies:Vertica in Eon Mode version 24.1 deployed on a 3-node physical server cluster.Virtuozzo Hybrid Infrastructure S3 version 6.1 running on a 7-node storage cluster.The architecture for the validation process is illustrated in the diagram below. It depicts the key components used during testing.Data access during the validation was managed through Virtuozzo\u2019s integrated S3 API, ensuring seamless interaction between Vertica and Virtuozzo Hybrid Infrastructure S3.Note: DNS with Round-Robin was used to load balance requests across the Virtuozzo S3 nodes during the tests.ResourcesThe table below provides a list of resources and technologies used to support the validation process.DescriptionOS versionDetails and specificationsVertica Servers3 Vertica database nodesRHEL 9.2CPU Intel(R) Xeon(R) Gold 6226R CPU @2.90GHz, 16 cores256GB RAMVertica Depot resides on 4TB NVMe100 G Mellanox Connect X5Virtuozzo Hybrid Infrastructure S3 cluster7 VHI nodesVirtuozzo Hybrid Infrastructure 6.1CPU AMD EPYC 7352 24-Core Processor128GB RAM8 x The Ultrastar DC SN640 NVMe 7.68TBMellanox ConnectX-5 2x25GbSupporting information and considerationsThe table below contains information related to the testing software.DescriptionDetailsVertica S3 API compatibility suiteDesigned to work with AWS S3 compatible object store.Vertica S3 benchmark suiteThe S3 benchmark suite is based on TPC-DS. TPC Benchmark DS (TPC- DS) is a decision support benchmark that models several applicable aspects of a decision support system, including queries and data maintenance. A benchmark result measures query response time in single user mode, query throughput in multi-user mode, and data maintenance performance for a given hardware, operating system, and data processing system configuration under a controlled, complex, and multi-user decision support workload.Virtuozzo Hybrid Infrastructure S3 configurationThe Virtuozzo Hybrid Infrastructure workflow includes the infrastructure setup and service provisioning. After the infrastructure setup, you will have a storage cluster with the configured network and the highly available management node. On top of the storage cluster, you can deploy and configure S3 services for provisioning to end users. All these tasks can be performed either in the admin panel or via the vinfra command-line tool. All of the deployment and configuration aspects can be found on the Welcome page of the Administrator Guide.Next, you can create and manage the Virtuozzo Hybrid Infrastructure S3 cluster. The process details, prerequisites, and features are described in the Provisioning object storage space section.Validation testsCompatibility testingThe following sets of tests are designed to validate Vertica in Eon Mode platform functionality when integrated with Virtuozzo Hybrid Infrastructure S3 as an on-premises cloud storage appliance.S3 API compatibilityTest goal: Verify that Virtuozzo Hybrid Infrastructure S3 is S3 API compatible with Vertica in Eon Mode.Pass criteria: All of the S3 API tests successfully pass.Test status: The test was successfully executed.Note: Per the EON_On_Prem_OS_S3_ObjectStore_TestingDetails_v3.0 we provided Vertica with the console output showing the results of the test.Vertica Depot ON test with a 5-TB databaseTest goal: Run the test_V3.sh script from the Vertica TPC-DS benchmark suite with a 5-TB database, Depot ON, 1 user, 3 users, and 1 repetition.Pass criteria: The tests pass successfully without errors, and durations are reasonably close to those captured by Vertica in an AWS environment.Test plan: Run the test_V3.sh script with the following parameters:size=5000users=\"1 3\"repetitions=1dataexists=0depotonforqueries=1Non-listed parameters use the default values from the Vertica TPC-DS benchmark suite.Test status: The test was successfully executed.Note: Per the EON_On_Prem_withS3_ObjectStore_TestingDetails_v3.0 we provided Vertica with the console output showing the results of the test.Vertica Depot OFF test with a 5-TB databaseTest goal: Run the test_V3.sh script from the Vertica TPC-DS benchmark suite with a 5-TB database, Depot OFF, 1 user, 3 users, and 1 repetition.Pass criteria: The tests pass successfully without errors, and durations are reasonably close to those captured by Vertica in an AWS environment.Test plan: Run the test_V3.sh script with the following parameters:size=5000users=\"1 3\"repetitions=1dataexists=1depotonforqueries=0Non-listed parameters use the default value from the Vertica TPC-DS benchmark suite.Note: During this test, the data was not generated as it had been already generated during the Depot ON test.Test status: The test was successfully executed.Note: Per the EON_On_Prem_withS3_ObjectStore_TestingDetails_v3.0 we provided Vertica with the console output showing the results of the test.Vertica database revive testTest goal: Revive the database from Virtuozzo Hybrid Infrastructure S3.Pass criteria: The depot is successfully revived.Test plan: Load 10 GB of data to the depot for these tests using the TPC-DS benchmark suite.Test status: The database was successfully revived.Note: Per the EON_On_Prem_withS3_ObjectStore_TestingDetails_v3.0 we provided Vertica with the console output showing the results of the test.Vertica database backup and recoveryTest goal: Back up and recover the Vertica database.Pass criteria: The Vertica database is successfully backed up and recovered.Test plan: Back up and restore the database.Test status: The backup and restore tests were successfully executed.Note: Per the EON_On_Prem_withS3_ObjectStore_TestingDetails_v3.0 we provided Vertica with the console output showing the results of the test.Test resultsThe table below shows the test results for all tasks.This section tracks the pass or conditional pass of all the tests and short comments, if any, for each test. More verbose comments can be added in the Comments section after the table.Note: Pass means that the test meets or beats the benchmark requirements. Conditional Pass means that it is mutually agreed that the test could meet or beat the benchmark requirements with correct sizing. If there were any blocking fails during testing, it would postpone to completing this document until resolved, thus there is no entry for Fail.#Task executionTest result (Pass or Conditional Pass)Comments1S3 API Compatibility TestPASS2Performance and Stress Test (5 TB)Data GenerationPASSLoad DataPASS3Query Test DEPOT ONConcurrency 1, Iteration 1PASSConcurrency 3, Iteration 1PASS4Query Test DEPOT OFFConcurrency 1, Iteration 1PASSConcurrency 3, Iteration 1PASS5External Table TestPASS",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/vertica-integration/"
    },
    {
        "title": "Setting bandwidth per second for buckets via CLI",
        "content": "Setting bandwidth per second for buckets via CLI\nYou can limit outgoing bandwidth of a response with the set-limits command and the following parameters: -b specifying the bucket name, -t bandwidth specifying the limit type, and -L out= specifying the limit key:# ostor-s3-admin set-limits -b example -t bandwidth -L out=100\r\nops:default=0.00ops/s\r\nops:get=3600.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=100kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-bandwidth-per-second-for-buckets-via-cli.html"
    },
    {
        "title": "Changing the self-service panel IP address",
        "content": "Changing the self-service panel IP address\nIf you created the management node high availability (HA) configuration, you can change the virtual IP address of the self-service panel.\nLimitations\n\nYou cannot change the virtual IP address, if the Self-service panel traffic type is assigned along with Compute API or Internal management to the same network. In this case, you need to destroy the management node high availability configuration and re-create it specifying the desired IP address.\n\nPrerequisites\n\nThe HA configuration is created, as described in Enabling management node high availability.\n\nTo change the virtual IP address of the self-service panel\n\nOn the Settings > System settings > Self-service portal screen, click Edit next to the Virtual IP address field.\n\nIn the Edit virtual IP address window, enter the desired IP address, and then click Save.\n\nSee also\n\nConfiguring branding for the self-service panel",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-self-service-virtual-ip.html"
    },
    {
        "title": "Replicating S3 data between datacenters",
        "content": "Replicating S3 data between datacenters\nFor data replication between datacenters, S3 users can use either S3 geo-replication or cross-region replication (CRR):\n\nGeo-replication is designed to improve the distribution of data across geographically distributed data networks. You can enable S3 geo-replication in the admin panel.\nCRR is used to copy objects asynchronously across S3 buckets stored in different clusters and public cloud providers. You can enable CRR by using the Amazon S3-compatible API. For details, refer to the Object Storage Orchestration API Reference.\n\nLimitations\n\nS3 geo-replication and cross-region replication (CRR) are incompatible. With geo-replication enabled, CRR is not available.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/replicating-s3-data-between-datacenters.html"
    },
    {
        "title": "DELETE service ostor-usage",
        "content": "DELETE service ostor-usage\nDescription\nDeletes the statistics object specified by name.\nRequests\nSyntaxDELETE /?ostor-usage&obj=<object_name> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nDELETE service ostor-usage parameters\n\nParameter\t\nDescription\t\nRequired\n\nobj\n\nStatistics object name.\nType: string.\nDefault value: none.\n\nNo\n\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nIf the request is successful, Status204NoContent is returned.\nExamples\nSample request\nThe following request deletes statistics object with name s3-usage-8000000000000003-2016-04-11T13:33:55.000Z-30.DELETE /?ostor-usage&obj=s3-usage-8000000000000003-2016-04-11T13:12:53.000Z-30 /HTTP1.1\r\nDate : Mon, 11 Apr 2016 17:52:05 GMT+3:00\r\nHost : s3.example.com\r\nAuthorization : <authorization_string>\nSample responseHTTP/1.1 204 No Content\r\nDate : Mon, 11 Apr 2016 14:52:05 GMT\r\nx-amz-req-time-micros : 4717\r\nConnection : keep-alive\r\nx-amz-request-id : 80000000000000030006b6bf31262d2c\r\nServer : nginx/1.8.1",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/delete-service-ostor-usage.html"
    },
    {
        "title": "Managing Acronis Backup Storage",
        "content": "Managing Acronis Backup Storage\nThis section describes administrator's tasks for Acronis Backup Storage: changing the redundancy scheme, managing multiple registrations for backup storage in Acronis Cyber Protect Cloud or Acronis Cyber Protect, adding and releasing nodes from the backup storage cluster. In addition, this section covers backup storage geo-replication between two geographically distributed data centers or two different backup destinations.  If you need to delete the backup storage, delete all of its registrations, and then release its nodes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-backup-storage.html"
    },
    {
        "title": "Configuring Windows boot volumes",
        "content": "Configuring Windows boot volumes\nWindows guests have neither Cloudbase-Init nor OpenSSH Server preinstalled by default. You need to install and configure them manually.\nTo install Cloudbase-Init and OpenSSH Server inside a Windows virtual machine\n\nLog in to a Windows VM.\nCreate a new administrator account that will be used for SSH connections and log in with it.\n\nTo install and configure OpenSSH Server:\n\nRun Windows PowerShell with administrator privileges and set the execution policy to unrestricted to be able to run scripts:> Set-ExecutionPolicy Unrestricted\r\n\n\nDownload OpenSSH Server (for example, from the GitHub repository), extract the archive into the C:\\Program Files directory, and then install it by running:> & 'C:\\Program Files\\OpenSSH-Win64\\install-sshd.ps1'\r\n\n\nStart the sshd service and set its startup type to \u00e2\u0080\u009cAutomatic\u00e2\u0080\u009d:> net start sshd> Set-Service sshd -StartupType Automatic\r\n\n\nOpen TCP port 22 for the OpenSSH service in the Windows Firewall:\n\nOn Windows 8.1, Windows Server 2012, and newer versions, run:> New-NetFirewallRule -Protocol TCP -LocalPort 22 -Direction Inbound -Action Allow -DisplayName OpenSSH\r\n\n\nOn Windows Server 2008/2008 R2, run:> netsh advfirewall firewall add rule name=sshd dir=in action=allow protocol=TCP localport=22\r\n\n\nOpen the C:\\ProgramData\\ssh\\sshd_config file:> notepad 'C:\\ProgramData\\ssh\\sshd_config'\r\n\nComment out the following lines at the end of the file:#Match Group administrators#AuthorizedKeysFile __PROGRAMDATA__/ssh/administrators_authorized_keys\r\n\nSave the changes.\n\nCreate the .ssh directory in C:\\Users\\<current_user> and an empty authorized_keys file inside it:> cd C:\\Users\\<current_user>> mkdir .ssh> notepad .\\.ssh\\authorized_keys\r\n\nRemove the .txt extension from the created file:> move .\\.ssh\\authorized_keys.txt .\\.ssh\\authorized_keys\r\n\n\nModify the permissions for the created file to disable inheritance:> icacls .\\.ssh\\authorized_keys /inheritance:r\r\n\n\nDownload Cloudbase-Init from https://cloudbase.it/cloudbase-init/#download, and then install it by following the procedure from the Installation section at https://cloudbase.it/cloudbase-init/.\n\nThe password for the user specified during the Cloudbase-Init installation will be reset on the next VM startup. If this user does not exist, a new user account will be created. You will be able to log in with this account by using the key authentication method or you can set a new password with a customization script. If there are multiple Windows users at the image preparation time, the passwords for other users will not be changed.\nWhen the Cloudbase-Init installation is complete, do not select the option to run Sysprep before clicking Finish. Otherwise, you will not be able to modify cloudbase-init.conf.\n\nRun Windows PowerShell with administrator privileges and open the file C:\\Program Files\\Cloudbase Solutions\\Cloudbase-Init\\conf\\cloudbase-init.conf:> notepad 'C:\\Program Files\\Cloudbase Solutions\\Cloudbase-Init\\conf\\cloudbase-init.conf'\r\n\nAdd metadata_services and plugins on two lines:metadata_services=\\cloudbaseinit.metadata.services.configdrive.ConfigDriveService,\\cloudbaseinit.metadata.services.httpservice.HttpServiceplugins=cloudbaseinit.plugins.common.mtu.MTUPlugin,\\cloudbaseinit.plugins.windows.ntpclient.NTPClientPlugin,\\cloudbaseinit.plugins.common.sethostname.SetHostNamePlugin,\\cloudbaseinit.plugins.windows.createuser.CreateUserPlugin,\\cloudbaseinit.plugins.common.networkconfig.NetworkConfigPlugin,\\cloudbaseinit.plugins.windows.licensing.WindowsLicensingPlugin,\\cloudbaseinit.plugins.common.sshpublickeys.SetUserSSHPublicKeysPlugin,\\cloudbaseinit.plugins.windows.extendvolumes.ExtendVolumesPlugin,\\cloudbaseinit.plugins.common.setuserpassword.SetUserPasswordPlugin,\\cloudbaseinit.plugins.common.userdata.UserDataPlugin,\\cloudbaseinit.plugins.windows.winrmlistener.ConfigWinRMListenerPlugin,\\cloudbaseinit.plugins.windows.winrmcertificateauth.\\ConfigWinRMCertificateAuthPlugin,\\cloudbaseinit.plugins.common.localscripts.LocalScriptsPlugin\r\n\n\nMake sure to remove all backslashes in the lines above.\n\nSave the changes.\n\nWhat's next\n\nEnabling logging for virtual machines\n\nCreating templates",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-windows-boot-volumes.html"
    },
    {
        "title": "Managing domains, users, and projects",
        "content": "Managing domains, users, and projects\nIn the admin panel, you can manage domains and their settings, admin and self-service users, projects and quotas for them. Domain administrators are able to create and assign self-service users to projects, they also can be allowed to manage projects and quotas in the self-service panel.\nPrerequisites\n\nA clear understanding of the concept Multitenancy.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-domains-users-and-projects.html"
    },
    {
        "title": "Managing security",
        "content": "Managing security\nThis section provides the best practices for cluster security. Additionally, it explains how to configure SSL access to the admin panel and data encryption for different tiers, as well as secure root access to cluster nodes via SSH.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-security.html"
    },
    {
        "title": "Setting default quotas via CLI",
        "content": "Setting default quotas via CLI\nYou can limit storage usage for all users or buckets by default with the set-quotas command and the following parameters: -o specifying user for users or bucket for buckets, and -q specifying the usage limit in gigabytes:# ostor-s3-admin set-quotas -o user -q 1024 -V 0100000000000002\r\nversion: '1'\r\nsize: '1024'\r\ntype: 'user'# ostor-s3-admin set-quotas -o bucket -q 256 -V 0100000000000002\r\nversion: '1'\r\nsize: '256'\r\ntype: 'bucket'",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-default-quotas-via-cli.html"
    },
    {
        "title": "Monitoring file storage",
        "content": "Monitoring file storage\nFor advanced monitoring of NFS nodes, services and shares, go to the Monitoring > Dashboard screen, and then click Grafana dashboard. A separate browser tab will open with preconfigured Grafana dashboards. Three of them are dedicated to the NFS service. To see a detailed description for each chart, click i in the chart\u00e2\u0080\u0099s top left corner.\nOn the NFS overview dashboard, note the following charts:\n\nNFS servers availability. The chart shows the availability of NFS hosts. Time periods when the hosts are unavailable will be highlighted in red. In this case, check /var/log/ganesha/ganesha.log and /var/log/ostor/ostorfs.log on these nodes, and report a problem.\nNFS services availability. The chart shows the availability of FS and OS services used by NFS. Time periods when the services are unavailable will be highlighted in red. In this case, check /var/log/ostor/FS-* and /var/log/ostor/OS-* on the corresponding nodes, and report a problem.\nLatency. The chart shows the average latency of read and write I/O operations across all NFS shares.\nIOPS. The chart shows the total numbers of read and write I/O operations, along with their average I/O operations per second across all NFS shares.\nBandwidth. The chart shows the total amount of data read from, or written to, all NFS shares per second.\n\nThe NFS details dashboard is intended for monitoring particular nodes, volumes, or NFS file operations.\n\nThe Object Storage FS details dashboard is intended for monitoring data on particular file services.\nSee also\n\nManaging file storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-file-storage.html"
    },
    {
        "title": "Usage statistics",
        "content": "Usage statistics\nThe S3 gateway can collect usage statistics for S3 users and S3 buckets. The collected data are saved as regular objects. One such object contains statistics for the set usage period.\nTo enable statistics collection on the gateway activity, do the following:\n\nOn each S3 node, create the gateway configuration file /var/lib/ostor/local/gw.conf with the following contents:# Enable usage statistics collection.\r\nS3_GW_COLLECT_STAT=1\nOther options you may need to set:\n\nS3_GW_USAGE_PERIOD\n\nUsage period in a single statistics object, in seconds.\nS3_GW_USAGE_CACHE_TIMEOUT\n\nFrequency of dumping statistics from memory to storage, in seconds.\n\nOn each S3 node, restart the gateway to apply the changes:# systemctl restart ostor-agentd\n\nRestarting the gateway is disruptive for the S3 service.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/usage-statistics.html"
    },
    {
        "title": "Creating VLAN interfaces",
        "content": "Creating VLAN interfaces\nAccording to the requirements listed in Compute cluster requirements, it is recommended to configure VLAN interfaces over network bonds for the compute cluster. You can create these logical interfaces on the Network interfaces tab of the node screen. Additionally, VLAN network interfaces on the compute nodes can be created with the automated procedure outlined in Connecting virtual switches to trunk interfaces.\nLimitations\n\nA network interface must have at least one IPv4 address.\nYou can only assign an IPv6 address manually. Obtaining an IPv6 address via DHCP is not supported.\n\nTo create a VLAN interface\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click Create.\nIn the Create network interface window, select the VLAN type and a network interface to create a VLAN interface from, and then click Next.\nSpecify a number for VLAN in the VLAN ID field. You can choose a number in the range from 1 to 4094.\n\nSelect a network to assign the VLAN to, and then specify the network parameters:\n\nSelect Automatically (DHCP) to obtain the IP address, DNS, and routing settings from the DHCP server.\nSelect Automatically (DHCP address only) to obtain only the IP address from the DHCP server.\nSelect Manually, and then specify the IPv4 address and optionally the IPv6 address in CIDR notation by clicking Add.\n\nDynamic IP address allocation will cause network issues as soon as the IP addresses of cluster nodes change. Configure static IP addresses from the start or as soon as possible.\n\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\n\nEnter the desired MTU value in the MTU field. If you leave Auto, the parent interface MTU will be used.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra node iface create-vlan [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                              [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                              [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                              [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                              [--network <network>] [--node <node>] --iface <iface> --tag <tag>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n--iface <iface>\n\nInterface name\n--tag <tag>\n\nVLAN tag number\n\nFor example, to create a VLAN interface with the tag 100 on the network interface eth2 on the node node002, run:# vinfra node iface create-vlan --iface eth2 --tag 100 --dhcp4 --node node002\n\nSee also\n\nChanging network interface parameters\n\nManaging network interfaces\n\nWhat's next\n\nAdding external DNS servers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface create-vlan [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                              [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                              [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                              [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                              [--network <network>] [--node <node>] --iface <iface> --tag <tag>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n--iface <iface>\n\nInterface name\n--tag <tag>\n\nVLAN tag number\n\nFor example, to create a VLAN interface with the tag 100 on the network interface eth2 on the node node002, run:# vinfra node iface create-vlan --iface eth2 --tag 100 --dhcp4 --node node002\n",
                "title": "To create a VLAN interface"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click Create.\nIn the Create network interface window, select the VLAN type and a network interface to create a VLAN interface from, and then click Next.\nSpecify a number for VLAN in the VLAN ID field. You can choose a number in the range from 1 to 4094.\n\nSelect a network to assign the VLAN to, and then specify the network parameters:\n\nSelect Automatically (DHCP) to obtain the IP address, DNS, and routing settings from the DHCP server.\nSelect Automatically (DHCP address only) to obtain only the IP address from the DHCP server.\nSelect Manually, and then specify the IPv4 address and optionally the IPv6 address in CIDR notation by clicking Add.\n\n\nDynamic IP address allocation will cause network issues as soon as the IP addresses of cluster nodes change. Configure static IP addresses from the start or as soon as possible.\n\n\n\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\n\n\nEnter the desired MTU value in the MTU field. If you leave Auto, the parent interface MTU will be used.\n\nClick Create.\n\n\n\n\n\n",
                "title": "To create a VLAN interface"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-vlan-interfaces.html"
    },
    {
        "title": "Changing placement assignment",
        "content": "Changing placement assignment\nLimitations\n\nAfter adding a node to a placement, VMs already hosted on the node will not be automatically assigned this placement.\n\nA virtual machine that is assigned a placement can only be migrated between nodes in this placement. When adding nodes to placements, make sure to provide migration options for various scenarios, including high availability and maintenance. Avoid situations when VMs cannot migrate because of limitations imposed by placements. In this case, a VM placement can be edited, as described in Managing virtual machines in placements.\n\nPrerequisites\n\nPlacements for compute nodes are created, as described in Creating placements.\n\nTo assign a placement to a node\n\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, click the required placement.\nGo to the Nodes tab, and then click Add.\nSelect the nodes to assign the placement to, and then click Add.\n\nCommand-line interface\nUse the following command:vinfra service compute placement assign --nodes <nodes> <placement>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of compute node IDs or hostnames to assign a compute placement to\n<placement>\n\nPlacement ID or name\n\nFor example, to assign the placement placement1 to the node node005.vstoragedomain, run:# vinfra service compute placement assign --nodes node005 placement1\n\nTo assign a placement to an image\n\nAdmin panel\n\nOpen the Compute > Nodes > Placements tab, and then click the required placement.\nOn the Properties tab, click Add in the Images section.\nSelect one or more images to assign the placement to, and then click Add.\n\nWhen you select this image while creating a VM, the corresponding placement will be selected automatically.\n\nCommand-line interface\nUse the following command:vinfra service compute placement assign --images <images> <placement>\r\n\n\n--images <images>\n\nA comma-separated list of image IDs or names to assign a compute placement to\n<placement>\n\nPlacement ID or name\n\nFor example, to assign the placement placement1 to the image cirros, run:# vinfra service compute placement assign --images cirros placement1\n\nTo assign a placement to a flavor\n\nAdmin panel\n\nOpen the Compute > Nodes > Placements tab, and then click the required placement.\nOn the Properties tab, click Add in the Flavors section.\nSelect one or more flavors to assign the placement to, and then click Add.\n\nWhen you select this flavor while creating a VM, the corresponding placement will be selected automatically.\n\nCommand-line interface\nUse the following command:vinfra service compute placement assign --flavors <images> <placement>\r\n\n\n--flavors <flavors>\n\nA comma-separated list of flavor IDs or names to assign a compute placement to\n<placement>\n\nPlacement ID or name\n\nFor example, to assign the placement placement1 to the flavor 102, run:# vinfra service compute placement assign --flavors 102 placement1\n\nTo remove placement assignments\n\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, click the required placement.\nOn the Properties tab, click the bin icon next to an image or a flavor to remove it.\nGo to the Nodes tab, and click the bin icon next to a node to remove it.\n\nCommand-line interface\n\nView the placement details, to check if the placement is assigned to any images, flavors, or nodes. For example:# vinfra service compute placement show placement1\r\n+-------------+--------------------------------------+\r\n| Field       | Value                                |\r\n+-------------+--------------------------------------+\r\n| description |                                      |\r\n| flavors     | 0                                    |\r\n| id          | e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| images      | 1                                    |\r\n| name        | placement1                           |\r\n| nodes       | 3                                    |\r\n| servers     | 0                                    |\r\n+-------------+--------------------------------------+\r\n\n\nList objects that the placement is assigned to, if any, to find out their names. For example:# vinfra service compute node list --long -c id -c placements\r\n+------------------------+----------------------------------------+\r\n| host                   | placements                             | \r\n+------------------------+----------------------------------------+\r\n| node001.vstoragedomain | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| node002.vstoragedomain | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| node003.vstoragedomain | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| node004.vstoragedomain | []                                     |\r\n| node005.vstoragedomain | []                                     |\r\n+------------------------+----------------------------------------+\r\n# vinfra service compute image list --long -c name -c placements\r\n+--------------------------+----------------------------------------+\r\n| name                     | placements                             |\r\n+--------------------------+----------------------------------------+\r\n| fedora-coreos-x64-k8saas | []                                     |\r\n| amphora-x64-haproxy      | []                                     |\r\n| cirros                   | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n+--------------------------+----------------------------------------+\r\n\n\nRemove all of the placement assignments. For example:# vinfra service compute placement delete-assign --node node001 placement1\r\n# vinfra service compute placement delete-assign --node node002 placement1\r\n# vinfra service compute placement delete-assign --node node003 placement1\r\n# vinfra service compute placement delete-assign --image cirros placement1\n\nSee also\n\nEditing and deleting placements",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute placement assign --nodes <nodes> <placement>\r\n\n\n--nodes <nodes>\n\nA comma-separated list of compute node IDs or hostnames to assign a compute placement to\n<placement>\n\nPlacement ID or name\n\nFor example, to assign the placement placement1 to the node node005.vstoragedomain, run:# vinfra service compute placement assign --nodes node005 placement1\n",
                "title": "To assign a placement to a node"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute placement assign --images <images> <placement>\r\n\n\n--images <images>\n\nA comma-separated list of image IDs or names to assign a compute placement to\n<placement>\n\nPlacement ID or name\n\nFor example, to assign the placement placement1 to the image cirros, run:# vinfra service compute placement assign --images cirros placement1\n",
                "title": "To assign a placement to an image"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute placement assign --flavors <images> <placement>\r\n\n\n--flavors <flavors>\n\nA comma-separated list of flavor IDs or names to assign a compute placement to\n<placement>\n\nPlacement ID or name\n\nFor example, to assign the placement placement1 to the flavor 102, run:# vinfra service compute placement assign --flavors 102 placement1\n",
                "title": "To assign a placement to a flavor"
            },
            {
                "example": "\nCommand-line interface\n\n\nView the placement details, to check if the placement is assigned to any images, flavors, or nodes. For example:# vinfra service compute placement show placement1\r\n+-------------+--------------------------------------+\r\n| Field       | Value                                |\r\n+-------------+--------------------------------------+\r\n| description |                                      |\r\n| flavors     | 0                                    |\r\n| id          | e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| images      | 1                                    |\r\n| name        | placement1                           |\r\n| nodes       | 3                                    |\r\n| servers     | 0                                    |\r\n+-------------+--------------------------------------+\r\n\n\n\nList objects that the placement is assigned to, if any, to find out their names. For example:# vinfra service compute node list --long -c id -c placements\r\n+------------------------+----------------------------------------+\r\n| host                   | placements                             | \r\n+------------------------+----------------------------------------+\r\n| node001.vstoragedomain | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| node002.vstoragedomain | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| node003.vstoragedomain | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n| node004.vstoragedomain | []                                     |\r\n| node005.vstoragedomain | []                                     |\r\n+------------------------+----------------------------------------+\r\n# vinfra service compute image list --long -c name -c placements\r\n+--------------------------+----------------------------------------+\r\n| name                     | placements                             |\r\n+--------------------------+----------------------------------------+\r\n| fedora-coreos-x64-k8saas | []                                     |\r\n| amphora-x64-haproxy      | []                                     |\r\n| cirros                   | - e4230b75-a858-404c-be3b-4b3f2dedb057 |\r\n+--------------------------+----------------------------------------+\r\n\n\n\nRemove all of the placement assignments. For example:# vinfra service compute placement delete-assign --node node001 placement1\r\n# vinfra service compute placement delete-assign --node node002 placement1\r\n# vinfra service compute placement delete-assign --node node003 placement1\r\n# vinfra service compute placement delete-assign --image cirros placement1\n\n\n",
                "title": "To remove placement assignments"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, click the required placement.\nGo to the Nodes tab, and then click Add.\nSelect the nodes to assign the placement to, and then click Add.\n\n",
                "title": "To assign a placement to a node"
            },
            {
                "example": "\nAdmin panel\n\nOpen the Compute > Nodes > Placements tab, and then click the required placement.\nOn the Properties tab, click Add in the Images section.\nSelect one or more images to assign the placement to, and then click Add.\n\nWhen you select this image while creating a VM, the corresponding placement will be selected automatically.\n",
                "title": "To assign a placement to an image"
            },
            {
                "example": "\nAdmin panel\n\nOpen the Compute > Nodes > Placements tab, and then click the required placement.\nOn the Properties tab, click Add in the Flavors section.\nSelect one or more flavors to assign the placement to, and then click Add.\n\nWhen you select this flavor while creating a VM, the corresponding placement will be selected automatically.\n",
                "title": "To assign a placement to a flavor"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Nodes > Placements tab, click the required placement.\nOn the Properties tab, click the bin icon next to an image or a flavor to remove it.\nGo to the Nodes tab, and click the bin icon next to a node to remove it.\n\n",
                "title": "To remove placement assignments"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-placement-assignment.html"
    },
    {
        "title": "13.4. Testing Connection Broker Configuration\u00c2\u00b6",
        "content": "13.4. Testing Connection Broker Configuration | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n13.4. Testing Connection Broker Configuration\u00c2\u00b6\nTo test your Connection Broker, ensure that users are being assigned to the correct policy, and offered the correct desktops. You can test user logins before the user has ever logged into, and been loaded into, Leostream.\n\nNavigate to the Resources > Users menu. As users log into your Leostream environment, their user information is added to this page. You do not need to load users before they can log in.\nClick the Test Login link at the top of the page, shown in the following figure.\n\nIn the Test Login form that opens, enter the name of the user to test in the User Name edit field.\nIf you are allowing the user to specify their domain, select a domain from the Domain drop-down.\nClick Run Test. The Connection Broker searches the authentication server for your user, and then presents a report, for example:\n\nSee \u00e2\u0080\u009cTesting User Role and Policy Assignment\u00e2\u0080\u009d in the Connection Broker Administrator\u00e2\u0080\u0099s Guide for information on interpreting test login results.\n\nImportant\nPlease complete a login test and ensure that your user is offered the correct policy, protocol plan, and desktop before proceeding.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/offering-vhi-desktops/testing-broker-configurations.html"
    },
    {
        "title": "Managing registrations for backup storage",
        "content": "Managing registrations for backup storage\nAfter deploying backup storage, you can use it as a centralized remote storage for backups by adding multiple registrations in different Acronis Cyber Protect Cloud instances.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-registrations-for-backup-storage.html"
    },
    {
        "title": "Managing the compute cluster",
        "content": "Managing the compute cluster\nThis section describes managing the compute cluster, its nodes, and compute networks. It also outlines how to configure placements, images, flavors, and SSH keys for virtual machines. In addition, this section describes operations with the compute storage, its volumes and storage policies.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-the-compute-cluster.html"
    },
    {
        "title": "Preparing nodes for GPU virtualization",
        "content": "Preparing nodes for GPU virtualization\nBefore configuring GPU virtualization, you need to check whether your NVIDIA graphics card supports SR-IOV. The SR-IOV technology enables splitting a single physical device (physical function) into several virtual devices (virtual functions).\n\nLegacy GPUs are based on the NVIDIA Tesla architecture and have no SR-IOV support. For such GPUs, virtualization is performed by creating a mediated device (mdev) over the physical function.\nModern GPUs are based on the NVIDIA Ampere architecture or newer and support SR-IOV. For such GPUs, virtualization is performed by creating a mdev over the virtual function.\n\nFor vGPU to work, enable it on the node by installing the NVIDIA kernel module, and then enable IOMMU. If you are using a modern GPU that based on the NVIDIA Ampere architecture or newer, you need to enable the virtual functions for the GPU. For more details, refer to the official NVIDIA documentation.\nNote that if you want to virtualize a GPU that was previously detached from the node for GPU passthrough, you need to additionally modify the GRUB configuration file.\nTo obtain the GPU PCI address\nList all graphics cards on the node and obtain their PCI addresses:# lspci -D | grep NVIDIA\r\n0000:01:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)\r\n0000:81:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)\nIn the command output, 0000:01:00.0 and \r\n0000:81:00.0 are the PCI addresses of the graphics cards.\nTo enable vGPU on a node\n\nOn the node with the physical GPU, do one of the following:\n\nIf the physical GPU is attached to the node\n\nBlacklist the Nouveau driver:# rmmod nouveau\r\n# echo -e \"blacklist nouveau\\noptions nouveau modeset=0\" > /usr/lib/modprobe.d/nouveau.conf\r\n# echo -e \"blacklist nouveau\\noptions nouveau modeset=0\" > /etc/modprobe.d/nouveau.conf\n\nIf the physical GPU is detached from the node\n\nIn the /etc/default/grub file, locate the GRUB_CMDLINE_LINUX line, and then delete pci-stub.ids=<gpu_vid>:<gpu_pid>. For example, for a GPU with the VID and PID 10de:1eb8, delete pci-stub.ids=10de:1eb8, and check the resulting file:# cat /etc/default/grub | grep CMDLINE\r\nGRUB_CMDLINE_LINUX=\"crashkernel=auto tcache.enabled=0 quiet iommu=pt rd.driver.blacklist=nouveau nouveau.modeset=0\"\n\nRegenerate the GRUB configuration file.\n\nOn a BIOS-based system, run:# /usr/sbin/grub2-mkconfig -o /etc/grub2.cfg --update-bls-cmdline\n\nOn a UEFI-based system, run:# /usr/sbin/grub2-mkconfig -o /etc/grub2-efi.cfg --update-bls-cmdline\n\nReboot the node to apply the changes:# reboot\n\nInstall the vGPU NVIDIA driver:\n\nInstall the kernel-devel and dkms packages:# dnf install kernel-devel dkms\r\n\n\nEnable and start the dkms service:\r\n# systemctl enable dkms.service \r\n# systemctl start dkms.service\n\nInstall the vGPU KVM kernel module from the NVIDIA GRID package with the --dkms option:# bash NVIDIA-Linux-x86_64-xxx.xx.xx-vgpu-kvm*.run --dkms\n\nRe-create the Linux boot image by running:# dracut -f\n\nEnable IOMMU on the node:\n\nRun the pci-helper.py enable-iommu script:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py enable-iommu\nThe script works for both Intel and AMD processors.\n\nReboot the node to apply the changes:# reboot\n\nCheck that IOMMU is successfully enabled in the dmesg output:# dmesg | grep -e DMAR -e IOMMU\r\n[    0.000000] DMAR: IOMMU enabled\n\n[For modern GPUs with SR-IOV support] Enable the virtual functions for your GPU:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py nvidia-sriov-mgr --enable\n\nTo check that vGPU is enabled\n\n[For legacy GPUs without SR-IOV support] Check the /sys/bus/pci/devices/<pci_address>/mdev_supported_types directory. For example, for the GPU with the PCI address 0000:01:00.0, run:ls /sys/bus/pci/devices/0000\\:01:00.0/mdev_supported_types\r\nnvidia-222  nvidia-223  nvidia-224  nvidia-225  nvidia-226  nvidia-227  nvidia-228  nvidia-229  nvidia-230  nvidia-231\r\nnvidia-232  nvidia-233  nvidia-234  nvidia-252  nvidia-319  nvidia-320  nvidia-321\nFor a vGPU-enabled card, the directory contains a list of supported vGPU types. A vGPU type is a vGPU configuration that defines the vRAM size, maximum resolution, maximum number of supported vGPUs, and other parameters.\n\n[For modern GPUs with SR-IOV support] Check supported vGPU types and the number of available instances per vGPU type. For example, for the GPU with the PCI address 0000:c1:00.0, run:# cd /sys/bus/pci/devices/0000:c1:00.0/virtfn0/mdev_supported_types\r\n# grep -vR --include=available_instances 0\r\nnvidia-568/available_instances:1\r\nnvidia-558/available_instances:1\r\nnvidia-556/available_instances:1\nIn the command output, the supported types are nvidia-568, nvidia-558, and nvidia-556 and each virtual function can host one instance.\n\nWhat's next\n\nEnabling PCI passthrough and vGPU support",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-nodes-for-gpu-virtualization.html"
    },
    {
        "title": "Changing retention period for metrics",
        "content": "Changing retention period for metrics\n\nExtending retention period increases the Gnocchi database size insignificantly compared to its default value.\n\nYou can change the retention period for metrics through an archive policy. By default, the ceilometer-low-rate and low policies are used to store metrics. Note that you cannot change the metering granularity for these policies.\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo show the details of a particular archive policy\nUse the gnocchi archive-policy show command. For example:# gnocchi --insecure archive-policy show ceilometer-low-rate\r\n+---------------------+---------------------------------------+\r\n| Field               | Value                                 |\r\n+---------------------+---------------------------------------+\r\n| aggregation_methods | rate:mean, mean                       |\r\n| back_window         | 0                                     |\r\n| definition          | - points: 8640, granularity: 0:05:00, |\r\n|                     |   timespan: 30 days, 0:00:00          |\r\n| name                | ceilometer-low-rate                   |\r\n+---------------------+---------------------------------------+\r\n\nIn the output:\n\n8640  points shows how many aggregates will be retained\nthe granularity of 5 minutes defines the time between two aggregates\nthe timespan of 30 days specifies the retention period for aggregates\n\nTo sum it up, metrics with the ceilometer-low-rate policy will keep 8640 computed aggregates for one month with 5-minute granularity.\nTo change the policy definition\nUse the gnocchi archive-policy update command. To calculate the correct number of points required for the desired timespan, refer to this formula:points = timespan \\ granularity\nFor example, to keep aggregates for 2 months with the 5-minute granularity, specify 17280 points:# gnocchi --insecure archive-policy update ceilometer-low-rate \\\r\n-d points:17280,granularity:0:05:00,timespan:60d\r\n+---------------------+----------------------------------------+\r\n| Field               | Value                                  |\r\n+---------------------+----------------------------------------+\r\n| aggregation_methods | rate:mean, mean                        |\r\n| back_window         | 0                                      |\r\n| definition          | - points: 17280, granularity: 0:05:00, |\r\n|                     |   timespan: 60 days, 0:00:00           |\r\n| name                | ceilometer-low-rate                    |\r\n+---------------------+----------------------------------------+\nSee also\n\nViewing resources, metrics, and measures\n\nViewing outgoing traffic usage\n\nViewing resource usage per project",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-retention-period-for-metrics.html"
    },
    {
        "title": "Configuring throttling for backup storage",
        "content": "Configuring throttling for backup storage\nWhen the percentage of used space on underlying storage reaches a certain threshold, backup storage starts to throttle write operations to slow down the data flow. With the public cloud destination, however, this threshold applies to the local storage usage as backup storage uses the local storage as the staging area.\nBy default, the throttling starting value is 85%. Throttling intensity increases with space consumption, until the percentage of free storage space is half the difference between the total storage space and the throttling starting value. After that, throttling works with maximum intensity until more storage space is added. For example, if the starting value is 85%, throttling maximum intensity will be reached when the storage has (100%-85%)/2 of free space left, that is, 7.5%. The throttling starting value can be increased up to 95%.\nWhen working with public clouds, backup storage throttling may also start for certain backup archives even if there is still enough free space left on the local storage. This happens when the size occupied by a single backup archive in the staging area is greater than or equal to the per-archive threshold. By default, this threshold is set to 300 MiB, which is a recommended value for small clusters below 500 GiB in size. If your cluster has more storage space, you can increase the throttling starting value per archive:\n\nFor medium clusters with 500 GiB to 1 TiB of available space, it is recommended to set a value of 1 to 3 GiB, depending on the number of files on the storage.\nFor large clusters above 1 TiB in size, the throttling starting value can be changed up to 100 GiB.\n\nTo monitor backup storage throttling, go to Storage services > Backup storage > Overview and check the Append throttling chart.\nPrerequisites\n\nThe backup storage cluster is created and registered in the Cloud Management Panel, as described in Provisioning Acronis Backup Storage space.\n\nTo change the throttling starting value\n\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Settings tab, and then click Throttling configuration.\nSelect the desired throttling starting value for local storage.\n[For backup storage with the public cloud destination] Select the desired throttling starting value per archive.\nClick Save.\n\nCommand-line interface\nUse the following command:vinfra service backup throttling set [--soft-threshold <soft_threshold>]\r\n                                     [--s3-threshold <s3_threshold>]\r\n\n\n--soft-threshold <soft_threshold>\n\nSoft threshold limit, in percent. The valid range is 85-95%.\n--s3-threshold <s3_threshold>\n\nObject storage threshold limit, in MiB. Must be greater than the default limit of 300 MiB. This parameter can only be used for backup storage with the public cloud destination.\n\nFor example, to change the throttling starting value to 90%, run:# vinfra service backup throttling set --soft-threshold 90\nThe updated parameters will be shown in the vinfra service backup throttling show output:# vinfra service backup throttling show\r\n+----------------+-------+\r\n| Field          | Value |\r\n+----------------+-------+\r\n| soft_threshold | 90    |\r\n+----------------+-------+\n\nTo reset the throttling starting value to default\n\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Settings tab, and then click Throttling configuration.\nClick Reset to default.\nIn the confirmation window, click Reset.\n\nCommand-line interface\nUse the following command:vinfra service backup throttling reset\nFor example, to reset the throttling starting value to 85%, run:# vinfra service backup throttling reset\nThe updated parameters will be shown in the vinfra service backup throttling show output:# vinfra service backup throttling show\r\n+----------------+-------+\r\n| Field          | Value |\r\n+----------------+-------+\r\n| soft_threshold | 85    |\r\n+----------------+-------+\n\nSee also\n\nMonitoring Acronis Backup Storage\n\nScaling the storage cluster",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup throttling set [--soft-threshold <soft_threshold>]\r\n                                     [--s3-threshold <s3_threshold>]\r\n\n\n--soft-threshold <soft_threshold>\n\nSoft threshold limit, in percent. The valid range is 85-95%.\n--s3-threshold <s3_threshold>\n\nObject storage threshold limit, in MiB. Must be greater than the default limit of 300 MiB. This parameter can only be used for backup storage with the public cloud destination.\n\nFor example, to change the throttling starting value to 90%, run:# vinfra service backup throttling set --soft-threshold 90\nThe updated parameters will be shown in the vinfra service backup throttling show output:# vinfra service backup throttling show\r\n+----------------+-------+\r\n| Field          | Value |\r\n+----------------+-------+\r\n| soft_threshold | 90    |\r\n+----------------+-------+\n",
                "title": "To change the throttling starting value"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service backup throttling reset\nFor example, to reset the throttling starting value to 85%, run:# vinfra service backup throttling reset\nThe updated parameters will be shown in the vinfra service backup throttling show output:# vinfra service backup throttling show\r\n+----------------+-------+\r\n| Field          | Value |\r\n+----------------+-------+\r\n| soft_threshold | 85    |\r\n+----------------+-------+\n",
                "title": "To reset the throttling starting value to default"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Settings tab, and then click Throttling configuration.\nSelect the desired throttling starting value for local storage.\n[For backup storage with the public cloud destination] Select the desired throttling starting value per archive.\nClick Save.\n\n",
                "title": "To change the throttling starting value"
            },
            {
                "example": "\nAdmin panel\n\nOn the Storage services > Backup storage screen, go to the Settings tab, and then click Throttling configuration.\nClick Reset to default.\nIn the confirmation window, click Reset.\n\n",
                "title": "To reset the throttling starting value to default"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-throttling-for-backup-storage.html"
    },
    {
        "title": "Managing identity providers",
        "content": "Managing identity providers\nBesides creating local users manually, you can add users from external identity providers and automatically map them to local domain groups.  User authentication can be based either on the Implicit Flow or Authorization Code Flow of the OpenID Connect (OIDC) protocol.\nUsers imported from identity providers are called Federated, that is, shared between different identity management systems. Unlike local users, federated users do not have credentials set in Virtuozzo Hybrid Infrastructure. They log in to the admin or self-service panels  by using their respective credentials from the primary identity management system. The set of actions available to federated users is defined by the roles you assign to their local domain groups.\nLimitations\n\nWhen federated users are removed by their identity provider, they are not automatically deleted from the infrastructure.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-identity-providers.html"
    },
    {
        "title": "Setting quotas for users via REST API",
        "content": "Setting quotas for users via REST API\nYou can limit storage usage per user with the ostor-quotas service and the following parameters: emailAddress specifying the email address and quota-size specifying the usage limit in gigabytes:# s3_curl PUT \"http://s3.example.com/?ostor-quotas&emailAddress=user@example.com&quota-size=1024\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-quotas-for-users-via-rest-api.html"
    },
    {
        "title": "Making a bootable USB drive",
        "content": "Making a bootable USB drive\nPrerequisites\n\nThe size of a USB drive is at least 8 GB.\n\n To copy the distribution image to a USB drive on Linux\nUse the dd utility:# dd if=image.iso of=/dev/sdb\n\nBe careful to specify the correct drive to transfer the image to.\n\n To copy the distribution image to a USB drive on Windows\n\nGo to https://rufus.ie/ and download the portable version.\nLaunch Rufus.\nIn the Drive Properties section, select your flash drive from the Device drop-down menu, and then click SELECT. Then, select the distribution image from your local machine. You can also change other options, if needed.\n\nClick START.\n\nIn a pop-up window, select Write in DD Image mode and click OK.\n\nWhat's next\n\nInstalling in the attended mode",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/making-a-bootable-usb-drive.html"
    },
    {
        "title": "Creating and deleting backups manually",
        "content": "Creating and deleting backups manually\nYou can initiate an instant backup job for a single volume by creating a backup manually. Such a backup does not have a retention policy and can only be deleted manually.\nPrerequisites\n\nThe backup service is enabled in the command-line interface, as described in Provisioning the backup service.\n\nTo manually create a volume backup\n\nAdmin panel\n\nOn the Compute > Storage > Volumes screen, click a volume that you want to back up.\nOn the volume right pane, click Create backup now.\n\nOnce the backup is created, it will appear on the Compute > Backup > Recovery points screen.\n\nCommand-line interface\nUse the following command:vinfra service compute volume backup create [--name <name>] [--description <description>] <volume>\n\n--name <name>\n\nVolume backup name\n--description <description>\n\nVolume backup description\n<volume>\n\nVolume ID or name\n\nFor example, to create the backup mybackup of the volume vm1/cirros/Boot volume, run:# vinfra service compute volume backup create 'vm1/cirros/Boot volume' --name mybackup\nThe backup will appear in the vinfra service compute volume backup list output:# vinfra service compute volume backup list\r\n+--------------------------------------+----------+-----------+--------------------------------------+\r\n| id                                   | name     | status    | volume_id                            |\r\n+--------------------------------------+----------+-----------+--------------------------------------+\r\n| 2ac79114-ab96-4c2a-8019-05819bbcdc51 | mybackup | available | 5a66c317-a218-4963-9f3e-d8f459e3d343 |\r\n+--------------------------------------+----------+-----------+--------------------------------------+\n\nTo manually delete a volume backup\n\nAdmin panel\n\nOn the Compute > Backup > Recovery points screen, click the recovery point that you want to delete.\nClick Delete in the confirmation window.\n\nAfter deleting a recovery point, all its data will be lost.\n\nCommand-line interface\nUse the following command:vinfra service compute volume backup delete [--force] <volume-backup>\n\n<volume-backup>\n\nVolume backup ID or name\n--force\n\nForcibly delete a backup\n\nFor example, to delete the backup mybackup, run:# vinfra service compute volume backup delete mybackup\n\nSee also\n\nCreating backup plans\n\nManaging compute backup quotas\n\nWhat's next\n\nRestoring volumes from backups\n\nRestoring virtual machines from backups",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume backup create [--name <name>] [--description <description>] <volume>\n\n--name <name>\n\nVolume backup name\n--description <description>\n\nVolume backup description\n<volume>\n\nVolume ID or name\n\nFor example, to create the backup mybackup of the volume vm1/cirros/Boot volume, run:# vinfra service compute volume backup create 'vm1/cirros/Boot volume' --name mybackup\nThe backup will appear in the vinfra service compute volume backup list output:# vinfra service compute volume backup list\r\n+--------------------------------------+----------+-----------+--------------------------------------+\r\n| id                                   | name     | status    | volume_id                            |\r\n+--------------------------------------+----------+-----------+--------------------------------------+\r\n| 2ac79114-ab96-4c2a-8019-05819bbcdc51 | mybackup | available | 5a66c317-a218-4963-9f3e-d8f459e3d343 |\r\n+--------------------------------------+----------+-----------+--------------------------------------+\n",
                "title": "To manually create a volume backup"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume backup delete [--force] <volume-backup>\n\n<volume-backup>\n\nVolume backup ID or name\n--force\n\nForcibly delete a backup\n\nFor example, to delete the backup mybackup, run:# vinfra service compute volume backup delete mybackup\n",
                "title": "To manually delete a volume backup"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes screen, click a volume that you want to back up.\nOn the volume right pane, click Create backup now.\n\nOnce the backup is created, it will appear on the Compute > Backup > Recovery points screen.\n",
                "title": "To manually create a volume backup"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Backup > Recovery points screen, click the recovery point that you want to delete.\nClick Delete in the confirmation window.\n\nAfter deleting a recovery point, all its data will be lost.\n",
                "title": "To manually delete a volume backup"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-and-deleting-backups-manually.html"
    },
    {
        "title": "Connecting to OpenStack command-line interface",
        "content": "Connecting to OpenStack command-line interface\nFor managing the compute cluster, you can also use the OpenStack command-line client, which is automatically installed along with the Virtuozzo Hybrid Infrastructure.\nTo connect to and be able to use the OpenStack CLI\n\nLocate the node with the management role in the admin panel. Open the Infrastructure > Nodes screen. The management node runs the  Admin panel service.\n\nAccess the management node via SSH and log in as the service user. For example:# ssh node001.vstoragedomain\r\n# su - vstoradmin\r\n\n\nGenerate the admin OpenRC script that sets environment variables:# kolla-ansible post-deploy\r\n\nThe command will create the /etc/kolla/admin-openrc.sh bash script:export OS_PROJECT_DOMAIN_NAME=Default\r\nexport OS_USER_DOMAIN_NAME=Default\r\nexport OS_PROJECT_NAME=admin\r\nexport OS_USERNAME=vstorage-service-user\r\nexport OS_PASSWORD=<password>\r\nexport OS_AUTH_URL=https://<MN_IP_address>:5000/v3\r\nexport OS_IDENTITY_API_VERSION=3\r\nexport OS_AUTH_TYPE=password\r\nexport OS_INSECURE=true\r\nexport PYTHONWARNINGS=\"ignore:Unverified HTTPS request is being made\"\r\nexport NOVACLIENT_INSECURE=true\r\nexport NEUTRONCLIENT_INSECURE=true\r\nexport CINDERCLIENT_INSECURE=true\r\nexport OS_PLACEMENT_API_VERSION=1.22\r\n\nBy default, the script is created to authorize OpenStack commands in the admin project under the vstorage-service-user user for managing the compute cluster with administrative privileges.\n\nTo perform administrative actions, run this script:\n\nYou need to run the script each session.\n# source /etc/kolla/admin-openrc.sh\r\n\n\nIf you want to work in another project under another user, you need to make changes to the admin-openrc.sh script. For example, to authorize OpenStack commands in the myproject project under the myuser user within the mydomain domain, do the following:\n\nCopy the script to the chosen directory with a new name. For example:# cp /etc/kolla/admin-openrc.sh /root/myscript.sh\r\n\n\nOpen the copied script for editing and change the first five variables as follows:export OS_PROJECT_DOMAIN_NAME=mydomain\r\nexport OS_USER_DOMAIN_NAME=mydomain\r\nexport OS_PROJECT_NAME=myproject\r\nexport OS_USERNAME=myuser\r\nexport OS_PASSWORD=<myuser_password>\r\n\nLeave other variables as is and save your changes.\n\nRun the modified script:\n\nYou need to run the script each session.\n# source /root/myscript.sh\r\n\n\nNow you can work in the project you have authorized in by executing OpenStack commands with the --insecure option. For example:# openstack --insecure server list\r\n+---------------------+------+--------+------------------------+-------+--------+\r\n| ID                  | Name | Status | Networks               | Image | Flavor |\r\n+---------------------+------+--------+------------------------+-------+--------+\r\n| 32b0f95d-477f-<...> | vm1  | ACTIVE | private=192.168.128.87 |       | tiny   |\r\n+---------------------+------+--------+------------------------+-------+--------+\r\n\nSee also\n\nUsing application credentials\n\nChanging parameters in OpenStack configuration files",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/connecting-to-openstack-command-line-interface.html"
    },
    {
        "title": "Best practices for using S3 in Virtuozzo Hybrid Infrastructure",
        "content": "Best practices for using S3 in Virtuozzo Hybrid Infrastructure\nThis section offers recommendations on how to best use the S3 feature with Virtuozzo Hybrid Infrastructure.\nS3 bucket and key naming policies\nIt is recommended to use bucket names that comply with DNS naming conventions:\n\nMust be from 3 to 63 characters long\n\nMust start and end with a lowercase letter or number\n\nCan contain lowercase letters, numbers, periods (.), hyphens (-), and underscores (_)\n\nCan be a series of valid name parts  separated by periods\n\nAn object key can be a string of any UTF-8 encoded characters, up to 1024 bytes long.\nUse multipart uploads for large objects\nObject storage supports uploading objects as large as 5 GB per single PUT request (5 TB via multipart upload). Upload performance can be improved by splitting large objects into pieces and uploading them concurrently (thus dividing the load between multiple OS services) with the multipart upload API.\nIt is recommended to use multipart uploads for objects larger than 5 MB.\nSee also\n\nManaging S3 users\n\nManaging S3 buckets",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/best-practices-for-using-s3.html"
    },
    {
        "title": "Transferring volumes between projects",
        "content": "Transferring volumes between projects\nThere is no direct way to migrate a virtual machine between different projects. However, you can transfer the VM boot volume, and then create a new VM from it. You can transfer both boot and non-boot volumes to projects within different domains.\nLimitations\n\nYou can only transfer volumes with the \"Available\" status.\nTransferring volumes that have snapshots breaks the snapshots.\n\nPrerequisites\n\nAccess to the compute API depends on your provider's settings.  You need to obtain from your provider the instruction how to connect to the API.\nYou have login credentials for the source and destination projects.\nIf you want to transfer a boot volume that is attached to a VM, clone this volume first, as described in Cloning volumes.\nIf you want to transfer a non-boot volume that is attached to a VM, detach it first, as described in Attaching and detaching volumes.\n\nTo transfer a volume between two projects\r\n\r\n\n\nLog in to the source project by changing the environment variables to the project credentials. For example:export OS_PROJECT_DOMAIN_NAME=domain1\r\nexport OS_USER_DOMAIN_NAME=domain1\r\nexport OS_PROJECT_NAME=project1\r\nexport OS_USERNAME=user1\r\nexport OS_PASSWORD=password\n\nList all volumes within your project to find out the ID of the volume you want to transfer:# openstack --insecure volume list\r\n+--------------------------------------+-------------------+-----------+------+\r\n| ID                                   | Name              | Status    | Size |\r\n+--------------------------------------+-------------------+-----------+------+\r\n| 2c8386fa-331b-4ba8-9e4c-de690969a4c8 | win10/Boot volume | available |   64 |\r\n+--------------------------------------+-------------------+-----------+------+\n\nCreate a transfer request by specifying the ID of the chosen volume. For example:# openstack --insecure volume transfer request create c0d4cf0e-48e3-417d-b6fc-f1fb36571c5f\r\n+------------+--------------------------------------+\r\n| Field      | Value                                |\r\n+------------+--------------------------------------+\r\n| auth_key   | 75fcf37d56f40182                     |\r\n| created_at | 2022-04-27T09:00:11.776511           |\r\n| id         | b9b835a3-ed41-489a-9552-483fae33c549 |\r\n| name       | None                                 |\r\n| volume_id  | c0d4cf0e-48e3-417d-b6fc-f1fb36571c5f |\r\n+------------+--------------------------------------+\r\n\nSave the request id and auth-key from the command output, to accept the transfer in the other project.\n\nLog in to the destination project by changing the environment variables to the project credentials. For example:export OS_PROJECT_DOMAIN_NAME=domain1\r\nexport OS_USER_DOMAIN_NAME=domain1\r\nexport OS_PROJECT_NAME=project2\r\nexport OS_USERNAME=user2\r\nexport OS_PASSWORD=password\n\nAccept the transfer request by specifying the request ID and authorization key. For example:# openstack --insecure volume transfer request accept --auth-key 75fcf37d56f40182 \\\r\nb9b835a3-ed41-489a-9552-483fae33c549\n\nOnce the volume is moved to the other project, you can create a virtual machine from it, as described in Creating virtual machines.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/transferring-volumes-between-projects.html"
    },
    {
        "title": "Viewing audit log",
        "content": "Viewing audit log\nIn the audit log, you can view all of the management operations performed by users and their activity events. The audit log is stored in /var/log/vstorage-ui-backend/audit.log on the management node.\nTo view a log entry\n\nAdmin panel\n\nGo to the Monitoring > Audit log screen to view the list of audit log entries. \nClick the required log entry on the list to open its details.\n\nCommand-line interface\nUse the following command:vinfra cluster auditlog show <auditlog>\r\n\n\n<auditlog>\n\nAudit log ID\n\nFor example, to the details of the audit log entry about the storage cluster creation, run:\r\n# vinfra cluster auditlog list\r\n+----+-----------+------------------------+--------------------------+---------------------+\r\n| id | username  | type                   | activity                 | timestamp           |\r\n+----+-----------+------------------------+--------------------------+---------------------+\r\n| 8  | admin     | CreateCluster          | Create cluster           | 2021-09-07T17:39:16 |\r\n| 7  | anonymous | RegisterNewNode        | Register new node        | 2021-09-07T17:39:14 |\r\n| 6  | anonymous | RegisterNewNode        | Register new node        | 2021-09-07T17:39:10 |\r\n| 5  | admin     | GetRegistrationToken   | Get registration token   | 2021-09-07T17:39:08 |\r\n| 4  | admin     | GetRegistrationToken   | Get registration token   | 2021-09-07T17:39:04 |\r\n| 3  | admin     | LoginUser              | User login               | 2021-09-07T17:39:04 |\r\n| 2  | anonymous | UpdateNodeRegistration | Update node registration | 2021-09-07T17:39:02 |\r\n| 1  | anonymous | RegisterNewNode        | Register new node        | 2021-09-07T17:38:54 |\r\n+----+-----------+------------------------+--------------------------+---------------------+\r\n# vinfra cluster auditlog show 8\r\n+--------------+--------------------------------------+\r\n| Field        | Value                                |\r\n+--------------+--------------------------------------+\r\n| activity     | Create cluster                       |\r\n| cluster_id   |                                      |\r\n| cluster_name |                                      |\r\n| component    | Cluster                              |\r\n| details      | - id: node                           |\r\n|              |   name: Node                         |\r\n|              |   value: node001.vstoragedomain      |\r\n| id           | 8                                    |\r\n| message      | Create cluster \"cluster1\"            |\r\n| node_id      | c3b2321a-7c12-8456-42ce-8005ff937e12 |\r\n| result       | success                              |\r\n| task_id      | r-38c61bb2c7144cef                   |\r\n| timestamp    | 2021-09-07T17:39:16                  |\r\n| type         | CreateCluster                        |\r\n| user_id      | c727a901a6444ee1a8ad31e3d5b53b3a     |\r\n| username     | admin                                |\r\n+--------------+--------------------------------------+\n\nSee also\n\nUsing Filebeat for log forwarding\n\nViewing alerts\n\nViewing cluster logs",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster auditlog show <auditlog>\r\n\n\n<auditlog>\n\nAudit log ID\n\nFor example, to the details of the audit log entry about the storage cluster creation, run:\r\n# vinfra cluster auditlog list\r\n+----+-----------+------------------------+--------------------------+---------------------+\r\n| id | username  | type                   | activity                 | timestamp           |\r\n+----+-----------+------------------------+--------------------------+---------------------+\r\n| 8  | admin     | CreateCluster          | Create cluster           | 2021-09-07T17:39:16 |\r\n| 7  | anonymous | RegisterNewNode        | Register new node        | 2021-09-07T17:39:14 |\r\n| 6  | anonymous | RegisterNewNode        | Register new node        | 2021-09-07T17:39:10 |\r\n| 5  | admin     | GetRegistrationToken   | Get registration token   | 2021-09-07T17:39:08 |\r\n| 4  | admin     | GetRegistrationToken   | Get registration token   | 2021-09-07T17:39:04 |\r\n| 3  | admin     | LoginUser              | User login               | 2021-09-07T17:39:04 |\r\n| 2  | anonymous | UpdateNodeRegistration | Update node registration | 2021-09-07T17:39:02 |\r\n| 1  | anonymous | RegisterNewNode        | Register new node        | 2021-09-07T17:38:54 |\r\n+----+-----------+------------------------+--------------------------+---------------------+\r\n# vinfra cluster auditlog show 8\r\n+--------------+--------------------------------------+\r\n| Field        | Value                                |\r\n+--------------+--------------------------------------+\r\n| activity     | Create cluster                       |\r\n| cluster_id   |                                      |\r\n| cluster_name |                                      |\r\n| component    | Cluster                              |\r\n| details      | - id: node                           |\r\n|              |   name: Node                         |\r\n|              |   value: node001.vstoragedomain      |\r\n| id           | 8                                    |\r\n| message      | Create cluster \"cluster1\"            |\r\n| node_id      | c3b2321a-7c12-8456-42ce-8005ff937e12 |\r\n| result       | success                              |\r\n| task_id      | r-38c61bb2c7144cef                   |\r\n| timestamp    | 2021-09-07T17:39:16                  |\r\n| type         | CreateCluster                        |\r\n| user_id      | c727a901a6444ee1a8ad31e3d5b53b3a     |\r\n| username     | admin                                |\r\n+--------------+--------------------------------------+\n",
                "title": "To view a log entry"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Monitoring > Audit log screen to view the list of audit log entries. \nClick the required log entry on the list to open its details.\n\n\n\n\n\n",
                "title": "To view a log entry"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-audit-log.html"
    },
    {
        "title": "Enabling SNMP access",
        "content": "Enabling SNMP access\nTo  enable the SNMP access on the node\n\nOpen UDP port 161 on the management node as follows:\n\nOn the Infrastructure > Networks screen, and then click Edit.\nAdd the SNMP traffic type to your public network by selecting the corresponding check box.\nClick Save.\n\nGo to Settings > System settings > SNMP, and then turn on the toggle switch Enable SNMP on the management node. The network management system (SNMP monitor) will be enabled, giving you access to the cluster via the SNMP protocol.\n\nClick the provided link to download the MIB file, and then set it up in your SNMP monitor.\n\nEnable sending SNMP traps to your SNMP monitor as follows:\n\nSelect Send SNMP traps to this network management system.\n\nSpecify the IP address, Port, and Community of the network management system.\nBy default, the snmptrapd daemon uses port 162. The default community is public.\n\nIf required, click Send test trap to test the service.\n\nClick Save to apply the changes.\n\nWhat's next\n\nAccessing cluster information objects via SNMP\n\nListening to SNMP traps\n\nMonitoring the cluster with Zabbix",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-snmp-access.html"
    },
    {
        "title": "Creating VPN endpoint groups",
        "content": "Creating VPN endpoint groupsPOST /v2.0/vpn/endpoint-groups\nCreate a VPN endpoint group.\nThe endpoint group contains one or more endpoints of a specific type that you can use to create a VPN connections.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-vpn-endpoint-group-detail#create-vpn-endpoint-group\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nendpoints\n\nbody\narray\nList of endpoints of the same type, for the endpoint group. The values will depend on the type.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ntype\n\nbody\nstring\nThe type of the endpoints in the group. A valid value is subnet, cidr, network, router, or vlan. Only subnet and cidr are supported at this moment.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"endpoint_group\": {\r\n        \"endpoints\": [\r\n            \"10.2.0.0/24\",\r\n            \"10.3.0.0/24\"\r\n        ],\r\n        \"type\": \"cidr\",\r\n        \"name\": \"peers\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/endpoint-groups\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nendpoints\n\nbody\narray\nList of endpoints of the same type, for the endpoint group. The values will depend on the type.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ntype\n\nbody\nstring\nThe type of the endpoints in the group. A valid value is subnet, cidr, network, router, or vlan. Only subnet and cidr are supported at this moment.\n\nid\n\nbody\nstring\nThe ID of the VPN endpoint group.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"endpoint_group\": {\r\n    \"id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"peers\",\r\n    \"description\": \"\",\r\n    \"type\": \"cidr\",\r\n    \"endpoints\": [\r\n      \"10.2.0.0/24\",\r\n      \"10.3.0.0/24\"\r\n    ],\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-vpn-endpoint-groups.html"
    },
    {
        "title": "Deleting IPsec policies",
        "content": "Deleting IPsec policiesDELETE /v2.0/vpn/ipsecpolicies/{ipsecpolicy_id}\nDelete an IPsec policy.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=remove-ipsec-policy-detail#remove-ipsec-policy\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicy_id\n\npath\nstring\nThe ID of the IPsec policy.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ipsecpolicies/805ab779-e91c-42db-b6b9-591156d9634e\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-ipsec-policies.html"
    },
    {
        "title": "13.1. Defining Pool-Based Plans\u00c2\u00b6",
        "content": "13.1. Defining Pool-Based Plans | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n13.1. Defining Pool-Based Plans\u00c2\u00b6\nAfter you separate your desktops into pools, define the rules that control how the Connection Broker manages the user\u00e2\u0080\u0099s connection to the desktops in those pools. To perform this step, ask yourself the following questions.\n\nWhat display protocols do I want to use to connect users to their desktops?\nHow do I want to manage the power state of each desktop, for example, should it be powered off when the user logs out?\nHow long can users remain assigned to a particular desktop? For example, if the user logs out, should they remain assigned to that desktop, or should another user be able to log in?\n\nImportant\nThe Leostream Connection Broker defines a pool-based plan as a set of rules that determine how the Connection Broker manages the connection to a desktop in a pool. This step describes three types of pool-based plans. 1) Protocol, 2) Power Control, and 3) Release. The Connection Broker also provides location-based plans for setting registry keys and attaching network printers to the remote desktop. See the Connection Broker Administrator\u00e2\u0080\u0099s Guide for information on using location-based plans.\n\n13.1.1. Protocol Plans\u00c2\u00b6\nProtocol plans determine the display protocol the Connection Broker uses to connect a user to their desktop. The Connection Broker provides one default protocol plan, which is shown on the Configuration > Protocol Plans page, shown in the following figure.\n\nThe Default Protocol Plan instructs the Connection Broker to connect to the remote desktops using Microsoft RDP. For this example, edit the Default protocol plan and use the Gateway drop-down menu in the RDP and RemoteFX section to indicate that the RDP connection should go through your Leostream Gateway, as shown in the following figure.\n\nIf needed, you can create a new Protocol Plan by clicking the Create Protocol Plan link. The Create Protocol Plan form is divided into sections based on the type of client device used to log into Leostream, for example, Leostream Connect or the Leostream Web client.\nNote that your Connection Broker license determines which display protocols your Connection Broker can use.\nIn each section, indicate which protocol the Connection Broker should use to connect users to their desktops by selecting 1 from that protocol\u00e2\u0080\u0099s Priority drop-down menu. Then, use the Configuration file and Command line parameters to determine how that connection is launched. For example, for RDP, the Configuration file is a list of RDP-file parameters that determine if, for example, the connection is launched in full screen.\nFor a complete description of protocol plans, see \u00e2\u0080\u009cBuilding Pool-Based Plans\u00e2\u0080\u009d in the Connection Broker Administrator\u00e2\u0080\u0099s Guide.\n\n13.1.2. Power Control Plans\u00c2\u00b6\nPower control and release plans allow you to take actions on the user\u00e2\u0080\u0099s remote session based on different events, such as:\n\nWhen the user disconnects from their desktop\nWhen the user logs out of their desktop\nWhen the desktop is released to its pool\nWhen the user\u00e2\u0080\u0099s session has been idle for a specified length of time\n\nThe remote desktop must have an installed and running Leostream Agent to allow the Connection Broker to distinguish between user logout and disconnect and to perform actions based on idle time.\nPower control plans define the power control action to take on a desktop. Available power control plans are shown on the Configuration > Power Control Plans page, shown in the following figure.\n\nNew Connection Broker installations contain one default power control plan, called Default, which leaves the virtual machine running at all times. You can edit the Default power control plan or create as many additional power control plans as needed for your deployment. To build a new power control plan:\n\nClick the Create Power Control Plan link on the Configuration > Power Control Plans page. The Create Power Control Plan form, shown in the following figure, opens.\n\nEnter a unique name for the plan in the Plan name edit field.\nFor each of the remaining sections:\n\nFrom the Wait drop-down menu, select the time to wait before applying the power action.\nFrom the then drop-down menu, select the power control action to apply. Selecting Do not change power state renders the setting in the Wait drop-down menu irrelevant, as no action is ever taken.\n\nClick Save to store the changes or Cancel to return to the Configuration > Power Control Plans page without creating the plan.\n\n13.1.3. Release Plans\u00c2\u00b6\nRelease plans determine how long a desktop remains assigned to a user. When the assignment is released, the desktop returns to its pool, making it available for other users. Available release plans are shown on the Configuration > Release Plans page, shown in the following figure.\n\nNote\nWhen a desktop is assigned to a user, the Connection Broker always offers that desktop to that user, regardless of where the user logs in, and to no other users. Desktops can be policy- assigned or hard-assigned. For a description of hard-assigned desktops, see the Connection Broker Administrator\u00e2\u0080\u0099s Guide.\n\nNew Connection Broker installations contain one default release plan. The default release plan is designed to keep the user assigned to their desktop until they log out. When the user logs out, the Connection Broker releases the desktop back to its pool. You can create as many additional release plans as needed for your deployment, using the Create Release Plan form shown in the following figure.\n\nFor example, to build a release plan that schedules a logout one hour after the user disconnects from their desktop and then deletes the virtual machine from your Virtuozzo Hybrid Infrastructure project:\n\nEnter a unique name for the plan in the Plan name edit field.\nTo build the Release Plan for our example, in the When User Disconnects from Desktop section, select after 1 hour from the Forced Logout drop-down menu.\nIn the When Desktop is Released section, select Immediately from the Delete virtual machine from disk option.\nClick Save.\n\nIn this release plan, the Connection Broker forcefully logs the user out an hour after they disconnect from their desktop. The logout event then triggers the When User Logs Out of Desktop section of the release plan, which releases the desktop back to its pool. The release action then triggers the When Desktop is Released section of the plan, which deletes the VM.\nFor more details on creating and using release plans, see the \u00e2\u0080\u009cRelease Plans\u00e2\u0080\u009d section in Chapter 11 of the Connection Broker Administrator\u00e2\u0080\u0099s Guide.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/offering-vhi-desktops/defining-pool-plans.html"
    },
    {
        "title": "Provisioning the backup service",
        "content": "Provisioning the backup service\nThe backup service, based on OpenStack Freezer, provides data protection for VM volumes located on either the local storage (Virtuozzo Storage) or an external storage. The service allows you to back up compute volumes, and then restore virtual machines and volumes from them. This helps to prevent data loss and mitigate issues with software or hardware.\nYou can configure the backup service to use the local storage or send backups to external NFS or S3-compatible object storage.\nBackups can be created and managed by both administrators and self-service users.\r\nHowever, to provide this functionality, you need to enable the backup service by using the vinfra command-line tool. When you enable the backup service, it is enabled for all domains by default. You can also disable it for specific domains, and then enable it again, if needed.\nLimitations \n\nThe backup service cannot be disabled.\n\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.\n\nTo enable and configure the backup service\nUse the following command:vinfra service compute backup configure [--enable] --driver {posix,nfs,s3} [--posix-path <path>]\r\n                                        [--nfs-share <host>:<share>] [--nfs-mount-options <options>]\r\n                                        [--s3-endpoint-url <url>] [--s3-store-access-key <access-key>]\r\n                                        [--s3-store-secret-key <secret-key>] [--s3-store-bucket <bucket>]\r\n                                        [--s3-verify-ssl] [--s3-no-verify-ssl] [--concurrent-jobs <int>]\r\n                                        [--volume-batch-size <int>]\n\n--enable\n\nEnable compute backup service\n--driver {posix,nfs,s3}\n\nBackup driver to use. Possible values are: posix, nfs, and s3.\n--posix-path <path>\n\nAbsolute path for storing backups. The path should be shared across all compute nodes and mounted under /mnt. To survive a node reboot, add this mount in /etc/fstab (or systemd mount).\n--nfs-share <host>:<share>\n\nNFS share in the format <host>:<share>, where:\n\n<host>: Node IP address or hostname;\n<share>: NFS share name.\n\n--nfs-mount-options <options>\n\nComma-separated list of standard NFS mount options\n--s3-endpoint-url <url>\n\nS3 endpoint URL\n--s3-store-access-key <access-key>\n\nS3 store access key\n--s3-store-secret-key <secret-key>\n\nS3 store secret key\n--s3-store-bucket <bucket>\n\nS3 bucket to store backups in\n--s3-verify-ssl\n\nVerify the SSL certificate for the S3 endpoint\n--s3-no-verify-ssl\n\nDon't verify the SSL certificate for the S3 endpoint\n--concurrent-jobs <int>\n\nMaximum number of concurrent jobs per scheduler\n--volume-batch-size <int>\n\nMaximum number of volume backups per job\n\nExample 1. To enable and configure the backup service to send backups to external S3 bucket, run:# vinfra service compute backup configure --enable --driver s3 --s3-endpoint-url https://s3.example.com \\\r\n--s3-store-access-key ccf52e4b<...> --s3-store-secret-key qoFfYUi3<...> --s3-store-bucket bucket1 --s3-verify-ssl\nYou can check the backup service configuration in the vinfra service compute backup show\r\noutput:# vinfra service compute backup show\r\n+-------------------+------------------------+\r\n| Field             | Value                  |\r\n+-------------------+------------------------+\r\n| concurrent_jobs   | 10                     |\r\n| driver            | s3                     |\r\n| s3_endpoint_url   | https://s3.example.com |\r\n| s3_store_bucket   | bucket1                |\r\n| s3_verify_ssl     | True                   |\r\n| volume_batch_size | 5                      |\r\n+-------------------+------------------------+\nExample 2. To enable and configure the backup service to send backups to an external NFS share, and also change the maximum number of concurrent backup jobs to 15 and the maximum number of volume backups per job to 10, run:# vinfra service compute backup configure --enable --driver nfs --nfs-share 10.10.10.10:myshare \\\r\n--nfs-mount-options lookupcache=none,nfsvers=4 --concurrent-jobs 15 --volume-batch-size 10\nYou can check the backup service configuration in the vinfra service compute backup show\r\noutput:# vinfra service compute backup show\r\n+-------------------+----------------------------+\r\n| Field             | Value                      |\r\n+-------------------+----------------------------+\r\n| concurrent_jobs   | 15                         |\r\n| driver            | nfs                        |\r\n| nfs_mount_options | lookupcache=none,nfsvers=4 |\r\n| nfs_share         | 10.10.10.10:myshare        |\r\n| volume_batch_size | 10                         |\r\n+-------------------+----------------------------+\nTo disable the backup service per domain\nUse the following command:vinfra domain properties create <domain> --key HciComputeBackupEnabled --data '{\"enabled\": false}'\n\n<domain>\n\nDomain name or domain ID\n\nFor example, to disable the backup service for the domain mydomain, run:# vinfra domain properties create mydomain --key HciComputeBackupEnabled --data '{\"enabled\": false}'\nTo enable the backup service per domain\nUse the following command:vinfra domain properties delete <domain> --key HciComputeBackupEnabled\n\n<domain>\n\nDomain name or domain ID\n\nFor example, to enable the backup service again for the domain mydomain, run:# vinfra domain properties delete mydomain --key HciComputeBackupEnabled\nSee also\n\nManaging external storages\n\nWhat's next\n\nManaging compute backups",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/provisioning-the-backup-service.html"
    },
    {
        "title": "Configuring InfiniBand devices",
        "content": "Configuring InfiniBand devices\nLimitations\n\nAs the admin panel only shows IP states and does not show InfiniBand (IB) connection states, it may report plugged in but yet unconfigured IB devices as Disconnected. The status will change to Connected once you assign an IP address to such a device.\nA network interface must have at least one IPv4 address.\nYou can only assign an IPv6 address manually. Obtaining an IPv6 address via DHCP is not supported.\n\nPrerequisites\n\nThe Storage traffic type is moved to a dedicated network.\n\nTo configure InfiniBand devices\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, assign the traffic type Storage to an empty network (without any other traffic types). If needed, create a new network by clicking Create network.\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface.\nOn the interface right pane, click Edit.\nIn the Edit network interface window, specify the network with the Storage traffic type, select Manually, and then specify the IP address in CIDR notation by clicking Add.\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\nSelect Connected mode.\n\nEnter the 65520 value in the MTU field.\n\nSetting a custom MTU in the admin panel prior to configuring it on the network hardware will result in network failure on the node and require manual resetting. Setting an MTU that differs from the one configured on the network hardware may result in a network outage or poor performance.\n\nClick Save to apply your changes.\nRepeat the steps for each IB device on your infrastructure nodes.\n\nCommand-line interface\nUse the following command:vinfra node iface set [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                      [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                      [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                      [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                      [--network <network> | --no-network] [--connected-mode | --datagram-mode]\r\n                      [--node <node>] <iface>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--no-network\n\nRemove a network from the interface\n--connected-mode\n\nEnable connected mode (InfiniBand interfaces only)\n--datagram-mode\n\nEnable datagram mode (InfiniBand interfaces only)\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nFor example, to assign the network Storage to the network interface ib2 located on the node node002, enable the connected mode, set its IP address to 192.168.30.20/24, and MTU to 65520,  run:# vinfra node iface set ib2 --network Storage --node node002 --ipv4 192.168.30.20/24 \\\r\n--mtu 65520 --connected-mode\n\nSee also\n\nChanging network interface parameters\n\nManaging network interfaces\n\nWhat's next\n\nEnabling RDMA",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface set [--ipv4 <ipv4>] [--ipv6 <ipv6>] [--gw4 <gw4>] [--gw6 <gw6>]\r\n                      [--mtu <mtu>] [--dhcp4 | --no-dhcp4] [--dhcp6 | --no-dhcp6]\r\n                      [--auto-routes-v4 | --ignore-auto-routes-v4]\r\n                      [--auto-routes-v6 | --ignore-auto-routes-v6]\r\n                      [--network <network> | --no-network] [--connected-mode | --datagram-mode]\r\n                      [--node <node>] <iface>\r\n\n\n--ipv4 <ipv4>\n\nA comma-separated list of IPv4 addresses\n--ipv6 <ipv6>\n\nA comma-separated list of IPv6 addresses\n--gw4 <gw4>\n\nGateway IPv4 address\n--gw6 <gw6>\n\nGateway IPv6 address\n--mtu <mtu>\n\nMTU interface value\n--dhcp4\n\nEnable DHCPv4\n--no-dhcp4\n\nDisable DHCPv4\n--dhcp6\n\nEnable DHCPv6\n--no-dhcp6\n\nDisable DHCPv6\n--auto-routes-v4\n\nEnable automatic IPv4 routes\n--ignore-auto-routes-v4\n\nIgnore automatic IPv4 routes\n--auto-routes-v6\n\nEnable automatic IPv6 routes\n--ignore-auto-routes-v6\n\nIgnore automatic IPv6 routes\n--network <network>\n\nNetwork ID or name\n--no-network\n\nRemove a network from the interface\n--connected-mode\n\nEnable connected mode (InfiniBand interfaces only)\n--datagram-mode\n\nEnable datagram mode (InfiniBand interfaces only)\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nFor example, to assign the network Storage to the network interface ib2 located on the node node002, enable the connected mode, set its IP address to 192.168.30.20/24, and MTU to 65520,  run:# vinfra node iface set ib2 --network Storage --node node002 --ipv4 192.168.30.20/24 \\\r\n--mtu 65520 --connected-mode\n",
                "title": "To configure InfiniBand devices"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, assign the traffic type Storage to an empty network (without any other traffic types). If needed, create a new network by clicking Create network.\nOn the Infrastructure > Nodes screen, click the name of the node, go to the Network interfaces tab, and then click the network interface.\nOn the interface right pane, click Edit.\nIn the Edit network interface window, specify the network with the Storage traffic type, select Manually, and then specify the IP address in CIDR notation by clicking Add.\nSpecify a gateway. The provided gateway will become the node\u00e2\u0080\u0099s default.\nSelect Connected mode.\n\nEnter the 65520 value in the MTU field.\n\nSetting a custom MTU in the admin panel prior to configuring it on the network hardware will result in network failure on the node and require manual resetting. Setting an MTU that differs from the one configured on the network hardware may result in a network outage or poor performance.\n\n\nClick Save to apply your changes.\nRepeat the steps for each IB device on your infrastructure nodes.\n\n",
                "title": "To configure InfiniBand devices"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-infiniband-devices.html"
    },
    {
        "title": "Managing volumes",
        "content": "Managing volumes",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-volumes.html"
    },
    {
        "title": "GET service replication",
        "content": "GET service replication\nDescription\nLists information about replication configuration for the specified bucket.\nRequests\nSyntaxGET /?replication HTTP/1.1\r\nHost: <bucket>.<host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nGET service replication parameters\n\nParameter\t\nDescription\t\nRequired\n\nbucket\n\nBucket name.\nType: string.\nDefault value: none.\n\nYes\n\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\n\nHeader\nDescription\t\n\nx-amz-geo-endpoint\n\nEndpoint of the remote region where to replicate objects to.\n\nx-amz-geo-access-key\n\nAccess key of a user of the remote region used to replicate objects.\n\nx-amz-geo-access-secret\n\nAccess secret of a user of the remote region used to replicate objects.\n\nBody\nAn XML replication configuration in the following format:<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<ReplicationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\r\n   <Role>arn:aws:iam::<user_id>:role/s3-replication-role</Role>\r\n   <Rule>\r\n      <Status>Enabled|Disabled</Status>\r\n      <Priority>1</Priority>\r\n      <DeleteMarkerReplication>\r\n         <Status>Enabled|Disabled</Status>\r\n      </DeleteMarkerReplication>\r\n      <Filter>\r\n         <Prefix />\r\n      </Filter>\r\n      <Destination>\r\n         <Bucket>arn:aws:s3:::<destination_bucket></Bucket>\r\n      </Destination>\r\n   </Rule>\r\n</ReplicationConfiguration>\nExamples\nSample request\nReturns replication configuration of the bucket\u00a0test.GET /?replication HTTP/1.1\r\nHost: test.s3.example.com\r\nDate: Tu, 18 Jan 2021 14:08:55 GMT\r\nAuthorization: <authorization_string>\nSample responseHTTP/1.1 200 OK\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection: closed\r\nx-amz-request-id : 80000000000000030005c8caec96d65b\r\nDate : Thu, 07 Apr 2016 14:08:56 GMT\r\nContent-type : application/xml\r\n<ReplicationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\r\n   <Role>arn:aws:iam::850b4943d62191a5:role/s3-replication-role</Role>\r\n   <Rule>\r\n      <Status>Enabled</Status>\r\n      <Priority>1</Priority>\r\n      <DeleteMarkerReplication>\r\n         <Status>Disabled</Status>\r\n      </DeleteMarkerReplication>\r\n      <Filter>\r\n         <Prefix />\r\n      </Filter>\r\n      <Destination>\r\n         <Bucket>arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET2</Bucket>\r\n      </Destination>\r\n   </Rule>\r\n</ReplicationConfiguration>",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/get-service-replication.html"
    },
    {
        "title": "5.1. System Requirements\u00c2\u00b6",
        "content": "5.1. System Requirements | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n5.1. System Requirements\u00c2\u00b6\nMinimum server requirements for the flawless operation of BitNinja.\n\nRAM: 512 MB\nDual-core: CPU or 2vCPUs\nStorage: 1024 MB\nInternet Access\n\nNote\nThe information above refers to the minimum number of resources used by BitNinja agent on the installed resource. When sizing your instances plan for (Number of resources needed by your services) + (Number of resources needed by BitNinja).\n\nFor more up-to-date information please check: https://doc.bitninja.io/docs/Installation/system_requirements#hardware-requirements.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/bitninja-agent-requirements/system-requirements.html"
    },
    {
        "title": "Updating floating IPs",
        "content": "Updating floating IPsPUT /v2.0/floatingips/{floatingip_id}\r\n\nAssign a port in a private network to an existing floating IP.\nTo disassociate a floating IP from a port, set the port_id\r\nattribute to null or omit it from the request body.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=update-floating-ip-detail#update-floating-ip\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingip_id\n\npath\nstring\nThe ID of the floating IP address.\n\nfloatingip\n\nbody\nobject\nA floatingip object. When you associate a\r\nfloating IP address with a VM, the instance has the same public IP\r\naddress each time that it boots, basically to maintain a\r\nconsistent IP address for maintaining DNS assignment.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource.\r\nDefault is an empty string.\n\nfixed_ip_address (Optional)\nbody\nstring\nThe fixed IP address that is associated with the floating IP.\r\nIf an internal port has multiple associated IP addresses,\r\nthe service chooses the first IP address unless you explicitly\r\ndefine a fixed IP address in the fixed_ip_address parameter.\n\nport_id\n\nbody\nstring\n\nThe ID of a port associated with the floating IP.\n\nTo associate the floating IP with a fixed IP,\r\nyou must specify the ID of the internal port.\r\nTo disassociate the floating IP, null should be specified.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"floatingip\": {\r\n    \"port_id\": \"fb0e8e3e-2a71-420a-885c-94f6d2c2f2b7\"\r\n  }\r\n}' https://<node_IP_addr>:9696/v2.0/floatingips/88c1ba84-7acf-4d6f-9f6e-85db1cafa906\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nfloatingip\n\nbody\nobject\nA floatingip object. When you associate a\r\nfloating IP address with a VM, the instance has the same public IP\r\naddress each time that it boots, basically to maintain a\r\nconsistent IP address for maintaining DNS assignment.\n\nid\n\nbody\nstring\nThe ID of the floating IP address.\n\nrouter_id\n\nbody\nstring\nThe ID of the router for the floating IP.\n\nstatus\n\nbody\nstring\nThe status of the floating IP. Values are\r\nACTIVE, DOWN and ERROR.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\ndns_name\n\nbody\nstring\nA valid DNS name.\n\nport_details\n\nbody\nstring\nThe information of the port that this floating IP associates with.\r\nIn particular, if the floating IP is associated with a port, this field\r\ncontains some attributes of the associated port, including name,\r\nnetwork_id, mac_address, admin_state_up, status,\r\ndevice_id and device_owner. If the floating IP is not associated\r\nwith a port, this field is null.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nfloating_network_id\n\nbody\nstring\nThe ID of the network associated with the\r\nfloating IP.\n\nfixed_ip_address\n\nbody\nstring\nThe fixed IP address that is associated with the\r\nfloating IP address.\n\nfloating_ip_address\n\nbody\nstring\nThe floating IP address.\n\nport_id\n\nbody\nstring\n\nThe ID of a port associated with the floating IP.\n\ntags\n\nbody\narray\nThe list of tags on the resource.\n\nport_forwardings\n\nbody\narray\nThe associated port forwarding resources for the floating IP. If the\r\nfloating IP has multiple port forwarding resources, this field has\r\nmultiple entries. Each entry consists of network IP protocol\r\n(protocol), the fixed IP address of internal neutron port\r\n(internal_ip_address), the TCP or UDP port used by internal\r\nneutron port (internal_port) and the TCP or UDP port used by\r\nfloating IP (external_port).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n412 - Precondition Failed\n\nThe server does not meet one of the preconditions that the requester put on the request header fields.\n\nExample{\r\n  \"floatingip\": {\r\n    \"router_id\": \"10349fb6-1104-4275-b571-e65e26301740\",\r\n    \"status\": \"DOWN\",\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"tenant_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"created_at\": \"2020-03-19T10:39:01Z\",\r\n    \"updated_at\": \"2020-03-20T13:17:07Z\",\r\n    \"floating_network_id\": \"02ed0e3e-6272-4f50-9780-69c211b3a091\",\r\n    \"port_details\": {\r\n      \"status\": \"DOWN\",\r\n      \"name\": \"octavia-lb-6a4e1daf-2277-43aa-bd03-1eca6dfe9df1\",\r\n      \"admin_state_up\": false,\r\n      \"network_id\": \"15f7dc0a-712c-422f-bfd3-31dc351d9026\",\r\n      \"device_owner\": \"Octavia\",\r\n      \"mac_address\": \"fa:16:3e:00:1d:f7\",\r\n      \"device_id\": \"lb-6a4e1daf-2277-43aa-bd03-1eca6dfe9df1\"\r\n    },\r\n    \"fixed_ip_address\": \"192.168.10.5\",\r\n    \"floating_ip_address\": \"10.94.129.67\",\r\n    \"revision_number\": 9,\r\n    \"project_id\": \"05341a23f649427baa2fd4039b7f378f\",\r\n    \"port_id\": \"fb0e8e3e-2a71-420a-885c-94f6d2c2f2b7\",\r\n    \"id\": \"88c1ba84-7acf-4d6f-9f6e-85db1cafa906\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-floating-ips.html"
    },
    {
        "title": "2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "2. Integrating Leostream with Virtuozzo Hybrid Infrastructure | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\u00c2\u00b6\n\nIn this chapter:\n\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-leostream/index.html"
    },
    {
        "title": "Viewing router ports",
        "content": "Viewing router ports\nPrerequisites\n\nYou have a virtual router created, as described in Creating virtual routers.\n\nTo view router ports\n\nAdmin panel\n\nGo to the Compute > Network > Routers screen and click the router name.\nOn the Ports tab, click a router port to view its details.\n\nRouter port details include:\n\nPort ID\nPort status\nName and ID of the port device (that is, router name/ID)\nDevice owner (the entity that uses the port)\nMAC address of the port\nIP address of the port\nHost binding\nNetwork the port belongs to\nTime of the port creation and last update\n\nCommand-line interface\nUse the following command:vinfra service compute port list [--long] [--limit <limit>] [--marker <id>] [--name <name>]\r\n                                 [--device-owner <device_owner>] [--device-id <device_id>] [--network-id <network>]\r\n                                 [--host-id <host_id>] [--project-id <project_id>] [--mac-address <mac_address>]\r\n                                 [--fixed-ip <ip-address|ip-address=<ip_address>,subnet-id=<subnet_id>>]\r\n                                 [--tags <tag>[,<tag>,...]] [--sort <sort>]\n\n--long\n\nEnable access and listing of all fields of objects.\n--limit <limit>\n\nThe maximum number of ports to list. To list all ports, set the option to -1.\n--marker <id>\n\nList ports after the marker.\n--name <name>\n\nList ports according to their name. The filter format is in: <value1>[,<value2>,...].\n--device-owner <device_owner>\n\nList only ports with the specified device owner. The filter format is in: <value1>[,<value2>,...].\n--device-id <device_id>\n\nList only ports with the specified device ID. The filter format is in: <value1>[,<value2>,...].\n--network-id <network>\n\nList only ports connected to this network ID. The filter format is in: <value1>[,<value2>,...].\n--host-id <host_id>\n\nList only ports bound to this host ID. The filter format is in: <value1>[,<value2>,...].\n--project-id <project_id>\n\nList ports according to their project ID. The filter format is in: <value1>[,<value2>,...].\n--mac-address <mac_address>\n\nList only ports with this MAC address. The filter format is in: <value1>[,<value2>,...].\n--tags <tag>[,<tag>,...]\n\nList ports, comma separated, that have all of the specified tags. The filter format is in: <value1>[,<value2>,...].\n--fixed-ip <ip-address|ip-address=<ip_address>,subnet-id=<subnet_id>>\n\nList only ports with specific IP address and/or subnet. The filter format is in: <value1>[,<value2>,...].\n--sort <sort>\n\nList ports sorted by key. The sorting format is <sort-key>:<order>. The order is asc or desc. Supported sort keys: id, name, status, admin_state_up, device_owner, created_at, updated_at.\n\nTo view the list of ports for the router with the ID 59a448af-e178-4cf5-b6e7-602d5ce22b25, run:# vinfra service compute port list --device-id 59a448af-e178-4cf5-b6e7-602d5ce22b25\r\n+-------------+--------+-------------+-------------------+-------------------------------+\r\n| id          | status | network_id  | mac_address       | fixed_ips                     |\r\n+-------------+--------+-------------+-------------------+-------------------------------+\r\n| 13a7a406<\u00e2\u0080\u00a6> | ACTIVE | 74f8b095<\u00e2\u0080\u00a6> | fa:16:3e:da:c7:fa | - ip_address: 169.254.192.84  |\r\n|             |        |             |                   |   subnet_id: b0f291a8<\u00e2\u0080\u00a6>      |\r\n| 3a894732<\u00e2\u0080\u00a6> | ACTIVE | 741b706b<\u00e2\u0080\u00a6> | fa:16:3e:db:d3:ee | - ip_address: 10.136.18.134   |\r\n|             |        |             |                   |   subnet_id: 41c86ca9<\u00e2\u0080\u00a6>      |\r\n| 4c892abc<\u00e2\u0080\u00a6> | ACTIVE | b1d5215d<\u00e2\u0080\u00a6> | fa:16:3e:0b:8d:16 | - ip_address: 192.168.128.1   |\r\n|             |        |             |                   |   subnet_id: f05899af<\u00e2\u0080\u00a6>      |\r\n| 76247386<\u00e2\u0080\u00a6> | ACTIVE | b1d5215d<\u00e2\u0080\u00a6> | fa:16:3e:50:29:8b | - ip_address: 192.168.128.169 |\r\n|             |        |             |                   |   subnet_id: f05899af<\u00e2\u0080\u00a6>      |\r\n+-------------+--------+-------------+-------------------+-------------------------------+\nYou can check the port details in the vinfra service compute port show output:# vinfra service compute port show 3a894732-afb1-461e-bc2f-54aa3373897b\r\n+-------------------------+---------------------------------------------------+\r\n| Field                   | Value                                             |\r\n+-------------------------+---------------------------------------------------+\r\n| admin_state_up          | True                                              |\r\n| allowed_address_pairs   | []                                                |\r\n| binding_host_id         | node001.vstoragedomain                            |\r\n| binding_profile         | {}                                                |\r\n| binding_vnic_type       | normal                                            |\r\n| created_at              | 2024-05-10T16:27:46Z                              |\r\n| description             |                                                   |\r\n| device_id               | 59a448af-e178-4cf5-b6e7-602d5ce22b25              |\r\n| device_owner            | network:router_gateway                            |\r\n| dns_domain              |                                                   |\r\n| dns_name                |                                                   |\r\n| extra_dhcp_opts         | []                                                |\r\n| fixed_ips               | - ip_address: 10.136.18.134                       |\r\n|                         |   subnet_id: 41c86ca9-2b78-4840-a15b-b93d2df35a3f |\r\n| id                      | 3a894732-afb1-461e-bc2f-54aa3373897b              |\r\n| mac_address             | fa:16:3e:db:d3:ee                                 |\r\n| mac_learning_enabled    |                                                   |\r\n| name                    |                                                   |\r\n| network_id              | 741b706b-1a74-4bbd-8aa7-d99ac9d82d2d              |\r\n| port_security_enabled   | False                                             |\r\n| project_id              |                                                   |\r\n| propagate_uplink_status |                                                   |\r\n| qos_policy_id           |                                                   |\r\n| resource_request        |                                                   |\r\n| revision_number         | 9                                                 |\r\n| security_groups         | []                                                |\r\n| status                  | ACTIVE                                            |\r\n| tags                    | []                                                |\r\n| updated_at              | 2024-05-20T11:38:25Z                              |\r\n+-------------------------+---------------------------------------------------+\n\nSee also\n\nManaging router interfaces\n\nManaging static routes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute port list [--long] [--limit <limit>] [--marker <id>] [--name <name>]\r\n                                 [--device-owner <device_owner>] [--device-id <device_id>] [--network-id <network>]\r\n                                 [--host-id <host_id>] [--project-id <project_id>] [--mac-address <mac_address>]\r\n                                 [--fixed-ip <ip-address|ip-address=<ip_address>,subnet-id=<subnet_id>>]\r\n                                 [--tags <tag>[,<tag>,...]] [--sort <sort>]\n\n--long\n\nEnable access and listing of all fields of objects.\n--limit <limit>\n\nThe maximum number of ports to list. To list all ports, set the option to -1.\n--marker <id>\n\nList ports after the marker.\n--name <name>\n\nList ports according to their name. The filter format is in: <value1>[,<value2>,...].\n--device-owner <device_owner>\n\nList only ports with the specified device owner. The filter format is in: <value1>[,<value2>,...].\n--device-id <device_id>\n\nList only ports with the specified device ID. The filter format is in: <value1>[,<value2>,...].\n--network-id <network>\n\nList only ports connected to this network ID. The filter format is in: <value1>[,<value2>,...].\n--host-id <host_id>\n\nList only ports bound to this host ID. The filter format is in: <value1>[,<value2>,...].\n--project-id <project_id>\n\nList ports according to their project ID. The filter format is in: <value1>[,<value2>,...].\n--mac-address <mac_address>\n\nList only ports with this MAC address. The filter format is in: <value1>[,<value2>,...].\n--tags <tag>[,<tag>,...]\n\nList ports, comma separated, that have all of the specified tags. The filter format is in: <value1>[,<value2>,...].\n--fixed-ip <ip-address|ip-address=<ip_address>,subnet-id=<subnet_id>>\n\nList only ports with specific IP address and/or subnet. The filter format is in: <value1>[,<value2>,...].\n--sort <sort>\n\nList ports sorted by key. The sorting format is <sort-key>:<order>. The order is asc or desc. Supported sort keys: id, name, status, admin_state_up, device_owner, created_at, updated_at.\n\nTo view the list of ports for the router with the ID 59a448af-e178-4cf5-b6e7-602d5ce22b25, run:# vinfra service compute port list --device-id 59a448af-e178-4cf5-b6e7-602d5ce22b25\r\n+-------------+--------+-------------+-------------------+-------------------------------+\r\n| id          | status | network_id  | mac_address       | fixed_ips                     |\r\n+-------------+--------+-------------+-------------------+-------------------------------+\r\n| 13a7a406<\u00e2\u0080\u00a6> | ACTIVE | 74f8b095<\u00e2\u0080\u00a6> | fa:16:3e:da:c7:fa | - ip_address: 169.254.192.84  |\r\n|             |        |             |                   |   subnet_id: b0f291a8<\u00e2\u0080\u00a6>      |\r\n| 3a894732<\u00e2\u0080\u00a6> | ACTIVE | 741b706b<\u00e2\u0080\u00a6> | fa:16:3e:db:d3:ee | - ip_address: 10.136.18.134   |\r\n|             |        |             |                   |   subnet_id: 41c86ca9<\u00e2\u0080\u00a6>      |\r\n| 4c892abc<\u00e2\u0080\u00a6> | ACTIVE | b1d5215d<\u00e2\u0080\u00a6> | fa:16:3e:0b:8d:16 | - ip_address: 192.168.128.1   |\r\n|             |        |             |                   |   subnet_id: f05899af<\u00e2\u0080\u00a6>      |\r\n| 76247386<\u00e2\u0080\u00a6> | ACTIVE | b1d5215d<\u00e2\u0080\u00a6> | fa:16:3e:50:29:8b | - ip_address: 192.168.128.169 |\r\n|             |        |             |                   |   subnet_id: f05899af<\u00e2\u0080\u00a6>      |\r\n+-------------+--------+-------------+-------------------+-------------------------------+\nYou can check the port details in the vinfra service compute port show output:# vinfra service compute port show 3a894732-afb1-461e-bc2f-54aa3373897b\r\n+-------------------------+---------------------------------------------------+\r\n| Field                   | Value                                             |\r\n+-------------------------+---------------------------------------------------+\r\n| admin_state_up          | True                                              |\r\n| allowed_address_pairs   | []                                                |\r\n| binding_host_id         | node001.vstoragedomain                            |\r\n| binding_profile         | {}                                                |\r\n| binding_vnic_type       | normal                                            |\r\n| created_at              | 2024-05-10T16:27:46Z                              |\r\n| description             |                                                   |\r\n| device_id               | 59a448af-e178-4cf5-b6e7-602d5ce22b25              |\r\n| device_owner            | network:router_gateway                            |\r\n| dns_domain              |                                                   |\r\n| dns_name                |                                                   |\r\n| extra_dhcp_opts         | []                                                |\r\n| fixed_ips               | - ip_address: 10.136.18.134                       |\r\n|                         |   subnet_id: 41c86ca9-2b78-4840-a15b-b93d2df35a3f |\r\n| id                      | 3a894732-afb1-461e-bc2f-54aa3373897b              |\r\n| mac_address             | fa:16:3e:db:d3:ee                                 |\r\n| mac_learning_enabled    |                                                   |\r\n| name                    |                                                   |\r\n| network_id              | 741b706b-1a74-4bbd-8aa7-d99ac9d82d2d              |\r\n| port_security_enabled   | False                                             |\r\n| project_id              |                                                   |\r\n| propagate_uplink_status |                                                   |\r\n| qos_policy_id           |                                                   |\r\n| resource_request        |                                                   |\r\n| revision_number         | 9                                                 |\r\n| security_groups         | []                                                |\r\n| status                  | ACTIVE                                            |\r\n| tags                    | []                                                |\r\n| updated_at              | 2024-05-20T11:38:25Z                              |\r\n+-------------------------+---------------------------------------------------+\n",
                "title": "To view router ports"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Network > Routers screen and click the router name.\nOn the Ports tab, click a router port to view its details.\n\nRouter port details include:\n\nPort ID\nPort status\nName and ID of the port device (that is, router name/ID)\nDevice owner (the entity that uses the port)\nMAC address of the port\nIP address of the port\nHost binding\nNetwork the port belongs to\nTime of the port creation and last update\n\n",
                "title": "To view router ports"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-router-ports.html"
    },
    {
        "title": "5.4. Virtual Server Port Requirements\u00c2\u00b6",
        "content": "5.4. Virtual Server Port Requirements | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n5.4. Virtual Server Port Requirements\u00c2\u00b6\nSome BitNinja modules require certain ports to be open on the server and on the firewall in front of the server (if there is one). The ports need to be open for both inbound and outbound connections. The following port numbers are the default values.\n\nProtocol\nPort\nBitNinja module(s)\n\nTCP\n60412\nCaptchaHttp, CaptchaSmtp\n\nTCP\n60413, 60418*\nCaptchaHttps\n\nTCP\n25\nCaptchaSmtp\n\nTCP\n60201\nCaptchaSmtp\n\nTCP\n60210\nCaptchaFtp (active)\n\nTCP\n60211-60250\nCaptchaFtp (passive)\n\nTCP\n60300\nWAF HTTP\n\nTCP\n60301\nWAF HTTPS\n\nTCP\n60414, 60415\nSslTerminating\n\nTCP\n60416\nTrustedProxy HTTP\n\nTCP\n60417\nTrustedProxy HTTPS\n\nNote\nPort 60418 is only required for the CaptchaHttps service if you are using cPanel/WHM. Otherwise, it\u00e2\u0080\u0099s not required.\n\nNote\nThe web server has to accept connections from 127.0.0.1 to http://<server_ip>:80 and to https://<server_ip>:443 in order for the WAF module to work.\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/bitninja-agent-requirements/port-requirements.html"
    },
    {
        "title": "How to use Trilio for Kubernetes",
        "content": "How to use Trilio for KubernetesThis guide describes how to deploy Trilio for Kubernetes and manage backups for Kubernetes-based applications on Virtuozzo Hybrid Infrastructure.About Trilio for KubernetesTrilio for Kubernetes (T4K) is a cloud-native, application-centric data protection and recovery solution designed specifically for Kubernetes environments. It provides backup and recovery services that are integrated with Kubernetes to help manage and protect applications across their entire lifecycle.\n\nNote: Trilio has a full-fledged user interface to manage the cluster and workload lifecycle, however, we are using the command-line interface to simplify and offer a quick overview of the capabilities.Prerequisites1. Deploy a Virtuozzo Hybrid Infrastructure cluster.2. Create the compute cluster with the Kubernetes and load balancing services.3. Configure a storage policy named standard for boot volumes on Kubernetes master nodes. Ensure that the selected policy is available for all projects where you are planning to deploy Kubernetes.4. Create a Kubernetes cluster. The guide is certified to work with Kubernetes versions v1.25.7\u2013v1.27.8.5. Use the table below to assess readiness:6. Ensure that you have the credentials (the access key and secret key) to the object storage service. In this guide, we will use the S3 object storage and a bucket provided by Virtuozzo Hybrid Infrastructure.7. Create a storage class with the snapshot functionality enabled:7.1. Create the csi-cinder-snapclass storage class with the storage policy standard. The storage policy must be available in your project. 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# cat > storage-class.yaml <<\\EOT\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: csi-cinder-snapclass\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"true\"\nprovisioner: cinder.csi.openstack.org\nparameters:\n  type: standard\nEOT\nApply the configuration file:1\n# kubectl create -f storage-class.yaml\n7.2. Install the required custom resource definitions (CRD) for volume snapshots:7.2.1. Check the existing CRDs:1\n2\n3\n4\n# kubectl api-resources | grep volumesnapshot\nvolumesnapshotclasses    snapshot.storage.k8s.io/v1beta1        false        VolumeSnapshotClass\nvolumesnapshotcontents   snapshot.storage.k8s.io/v1beta1        false        VolumeSnapshotContent\nvolumesnapshots          snapshot.storage.k8s.io/v1beta1        true         VolumeSnapshot\n7.2.2. Install the missing CRDs (install only one version):1\n2\n3\n4\n5\n6\n7\n8\n# git clone https://github.com/kubernetes-csi/external-snapshotter/\n# cd ./external-snapshotter\n# git checkout release-5.0\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml\n# kubectl apply -f client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml\n# kubectl apply -f deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml -n kube-system\n# kubectl apply -f deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml -n kube-system\nImportant: The CSI snapshotter version must not be higher than release-5.0.7.3. Create a snapshot class: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n# cat > snapshotclass.yaml <<\\EOT\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshotClass\nmetadata:\n  name: csi-cinder-snapclass\ndriver: cinder.csi.openstack.org\ndeletionPolicy: Delete\nparameters:\n  force-create: \"true\" \nEOT\nApply the configuration file:1\n# kubectl apply -f snapshot-class.yaml\n8. Check the compatibility matrix for the Kubernetes version supported by Trilio:Note: In this guide, we are using Trilio 4.0.2 and Kubernetes v1.27.8.Installing Trilio for Kubernetes1. Add the repository where the Trilio operator helm chart is located:1\n# helm repo add triliovault-operator https://charts.k8strilio.net/trilio-stable/k8s-triliovault-operator\n2. Install the chart from the added repository. Note that we are adding a custom configuration to change the default NodePort to the LoadBalancer service type, so that you can access the T4K interface at a public IP address. Otherwise, if you do not want to add a public IP, you can access the T4K control plane with the kubectl port-forward feature:1\n# helm install tvm triliovault-operator/k8s-triliovault-operator --version 4.0.2 -n trilio-system --create-namespace --set installT4K.ComponentConfiguration.ingressController.service.type=LoadBalancer \nVerifying the Trilio installation1. Verify the Trilio Operator has started:1\n# kubectl --n trilio-system wait --for=condition=ready pod -l \"release=tvm\"\n2. Check the status of the deployment:1\n# kubectl --n trilio-system get triliovaultmanagers.triliovault.trilio.io triliovault-manager -o yaml\n3. Verify that you can access the control plane. If you want to access with an external floating IP address and you have deployed the cluster with the LoadBalancer service type, you can check your external IP address in the command-line interface:1\n# kubectl get ing --n trilio-system \nOr1\n# kubectl get svc k8s-triliovault-ingress-nginx-controller  --n trilio-system \nInstalling the license1. Request a trial license from Trilio.2. Apply the license to your T4K application:1\n# kubectl apply -f virtuozzo_trial.yaml --n trilio-system\nCreating an S3 backup targetIn this guide, we are using a Virtuozzo S3 storage bucket.1. Create a sample secret with your access and secret keys: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n# cat > sample-secret.yaml <<\\EOT\napiVersion: v1\nkind: Secret\nmetadata:\n  name: sample-secret\ntype: Opaque\nstringData:\n  accessKey: AKIAS5B35DGFSTY7T55D\n  secretKey: xWBupfGvkgkhaH8ansJU1wRhFoGoWFPmhXD6/vVDcode\nEOT\nApply the configuration file:1\n# kubectl apply -f sample-secret.yaml\n2. Create a backup target. To enable immutability, you need to enable object locking in your bucket and define this option when creating the target YAML file (ObjectLockingEnabled). Alternatively, you can enable immutability later in the UI. 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n# cat > demo-s3-target.yaml <<\\EOT\napiVersion: triliovault.trilio.io/v1\nkind: Target\nmetadata:\n  name: virtuozzo-s3-target\nspec:\n  type: ObjectStore\n  vendor: Other\n  objectStoreCredentials:\n    bucketName: se-backup\n    url: https://your.virtuozzoS3.com\n    credentialSecret:\n      name: sample-secret\n      namespace: default\n  thresholdCapacity: 100Gi\nEOT\nApply the configuration file:1\n# kubectl apply -f demo-s3-target.yaml\n3. Create a retention policy: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n# cat > default-policy.yaml <<\\EOT\napiVersion: triliovault.trilio.io/v1\nkind: Policy\nmetadata:\n  name: demo-policy\nspec:\n  type: Retention\n  default: false\n  retentionConfig:\n    latest: 2\n    weekly: 1\n    dayOfWeek: Wednesday\n    monthly: 1\n    dateOfMonth: 15\n    monthOfYear: March\n    yearly: 1\nEOT\nApply the configuration file:1\n# kubectl apply -f default-policy.yaml\nTesting application backup1. Create an application to test the backup functionality:  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n 10\n 11\n 12\n 13\n 14\n 15\n 16\n 17\n 18\n 19\n 20\n 21\n 22\n 23\n 24\n 25\n 26\n 27\n 28\n 29\n 30\n 31\n 32\n 33\n 34\n 35\n 36\n 37\n 38\n 39\n 40\n 41\n 42\n 43\n 44\n 45\n 46\n 47\n 48\n 49\n 50\n 51\n 52\n 53\n 54\n 55\n 56\n 57\n 58\n 59\n 60\n 61\n 62\n 63\n 64\n 65\n 66\n 67\n 68\n 69\n 70\n 71\n 72\n 73\n 74\n 75\n 76\n 77\n 78\n 79\n 80\n 81\n 82\n 83\n 84\n 85\n 86\n 87\n 88\n 89\n 90\n 91\n 92\n 93\n 94\n 95\n 96\n 97\n 98\n 99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n# cat > mysql.yaml <<\\EOT\n## Secret for mysql password\napiVersion: v1\nkind: Secret\nmetadata:\n  name: mysql-pass\n  labels:\n    app: k8s-demo-app\n    tier: frontend\ntype: Opaque\ndata:\n  password: dHJpbGlvcGFzcw==\n## password base64 encoded, plain text: triliopass\n## \"echo -n triliopass | base64\" -> to get the encoded password\n---\n## PVC for mysql PV\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysql-pv-claim\n  labels:\n    app: k8s-demo-app\n    tier: mysql\nspec:\n  storageClassName: csi-cinder-snapclass\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n---\n## Mysql app deployment\napiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2\nkind: Deployment\nmetadata:\n  name: k8s-demo-app-mysql\n  labels:\n    app: k8s-demo-app\n    tier: mysql\nspec:\n  selector:\n    matchLabels:\n      app: k8s-demo-app\n      tier: mysql\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: k8s-demo-app\n        tier: mysql\n    spec:\n      containers:\n      - image: mysql:latest\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n---\n## Service for mysql app\napiVersion: v1\nkind: Service\nmetadata:\n  name: k8s-demo-app-mysql\n  labels:\n    app: k8s-demo-app\n    tier: mysql\nspec:\n  type: ClusterIP\n  ports:\n    - port: 3306\n  selector:\n    app: k8s-demo-app\n    tier: mysql\n---\n## Deployment for frontend webserver\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-demo-app-frontend\n  labels:\n    app: k8s-demo-app\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: k8s-demo-app\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: k8s-demo-app\n        tier: frontend\n    spec:\n      containers:\n      - name: demoapp-frontend\n        image: docker.io/trilio/k8s-demo-app:v1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n---\n## Service for frontend\napiVersion: v1\nkind: Service\nmetadata:\n  name: k8s-demo-app-frontend\n  labels:\n    app: k8s-demo-app\n    tier: frontend\nspec:\n  ports:\n  - name: web\n    port: 80\n  selector:\n    app: k8s-demo-app\n    tier: frontend\nEOT\nApply the configuration file:1\n# kubectl apply -f mysql.yaml\n2. Create a backup plan: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n# cat > backup-plan-K8s-demo-app.yaml <<\\EOT\napiVersion: triliovault.trilio.io/v1\nkind: BackupPlan\nmetadata:\n  name: mysql-label-backupplan\nspec:\n  backupConfig:\n    target:\n      namespace: default\n      name: virtuozzo-s3-target\n    retentionPolicy:\n      namespace: default\n      name: demo-policy\n  backupPlanComponents:\n    custom:\n      - matchLabels:\n          app: k8s-demo-app\nEOT\nApply the configuration file:1\n# kubectl apply -f backup-plan-K8s-demo-app.yaml\n3. Create a backup: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# cat > backup-demo-mysql-app.yaml <<\\EOT\napiVersion: triliovault.trilio.io/v1\nkind: Backup\nmetadata:\n  name: mysql-label-backup\nspec:\n  type: Full\n  backupPlan:\n    name: mysql-label-backupplan\n    namespace: default\nEOT\nApply the configuration file:1\n# kubectl apply -f backup-demo-mysql-app.yaml\n4. Now, let\u2019s simulate a case when the application is removed by mistake:1\n# kubectl delete -f mysql.yaml\n5. Check your resources:1\n2\n# kubectl get pods -l \"app=k8s-demo-app\"\nNo resources found in default namespace.\nAs we can see in the command output, no resources labeled app=k8s-demo-app exist in the default namespace.6. Restore the application from the created backup: 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\ncat > restore-mysql-app.yaml <<\\EOT\napiVersion: triliovault.trilio.io/v1\nkind: Restore\nmetadata:\n  name: demo-restore\nspec:\n  source:\n    type: Backup\n    backup:\n      name: mysql-label-backup\n      namespace: default\n  skipIfAlreadyExists: true\nEOT\nApply the configuration file:1\n# kubectl apply -f restore-mysql-app.yaml\nIn a few minutes, the application is fully restored.To learn more about Trilio for Kubernetes, refer to the official documentation.Enjoy!",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://www.virtuozzo.com/hybrid-infrastructure-docs/kubernetes-backups-with-trilio/"
    },
    {
        "title": "Configuring virtual machine volumes",
        "content": "Configuring virtual machine volumes\nYou can add new volumes to your virtual machines, attach existing volumes, and detach unneeded volumes from virtual machines.\nLimitations\n\nYou cannot change, detach, or delete the boot volume.\nYou can only attach and detach non-boot volumes.\nYou cannot manage volumes of shelved VMs.\n\nPrerequisites\n\nTo be able to use volumes attached to VMs, they must be initialized inside the guest OS by standard means.\n\nTo attach a volume to a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Disks field.\n\nIn the Volumes window:\n\nClick Attach to attach an existing volume, and then select the volume in the Attach volume window.\nClick Add to create a new volume, and then specify the volume name, size, and storage policy. The created volume will be automatically added to the VM disks.\n\nClick Done to finish editing VM disks and save your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute server volume attach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to attach the available volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba to the virtual machine myvm, run:# vinfra service compute server volume attach e4cb5363-1fb2-41f5-b24b-18f98a388cba --server myvm\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/vdb                             |\r\n| id     | e4cb5363-1fb2-41f5-b24b-18f98a388cba |\r\n+--------+--------------------------------------+\r\n\nThe name of the new device will be shown in the command output. To see all of the VM volumes, run:# vinfra service compute server volume list --server myvm\r\n+--------------------------------------+----------+\r\n| id                                   | device   |\r\n+--------------------------------------+----------+\r\n| e4cb5363-1fb2-41f5-b24b-18f98a388cba | /dev/vdb |\r\n| b325cc6e-8de1-4b6c-9807-5a497e3da7e3 | /dev/vda |\r\n+--------------------------------------+----------+\r\n\n\nTo detach a volume from a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Disks field.\n\nIn the Volumes window:\n\nClick Detach to detach a volume from a stopped virtual machine.\n\nClick Force detach to detach a volume from a running virtual machine.\n\nThere is a risk of data loss.\n\nClick Done to finish editing VM disks and save your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute server volume detach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to detach the volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba from the virtual machine myvm, run:# vinfra service compute server volume detach e4cb5363-1fb2-41f5-b24b-18f98a388cba \\\r\n--server 871fef54-519b-4111-b18d-d2039e2410a8\n\nSee also\n\nChanging virtual machine resources\n\nConfiguring network interfaces of virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server volume attach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to attach the available volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba to the virtual machine myvm, run:# vinfra service compute server volume attach e4cb5363-1fb2-41f5-b24b-18f98a388cba --server myvm\r\n+--------+--------------------------------------+\r\n| Field  | Value                                |\r\n+--------+--------------------------------------+\r\n| device | /dev/vdb                             |\r\n| id     | e4cb5363-1fb2-41f5-b24b-18f98a388cba |\r\n+--------+--------------------------------------+\r\n\nThe name of the new device will be shown in the command output. To see all of the VM volumes, run:# vinfra service compute server volume list --server myvm\r\n+--------------------------------------+----------+\r\n| id                                   | device   |\r\n+--------------------------------------+----------+\r\n| e4cb5363-1fb2-41f5-b24b-18f98a388cba | /dev/vdb |\r\n| b325cc6e-8de1-4b6c-9807-5a497e3da7e3 | /dev/vda |\r\n+--------------------------------------+----------+\r\n\n",
                "title": "To attach a volume to a virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server volume detach --server <server> <volume>\r\n\n\n--server <server>\n\nVirtual machine ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to detach the volume with the ID e4cb5363-1fb2-41f5-b24b-18f98a388cba from the virtual machine myvm, run:# vinfra service compute server volume detach e4cb5363-1fb2-41f5-b24b-18f98a388cba \\\r\n--server 871fef54-519b-4111-b18d-d2039e2410a8\n",
                "title": "To detach a volume from a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Disks field.\n\nIn the Volumes window:\n\nClick Attach to attach an existing volume, and then select the volume in the Attach volume window.\nClick Add to create a new volume, and then specify the volume name, size, and storage policy. The created volume will be automatically added to the VM disks.\n\n\nClick Done to finish editing VM disks and save your changes.\n\n",
                "title": "To attach a volume to a virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Disks field.\n\nIn the Volumes window:\n\nClick Detach to detach a volume from a stopped virtual machine.\n\nClick Force detach to detach a volume from a running virtual machine.\n\nThere is a risk of data loss.\n\n\n\n\nClick Done to finish editing VM disks and save your changes.\n\n",
                "title": "To detach a volume from a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-vm-volumes.html"
    },
    {
        "title": "Deleting statistics objects in WHMCS",
        "content": "Deleting statistics objects in WHMCS\nYou can delete existing statistics objects with the ostor-usage service and parameter obj specifying the statistics object. WHMCS removes the statistics object from S3 cluster when you click the Delete button. Create a file S3_deleteStatsForObject.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Delete s3 statistics object.\r\nfunction S3_deleteStatsForObject($object) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Delete s3 statistics object.\r\n    S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-usage&obj=\" . $object,\r\n        \"DELETE\"\r\n    );\r\n\r\n    // Clear array.\r\n    $_SESSION['s3_limits_bucket'] = null;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_deleteStatsForObject($_GET['object']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-statistics-objects-in-whmcs.html"
    },
    {
        "title": "Enabling access to S3 storage",
        "content": "Enabling access to S3 storage\nTo be able to manage S3 resources, you need to enable access to the S3 storage in the self-service panel. This will automatically generate an access key pair, an access key ID and a secret access key, for the current user. You can think of the access key ID as the login and the secret access key as the password.\nBy default, the access to the S3 storage is disabled for all self-service users.\nTo enable access to S3 storage\nGo to the S3 screen and click Enable S3 storage.\nOnce the access is enabled, you can proceed to manage your buckets and access keys.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/enabling-access-to-s3-storage.html"
    },
    {
        "title": "Listing statistics objects in WHMCS",
        "content": "Listing statistics objects in WHMCS\nYou can list all available statistics objects with the ostor-usage service and no parameters. The output only contains objects that have not been deleted. WHMCS lists the available statistics objects from S3 cluster when you click List statistics objects (on/off). Create a file S3_listStatsObjects.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// List s3 statistics objects.\r\nfunction S3_listStatsObjects() {\r\n\r\n    // Hide now.\r\n    if ($_SESSION['s3_stat_objects'] == 1) {\r\n\r\n        // Hide.\r\n        $_SESSION['s3_stat_objects'] = 0;\r\n\r\n        // Redirect back.\r\n        header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n\r\n     // Return immediately.\r\n        return;\r\n    }\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get s3 statistics objects.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-usage\",\r\n        \"GET\"\r\n    );\r\n\r\n    // Store s3 result.\r\n    $_SESSION['s3_stat_objects'] = 1;\r\n    $_SESSION['s3_stat'] = $s3_client;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_listStatsObjects();\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/listing-statistics-objects-in-whmcs.html"
    },
    {
        "title": "Backup storage on an NFS share",
        "content": "Backup storage on an NFS share\n\nGeneral requirements are listed in General requirements.\n\nTo better understand how to calculate the hardware configuration for backup storage with the NFS share destination, consider the following example with RAM and CPU reservations.   \nIf you have 1 node (1 system+metadata disk and 1 storage disk) and want to use it for backup storage, refer to the table below for the calculations.\n\nBackup storage on an NFS share                   \n\nService\nThe only node\n\nSystem\n4.5 GB,\t3.3 cores\n\nStorage services\n\n1 storage disk1 Though data is not stored locally, it is required to have one  100+ GB disk the with storage role as it will be used for internal needs., 1 metadata on system disk (each takes 0.5 GB and 0.2 cores), that is 1 GB and 0.4 cores in total\n\nBackup Gateway\n1 GB, 0.5 cores\n\nService reservations\n6.5 GB of RAM and\r\n4.2 cores\n\nMinimum hardware configuration\n8 GB of RAM and 4 cores\n\nRecommended hardware configuration\n8 GB of RAM and 6 cores\n\nSee also\n\nAcronis Backup Storage network requirements\n\nProvisioning Acronis Backup Storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup-storage-on-an-nfs-share.html"
    },
    {
        "title": "Releasing node disks",
        "content": "Releasing node disks\nDuring a disk release, its data is safely migrated to other disks, which takes time. To avoid data loss, wait until data migration is complete.\nLimitations\n\nA graceful release of a storage disk is possible only if the remaining disks in the storage cluster can comply with the configured redundancy scheme. You can, however, release a disk forcibly without data migration, but it will make the cluster degraded and trigger the cluster self-healing.\n\nPrerequisites\n\nBefore replacing a disk with the Metadata, Cache, or Metadata+Cache role, ensure that the same role is assigned to a new disk, and then release the old disk.\nIf you want all disks with the Storage role to be assigned automatically after replacement, automatic configuration of new disks must be enabled, as described in Configuring new storage disks automatically.\n\nTo release a disk from the storage cluster\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node.\nOn the Disks tab, click the disk to replace.\nOn the disk right pane, click Release.\n\n(Optional, highly not recommended) If you do not want to wait for data migration to finish, select Release without data migration.\n\nThere is a risk of data loss. Use this option only if your data is redundant.\n\nClick Release.\n\nWhen the data migration from the disk completes, the disk will be displayed without a role on the Disks tab and can be replaced with a new one.\n\nCommand-line interface\nUse the following command:vinfra node disk release [--force] [--node <node>] <disk>\r\n\n\n--force\n\nRelease without data migration\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<disk>\n\nDisk ID or device name\n\nFor example, to release the role cs from the disk sdc on the node node003, run:# vinfra node disk release sdc --node node003\n\nWhat's next\n\nConfiguring new disks manually",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node disk release [--force] [--node <node>] <disk>\r\n\n\n--force\n\nRelease without data migration\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<disk>\n\nDisk ID or device name\n\nFor example, to release the role cs from the disk sdc on the node node003, run:# vinfra node disk release sdc --node node003\n",
                "title": "To release a disk from the storage cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node.\nOn the Disks tab, click the disk to replace.\nOn the disk right pane, click Release.\n\n(Optional, highly not recommended) If you do not want to wait for data migration to finish, select Release without data migration.\n\nThere is a risk of data loss. Use this option only if your data is redundant.\n\n\nClick Release.\n\nWhen the data migration from the disk completes, the disk will be displayed without a role on the Disks tab and can be replaced with a new one.\n",
                "title": "To release a disk from the storage cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/releasing-node-disks.html"
    },
    {
        "title": "Preparing boot volumes",
        "content": "Preparing boot volumes\nThe instruction for preparing a boot volume differs depending on the source type.\nTo make a boot volume from an existing virtual machine\n\nAdmin panel\n\nShut down the VM which boot volume you want to use.\nOn the VM right panel, go to the Properties section, and then click the disk marked as Bootable.\nOn the volume right pane, click Clone.\n\nIn the Clone volume window, specify a volume name, size, and storage policy. Click Clone.\n\nCommand-line interface\n\nShut down the VM which boot volume you want to use. For example:# vinfra service compute server stop myvm\n\nFind out the boot volume's ID. For example:# vinfra service compute server show myvm\r\n+---------------+--------------------------------------------+\r\n| Field         | Value                                      |\r\n+---------------+--------------------------------------------+\r\n| config_drive  |                                            |\r\n| created       | 2021-06-10T08:55:53Z                       |\r\n| description   |                                            |\r\n| fault         |                                            |\r\n| flavor        | disk: 0                                    |\r\n|               | ephemeral: 0                               |\r\n|               | extra_specs: {}                            |\r\n|               | original_name: tiny                        |\r\n|               | ram: 512                                   |\r\n|               | swap: 0                                    |\r\n|               | vcpus: 1                                   |\r\n| ha_enabled    | True                                       |\r\n| host          | amigai-ac-ve0.vstoragedomain               |\r\n| host_status   | UP                                         |\r\n| id            | 6d0fc132-7ea7-41f0-81ca-a4a2b2a2c893       |\r\n| key_name      |                                            |\r\n| metadata      | {}                                         |\r\n| name          | myvm                                       |\r\n| networks      | - id: bd17c207-5291-4096-be6a-0a8a4bf67792 |\r\n|               |   ipam_enabled: true                       |\r\n|               |   ips:                                     |\r\n|               |   - 192.168.128.100                        |\r\n|               |   mac_addr: fa:16:3e:6b:6c:83              |\r\n|               |   name: private                            |\r\n|               |   spoofing_protection: true                |\r\n| orig_hostname | amigai-ac-ve0                              |\r\n| placements    | []                                         |\r\n| power_state   | SHUTDOWN                                   |\r\n| project_id    | dfd99654b8c94b939b638f94abb2ad73           |\r\n| status        | SHUTOFF                                    |\r\n| task_state    |                                            |\r\n| updated       | 2021-06-15T11:24:05Z                       |\r\n| user_data     |                                            |\r\n| vm_state      | stopped                                    |\r\n| volumes       | - delete_on_termination: false             |\r\n|               |   id: 49be1057-c026-494f-b85d-e013728d41bd |\r\n|               | - delete_on_termination: false             |\r\n|               |   id: eca9f679-7e35-4768-ad20-9bcb6af6fd59 |\r\n+---------------+--------------------------------------------+\r\n\nThe first volume in the output is the boot one.\n\nClone the boot volume specifying the name of the new volume. For example:# vinfra service compute volume clone 49be1057-c026-494f-b85d-e013728d41bd \\\r\n--name cloned_volume\n\nThe cloned volume will appear in the vinfra service compute volume list output:# vinfra service compute volume list\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| id               | name                    | size | status    | os-vol-host-attr:host     |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| 14f4053e-cff5<\u00e2\u0080\u00a6> | cloned_volume           | 1    | available | node003.vstoragedomain<\u00e2\u0080\u00a6> |\r\n| 504078c7-9035<\u00e2\u0080\u00a6> | myvm/cirros/Boot volume | 1    | in-use    | node002.vstoragedomain<\u00e2\u0080\u00a6> |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n\n\nTo make a boot volume from a template\n\nAdmin panel\n\nGo to the Compute > Storage > Images tab, and then click the required image.\nOn the image panel, click Create volume.\n\nIn the Create volume window, specify the volume name, size, and select a storage policy.\n\nClick Create.\n\nThe new volume will appear on the Compute > Storage > Volumes tab.\n\nCommand-line interface\nUse the following command:vinfra service compute volume create [--description <description>] [--image <image>]\r\n                                     --storage-policy <storage_policy> --size <size-gb> <volume-name>\r\n\n\n--description <description>\n\nVolume description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--image <image>\n\nSource compute image ID or name\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n--size <size-gb>\n\nVolume size, in gigabytes\n<volume-name>\n\nVolume name\n\nFor example, to create a volume called cirros_volume with the size of 1 GB and the default storage policy from the cirros image, run:# vinfra service compute volume create cirros_volume --image cirros --storage-policy default --size 1\nThe new volume will appear in the vinfra service compute volume list output:# vinfra service compute volume list\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| id               | name                    | size | status    | os-vol-host-attr:host     |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| 232d09db-bc75<\u00e2\u0080\u00a6> | cirros_volume           | 1    | available | node003.vstoragedomain<\u00e2\u0080\u00a6> |\r\n| 14f4053e-cff5<\u00e2\u0080\u00a6> | cloned_volume           | 1    | available | node003.vstoragedomain<\u00e2\u0080\u00a6> |\r\n| 504078c7-9035<\u00e2\u0080\u00a6> | myvm/cirros/Boot volume | 1    | in-use    | node002.vstoragedomain<\u00e2\u0080\u00a6> |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n\n\nWhat's next\n\nCreating virtual machines\n\nManaging images",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nShut down the VM which boot volume you want to use. For example:# vinfra service compute server stop myvm\n\n\nFind out the boot volume's ID. For example:# vinfra service compute server show myvm\r\n+---------------+--------------------------------------------+\r\n| Field         | Value                                      |\r\n+---------------+--------------------------------------------+\r\n| config_drive  |                                            |\r\n| created       | 2021-06-10T08:55:53Z                       |\r\n| description   |                                            |\r\n| fault         |                                            |\r\n| flavor        | disk: 0                                    |\r\n|               | ephemeral: 0                               |\r\n|               | extra_specs: {}                            |\r\n|               | original_name: tiny                        |\r\n|               | ram: 512                                   |\r\n|               | swap: 0                                    |\r\n|               | vcpus: 1                                   |\r\n| ha_enabled    | True                                       |\r\n| host          | amigai-ac-ve0.vstoragedomain               |\r\n| host_status   | UP                                         |\r\n| id            | 6d0fc132-7ea7-41f0-81ca-a4a2b2a2c893       |\r\n| key_name      |                                            |\r\n| metadata      | {}                                         |\r\n| name          | myvm                                       |\r\n| networks      | - id: bd17c207-5291-4096-be6a-0a8a4bf67792 |\r\n|               |   ipam_enabled: true                       |\r\n|               |   ips:                                     |\r\n|               |   - 192.168.128.100                        |\r\n|               |   mac_addr: fa:16:3e:6b:6c:83              |\r\n|               |   name: private                            |\r\n|               |   spoofing_protection: true                |\r\n| orig_hostname | amigai-ac-ve0                              |\r\n| placements    | []                                         |\r\n| power_state   | SHUTDOWN                                   |\r\n| project_id    | dfd99654b8c94b939b638f94abb2ad73           |\r\n| status        | SHUTOFF                                    |\r\n| task_state    |                                            |\r\n| updated       | 2021-06-15T11:24:05Z                       |\r\n| user_data     |                                            |\r\n| vm_state      | stopped                                    |\r\n| volumes       | - delete_on_termination: false             |\r\n|               |   id: 49be1057-c026-494f-b85d-e013728d41bd |\r\n|               | - delete_on_termination: false             |\r\n|               |   id: eca9f679-7e35-4768-ad20-9bcb6af6fd59 |\r\n+---------------+--------------------------------------------+\r\n\nThe first volume in the output is the boot one.\n\n\nClone the boot volume specifying the name of the new volume. For example:# vinfra service compute volume clone 49be1057-c026-494f-b85d-e013728d41bd \\\r\n--name cloned_volume\n\n\nThe cloned volume will appear in the vinfra service compute volume list output:# vinfra service compute volume list\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| id               | name                    | size | status    | os-vol-host-attr:host     |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| 14f4053e-cff5<\u00e2\u0080\u00a6> | cloned_volume           | 1    | available | node003.vstoragedomain<\u00e2\u0080\u00a6> |\r\n| 504078c7-9035<\u00e2\u0080\u00a6> | myvm/cirros/Boot volume | 1    | in-use    | node002.vstoragedomain<\u00e2\u0080\u00a6> |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n\n",
                "title": "To make a boot volume from an existing virtual machine"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume create [--description <description>] [--image <image>]\r\n                                     --storage-policy <storage_policy> --size <size-gb> <volume-name>\r\n\n\n--description <description>\n\n\nVolume description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--image <image>\n\nSource compute image ID or name\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n--size <size-gb>\n\nVolume size, in gigabytes\n<volume-name>\n\nVolume name\n\nFor example, to create a volume called cirros_volume with the size of 1 GB and the default storage policy from the cirros image, run:# vinfra service compute volume create cirros_volume --image cirros --storage-policy default --size 1\nThe new volume will appear in the vinfra service compute volume list output:# vinfra service compute volume list\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| id               | name                    | size | status    | os-vol-host-attr:host     |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n| 232d09db-bc75<\u00e2\u0080\u00a6> | cirros_volume           | 1    | available | node003.vstoragedomain<\u00e2\u0080\u00a6> |\r\n| 14f4053e-cff5<\u00e2\u0080\u00a6> | cloned_volume           | 1    | available | node003.vstoragedomain<\u00e2\u0080\u00a6> |\r\n| 504078c7-9035<\u00e2\u0080\u00a6> | myvm/cirros/Boot volume | 1    | in-use    | node002.vstoragedomain<\u00e2\u0080\u00a6> |\r\n+------------------+-------------------------+------+-----------+---------------------------+\r\n\n",
                "title": "To make a boot volume from a template"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nShut down the VM which boot volume you want to use.\nOn the VM right panel, go to the Properties section, and then click the disk marked as Bootable.\nOn the volume right pane, click Clone.\n\nIn the Clone volume window, specify a volume name, size, and storage policy. Click Clone.\n\n\n\n\n\n\n",
                "title": "To make a boot volume from an existing virtual machine"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Compute > Storage > Images tab, and then click the required image.\nOn the image panel, click Create volume.\n\nIn the Create volume window, specify the volume name, size, and select a storage policy.\n\n\n\n\n\nClick Create.\n\nThe new volume will appear on the Compute > Storage > Volumes tab.\n",
                "title": "To make a boot volume from a template"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-boot-volumes.html"
    },
    {
        "title": "Detaching external storages",
        "content": "Detaching external storages\nLimitations\n\nAfter detaching an external NFS storage, the associated NFS share is left mounted.\n\nPrerequisites\n\nAn external storage is attached to the compute cluster, as described in Attaching external iSCSI storage or Attaching external NFS storage.\n\nTo detach an external storage\n\nDisconnect the external storage from the compute cluster. For example, to remove the external storage pure-storage, run:# vinfra service compute storage remove pure-storage\n\n[For an external iSCSI storage] On each compute node, stop and disable the multipathing service:\r\n# systemctl stop multipathd; systemctl disable multipathd\n\nAfter detaching your external storage, you will have to manually delete storage policies associated with it.\nSee also\n\nManaging storage policies",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/detaching-external-storages.html"
    },
    {
        "title": "Managing geo-replication for backup storage",
        "content": "Managing geo-replication for backup storage\nVirtuozzo Hybrid Infrastructure allows you to enable backup storage replication between two geographically distributed datacenters registered in the Cloud Management Panel. It provides backup data protection against the primary datacenter failure. You can enable geo-replication for backup storage clusters that are set up on different storage backends: a local storage cluster, NFS share, or public cloud.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-geo-replication-backup-storage.html"
    },
    {
        "title": "Deleting virtual machines",
        "content": "Deleting virtual machinesDELETE /servers/{server_id}\r\n\nDelete a server with the specified ID.\nBy default, the instance is going to be hard-deleted immediately from\r\nthe system, but you can set reclaim_instance_interval > 0 to make\r\nthe API soft-delete the instance, so that the instance will not be\r\ndeleted until the reclaim_instance_interval has expired since the\r\ninstance was soft-deleted. The instance marked as SOFT_DELETED can\r\nbe recovered via restore action before it is really deleted from the\r\nsystem.\nPreconditions:\n\nThe server must exist.\nAnyone can delete a server when the status of the server is not\r\nlocked and when the policy allows.\nIf the server is locked, you must have administrator privileges to\r\ndelete the server.\n\nAsynchronous postconditions:\n\nWith correct permissions, you can see the server status as deleting.\nThe ports attached to the server, which Nova created during the server\r\ncreate process or when attaching interfaces later, are deleted.\nThe server does not appear in the list servers response.\nIf hard delete, the server managed by OpenStack Compute is deleted\r\non the compute node.\n\nTroubleshooting:\n\nIf server status remains to be deleting or another error,\r\nthe request failed. Ensure that you meet the\r\npreconditions. Then, investigate the compute back end.\nThe request returns the HTTP 409 response code when the server is\r\nlocked even if you have correct permissions. Ensure that you meet the\r\npreconditions then investigate the server status.\nThe server managed by OpenStack Compute is not deleted from the\r\ncompute node.\n\nSource: https://docs.openstack.org/api-ref/compute/?expanded=delete-server-detail#delete-server\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26/servers/642b7726-bc3b-4824-872b-124097d2d20c\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-virtual-machines.html"
    },
    {
        "title": "Attaching volumes to virtual machines",
        "content": "Attaching volumes to virtual machinesPOST /servers/{server_id}/os-volume_attachments\r\n\nAttach a volume to the given virtual machine.\n\nThis is an asynchronous API, callers should poll the status and list of volume attachments within the volume API, to determine when the attachment has completed successfully.\n\nSource: https://docs.openstack.org/api-ref/compute/?expanded=attach-a-volume-to-an-instance-detail#attach-a-volume-to-an-instance\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nserver_id\n\npath\nstring\nThe UUID of the server.\n\nvolumeAttachment\n\nbody\nobject\n\nA dictionary representation of a volume attachment containing the fields\r\ndevice and volumeId.\n\ndevice (Optional)\nbody\nstring\nName of the device such as, /dev/vdb. Omit or set this parameter to null for\r\nauto-assignment, if supported. If you specify this parameter, the device must\r\nnot exist in the guest operating system. Note that as of the 12.0.0 Liberty release,\r\nthe Nova libvirt driver no longer honors a user-supplied device name. This is\r\nthe same behavior as if the device name parameter is not supplied on the request.\n\nvolumeId\n\nbody\nstring\nThe UUID of the volume to attach.\n\ntag (Optional)\nbody\nstring\n\nA device role tag that can be applied to a volume when attaching it to the\r\nVM. The guest OS of a server that has devices tagged in this manner can\r\naccess hardware metadata about the tagged devices from the metadata API and\r\non the config drive, if enabled.\n\nTagged volume attachment is not supported for shelved-offloaded\r\ninstances.\n\nNew in version 2.49\n\ndelete_on_termination (Optional)\nbody\nboolean\n\nTo delete the attached volume when the server is destroyed, specify true.\r\nOtherwise, specify false. Default is false.\nNew in version 2.79\n\nExample\nAttach an existing volume with the specified ID to a VM with the specified ID.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"volumeAttachment\": {\r\n        \"volumeId\": \"16cd801e-f3c1-4cac-aa6c-aecf22642a89\",\r\n        \"device\": \"/dev/sdb\"\r\n    }\r\n}' https://<node_IP_addr>:8774/v2.1/b906404c55bb44729da99987536ac5bc/servers/0785ee80-1eca-426b-b8c4-5b499fc7f614/os-volume_attachments\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvolumeAttachment\n\nbody\nobject\n\nA dictionary representation of a volume attachment containing the fields\r\ndevice, id, serverId and volumeId.\n\ndevice\n\nbody\nstring\nName of the device such as, /dev/vdb.\n\nid\n\nbody\nstring\nThe UUID of the volume.\n\nserverId (Optional)\nbody\nstring\nThe UUID of the server.\n\nvolumeId (Optional)\nbody\nstring\nThe UUID of the attached volume.\n\ntag\n\nbody\nstring\n\nThe device tag applied to the volume block device or null.\nNew in version 2.70\n\ndelete_on_termination\n\nbody\nboolean\n\nA flag indicating if the attached volume will be deleted when the server is\r\ndeleted.\nNew in version 2.79\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"volumeAttachment\": {\r\n    \"device\": \"/dev/vdb\",\r\n    \"serverId\": \"0785ee80-1eca-426b-b8c4-5b499fc7f614\",\r\n    \"id\": \"16cd801e-f3c1-4cac-aa6c-aecf22642a89\",\r\n    \"volumeId\": \"16cd801e-f3c1-4cac-aa6c-aecf22642a89\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/attaching-volumes-to-virtual-machines.html"
    },
    {
        "title": "Installing updates",
        "content": "Installing updates\nVirtuozzo Hybrid Infrastructure supports non-disruptive rolling updates. Nodes are updated one by one, with the data availability unaffected.\nAn update may have the following impact on a node:\n\nReboot required. During such an update, a node needs to be rebooted to apply a new kernel. In this case, you can place the node into the maintenance mode and evacuate its services and virtual machines to other nodes, to avoid their downtime. During the node maintenance, the compute API services are fenced from processing compute requests. Once the node is updated, it is automatically rebooted. If the node entered maintenance, it returns to operation after the reboot and the migrated workloads, except for VMs, are moved back on the node. The evacuated VMs remain on other nodes.\nMaintenance required. During such an update, a node needs to enter the maintenance mode to install new packages for major services. In this case, you can place the node into the maintenance mode and evacuate its services and virtual machines to other nodes, to avoid their downtime. During the node maintenance, the compute API services are fenced from processing compute requests. Once updated, the node exits maintenance without a reboot and the migrated workloads, except for VMs, are moved back on the node. The evacuated VMs remain on other nodes.\nNo impact. In this case, an update is performed without a node reboot or maintenance.\n\nYou can update different cluster components all together or separately. In either case, the components are updated in the following order:\n\nCluster nodes are updated first. If any of these nodes are included in the compute cluster, the compute services on them are updated at this step.\nManagement nodes are updated only when all of the cluster nodes are up to date. The primary management node is the last one to be updated. If management nodes have the compute services deployed, these services are updated at this step.\nThe management panel (admin and self-service) is updated on management nodes and only when all of the nodes, both cluster and management, are up to date. While updating this component, management nodes do not require a reboot.\n\nLimitations\n\nNodes must be updated only in the admin panel or via the vinfra tool. Do not use yum update.\nUnassigned nodes can be updated.\nUpdates are applied to one node at a time.\nYou can only update management nodes all together, one at a time, and after updating all of the cluster nodes.\nYou can only update the management panel after updating all of the management and cluster nodes.\nIn a single-node deployment, the node does not enter maintenance during an update. If an update requires a node reboot or maintenance, the cluster downtime is expected.\nLive migration is not supported for suspended virtual machines, as well as for virtual machines with attached vGPU or PCI devices.\n\nPrerequisites\n\nThe storage cluster is created by following the instructions in Deploying the storage cluster.\nAny third-party repositories are disabled.\nThe cluster is healthy and each node in the infrastructure is online.\nThe cluster DNS is configured, as described in Adding external DNS servers, and point to a DNS table to resolve external host names.\n\nTo update cluster components\n\nAdmin panel\n\nOpen the Settings > Updates screen. The date of the last check is displayed in the upper right corner. Click the round arrow to check for new updates. If updates are available for a cluster component, its update status changes to Available. Check if a node needs a reboot or  maintenance in the Update impact column.\n\nClick Download in the upper right corner to get the updates. Wait until the updates are downloaded and the update status changes to Ready to install.\n\nOnce the updates are downloaded, the automatic check for updates is disabled until the updates are installed or the operation is canceled. To reset the software updates state and make it possible to check for a newer version at this step, use the vinfra software-updates reset command.\n\nClick Release notes to read the release notes.\n\nSelect components that you want to be updated:\n\nTo update cluster nodes, select the desired cluster nodes.\nTo update management nodes, select all of the management nodes and those cluster nodes that require an update.\nTo update the management panel, select this component and all of the management nodes if they require an update.\n\nClick Update to continue.\nWhen upgrading to a new major version, review the upgrade notes, and then click Next.\n\nIf you have selected nodes that require a reboot or maintenance, do the following:\n\nDecide whether these nodes will enter the maintenance mode. Select Maintenance mode, if you want to place the nodes in the maintenance mode.\n\nIf you have selected nodes with the compute service, choose how to migrate virtual machines running on these nodes:\n\nWith the option Ignore VMs that cannot be live migrated, VMs from a node that enters the maintenance mode will be live migrated to other compute nodes. VMs that cannot be live migrated will be ignored. This applies to suspended VMs, VMs with vGPU or PCI devices attached, or if other compute nodes have insufficient vCPU or RAM resources. During the node update, ignored VMs will be stopped, resulting in downtime. They will be started automatically once the update is complete. After the node exits maintenance, the migrated VMs will not be moved back on the node.\nWith the option Ignore VMs that cannot be or failed to be live migrated, VMs from a node that enters the maintenance mode will be live migrated to other compute nodes. VMs that cannot be live migrated will be ignored. This applies to suspended VMs, VMs with vGPU or PCI devices attached, or if other compute nodes have insufficient vCPU or RAM resources. During the node update, ignored VMs and VMs that failed to be live migrated will be stopped, resulting in downtime. They will be started automatically once the update is complete. After the node exits maintenance, the migrated VMs will not be moved back on the node.\nWith the option Live migrate all VMs, all of the VMs from a node that enters the maintenance mode will be live migrated to other compute nodes. After the node exits maintenance, the migrated VMs will not be moved back on the node.\n\nReview the selected components, and then click Install. The system will start update eligibility checks. In case of a major release, the system will also check for removed and unmaintained hardware:\n\nRemoved hardware means that its support has been discontinued. If removed hardware is detected, review its details. If your hardware is detected correctly, the upgrade will fail because such devices are no longer available in the new version. Otherwise, you can force the upgrade by clicking Force update.\nUnmaintained hardware includes devices (drivers and adapters) that are no longer being tested and updated in the new version. If unmaintained hardware is detected, you cannot continue the upgrade because such devices should no longer be used in production.\n\nYou can export the list of detected hardware to a JSON file by clicking Export to file.\n\nDo not perform any cluster configuration tasks in the admin panel or command-line interface during the update, as this will lead to an update failure and cluster downtime.\n\nWhile the updates are being installed, you can pause or cancel the process. After the update is complete, the component statuses will change to Up to date.\nIf the update fails, click Details to view the issue details and decide how to proceed. You can cancel the update, solve the issues, and retry updating without downtime. Alternatively, you can force the update without putting the nodes into maintenance. However, this will cause a downtime of workloads running on them.\nIf canceling or forcing the update fails as well, you can reset the update state and discard the downloaded packages by using the vinfra software-updates reset command. Once the update state is reset, you can start the update anew.\n\nCommand-line interface\nUse the following commands:\n\nCheck if there are updates for the storage cluster:# vinfra software-updates check-for-updates\n\nView the results of the check-up:# vinfra software-updates status\r\n+---------------------------+--------------------------------------------+\r\n| Field                     | Value                                      |\r\n+---------------------------+--------------------------------------------+\r\n| available_storage_release | release: '127'                             |\r\n|                           | version: 5.2.0                             |\r\n| control_plane             | available_storage_release:                 |\r\n|                           |   release: '127'                           |\r\n|                           |   version: 5.2.0                           |\r\n|                           | installed_storage_release:                 |\r\n|                           |   release: '206'                           |\r\n|                           |   version: 5.1.0                           |\r\n|                           | status: available                          |\r\n| last_check_datetime       | 2021-11-01T12:22:10.630818                 |\r\n| nodes                     | - available_storage_release:               |\r\n|                           |     release: '127'                         |\r\n|                           |     version: 5.2.0                         |\r\n|                           |   current_storage_release:                 |\r\n|                           |     release: '206'                         |\r\n|                           |     version: 5.1.0                         |\r\n|                           |   downloaded_storage_release: null         |\r\n|                           |   host: node001.vstoragedomain             |\r\n|                           |   id: 0175ce44-c86d-7818-3259-3182f5fd83f6 |\r\n|                           |   is_in_ha: false                          |\r\n|                           |   is_primary: true                         |\r\n|                           |   maintenance_required: true               |\r\n|                           |   orig_hostname: node001                   |\r\n|                           |   reboot_required: true                    |\r\n|                           |   status: available                        |\r\n|                           | - available_storage_release:               |\r\n|                           |     release: '127'                         |\r\n|                           |     version: 5.2.0                         |\r\n|                           |   current_storage_release:                 |\r\n|                           |     release: '206'                         |\r\n|                           |     version: 5.1.0                         |\r\n|                           |   downloaded_storage_release: null         |\r\n|                           |   host: node002.vstoragedomain             |\r\n|                           |   id: 923926da-a879-5f56-1b24-1462917ed335 |\r\n|                           |   is_in_ha: false                          |\r\n|                           |   is_primary: false                        |\r\n|                           |   maintenance_required: true               |\r\n|                           |   orig_hostname: node002                   |\r\n|                           |   reboot_required: true                    |\r\n|                           |   status: available                        |\r\n|                           | - available_storage_release:               |\r\n|                           |     release: '127'                         |\r\n|                           |     version: 5.2.0                         |\r\n|                           |   current_storage_release:                 |\r\n|                           |     release: '206'                         |\r\n|                           |     version: 5.1.0                         |\r\n|                           |   downloaded_storage_release: null         |\r\n|                           |   host: node003.vstoragedomain             |\r\n|                           |   id: ef24c47c-620d-8726-2677-ed94d853de2e |\r\n|                           |   is_in_ha: false                          |\r\n|                           |   is_primary: false                        |\r\n|                           |   maintenance_required: true               |\r\n|                           |   orig_hostname: node003                   |\r\n|                           |   reboot_required: true                    |\r\n|                           |   status: available                        |\r\n| status                    | available                                  |\r\n+---------------------------+--------------------------------------------+\r\n\nThe output above shows that an update to build 234 is available.\n\nDownload the software update:# vinfra software-updates download\n\nCheck whether the nodes in the storage cluster are eligible for the update:# vinfra software-updates eligibility-check\r\n+---------+--------------------------------------+\r\n| Field   | Value                                |\r\n+---------+--------------------------------------+\r\n| task_id | 88e51115-8f0e-4c6f-b33b-949728d1fb99 |\r\n+---------+--------------------------------------+\r\n# vinfra task show 88e51115-8f0e-4c6f-b33b-949728d1fb99\r\n+---------+------------------------------------------------------------------+\r\n| Field   | Value                                                            |\r\n+---------+------------------------------------------------------------------+\r\n| details |                                                                  |\r\n| name    | backend.presentation.software_updates.tasks.EligibilityCheckTask |\r\n| result  | chunks_rebalancing_rate:                                         |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: info                                                 |\r\n|         | cluster_has_releasing_nodes:                                     |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | cluster_unhealthy:                                               |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | not_enough_space_on_agents:                                      |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | not_enough_space_on_mn:                                          |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | postgres_not_running:                                            |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | request_accept_eula:                                             |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | server_with_pci_devices:                                         |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: info                                                 |\r\n|         | shaman:                                                          |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | tgtd:                                                            |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | too_many_pending_chunks:                                         |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: info                                                 |\r\n| state   | success                                                          |\r\n| task_id | 88e51115-8f0e-4c6f-b33b-949728d1fb99                             |\r\n+---------+------------------------------------------------------------------+\r\n\n\nStart the software update procedure by running the command:vinfra software-updates start [--maintenance enabled={yes,no}[,key=value,\u00e2\u0080\u00a6]]\r\n                              [--nodes <nodes>] [--skip-control-plane]\r\n                              \n\n--maintenance enabled={yes,no}[,key=value,\u00e2\u0080\u00a6]>\n\nSpecify maintenance parameters:\n\nenabled: enter maintenance during the upgrade (yes or no)\n\ncomma-separated key=value pairs with keys (optional):\n\non-fail: choose how to proceed with the update if maintenance fails:\n\nstop (default): stop the update if a node cannot enter maintenance mode. Nodes that have already been updated will remain so.\nskip: skip and do not update nodes that cannot enter maintenance mode\nforce: forcibly update and reboot (if needed) all nodes even if they cannot enter maintenance mode. Using this option may result in downtime.\n\ncompute-mode: choose how to proceed with the update if a VM cannot be live migrated:\n\nstrict: stop the upgrade if a VM cannot be live migrated\nignore: ignore a VM that cannot be live migrated\nignore_ext: ignore a VM that cannot be or failed to be live migrated\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--skip-control-plane\n\nUpdate the cluster without updating the management panel.\n\nFor example, to start updating the nodes node001, node002, and node003 and put them into maintenance, run:# vinfra software-updates start --nodes node001,node002,node003 \\\r\n--maintenance enabled=yes,on-fail=skip,compute-mode=ignore\r\n\nThose nodes that cannot enter maintenance will be skipped. Virtual machines that cannot be live migrated during maintenance will be ignored.\n\nTo pause software updates, use the command vinfra software-updates pause. To resume the update procedure, run vinfra software-updates resume.\nYou can cancel the update and exit the maintenance mode for a node by using the command:vinfra software-updates cancel [--maintenance-mode {exit,exit-keep-resources,hold}]\n\n--maintenance-mode {exit,exit-keep-resources,hold}\n\nMaintenance mode:\n\nexit: exit maintenance for the node and return evacuated resources back on the node\nexit-keep-resources (default): exit maintenance for the node but keep evacuated resources on another node\nhold: do not exit maintenance\n\nFor example, to cancel the update and return the node to operation, run:# vinfra software-updates cancel exit\nThe evacuated resources from this node will be moved back to it.\nIf an update fails and cannot be canceled, you can reset the update state and discard the downloaded packages by using the vinfra software-updates reset command. Once the update state is reset, you can start the update anew.\n\nSee also\n\nPerforming node maintenance",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following commands:\n\n\nCheck if there are updates for the storage cluster:# vinfra software-updates check-for-updates\n\n\nView the results of the check-up:# vinfra software-updates status\r\n+---------------------------+--------------------------------------------+\r\n| Field                     | Value                                      |\r\n+---------------------------+--------------------------------------------+\r\n| available_storage_release | release: '127'                             |\r\n|                           | version: 5.2.0                             |\r\n| control_plane             | available_storage_release:                 |\r\n|                           |   release: '127'                           |\r\n|                           |   version: 5.2.0                           |\r\n|                           | installed_storage_release:                 |\r\n|                           |   release: '206'                           |\r\n|                           |   version: 5.1.0                           |\r\n|                           | status: available                          |\r\n| last_check_datetime       | 2021-11-01T12:22:10.630818                 |\r\n| nodes                     | - available_storage_release:               |\r\n|                           |     release: '127'                         |\r\n|                           |     version: 5.2.0                         |\r\n|                           |   current_storage_release:                 |\r\n|                           |     release: '206'                         |\r\n|                           |     version: 5.1.0                         |\r\n|                           |   downloaded_storage_release: null         |\r\n|                           |   host: node001.vstoragedomain             |\r\n|                           |   id: 0175ce44-c86d-7818-3259-3182f5fd83f6 |\r\n|                           |   is_in_ha: false                          |\r\n|                           |   is_primary: true                         |\r\n|                           |   maintenance_required: true               |\r\n|                           |   orig_hostname: node001                   |\r\n|                           |   reboot_required: true                    |\r\n|                           |   status: available                        |\r\n|                           | - available_storage_release:               |\r\n|                           |     release: '127'                         |\r\n|                           |     version: 5.2.0                         |\r\n|                           |   current_storage_release:                 |\r\n|                           |     release: '206'                         |\r\n|                           |     version: 5.1.0                         |\r\n|                           |   downloaded_storage_release: null         |\r\n|                           |   host: node002.vstoragedomain             |\r\n|                           |   id: 923926da-a879-5f56-1b24-1462917ed335 |\r\n|                           |   is_in_ha: false                          |\r\n|                           |   is_primary: false                        |\r\n|                           |   maintenance_required: true               |\r\n|                           |   orig_hostname: node002                   |\r\n|                           |   reboot_required: true                    |\r\n|                           |   status: available                        |\r\n|                           | - available_storage_release:               |\r\n|                           |     release: '127'                         |\r\n|                           |     version: 5.2.0                         |\r\n|                           |   current_storage_release:                 |\r\n|                           |     release: '206'                         |\r\n|                           |     version: 5.1.0                         |\r\n|                           |   downloaded_storage_release: null         |\r\n|                           |   host: node003.vstoragedomain             |\r\n|                           |   id: ef24c47c-620d-8726-2677-ed94d853de2e |\r\n|                           |   is_in_ha: false                          |\r\n|                           |   is_primary: false                        |\r\n|                           |   maintenance_required: true               |\r\n|                           |   orig_hostname: node003                   |\r\n|                           |   reboot_required: true                    |\r\n|                           |   status: available                        |\r\n| status                    | available                                  |\r\n+---------------------------+--------------------------------------------+\r\n\nThe output above shows that an update to build 234 is available.\n\n\nDownload the software update:# vinfra software-updates download\n\n\nCheck whether the nodes in the storage cluster are eligible for the update:# vinfra software-updates eligibility-check\r\n+---------+--------------------------------------+\r\n| Field   | Value                                |\r\n+---------+--------------------------------------+\r\n| task_id | 88e51115-8f0e-4c6f-b33b-949728d1fb99 |\r\n+---------+--------------------------------------+\r\n# vinfra task show 88e51115-8f0e-4c6f-b33b-949728d1fb99\r\n+---------+------------------------------------------------------------------+\r\n| Field   | Value                                                            |\r\n+---------+------------------------------------------------------------------+\r\n| details |                                                                  |\r\n| name    | backend.presentation.software_updates.tasks.EligibilityCheckTask |\r\n| result  | chunks_rebalancing_rate:                                         |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: info                                                 |\r\n|         | cluster_has_releasing_nodes:                                     |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | cluster_unhealthy:                                               |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | not_enough_space_on_agents:                                      |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | not_enough_space_on_mn:                                          |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | postgres_not_running:                                            |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | request_accept_eula:                                             |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | server_with_pci_devices:                                         |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: info                                                 |\r\n|         | shaman:                                                          |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | tgtd:                                                            |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: critical                                             |\r\n|         | too_many_pending_chunks:                                         |\r\n|         |   details: null                                                  |\r\n|         |   exception: null                                                |\r\n|         |   message: null                                                  |\r\n|         |   passed: true                                                   |\r\n|         |   severity: info                                                 |\r\n| state   | success                                                          |\r\n| task_id | 88e51115-8f0e-4c6f-b33b-949728d1fb99                             |\r\n+---------+------------------------------------------------------------------+\r\n\n\n\nStart the software update procedure by running the command:vinfra software-updates start [--maintenance enabled={yes,no}[,key=value,\u00e2\u0080\u00a6]]\r\n                              [--nodes <nodes>] [--skip-control-plane]\r\n                              \n\n--maintenance enabled={yes,no}[,key=value,\u00e2\u0080\u00a6]>\n\n\nSpecify maintenance parameters:\n\nenabled: enter maintenance during the upgrade (yes or no)\n\ncomma-separated key=value pairs with keys (optional):\n\n\non-fail: choose how to proceed with the update if maintenance fails:\n\nstop (default): stop the update if a node cannot enter maintenance mode. Nodes that have already been updated will remain so.\nskip: skip and do not update nodes that cannot enter maintenance mode\nforce: forcibly update and reboot (if needed) all nodes even if they cannot enter maintenance mode. Using this option may result in downtime.\n\n\n\n\n\ncompute-mode: choose how to proceed with the update if a VM cannot be live migrated:\n\nstrict: stop the upgrade if a VM cannot be live migrated\nignore: ignore a VM that cannot be live migrated\nignore_ext: ignore a VM that cannot be or failed to be live migrated\n\n\n\n\n\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--skip-control-plane\n\nUpdate the cluster without updating the management panel.\n\nFor example, to start updating the nodes node001, node002, and node003 and put them into maintenance, run:# vinfra software-updates start --nodes node001,node002,node003 \\\r\n--maintenance enabled=yes,on-fail=skip,compute-mode=ignore\r\n\nThose nodes that cannot enter maintenance will be skipped. Virtual machines that cannot be live migrated during maintenance will be ignored.\n\n\nTo pause software updates, use the command vinfra software-updates pause. To resume the update procedure, run vinfra software-updates resume.\nYou can cancel the update and exit the maintenance mode for a node by using the command:vinfra software-updates cancel [--maintenance-mode {exit,exit-keep-resources,hold}]\n\n--maintenance-mode {exit,exit-keep-resources,hold}\n\n\nMaintenance mode:\n\nexit: exit maintenance for the node and return evacuated resources back on the node\nexit-keep-resources (default): exit maintenance for the node but keep evacuated resources on another node\nhold: do not exit maintenance\n\n\n\nFor example, to cancel the update and return the node to operation, run:# vinfra software-updates cancel exit\nThe evacuated resources from this node will be moved back to it.\nIf an update fails and cannot be canceled, you can reset the update state and discard the downloaded packages by using the vinfra software-updates reset command. Once the update state is reset, you can start the update anew.\n",
                "title": "To update cluster components"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nOpen the Settings > Updates screen. The date of the last check is displayed in the upper right corner. Click the round arrow to check for new updates. If updates are available for a cluster component, its update status changes to Available. Check if a node needs a reboot or  maintenance in the Update impact column.\n\n\nClick Download in the upper right corner to get the updates. Wait until the updates are downloaded and the update status changes to Ready to install.\n\nOnce the updates are downloaded, the automatic check for updates is disabled until the updates are installed or the operation is canceled. To reset the software updates state and make it possible to check for a newer version at this step, use the vinfra software-updates reset command.\n\n\n\nClick Release notes to read the release notes.\n\n\nSelect components that you want to be updated:\n\nTo update cluster nodes, select the desired cluster nodes.\nTo update management nodes, select all of the management nodes and those cluster nodes that require an update.\nTo update the management panel, select this component and all of the management nodes if they require an update.\n\n\nClick Update to continue.\nWhen upgrading to a new major version, review the upgrade notes, and then click Next.\n\nIf you have selected nodes that require a reboot or maintenance, do the following:\n\nDecide whether these nodes will enter the maintenance mode. Select Maintenance mode, if you want to place the nodes in the maintenance mode.\n\nIf you have selected nodes with the compute service, choose how to migrate virtual machines running on these nodes:\n\nWith the option Ignore VMs that cannot be live migrated, VMs from a node that enters the maintenance mode will be live migrated to other compute nodes. VMs that cannot be live migrated will be ignored. This applies to suspended VMs, VMs with vGPU or PCI devices attached, or if other compute nodes have insufficient vCPU or RAM resources. During the node update, ignored VMs will be stopped, resulting in downtime. They will be started automatically once the update is complete. After the node exits maintenance, the migrated VMs will not be moved back on the node.\nWith the option Ignore VMs that cannot be or failed to be live migrated, VMs from a node that enters the maintenance mode will be live migrated to other compute nodes. VMs that cannot be live migrated will be ignored. This applies to suspended VMs, VMs with vGPU or PCI devices attached, or if other compute nodes have insufficient vCPU or RAM resources. During the node update, ignored VMs and VMs that failed to be live migrated will be stopped, resulting in downtime. They will be started automatically once the update is complete. After the node exits maintenance, the migrated VMs will not be moved back on the node.\nWith the option Live migrate all VMs, all of the VMs from a node that enters the maintenance mode will be live migrated to other compute nodes. After the node exits maintenance, the migrated VMs will not be moved back on the node.\n\n\n\n\n\nReview the selected components, and then click Install. The system will start update eligibility checks. In case of a major release, the system will also check for removed and unmaintained hardware:\n\nRemoved hardware means that its support has been discontinued. If removed hardware is detected, review its details. If your hardware is detected correctly, the upgrade will fail because such devices are no longer available in the new version. Otherwise, you can force the upgrade by clicking Force update.\nUnmaintained hardware includes devices (drivers and adapters) that are no longer being tested and updated in the new version. If unmaintained hardware is detected, you cannot continue the upgrade because such devices should no longer be used in production.\n\nYou can export the list of detected hardware to a JSON file by clicking Export to file.\n\n\n\nDo not perform any cluster configuration tasks in the admin panel or command-line interface during the update, as this will lead to an update failure and cluster downtime.\n\nWhile the updates are being installed, you can pause or cancel the process. After the update is complete, the component statuses will change to Up to date.\nIf the update fails, click Details to view the issue details and decide how to proceed. You can cancel the update, solve the issues, and retry updating without downtime. Alternatively, you can force the update without putting the nodes into maintenance. However, this will cause a downtime of workloads running on them.\nIf canceling or forcing the update fails as well, you can reset the update state and discard the downloaded packages by using the vinfra software-updates reset command. Once the update state is reset, you can start the update anew.\n",
                "title": "To update cluster components"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/installing-updates.html"
    },
    {
        "title": "Restoring backups",
        "content": "Restoring backupsPOST /v3/{project_id}/backups/{backup_id}/restore\nRestore a backup to a new volume.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/#restore-a-backup\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project.\n\nbackup_id\n\npath\nstring\nThe UUID for a backup.\n\nrestore\n\nbody\nobject\nA restore object.\n\nvolume_type\n\nbody\nstring\nThe name of the storage policy for a new volume.\n\nname (Optional)\nbody\nstring\nThe name of a new volume.\n\nExample# curl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\{\r\n    \"restore\": {\r\n        \"name\": \"newvolume\",\r\n        \"volume_type\": \"default\"\r\n    }\r\n}' https://<node_IP_addr>:8776/v3/3046fb2c2a314a0fbb32607caa1e5277/backups/bcb8fc88-a0ba-4cd0-801a-e9face1eac88/restore\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nrestore\n\nbody\nobject\nA restore object.\n\nbackup_id\n\nbody\nstring\nThe UUID of the backup.\n\nvolume_id\n\nbody\nstring\nThe UUID of the volume.\n\nvolume_name\n\nbody\nstring\nThe volume name.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n413 - Request Entity Too Large\n\nThis operation cannot be completed.\n\nExample{\r\n  \"restore\": {\r\n    \"backup_id\": \"bcb8fc88-a0ba-4cd0-801a-e9face1eac88\",\r\n    \"volume_id\": \"a28b2729-0dda-4441-9e10-39fbc52fa134\",\r\n    \"volume_name\": \"newvolume\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/restoring-backups.html"
    },
    {
        "title": "Viewing backup plan history",
        "content": "Viewing backup plan history\nYou can check the backup plan history by examining the list and details of backup plan executions.\nPrerequisites\n\nA backup plan is created, as described in Creating backup plans.\n\nTo list backup plan executions\nUse the following command:vinfra service compute backup-plan execution list <backup-plan>\n\n<backup-plan>\n\nBackup plan ID or name\n\nFor example, to check how many times the backup plan myplan has been executed, run:# vinfra service compute backup-plan execution list myplan\r\n+----------------------------------+----------------+-------------+-----------+\r\n| id                               | backup_plan_id | project_id  | status    |\r\n+----------------------------------+----------------+-------------+-----------+\r\n| 04f5254703be4cd499d6a34cb3b6c78d | bc9b9edc<\u00e2\u0080\u00a6>    | 70eff985<\u00e2\u0080\u00a6> | completed |\r\n| 9652a1f72598416e98d1f9cfb0643c96 | bc9b9edc<\u00e2\u0080\u00a6>    | 70eff985<\u00e2\u0080\u00a6> | completed |\r\n+----------------------------------+----------------+-------------+-----------+\nTo view the details of a backup plan execution\nUse the following command:vinfra service compute backup-plan execution show <backup-plan> <execution-id>\n\n<backup-plan>\n\nBackup plan ID or name\n<execution-id>\n\nExecution ID\n\nFor example, to check the details of the execution with the ID 04f5254703be4cd499d6a34cb3b6c78d of the backup plan myplan, run:# vinfra service compute backup-plan execution show myplan 04f5254703be4cd499d6a34cb3b6c78d\r\n+----------------+----------------------------------+\r\n| Field          | Value                            |\r\n+----------------+----------------------------------+\r\n| backup_plan_id | bc9b9edc5ae346e1b49614a9cb0c3cdb |\r\n| created_at     | 2024-03-13T15:30:27.473014       |\r\n| id             | 04f5254703be4cd499d6a34cb3b6c78d |\r\n| metadata       |                                  |\r\n| project_id     | 70eff98528054d0b95a8936bfa4aa2a3 |\r\n| status         | completed                        |\r\n| updated_at     | 2024-03-13T15:32:49.648791       |\r\n+----------------+----------------------------------+\nSee also\n\nManaging volumes in backup plans\n\nEditing and deleting backup plans\n\nRestoring volumes from backups\n\nRestoring virtual machines from backups\n\nCreating and deleting backups manually",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-backup-plan-history.html"
    },
    {
        "title": "Managing the compute storage",
        "content": "Managing the compute storage\nIn Virtuozzo Hybrid Infrastructure, the compute storage comprises volumes provisioned to virtual machines. The provisioned storage space can exceed available physical space. Rules for storing volumes can be set via storage policies. Storage policies also allow you to set different performance levels and redundancy modes for VM volumes.\nPrerequisites\n\nThe compute cluster is created, as described in Creating the compute cluster.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-the-compute-storage.html"
    },
    {
        "title": "About block storage",
        "content": "About block storage\nVirtuozzo Hybrid Infrastructure can be used as a block storage backend over iSCSI. Block storage is optimized for data that must be frequently accessed and edited. It is ideal for hot data and virtual machines.\nBlock storage enables managing data as blocks, as opposed to files in file systems or objects in S3 storage. Those blocks can be stored in different operating systems in a SAN-like manner.\nVirtuozzo Hybrid Infrastructure allows you to create groups of redundant targets running on different storage nodes. To each target group, you can attach multiple storage volumes with their own redundancy provided by the storage layer. Targets export these volumes as LUNs.\nYou can create multiple target groups on same nodes. A volume, however, may only be attached to one target group at any moment in time.\nEach node in a target group can host a single target for that group. If one of the nodes in a target group fails along with its targets, healthy targets from the same group continue to provide access to the LUNs previously serviced by the failed targets.\nYou can configure access to the target group by using CHAP or ACL. \nSample block storage\nThe figure below shows a typical setup for exporting Virtuozzo Hybrid Infrastructure disk space via iSCSI.\n\nThe figure shows two volumes located on redundant storage provided by Virtuozzo Hybrid Infrastructure. The volumes are attached as LUNs to a group of two targets running on Virtuozzo Hybrid Infrastructure nodes. Each target has two portals, one per network interface, with the iSCSI traffic type. This makes a total of four discoverable endpoints with different IP addresses. Each target provides access to all LUNs attached to the group.\nTargets work in the ALUA mode, so one path to the volume is preferred and considered Active/Optimized while the other is Standby. The Active/Optimized path is normally chosen by the initiator (Explicit ALUA). If the initiator cannot do so (either does not support it or times out), the path is chosen by the storage itself (Implicit ALUA).\nNetwork interfaces eth0 and eth1 on each node are connected to different switches for redundancy. The initiator, for example, VMware ESXi, is connected to both switches as well and provides volumes as iSCSI disks 1 and 2 to a VM via different network paths.\nIf the Active/Optimized path becomes unavailable for some reason (for example, the node with the target or network switch fails), the Standby path through the other target will be used instead to connect to the volume. When the Active/Optimized path is restored, it will be used again.\nSee also\n\nProvisioning block storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/about-block-storage.html"
    },
    {
        "title": "Storage policies",
        "content": "Storage policies\nIn Virtuozzo Hybrid Infrastructure, the common unit of data is a volume. When you create a volume, you need to define its redundancy mode, tier, and failure domain. These parameters make up a storage policy defining how redundant a volume must be and where it needs to be located.\nTo better understand a storage policy, let\u00e2\u0080\u0099s have a look at its main components (tiers, failure domains, and redundancy), for a sample scenario. For example, you have three nodes with a number of storage nodes: fast SSDs and high-capacity HDDs. Node 1 has only SSDs; nodes 2 and 3 have both SSDs and HDDs. You want to export storage space via iSCSI and S3, so you need to define a suitable storage policy for each workload.\n\nThe first parameter, tier, defines a group of disks united by criteria (drive type, as a rule) tailored to a specific storage workload. For this sample scenario, you can group your SSD drives into tier 2, and HDD drives into tier 3. You can assign a disk to a tier when creating a storage cluster or adding nodes to it. Note that only nodes 2 and 3 have HDDs and will be used for tier 3. The first node\u00e2\u0080\u0099s SSDs cannot be used for tier 3.\nThe second parameter, failure domain, defines a scope within which a set of storage services can fail in a correlated manner. The default failure domain is host. Each data chunk is copied to different storage nodes, just one copy per node. If a node fails, the data is still accessible from the healthy nodes. A disk can also be a failure domain, though it is only relevant for one-node clusters. As you have three nodes in this scenario, we recommend choosing the host failure domain.\nThe third parameter, redundancy, should be configured to fit the available disks and tiers. In our example, you have three nodes: all of them have SSDs on tier 2. So, if you select tier 2 in your storage policy, you can use the three nodes for 1, 2, or 3 replicas. But only two of your nodes have HDDs on tier 3. So, if you select tier 3 in your storage policy, you can only store 1 or 2 replicas on the two nodes. In both cases, you can also use encoding, but in this scenario, let\u00e2\u0080\u0099s stick to replication: 3 replicas for SSDs and 2 replicas for HDDs.\n\nTo sum it up, the resulting storage policies are:\n\nSee also\n\nData redundancy\n\nFailure domains\n\nStorage tiers\n\n\u00d0\u00a1luster rebuilding",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/storage-policies.html"
    },
    {
        "title": "Creating S3 accounts via REST API",
        "content": "Creating S3 accounts via REST API\nYou can create an account for an S3 user by sending a PUT request to the ostor-accounts service along with the user email address and an account name:# s3_curl POST \"http://s3.example.com/?ostor-accounts&emailAddress=user@email.com&accountName=account\"\r\n{\r\n    \"Name\": \"account\",\r\n    \"AWSAccessKeys\": [\r\n        {\r\n            \"AWSAccessKeyId\": \"bc6265392b818465V8NZ\",\r\n            \"AWSSecretAccessKey\": \"KcPbLkqOrbtLXCn3UgqAz3CEurRXtikrT9ZeDVFa\"\r\n        }\r\n    ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/creating-s3-accounts-via-rest-api.html"
    },
    {
        "title": "Listing volumes",
        "content": "Listing volumesGET /v3/{project_id}/volumes\r\n\nList summary information for all block storage volumes that the\r\nproject can access.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=list-accessible-volumes-detail#list-accessible-volumes\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\ncreated_at (Optional)\nquery\nstring\n\nFilters results by a time that resources are created at with time\r\ncomparison operators: gt, gte, eq, neq, lt, lte.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nNew in version 3.60\n\nupdated_at (Optional)\nquery\nstring\n\nFilters results by a time that resources are updated at with time\r\ncomparison operators: gt, gte, eq, neq, lt, lte.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\nNew in version 3.60\n\nall_tenants (Optional)\nquery\nstring\nShows details for all projects. Admin only.\n\nsort (Optional)\nquery\nstring\nComma-separated list of sort keys and optional\r\nsort directions in the form of <key>[:<direction>]. A valid\r\ndirection is asc (ascending) or desc (descending).\n\nlimit (Optional)\nquery\ninteger\nRequests a page size of items. Returns a number\r\nof items up to a limit value. Use the limit parameter to make\r\nan initial limited request and use the ID of the last-seen item\r\nfrom the response as the marker parameter value in a\r\nsubsequent limited request.\n\noffset (Optional)\nquery\ninteger\nUsed in conjunction with limit to return a slice of items. offset\r\nis where to start in the list.\n\nmarker (Optional)\nquery\nstring\nThe ID of the last-seen item. Use the limit\r\nparameter to make an initial limited request and use the ID of the\r\nlast-seen item from the response as the marker parameter value\r\nin a subsequent limited request.\n\nwith_count (Optional)\nquery\nboolean\n\nWhether to show count in API response or not, default is false.\nNew in version 3.45\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nvolumes\n\nbody\narray\nA list of volume objects.\n\nid\n\nbody\nstring\nThe UUID of the volume.\n\nlinks\n\nbody\narray\nThe volume links.\n\nname\n\nbody\nstring\nThe volume name.\n\nvolumes_links (Optional)\nbody\narray\nThe volume links.\n\ncount (Optional)\nbody\ninteger\n\nThe total count of requested resource before pagination is applied.\nNew in version 3.45\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\nExample{\r\n  \"volumes\": [\r\n    {\r\n      \"id\": \"cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n      \"links\": [\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n          \"rel\": \"self\"\r\n        },\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8776/f5d834d636c642c7bfe8af86139c6f26/volumes/cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n          \"rel\": \"bookmark\"\r\n        }\r\n      ],\r\n      \"name\": \"vol1\"\r\n    },\r\n    {\r\n      \"id\": \"76736e1a-ad97-4599-8ca8-476650459310\",\r\n      \"links\": [\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/76736e1a-ad97-4599-8ca8-476650459310\",\r\n          \"rel\": \"self\"\r\n        },\r\n        {\r\n          \"href\": \"https://<node_IP_addr>:8776/f5d834d636c642c7bfe8af86139c6f26/volumes/76736e1a-ad97-4599-8ca8-476650459310\",\r\n          \"rel\": \"bookmark\"\r\n        }\r\n      ],\r\n      \"name\": \"vm1/cirros/Boot volume\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-volumes.html"
    },
    {
        "title": "Adding, deleting, and listing S3 buckets",
        "content": "Adding, deleting, and listing S3 buckets\nOn the Buckets screen:\n\nTo add a new bucket, click Add bucket, specify a name, and click Add.\n\nUse bucket names that comply with DNS naming conventions. For more information on bucket naming, refer to S3 bucket and key naming policies.\n\nTo delete a bucket, select it, and then click Delete.\nTo list the bucket contents, click the bucket name on the list.\n\nListing S3 bucket contents in a browser\nYou can list bucket contents with a web browser. To do this, visit the URL that consists of the external DNS name for the S3 endpoint that you specified when creating the S3 cluster and the bucket name. For example, s3.example.com/mybucket.\n\nYou can also copy the link to bucket contents by right-clicking it in CyberDuck, and then selecting Copy URL.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/adding-deleting-and-listing-s3-buckets.html"
    },
    {
        "title": "Managing virtual machines",
        "content": "Managing virtual machines\nEach virtual machine (VM) is an independent system with an independent set of virtual hardware. Its main features are the following:\n\nA virtual machine resembles and works like a regular computer. It has its own virtual hardware. Software applications can run in virtual machines without any modifications or adjustment.\nVirtual machine configuration can be changed easily, for example, by adding new virtual disks or memory.\nAlthough virtual machines share physical hardware resources, they are fully isolated from each other (file system, processes, sysctl variables) and the compute node.\nA virtual machine can run any supported guest operating system.\n\nThe following table lists the current virtual machine configuration limits:\n\nResource\nLimit\n\nRAM\n1 TiB\n\nCPU\n64 virtual CPUs\n\nStorage\n15 volumes, 512 TiB each\n\nNetwork\n15 NICs",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-virtual-machines.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Self-Service Guide\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nSelf-Service Guide\n\nHome\n\nContents\n\nIndex\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureSelf-Service Guide\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/index.html"
    },
    {
        "title": "Setting a password inside virtual machines",
        "content": "Setting a password inside virtual machines\nInstead of an SSH key, you can use a password of the default administrator, to access a virtual machine created from a template.\nSetting a password inside virtual machines is supported for both Linux and Windows guest operating systems.\n\nIf you do not have this functionality available for a virtual machine, contact your system administrator.\n\nTo set a password inside a virtual machine\n\nOn the Virtual machines screen, click the required VM.\nOn the VM right pane, click Set password.\n\nIn the Set password window, specify a password for the default administrator login. The password must meet the following complexity requirements:\n\nIt must be at least 12 characters long.\n\nIt must contain characters from all of the following categories:\n\nUppercase Latin letters\nLowercase Latin letters\nBase 10 digits (0 through 9)\nNon-alphanumeric characters (special characters)\n\nAlternatively, click Generate to automatically generate a random password and copy it to the clipboard.\n\nSave this password. After closing this window, the password will be hidden and unavailable for recovery.\n\nClick Set to set the specified password for the default administrator account inside the VM.\n\nOnce the password is injected inside the virtual machine, you can use it to log in to the guest operating system with the default admin login. The Default admin login is displayed on the VM right pane in the VM properties.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/setting-password-inside-vms.html"
    },
    {
        "title": "Statically provisioning persistent volumes",
        "content": "Statically provisioning persistent volumes\nYou can mount existing compute volumes to pods using static provisioning of persistent volumes.\nTo mount a compute volume\n\nIn the self-service panel, obtain the ID of the desired volume.\n\n\r\n                    Access the Kubernetes cluster via the dashboard. Click Kubernetes access for instructions.\r\n                \n\r\n                   On the Kubernetes dashboard, create a storage class, as described in Creating storage classes.\r\n                \n\nCreate a persistent volume. To do it, click + Create and specify the following YAML file:apiVersion: v1\r\nkind: PersistentVolume\r\nmetadata:\r\n  annotations:\r\n    pv.kubernetes.io/provisioned-by: cinder.csi.openstack.org\r\n  name: mypv\r\nspec:\r\n  accessModes:\r\n  - ReadWriteOnce\r\n  capacity:\r\n    storage: 10Gi\r\n  csi:\r\n    driver: cinder.csi.openstack.org\r\n    fsType: ext4\r\n    volumeHandle: c5850e42-4f9d-42b5-9bee-8809dedae424\r\n  persistentVolumeReclaimPolicy: Delete\r\n  storageClassName: default\nThis manifest specifies the persistent volume mypv from the storage class default that has 10 GiB of storage and access mode that allows it to be mounted in the read/write mode by a single node. The PV mypv uses the compute volume with the ID c5850e42-4f9d-42b5-9bee-8809dedae424 as backing storage.\n\nCreate a persistent volume claim. Before you define the PVC, make sure the PV is created and has the status \u00e2\u0080\u009cAvailable\u00e2\u0080\u009d. The existing PV must meet the claim\u00e2\u0080\u0099s requirements to storage size, access mode and storage class. Click + Create and specify the following YAML file:apiVersion: v1\r\nkind: PersistentVolumeClaim\r\nmetadata:\r\n  name: mypvc\r\nspec:\r\n  accessModes:\r\n  - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 10Gi\r\n  storageClassName: default\nOnce the persistent volume claim mypvc is created, the volume mypv is bound to it.\n\nCreate a pod and specify the PVC as its volume. Use the example from Step 4 in Dynamically provisioning persistent volumes.\nIn the self-service panel, the compute volume will be mounted to the virtual machine running the Kubernetes pod.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/statically-provisioning-persistent-volumes.html"
    },
    {
        "title": "Managing volumes",
        "content": "Managing volumes\nA volume in Virtuozzo Hybrid Infrastructure is a virtual disk drive that can be attached to a virtual machine. The integrity of data in volumes is protected by the redundancy mode specified in the storage policy.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-volumes.html"
    },
    {
        "title": "Listing virtual routers",
        "content": "Listing virtual routersGET /v2.0/routers\r\n\nLists virtual routers that the project who submits the request can access.\nDefault policy settings return only those routers that the project\r\nwho submits the request owns, unless an administrative user submits\r\nthe request.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=list-routers-detail#list-routers\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nid (Optional)\nquery\nstring\nFilter the list result by the ID of the router.\n\ntenant_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\nproject_id (Optional)\nquery\nstring\nFilter the list result by the ID of the project that owns the resource.\n\nname (Optional)\nquery\nstring\nFilter the list result by the human-readable name of the resource.\n\ndescription (Optional)\nquery\nstring\nFilter the list result by the human-readable description of the resource.\n\nadmin_state_up (Optional)\nquery\nboolean\nFilter the list result by the administrative state of the resource,\r\nwhich is up (true) or down (false).\n\nrevision_number (Optional)\nquery\ninteger\nFilter the list result by the revision number of the resource.\n\nsort_dir (Optional)\nquery\nstring\nSort direction. A valid value is asc (ascending) or desc\r\n(descending). You can specify multiple pairs of sort key and\r\nsort direction query parameters.\n\nsort_key (Optional)\nquery\nstring\n\nSorts by a router attribute. You can specify multiple pairs of sort key\r\nand sort direction query parameters. The sort keys are limited to:\n\nadmin_state_up\n\nflavor_id\n\nid\n\nname\n\nstatus\n\ntenant_id\n\nproject_id\n\ntags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be returned.\r\nTags in query must be separated by comma.\n\ntags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be returned.\r\nTags in query must be separated by comma.\n\nnot-tags (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match all tags in this list will be excluded.\r\nTags in query must be separated by comma.\n\nnot-tags-any (Optional)\nquery\nstring\nA list of tags to filter the list result by.\r\nResources that match any tag in this list will be excluded.\r\nTags in query must be separated by comma.\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/routers\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nrouters\n\nbody\narray\nA list of router objects.\n\nid\n\nbody\nstring\nThe ID of the router.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nname\n\nbody\nstring\nHuman-readable name of the resource.\n\ndescription\n\nbody\nstring\nA human-readable description for the resource.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is\r\nup (true) or down (false).\n\nstatus\n\nbody\nstring\nThe router status.\n\nexternal_gateway_info\n\nbody\nobject\nThe external gateway information of the router.\r\nIf the router has an external gateway, this would be a dictionary \r\nof network_id, enable_snat and external_fixed_ips.\r\nOtherwise, this would be null.\n\nnetwork_id\n\nbody\nstring\nNetwork ID which the router gateway is connected to.\n\nenable_snat\n\nbody\nboolean\nEnable Source NAT (SNAT) attribute.\r\ntrue means Network Address Translation (NAT) is enabled\r\nfor traffic generated by subnets attached to the router\r\nwhen the traffic is sent to/received from the external network.\r\nfalse means no NAT is applied for traffic from/to the external network.\r\nIt is available when ext-gw-mode extension is enabled.\n\nexternal_fixed_ips\n\nbody\narray\nIP address(es) of the external gateway of the router.\r\nIt is a list of IP addresses. Each element of the list\r\nis a dictionary of ip_address and subnet_id.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the resource.\n\nroutes\n\nbody\narray\nThe extra routes configuration for L3 router.\r\nA list of dictionaries with destination and nexthop parameters.\r\nIt is available when extraroute extension is enabled.\n\ndestination\n\nbody\nstring\nThe destination CIDR.\n\nnexthop\n\nbody\nstring\nThe IP address of the next hop for the corresponding destination.\r\nThe next hop IP address must be a part of one of the subnets to\r\nwhich the router interfaces are connected.\n\ndistributed\n\nbody\nboolean\ntrue indicates a distributed router.\r\nIt is available when dvr extension is enabled.\n\nha\n\nbody\nboolean\ntrue indicates a highly-available router.\r\nIt is available when l3-ha extension is enabled.\n\navailability_zone_hints\n\nbody\narray\nThe availability zone candidates for the router.\r\nIt is available when router_availability_zone extension is enabled.\n\navailability_zones\n\nbody\narray\nThe availability zone(s) for the router.\r\nIt is available when router_availability_zone extension is enabled.\n\nservice_type_id\n\nbody\nstring\nThe ID of the service type associated with the router.\n\nflavor_id\n\nbody\nstring\nThe ID of the flavor associated with the router.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ntags\n\nbody\narray\nThe list of tags on the router.\n\nconntrack_helpers\n\nbody\narray\nThe associated conntrack helper resources for the router. If the\r\nrouter has multiple conntrack helper resources, this field has\r\nmultiple entries. Each entry consists of netfilter conntrack helper\r\n(helper), the network protocol (protocol), the network port\r\n(port).\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"routers\": [\r\n    {\r\n      \"status\": \"ACTIVE\",\r\n      \"external_gateway_info\": {\r\n        \"network_id\": \"b4907761-8c0f-447e-9cfe-c688ca6e44a0\",\r\n        \"enable_snat\": true,\r\n        \"external_fixed_ips\": [\r\n          {\r\n            \"subnet_id\": \"351884c7-ee37-4a7d-9dcb-4cff4a1bba27\",\r\n            \"ip_address\": \"10.94.139.172\"\r\n          }\r\n        ]\r\n      },\r\n      \"availability_zone_hints\": [],\r\n      \"availability_zones\": [\r\n        \"nova\"\r\n      ],\r\n      \"description\": \"\",\r\n      \"tags\": [],\r\n      \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"created_at\": \"2020-03-04T15:22:40Z\",\r\n      \"admin_state_up\": true,\r\n      \"distributed\": false,\r\n      \"updated_at\": \"2020-03-04T15:22:44Z\",\r\n      \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n      \"flavor_id\": null,\r\n      \"revision_number\": 4,\r\n      \"routes\": [],\r\n      \"ha\": false,\r\n      \"id\": \"ce996632-45a2-4c6b-a951-a624eba74621\",\r\n      \"name\": \"router1\"\r\n    }\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-virtual-routers.html"
    },
    {
        "title": "Viewing resources, metrics, and measures",
        "content": "Viewing resources, metrics, and measures\nAfter connecting to the OpenStack command-line interface, you can get access to your compute resource metrics by using the Gnocchi command-line tool. You can see the full list of gnocchi commands in the Gnocchi documentation.\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo view existing resources\nUse the gnocchi resource list command. For example:# gnocchi --insecure resource list -c id -c type -c project_id\r\n+---------------+----------------------------+------------+\r\n| id            | type                       | project_id |\r\n+---------------+----------------------------+------------+\r\n| 238597c7<...> | volume                     | c1bf1<...> |\r\n| 3c78558f<...> | instance                   | c1bf1<...> |\r\n| 44f1896f<...> | instance_network_interface | c1bf1<...> |\r\n| 880e9efc<...> | instance_disk              | c1bf1<...> |\r\n+---------------+----------------------------+------------+\r\n\nThe output shows that the compute cluster hosts one virtual machine with one NIC and one disk that is also present as a volume.\nTo view available metrics for resources\nUse the gnocchi metric list command. For example:# gnocchi --insecure metric list\r\n+-------------+-------+-------------------------------+---------+-------------+\r\n| id          | <...> | name                          | unit    | resource_id |\r\n+-------------+-------+-------------------------------+---------+-------------+\r\n| 243c7a<...> | <...> | disk.root.size                | GB      | 3c7855<...> |\r\n| 365e45<...> | <...> | network.outgoing.packets      | packet  | 44f189<...> |\r\n| 4fbd3e<...> | <...> | disk.device.read.requests     | request | 880e9e<...> |\r\n| 54519f<...> | <...> | compute.instance.booting.time | sec     | 3c7855<...> |\r\n| 5e1406<...> | <...> | disk.device.write.bytes       | B       | 880e9e<...> |\r\n| 66a96c<...> | <...> | vcpus                         | vcpu    | 3c7855<...> |\r\n| 722ea9<...> | <...> | memory                        | MB      | 3c7855<...> |\r\n| 7c961a<...> | <...> | disk.device.write.requests    | request | 880e9e<...> |\r\n| 87e9fb<...> | <...> | network.incoming.packets      | packet  | 44f189<...> |\r\n| 9d5632<...> | <...> | disk.device.read.bytes        | B       | 880e9e<...> |\r\n| b8be8f<...> | <...> | cpu                           | ns      | 3c7855<...> |\r\n| c1961b<...> | <...> | disk.ephemeral.size           | GB      | 3c7855<...> |\r\n| c9b61e<...> | <...> | volume.size                   | GB      | 238597<...> |\r\n| d06a58<...> | <...> | network.outgoing.bytes        | B       | 44f189<...> |\r\n| e2d998<...> | <...> | network.incoming.bytes        | B       | 44f189<...> |\r\n| eaac2b<...> | <...> | memory.usage                  | MB      | 3c7855<...> |\r\n+-------------+-------+-------------------------------+---------+-------------+\r\n\nTo view measures for a metric\nUse the gnocchi measures show command. For example:# gnocchi --insecure measures show cpu --resource-id 3c78558f-08bf-47e2-ba3e-bdb13e7b25bb\r\n+---------------------------+-------------+-------------+\r\n| timestamp                 | granularity |       value |\r\n+---------------------------+-------------+-------------+\r\n| 2019-12-11T17:05:00+03:00 |       300.0 |  2.2756e+11 |\r\n| 2019-12-11T17:10:00+03:00 |       300.0 |  2.8897e+11 |\r\n| 2019-12-11T17:15:00+03:00 |       300.0 |  3.7367e+11 |\r\n| 2019-12-11T17:20:00+03:00 |       300.0 |    4.64e+11 |\r\n| 2019-12-11T17:25:00+03:00 |       300.0 |  7.6104e+11 |\r\n+---------------------------+-------------+-------------+\r\n\nBy default, the mean aggregation method is used. To obtain how much CPU time is consumed per interval, use the --aggregation rate:mean option:# gnocchi --insecure measures show cpu --aggregation rate:mean \\\r\n--resource-id 3c78558f-08bf-47e2-ba3e-bdb13e7b25bb\r\n+---------------------------+-------------+---------------+\r\n| timestamp                 | granularity |         value |\r\n+---------------------------+-------------+---------------+\r\n| 2019-12-11T17:10:00+03:00 |       300.0 | 61410000000.0 |\r\n| 2019-12-11T17:15:00+03:00 |       300.0 | 84700000000.0 |\r\n| 2019-12-11T17:20:00+03:00 |       300.0 | 90330000000.0 |\r\n| 2019-12-11T17:25:00+03:00 |       300.0 |    2.9704e+11 |\r\n| 2019-12-11T17:30:00+03:00 |       300.0 |      3.64e+11 |\r\n+---------------------------+-------------+---------------+\r\n\nSee also\n\nChanging retention period for metrics\n\nViewing outgoing traffic usage\n\nViewing resource usage per project",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-resources-metrics-and-measures.html"
    },
    {
        "title": "Managing S3 accounts via REST API",
        "content": "Managing S3 accounts via REST API\nThis section describes how to manage S3 accounts via the REST API in a service provider scenario. An S3 account is a container for S3 user with additional credentials. An account is owned by a single user while a user can have multiple accounts.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-accounts-via-rest-api.html"
    },
    {
        "title": "Updating snapshots",
        "content": "Updating snapshotsPUT /v3/{project_id}/snapshots/{snapshot_id}\r\n\nUpdate a snapshot.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=update-a-snapshot-detail#update-a-snapshot\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nsnapshot_id\n\npath\nstring\nThe UUID of the snapshot.\n\nsnapshot\n\nbody\nobject\nA snapshot object.\n\nname\n\nbody\nstring\nThe name of the snapshot.\n\ndescription (Optional)\nbody\nstring\nA description for the snapshot. Default is\r\nNone.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"snapshot\": {\r\n    \"name\": \"snapshot2\",\r\n    \"description\": \"New description\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/snapshots/aebe052f-6c13-417a-8ea9-771f40d6667f\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nsnapshot\n\nbody\nobject\nA snapshot object.\n\nuser_id\n\nbody\nstring\n\nThe UUID of the user.\nNew in version 3.41\n\nvolume_id\n\nbody\nstring\nIf the snapshot was created from a volume, the\r\nvolume ID.\n\nname\n\nbody\nstring\nThe name of the snapshot.\n\nstatus\n\nbody\nstring\nThe status for the snapshot.\n\ndescription\n\nbody\nstring\nA description for the snapshot.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nmetadata\n\nbody\nobject\nOne or more metadata key and value pairs for the\r\nsnapshot, if any.\n\nid\n\nbody\nstring\nThe snapshot UUID.\n\nsize\n\nbody\ninteger\nThe size of the volume, in gibibytes (GiB).\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nExample{\r\n  \"snapshot\": {\r\n    \"status\": \"available\",\r\n    \"size\": 2,\r\n    \"metadata\": {},\r\n    \"name\": \"snapshot2\",\r\n    \"volume_id\": \"cb623b3c-f14a-48d6-a339-d9fda95be662\",\r\n    \"created_at\": \"2020-03-11T14:01:54.381048\",\r\n    \"description\": \"New description\",\r\n    \"id\": \"aebe052f-6c13-417a-8ea9-771f40d6667f\",\r\n    \"updated_at\": \"2020-03-11T14:01:56.522040\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-snapshots.html"
    },
    {
        "title": "Managing buckets",
        "content": "Managing buckets\nAfter enabling access to the S3 storage, you can start creating buckets and uploading data in them. In an Amazon S3-like storage, a bucket is a uniquely named container for files, known as objects . Buckets are used to group and isolate objects from those in other buckets.\nIt is recommended to use bucket names that comply with DNS naming conventions:\n\nMust be from 3 to 63 characters long\n\nMust start and end with a lowercase letter or number\n\nCan contain lowercase letters, numbers, periods (.), hyphens (-), and underscores (_)\n\nCan be a series of valid name parts  separated by periods\n\nLimitations\n\nYou can only delete an empty bucket.\n\nPrerequisites\n\nAccess to the S3 storage is enabled, as described in Enabling access to S3 storage.\n\nTo create a bucket\n\nGo to the S3 > Buckets screen, and click Create bucket.\nIn the Create bucket window, specify a name for the bucket, and then click Create.\n\nTo list the bucket contents\nGo to the S3 > Buckets screen, and click the bucket name to open the list of its contents.\nTo delete a bucket\n\nGo to the S3 > Buckets screen, and click the required bucket.\nOn the bucket right pane, click Delete.\nIn the conformation window, click Delete.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-buckets.html"
    },
    {
        "title": "9. Configuring Leostream Connection Broker\u00c2\u00b6",
        "content": "9. Configuring Leostream Connection Broker | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n9. Configuring Leostream Connection Broker\u00c2\u00b6\n\nIn this chapter:\n\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/configuring-broker/index.html"
    },
    {
        "title": "Disk-related metrics in Prometheus",
        "content": "Disk-related metrics in Prometheus\nThe Prometheus service stores the following disk-related metrics:\n\nCS-related metrics\n\ncsd_io_op_time_seconds\n\nMean time per I/O request\r\n\n\nmaster:mdsd_cs_status\n\nCS status on master MDS\r\n\n\nDisk-related metrics in /proc/diskstats\n\nnode_disk_read_time_seconds\n\nTotal time, in seconds, spent on read requests\n\nnode_disk_reads_completed\n\nTotal number of completed read requests\r\n\n\nnode_disk_write_time_seconds\n\nTotal time, in seconds, spent on write requests\n\nnode_disk_writes_completed\n\nTotal number of completed write requests\n\nS.M.A.R.T. metrics\n\nsmart_device_smart_healthy\n\nS.M.A.R.T. status is healthy\n\nsmart_reallocated_sector_ct\n\nTotal number of reallocated disk sectors (05)\n\nsmart_reported_uncorrect\n\nTotal number of errors that could not be recovered using hardware ECC (187)\n\nsmart_command_timeout\n\nTotal number of aborted operations due to a timeout (188)\n\nsmart_current_pending_sector\n\nTotal number of unstable sectors (197)\n\nsmart_offline_uncorrectable\n\nTotal number of uncorrectable errors when reading/writing a sector (198)\n\nsmart_media_wearout_indicator\n\nMedia Wearout Indicator for SSD (233)\n\nsmart_nvme_intel_wear_leveling\n\nMedia Wearout Indicator for Intel NVME (233)\n\nsmart_scsi_read_errors_uncorrected\n\nTotal number of uncorrectable errors when reading a sector\n\nsmart_scsi_reallocated_sector_ct\n\nTotal number of reallocated disk sectors\n\nsmart_scsi_verify_errors_uncorrected\n\nTotal number of uncorrectable errors when verifying a sector\n\nsmart_scsi_write_errors_uncorrected\n\nTotal number of uncorrectable errors when writing a sector\n\nKernel SCSI errors\n\nkernel_scsi_failures_total\n\nTotal number of SCSI failures reported by the kernel\n\nDisk health metric from vstorage-disks-monitor\n\ndiskmon_cs_disk_health\n\nDisk health reported by the vstorage-disks-monitor service. Possible values are 0.0\u00e2\u0080\u00931.0. The 1.0 value means that the disk is 100% healthy.\n\nSee also\n\nDisk health analyzers",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/disk-related-metrics-in-prometheus.html"
    },
    {
        "title": "Preparing nodes for GPU passthrough",
        "content": "Preparing nodes for GPU passthrough\nFor GPU passthrough, detach the graphics card that you want to attach to VMs from the host, and then enable IOMMU. You can detach multiple graphics cards with the same VID and PID, as well as particular graphics cards by using their PCI addresses.\nIf you have multiple graphics cards detached from the node with pci-helper.py detach but want to use only one of them for GPU passthrough, you need to revert the detachment, and then detach one card with pci-helper.py bind-to-stub. In this case, other graphics cards on the node can be used as vGPUs.\nTo detach multiple graphics cards from a node and enable IOMMU\n\nList all graphics cards on a node and  obtain their VID and PID:# lspci -nnD | grep NVIDIA\r\n0000:01:00.0 3D controller [0302]: NVIDIA Corporation TU104GL [Tesla T4] [10de:1eb8] (rev a1)\r\n0000:81:00.0 3D controller [0302]: NVIDIA Corporation TU104GL [Tesla T4] [10de:1eb8] (rev a1)\n[10de:1eb8] is the VID and PID of the graphics card.\n\nRun the pci-helper.py detach script to detach all graphics cards with the same VID and PID. For NVIDIA graphics cards, additionally blacklist the Nouveau driver. For example:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py detach 10de:1eb8 --blacklist-nouveau\nThe command detaches the graphics cards with the VID and PID 10de:1eb8 from the node and prevents the Nouveau driver from loading.\n\nRun the pci-helper.py enable-iommu script to enable IOMMU on the node:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py enable-iommu\nThe script works for both Intel and AMD processors.\n\nReboot the node to apply the changes:# reboot\n\nYou can check that IOMMU is successfully enabled in the dmesg output:# dmesg | grep -e DMAR -e IOMMU\r\n[    0.000000] DMAR: IOMMU enabled\nTo revert multiple GPU detachment\n\nIn the /etc/default/grub file, locate the GRUB_CMDLINE_LINUX line, and then delete pci-stub.ids=<gpu_vid>:<gpu_pid> rd.driver.blacklist=nouveau nouveau.modeset=0. The resulting file may look as follows:# cat /etc/default/grub | grep CMDLINE\r\nGRUB_CMDLINE_LINUX=\"crashkernel=auto tcache.enabled=0 quiet iommu=pt\"\n\nRegenerate the GRUB configuration file.\n\nOn a BIOS-based system, run:# /usr/sbin/grub2-mkconfig -o /etc/grub2.cfg\n\nOn a UEFI-based system, run:# /usr/sbin/grub2-mkconfig -o /etc/grub2-efi.cfg\n\nDelete the /etc/modprobe.d/blacklist-nouveau.conf file.\n\nRe-create the Linux boot image by running:# dracut -f\n\nReboot the node to apply the changes:# reboot\n\nTo detach a particular graphics card from a node and enable IOMMU\n\nList all graphics cards on a node and  obtain their PCI addresses:# lspci -nnD | grep NVIDIA\r\n0000:01:00.0 3D controller [0302]: NVIDIA Corporation TU104GL [Tesla T4] [10de:1eb8] (rev a1)\r\n0000:81:00.0 3D controller [0302]: NVIDIA Corporation TU104GL [Tesla T4] [10de:1eb8] (rev a1)\n0000:01:00.0 and \r\n0000:81:00.0 are the PCI addresses of the graphics cards.\n\nRun the pci-helper.py bind-to-stub script to assign the pci-stub driver to the GPU at its PCI address. For example:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py bind-to-stub 0000:01:00.0\nThe command detaches the graphics card with PCI address 0000:01:00.0 from the node and prevents the Nouveau driver from loading.\n\nRun the pci-helper.py enable-iommu script to enable IOMMU on the node:# /usr/libexec/vstorage-ui-agent/bin/pci-helper.py enable-iommu\nThe script works for both Intel and AMD processors.\n\nReboot the node to apply the changes:# reboot\n\nYou can check that IOMMU is successfully enabled in the dmesg output:# dmesg | grep -e DMAR -e IOMMU\r\n[    0.000000] DMAR: IOMMU enabled\nWhat's next\n\nEnabling PCI passthrough and vGPU support",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/preparing-nodes-gpu-passthrough.html"
    },
    {
        "title": "Configuring NVMe performance",
        "content": "Configuring NVMe performance\nIn the storage cluster, the performance of any disk is limited by the performance of a chunk service (CS), which is single threaded. To increase the parallelism and throughput of fast disks such as non-volatile memory express (NVMe) devices, you can enable NVMe performance for specific storage tiers. You can benefit from using this feature when running workloads with random writes, such as virtual machines. With NVMe performance enabled, one physical device will be able to run multiple chunk services. Note, however, that the amount of RAM and CPU cores reserved on a node will increase linearly with the number of CSes.\nA storage tier with the disk failure domain cannot have NVMe performance enabled. If you want to use such tiers in your cluster, ensure that they have NVMe performance disabled before assigning storage disks to them.\nThough it is convenient to configure NVMe performance before creating the storage cluster, you can also do this at any time afterwards. However, configuring NVMe performance in the existing cluster requires releasing and reattaching each device in the tier, for the change to take effect.\nLimitations\n\nIt is recommended to enable NVMe performance only for NVMe or SSD devices. Using this feature with other devices will lead to higher resource consumption without actual performance benefits.\nWith NVMe performance enabled, it is recommended to configure redundancy by replication. Using erasure coding in this case will not improve the storage cluster performance.\nYou cannot configure NVMe performance for a storage tier with the failure domain set to \"Disk\".\nUsing multiple chunk services per physical drive is only recommended for NVMe devices above 512 GB in size.\nIn a single-node deployment, using multiple chunk services per physical drive is not supported.\n\nPrerequisites\n\nThe infrastructure nodes are equipped with NVMe or SSD disks.\nWhen increasing the number of chunk services per physical device, ensure that each CS has sufficient space allocated to it, that is, at least 100 GB.\nA clear understanding of the CPU and RAM reservations, which are described in General requirements.\n\nTo enable NVMe performance for a tier\n\nAdmin panel\n\nGo to the Settings > System settings > Storage performance screen.\n\nIn the Custom NVMe performance section, select the desired number of chunk services per physical device for the required storage tier. The maximum number is 4. The recommended number is 2 for NVMe devices and 4 for PMem devices.\n\nClick Save to apply the changes.\nIf you have enabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n\nCommand-line interface\nUse the following command:vinfra cluster settings number-of-cses-per-disk set [--tier0 <number>] [--tier1 <number>] \r\n                                                    [--tier2 <number>] [--tier3 <number>]\n\n--tier0 <number>\n\nSet the number of CSes per disk for tier 0.\n--tier1 <number>\n\nSet the number of CSes per disk for tier 1.\n--tier2 <number>\n\nSet the number of CSes per disk for tier 2.\n--tier3 <number>\n\nSet the number of CSes per disk for tier 3.\n\nFor example, to set 4 CSes per disk for the tier 0 and 4 CSes per disk for the tier 1, run:# vinfra cluster settings number-of-cses-per-disk set --tier0 4 --tier1 4\nYou can check that the setting has been applied by running vinfra cluster settings number-of-cses-per-disk show:# vinfra cluster settings number-of-cses-per-disk show\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| maximal | 10    |\r\n| minimal | 1     |\r\n| tier0   | 4     |\r\n| tier1   | 4     |\r\n| tier2   | 1     |\r\n| tier3   | 1     |\r\n+---------+-------+\nIf you have enabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n\nTo disable NVMe performance for a tier\n\nAdmin panel\n\nGo to the Settings > System settings > Storage performance screen.\nSelect 1 as the number of chunk services per physical device for the required storage tier.\nClick Save to apply the changes.\nIf you have disabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n\nCommand-line interface\nUse the following command:vinfra cluster settings number-of-cses-per-disk set [--tier0 <number>] [--tier1 <number>] \r\n                                                    [--tier2 <number>] [--tier3 <number>]\n\n--tier0 <number>\n\nSet the number of CSes per disk for tier 0.\n--tier1 <number>\n\nSet the number of CSes per disk for tier 1.\n--tier2 <number>\n\nSet the number of CSes per disk for tier 2.\n--tier3 <number>\n\nSet the number of CSes per disk for tier 3.\n\nFor example, to disable NVMe performance for the tier 1, run:# vinfra cluster settings number-of-cses-per-disk set --tier1 1\nYou can check that the setting has been applied by running vinfra cluster settings number-of-cses-per-disk show:# vinfra cluster settings number-of-cses-per-disk show\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| maximal | 10    |\r\n| minimal | 1     |\r\n| tier0   | 4     |\r\n| tier1   | 1     |\r\n| tier2   | 1     |\r\n| tier3   | 1     |\r\n+---------+-------+\nIf you have disabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n\nSee also\n\nReleasing node disks\n\nWhat's next\n\nConfiguring node locations",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings number-of-cses-per-disk set [--tier0 <number>] [--tier1 <number>] \r\n                                                    [--tier2 <number>] [--tier3 <number>]\n\n--tier0 <number>\n\nSet the number of CSes per disk for tier 0.\n--tier1 <number>\n\nSet the number of CSes per disk for tier 1.\n--tier2 <number>\n\nSet the number of CSes per disk for tier 2.\n--tier3 <number>\n\nSet the number of CSes per disk for tier 3.\n\nFor example, to set 4 CSes per disk for the tier 0 and 4 CSes per disk for the tier 1, run:# vinfra cluster settings number-of-cses-per-disk set --tier0 4 --tier1 4\nYou can check that the setting has been applied by running vinfra cluster settings number-of-cses-per-disk show:# vinfra cluster settings number-of-cses-per-disk show\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| maximal | 10    |\r\n| minimal | 1     |\r\n| tier0   | 4     |\r\n| tier1   | 4     |\r\n| tier2   | 1     |\r\n| tier3   | 1     |\r\n+---------+-------+\nIf you have enabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n",
                "title": "To enable NVMe performance for a tier"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings number-of-cses-per-disk set [--tier0 <number>] [--tier1 <number>] \r\n                                                    [--tier2 <number>] [--tier3 <number>]\n\n--tier0 <number>\n\nSet the number of CSes per disk for tier 0.\n--tier1 <number>\n\nSet the number of CSes per disk for tier 1.\n--tier2 <number>\n\nSet the number of CSes per disk for tier 2.\n--tier3 <number>\n\nSet the number of CSes per disk for tier 3.\n\nFor example, to disable NVMe performance for the tier 1, run:# vinfra cluster settings number-of-cses-per-disk set --tier1 1\nYou can check that the setting has been applied by running vinfra cluster settings number-of-cses-per-disk show:# vinfra cluster settings number-of-cses-per-disk show\r\n+---------+-------+\r\n| Field   | Value |\r\n+---------+-------+\r\n| maximal | 10    |\r\n| minimal | 1     |\r\n| tier0   | 4     |\r\n| tier1   | 1     |\r\n| tier2   | 1     |\r\n| tier3   | 1     |\r\n+---------+-------+\nIf you have disabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n",
                "title": "To disable NVMe performance for a tier"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Settings > System settings > Storage performance screen.\n\nIn the Custom NVMe performance section, select the desired number of chunk services per physical device for the required storage tier. The maximum number is 4. The recommended number is 2 for NVMe devices and 4 for PMem devices.\n\n\n\n\n\nClick Save to apply the changes.\nIf you have enabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n\n",
                "title": "To enable NVMe performance for a tier"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Settings > System settings > Storage performance screen.\nSelect 1 as the number of chunk services per physical device for the required storage tier.\nClick Save to apply the changes.\nIf you have disabled NVMe performance after creating the storage cluster, release and reattach each NVMe disk in the affected storage tiers.\n\n",
                "title": "To disable NVMe performance for a tier"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-nvme-performance.html"
    },
    {
        "title": "3.2. Activating Module WHMCS\u00c2\u00b6",
        "content": "3.2. Activating Module WHMCS | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nPrev\nNext\n\n3.2. Activating Module WHMCS\u00c2\u00b6\n\nOnce the module has been downloaded unzip the module to your \u00e2\u0080\u009c/{user}/modules/\u00e2\u0080\u009d directory:\n# unzip BitNinja_plugin_for_whmcs.zip\n\n\nThis will unzip all the contents to \u00e2\u0080\u009c/{user}/modules/servers/bitninja\u00e2\u0080\u009d.\nCopy the contents from the previous directory to your content directory, e.g.:\n# cp -r /{user}/modules/servers/bitninja/  /var/www/html/modules/servers/bitninja\n\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/whmcs-bitninja/activating-module.html"
    },
    {
        "title": "Creating backup plans",
        "content": "Creating backup plans\nYou can schedule an automatic backup job for multiple volumes by creating a backup plan. A backup plan defines the backup schedule and retention policy that are applied to all backups created by this plan.\nTo create a backup plan\n\nOn the Backup plans screen, click Create backup plan.\n\nIn the Create backup plan window, specify a name for the backup plan and, optionally, a description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nIn What to back up, click Manage. In the Manage volumes window, select compute volumes that will be included in the backup plan, and then click Save.\n\nIn Schedule, select the schedule for the backup plan:\n\nSelect Retention 7 days to create a backup of the selected volumes every day and keep each backup for seven days.\nSelect Retention 14 days to create a backup of the selected volumes every day and keep each backup for 14 days.\nSelect Custom to configure a custom schedule for the automatic backup. You can choose months, days of the week, days of the month, time, and the maximum number of recovery points to keep.\n\nClick Create.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-backup-plans.html"
    },
    {
        "title": "Revoking S3 account access key pairs via CLI",
        "content": "Revoking S3 account access key pairs via CLI\nYou can revoke the specified access key pair for the specified account of an S3 user with the ostor-s3-admin revoke-access-key command. You need to specify the access key in the key pair you want to delete, as well as  the user email (-e) or S3 ID (-i). For example:# ostor-s3-admin revoke-access-key -e user@email.com -k de86d1c19e616455YIPU -V 0100000000000002",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/revoking-s3-account-access-key-pairs-via-cli.html"
    },
    {
        "title": "GET service ostor-settings",
        "content": "GET service ostor-settings\nDescription\nLists existing object storage settings.\nRequests\nSyntaxGET /?ostor-settings HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\nEmpty.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nA JSON dictionary with a list of settings in the following format:{\r\n  \"OS.max_count\": <value>,\r\n  \"OS.max_size\": <value>,\r\n  \"cfg.autosplit.enabled\": <value>,\r\n  \"cfg.autosplit.max_active\": <value>,\r\n  \"ostor.default_cors.enabled\": <value>\r\n}\nExamples\nSample request\nThe following request returns information about all object storage settings.GET /?ostor-settings /HTTP1.1\r\nDate : Mon, 14 Nov 2023 14:39:21 GMT+3:00\r\nHost : s3.example.com\r\nAuthorization : <authorization_string>\nSample responseHTTP/1.1 200 OK\r\nx-amz-req-time-micros : 404\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nx-amz-request-id : 80000000000000030008e3ac6b0bc436\r\nDate : Mon, 14 Nov 2023 14:39:22 GMT\r\nContent-type : application/json\r\n\r\n{\r\n  \"OS.max_count\": 100,\r\n  \"OS.max_size\": 1000,\r\n  \"cfg.autosplit.enabled\": 1,\r\n  \"cfg.autosplit.max_active\": 1,\r\n  \"ostor.default_cors.enabled\": 1\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/get-service-ostor-settings.html"
    },
    {
        "title": "Generating S3 user access key pairs via CLI",
        "content": "Generating S3 user access key pairs via CLI\nYou can generate a new access key pair for the specified user with the ostor-s3-admin gen-access-key command. The maximum of 2 active access key pairs are allowed per user (same as with the Amazon Web Services). You need to specify either the user email (-e) or S3 ID (-i). For example:# ostor-s3-admin gen-access-key -e user@email.com -V 0100000000000002\r\nGenerate access key: user id=d866d9d114cc3d20, access key id=d866d9d114cc3d20D8EW,\r\nsecret access key=83tTsNAuuRyoBBqhxMFqHAC60dhKHtTCCkQe54zu\r\n\nIt is recommended to periodically revoke old and generate new access key pairs.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/generating-s3-user-access-key-pairs-via-cli.html"
    },
    {
        "title": "Updating aggregate metadata",
        "content": "Updating aggregate metadataPOST /os-aggregates/{aggregate_id}/action\r\n\nCreates or replaces metadata for an aggregate.\nSpecify the set_metadata action and metadata info in the request body.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=create-or-update-aggregate-metadata-detail#create-or-update-aggregate-metadata\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\naggregate_id\n\npath\ninteger\nThe aggregate ID.\n\nset_metadata\n\nbody\nobject\nThe set_metadata object used to set metadata for host aggregate.\n\nmetadata\n\nbody\nobject\n\nMetadata key and value pairs associated with the aggregate.\r\nThe maximum size for each metadata key and value pair is 255 bytes.\nNew keys will be added to existing aggregate metadata. For existing\r\nkeys, if the value is null the entry is removed, otherwise the\r\nvalue is updated. Note that the special availability_zone metadata\r\nentry cannot be unset to null.\n\nYou should not change the availability zone of an\r\naggregate when that aggregate has hosts which contain servers in it\r\nsince that may impact the ability for those servers to move to another\r\nhost.\n\nExample\nAssociate a trait with a host aggregate:curl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"set_metadata\": {\r\n    \"metadata\": {\r\n      \"trait:CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\": \"required\"\r\n    }\r\n  }\r\n}' https://<node_IP_addr>:8774/v2.1/6ef5371261ea42008e3d1d41ba051977/os-aggregates/4/action\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\naggregate\n\nbody\nobject\nThe host aggregate object.\n\nname\n\nbody\nstring\nThe name of the host aggregate.\n\navailability_zone\n\nbody\nstring\nThe availability zone of the host aggregate.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted_at\n\nbody\nstring\n\nThe date and time when the resource was deleted. If the resource has\r\nnot been deleted yet, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted\n\nbody\nboolean\nA boolean indicates whether this aggregate is deleted or not, if it has\r\nnot been deleted, false will appear.\n\nhosts\n\nbody\narray\nAn array of host information.\n\nid\n\nbody\ninteger\nThe ID of the host aggregate.\n\nmetadata\n\nbody\nobject\nMetadata key and value pairs associated with the aggregate.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nuuid\n\nbody\nstring\n\nThe UUID of the host aggregate.\nNew in version 2.41\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"aggregate\": {\r\n    \"name\": \"CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\",\r\n    \"availability_zone\": null,\r\n    \"deleted\": false,\r\n    \"created_at\": \"2020-04-19T12:56:10.191466\",\r\n    \"updated_at\": null,\r\n    \"deleted_at\": null,\r\n    \"id\": 4,\r\n    \"metadata\": {\r\n      \"trait:CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\": \"required\"\r\n    }\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-aggregate-metadata.html"
    },
    {
        "title": "11.3. Adding Leostream Gateway\u00c2\u00b6",
        "content": "11.3. Adding Leostream Gateway | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n11.3. Adding Leostream Gateway\u00c2\u00b6\nYou add your Leostream Gateway to your Connection Broker, as follows.\n\nGo to Setup > Gateways page.\nClick the Add Gateway link.\nIn the Add Gateway form, enter a name for the Gateway in the Name edit field.\nFor this example, enter the publicly accessible IP address or hostname for your Leostream Gateway. If you are placing the Leostream Gateway behind your corporate firewall, enter the public address of your firewall.\nIn the IP address or FQDN used for Connection Broker communications to this Gateway field, enter the private address of your Leostream Gateway. This address is optional. If provided, the Connection Broker communicates with the Leostream Gateway using a private address. This address is never used for forwarding display protocol traffic.\nIf this gateway is used to forward client-based display-protocol traffic, use the Method for routing display protocol traffic through this Leostream Gateway drop-down menu to indicate which method the gateway uses to configure the firewall rule for routing traffic.\n\nNote that the option you select here has ramifications on the ports you must open in the Security Group assigned to your Leostream Gateway virtual machine. The method for routing display protocol influences which ports should be open on your Leostream Gateway.\n\nClick Save. After saving the form, the Connection Broker registers with the Leostream Gateway and you can now use the gateway in your protocol plans.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-external-systems/adding-leostream-gateway.html"
    },
    {
        "title": "Managing virtual machine power state",
        "content": "Managing virtual machine power state\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo manage the power state of a virtual machine\n\nClick the virtual machine or the ellipsis button next to it to see the full list of actions available for the current state. \n\nTo power up a VM, click Run.\nTo gracefully shut down a running VM, click Shut down. The default shutdown timeout, after which a virtual machine will be powered off, is 10 minutes.\nTo forcibly cut off power from a VM, click Power off.\nTo softly reboot a running VM, click Reboot.\nTo reboot a VM without the guest OS graceful shutdown, click Hard reboot.\nTo save the current VM state to a file, click Suspend. This may prove useful, for example, if you need to restart the host but do not want to quit the applications currently running in the VM or restart its guest OS.\nTo restore a VM from the suspended state, click Resume.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/managing-virtual-machine-power-state.html"
    },
    {
        "title": "POST service ostor-accounts",
        "content": "POST service ostor-accounts\nDescription\nCreates a new account.\r\n\r\n\nRequests\nSyntaxPOST /?ostor-accounts&emailAddress=<value>&accountName=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>POST /?ostor-accounts&id=<value>&accountName=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nPOST service ostor-accounts parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nNo*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nNo*\n\naccountName\n\nAccount name.\n\r\nType: string.\n\r\nDefault value: none.\n\nYes\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nA JSON dictionary with account information in the following format:{\r\n\"Name\" : \"<name>\",\r\n\"AWSAccessKeys : [\r\n{\r\n\"AWSAccessKeyId\" : \"<access_key>\",\r\n\"AWSSecretAccessKey\" : \"<secret_key>\"\r\n}]\r\n}\nExamples\nSample request\nCreates an account with the name account1 for the user with the email user1@email.com.POST /?ostor-accounts&emailAddress=user1@email.com&accountName=account1 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 24 Mar 2021 14:37:10 GMT\r\nAuthorization: <authorization_string>\nSample responseHTTP/1.1 200 OK\r\nServer: nginx\r\nContent-Type: application/json\r\nTransfer-Encoding: chunked\r\nConnection: keep-alive\r\nDate: Wed, 24 Mar 2021 14:37:11 GMT\r\nx-amz-req-time-micros: 32753\r\nx-amz-request-id: 8000000000000016000060d722e695e2\r\n{\r\n  \"Name\": \"account1\",\r\n  \"AWSAccessKeys\": [\r\n    {\r\n      \"AWSAccessKeyId\": \"bc6265392b818465FQYC\",\r\n      \"AWSSecretAccessKey\": \"iWs4rkwHMUYn8K0fPhjjAENC4QYUBIgIyJhNEx4l\"\r\n    }\r\n  ]\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/post-service-ostor-accounts.html"
    },
    {
        "title": "Enabling RDMA",
        "content": "Enabling RDMA\nVirtuozzo Hybrid Infrastructure supports remote direct memory access (RDMA) over InfiniBand (IB) or Converged Ethernet (RoCE) for the storage backend network. The RDMA technology allows servers in this network to exchange data in main memory without involving their processors, cache or operating systems, thus freeing up resources and improving throughput and performance.\nBy default, RDMA is disabled. To configure it automatically, you can enable it in the admin panel or by using the vinfra tool. However, this is only possible before the storage cluster is created. Before enabling the feature, check the RDMA\u00a0network first.\nLimitations\n\nWe recommend using NVIDIA Mellanox ConnectX-5 or ConnectX-6 adapters for the RDMA mode. If you want to use other adapters in the RDMA mode, contact the technical support team for recommendations.\n\nTo be used for the RDMA traffic, a network bond can only be configured across different interfaces of the same NIC.\n\nRDMA is not supported for the compute service. Therefore, the compute and storage networks must be physically separated on different NICs. If you use the recommended approach with bonded network interfaces, you should have one network card with two bonded network interfaces for the storage network and one network card with two bonded network interfaces for the compute network. To learn how to use a compute trunk network, refer to Connecting virtual switches to trunk interfaces.\n\nEnabling or disabling RDMA may temporarily affect cluster availability.\n\nPrerequisites\n\nYour RDMA network infrastructure must be ready before you install Virtuozzo Hybrid Infrastructure.\nEach network adapter connected to a network with the Storage traffic type supports RDMA.\nInfiniBand devices are configured on all of your nodes, as described in Configuring InfiniBand devices.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-rdma.html"
    },
    {
        "title": "Configuring outbound firewall rules",
        "content": "Configuring outbound firewall rules\nTo control outbound traffic from your cluster nodes, you can configure outbound firewall rules for public networks by using the vinfra tool. By default, ports used by system services are opened, to ensure non-disruptive cluster operation. Additionally, outbound traffic is always allowed in the subnet dedicated to internal communication between cluster nodes. As a private network is not publicly exposed and does not communicate with any external endpoints, you do not need to restrict outbound traffic for it. A network is recognized as private if it is assigned any of these traffic types:\n\nOSTOR private\nBackup (ABGW) private\nInternal management\nStorage\n\nA private network always has the rule <private_subnet_cidr>:any:0, which allows all outbound traffic in the current subnet. This rule is not visible via the vinfra commands and exists only in iptables.\nTo block all outbound traffic except that which is necessary for cluster operation, perform the following steps:\n\nCreate additional firewall rules, to allow outbound traffic for particular services.\nRemove the rule that allows all outbound traffic.\nCheck your network settings.\n\nSee also\n\nConfiguring inbound firewall rules\n\nManaging networks\n\nConfiguring data-in-transit encryption\n\nManaging traffic types",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-outbound-firewall-rules.html"
    },
    {
        "title": "Monitoring node network interfaces",
        "content": "Monitoring node network interfaces\nTo check the network interface status\nGo to the Infrastructure > Nodes screen and click the node name. Open the Network interfaces tab to see a list of all network interfaces on the node with their statuses.\nA network interface can have the following statuses:\n\nConnected\n\nThe network adapter is plugged in and up on the node.\nDisconnected\n\nThe network adapter is disconnected.\nDisabled\n\nThe network adapter is down on the node.\nWarning\n\nThe network adapter is not in the full duplex mode, has low speed, or incorrect settings.\n\nTo display network interface details\n\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOpen the Network interfaces tab, click a network interface, and then go to the Overview tab.\n\nNetwork interface details include the interface status, type, assigned network, MTU, MAC, and IP addresses. You can also check the interface speed, as well as transmit (TX) and receive (RX) rates, in packets per second.\n\nCommand-line interface\nUse the following command:vinfra node iface show [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nFor example, to view the details of the network interface bond0.362 on the node node003, run:# vinfra node iface show bond0.362 --node node003\r\n+-----------------------+--------------------------------------+\r\n| Field                 | Value                                |\r\n+-----------------------+--------------------------------------+\r\n| built_on              | bond0                                |\r\n| dhcp4                 |                                      |\r\n| dhcp4_enabled         | False                                |\r\n| dhcp6                 |                                      |\r\n| dhcp6_enabled         | False                                |\r\n| duplex                | full                                 |\r\n| gw4                   |                                      |\r\n| gw6                   |                                      |\r\n| ignore_auto_routes_v4 | True                                 |\r\n| ignore_auto_routes_v6 | True                                 |\r\n| ipv4                  | - 192.168.0.15/24                    |\r\n| ipv6                  | []                                   |\r\n| mac_addr              | 0c:42:a1:0d:f4:ac                    |\r\n| mtu                   | 9000                                 |\r\n| multicast             | True                                 |\r\n| name                  | bond0.362                            |\r\n| network               | e4347c48-2a93-4495-9221-0036d4b7fd2c |\r\n| node_id               | c4d14337-0863-4a67-9dbd-f19c3e49e114 |\r\n| plugged               | True                                 |\r\n| rx_bytes              | 132795090298899                      |\r\n| rx_dropped            | 0                                    |\r\n| rx_errors             | 0                                    |\r\n| rx_overruns           | 0                                    |\r\n| rx_packets            | 11992910723                          |\r\n| speeds                | current: 50000                       |\r\n|                       | max: 50000                           |\r\n| state                 | up                                   |\r\n| tag                   | 362                                  |\r\n| tx_bytes              | 97570120705648                       |\r\n| tx_dropped            | 0                                    |\r\n| tx_errors             | 0                                    |\r\n| tx_overruns           | 0                                    |\r\n| tx_packets            | 10744028252                          |\r\n| type                  | vlan                                 |\r\n+-----------------------+--------------------------------------+\r\n\nIn the command output, network interface details include the interface state, type, assigned network, MTU, MAC and IP addresses, etc. You can also check the interface speed, as well as transmit (TX) and receive (RX) rates, in packets per second.\n\nTo monitor performance  of a network interface\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOpen the Network interfaces tab, click a network interface, and then take a look at the charts on the Monitoring tab.\n\nWhen monitoring network performance, keep in mind that if the Errors charts are not empty, the network is experiencing issues and requires attention. For advanced monitoring, click Grafana dashboard.\nThe default time interval for the charts is twelve hours. To zoom into a particular time interval, select the interval with the mouse; to reset zoom, double-click any chart.\nSee also\n\nMonitoring node performance\n\nMonitoring node disks",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node iface show [--node <node>] <iface>\r\n\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n<iface>\n\nNetwork interface name\n\nFor example, to view the details of the network interface bond0.362 on the node node003, run:# vinfra node iface show bond0.362 --node node003\r\n+-----------------------+--------------------------------------+\r\n| Field                 | Value                                |\r\n+-----------------------+--------------------------------------+\r\n| built_on              | bond0                                |\r\n| dhcp4                 |                                      |\r\n| dhcp4_enabled         | False                                |\r\n| dhcp6                 |                                      |\r\n| dhcp6_enabled         | False                                |\r\n| duplex                | full                                 |\r\n| gw4                   |                                      |\r\n| gw6                   |                                      |\r\n| ignore_auto_routes_v4 | True                                 |\r\n| ignore_auto_routes_v6 | True                                 |\r\n| ipv4                  | - 192.168.0.15/24                    |\r\n| ipv6                  | []                                   |\r\n| mac_addr              | 0c:42:a1:0d:f4:ac                    |\r\n| mtu                   | 9000                                 |\r\n| multicast             | True                                 |\r\n| name                  | bond0.362                            |\r\n| network               | e4347c48-2a93-4495-9221-0036d4b7fd2c |\r\n| node_id               | c4d14337-0863-4a67-9dbd-f19c3e49e114 |\r\n| plugged               | True                                 |\r\n| rx_bytes              | 132795090298899                      |\r\n| rx_dropped            | 0                                    |\r\n| rx_errors             | 0                                    |\r\n| rx_overruns           | 0                                    |\r\n| rx_packets            | 11992910723                          |\r\n| speeds                | current: 50000                       |\r\n|                       | max: 50000                           |\r\n| state                 | up                                   |\r\n| tag                   | 362                                  |\r\n| tx_bytes              | 97570120705648                       |\r\n| tx_dropped            | 0                                    |\r\n| tx_errors             | 0                                    |\r\n| tx_overruns           | 0                                    |\r\n| tx_packets            | 10744028252                          |\r\n| type                  | vlan                                 |\r\n+-----------------------+--------------------------------------+\r\n\nIn the command output, network interface details include the interface state, type, assigned network, MTU, MAC and IP addresses, etc. You can also check the interface speed, as well as transmit (TX) and receive (RX) rates, in packets per second.\n",
                "title": "To display network interface details"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Infrastructure > Nodes screen and click the node name.\nOpen the Network interfaces tab, click a network interface, and then go to the Overview tab.\n\nNetwork interface details include the interface status, type, assigned network, MTU, MAC, and IP addresses. You can also check the interface speed, as well as transmit (TX) and receive (RX) rates, in packets per second.\n",
                "title": "To display network interface details"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-node-network-interfaces.html"
    },
    {
        "title": "Cluster objects and traps",
        "content": "Cluster objects and traps\nCluster-related objects\n\nVSTORAGE-MIB:cluster\n\nGeneral cluster information.\nVSTORAGE-MIB:csStatTable\n\nChunk server statistics table.\nVSTORAGE-MIB:mdsStatTable\n\nMetadata server statistics table.\nVSTORAGE-MIB::clusterName\n\nCluster name.\nVSTORAGE-MIB::healthStatus\n\nCluster health status.\nVSTORAGE-MIB::usedLogicalSpace\n\nThe space occupied by all data chunks and their replicas, plus the space occupied by any other data stored on the cluster nodes\u00e2\u0080\u0099 disks.\nVSTORAGE-MIB::totalLogicalSpace\n\nThe total space on all cluster nodes\u00e2\u0080\u0099 disks.\nVSTORAGE-MIB::freeLogicalSpace\n\nThe unused space on all cluster nodes\u00e2\u0080\u0099 disks.\nVSTORAGE-MIB::licenseStatus\n\nLicense status.\nVSTORAGE-MIB::licenseCapacity\n\nThe maximum disk space available as defined by the license.\nVSTORAGE-MIB::licenseExpirationStatus\n\nLicense expiration status.\nVSTORAGE-MIB::ioReadOpS\n\nCurrent read speed, in operations per second.\nVSTORAGE-MIB::ioWriteOpS\n\nCurrent write speed, in operations per second.\nVSTORAGE-MIB::ioReads\n\nCurrent read speed, in bytes per second.\nVSTORAGE-MIB::ioWrites\n\nCurrent write speed, in bytes per second.\nVSTORAGE-MIB::csActive\n\nThe number of active chunk servers.\nVSTORAGE-MIB::csTotal\n\nThe total number of chunk servers.\nVSTORAGE-MIB::mdsAvail\n\nThe number of running metadata servers.\nVSTORAGE-MIB::mdsTotal\n\nThe total number of metadata servers.\nVSTORAGE-MIB::s3OsAvail\n\nThe number of running S3 object servers.\nVSTORAGE-MIB::s3OsTotal\n\nThe total number of S3 object servers.\nVSTORAGE-MIB::s3NsAvail\n\nThe number of running S3 name servers.\nVSTORAGE-MIB::s3NsTotal\n\nThe total number of S3 name servers.\nVSTORAGE-MIB::s3GwAvail\n\nThe number of running S3 gateways.\nVSTORAGE-MIB::s3GwTotal\n\nThe total number of S3 gateways.\n\nCS-related objects\n\nVSTORAGE-MIB::csId\n\nChunk server identifier.\nVSTORAGE-MIB::csStatus\n\nCurrent chunk server status.\nVSTORAGE-MIB::csIoReadOpS\n\nCurrent read speed of a chunk server, in operations per second.\nVSTORAGE-MIB::csIoWriteOpS\n\nCurrent write speed of a chunk server, in operations per second.\nVSTORAGE-MIB::csIoWait\n\nThe percentage of time spent waiting for I/O operations. Includes time spent waiting for synchronization.\nVSTORAGE-MIB::csIoReadS\n\nCurrent read speed of a chunk server, in bytes per second.\nVSTORAGE-MIB::csIoWriteS\n\nCurrent write speed of a chunk server, in bytes per second.\n\nMDS-related objects\n\nVSTORAGE-MIB::mdsId\n\nMetadata server identifier.\nVSTORAGE-MIB::mdsStatus\n\nCurrent metadata server status.\nVSTORAGE-MIB::mdsMemUsage\n\nThe amount of memory used by a metadata server.\nVSTORAGE-MIB::mdsCpuUsage\n\nThe percentage of the CPU\u00e2\u0080\u0099s capacity used by a metadata server.\nVSTORAGE-MIB::mdsUpTime\n\nTime since the startup of a metadata server.\n\nSNMP traps triggered by the specified alerts\n\nlicense expired\n\nThe license has expired.\nlicense_isnot_loaded\n\nThe license is not loaded.\ntoo few free space\n\nThe cluster is running out of logical space.\ntoo_few_free_phys_space\n\nThe cluster is running out of physical space.\noffline node\n\nA cluster node is offline.\ntoo few nodes\n\nToo few cluster nodes are left.\ntoo few mdses\n\nToo few MDSes are left.\ntoo_much_mdses\n\nMore than one MDS is on a node.\ntoo few cses\n\nToo few CSes are left.\nfailed mds\n\nThe MDS service has failed.\nfailed cs\n\nThe CS service has failed.\ncses_on_single_tier_have_different_journalling_settings\n\nA CS has incorrect journalling settings.\ncses_on_single_tier_have_different_encryption_settings\n\nA CS has incorrect encryption settings.\nsmart_failed\n\nA disk has failed a S.M.A.R.T. check.\ndisk_failed\n\nA disk has failed.\ntoo_few_root_space\n\nThe root partition on a node is out of space.\ntoo_few_space_on_metadata_disk\n\nAn MDS disk is out of space.\nlow_level_network_settings\n\nA network interface is missing important features.\nhalf_duplex\n\nA network interface is not in the full duplex mode.\nlow_speed\n\nA network interface has a speed lower than 1 Gbps.\nundefined_speed\n\nA network interface has an undefined speed.\nnetwork link\n\nA network interface is misconfigured.\nabgw_cert_expired\n\nThe Backup Gateway certificate has expired or will expire soon.\niscsi_redundancy_disk\n\nThe failure domain set for an iSCSI LUN does not make it highly available.\ns3_redundancy_disk\n\nThe failure domain set for an S3 cluster does not make it highly available.\nsoftware_updates\n\nSoftware updates exist for a node.\nno_internet_connection\n\nNo internet connection on a node.\ndisk_write_cache_enabled\n\nDisk write cache is enabled.\ndisk_write_cache_status_unknown\n\nDisk write cache has an unknown status.\ncompute_unavailable\n\nThe compute cluster has failed.\noom_happened\n\nThe OOM killer has been triggered.\nkernel_not_current\n\nThe kernel is outdated on a node.\nno_ha\n\nHigh availability for the admin panel is not configured.\ntime_not_synced\n\nTime is not synced on a node.\niscsi_upgrade_failed\n\niSCSI major upgrade has failed.\nbackend_backup_is_too_old\n\nThe last management node backup has failed, does not exist, or is too old.\n\nother\n\nOther alerts.\n\nSee also\n\nInfrastructure alerts\n\nCore storage alerts\n\nObject storage alerts",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/cluster-objects-and-traps.html"
    },
    {
        "title": "Changing S3 protocol settings",
        "content": "Changing S3 protocol settings\nAfter creating the S3 storage, you can change the protocol settings of the S3 endpoint.\nPrerequisites\n\nS3 clusters are created, as described in Creating the S3 cluster.\n\nTo change S3 protocol settings\n\nAdmin panel\n\n Open the Storage services > S3 > Settings screen, and then click Protocol.\n\nSelect an S3 endpoint protocol: HTTP, HTTPS, or both.\n\nIt is recommended to use only HTTPS for production deployments.\n\nIf you selected the HTTPS protocol, do one of the following: \n\nSelect Upload a certificate, specify the prepared SSL certificate, and then specify the SSL key or passphrase (for PKCS#12 files).\nYou need to acquire a key and a trusted wildcard SSL certificate for endpoint\u00e2\u0080\u0099s bottom-level domain. For example, the endpoint s3storage.example.com would need a wildcard certificate for *.s3storage.example.com with the subject alternative name s3storage.example.com.\nIf you acquired an SSL certificate from an intermediate certificate authority (CA)\n\nYou should have an end-user certificate along with a CA bundle that contains the root and intermediate certificates. To be able to use these certificates, you need to merge them into a chain first. A certificate chain includes the end-user certificate, the certificates of intermediate CAs, and the certificate of a trusted root CA. In this case, an SSL certificate can only be trusted if every certificate in the chain is properly issued and valid.\nFor example, if you have an end-user certificate, two intermediate CA certificates, and a root CA certificate, create a new certificate file and add all certificates to it in the following order:# End-user certificate issued by the intermediate CA 1\r\n-----BEGIN CERTIFICATE-----\r\nMIICiDCCAg2gAwIBAgIQNfwmXNmET8k9Jj1X<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 1 certificate issued by the intermediate CA 2\r\n-----BEGIN CERTIFICATE-----\r\nMIIEIDCCAwigAwIBAgIQNE7VVyDV7exJ9ON9<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 2 certificate issued by the root CA\r\n-----BEGIN CERTIFICATE-----\r\nMIIC8jCCAdqgAwIBAgICZngwDQYJKoZIhvcN<...>\r\n-----END CERTIFICATE-----\r\n# Root CA certificate\r\n-----BEGIN CERTIFICATE-----\r\nMIIDODCCAiCgAwIBAgIGIAYFFnACMA0GCSqG<...>\r\n-----END CERTIFICATE-----\r\n\n\nSelect Generate a certificate, to get a self-signed certificate for HTTPS evaluation purposes.\n\nS3 geo-replication requires a certificate from a trusted authority. It does not work with self-signed certificates.\nTo access the data in the S3 cluster via a browser, add the self-signed certificate to browser\u00e2\u0080\u0099s exceptions.\n\nClick Save to apply your changes.\n\nCommand-line interface\nUse the following command:vinfra service s3 cluster change [--self-signed | --no-ssl | --cert-file <cert_file>]\r\n                                 [--insecure] [--key-file <key_file>] [--password]\n\n--self-signed\n\n        Generate a new self-signed certificate (default)\n--no-ssl\n\nDo not generate a self-signed certificate\n--cert-file <cert_file>\n\nPath to a file with the new certificate\n--insecure\n\nAllow insecure connections in addition to secure ones (only used with the --cert-file and --self-signed options)\n--key-file <key_file>\n\nPath to a file with the private key (only used with the --cert-file option)\n--password\n\nRead certificate password from stdin (only used with the --cert-file option)\n\nFor example,  to use a self-signed certificate for the S3 storage, run:# vinfra service s3 cluster change --self-signed\n\nSee also\n\nManaging S3 users\n\nManaging S3 buckets\n\nChanging the redundancy scheme for S3 data\n\nReplicating S3 data between datacenters\n\nChanging the TLS configuration for S3",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service s3 cluster change [--self-signed | --no-ssl | --cert-file <cert_file>]\r\n                                 [--insecure] [--key-file <key_file>] [--password]\n\n--self-signed\n\n        Generate a new self-signed certificate (default)\n--no-ssl\n\nDo not generate a self-signed certificate\n--cert-file <cert_file>\n\nPath to a file with the new certificate\n--insecure\n\nAllow insecure connections in addition to secure ones (only used with the --cert-file and --self-signed options)\n--key-file <key_file>\n\nPath to a file with the private key (only used with the --cert-file option)\n--password\n\nRead certificate password from stdin (only used with the --cert-file option)\n\nFor example,  to use a self-signed certificate for the S3 storage, run:# vinfra service s3 cluster change --self-signed\n",
                "title": "To change S3 protocol settings"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n Open the Storage services > S3 > Settings screen, and then click Protocol.\n\nSelect an S3 endpoint protocol: HTTP, HTTPS, or both.\n\nIt is recommended to use only HTTPS for production deployments.\n\n\n\n\n\nIf you selected the HTTPS protocol, do one of the following: \n\n\nSelect Upload a certificate, specify the prepared SSL certificate, and then specify the SSL key or passphrase (for PKCS#12 files).\nYou need to acquire a key and a trusted wildcard SSL certificate for endpoint\u00e2\u0080\u0099s bottom-level domain. For example, the endpoint s3storage.example.com would need a wildcard certificate for *.s3storage.example.com with the subject alternative name s3storage.example.com.\nIf you acquired an SSL certificate from an intermediate certificate authority (CA)\n\nYou should have an end-user certificate along with a CA bundle that contains the root and intermediate certificates. To be able to use these certificates, you need to merge them into a chain first. A certificate chain includes the end-user certificate, the certificates of intermediate CAs, and the certificate of a trusted root CA. In this case, an SSL certificate can only be trusted if every certificate in the chain is properly issued and valid.\nFor example, if you have an end-user certificate, two intermediate CA certificates, and a root CA certificate, create a new certificate file and add all certificates to it in the following order:# End-user certificate issued by the intermediate CA 1\r\n-----BEGIN CERTIFICATE-----\r\nMIICiDCCAg2gAwIBAgIQNfwmXNmET8k9Jj1X<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 1 certificate issued by the intermediate CA 2\r\n-----BEGIN CERTIFICATE-----\r\nMIIEIDCCAwigAwIBAgIQNE7VVyDV7exJ9ON9<...>\r\n-----END CERTIFICATE-----\r\n# Intermediate CA 2 certificate issued by the root CA\r\n-----BEGIN CERTIFICATE-----\r\nMIIC8jCCAdqgAwIBAgICZngwDQYJKoZIhvcN<...>\r\n-----END CERTIFICATE-----\r\n# Root CA certificate\r\n-----BEGIN CERTIFICATE-----\r\nMIIDODCCAiCgAwIBAgIGIAYFFnACMA0GCSqG<...>\r\n-----END CERTIFICATE-----\r\n\n\n\n\n\nSelect Generate a certificate, to get a self-signed certificate for HTTPS evaluation purposes.\n\n\nS3 geo-replication requires a certificate from a trusted authority. It does not work with self-signed certificates.\nTo access the data in the S3 cluster via a browser, add the self-signed certificate to browser\u00e2\u0080\u0099s exceptions.\n\n\n\n\n\nClick Save to apply your changes.\n\n",
                "title": "To change S3 protocol settings"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-s3-protocol-settings.html"
    },
    {
        "title": "Checking disk data flushing capabilities",
        "content": "Checking disk data flushing capabilities\nIt is highly recommended to ensure that all storage devices you plan to include in your cluster can flush data from cache to disk if the power goes out unexpectedly. Thus you will find devices that may lose data in a power failure.\nVirtuozzo Hybrid Infrastructure ships with the vstorage-hwflush-check tool that checks how a storage device flushes data to disk in emergencies. The tool is implemented as a client/server utility:\n\nThe client continuously writes blocks of data to the storage device. When a data block is written, the client increases a special counter and sends it to the server that keeps it.\nThe server keeps track of counters incoming from the client and always knows the next counter number. If the server receives a counter smaller than the one it has (for example, because the power has failed and the storage device has not flushed the cached data to disk), the server reports an error.\n\nTo check that a storage device can successfully flush data to disk when power fails, follow the procedure below:\n\nOn one node, run the server: # vstorage-hwflush-check -l\n\nOn a different node that hosts the storage device you want to test, run the client. For example:# vstorage-hwflush-check -s vstorage1.example.com -d /vstorage/stor1-ssd/test -t 50\nwhere\n\nvstorage1.example.com is the host name of the server.\n/vstorage/stor1-ssd/test is the directory to use for data flushing tests. During execution, the client creates a file in this directory and writes data blocks to it.\n50 is the number of threads for the client to write data to disk. Each thread has its own file and counter. You can increase the number of threads (max. 200) to test your system in more stressful conditions. You can also specify other options when running the client. For more information on available options, refer to the vstorage-hwflush-check manual page.\n\nWait for at least 10-15 seconds, cut power from the client node (either press the Power button or pull the power cord out), and then power it on again.\n\nRestart the client:\n# vstorage-hwflush-check -s vstorage1.example.com -d /vstorlage/stor1-ssd/test -t 50\nOnce launched, the client will read all previously written data, determine the version of data on the disk, and restart the test from the last valid counter. It then will send this valid counter to the server and the server will compare it to the latest counter it has. You may see output like:\nid<N>:<counter_on_disk> -> <counter_on_server>\n\nwhich means one of the following:\n\nIf the counter on the disk is lower than the counter on the server, the storage device has failed to flush the data to the disk. Avoid using this storage device in production, especially for CS or journals, as you risk losing data.\nIf the counter on the disk is higher than the counter on the server, the storage device has flushed the data to the disk but the client has failed to report it to the server. The network may be too slow or the storage device may be too fast for the set number of load threads, so consider increasing it. This storage device can be used in production.\nIf both counters are equal, the storage device has flushed the data to the disk and the client has reported it to the server. This storage device can be used in production.\n\nTo be on the safe side, repeat the procedure several times. Once you have checked your first storage device, continue with all of the remaining devices you plan to use in the cluster. You need to test all devices you plan to use in the cluster: SSD disks used for CS journaling, disks used for MDS journals and chunk servers.\nSee also\n\nQuantity of disks per node\n\nHDD/SSD configuration\n\nProtecting data during a power outage\n\nServer requirements\n\nNetwork requirements and recommendations",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/checking-disk-data-flushing-capabilities.html"
    },
    {
        "title": "3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nBefore starting with the deployment of the Hystax Acura migration solution, we need to review the solution architecture, gather information, and verify that we have the necessary resources available on our Virtuozzo Hybrid Infrastructure Platform. The information gathered, will be used to deploy the Hystax Acura solution.\nHystax Acura Migration Solution Architectural Overview\n\nWe need to verify that the following resources exist on our Virtuozzo Hybrid Infrastructure Platform. If the resources do not exist, we will need to create them:\n\nA customer domain, we will name it Ringo-Cloud for the purpose of this example. This domain will be where our customer\u00e2\u0080\u0099s projects will be created. We will refer to this domain as the target project domain. If you already have a domain configured that you wish to use to create your customer\u00e2\u0080\u0099s projects on, please use it.  A domain is a container for projects and users that have roles assigned to them.\nA project to host the migrated infrastructure, we will name the project migration-infra for the purpose of this example. This project will live inside the domain created on the previous step. We will refer to this project as the target project or target cloud. This project will be where replicated workloads will be spun, also the Acura Cloud Agent (an instance automatically deployed by the Hystax Acura Solution, which job is to forward replication data and write it to a storage volume on the target project) instance will be created here. A project is a container of virtual objects with set virtual resource constraints, such as virtual CPU, RAM, storage, and floating IP addresses, as well as assigned users. Each project is also known as a tenant. We will also be creating a network, a virtual network and a router for this project.\nA user who will execute the migration, we will name this user \u00e2\u0080\u009cmigration-user\u00e2\u0080\u009d. The user will have the necessary access rights defined by the role assigned, to perform the migration tasks. We will use this to fill the username field when configuring the Hystax Acura Migration Solution appliance. A role defines all of the actions that a user may execute, at the level of the entire infrastructure, a specific domain, or a single project. The user will be assigned the \u00e2\u0080\u009cproject member\u00e2\u0080\u009d role, and will have single project scope.\nA domain and project which will host the Hystax Acura Migration Solution (Hystax Acura Controller), we will refer to this project as the Hystax service project. The domain that has been used in previous steps can be used to create this service project. The Hystax Acura Migration instance will be deployed on this project. This way the instance will be isolated. This isolation is relevant, as when configuring the Hystax Acura Solution instance in the next section, we will need to define which network is used by the instance in order to communicate with the Acura Cloud Agent instance, which is spun on every customer project. We have two choices; we can define the network attached to the Hystax Acura instance, in order to do this, we need to create a RBAC rule using the OpenStack command line to share the network with every project we wish to communicate. The other option is to use an external physical network, which can be made shareable with any project via the Web UI interface. We will use a physical external network type to establish this communication in this example.\n\nCreate a Domain, log in to your Virtuozzo Hybrid Infrastructure Platform Admin Panel, go to Projects and Users and click on Create Domain. This is only necessary if your customer does not have an organization domain already.\n\nNow create a new Project inside the domain that you have just created (or existing customer domain). Click on the name of the Domain, then on Projects and click on Create project, in this example we have created a project with unlimited resources.\n\nRemember you need to account for the following resources when creating the projects:\n\nService project: Resources to launch a virtual machine with 8 vCPUs, 16 GB RAM, 100 GB disk created from the Hystax Acura Golden image.\nTarget project: Resources to launch a VM with 2 vCPUs, 4 GB RAM, 20 GB disk for the Hystax Cloud Agent. Created in each target / failover Virtuozzo Hybrid Infrastructure project. Also, any replicated workloads will be deployed here.\n\nCreate a project user and assign it to the migration project. Click on Domain Users then on Create user. Allow the user to upload images.\n\nCreate a Domain and a Project where the Hystax Acura Solution instance will be deployed. Remember this project will be the Acura Service Project. When the Hystax Acura Solution is deployed you will be able to manage multiple tenants from this single instance. This is the reason why having dedicated domain a project helps to organise resources. From your Virtuozzo Hybrid Infrastructure Appliance, go to \u00e2\u0080\u009cProjects and users\u00e2\u0080\u009d tab on the left-hand side navigation menu, then click on Create Domain.\n\nNow click on the Acura Service Domain > Projects > Create Project. This project will be the service project. We will use it to deploy the Hystax Acura Solution Instance.\n\nNow create a user. This user will be used to login later into the Acura Service Project in order to deploy the Hystax Acura Solution instance. Don\u00e2\u0080\u0099t forget to assign the user to the Acura Service Project.\n\nGo to Projects and Users, click Acura Service Domain > Create User. Assign the user to the Acura Service Project with the Project Member role.\n\nAt this point, our Acura Service and the Target Projects are ready but there is a missing configuration related to the network, the Hystax service network. Later in this guide, we will deploy the Hystax Acura Instance. This instance will communicate with the Acura Cloud Agent instance through an external physical network which will be made available on both projects. We will use the same physical network to simplify the configuration. The only requisite when choosing the network to use for the Hystax service network is that the network should be routable from the Acura Cloud Agent instance network to the network in which the Hystax Acura Instance is located.\nLogin to your Virtuozzo Hybrid Infrastructure Admin Panel and click on network on the left-hand navigation panel. Identify the external network you wish to use (for this example we will use a network named public) and click on top of it, you\u00e2\u0080\u0099ll see a new panel on the left, find the network access section and click Edit.\n\nNow enable the network on the Service Domain and the Ringo Cloud Domain as we only have one project on each, the access will be inherited by the project.\n\nDownload the Hystax Acura image to your admin panel server and upload the image to the Acura Service Project.\n\nSSH in to your Virtuozzo Hybrid Infrastructure Admin panel compute node.\nSource your admin credentials:\n\nsu - vstoradmin\nkolla-ansible post-deploy ; exit\nsource /etc/kolla/admin-openrc.sh\n\n\nDownload the Hystax Acura image:\n\nwget https://xx-hystax-imagexx-acura.tar.gz\n\n\nExtract the archive:\n\ntar -xvf xx-hystax-imagexx-acura.tar.gz\n\n\nUpload the Hystax Acura image to your project:\n\nopenstack --insecure image create \"Hystax Acura\" \\\n--disk-format raw \\\n--container-format bare \\\n--file Hystax_Acura_VA_MGR_Virtuozzo_3_7_1701-release_3_7_ \\\n--project name_of_the_hystax_service_project\n\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/installation-steps/resource-planning.html"
    },
    {
        "title": "7. Installing and Configuring Leostream Gateway\u00c2\u00b6",
        "content": "7. Installing and Configuring Leostream Gateway | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n7. Installing and Configuring Leostream Gateway\u00c2\u00b6\nAfter building and updating your base operating system, run the following command to install your Leostream Gateway.\ncurl http://downloads.leostream.com/gateway.sh | bash\n\n\nThe installation script downloads and installs any dependencies required by the gateway.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/installing-gateway.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Integration Guide for CloudBlue Connect\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nIntegration Guide for CloudBlue Connect\n\nHome\n\nContents\n\nIndex\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureIntegration Guide for CloudBlue Connect\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_cloudblue_integration_guide/index.html"
    },
    {
        "title": "GET service ostor-usage",
        "content": "GET service ostor-usage\nDescription\nLists existing statistics objects or queries information contained in a specified object.\nRequests\nSyntaxGET /?ostor-usage HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET /?ostor-usage&obj=<object_name> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>GET ?ostor-usage&after=<object_name>&limit=<number> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nGET service ostor-usage parameters\n\nParameter\t\nDescription\t\nRequired\n\nobj\n\nStatistics object name.\nType: string.\nDefault value: none.\n\nNo\n\nafter\n\nObject name after which to show the list of statistics objects. The specified name will not be shown in the response.\nType: string.\nDefault value: none.\n\nNo\n\nlimit\n\nNumber of statistics objects to show in the response.\nType: integer.\nDefault value: none.\n\nNo\n\nIf the obj subresource is undefined, the response contains information about all existing statistics objects. Otherwise, information from the specified object obj is returned.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nIf obj is unspecified:{ \"nr_items\": <number_of_statistics_objects>,\r\n  \"truncated\": <true_if_list_is_truncated>,\r\n  \"items\": [ <list_of_statistics_objects>\r\n   \"<first_object's_name>\",\r\n   \"s3-usage-<obj1>\",\r\n   \"s3-usage-<obj2>\",\r\n   \"s3-usage-<obj3>\",\r\n   ...\r\n]\r\n}\nIf obj is specified:{ \"fmt_version\": <version_of_response_format>,\r\n  \"service_id\": <id_of_service_that_collected_statistics>,\r\n  \"start_ts\": <timestamp_of_statistics_upload>,\r\n  \"period\": <statistics_upload_period_in_seconds>,\r\n  \"nr_items\": <number_of_counters>,\r\n  \"items\": [<list_of_usage_counters>\r\n  {\r\n       \"key\": { \"bucket\": \"<bucket_name>\", \"epoch\": <bucket_epoch_time>, \"user_id\": \"<user_id>\", \"tag\": \"<statistics_object_tag>\" },\r\n       \"counters\": {\r\n               \"ops\": { \"put\":<count_of_put_operations>, \"get\": <count_of_get_operations>, \"list\": <count_of_list_operations>, \"other\": <count_of_other_operations> },\r\n               \"net_io\": { \"uploaded\": <number_of_uploaded_bytes_during_period>,\r\n               \"downloaded\": <number_of_downloaded_bytes_during_period> }\r\n       }\r\n  },\r\n  ...\r\n ]\r\n}\nExamples\nSample request #1\nThe following request returns information about all statistics objects.GET /?ostor-usage /HTTP1.1\r\nDate : Mon, 11 Apr 2016 16:43:16 GMT+3:00\r\nHost : s3.example.com\r\nAuthorization : <authorization_string>\nSample response #1HTTP/1.1 200 OK\r\nx-amz-req-time-micros : 404\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nx-amz-request-id : 80000000000000030006b6be3b0ae378\r\nDate : Mon, 11 Apr 2016 13:43:16 GMT\r\nContent-type : application/json\r\n\r\n{ \"nr_items\": 9,\r\n  \"truncated\": false,\r\n  \"items\": [\r\n   \"s3-usage-8000000000000003-2016-04-11T13:10:29.000Z-1800\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:12:53.000Z-30\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:13:23.000Z-30\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:15:53.000Z-30\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:16:23.000Z-30\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:31:54.000Z-30\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:33:25.000Z-30\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:33:55.000Z-30\",\r\n   \"s3-usage-8000000000000003-2016-04-11T13:34:25.000Z-30\"\r\n  ]\r\n}\nSample request #2\nThe following request returns information from the object s3-usage-8000000000000003-2016-04-11T13:33:55.000Z-30.GET /?ostor-usage&obj=s3-usage-8000000000000003-2016-04-11T13:12:53.000Z-30 /HTTP1.1\r\nDate: Mon, 11 Apr 2016 17:48:21 GMT+3:00\r\nHost: s3.example.com\r\nAuthorization: <authorization_string>\nSample response #2HTTP/1.1 200 OK\r\nX-amz-req-time-micros : 576\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nX-amz-request-id : 80000000000000030006b6bf23c77f09\r\nDate : Mon, 11 Apr 2016 14:48:21 GMT\r\nContent-type : application/json\r\n\r\n{ \"fmt_version\": 1, \"service_id\":8000000000000003,\r\n  \"start_ts\":1460380373, \"period\": 30, \"nr_items\":2,\r\n  \"items\": [\r\n  {\r\n       \"key\": { \"bucket\": \"bucket\", \"epoch\":16394, \"user_id\": \"f82c23f7823589eb\", \"tag\": \"\" },\r\n       \"counters\": {\r\n               \"ops\": { \"put\":15, \"get\":0, \"list\":1, \"other\":0 },\r\n               \"net_io\": { \"uploaded\":99785, \"downloaded\":0 }\r\n       }\r\n  },\r\n  {\r\n       \"key\": { \"bucket\": \"\", \"epoch\":0, \"user_id\": \"f82c23f7823589eb\", \"tag\": \"\" },\r\n       \"counters\": {\r\n               \"ops\": { \"put\":0, \"get\":2, \"list\":0, \"other\":0 },\r\n               \"net_io\": { \"uploaded\":0, \"downloaded\":0 }\r\n       }\r\n  }\r\n ]\r\n}\nSample request #3\nThe following request returns information about 5 statistics objects after the object s3-usage-8000000000000015-2024-02-15T11:56:49.000Z-1800.GET /?ostor-usage&after=s3-usage-8000000000000015-2024-02-15T11:56:49.000Z-1800&limit=5 /HTTP1.1\r\nDate: Fri, 19 Apr 2024 15:07:53 GMT+3:00\r\nHost: s3.example.com\r\nAuthorization: <authorization_string>\nSample response #3HTTP/1.1 200 OK\r\nx-amz-req-time-micros : 404\r\nTransfer-encoding : chunked\r\nServer : nginx/1.8.1\r\nConnection : keep-alive\r\nx-amz-request-id : 80000000000000030006b6be3b0ae378\r\nDate : Fri, 19 Apr 2024 15:07:53 GMT\r\nContent-type : application/json\r\n\r\n{ \"nr_items\": 5,\r\n  \"truncated\": false,\r\n  \"items\": [\r\n   \"s3-usage-8000000000000015-2024-02-15T12:12:03.000Z-30\",\r\n   \"s3-usage-8000000000000015-2024-02-15T12:15:21.000Z-30\",\r\n   \"s3-usage-8000000000000015-2024-02-15T12:20:36.000Z-30\",\r\n   \"s3-usage-8000000000000015-2024-02-15T12:25:40.000Z-30\",\r\n   \"s3-usage-8000000000000015-2024-02-15T12:31:54.000Z-30\"\r\n  ]\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/get-service-ostor-usage.html"
    },
    {
        "title": "About the guide",
        "content": "About the guide\nThe guide explains how to use the REST API to manage S3 clusters based on Virtuozzo Hybrid Infrastructure. The system API enables storage administrators to manage users, accounts, limits, and storage quotas, as well as display billing statistics. The system REST API enables remote execution of operations similar to ostor-s3-admin functionality.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/about-the-guide.html"
    },
    {
        "title": "Setting up networks for file storage",
        "content": "Setting up networks for file storage\nPrerequisites\n\nA clear understanding of the concept Traffic types.\n\nTo create the network configuration for file storage\n\nAdmin panel\n\nGo to Infrastructure > Networks and ensure that your infrastructure has the following networks: A private network with the OSTOR private traffic typeA public network with the NFS public traffic type\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the NFS cluster.\n\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n\nSee also\n\nManaging infrastructure networks\n\nWhat's next\n\nConfiguring node network interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n",
                "title": "To create the network configuration for file storage"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Infrastructure > Networks and ensure that your infrastructure has the following networks: A private network with the OSTOR private traffic typeA public network with the NFS public traffic type\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces  on the nodes that you plan to join the NFS cluster.\n\n",
                "title": "To create the network configuration for file storage"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-networks-file-storage.html"
    },
    {
        "title": "Changing network configuration",
        "content": "Changing network configuration\nYou can change your network configuration and IP address assignment to cluster nodes by using network migration.\nLimitations\n\nDHCP can be enabled for the source network but must be disabled for the target network. After migration, IP addresses obtained via DHCP will become static.\nMigration from IPv4 to IPv6 is not supported.\n\nPrerequisites\n\nAll of the connected node interfaces are online.\nEach network interface has only one IP address.\nHigh availability is disabled, as described in Managing high availability configuration. You can enable high availability later, if required.\nIf a network is the default gateway network, all nodes connected to it must use the same default gateway.\nIf you have restricted outbound traffic in your cluster, you need to manually add a rule that will allow outbound traffic on TCP and UDP ports 60000\u00e2\u0080\u009360100, as described in Configuring outbound firewall rules.\n\nTo migrate a network from the source configuration to the target one\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Migrate.\n\nIn the Migrate network: <network name> window, review the current network configuration, and important information about potential risks, and edit the new network configuration, if required.\nIf you plan to move your cluster to another location, which implies cluster manual shutdown, select Cluster relocation with shutdown is planned.\nThen, click Next.\n\nOn the next step, specify new IP addresses for cluster nodes, and click Try new configuration. Then, confirm your action by clicking Continue in the Try new configuration window.\n\nIf you plan cluster relocation, you can shut down your cluster nodes and then turn them on in a new datacenter, as described in Shutting down and starting up the cluster. After cluster relocation, click Resume.\n\nWait until the new configuration is created and then click Apply.\n\nWhile network migration is in progress, users cannot perform other tasks in the admin panel. Moreover, the self-service users may not have access to the portal and will need to wait until the migration is complete.\n\nIf the connectivity checks fail, you need to fix the found issues and try again. If the specified new IP addresses are not available or valid, you can change them in the wizard and click Retry. With other network issues, revert to your old network configuration by clicking Revert, fix the issue, and try again.\nWait until the migration is complete on all the connected interfaces, and then click Done.\nIf you migrate a network with the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\nCommand-line interface\n\nStart the network migration by using the following command:vinfra cluster network migration start <network> [--subnet <subnet>]\r\n                                       [--netmask <netmask>]\r\n                                       [--gateway <gateway>] [--shutdown]\r\n                                       [--node <node> <address>]\r\n\n\n--network <network>\n\nNetwork ID or name\n--subnet <subnet>\n\nNew network subnet\n--netmask <netmask>\n\nNew network mask\n--gateway <gateway>\n\nNew network gateway\n--shutdown\n\nPrepare the cluster to be shut down manually for relocation\n--node <node> <address>\n\nNew node address in the format:\n\n<node>: node ID or hostname\n<address>: IPv4 address\n\nThis option can be used multiple times.\n\nFor example:# vinfra cluster network migration start --network \"Private\" \\\r\n--subnet 192.168.128.0 --netmask 255.255.255.0 --node node001 192.168.128.11 \\\r\n--node node002 192.168.128.12 --node node003 192.168.128.13\r\n+----------------------------+--------------------------------------------------+\r\n| Field                      | Value                                            |\r\n+----------------------------+--------------------------------------------------+\r\n| configuration              | network_id: 3e3619b7-2c93-4e90-a187-135c6f8b9060 |\r\n| link                       | href: /api/v2/network/migration/2d4ec3a9-<...>/  |\r\n|                            | method: GET                                      |\r\n|                            | rel: network-migration-details                   |\r\n| operation                  | network-migration                                |\r\n| progress                   | 0.0                                              |\r\n| single_interface_migration | False                                            |\r\n| state                      | preparing                                        |\r\n| task_id                    | 2d4ec3a9-7714-479d-a03c-1efbe6ffecf5             |\r\n| transitions                | 0                                                |\r\n+----------------------------+--------------------------------------------------+\r\n\n\nView the current network migration details. For example:# vinfra cluster network migration show\r\n+----------------------------+-------------------------------------------------+\r\n| Field                      | Value                                           |\r\n+----------------------------+-------------------------------------------------+\r\n| link                       | href: /api/v2/network/migration/2d4ec3a9-<...>/ |\r\n|                            | method: GET                                     |\r\n|                            | rel: network-migration-details                  |\r\n| operation                  | network-migration                               |\r\n| progress                   | 1.0                                             |\r\n| single_interface_migration | False                                           |\r\n| state                      | test-passed                                     |\r\n| task_id                    | 2d4ec3a9-7714-479d-a03c-1efbe6ffecf5            |\r\n| transitions                | 5                                               |\r\n+----------------------------+-------------------------------------------------+\r\n\nThe output shows that the new network configuration has been tested and can be applied.\n\nIf you plan cluster relocation, you can shut down your cluster nodes and then turn them on in a new datacenter, as described in Shutting down and starting up the cluster. After cluster relocation, run:# vinfra cluster network migration resume\n\nContinue the network migration and apply the new network configuration. For example:# vinfra cluster network migration apply\n\nIf you migrate a network with the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\nIf the connectivity checks fail, you need to fix the found issues and try again. If the specified new IP addresses are not available or valid, you can change them by using the following command:vinfra cluster network migration retry [--subnet <subnet>]\r\n                                       [--netmask <netmask>]\r\n                                       [--node <node> <address>]\r\n\n\n--subnet <subnet>\n\nNew network subnet\n--netmask <netmask>\n\nNew network mask\n--node <node> <address>\n\nNew node address in the format:\n\n<node>: node ID or hostname\n<address>: IPv4 address\n\nThis option can be used multiple times.\n\nFor example:# vinfra cluster network migration retry --subnet 192.168.128.0 \\\r\n--netmask 255.255.255.0 --node node001 192.168.128.12 --node node002 192.168.128.13 \\\r\n--node node003 192.168.128.14\r\n+----------------------------+-------------------------------------------------+\r\n| Field                      | Value                                           |\r\n+----------------------------+-------------------------------------------------+\r\n| link                       | href: /api/v2/network/migration/2d4ec3a9-<...>/ |\r\n|                            | method: GET                                     |\r\n|                            | rel: network-migration-details                  |\r\n| operation                  | network-migration                               |\r\n| progress                   | 0.9                                             |\r\n| single_interface_migration | False                                           |\r\n| state                      | failed-to-apply                                 |\r\n| task_id                    | 2ce42f0e-6401-47c1-a52f-33e7c68d0df4            |\r\n| transitions                | 5                                               |\r\n+----------------------------+-------------------------------------------------+\r\n\nWith other network issues, revert to your old network configuration with vinfra cluster network migration revert, fix the issue, and try again.\n\nTo troubleshoot a failed migration\n\nConnect to your cluster via SSH.\nInvestigate /var/log/vstorage-ui-backend/celery.log to find the root cause.\nFix the issue.\nGo back to the wizard screen and click Retry.\n\nSee also\n\nManaging networks\n\nManaging traffic types",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\n\n\nStart the network migration by using the following command:vinfra cluster network migration start <network> [--subnet <subnet>]\r\n                                       [--netmask <netmask>]\r\n                                       [--gateway <gateway>] [--shutdown]\r\n                                       [--node <node> <address>]\r\n\n\n--network <network>\n\nNetwork ID or name\n--subnet <subnet>\n\nNew network subnet\n--netmask <netmask>\n\nNew network mask\n--gateway <gateway>\n\nNew network gateway\n--shutdown\n\nPrepare the cluster to be shut down manually for relocation\n--node <node> <address>\n\n\nNew node address in the format:\n\n<node>: node ID or hostname\n<address>: IPv4 address\n\nThis option can be used multiple times.\n\n\nFor example:# vinfra cluster network migration start --network \"Private\" \\\r\n--subnet 192.168.128.0 --netmask 255.255.255.0 --node node001 192.168.128.11 \\\r\n--node node002 192.168.128.12 --node node003 192.168.128.13\r\n+----------------------------+--------------------------------------------------+\r\n| Field                      | Value                                            |\r\n+----------------------------+--------------------------------------------------+\r\n| configuration              | network_id: 3e3619b7-2c93-4e90-a187-135c6f8b9060 |\r\n| link                       | href: /api/v2/network/migration/2d4ec3a9-<...>/  |\r\n|                            | method: GET                                      |\r\n|                            | rel: network-migration-details                   |\r\n| operation                  | network-migration                                |\r\n| progress                   | 0.0                                              |\r\n| single_interface_migration | False                                            |\r\n| state                      | preparing                                        |\r\n| task_id                    | 2d4ec3a9-7714-479d-a03c-1efbe6ffecf5             |\r\n| transitions                | 0                                                |\r\n+----------------------------+--------------------------------------------------+\r\n\n\n\nView the current network migration details. For example:# vinfra cluster network migration show\r\n+----------------------------+-------------------------------------------------+\r\n| Field                      | Value                                           |\r\n+----------------------------+-------------------------------------------------+\r\n| link                       | href: /api/v2/network/migration/2d4ec3a9-<...>/ |\r\n|                            | method: GET                                     |\r\n|                            | rel: network-migration-details                  |\r\n| operation                  | network-migration                               |\r\n| progress                   | 1.0                                             |\r\n| single_interface_migration | False                                           |\r\n| state                      | test-passed                                     |\r\n| task_id                    | 2d4ec3a9-7714-479d-a03c-1efbe6ffecf5            |\r\n| transitions                | 5                                               |\r\n+----------------------------+-------------------------------------------------+\r\n\nThe output shows that the new network configuration has been tested and can be applied.\n\n\nIf you plan cluster relocation, you can shut down your cluster nodes and then turn them on in a new datacenter, as described in Shutting down and starting up the cluster. After cluster relocation, run:# vinfra cluster network migration resume\n\n\nContinue the network migration and apply the new network configuration. For example:# vinfra cluster network migration apply\n\n\nIf you migrate a network with the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\n\nIf the connectivity checks fail, you need to fix the found issues and try again. If the specified new IP addresses are not available or valid, you can change them by using the following command:vinfra cluster network migration retry [--subnet <subnet>]\r\n                                       [--netmask <netmask>]\r\n                                       [--node <node> <address>]\r\n\n\n--subnet <subnet>\n\nNew network subnet\n--netmask <netmask>\n\nNew network mask\n--node <node> <address>\n\n\nNew node address in the format:\n\n<node>: node ID or hostname\n<address>: IPv4 address\n\nThis option can be used multiple times.\n\n\nFor example:# vinfra cluster network migration retry --subnet 192.168.128.0 \\\r\n--netmask 255.255.255.0 --node node001 192.168.128.12 --node node002 192.168.128.13 \\\r\n--node node003 192.168.128.14\r\n+----------------------------+-------------------------------------------------+\r\n| Field                      | Value                                           |\r\n+----------------------------+-------------------------------------------------+\r\n| link                       | href: /api/v2/network/migration/2d4ec3a9-<...>/ |\r\n|                            | method: GET                                     |\r\n|                            | rel: network-migration-details                  |\r\n| operation                  | network-migration                               |\r\n| progress                   | 0.9                                             |\r\n| single_interface_migration | False                                           |\r\n| state                      | failed-to-apply                                 |\r\n| task_id                    | 2ce42f0e-6401-47c1-a52f-33e7c68d0df4            |\r\n| transitions                | 5                                               |\r\n+----------------------------+-------------------------------------------------+\r\n\nWith other network issues, revert to your old network configuration with vinfra cluster network migration revert, fix the issue, and try again.\n",
                "title": "To migrate a network from the source configuration to the target one"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Migrate.\n\nIn the Migrate network: <network name> window, review the current network configuration, and important information about potential risks, and edit the new network configuration, if required.\nIf you plan to move your cluster to another location, which implies cluster manual shutdown, select Cluster relocation with shutdown is planned.\nThen, click Next.\n\n\n\n\nOn the next step, specify new IP addresses for cluster nodes, and click Try new configuration. Then, confirm your action by clicking Continue in the Try new configuration window.\n\n\n\nIf you plan cluster relocation, you can shut down your cluster nodes and then turn them on in a new datacenter, as described in Shutting down and starting up the cluster. After cluster relocation, click Resume.\n\nWait until the new configuration is created and then click Apply.\n\n\n\nWhile network migration is in progress, users cannot perform other tasks in the admin panel. Moreover, the self-service users may not have access to the portal and will need to wait until the migration is complete.\n\n\nIf the connectivity checks fail, you need to fix the found issues and try again. If the specified new IP addresses are not available or valid, you can change them in the wizard and click Retry. With other network issues, revert to your old network configuration by clicking Revert, fix the issue, and try again.\nWait until the migration is complete on all the connected interfaces, and then click Done.\nIf you migrate a network with the Internal management or VM private traffic type, manually restart all running virtual machines, to be able to access them via VNC console.\n\n",
                "title": "To migrate a network from the source configuration to the target one"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/changing-network-configuration.html"
    },
    {
        "title": "Editing VPN connections",
        "content": "Editing VPN connections\nAfter a VPN connection is created, you can change its endpoint groups and VPN settings at any time.\nLimitations\n\nYou cannot change the virtual router and security policies used to establish a VPN connection.\n\nPrerequisites\n\nA VPN connection is created, as described in Creating VPN connections.\n\nTo edit a VPN connection\n\nOn the VPN screen, click a VPN connection to modify.\nOn the connection right pane, click Edit.\nIn the Edit VPN window, configure local and remote endpoints, if required, and then click Next.\nOn the next step, change VPN parameters such as the VPN connection name, peer IP address, and PSK key. If necessary, you can also configure additional settings by selecting Advanced settings and editing the required parameters.\nClick Save to apply your changes.\n\nAfter you update the connection parameters, its status will change to \"Down\". The connection will re-initiate once the parameters are similarly updated by the other VPN party.\n\nThe IKE and IPsec configuration must match for both communicating parties. Otherwise, the VPN connection between them will not be established.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/editing-vpn-connections.html"
    },
    {
        "title": "Querying statistics objects in WHMCS",
        "content": "Querying statistics objects in WHMCS\nYou can display usage statistics with the ostor-usage service and parameter obj specifying the statistics object. WHMCS displays the accessed buckets, user ID, and counters when you click the Get button. Create a file S3_getStatsForObject.php with the following contents:<?php\r\n\r\n// Load configuration and libraries.\r\nrequire('../../includes/staas_scripts/S3_getConfig.php');\r\nrequire('../../includes/staas_scripts/S3_requestCurl.php');\r\nrequire('../../init.php');\r\n\r\n// Get s3 statistics object.\r\nfunction S3_getStatsObjects($object) {\r\n\r\n    // Load configuration.\r\n    $s3_config = s3_getConfig();\r\n\r\n    // Get s3 statistics object.\r\n    $s3_client = S3_requestCurl(\r\n        $s3_config['s3_key'],\r\n        $s3_config['s3_secret'],\r\n        $s3_config['s3_gateway'],\r\n        \"/?ostor-usage&obj=\" . $object,\r\n        \"GET\"\r\n    );\r\n\r\n    // Store s3 result.\r\n    $_SESSION['s3_object_statistic'] = $s3_client;\r\n    $_SESSION['s3_object'] = $object;\r\n\r\n    // Redirect back.\r\n    header('Location: ' . $_SERVER['HTTP_REFERER']);\r\n}\r\n\r\n// Call function.\r\nS3_getStatsObjects($_GET['object']);\r\n\r\n?>\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-statistics-objects-in-whmcs.html"
    },
    {
        "title": "Object storage requirements",
        "content": "Object storage requirements\n\nGeneral requirements are listed in General requirements.\n\nNote the additional requirements for object storage:\n\nTo be able to deploy and work with object storage, run Virtuozzo Hybrid Infrastructure on physical servers.\nKeep in mind that object storage uses more space than is occupied by all S3 objects. This happens because the S3 service also stores internal metadata about objects and their distribution across object servers. This metadata usually requires 0.5\u00e2\u0080\u009311 Object metadata might use more space if all objects in the S3 cluster occupy less than 100 KB, or if an S3 user additionally sets metadata when uploading an object. percent of the space used by S3 data. Moreover, since version 4.6, Virtuozzo Hybrid Infrastructure provides backups for object metadata, which increase the metadata size by additional 0.5 percent. The backups have automatic retention and do not require any assistance from a system administrator. The metadata and backups use the same redundancy scheme that is configured for the S3 cluster.\n\nObjects storage reserves RAM and CPU cores depending on the number of S3 nodes and taking into account a possible node failure. Each S3 node runs the hostd daemon, an S3 gateway, up to 10 object services (OS), and up to 10 name services (NS). However, the entire S3 cluster cannot host more than 24 OS and 16 NS services.\nThe reserved RAM size on an S3 node is calculated by using the following formula:HOSTD * 256 MB + S3GW * 256 MB + (total_OS * 256 MB + total_NS * 512 MB) / (S3_nodes_number - nodes_that_can_fail_number)\nThe reserved CPU cores on an S3 node are calculated by using the following formula:S3GW * 1 core + (total_OS * 0.1 cores + total_NS * 0.2 cores) / (S3_nodes_number - nodes_that_can_fail_number)\nFor example, the S3 cluster of five nodes runs 24 object services, 16 name services, and may lose one node without data loss. In this case, the reserved RAM size on each S3 node will be calculated as 256 MB + 256 MB + (24 * 256 MB + 16 * 512 MB) / (5 - 1), that is 4096 MB or 4 GB. Also, the reserved CPU cores will be calculated as 1 core + (24 * 0.1 cores + 16 * 0.2 cores) / (5 - 1), that is 2.4 cores.\n\nTo better understand how to calculate the hardware configuration for object storage, consider the following examples with RAM and CPU reservations.\nExample 1. If you have 3 nodes (1 system+metadata disk and 5 storage disks) and want to use 3 replicas redundancy mode with the host failure domain, refer to the table below for the calculations. Note that three nodes are used for the management node high availability, and each of them meets the requirements for the management node.\n\n3 nodes for the S3 cluster                    \n\nService\nManagement nodes\n\nSystem\n4.5 GB,\t3.3 cores\n\nStorage services\n\n5 storage disks, 1 metadata on system disk (each takes 0.5 GB and 0.2 cores), that is 3 GB and 1.2 cores in total\n\nS3\n7.7 GB, 3.8 cores\n\nService reservations\n15.2 GB of RAM and 8.3 cores\n\nMinimum hardware configuration\n16 GB of RAM and 8  cores\n\nRecommended hardware configuration\n32 GB of RAM and 16  cores\n\nExample 2. If you have 5 nodes (1 system+metadata disk, 1 SSD cache disk, 10 storage disks) and want to use them for the S3 cluster, refer to the table below for the calculations. Note that three nodes are used for the management node high availability, and each of them meets the requirements for the management node.\n\n5 nodes for the S3 cluster\n\nService\nManagement nodes (nodes 1-3)\nSecondary nodes (4-5)\n\nSystem\n4.5 GB,\t3.3 cores\n1.5 GB,\t1.1 cores\n\nStorage services\n10 storage disks, 1 metadata on system disk, 1 cache disk (each takes 0.5 GB and 0.2 cores), that is 6 GB and 2.4 cores in total\n10 storage disks, 1 metadata on system disk, 1 cache disk (each takes 0.5 GB and 0.2 cores), that is 6 GB and 2.4 cores in total\n\nS3\n4 GB, 2.4 cores\n4 GB, 2.4 cores\n\nService reservations\n12.6 GB of RAM and 8.1 cores\n9.6 GB of RAM and 5.9 cores\n\nMinimum hardware configuration\n16 GB of RAM and 8 cores\n12 GB of RAM and 6  cores\n\nRecommended hardware configuration\n48 GB of RAM and 16  cores\n\r\n48 GB of RAM and 16  cores\n\nSee also\n\nNetwork requirements\n\nProvisioning object storage space",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/object-storage-requirements.html"
    },
    {
        "title": "Creating virtual machines",
        "content": "Creating virtual machines\nLimitations\n\nUEFI boot is not supported for CentOS 7.x virtual machines with less than 1 GiB of RAM.\n\nPrerequisites\n\nYou have a guest OS source prepared, as described in Managing images.\nOne or more compute networks are created by using the instructions in Managing virtual networks.\n\nCustom security groups are configured, as instructed in Managing security groups.\n\nAn SSH key is added, as outlined in Managing SSH keys. You can specify an SSH key only when creating VMs from a template or boot volume.\n\nTo create a virtual machine\n\nOn the Virtual machines screen, click Create virtual machine. A window will open where you will need to specify the VM parameters.\n\nSpecify a name for the new VM.\n\nSelect the VM boot media:\n\nIf you have an ISO image or a template\n\nSelect Image in the Deploy from section, and then click Specify in the Image section.\n\nIn the Images window, select the ISO image or template, and then click Done.\n\nIf you have a compute boot volume\n\nSelect Volume in the Deploy from section, and then click Specify in the Volumes section.\nIn the Volumes window, click Attach.\n\nIn the Attach volume window, find and select the volume, and then click Attach.\n\nIf you attach more than one volume, the first attached volume becomes the boot volume, by default. To select another volume as bootable, place it first in the list by clicking the up arrow button next to it.\n\nIf you select an image or volume with an assigned placement, the created VM will also inherit this placement.\n\nAfter selecting the boot media, volumes required for this media to boot will be automatically added to the Volumes section.\n\nConfigure the VM disks:\n\nIn the Volumes window, make sure the default boot volume is large enough to accommodate the guest OS. Otherwise, click the ellipsis icon next to it, and then Edit. Change the volume size and click Save.\n\nAdd more disks to the VM by creating or attaching volumes. To do this, click the pencil icon in the Volumes section, and then Add or Attach in the Volumes window.\n\nSelect volumes that will be removed during the VM deletion. To do this, click the pencil icon in the Volumes section, click the ellipsis icon next to the needed volume, and then Edit. Enable Delete on termination and click Save.\nWhen you finish configuring the VM disks, click Done.\n\nChoose the amount of RAM and CPU resources that will be allocated to the VM in the Flavor section. In the Flavor window, select a flavor, and then click Done.\n\nWhen choosing a flavor for a VM, ensure it satisfies the hardware requirements of the guest OS.\n\nTo select a flavor with an assigned placement, you can filter flavors by placement. The VM created from such a flavor will also inherit this placement.\n\nAdd network interfaces to the VM in the Networks section:\n\nIn the Network interfaces window, click Add to attach a network interface.\n\nIn the Add network interface window, select a compute network to connect to, and then specify MAC address, IPv4 and/or IPv6 addresses, and security groups. By default, MAC and primary IP addresses are assigned automatically. To specify them manually, clear the Assign automatically check boxes, and enter the desired addresses. Optionally, assign additional IP addresses to the network interface in the Secondary IP addresses section. Note that a secondary IPv6 address is not available for an IPv6 subnet that works in the SLAAC or DHCPv6 stateless mode.\n\nSecondary IP addresses, unlike the primary one, will not be automatically assigned to the network interface inside the virtual machine guest OS. You should assign them manually.\n\nIf you selected a virtual network with enabled IP address management\n\nIn this case, spoofing protection is enabled and the default security group is selected by default. This security group allows all incoming and outgoing traffic on all the VM ports. If required, you can select another security group or multiple security groups.\nTo disable spoofing protection, clear all of the check boxes and turn off the toggle switch. Security groups cannot be configured with disabled spoofing protection.\n\nIf you selected a virtual network with disabled IP address management\nIn this case, spoofing protection is disabled by default and cannot be enabled. Security groups cannot be configured for such a network.\n\nIf you selected a shared physical network\n\nIn this case, spoofing protection cannot be configured by a self-service user. If you want to enable or disable spoofing protection, contact your system administrator.\r\n                        \n\nAfter specifying the network interface parameters, click Add. The network interface will appear in the Network interfaces list.\n\nIf required, edit IP addresses and security groups of newly added network interfaces. To do this, click the ellipsis icon, click Edit, and then set the parameters.\n\nWhen you finish configuring the VM network interfaces, click Done.\n\nIf you have chosen to boot from a template or volume, which has cloud-init and OpenSSH installed:\n\nAs cloud images have no default password, you can access VMs deployed from them only by using the key authentication method with SSH.\n\nAdd an SSH key to the VM, to be able to access it via SSH without a password. \n\nIn the Select an SSH key window, select an SSH key  and then click Done.\n\nAdd user data to customize the VM after launch, for example, change a user password. \n\nWrite a cloud-config or shell script in the Customization script field or browse a file on your local server to load the script from.\n\nTo inject a script in a Windows VM, refer to the Cloudbase-Init documentation. For example, you can set a new password for the account using the following script:#ps1\r\nnet user <username> <new_password>\r\n\n\nEnable CPU and RAM hot plug for the VM in Advanced options, to be able to change its flavor when the VM is running. You can also enable hot plug after the VM is created.\n\nIf you do not see this option, CPU and RAM hot plug is disabled in your project. To enable it, contact your system administrator.\n\nIf you have chosen to boot from an ISO image, enable UEFI boot in Advanced options, to be able to boot the VM in the UEFI mode. This option cannot be configured after the VM is created.\n\nYou cannot configure UEFI boot if you have selected a template as the VM boot media. If your template has UEFI boot enabled, the option is automatically enabled for the VM, and vice versa.\n\nAfter configuring all of the VM parameters, click Deploy to create and boot the VM.\n\nIf you are deploying the VM from an ISO image, you need to install the guest OS inside the VM by using the built-in VNC console. For VMs with UEFI boot enabled, open the VNC console, and then press any key to boot from the chosen ISO image. Virtual machines created from a template or a boot volume already have a preinstalled guest OS.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-virtual-machines.html"
    },
    {
        "title": "Creating, deleting, and listing folders",
        "content": "Creating, deleting, and listing folders\nOn the bucket contents screen:\n\nTo create a folder, click New folder, specify the folder name in the New folder window, and then click Add.\n\nTo delete a folder, select it, and then click Delete.\nTo list the folder contents, click the folder name.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/creating-deleting-and-listing-folders.html"
    },
    {
        "title": "10.1. Supported Operating Systems\u00c2\u00b6",
        "content": "10.1. Supported Operating Systems | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n10.1. Supported Operating Systems\u00c2\u00b6\nThe Leostream Connection Broker can manage connections to virtual machines running any of the following operating systems:\n\nAny Microsoft Windows operating system version currently covered by Mainstream Support under the Microsoft Fixed Lifecycle Policy, or in service under the Microsoft Modern Lifecycle Policy.\nAny of the following operating systems when running a Java Runtime Environment version 1.7, or later:\n\nCentOS\nDebian\nFedora\nSUSE Linux Enterprise\nRed Hat Enterprise Linux\nUbuntu\nmacOS\n\nWhen creating instances within Virtuozzo Hybrid Infrastructure, ensure that you install the appropriate Leostream Agent onto the virtual machine and register that agent with your Leostream Connection Broker, as described in the following section.\nTo upload an existing image, consult the Virtuozzo documentation.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/preparing-master-images/supported-operating-systems.html"
    },
    {
        "title": "2.1. Resource Planning and Configuration for VMware\u00c2\u00b6",
        "content": "2.1. Resource Planning and Configuration for VMware | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nPrev\nNext\n\n2.1. Resource Planning and Configuration for VMware\u00c2\u00b6\nIn this guide we will be performing a migration from VMware to the Virtuozzo Hybrid Infrastructure Platform; Before we can start with the migration, we need to ensure certain resources are available on the VMware Platform, such as a user with some specific permissions and the HVRAgent (Hystax Replication Agent for VMware) deployed on each of the ESXi Hypervisors. Replication agents are used to replicate the workloads between VMware ESXi Hypervisors (Source Platform) and the Virtuozzo Hybrid Infrastructure Platform (Target Platform/Target Project). From now on we will be referring to the VMware Platform as the Source Platform, and the Target Project or Platform when referring to the Virtuozzo Hybrid Infrastructure Platform.\nHystax Acura Migration Solution Architectural Overview\n\nPorts needed for correct agent work:\n\nvSphere host - tcp/443\nESXi host(s) - tcp/udp/902\nSend logs to the Acura cluster - udp/12201\n\nHystax VMware Replication Agent requires the following user permissions in vSphere (the \u00e2\u0080\u009cVMware Consolidated Backup user\u00e2\u0080\u009d role in vCenter):\n\nVirtual machine - Configuration - Disc Lease\nVirtual machine - Provisioning - Allow read-only disk access\nVirtual machine - Provisioning - Allow virtual machine files upload\nVirtual machine - Snapshot management - Create snapshot\nVirtual machine - Snapshot management - Remove Snapshot\n\nPermission to access CBT is necessary for the correct performance of the application. To enable CBT:\n\nVirtual machine - Configuration - Disc change tracking\n\nAdditionally, it is recommended to include the following global permissions:\n\nGlobal - Disable methods\nGlobal - Enable methods\nGlobal - Licenses\n\nNote\nIn case of using vCloud, vCenter user requires one extra permission to operate: Profile-driven storage > Profile-driven storage view.\n\nHystax VMware Replication Agent uses VMware snapshots and VMware CBT API in order to create consistent replicas of machines\u00e2\u0080\u0099 data.\nThis implies the following considerations regarding VMware storage:\n\nVMware snapshots consume storage to retain copy-on-write buffer, so it is recommended to have at least 10% free space available on VMware storage.\nVMware puts additional load on storage while creating snapshots or running machines with existing snapshots.\n\nPlease consider that storage performance warning thresholds need to be adjusted in order to meet this increased load during replication.\n\nImportant\nThe source machine must have VMware Tools installed manually prior to any replication procedures for it to display its network information in the target VMware ESXi correctly.\n\nLogin to your vCenter.\n\nCreate a user, in this example we will create a user named hystax-user. On your VMware vCenter client go to Administration > Single Sign On > Users and Groups, select your domain in the Domain drop-down menu and click ADD.\n\nCreate a role, we will clone the role VMware Consolidated Backup user and name it Hystax-HVRAgent. On Administration tab, go to Access Control > Roles, select VMware Consolidated Backup user, and click CLONE. Give it a meaningful name and ensure it has the following permissions selected:\n\nVirtual machine - Configuration - Disc Lease\nVirtual machine - Provisioning - Allow read-only disk access\nVirtual machine - Provisioning - Allow virtual machine files upload\nVirtual machine - Snapshot management - Create snapshot\nVirtual machine - Snapshot management - Remove Snapshot\nVirtual machine - Configuration - Disc change tracking\n\nAssign the role to the user.  Go to Inventory > Permissions, select the previously created user, and click Edit. Search for the newly created role and add the role to the user.\n\nAt this point, the hystax-acura user has the necessary permissions to perform the migrations.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/migration-steps/resource-planning.html"
    },
    {
        "title": "Viewing alerts",
        "content": "Viewing alerts\nAn alert is generated and logged each time one of the following conditions is met or events happen:\n\nA critical issue has happened with a cluster, its components (CS, MDS), disks, nodes, or services.\nThe cluster requires configuration or more resources to build or restore its health.\nThe network requires configuration or is experiencing issues that may affect performance.\nA license has expired.\nThe cluster is about to, or has, run out of available space.\n\nAlerts can be ignored (deleted from the alerts list) or postponed for several hours. Postponed alerts reappear in the list after some time. \nTo view an alert\n\nAdmin panel\n\nGo to the Monitoring > Alerts screen, which lists all of the alerts logged by Virtuozzo Hybrid Infrastructure. \nClick the required alert on the list to open its details.\n\nCommand-line interface\nUse the following command:vinfra cluster alert show <alert>\r\n\n\n<alert>\n\nAlert ID that can be obtained with vinfra cluster alert list\n\nFor example, to view the details of the license alert, run:# vinfra cluster alert list\r\n+----+----------------------------------------------------------+---------------------+----------+---------+\r\n| id | type                                                     | datetime            | severity | enabled |\r\n+----+----------------------------------------------------------+---------------------+----------+---------+\r\n| 8  | High availability for the admin panel must be configured | 2021-09-07T18:38:55 | error    | True    |\r\n| 6  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n| 4  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n| 23 | Disk cache settings are not optimal                      | 2021-09-30T23:46:28 | warning  | True    |\r\n| 1  | License is not loaded                                    | 2021-09-07T18:38:55 | warning  | True    |\r\n| 22 | Configuration warning                                    | 2021-09-30T23:21:32 | warning  | True    |\r\n| 3  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n| 7  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n+----+----------------------------------------------------------+---------------------+----------+---------+\r\n# vinfra cluster alert show 1\r\n+---------------+-----------------------+\r\n| Field         | Value                 |\r\n+---------------+-----------------------+\r\n| _type         | license_isnot_loaded  |\r\n| cluster_id    | 1                     |\r\n| cluster_name  | cluster1              |\r\n| datetime      | 2021-09-07T18:38:55   |\r\n| details       | {}                    |\r\n| enabled       | True                  |\r\n| group         | cluster               |\r\n| host          |                       |\r\n| id            | 1                     |\r\n| message       | License is not loaded |\r\n| node_id       |                       |\r\n| object_id     | None                  |\r\n| orig_hostname |                       |\r\n| severity      | warning               |\r\n| suspended     |                       |\r\n| type          | License is not loaded |\r\n+---------------+-----------------------+\n\nTo ignore an alert\n\nGo to the Monitoring > Alerts screen, and then click the required alert on the list. \nOn the alert right pane, click Ignore.\n\nTo postpone an alert\n\nAdmin panel\n\nGo to the Monitoring > Alerts screen, and then click the required alert on the list. \nOn the alert right pane, click Postpone.\n\nCommand-line interface\nUse the following command:vinfra cluster alert delete <alert>\r\n\n\n<alert>\n\nAlert ID\n\nFor example, to delete the alert with the ID 1 from the log, run:# vinfra cluster alert delete 1\n\nSee also\n\nSending email notifications\n\nUsing Alertmanager for notifications\n\nViewing audit log\n\nViewing cluster logs",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster alert show <alert>\r\n\n\n<alert>\n\nAlert ID that can be obtained with vinfra cluster alert list\n\nFor example, to view the details of the license alert, run:# vinfra cluster alert list\r\n+----+----------------------------------------------------------+---------------------+----------+---------+\r\n| id | type                                                     | datetime            | severity | enabled |\r\n+----+----------------------------------------------------------+---------------------+----------+---------+\r\n| 8  | High availability for the admin panel must be configured | 2021-09-07T18:38:55 | error    | True    |\r\n| 6  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n| 4  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n| 23 | Disk cache settings are not optimal                      | 2021-09-30T23:46:28 | warning  | True    |\r\n| 1  | License is not loaded                                    | 2021-09-07T18:38:55 | warning  | True    |\r\n| 22 | Configuration warning                                    | 2021-09-30T23:21:32 | warning  | True    |\r\n| 3  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n| 7  | Network warning                                          | 2021-09-07T18:38:55 | warning  | True    |\r\n+----+----------------------------------------------------------+---------------------+----------+---------+\r\n# vinfra cluster alert show 1\r\n+---------------+-----------------------+\r\n| Field         | Value                 |\r\n+---------------+-----------------------+\r\n| _type         | license_isnot_loaded  |\r\n| cluster_id    | 1                     |\r\n| cluster_name  | cluster1              |\r\n| datetime      | 2021-09-07T18:38:55   |\r\n| details       | {}                    |\r\n| enabled       | True                  |\r\n| group         | cluster               |\r\n| host          |                       |\r\n| id            | 1                     |\r\n| message       | License is not loaded |\r\n| node_id       |                       |\r\n| object_id     | None                  |\r\n| orig_hostname |                       |\r\n| severity      | warning               |\r\n| suspended     |                       |\r\n| type          | License is not loaded |\r\n+---------------+-----------------------+\n",
                "title": "To view an alert"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster alert delete <alert>\r\n\n\n<alert>\n\nAlert ID\n\nFor example, to delete the alert with the ID 1 from the log, run:# vinfra cluster alert delete 1\n",
                "title": "To postpone an alert"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to the Monitoring > Alerts screen, which lists all of the alerts logged by Virtuozzo Hybrid Infrastructure. \nClick the required alert on the list to open its details.\n\n\n\n\n\n",
                "title": "To view an alert"
            },
            {
                "example": "\nAdmin panel\n\nGo to the Monitoring > Alerts screen, and then click the required alert on the list. \nOn the alert right pane, click Postpone.\n\n",
                "title": "To postpone an alert"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/viewing-alerts.html"
    },
    {
        "title": "Showing virtual network details",
        "content": "Showing virtual network detailsGET /v2.0/networks/{network_id}\r\n\nShows the details of a network with the specified ID.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-network-details-detail#show-network-details\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nnetwork_id\n\npath\nstring\nThe ID of the network.\n\nfields (Optional)\nquery\nstring\nThe fields that you want the server to return. If no fields query parameter is specified, the networking API returns all attributes allowed by the policy settings. By using the fields parameter, the API returns only the requested set of attributes. The fields parameter can be specified multiple times. For example, if you specify fields=id&fields=name in the request URL, only the id and name attributes will be returned.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/networks/c5252a20-9206-4b8e-9a0f-45bd22ee7bc8\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nnetwork\n\nbody\nobject\nA network object.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the network, which is\r\nup (true) or down (false).\n\navailability_zone_hints\n\nbody\narray\nThe availability zone candidate for the network.\n\navailability_zones\n\nbody\narray\nThe availability zone for the network.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndns_domain\n\nbody\nstring\nA valid DNS domain.\n\nid\n\nbody\nstring\nThe ID of the network.\n\nipv4_address_scope\n\nbody\nstring\nThe ID of the IPv4 address scope that the network is associated with.\n\nipv6_address_scope\n\nbody\nstring\nThe ID of the IPv6 address scope that the network is associated with.\n\nl2_adjacency\n\nbody\nboolean\nIndicates whether L2 connectivity is available throughout\r\nthe network.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to\r\naddress fragmentation. Minimum value is 68 for IPv4, and 1280 for\r\nIPv6.\n\nname\n\nbody\nstring\nHuman-readable name of the network.\n\nport_security_enabled\n\nbody\nboolean\nThe port security status of the network. Valid values are\r\nenabled (true) and disabled (false).\r\nThis value is used as the default value of port_security_enabled\r\nfield of a newly created port.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nprovider:network_type\n\nbody\nstring\nThe type of physical network that this network is mapped to.\r\nFor example, flat, vlan, vxlan, or gre.\r\nValid values depend on a networking back-end.\n\nprovider:physical_network\n\nbody\nstring\nThe physical network where this network/segment is implemented.\n\nprovider:segmentation_id\n\nbody\ninteger\nThe ID of the isolated segment on the physical network.\r\nThe network_type attribute defines the segmentation model.\r\nFor example, if the network_type value is vlan, this ID is a vlan\r\nidentifier. If the network_type value is gre, this ID is a gre key.\n\nqos_policy_id\n\nbody\nstring\nThe ID of the QoS policy associated with the network.\n\nrevision_number\n\nbody\ninteger\nThe revision number of the network.\n\nrouter:external\n\nbody\nboolean\nIndicates whether the network has an external routing facility that\u00e2\u0080\u0099s not\r\nmanaged by the networking service. If the network is updated from external\r\nto internal the unused floating IPs of this network are automatically\r\ndeleted when extension floatingip-autodelete-internal is present.\n\nsegments\n\nbody\narray\nA list of provider segment objects.\n\nshared\n\nbody\nboolean\nIndicates whether this network is shared across all tenants. By default,\r\nonly administrative users can change this value.\n\nstatus\n\nbody\nstring\nThe network status. Values are ACTIVE, DOWN, BUILD or ERROR.\n\nsubnets\n\nbody\narray\nThe associated subnets.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nvlan_transparent\n\nbody\nboolean\nIndicates the VLAN transparency mode of the network, which is\r\nVLAN transparent (true) or not VLAN transparent (false).\n\ndefault_vnic_type\n\nbody\nstring\nThe default value of the vnic_type parameter for each virtual port created in this network.\n\ndescription\n\nbody\nstring\nA human-readable description for the network.\n\nis_default\n\nbody\nboolean\nThe network is default pool or not.\n\ntags\n\nbody\narray\nThe list of tags on the network.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"network\": {\r\n    \"provider:physical_network\": null,\r\n    \"ipv6_address_scope\": null,\r\n    \"revision_number\": 2,\r\n    \"port_security_enabled\": true,\r\n    \"provider:network_type\": \"vxlan\",\r\n    \"id\": \"c5252a20-9206-4b8e-9a0f-45bd22ee7bc8\",\r\n    \"router:external\": false,\r\n    \"availability_zone_hints\": [],\r\n    \"availability_zones\": [\r\n      \"nova\"\r\n    ],\r\n    \"ipv4_address_scope\": null,\r\n    \"shared\": true,\r\n    \"project_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"status\": \"ACTIVE\",\r\n    \"subnets\": [\r\n      \"aa29d149-b2a4-45a0-8066-dc63fa9c9b77\"\r\n    ],\r\n    \"description\": \"\",\r\n    \"tags\": [],\r\n    \"updated_at\": \"2020-02-14T13:42:56Z\",\r\n    \"provider:segmentation_id\": 5,\r\n    \"name\": \"net1\",\r\n    \"admin_state_up\": true,\r\n    \"tenant_id\": \"f5d834d636c642c7bfe8af86139c6f26\",\r\n    \"created_at\": \"2020-02-14T13:36:11Z\",\r\n    \"mtu\": 1450\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-virtual-network-details.html"
    },
    {
        "title": "Setting up networks for block storage",
        "content": "Setting up networks for block storage\nPrerequisites\n\nA clear understanding of the concept Traffic types.\n\nTo create the network configuration for block storage\n\nAdmin panel\n\nGo to Infrastructure > Networks and ensure that your infrastructure has  a public network with the iSCSI traffic type.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces on the nodes that you plan to add to an iSCSI target group.\n\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n\nSee also\n\nManaging infrastructure networks\n\nWhat's next\n\nConfiguring node network interfaces",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nReview your network configuration by using the following command:# vinfra cluster network list -c id -c name -c traffic_types\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| id                                   | name    | traffic_types                                                   |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n| f50605a3-64f4-4f0c-b50e-9481ec221c72 | Private | Backup (ABGW) private,Internal management,OSTOR private,Storage |\r\n| 955041d4-b059-47a1-ba4c-0be117e8cbd2 | Public  | Backup (ABGW) public,iSCSI,NFS,S3 public,Admin panel,SSH        |\r\n+--------------------------------------+---------+-----------------------------------------------------------------+\r\n\n",
                "title": "To create the network configuration for block storage"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Infrastructure > Networks and ensure that your infrastructure has  a public network with the iSCSI traffic type.\nIf you plan to use RDMA over InfiniBand, move the traffic type Storage to a dedicated network and assign that network to the IB interface.\nConfigure network interfaces on the nodes that you plan to add to an iSCSI target group.\n\n",
                "title": "To create the network configuration for block storage"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-up-networks-block-storage.html"
    },
    {
        "title": "Migrating virtual machines to Virtuozzo Hybrid Infrastructure offline",
        "content": "Migrating virtual machines to Virtuozzo Hybrid Infrastructure offline\nIf the network connection between the virt-v2v appliance VM and VMware vCenter is inferior, you can manually copy the VMs to a USB drive, connect it to the virt-v2v appliance VM, and convert them to Virtuozzo Hybrid Infrastructure.\nLimitations\n\nYou can migrate VMs created on vCenter 5.0 or newer.\n\nPrerequisites\n\nAuthentication is configured in the appliance VM, as described in Setting up authentication in the appliance virtual machine.\nRemove VMware tools from Windows VMs before the migration to avoid issues on boot afterwards. VMware tools will be removed from Linux guests automatically.\n\nTo migrate a VM from VMware vCenter offline\n\nCopy all of the VM files, including vmdk and vmx, to a USB drive.\nAttach the USB drive to a host in the same local network as the appliance VM.\nLog in to the appliance VM as the admin user with the SSH key.\nGet root privileges, for example, with sudo -i.\nCopy VM files to the appliance VM, for example, using rsync or scp.\n\nSet OpenStack credentials:# source user-openrc.sh\r\n\n\nMigrate the VM to a volume in Virtuozzo Hybrid Infrastructure specifying a storage policy. To list available storage policies, run vinfra service compute storage-policy list in Virtuozzo Hybrid Infrastructure. For example:# virt-v2v -i libvirtxml <VM_config> -o openstack \\\r\n-oo server-id=635ae4cc-4c01-461a-ae63-91ca4187a7b1 -os <policy_name>\nWhere <VM_config> is the VM configuration file in the vmx format and <policy_name> is the storage policy for the converted volume.\n\nFind out the new volume\u00e2\u0080\u0099s ID or name. For example:# openstack --insecure volume list\r\n+---------------------+------+-----------+------+-------------+\r\n| ID                  | Name | Status    | Size | Attached to |\r\n+---------------------+------+-----------+------+-------------+\r\n| 024b6843-2de3-<...> | sda1 | available |   64 |             |\r\n+---------------------+------+-----------+------+-------------+\r\n\n\nIf the VM used UEFI firmware, manually set the correct OS distribution and UEFI firmware type for the converted volume. To list available distributions, run vinfra service compute show in Virtuozzo Hybrid Infrastructure. For example:# openstack --insecure volume set sda1 --image-property os_distro=win2k8\r\n# openstack --insecure volume set sda1 --image-property hw_firmware_type=uefi\n\nIn Virtuozzo Hybrid Infrastructure, create a virtual machine  based on the new volume. For example:# vinfra service compute server create migratedvm --network id=private \\\r\n--network id=public --volume source=volume,id=sda1,size=64 --flavor medium\r\n\n\nAfter the migration, it is recommended to install the guest tools inside the VM. The guest tools installation will prevent possible problems with guest OS interaction via the VNC console.\nSee also\n\nMigrating virtual machines to Virtuozzo Hybrid Infrastructure online\n\nWhat's next\n\nInstalling guest tools",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/migrating-vms-to-infrastructure-offline.html"
    },
    {
        "title": "Listing resource provider traits",
        "content": "Listing resource provider traitsGET /resource_providers/{uuid}/traits\r\n\nReturn a list of traits for the resource provider with the specified ID.\nSource: https://docs.openstack.org/api-ref/placement/?expanded=list-resource-provider-traits-detail#list-resource-provider-traits\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nuuid\n\npath\nstring\nThe UUID of a resource provider.\n\nExamplecurl -ks -H 'Content-Type: application/json' -H 'OpenStack-API-Version: placement 1.32' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8780/resource_providers/acf24470-ff88-4208-88ce-e040c0bb4c91/traits\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\ntraits\n\nbody\narray\nA list of traits.\n\nresource_provider_generation\n\nbody\ninteger\nA consistent view marker that assists with the management of concurrent resource provider updates.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"traits\": [\r\n    \"COMPUTE_DEVICE_TAGGING\",\r\n    \"COMPUTE_TRUSTED_CERTS\",\r\n    \"COMPUTE_VOLUME_EXTEND\",\r\n    \"COMPUTE_NET_ATTACH_INTERFACE_WITH_TAG\",\r\n    \"COMPUTE_NET_ATTACH_INTERFACE\",\r\n    \"COMPUTE_VOLUME_ATTACH_WITH_TAG\",\r\n    \"COMPUTE_VOLUME_MULTI_ATTACH\",\r\n    \"CUSTOM_HCI_E3A45A6A4B614263893D72015BFB1A5F\"\r\n  ],\r\n  \"resource_provider_generation\": 7936\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-resource-provider-traits.html"
    },
    {
        "title": "S3 bucket and key naming policies",
        "content": "S3 bucket and key naming policies\nIt is recommended to use bucket names that comply with DNS naming conventions:\n\nMust be from 3 to 63 characters long\n\nMust start and end with a lowercase letter or number\n\nCan contain lowercase letters, numbers, periods (.), hyphens (-), and underscores (_)\n\nCan be a series of valid name parts  separated by periods\n\nAn object key can be a string of any UTF-8 encoded characters, up to 1024 bytes long.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/s3-bucket-and-key-naming-policies.html"
    },
    {
        "title": "Dynamically provisioning persistent volumes",
        "content": "Dynamically provisioning persistent volumes\nPersistent volumes can be dynamically provisioned via persistent volume claims (PVC). A PVC requests for a PV of a specific storage class, access mode, and size. If a suitable PV exists in the cluster, it is bound to the claim. If suitable PVs do not exist but can be provisioned, a new volume is created and bound to the claim. Kubernetes uses a PVC to obtain the PV backing it and mounts it to the pod.\nPrerequisites\n\nA pod and the persistent volume claim it uses must exist in the same namespace.\n\nTo dynamically provision a PV to a pod\n\nAccess the Kubernetes cluster via the dashboard. Click Kubernetes access for instructions.\r\n            \n\r\n                On the Kubernetes dashboard, create a storage class, as described in Creating storage classes.\r\n            \n\nCreate a persistent volume claim. To do it, click + Create and specify the following YAML file:apiVersion: v1\r\nkind: PersistentVolumeClaim\r\nmetadata:\r\n  name: mypvc\r\nspec:\r\n  accessModes:\r\n  - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 10Gi\r\n  storageClassName: default\nThis manifest specifies the persistent volume claim mypvc that requests from the storage class default a volume of at least 10 GiB that can be mounted in the read/write mode by a single node.\nCreation of the PVC triggers dynamic provisioning of a persistent volume that satisfies the claim\u00e2\u0080\u0099s requirements. Kubernetes then binds it to the claim.\n\nCreate a pod and specify the PVC as its volume. To do it, click + Create and enter the following YAML file:apiVersion: v1\r\nkind: Pod\r\nmetadata:\r\n  name: nginx\r\nspec:\r\n  containers:\r\n  - image: nginx\r\n    imagePullPolicy: IfNotPresent\r\n    name: nginx\r\n    ports:\r\n    - containerPort: 80\r\n      protocol: TCP\r\n    volumeMounts:\r\n      - mountPath: /var/lib/www/html\r\n        name: mydisk\r\n  volumes:\r\n  - name: mydisk\r\n    persistentVolumeClaim:\r\n      claimName: mypvc\r\n      readOnly: false\r\n\nThis configuration file describes the pod nginx that uses the persistent volume claim mypvc. The persistent volume bound to the claim will be accessible at /var/lib/www/html inside the nginx container.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/dynamically-provisioning-persistent-volumes.html"
    },
    {
        "title": "12.3. Disable Provisioning\u00c2\u00b6",
        "content": "12.3. Disable Provisioning | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n12.3. Disable Provisioning\u00c2\u00b6\nIf you\u00e2\u0080\u0099ve set non-zero provisioning limits in your pool and need to temporarily disable provisioning, uncheck the Provisioning enabled check box, shown in the following figure.\n\nThe Connection Broker may automatically disable provisioning in cases where provisioning is failing due to configuration errors in your pool. If this occurs, please check and correct your provisioning parameters before enabling provisioning.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/pooling-and-provisioning/disable-provisioning.html"
    },
    {
        "title": "Deleting load balancers",
        "content": "Deleting load balancersDELETE /v2/lbaas/loadbalancers/{loadbalancer_id}\r\n\nDelete a load balancer with the specified ID.\nThe optional parameter cascade when defined as true will delete all\r\nchild objects of the load balancer.\nThe API immediately purges any and all configuration data, depending on the\r\nconfiguration settings. You cannot recover it.\nSource: https://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=remove-a-load-balancer-detail#remove-a-load-balancer\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nloadbalancer_id\n\npath\nuuid\nThe ID of the load balancer to query.\n\ncascade (Optional)\nquery\nboolean\nIf true will delete all child objects of the load balancer.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9888/v2/lbaas/loadbalancers/6322ba02-93d9-4282-a12e-d97901a467d9?cascade=True\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n204 - No Content\n\nThe server has fulfilled the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\n500 - Internal Server Error\n\nSomething went wrong inside the service. This should not happen usually.\r\nIf it does happen, it means the server has experienced some serious\r\nproblems.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-load-balancers.html"
    },
    {
        "title": "Editing and deleting compute networks",
        "content": "Editing and deleting compute networks\nYou can edit the network name and network access, as well as delete a compute network that is not used by virtual machines.\nLimitations\n\nYou cannot change IP management of a compute network.\n\nPrerequisites\n\nCompute networks are created automatically during the compute cluster deployment or manually, as described in Creating physical compute networks and Creating virtual compute networks.\nTo be able to delete a compute network, no virtual machines must be connected to it.\n\nTo view and edit parameters of a compute network\n\nAdmin panel\n\nOn the Compute > Networks tab, click the network you want to edit. \nOn the network right pane, click the pencil icon next to the required section, and then make your changes.\n\nCommand-line interface\nUse the following command:vinfra service compute network set [--rbac-policies <rbac-policies>]\r\n                                   [--name <name>] <network>\r\n\n\n--rbac-policies <rbac-policies>\n\nComma-separated list of RBAC policies in the format: <target>:<target_id>:<action> | none. Valid targets: project, domain. Valid actions: direct, full, routed. \u00e2\u0080\u0098*\u00e2\u0080\u0099 is valid target_id for all targets. Pass none to clear out all existing policies.\nExample: domain:default:routed,project:uuid1:full\n\n--name <name>\n\nA new name for the network\n<network>\n\nNetwork ID or name\n\nFor example, to  disable network access for the compute network mypubnet, run:# vinfra service compute network set mypubnet --rbac-policies none\r\n+------------------+--------------------------------------+\r\n| Field            | Value                                |\r\n+------------------+--------------------------------------+\r\n| allocation_pools | 10.136.18.141-10.136.18.148          |\r\n| cidr             | 10.136.16.0/22                       |\r\n| dns_nameservers  | 10.35.11.7                           |\r\n| enable_dhcp      | True                                 |\r\n| gateway_ip       | 10.136.16.1                          |\r\n| id               | 22674f9d-1c94-4953-b79b-7f6029ee9bd0 |\r\n| ip_version       | 4                                    |\r\n| ipam_enabled     | True                                 |\r\n| name             | mypubnet                             |\r\n| physical_network | Public                               |\r\n| project_id       | c22613639b3147e0b22ef057b87698fe     |\r\n| rbac_policies    | []                                   |\r\n| router_external  | False                                |\r\n| shared           | False                                |\r\n| tags             | []                                   |\r\n| type             | physical                             |\r\n| vlan_id          |                                      |\r\n+------------------+--------------------------------------+\r\n\n\nTo delete a compute network\n\nAdmin panel\n\nOn the Compute > Networks tab, click the network you want to delete. \nOn the network right pane, click Delete.\n\nCommand-line interface\nUse the following command:vinfra service compute network delete <network>\r\n\n\n<network>\n\nNetwork ID or name\n\nFor example, to delete the compute network myprivnet, run:# vinfra service compute network delete myprivnet\n\nSee also\n\nManaging security groups\n\nManaging virtual routers\n\nManaging floating IP addresses\n\nManaging load balancers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute network set [--rbac-policies <rbac-policies>]\r\n                                   [--name <name>] <network>\r\n\n\n--rbac-policies <rbac-policies>\n\n\nComma-separated list of RBAC policies in the format: <target>:<target_id>:<action> | none. Valid targets: project, domain. Valid actions: direct, full, routed. \u00e2\u0080\u0098*\u00e2\u0080\u0099 is valid target_id for all targets. Pass none to clear out all existing policies.\nExample: domain:default:routed,project:uuid1:full\n\n--name <name>\n\nA new name for the network\n<network>\n\nNetwork ID or name\n\nFor example, to  disable network access for the compute network mypubnet, run:# vinfra service compute network set mypubnet --rbac-policies none\r\n+------------------+--------------------------------------+\r\n| Field            | Value                                |\r\n+------------------+--------------------------------------+\r\n| allocation_pools | 10.136.18.141-10.136.18.148          |\r\n| cidr             | 10.136.16.0/22                       |\r\n| dns_nameservers  | 10.35.11.7                           |\r\n| enable_dhcp      | True                                 |\r\n| gateway_ip       | 10.136.16.1                          |\r\n| id               | 22674f9d-1c94-4953-b79b-7f6029ee9bd0 |\r\n| ip_version       | 4                                    |\r\n| ipam_enabled     | True                                 |\r\n| name             | mypubnet                             |\r\n| physical_network | Public                               |\r\n| project_id       | c22613639b3147e0b22ef057b87698fe     |\r\n| rbac_policies    | []                                   |\r\n| router_external  | False                                |\r\n| shared           | False                                |\r\n| tags             | []                                   |\r\n| type             | physical                             |\r\n| vlan_id          |                                      |\r\n+------------------+--------------------------------------+\r\n\n",
                "title": "To view and edit parameters of a compute network"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute network delete <network>\r\n\n\n<network>\n\nNetwork ID or name\n\nFor example, to delete the compute network myprivnet, run:# vinfra service compute network delete myprivnet\n",
                "title": "To delete a compute network"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Networks tab, click the network you want to edit. \nOn the network right pane, click the pencil icon next to the required section, and then make your changes.\n\n",
                "title": "To view and edit parameters of a compute network"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Networks tab, click the network you want to delete. \nOn the network right pane, click Delete.\n\n",
                "title": "To delete a compute network"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/editing-and-deleting-compute-networks.html"
    },
    {
        "title": "Managing S3 bucket versions",
        "content": "Managing S3 bucket versions\nVersioning is a way of keeping multiple variants of an object in the same bucket. You can use versioning to preserve, retrieve, and restore every version of every object stored in your S3 bucket. With versioning, you can easily recover from both unintended user actions and application failures. For more information about bucket versioning, refer to the Amazon documentation.\nBucket versioning is turned off by default. In CyberDuck, you can enable it in bucket properties. For example:",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/managing-s3-bucket-versions.html"
    },
    {
        "title": "Performing node maintenance",
        "content": "Performing node maintenance\nWhenever you need to perform service operations on a cluster node, place it in the maintenance mode. When you do so, the node stops allocating new chunks of storage data, but continues to handle I/O operations for the core storage services such as MDS, CS, and cache. They will not, however, be used to allocate new data, so placing the node in maintenance may reduce the free space in the storage cluster. All storage services on the node will continue serving data unless the node goes offline. Other node\u00e2\u0080\u0099s services (compute, Backup Gateway, iSCSI, S3, and NFS) can either be relocated or left as is during maintenance. \nIf a service cannot be evacuated from the node for some reason, entering maintenance will be halted. You will need to decide on how to proceed: exit or force maintenance.\nOnce the node is in the maintenance mode, you can shut it down and perform service operations on it. Once you are done, power on the node and return it to operation in the admin panel.\nIf needed, you can place more nodes in the maintenance mode, one at a time. The cluster can tolerate multiple nodes in maintenance simultaneously as long as the other cluster nodes have enough resources to accommodate evacuated workloads. This also applies during a cluster update, which can be performed when the cluster already has nodes in maintenance. If nodes that have entered the maintenance mode are online, they are updated together with the other cluster nodes, but do not exit maintenance after the update is complete. If a node goes offline while in maintenance, the cluster becomes degraded, thus blocking an update. You can wait until this node is up again or release it from the cluster.\nLimitations\n\nThe last management node cannot be placed in the maintenance mode.\nYou cannot evacuate a service from the last operational node where this service is deployed. For example, VMs that are hosted on the last compute node cannot be relocated from this node and will be ignored during maintenance.\nSuspended VMs cannot be relocated from the node and will be ignored.\nNodes in maintenance can only be returned to operation or released.\n\nPrerequisites\n\nA clear understanding of cluster self-healing, which is explained in \u00d0\u00a1luster rebuilding.\nYou have five MDS services in the storage cluster. In this case, when a node running the MDS service is shut down during maintenance, the cluster can survive the failure of another node.\nIf the node hosts virtual machines, the other compute nodes have enough resources to accommodate these VMs.\nIf the node hosts iSCSI targets, the iSCSI initiators are configured to use multiple IP addresses from the same target group.\nIf the node runs an S3 gateway, its IP addresses are removed from the DNS records of the S3 access points. Otherwise, some of the S3 clients may experience connection timeouts.\n\nTo place a node in the maintenance mode\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the line with the desired node.\nOn the node right pane, click Enter maintenance.\n\nIn the Enter maintenance window, select to Evacuate or Ignore the following workloads during maintenance:\n\nBlock storage. iSCSI target groups are highly available, with multiple targets running on different nodes. When the node enters maintenance, the target it hosts is stopped and the preferred path is moved to another node in the target group within 60 seconds. Thus, the service is not interrupted during maintenance.\nCompute. Evacuating virtual machines from the node means migrating them live one by one to other compute nodes. If you select to ignore them, they will continue running until you reboot or shut down the node. In this case, they will be stopped, resulting in downtime. They also will not be started automatically once the node is up again.\nS3. You can evacuate S3 services from this node to other nodes in the S3 cluster or ignore them. In the latter case, they will continue running until you reboot or shut down the node, resulting in downtime. They will be started automatically once the node is up again.\nNFS. You can evacuate NFS services from this node to other nodes in the NFS cluster or ignore them. In the latter case, they will continue running until you reboot or shut down the node, resulting in downtime. They will be started automatically once the node is up again.\nABGW. This service is highly available, with multiple instances spread across different nodes. Placing this node in the maintenance mode will stop one of the instances, but the others will continue working, so the service will not be interrupted.\n\nStart data healing. Cluster self-healing is an automatic restoration of storage cluster data that becomes unavailable when a storage node (or a disk) goes offline. If this happens during maintenance, self-healing is delayed (for 30 minutes by default) to save cluster resources. If the node goes back online before the delay ends, self-healing is not necessary.\nYou can manually configure the replication timeout by setting the mds.wd.offline_tout_mnt parameter, in milliseconds, with the vstorage -c <cluster_name> set-config command.\n\nIf the node has non-redundant chunks of data, you will see the Relocate non-redundant data option. Select it to move the non-redundant data to other storage nodes. Otherwise, this data will become unavailable if the node goes offline. The data may also be temporarily moved to another tier if the current one is full.\nClick Enter.\n\nCommand-line interface\nUse the following commands:\n\nStart maintenance precheck for a node. For example:# vinfra node maintenance precheck node001\r\n\n\nView the maintenance status. For example:# vinfra node maintenance status node001\r\n+-----------+------------------------------------------+\r\n| Field     | Value                                    |\r\n+-----------+------------------------------------------+\r\n| node_id   | c3b2321a-7c12-8456-42ce-8005ff937e12     |\r\n| params    | alua_mode: suspend                       |\r\n|           | compute_mode: evacuate                   |\r\n|           | iscsi_mode: evacuate                     |\r\n|           | nfs_mode: evacuate                       |\r\n|           | s3_mode: evacuate                        |\r\n|           | storage_mode: suspend                    |\r\n| precheck  | flow: completed                          |\r\n|           | id: c15bf919-9a81-45b1-8fef-5f626e68f957 |\r\n|           | result:                                  |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources: null                        |\r\n|           |   service: node                          |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: false                   |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources: null                        |\r\n|           |   service: iscsi                         |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources:                             |\r\n|           |     failed: []                           |\r\n|           |   service: alua                          |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources: null                        |\r\n|           |   service: compute                       |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: false                   |\r\n|           |   relocation_is_possible: null           |\r\n|           |   resources: null                        |\r\n|           |   service: nfs                           |\r\n|           |   service_is_available: false            |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: false          |\r\n|           |   resources: null                        |\r\n|           |   service: s3                            |\r\n|           |   service_is_available: true             |\r\n|           | state: success                           |\r\n|           | updated_at: '2021-11-01T11:09:41.331926' |\r\n| resources |                                          |\r\n| state     | completed                                |\r\n| task      |                                          |\r\n+-----------+------------------------------------------+\nThe output above shows that the node has relocatable iSCSI and compute services, as well as the S3 service that cannot be relocated.\n\nStart the node maintenance by running the command:vinfra node maintenance start [--iscsi-mode <mode>] [--compute-mode <mode>]\r\n                              [--s3-mode <mode>] [--storage-mode <mode>]\r\n                              [--alua-mode <mode>] [--nfs-mode <mode>] <node>\r\n\n\n--iscsi-mode <mode>\n\nIgnore ISCSI evacuation during maintenance (ignore).\n--compute-mode <mode>\n\nIgnore compute evacuation during maintenance (ignore).\n--s3-mode <mode>\n\nIgnore S3 evacuation during maintenance (ignore).\n--storage-mode <mode>\n\nIgnore storage evacuation during maintenance (ignore).\n--alua-mode <mode>\n\nIgnore Block Storage target groups during maintenance (ignore).\n--nfs-mode <mode>\n\nIgnore NFS evacuation during maintenance (ignore).\n<node>\n\nNode ID or hostname\n\nFor example, to start maintenance for the node node001 without evacuating its S3 service, run:# vinfra node maintenance start node001 --s3-mode ignore\n\nTo proceed after entering maintenance halted\n\nOn the Infrastructure > Nodes screen, click the line with the desired node.\nOn the node right pane, click Enter maintenance.\nSelect the desired action:Select Exit maintenance to return all services on the node  to their normal state.Select Force maintenance to stop the services that could not be evacuated  during node reboot or shutdown.\n Click Continue.\n\nTo return a node to operation\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the line with the desired node.\nOn the node right pane, click Exit maintenance.\nIn the confirmation window, click Yes.\n\nCommand-line interface\nUse the following command:vinfra node maintenance stop <node> [--ignore-compute]\n\n<node>\n\nNode ID or hostname\n--ignore-compute\n\nIgnore compute resources while returning a node to operation\n\nFor example, to stop maintenance for the node node001, run:# vinfra node maintenance stop node001\n\nSee also\n\nInstalling updates",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following commands:\n\n\nStart maintenance precheck for a node. For example:# vinfra node maintenance precheck node001\r\n\n\n\nView the maintenance status. For example:# vinfra node maintenance status node001\r\n+-----------+------------------------------------------+\r\n| Field     | Value                                    |\r\n+-----------+------------------------------------------+\r\n| node_id   | c3b2321a-7c12-8456-42ce-8005ff937e12     |\r\n| params    | alua_mode: suspend                       |\r\n|           | compute_mode: evacuate                   |\r\n|           | iscsi_mode: evacuate                     |\r\n|           | nfs_mode: evacuate                       |\r\n|           | s3_mode: evacuate                        |\r\n|           | storage_mode: suspend                    |\r\n| precheck  | flow: completed                          |\r\n|           | id: c15bf919-9a81-45b1-8fef-5f626e68f957 |\r\n|           | result:                                  |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources: null                        |\r\n|           |   service: node                          |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: false                   |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources: null                        |\r\n|           |   service: iscsi                         |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources:                             |\r\n|           |     failed: []                           |\r\n|           |   service: alua                          |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: true           |\r\n|           |   resources: null                        |\r\n|           |   service: compute                       |\r\n|           |   service_is_available: true             |\r\n|           | - has_resources: false                   |\r\n|           |   relocation_is_possible: null           |\r\n|           |   resources: null                        |\r\n|           |   service: nfs                           |\r\n|           |   service_is_available: false            |\r\n|           | - has_resources: true                    |\r\n|           |   relocation_is_possible: false          |\r\n|           |   resources: null                        |\r\n|           |   service: s3                            |\r\n|           |   service_is_available: true             |\r\n|           | state: success                           |\r\n|           | updated_at: '2021-11-01T11:09:41.331926' |\r\n| resources |                                          |\r\n| state     | completed                                |\r\n| task      |                                          |\r\n+-----------+------------------------------------------+\nThe output above shows that the node has relocatable iSCSI and compute services, as well as the S3 service that cannot be relocated.\n\n\nStart the node maintenance by running the command:vinfra node maintenance start [--iscsi-mode <mode>] [--compute-mode <mode>]\r\n                              [--s3-mode <mode>] [--storage-mode <mode>]\r\n                              [--alua-mode <mode>] [--nfs-mode <mode>] <node>\r\n\n\n--iscsi-mode <mode>\n\nIgnore ISCSI evacuation during maintenance (ignore).\n--compute-mode <mode>\n\nIgnore compute evacuation during maintenance (ignore).\n--s3-mode <mode>\n\nIgnore S3 evacuation during maintenance (ignore).\n--storage-mode <mode>\n\nIgnore storage evacuation during maintenance (ignore).\n--alua-mode <mode>\n\nIgnore Block Storage target groups during maintenance (ignore).\n--nfs-mode <mode>\n\nIgnore NFS evacuation during maintenance (ignore).\n<node>\n\nNode ID or hostname\n\nFor example, to start maintenance for the node node001 without evacuating its S3 service, run:# vinfra node maintenance start node001 --s3-mode ignore\n\n\n",
                "title": "To place a node in the maintenance mode"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node maintenance stop <node> [--ignore-compute]\n\n<node>\n\nNode ID or hostname\n--ignore-compute\n\nIgnore compute resources while returning a node to operation\n\nFor example, to stop maintenance for the node node001, run:# vinfra node maintenance stop node001\n",
                "title": "To return a node to operation"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the line with the desired node.\nOn the node right pane, click Enter maintenance.\n\nIn the Enter maintenance window, select to Evacuate or Ignore the following workloads during maintenance:\n\nBlock storage. iSCSI target groups are highly available, with multiple targets running on different nodes. When the node enters maintenance, the target it hosts is stopped and the preferred path is moved to another node in the target group within 60 seconds. Thus, the service is not interrupted during maintenance.\nCompute. Evacuating virtual machines from the node means migrating them live one by one to other compute nodes. If you select to ignore them, they will continue running until you reboot or shut down the node. In this case, they will be stopped, resulting in downtime. They also will not be started automatically once the node is up again.\nS3. You can evacuate S3 services from this node to other nodes in the S3 cluster or ignore them. In the latter case, they will continue running until you reboot or shut down the node, resulting in downtime. They will be started automatically once the node is up again.\nNFS. You can evacuate NFS services from this node to other nodes in the NFS cluster or ignore them. In the latter case, they will continue running until you reboot or shut down the node, resulting in downtime. They will be started automatically once the node is up again.\nABGW. This service is highly available, with multiple instances spread across different nodes. Placing this node in the maintenance mode will stop one of the instances, but the others will continue working, so the service will not be interrupted.\n\n\n\n\n\n\n\nStart data healing. Cluster self-healing is an automatic restoration of storage cluster data that becomes unavailable when a storage node (or a disk) goes offline. If this happens during maintenance, self-healing is delayed (for 30 minutes by default) to save cluster resources. If the node goes back online before the delay ends, self-healing is not necessary.\nYou can manually configure the replication timeout by setting the mds.wd.offline_tout_mnt parameter, in milliseconds, with the vstorage -c <cluster_name> set-config command.\n\nIf the node has non-redundant chunks of data, you will see the Relocate non-redundant data option. Select it to move the non-redundant data to other storage nodes. Otherwise, this data will become unavailable if the node goes offline. The data may also be temporarily moved to another tier if the current one is full.\nClick Enter.\n\n",
                "title": "To place a node in the maintenance mode"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the line with the desired node.\nOn the node right pane, click Exit maintenance.\nIn the confirmation window, click Yes.\n\n",
                "title": "To return a node to operation"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/performing-node-maintenance.html"
    },
    {
        "title": "Supported Amazon response headers",
        "content": "Supported Amazon response headers\nThe following Amazon S3 REST response headers are currently supported by the Virtuozzo Hybrid Infrastructure implementation of the Amazon S3 protocol:\n\nContent-Length\n\nThe length in bytes of the body in the response.\nContent-Type\n\nThe MIME type of the content.\nConnection\n\nA value that specifies whether the connection to the server is open or closed.\nDate\n\nThe date and time of the response.\nETag\n\nThe entity tag (ETag) represents a specific version of the object. The ETag reflects changes only to the contents of an object, not its metadata.\nx-amz-delete-marker\n\nIndicates whether the returned object was or was not a delete marker.\nx-amz-request-id\n\nA generated value that uniquely identifies the request.\nx-amz-version-id\n\nThe version of the object.\nx-amz-object-lock-retain-until-date\n\nThe date and time when the object's object lock will expire.\nx-amz-object-lock-mode\n\nThe object lock mode that is currently in place for the object.\nx-amz-object-lock-legal-hold\n\nIndicates whether the object has an active legal hold.\nx-amz-expiration\n\nIndicates the expiration date of the object.\nx-amz-storage-class\n\nThe storage class of the object.\nx-amz-replication-status\n\nThe replication status of the object.\n\nThe following Amazon S3 REST response headers are not used:\n\nServer\n\nThe name of the server that created the response.\nx-amz-id-2\n\nA special token that is used for troubleshooting purposes.\n\nFor more information about Amazon S3 REST error response headers, refer to the Amazon S3 REST API documentation.\n\nSee also\n\nSupported Amazon S3 REST operations\n\nSupported Amazon request headers\n\nSupported Amazon error response headers\n\nSupported authentication schemes\n\nAmazon S3 features supported by bucket policies\n\nSupported Amazon S3 object expiration actions",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/supported-response-headers.html"
    },
    {
        "title": "BitNinja Integration\u00c2\u00b6",
        "content": "BitNinja Integration | BitNinja Integration\n\nDocumentation\n\nBack to guides list\n\nNext\n\nBack to guides list\nBitNinja Integration\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n3.1. Downloading Module\n3.2. Activating Module WHMCS\n3.3. Creating BitNinja Product and Service\n\n4. SECaaS Service Offering with HostBill BitNinja Module\n4.1. Activating Module HostBill\n4.2. Connecting HostBill to BitNinja\n4.3. Adding New BitNinja Service (Product)\n4.4. Configuring Client Functions\n\n5. BitNinja Full-Stack Server Protection Agent Requirements\n5.1. System Requirements\n5.2. Software Requirements\n5.3. Package Dependencies\n5.4. Virtual Server Port Requirements\n5.5. Software Compatibility Matrix\n\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nBitNinja IntegrationPDF, 3021 KB\n\nNext\n\nBitNinja Integration\u00c2\u00b6\n\n1. Integration Overview\n2. What is BitNinja?\n3. SECaaS Service Offering with WHMCS BitNinja Module\n4. SECaaS Service Offering with HostBill BitNinja Module\n5. BitNinja Full-Stack Server Protection Agent Requirements\n6. Installing BitNinja Agent\n7. Support and Documentation\n\nVersion 7.5 \u00e2\u0080\u0094 Mar 23, 2023\n\nEdit\nPrint\nShare\n\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_bitninja/index.html"
    },
    {
        "title": "Managing volume snapshots",
        "content": "Managing volume snapshots\nYou can save the current state of a VM file system or user data by creating a snapshot of a volume. A snapshot of a boot volume may be useful, for example, before updating VM software. If anything goes wrong, you will be able to revert the VM to a working state at any time. A snapshot of a data volume can be used for backing up user data and testing purposes.\nPrerequisites\n\nTo create a consistent snapshot of a running VM\u00e2\u0080\u0099s volume, the guest tools must be installed in the VM, as described in Installing guest tools. The QEMU guest agent included in the guest tools image automatically quiesces the filesystem during snapshotting.\n\nTo create a snapshot of a volume\n\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\n\nIn the volume right pane, switch to Snapshots, and then click Create snapshot.\n\nCommand-line interface\nUse the following command:vinfra service compute volume snapshot create [--description <description>]\r\n                                              --volume <volume> <volume-snapshot-name>\r\n\n\n--description <description>\n\nVolume snapshot description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n--volume <volume>\n\nVolume ID or name\n<volume-snapshot-name>\n\nVolume snapshot name\n\nFor example, to create a snapshot mysnapshot of the volume myvolume, run:# vinfra service compute volume snapshot create mysnapshot --volume myvolume\r\n+-------------+--------------------------------------+\r\n| Field       | Value                                |\r\n+-------------+--------------------------------------+\r\n| created_at  | 2019-04-30T13:12:54.297629+00:00     |\r\n| description |                                      |\r\n| id          | 3fdfe5d6-8bd2-4bf5-8599-a9cef50e5b71 |\r\n| metadata    | {}                                   |\r\n| name        | mysnapshot                           |\r\n| project_id  | fd0ae61496d04ef6bb637bc3167b7eaf     |\r\n| size        | 8                                    |\r\n| status      | creating                             |\r\n| volume_id   | 92dc3bd7-713d-42bf-83cd-4de40c24fed9 |\r\n+-------------+--------------------------------------+\r\n\nThe new snapshot will appear in the vinfra service compute volume snapshot list output:# vinfra service compute volume snapshot list -c id -c name -c size -c status\r\n+--------------------------------------+------------+-----------+\r\n| id                                   | name       | status    |\r\n+--------------------------------------+------------+-----------+\r\n| 3fdfe5d6-8bd2-4bf5-8599-a9cef50e5b71 | mysnapshot | available |\r\n+--------------------------------------+------------+-----------+\r\n\n\nTo manage a volume snapshot\n\nAdmin panel\nSelect a volume and open the Snapshots tab on its right pane.\n\nYou can do the following:\n\nCreate a new volume from the snapshot.\nCreate a template from the snapshot.\n\nDiscard all changes that have been made to the volume since the snapshot was taken. This action is available only for VMs with the \"Shut down\" and \"Shelved offloaded\" statuses.\n\nAs each volume has only one snapshot branch, all snapshots created after the snapshot you are reverting to will be deleted. If you want to save a subsequent snapshot before reverting, create a volume or an image from it first.\n\nChange the snapshot name and description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\nReset the snapshot stuck in an \"Error\" state or transitional state to the \"Available\" state. \nRemove the snapshot.\n\nTo perform these actions, click the ellipsis button next to a snapshot, and then click the corresponding action.\n\nCommand-line interface\nUse the following commands:\n\nTo revert a volume to the snapshot, use vinfra service compute volume snapshot revert. For example:# vinfra service compute volume snapshot revert mynewsnapshot\n\nTo create a template from the snapshot, use vinfra service compute volume snapshot upload-to-image. For example:# vinfra service compute volume snapshot upload-to-image --name myvm-image mysnapshot\r\n\n\nTo create a new volume from the snapshot, use vinfra service compute volume create. For example:# vinfra service compute volume create myvolume2 --snapshot mysnapshot --storage-policy default --size 8\n\nTo change the snapshot name and description, use vinfra service compute volume snapshot set. For example:# vinfra service compute volume snapshot set mysnapshot --name mynewsnapshot \\\r\n--description \"My new snapshot\"\r\n\n\nTo reset the snapshot stuck in an \"Error\" state or transitional state to the \"Available\" state, use vinfra service compute volume snapshot reset-state. For example:# vinfra service compute volume snapshot reset-state mysnapshot\n\nTo remove the snapshot, use vinfra service compute volume snapshot delete. For example:# vinfra service compute volume snapshot delete mynewsnapshot\n\nSee also\n\nAttaching and detaching volumes\n\nResizing volumes\n\nChanging the storage policy for volumes\n\nCloning volumes",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume snapshot create [--description <description>]\r\n                                              --volume <volume> <volume-snapshot-name>\r\n\n\n--description <description>\n\n\nVolume snapshot description\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\n--volume <volume>\n\nVolume ID or name\n<volume-snapshot-name>\n\nVolume snapshot name\n\nFor example, to create a snapshot mysnapshot of the volume myvolume, run:# vinfra service compute volume snapshot create mysnapshot --volume myvolume\r\n+-------------+--------------------------------------+\r\n| Field       | Value                                |\r\n+-------------+--------------------------------------+\r\n| created_at  | 2019-04-30T13:12:54.297629+00:00     |\r\n| description |                                      |\r\n| id          | 3fdfe5d6-8bd2-4bf5-8599-a9cef50e5b71 |\r\n| metadata    | {}                                   |\r\n| name        | mysnapshot                           |\r\n| project_id  | fd0ae61496d04ef6bb637bc3167b7eaf     |\r\n| size        | 8                                    |\r\n| status      | creating                             |\r\n| volume_id   | 92dc3bd7-713d-42bf-83cd-4de40c24fed9 |\r\n+-------------+--------------------------------------+\r\n\nThe new snapshot will appear in the vinfra service compute volume snapshot list output:# vinfra service compute volume snapshot list -c id -c name -c size -c status\r\n+--------------------------------------+------------+-----------+\r\n| id                                   | name       | status    |\r\n+--------------------------------------+------------+-----------+\r\n| 3fdfe5d6-8bd2-4bf5-8599-a9cef50e5b71 | mysnapshot | available |\r\n+--------------------------------------+------------+-----------+\r\n\n",
                "title": "To create a snapshot of a volume"
            },
            {
                "example": "\nCommand-line interface\nUse the following commands:\n\n\nTo revert a volume to the snapshot, use vinfra service compute volume snapshot revert. For example:# vinfra service compute volume snapshot revert mynewsnapshot\n\n\nTo create a template from the snapshot, use vinfra service compute volume snapshot upload-to-image. For example:# vinfra service compute volume snapshot upload-to-image --name myvm-image mysnapshot\r\n\n\n\nTo create a new volume from the snapshot, use vinfra service compute volume create. For example:# vinfra service compute volume create myvolume2 --snapshot mysnapshot --storage-policy default --size 8\n\n\nTo change the snapshot name and description, use vinfra service compute volume snapshot set. For example:# vinfra service compute volume snapshot set mysnapshot --name mynewsnapshot \\\r\n--description \"My new snapshot\"\r\n\n\n\nTo reset the snapshot stuck in an \"Error\" state or transitional state to the \"Available\" state, use vinfra service compute volume snapshot reset-state. For example:# vinfra service compute volume snapshot reset-state mysnapshot\n\n\nTo remove the snapshot, use vinfra service compute volume snapshot delete. For example:# vinfra service compute volume snapshot delete mynewsnapshot\n\n\n",
                "title": "To manage a volume snapshot"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\n\nIn the volume right pane, switch to Snapshots, and then click Create snapshot.\n\n\n\n\n\n\n",
                "title": "To create a snapshot of a volume"
            },
            {
                "example": "\nAdmin panel\nSelect a volume and open the Snapshots tab on its right pane.\n\n\n\n\nYou can do the following:\n\nCreate a new volume from the snapshot.\nCreate a template from the snapshot.\n\nDiscard all changes that have been made to the volume since the snapshot was taken. This action is available only for VMs with the \"Shut down\" and \"Shelved offloaded\" statuses.\n\nAs each volume has only one snapshot branch, all snapshots created after the snapshot you are reverting to will be deleted. If you want to save a subsequent snapshot before reverting, create a volume or an image from it first.\n\n\n\n\n\nChange the snapshot name and description.\n\nA description should not contain any personally identifiable information or sensitive business data.\n\n\nReset the snapshot stuck in an \"Error\" state or transitional state to the \"Available\" state. \nRemove the snapshot.\n\nTo perform these actions, click the ellipsis button next to a snapshot, and then click the corresponding action.\n",
                "title": "To manage a volume snapshot"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-volume-snapshots.html"
    },
    {
        "title": "Creating custom load balancer flavors",
        "content": "Creating custom load balancer flavors\nLoad balancer flavors are predefined sets of provider configuration options. They are defined per provider driver and expose the unique capabilities of each provider.\nBy default, there are two load balancer flavors:\n\nACTIVE_STANDBY is used to build highly available load balancers with two instances\nSINGLE is used to build load balancers with single instances\n\nIf needed, administrators can add more flavors for self-service users.\nPrerequisites\n\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo create a load balancer flavor\n\nList the load balancer provider capabilities and choose those that will be configured in the flavor. As we use the amphora provider, run:# openstack --insecure loadbalancer provider capability list amphora\r\n+-------------------+-------------------------------+---------------------------------------------------+\r\n|type               | name                          | description                                       |\r\n+-------------------+-------------------------------+---------------------------------------------------+\r\n| flavor            | loadbalancer_topology         | The load balancer topology. One of:               |\r\n|                   |                               | SINGLE - One amphora per load balancer.           |\r\n|                   |                               | ACTIVE_STANDBY - Two amphora per load balancer.   |\r\n| flavor            | compute_flavor                | The compute driver flavor ID.                     |\r\n| flavor            | amp_image_tag                 | The amphora image tag.                            |\r\n| flavor            | amp_bdm_delete_on_termination | Delete on termination the amphora block device    |\r\n|                   |                               | mapping.                                          |\r\n| availability_zone | compute_zone                  | The compute availability zone.                    |\r\n| availability_zone | management_network            | The management network ID for the amphora.        |\r\n| availability_zone | valid_vip_networks            | List of network IDs that are allowed for VIP use. |\r\n|                   |                               | This overrides/replaces the list of allowed       |\r\n|                   |                               | networks configured in `octavia.conf`.            |\r\n+-------------------+-------------------------------+---------------------------------------------------+\n\nList the current compute flavors to learn their IDs:# openstack --insecure flavor list\r\n+-----+--------+-------+------+-----------+-------+-----------+\r\n| ID  | Name   |   RAM | Disk | Ephemeral | VCPUs | Is Public |\r\n+-----+--------+-------+------+-----------+-------+-----------+\r\n| 100 | tiny   |   512 |    0 |         0 |     1 | True      |\r\n| 101 | small  |  2048 |    0 |         0 |     1 | True      |\r\n| 102 | medium |  4096 |    0 |         0 |     2 | True      |\r\n| 103 | large  |  8192 |    0 |         0 |     4 | True      |\r\n| 104 | xlarge | 16384 |    0 |         0 |     8 | True      |\r\n+-----+--------+-------+------+-----------+-------+-----------+\r\n\n\nCreate a flavor profile that is responsible for the load balancer topology and associated with a compute flavor. Load balancers use the same compute flavor as virtual machines. For example, to create a flavor profile that will build highly available load balancers with the small flavor, run:# openstack --insecure loadbalancer flavorprofile create --name amphora-ha-small --provider amphora  \\\r\n--flavor-data '{\"loadbalancer_topology\": \"ACTIVE_STANDBY\", \"compute_flavor\": \"101\"}'\r\n+---------------+----------------------------------------------------------------------+\r\n| Field         | Value                                                                |\r\n+---------------+----------------------------------------------------------------------+\r\n| id            | a1c7d342-df30-490d-b3ec-29d36ff1b0ba                                 |\r\n| name          | amphora-ha-small                                                     |\r\n| provider_name | amphora                                                              |\r\n| flavor_data   | {\"loadbalancer_topology\": \"ACTIVE_STANDBY\", \"compute_flavor\": \"101\"} |\r\n+---------------+----------------------------------------------------------------------+\r\n\nIn this case, the created flavor profile will use the default amphora image configured for the load balancing service (refer to Provisioning load balancers). To use a custom amphora image, you need to associate it with the flavor profile by specifying the  image tag with amp_image_tag. Note that an image with this tag must exist in the compute cluster (refer to Changing the default load balancer image). For example, to create a flavor profile that will build highly available load balancers with the small flavor and the custom_amphora image, run:# openstack --insecure loadbalancer flavorprofile create --name amphora-ha-small --provider amphora  \\\r\n--flavor-data '{\"loadbalancer_topology\": \"ACTIVE_STANDBY\", \"compute_flavor\": \"101\", \"amp_image_tag\": \"custom_amphora\"}'\nThe created flavor profile will appear in the vinfra service compute load-balancer flavorprofile list output:# vinfra service compute load-balancer flavorprofile list\r\n+--------------------------------------+--------------------+\r\n| id                                   | name               |\r\n+--------------------------------------+--------------------+\r\n| 0347cfa1-d471-466e-8ed3-b52e41c47140 | amphora-single     |\r\n| a1c7d342-df30-490d-b3ec-29d36ff1b0ba | amphora-ha-small   |\r\n| d91d5113-38ad-4a93-951a-36e53be6555a | amphora-act-stndby |\r\n+--------------------------------------+--------------------+\n\nCreate a load balancer flavor using the new flavor profile. For example:# openstack --insecure loadbalancer flavor create --name HA-SMALL --enable --flavorprofile amphora-ha-small\r\n+-------------------+--------------------------------------+\r\n| Field             | Value                                |\r\n+-------------------+--------------------------------------+\r\n| id                | b8b84c9e-7a15-4693-8a06-20ddb1faa75e |\r\n| name              | HA-SMALL                             |\r\n| flavor_profile_id | a1c7d342-df30-490d-b3ec-29d36ff1b0ba |\r\n| enabled           | True                                 |\r\n| description       |                                      |\r\n+-------------------+--------------------------------------+\r\n\n\nThe new load balancer flavor will appear in the vinfra service compute load-balancer flavor list output:# vinfra service compute load-balancer flavor list\r\n+--------------------------------------+----------------+--------------------------------------+---------+\r\n| id                                   | name           | flavor_profile_id                    | enabled |\r\n+--------------------------------------+----------------+--------------------------------------+---------+\r\n| 7ea31357-f9db-4414-b2b2-f0799ebdf356 | ACTIVE_STANDBY | d91d5113-38ad-4a93-951a-36e53be6555a | True    |\r\n| a68c6434-7672-4d3f-91c9-f109bbc7fb75 | SINGLE         | 0347cfa1-d471-466e-8ed3-b52e41c47140 | True    |\r\n| b8b84c9e-7a15-4693-8a06-20ddb1faa75e | HA-SMALL       | a1c7d342-df30-490d-b3ec-29d36ff1b0ba | True    |\r\n+--------------------------------------+----------------+--------------------------------------+---------+\nNow, you can use the new flavor for creating load balancers in the self-service panel.\nSee also\n\nChanging load balancer resources\n\nChanging the default load balancer image\n\nManaging balancing pools",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-custom-load-balancer-flavors.html"
    },
    {
        "title": "2. Migration Steps\u00c2\u00b6",
        "content": "2. Migration Steps | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nPrev\nNext\n\n2. Migration Steps\u00c2\u00b6\nThe migration process will be divided in to four sections:\n\nEnsure the Virtuozzo Hybrid Infrastructure Platform is ready. Refer to the Integration Guide for Hystax Acura guide and check the following sections:\n\nVirtuozzo Hybrid Infrastructure Platform resources planning and configuration.\nDeploying the Hystax Acura migration solution on the Virtuozzo Hybrid Infrastructure.\n\nVMware resources planning and configuration.\nDeploying the HVRAgent on the VMware ESXi Hypervisor.\nSimple Test Migration.\n\nIn this chapter:\n\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/migration-steps/index.html"
    },
    {
        "title": "Cloning volumes",
        "content": "Cloning volumes\nLimitations\n\nYou can clone volumes that are not attached to VMs or attached to stopped VMs.\n\nPrerequisites\n\nA volume is created, as described in Creating and deleting volumes.\n\nTo clone a volume\n\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\nOn the volume right pane, click Clone.\n\nIn the Clone volume window, specify a volume name, size, and storage policy. Click Clone.\n\nCommand-line interface\nUse the following command:vinfra service compute volume clone --name <name> [--size <size-gb>]\r\n                                    [--storage-policy <storage_policy>] <volume>\n\n--name <name>\n\n        New volume name\n--size <size-gb>\n\nVolume size, in gigabytes\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to clone the volume myvolume to myvolume2, run:# vinfra service compute volume clone myvolume --name myvolume2\r\n+--------------------------------+------------------------------------------+\r\n| Field                          | Value                                    |\r\n+--------------------------------+------------------------------------------+\r\n| attachments                    | []                                       |\r\n| availability_zone              | nova                                     |\r\n| bootable                       | True                                     |\r\n| consistencygroup_id            |                                          |\r\n| created_at                     | 2021-10-18T16:36:39.937068               |\r\n| description                    |                                          |\r\n| encrypted                      | False                                    |\r\n| id                             | 22eb7529-0a2c-44ce-a73c-24f3152bdb54     |\r\n| imageRef                       |                                          |\r\n| migration_status               |                                          |\r\n| multiattach                    | False                                    |\r\n| name                           | myvolume2                                |\r\n| network_install                | False                                    |\r\n| os-vol-host-attr:host          | node003.vstoragedomain@vstorage#vstorage |\r\n| os-vol-mig-status-attr:migstat |                                          |\r\n| os-vol-mig-status-attr:name_id |                                          |\r\n| project_id                     | b906404c55bb44729da99987536ac5bc         |\r\n| replication_status             |                                          |\r\n| size                           | 64                                       |\r\n| snapshot_id                    |                                          |\r\n| source_volid                   | c80f58c9-c52e-41c4-ad5f-d5b5ed072d4a     |\r\n| status                         | creating                                 |\r\n| storage_policy_name            | default                                  |\r\n| traits                         | []                                       |\r\n| updated_at                     | 2021-10-18T16:36:40.133516               |\r\n| user_id                        | c727a901a6444ee1a8ad31e3d5b53b3a         |\r\n| volume_image_metadata          |                                          |\r\n+--------------------------------+------------------------------------------+\r\n\n\nSee also\n\nAttaching and detaching volumes\n\nResizing volumes\n\nChanging the storage policy for volumes\n\nTransferring volumes between projects",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute volume clone --name <name> [--size <size-gb>]\r\n                                    [--storage-policy <storage_policy>] <volume>\n\n--name <name>\n\n        New volume name\n--size <size-gb>\n\nVolume size, in gigabytes\n--storage-policy <storage_policy>\n\nStorage policy ID or name\n<volume>\n\nVolume ID or name\n\nFor example, to clone the volume myvolume to myvolume2, run:# vinfra service compute volume clone myvolume --name myvolume2\r\n+--------------------------------+------------------------------------------+\r\n| Field                          | Value                                    |\r\n+--------------------------------+------------------------------------------+\r\n| attachments                    | []                                       |\r\n| availability_zone              | nova                                     |\r\n| bootable                       | True                                     |\r\n| consistencygroup_id            |                                          |\r\n| created_at                     | 2021-10-18T16:36:39.937068               |\r\n| description                    |                                          |\r\n| encrypted                      | False                                    |\r\n| id                             | 22eb7529-0a2c-44ce-a73c-24f3152bdb54     |\r\n| imageRef                       |                                          |\r\n| migration_status               |                                          |\r\n| multiattach                    | False                                    |\r\n| name                           | myvolume2                                |\r\n| network_install                | False                                    |\r\n| os-vol-host-attr:host          | node003.vstoragedomain@vstorage#vstorage |\r\n| os-vol-mig-status-attr:migstat |                                          |\r\n| os-vol-mig-status-attr:name_id |                                          |\r\n| project_id                     | b906404c55bb44729da99987536ac5bc         |\r\n| replication_status             |                                          |\r\n| size                           | 64                                       |\r\n| snapshot_id                    |                                          |\r\n| source_volid                   | c80f58c9-c52e-41c4-ad5f-d5b5ed072d4a     |\r\n| status                         | creating                                 |\r\n| storage_policy_name            | default                                  |\r\n| traits                         | []                                       |\r\n| updated_at                     | 2021-10-18T16:36:40.133516               |\r\n| user_id                        | c727a901a6444ee1a8ad31e3d5b53b3a         |\r\n| volume_image_metadata          |                                          |\r\n+--------------------------------+------------------------------------------+\r\n\n",
                "title": "To clone a volume"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Storage > Volumes tab, click a volume.\nOn the volume right pane, click Clone.\n\nIn the Clone volume window, specify a volume name, size, and storage policy. Click Clone.\n\n\n\n\n\n\n",
                "title": "To clone a volume"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/cloning-volumes.html"
    },
    {
        "title": "DELETE service ostor-accounts",
        "content": "DELETE service ostor-accounts\nDescription\nDeletes an account of a user specified by email or ID.\nRequests\nSyntaxDELETE /?ostor-accounts&emailAddress=<value>&accountName=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>DELETE /?ostor-accounts&id=<value>&accountName=<value> HTTP/1.1\r\nHost: <host>\r\nDate: <date>\r\nAuthorization: <authorization_string>\nParameters\n\nDELETE service ostor-accounts parameters\n\nParameter\t\nDescription\t\nRequired\n\nemailAddress\n\nUser email address.\nType: string.\nDefault value: none.\n\nNo*\n\nid\n\nUser ID.\nType: string.\nDefault value: none.\n\nNo*\n\naccountName\n\nAccount name.\n\r\nType: string.\n\r\nDefault value: none.\n\nYes\n\n* Only one of the required parameters can be set in a single request.\nHeaders\nThis implementation uses only common request headers.\nResponses\nHeaders\nThis implementation uses only common response headers.\nBody\nEmpty.\nErrors\nReturns Error Code 400 if more than one required parameter is set.\nIf an account is successfully deleted, Status204NoContent is returned.\nExamples\nSample request\nDeletes the account with the name account1 for the user with the email user1@email.com.DELETE /?ostor-accounts&emailAddress=user1@email.com&accountName=account1 HTTP/1.1\r\nHost: s3.example.com\r\nDate: Wed, 24 Mar 2021 14:53:53 GMT\r\nAuthorization: <authorization_string>\nSample response\r\nHTTP/1.1 204 No Content\r\nServer: nginx\r\nContent-Type: application/xml\r\nConnection: keep-alive\r\nDate: Wed, 24 Mar 2021 14:53:55 GMT\r\nx-amz-req-time-micros: 47411\r\nx-amz-request-id: 8000000000000016000060d75ec8e4dd\t\t\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_ostor_api_reference/delete-service-ostor-accounts.html"
    },
    {
        "title": "2.2. Deploying HVRAgent on VMware ESXi Hypervisor\u00c2\u00b6",
        "content": "2.2. Deploying HVRAgent on VMware ESXi Hypervisor | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nPrev\nNext\n\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\u00c2\u00b6\nThere are three types of replication agents:\n\nVMware agent - an external agent to replicate VMware virtual machines without installing any software directly on VMs. Please refer that the agent requires access to VMware CBT API and network access to vCenter or ESXi host is mandatory. Note that the agent from the same ova template must be deployed to all ESXi hosts where machines need to be protected.\nWindows agent - an internal agent which can be deployed to any number of customer Windows virtual or physical machines.\nLinux agent - an internal agent which can be deployed to any number of customer Linux virtual or physical machines.\n\nAs we are performing a migration from VMware as the Source Cloud Platform, we will be using the VMware Agent. When any of the agents are deployed, the machine with it (or all machines on the same ESXi host where the agent is located) will appear in Hystax Acura Control Panel under customer dashboard in the Discovered state.\n\nLogin to the Hystax Acura portal by going to https://floating-ip-acura-instace.\n\nClick on the customer you wish to perform the migration for, in our example we will be performing a migration from VMware as Source Cloud to Virtuozzo Hybrid Infrastructure platform. Any time you wish to go back to the main menu click on the Hystax logo on the top left.\n\nClick Install agents.\n\nSelect the VMware agent and click Next.\n\nYou will be asked to provide credentials for the vSphere environment. Provide the credentials created previously.\n\nNow download the OVA file and deploy it on each ESXi host in your VMware cluster that you want to migrate workloads from.\n\nDeploy the agent:\n\nUse the Deploy OVF Template wizard to deploy the HRVAgent. Right click on the ESXi server you would like to deploy the agent. You\u00e2\u0080\u0099ll need to repeat this procedure for each ESXi server available that you wish to migrate workloads from.\n\nSelect Local file, click Upload files, and choose the OVA file.\n\nFollow the deployment wizard and provide the necessary information (compute resource, storage, networks) HVRAgent. The HVRAgent should be able to access the vCenter internal IP.\n\nOnce the HVRAgent VM is up, check the console and verify all is correct.\n\nClick on the Hystax logo on the top left and on the customer, you\u00e2\u0080\u0099d like to manage. You will see the machines running on your ESXI server have been discovered.\n\nClick on Start Replication. If everything is correctly configured, replication of the remote instance will start on your target cloud. Replication will take some time, depending on how much data will be replicated and the connection between your source and target cloud.\n\nWait until the instance is synced.\n\nWhile the image is being synced, let\u00e2\u0080\u0099s create a target network (the network that will be used by our instance on the replicated target cloud). Go to your VHI self-service portal on \u00e2\u0080\u009cvhi-admin-panel-fqdn:8800\u00e2\u0080\u009d and login to the target project.\n\nOnce you\u00e2\u0080\u0099ve logged in, check the Virtual machines tab and you will see that the Acura cloud agent has been deployed automatically.\n\nGo to Networks, click Create virtual network, and follow the steps. I will create the network using exactly the same CIDR (172.31.32.0/20) as the instance being replicated. You could use any other network CIDR, this is just to show an example of a migration with exactly the same IP address source and remote.\nAdd a migration plan. Start by adding a machine. Click on the ellipsis icon \u00e2\u0080\u009c\u00e2\u0080\u00a6\u00e2\u0080\u009d, then click Add machine > Default, and select discovered machine.\n\nNext, configure the subnets for your new instance. Expand the view for your instance. You will see information regarding Machine ID, Flavor (important to check the flavor you choose have enough resources for your instance), and Port (network). Also, on the left you\u00e2\u0080\u0099ll see information regarding the network to be used.\n\nWe will replace the Flavor name with one that is available on our cloud. You can check available flavors by going to Virtual machines and Flavors. Also, we will find the subnet ID for our newly created network and paste it there.\n\nSource the information regarding the subnet ID.\n\nLogin to your Virtuozzo Hybrid Infrastructure Admin panel via SSH.\nSource the admin-openrc.sh file.\n\n# source /etc/kolla/admin-openrc.sh\n\n\nRun the command openstack network list --insecure and identify the subnet ID.\n\nAdd the subnet ID.\n\nAdd a secondary Port. Add a subnet by clicking the \u00e2\u0080\u009c+\u00e2\u0080\u009d button on the Subnets section, we will be adding a floating IP.\n\nClick on the Subnet ID* drop down menu for your new subnet and select the Public IP you wish to use. By leaving the Port IP field blank you are specifying DHCP. Provide a name for the plan and click Save.\n\nClick on Run test migration and select the migration plan.\n\nCreate a cloud site by giving a name, a cloud site is a way to logically group a migration plan with a snapshot to be used for the migration. Give the Cloud Site a name, select a snapshot and click on Run migration.\n\nIf all went well you will see your replicated instance available on your target cloud. When you are done reviewing the migration test you can delete the resources, by deleting the cloud site, then you can redo the migration, or you could detach.\n\nFor the final cutover, just detach Hystax Acura from the migration and Hystax Acura will stop tracking any resources belonging to this migration.\n\nNow you can manage your resources from VHI as you would normally do.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/migration-steps/deploying-hvragent.html"
    },
    {
        "title": "6. Adding Floating IP to Gateway VM (DNAT Access)\u00c2\u00b6",
        "content": "6. Adding Floating IP to Gateway VM (DNAT Access) | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\u00c2\u00b6\nThe Leostream Gateway provides access to the private virtual desktops and forwards traffic to the Connection Broker, which is behind a firewall. To make the Leostream Gateway publicly accessible, associate a floating IP address with the Leostream Gateway\u00e2\u0080\u0099s private IP, as follows.\n\nFrom the self-service portal, go to Compute > Floating IPs and click Add to allocate a new floating IP to your project.\nClick the ellipses icon at the far right of the row for your new floating IP, and select Assign. In the Assign floating IP address window, select the Leostream Gateway VM network interface with a fixed private IP address.\n\nThe following figure shows a floating IP assigned to a VM IP address.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/adding-floating-ip.html"
    },
    {
        "title": "HDD/SSD configuration",
        "content": "HDD/SSD configuration\nHDD only\nThis basic configuration requires a dedicated disk for each metadata server.\n\nHDD-only configuration\r\n            \n\nNodes 1-5 (base)\nNodes 6+ (extension)\n\nDisk #\nDisk type\nDisk roles\nDisk #\nDisk type\nDisk roles\n\n1\nHDD\nSystem\n1\nHDD\nSystem\n\n2\nHDD\nMDS\n2\nHDD\nCS\n\n3\nHDD\nCS\n3\nHDD\nCS\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nHDD\nCS\nN\nHDD\nCS\n\nHDD + system SSD (no cache)\nThis configuration is good for creating capacity-oriented clusters.\n\nHDD + system SSD (no cache) configuration\r\n            \n\nNodes 1-5 (base)\nNodes 6+ (extension)\n\nDisk #\nDisk type\nDisk roles\nDisk #\nDisk type\nDisk roles\n\n1\nSSD\nSystem, MDS\n1\nSSD\nSystem\n\n2\nHDD\nCS\n2\nHDD\nCS\n\n3\nHDD\nCS\n3\nHDD\nCS\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nHDD\nCS\nN\nHDD\nCS\n\nHDD + SSD\nThis configuration is good for creating performance-oriented clusters.\n\nHDD + SSD configuration\r\n            \n\nNodes 1-5 (base)\nNodes 6+ (extension)\n\nDisk #\nDisk type\nDisk roles\nDisk #\nDisk type\nDisk roles\n\n1\nHDD\nSystem\n1\nHDD\nSystem\n\n2\nSSD\nMDS, cache\n2\nSSD\nCache\n\n3\nHDD\nCS\n3\nHDD\nCS\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nHDD\nCS\nN\nHDD\nCS\n\nSSD only\nThis configuration does not require SSDs for cache.\n\nIn this configuration, network latency defines more than half of overall performance, so make sure that the network latency is minimal. One recommendation is to have one 10Gbps switch between any two nodes in the cluster.\n\nSSD-only configuration\r\n                \n\nNodes 1-5 (base)\nNodes 6+ (extension)\n\nDisk #\nDisk type\nDisk roles\nDisk #\nDisk type\nDisk roles\n\n1\nSSD\nSystem, MDS\n1\nSSD\nSystem\n\n2\nSSD\nCS\n2\nSSD\nCS\n\n3\nSSD\nCS\n3\nSSD\nCS\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nSSD\nCS\nN\nSSD\nCS\n\nHDD + SSD (no cache), 2 tiers\nIn this configuration example, tier 1 is for HDDs without cache and tier 2 is for SSDs. Tier 1 can store cold data (for example, backups), tier 2 can store hot data (for example, high-performance virtual machines).\n\nHDD + SSD (no cache) 2-tier configuration for nodes 1-5 (base)\r\n            \n\nDisk #\nDisk type\nDisk roles\nTier\n\n1\nSSD\nSystem, MDS\n\u00a0\n\n2\nSSD\nCS\n2\n\n3\nHDD\nCS\n1\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nHDD/SSD\nCS\n1/2\n\nHDD + SSD (no cache) 2-tier configuration for nodes 6+ (extension)\r\n            \n\nDisk #\nDisk type\nDisk roles\nTier\n\n1\nSSD\nSystem\n\u00a0\n\n2\nSSD\nCS\n2\n\n3\nHDD\nCS\n1\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nHDD/SSD\nCS\n1/2\n\nHDD + SSD, 3 tiers\nIn this configuration example, tier 1 is for HDDs without cache, tier 2 is for HDDs with cache, and tier 3 is for SSDs. Tier 1 can store cold data (for example, backups), tier 2 can store regular virtual machines, and tier 3 can store high-performance virtual machines.\n\nHDD + SSD 3-tier configuration for nodes 1-5 (base)\r\n            \n\nDisk #\nDisk type\nDisk roles\nTier\n\n1\nHDD/SSD\nSystem\n\u00a0\n\n2\nSSD\nMDS, T2 cache\n\u00a0\n\n3\nHDD\nCS\n1\n\n4\nHDD\nCS\n2\n\n5\nSSD\nCS\n3\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nHDD/SSD\nCS\n1/2/3\n\nHDD + SSD 3-tier configuration for nodes 6+ (extension)\r\n            \n\nDisk #\nDisk type\nDisk roles\nTier\n\n1\nHDD/SSD\nSystem\n\u00a0\n\n2\nSSD\nT2 cache\n\u00a0\n\n3\nHDD\nCS\n1\n\n4\nHDD\nCS\n2\n\n5\nSSD\nCS\n3\n\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\u00e2\u0080\u00a6\n\nN\nHDD/SSD\nCS\n1/2/3\n\nSee also\n\nQuantity of disks per node\n\nProtecting data during a power outage\n\nChecking disk data flushing capabilities\n\nServer requirements\n\nNetwork requirements and recommendations",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/hdd-ssd-configuration.html"
    },
    {
        "title": "Managing networks",
        "content": "Managing networks\nYou can create networks, view network details, edit, and delete them.\nLimitations\n\nIf you create allow rules but leave the deny list empty, all incoming traffic will still be allowed.\nAn infrastructure network cannot be renamed if it is used by a compute virtual network.\nYou can only delete networks that are not assigned to any network adapters. \n\nTo create a network\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Create network.\nIn the New network window, specify a network name. Network names may contain only Latin letters, numbers, and underscores, and must be 3 to 32 characters long.\n\nIn the Access rules section, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\nClick Create.\n\nCommand-line interface\nUse the following command:vinfra cluster network create [--traffic-types <traffic-types>] [--inbound-allow-list <addresses>]\r\n                              [--inbound-deny-list <addresses>] [--outbound-allow-list <rules>]\r\n                              <network-name>\r\n\n\n--traffic-types <traffic-types>\n\nA comma-separated list of traffic type IDs or names\n--inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses\n--outbound-allow-list <rules>\n\nA comma-separated list of allow rules in the format: <address>:<protocol>:<port>:<description>\n<network-name>\n\nNetwork name\n\nFor example, to create a custom network MyNet and assign the traffic type SSH to it, run:# vinfra cluster network create MyNet --traffic-types ssh\r\n+---------------------+------------------------------------------+\r\n| Field               | Value                                    |\r\n+---------------------+------------------------------------------+\r\n| id                  | b451c5ed-a553-4214-96c4-d926daa6110e     |\r\n| inbound_allow_list  | []                                       |\r\n| inbound_deny_list   | []                                       |\r\n| name                | MyNet                                    |\r\n| outbound_allow_list | - 0.0.0.0:tcp:8888:Internal management   |\r\n|                     | - 0.0.0.0:tcp:80:HTTP                    |\r\n|                     | - 0.0.0.0:tcp:443:HTTPS                  |\r\n|                     | - 0.0.0.0:udp:53:DNS                     |\r\n|                     | - 0.0.0.0:tcp:53:DNS                     |\r\n|                     | - 0.0.0.0:udp:123:NTP                    |\r\n|                     | - 0.0.0.0:tcp:8443:ABGW registration     |\r\n|                     | - 0.0.0.0:tcp:44445:ABGW Geo-replication |\r\n|                     | - 0.0.0.0:tcp:9877:Acronis Cyber Protect |\r\n|                     | - 0.0.0.0:any:0:Allow all                |\r\n| name                | MyNet                                    |\r\n| traffic_types       | SSH                                      |\r\n| vlan                |                                          |\r\n+---------------------+------------------------------------------+\r\n\n\nTo view network details\nClick the cogwheel icon next to the network name. In the network summary window, the following information is available:\n\nThe General section includes the network CIDR and subnet mask.\nThe Connected interfaces section shows the nodes\u00e2\u0080\u0099 network interfaces with their IP addresses.\n\nTo rename a network\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Edit.\nIn the Edit window, enter a new name, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra cluster network set [--name <network-name>] <network>\r\n\n\n--name <network-name>\n\nNetwork name\n<network>\n\nNetwork ID or name\n\nFor example, to rename the network MyNet to MyOtherNet, run:# vinfra cluster network set MyNet --name MyOtherNet\r\n\n\nTo delete a network\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Delete.\nIn the Delete network window, confirm your action by clicking Delete.\n\nCommand-line interface\nUse the following command:vinfra cluster network delete <network>\r\n\n\n<network>\n\nNetwork ID or name\n\nFor example, to delete the network MyOtherNet, run:# vinfra cluster network delete MyOtherNet\n\nSee also\n\nChanging network configuration\n\nConfiguring inbound firewall rules\n\nConfiguring outbound firewall rules\n\nConfiguring data-in-transit encryption\n\nManaging traffic types",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network create [--traffic-types <traffic-types>] [--inbound-allow-list <addresses>]\r\n                              [--inbound-deny-list <addresses>] [--outbound-allow-list <rules>]\r\n                              <network-name>\r\n\n\n--traffic-types <traffic-types>\n\nA comma-separated list of traffic type IDs or names\n--inbound-allow-list <addresses>\n\nA comma-separated list of IP addresses\n--inbound-deny-list <addresses>\n\nA comma-separated list of IP addresses\n--outbound-allow-list <rules>\n\nA comma-separated list of allow rules in the format: <address>:<protocol>:<port>:<description>\n<network-name>\n\nNetwork name\n\nFor example, to create a custom network MyNet and assign the traffic type SSH to it, run:# vinfra cluster network create MyNet --traffic-types ssh\r\n+---------------------+------------------------------------------+\r\n| Field               | Value                                    |\r\n+---------------------+------------------------------------------+\r\n| id                  | b451c5ed-a553-4214-96c4-d926daa6110e     |\r\n| inbound_allow_list  | []                                       |\r\n| inbound_deny_list   | []                                       |\r\n| name                | MyNet                                    |\r\n| outbound_allow_list | - 0.0.0.0:tcp:8888:Internal management   |\r\n|                     | - 0.0.0.0:tcp:80:HTTP                    |\r\n|                     | - 0.0.0.0:tcp:443:HTTPS                  |\r\n|                     | - 0.0.0.0:udp:53:DNS                     |\r\n|                     | - 0.0.0.0:tcp:53:DNS                     |\r\n|                     | - 0.0.0.0:udp:123:NTP                    |\r\n|                     | - 0.0.0.0:tcp:8443:ABGW registration     |\r\n|                     | - 0.0.0.0:tcp:44445:ABGW Geo-replication |\r\n|                     | - 0.0.0.0:tcp:9877:Acronis Cyber Protect |\r\n|                     | - 0.0.0.0:any:0:Allow all                |\r\n| name                | MyNet                                    |\r\n| traffic_types       | SSH                                      |\r\n| vlan                |                                          |\r\n+---------------------+------------------------------------------+\r\n\n",
                "title": "To create a network"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network set [--name <network-name>] <network>\r\n\n\n--name <network-name>\n\nNetwork name\n<network>\n\nNetwork ID or name\n\nFor example, to rename the network MyNet to MyOtherNet, run:# vinfra cluster network set MyNet --name MyOtherNet\r\n\n",
                "title": "To rename a network"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster network delete <network>\r\n\n\n<network>\n\nNetwork ID or name\n\nFor example, to delete the network MyOtherNet, run:# vinfra cluster network delete MyOtherNet\n",
                "title": "To delete a network"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click Create network.\nIn the New network window, specify a network name. Network names may contain only Latin letters, numbers, and underscores, and must be 3 to 32 characters long.\n\nIn the Access rules section, do the following:\n\nTo block traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Deny list section.\nTo allow traffic from particular IP addresses, IP address ranges, or subnets, specify them in the Allow list section. Additionally, specify 0.0.0.0/0 in the Deny list section, to block all other traffic.\n\n\n\n\n\n\nClick Create.\n\n",
                "title": "To create a network"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Edit.\nIn the Edit window, enter a new name, and then click Save.\n\n",
                "title": "To rename a network"
            },
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, click the cogwheel icon next to the network name.\nIn the network summary window, click Delete.\nIn the Delete network window, confirm your action by clicking Delete.\n\n",
                "title": "To delete a network"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-networks.html"
    },
    {
        "title": "Using the command-line interface",
        "content": "Using the command-line interface\nTo manage Virtuozzo Hybrid Infrastructure from console and automate such management tasks, you can use the vinfra command-line tool, which is installed automatically with the product. The tool can also be installed on a remote Linux or macOS machine from the https://github.com/virtuozzo/vinfra/ repository.\nTo get a list of all the supported commands and their descriptions, run vinfra help. For help on a specific command, either run vinfra help <command> or vinfra <command> --help.\nNote that the following operations should not be done from the command line:\n\nSetting custom paths for Virtuozzo Hybrid Infrastructure services, in particular:Creating S3 clusters only in /mnt/vstorage/vols/s3Creating iSCSI targets only in /mnt/vstorage/vols/iscsi\nMounting clusters or change cluster mount options\nConfiguring firewall with firewall-cmd\nRenaming network connections\nManaging metadata and storage services\nManaging partitions, LVMs, or software RAID\nModifying files in /mnt/vstorage/vols and /mnt/vstorage/webcp/backup directories\nSetting encoding or replication of cluster root\n\nProviding credentials to vinfra\nThe vinfra tool requires the following information:\n\nIP address or hostname of the management node (set to backend-api.svc.vstoragedomain by default)\nUser name (admin by default)\nPassword (created during installation of Virtuozzo Hybrid Infrastructure)\nDomain name to authenticate with (Default by default)\nProject ID to authenticate with (admin by default)\n\nThis information can be supplied by using the following command-line parameters with each command:\n\n--vinfra-portal <portal>\n\n--vinfra-username <username>\n\n--vinfra-password <password>\n\n--vinfra-domain <domain>\n\n--vinfra-project <project>\n\nAlternatively, you can supply custom credentials by setting the following environment variables (for example, in your ~/.bash_profile): VINFRA_PORTAL, VINFRA_USERNAME, VINFRA_PASSWORD, VINFRA_DOMAIN, and VINFRA_PROJECT. In this case, you will be able to run the CLI tool without the aforementioned command-line parameters.\nAs you typically run vinfra from the management node as admin, the only variable you usually need to set is the password. For example:# export VINFRA_PASSWORD=12345\r\n\nIf you installed vinfra on a remote machine and/or run it as a different system administartor, you will need to set VINFRA_PORTAL and/or VINFRA_USERNAME on that machine in addition to VINFRA_PASSWORD.\nIn addition, if you want to authenticate within a different project or/and domain, you will need to set two more environment variables: VINFRA_PROJECT and/or VINFRA_DOMAIN.\nManaging vinfra tasks\nThe vinfra tool executes some commands immediately, while for other commands (that may take some time to complete) it creates system tasks that are queued. Examples of actions performed via tasks are creating the storage or compute cluster and adding nodes to it.\nTo keep track of tasks performed by vinfra, use the vinfra task list and vinfra task show commands. For example:# vinfra task list\r\n+----------------+---------+-----------------------------------------+\r\n| task_id        | state   | name                                    |\r\n+----------------+---------+-----------------------------------------+\r\n| 8fc27e7a-<...> | success | backend.tasks.cluster.CreateNewCluster  |\r\n| e61377db-<...> | success | backend.tasks.disks.ApplyDiskRoleTask   |\r\n| a005b748-<...> | success | backend.tasks.node.AddNodeInClusterTask |\r\n+----------------+---------+-----------------------------------------+\r\n# vinfra task show 8fc27e7a-ba73-471d-9134-e351e1137cf4\r\n+---------+----------------------------------------+\r\n| Field   | Value                                  |\r\n+---------+----------------------------------------+\r\n| args    | - stor1                                |\r\n|         | - 7ffa9540-5a20-41d1-b203-e3f349d62565 |\r\n|         | - null                                 |\r\n|         | - null                                 |\r\n| kwargs  | {}                                     |\r\n| name    | backend.tasks.cluster.CreateNewCluster |\r\n| result  | cluster_id: 1                          |\r\n| state   | success                                |\r\n| task_id | 8fc27e7a-ba73-471d-9134-e351e1137cf4   |\r\n+---------+----------------------------------------+\r\n\nWhat's next\n\nSetting up networks",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-the-command-line-interface.html"
    },
    {
        "title": "Querying user limits via REST API",
        "content": "Querying user limits via REST API\nYou can display the current limits with the ostor-limits service and parameter emailAddress specifying the email address:# s3_curl GET \"http://s3.example.com/?ostor-limits&emailAddress=client@example.com\"\r\n{\r\n    \"ops:default\": \"0.00\",\r\n    \"ops:get\": \"3600.00\",\r\n    \"ops:put\": \"0.00\",\r\n    \"ops:list\": \"0.00\",\r\n    \"ops:delete\": \"0.00\",\r\n    \"bandwidth:out\": \"100\"\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/querying-user-limits-via-rest-api.html"
    },
    {
        "title": "Setting quotas for users via CLI",
        "content": "Setting quotas for users via CLI\nYou can limit storage usage per user with the set-quotas command and the following parameters: -e specifying the email address or -i specifying the user ID, and -q specifying the usage limit in gigabytes:# ostor-s3-admin set-quotas -e user@example.com -q 1024 -V 0100000000000002\r\nversion: '1'\r\nsize: '1024'\r\ntype: 'user'# ostor-s3-admin set-quotas -i fa153230721eed05 -q 1024 -V 0100000000000002\r\nversion: '1'\r\nsize: '1024'\r\ntype: 'user'",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-quotas-for-users-via-cli.html"
    },
    {
        "title": "Deleting default quotas via REST API",
        "content": "Deleting default quotas via REST API\nYou can delete the current default quotas for all users or buckets with the ostor-quotas service and the following parameters: default specifying user for users or bucket for buckets:# s3_curl DELETE \"http://s3.example.com/?ostor-quotas&default=user\"\r\n# s3_curl DELETE \"http://s3.example.com/?ostor-quotas&default=bucket\"\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-default-quotas-via-rest-api.html"
    },
    {
        "title": "Managing S3 user and bucket quotas via CLI",
        "content": "Managing S3 user and bucket quotas via CLI\nThis section describes quotas you can define for S3 users and buckets via the command-line interface. These quotas limit object storage usage per user or per bucket. You can apply them to different users or buckets separately or set the default quotas to apply them to all S3 users and buckets by default.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/managing-s3-user-and-bucket-quotas-via-cli.html"
    },
    {
        "title": "Configuring memory for the storage services",
        "content": "Configuring memory for the storage services\nYou can configure memory limits and guarantees for the storage services at runtime by using the vinfra tool. You can do this for the entire cluster or a specific node.\nThe following memory parameters can be configured manually:\n\nMemory guarantee\nSwap size\nPage cache (which, in turn, is set using cache ratio, minimum, and maximum)\n\nPage cache is calculated according to the following formula:$PAGE_CACHE = minimum <= ratio * $TOTAL_MEMORY <= maximum\r\n\nThe minimum and maximum values are hard limits that are applied if the ratio * $TOTAL_MEMORY value is outside these limits.\nTo better understand how page cache size is calculated, consider the following examples:\n\n\u00a0\n\nExample 1\n(cache size is\r\nwithin limits)\n\nExample 2\n(cache size\r\nequals minimum)\n\nExample 3\n(cache size\r\nequals maximum)\n\nTotal memory\n4 GiB\n4 GiB\n4 GiB\n\nCache ratio\n0.5\n0.1\n0.9\n\nCache minimum\n1 GiB\n2 GiB\n1 GiB\n\nCache maximum\n3 GiB\n3 GiB\n3 GiB\n\nCache size\n2 GiB\n2 GiB\n3 GiB\n\nIf memory parameters are set both per node and per cluster, the per-node ones are applied. If no memory parameters are configured manually, the memory management is performed automatically by the vcmmd daemon as follows:\n\nEach CS (for example, storage disk) requires 512 MiB of RAM for page cache.\nThe page cache minimum is 1 GiB.\nIf the total memory is less than 48 GiB, the page cache maximum is calculated as two-thirds of it.\nIf the total memory is greater than 48 GiB, the page cache maximum is 32 GiB.\n\nTo check the current memory parameters for the storage services set by vcmmd, run:# vcmmdctl list\r\nname                                 type active guarantee    limit swap   cache\r\n<...>\r\nvstorage.slice/vstorage-services.sl\u00e2\u0080\u00a6 SRVC    yes   1310720 24522132    0 1048576\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-memory-for-the-storage-services.html"
    },
    {
        "title": "Considerations for using blade servers",
        "content": "Considerations for using blade servers\n\nGeneral requirements are listed in General requirements.\n\nWith the local storage (Virtuozzo Storage) as the default storage for compute volumes, we recommend using blade servers for Virtuozzo Hybrid Infrastructure installations if the blade configuration meets the general server requirements.  Note that the local storage requires three or more SSD/HDD drives per server and a 10+ Gbit/s network between storage servers. Blade servers, however, usually support only up to two drives. With the recommended system disk configuration when two SSD drives are combined in a software RAID mirror, no drives will be left for the local storage.\nYou can also use blade servers with the supported external storage, for example, Pure Storage or NFS, as the main storage for compute volumes. In this case, you need to ensure that network performance is good enough to work with the local and external storage, with at least 10 Gbit/s speed between blades participating in the storage cluster. Even with external storage, Virtuozzo Storage is a mandatory component for storing VM templates and some system components with the default storage policy.\nConsider the following three main use cases:\n\nUse case 1. Virtuozzo Hybrid Infrastructure with the local storage as the main storage based on blade servers with only two drives. This configuration is not recommended and cannot be used.\nUse case 2. Virtuozzo Hybrid Infrastructure with the local storage as the main storage based on storage blades or with at least three internal drives. This configuration is not recommended due to the limited number of storage options, but can be used. Some vendors support a special \"storage blade\" that can be attached to a \"compute blade\" and used as a disk chassis for additional 8-12 drives. In this case, there is enough storage to build software-defined storage (SDS) based on the blade storage only, without external storage.\nUse case 3. Virtuozzo Hybrid Infrastructure with external storage, for example, Pure Storage or NFS, as the main storage. Blade servers can be used as any other servers. All compute volumes should be stored on the external storage. You can sacrifice system reliability and use only one drive for the system, without RAID1, and the second drive as a storage disk for the default storage policy. Though this configuration is possible, it is not recommended as the loss of the single system disk will result in losing the entire node.\n\nSee also\n\nCompute cluster requirements\n\nQuantity of servers",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/considerations-for-using-blade-servers.html"
    },
    {
        "title": "Multitenancy",
        "content": "Multitenancy\nVirtuozzo Hybrid Infrastructure uses the administrative hierarchy of domains and projects (tenants) with Role-Based Access Control (RBAC) to manage virtual objects of the compute cluster, such as virtual machines, volumes, and virtual networks. A domain is an isolated container of projects  and users with assigned roles. Each project and user can only belong to one domain. A project is an isolated container of virtual objects with defined limits for virtual resources, such as vCPU, RAM, storage and floating IP addresses, and assigned users. A role is global and defines all of the possible tasks the user may perform at the level of the entire infrastructure, a specific domain, or project.\nAccording to these levels, there are three user roles in Virtuozzo Hybrid Infrastructure: a system administrator, a domain administrator, and a project member. The following chart shows typical users with these roles working at service providers and enterprises, along with their workspaces: admin or self-service panels.\n\nA system administrator can perform system administration tasks, depending on the assigned permissions and has access to the admin panel. This role also enables user and project management in the admin panel. Additionally, a system administrator with domain permissions can manage the Default domain in the self-service panel. \nSystem administrators are usually infrastructure administrators of an SP or MSP, or the main IT department of an enterprise, depending on your business case.\n\nA domain administrator is in charge of its domain in the self-service panel. A domain administrator can be assigned only to one domain and can manage virtual objects in all projects within this domain. This role also enables user and project management in the self-service panel. \nDomain administrators are usually system administrators of an SP's or MSP's client, or the IT department of an enterprise subsidiary, depending on your business case.\n\nA project member acts as a project administrator in a specific domain in the self-service panel. A project member can be assigned to multiple projects and can manage virtual objects in them.\nProject members are usually end users of an SP's or MSP's client, or end users in an enterprise, depending on your business case.\n\nSuch an implementation provides an administrative environment with its own users and virtual objects, and ensures their isolation from other users and virtual objects.\nSee also\n\nConfiguring multitenancy\n\nManaging domains, users, and projects",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/multitenancy.html"
    },
    {
        "title": "Securing root access to cluster nodes over SSH",
        "content": "Securing root access to cluster nodes over SSH\nIn certain situations, you or the technical support team may need root access to cluster nodes via SSH. We recommend using SSH keys as they are generally more secure than passwords. You can generate a key pair on a client from which you will connect to the nodes via SSH. The private key will be stored on the client. Make sure you do not share the private key with anyone for security reasons. The public key will need to be uploaded to Virtuozzo Hybrid Infrastructure.\nAfter the key is uploaded, you can access your cluster nodes by using the key authentication method with SSH. When connecting via SSH, follow these rules:\n\nDo not enable third-party repositories. Install third-party software only from the default repository.\nUse only commands allowed in the product documentation.\n\nTo create and upload a public key\n\nAdmin panel\n\nObtain an SSH public key from the technical support team, or generate an SSH key pair on a client by using the ssh-keygen utility:\n\nOpen the terminal and run the command:# ssh-keygen -t rsa\nAfter the following dialog appears, press Enter:Enter file in which to save the key (/home/user/.ssh/id_rsa):\nWhen prompted to enter a passphrase to secure the SSH connection, press Enter to skip this step:Enter passphrase (empty for no passphrase):\nThe key will be created with the following message:Your public key has been saved in /home/user/.ssh/id_rsa.pub.\r\nThe key fingerprint is:\r\n476:b2:a8:7f:08:b4:c0:af:81:25:7e:21:48:01:0e:98 user@localhost\r\n\r\nThe key's randomart image is:\r\n+---[RSA 3072]----+\r\n|            oo.o+|\r\n|           oo.o.+|\r\n|        . ..+E..=|\r\n|   .     ooB+o...|\r\n|  o . . So.o&    |\r\n|   = . o ..O O   |\r\n|    + . o = B o  |\r\n|     .   . + +   |\r\n|          .      |\r\n+----[SHA256]-----+\n\nRun the following command to display the public key:$ cat ~/.ssh/id_rsa.pub\n\nCopy the displayed key.\n\nGo to Settings > System settings > SSH keys, and then click Add.\n\nIn the Add SSH key window, paste the key, and then click Add.\n\nAlternatively, you can upload the SSH key to the admin panel by clicking Upload and selecting the public key from your local machine. By default, the generated public key is located in /root/.ssh/id_rsa.pub.\n\nCommand-line interface\nUse the following command:vinfra cluster sshkey add <file>\r\n\n\n<file>\n\nSSH public key file\n\nFor example, to add a public SSH key from the file id_rsa.pub to the list of trusted keys, run:# vinfra cluster sshkey add id_rsa.pub\nThe added SSH key will appear in the vinfra cluster sshkey list output:# vinfra cluster sshkey list\r\n+---------------------+----------------------------------+------------------+\r\n| id                  | key                              | label            |\r\n+---------------------+----------------------------------+------------------+\r\n| 8ccf7f1b-6a53-<...> | ssh-rsa AAAAB3NzaC1yc2EAAAA<...> | user@example.com |\r\n|                     | user@example.com                 |                  |\r\n+---------------------+----------------------------------+------------------+\r\n\n\nTo delete a public key\n\nAdmin panel\n\nGo to Settings > System settings > SSH keys.\nSelect the required SSH key, and then click Delete.\nClick Yes in the confirmation window.\n\nCommand-line interface\nUse the following command:vinfra cluster sshkey delete <sshkey>\r\n\n\n<sshkey>\n\nSSH key value\n\nFor example, to delete the SSH key with the ID 8ccf7f1b-6a53-4d74-99ce-c410d51a9921, run:# vinfra cluster sshkey delete 8ccf7f1b-6a53-4d74-99ce-c410d51a9921\n\nSee also\n\nBest practices for cluster security\n\nAccessing the admin panel via SSL\n\nEnabling data encryption",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster sshkey add <file>\r\n\n\n<file>\n\nSSH public key file\n\nFor example, to add a public SSH key from the file id_rsa.pub to the list of trusted keys, run:# vinfra cluster sshkey add id_rsa.pub\nThe added SSH key will appear in the vinfra cluster sshkey list output:# vinfra cluster sshkey list\r\n+---------------------+----------------------------------+------------------+\r\n| id                  | key                              | label            |\r\n+---------------------+----------------------------------+------------------+\r\n| 8ccf7f1b-6a53-<...> | ssh-rsa AAAAB3NzaC1yc2EAAAA<...> | user@example.com |\r\n|                     | user@example.com                 |                  |\r\n+---------------------+----------------------------------+------------------+\r\n\n",
                "title": "To create and upload a public key"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster sshkey delete <sshkey>\r\n\n\n<sshkey>\n\nSSH key value\n\nFor example, to delete the SSH key with the ID 8ccf7f1b-6a53-4d74-99ce-c410d51a9921, run:# vinfra cluster sshkey delete 8ccf7f1b-6a53-4d74-99ce-c410d51a9921\n",
                "title": "To delete a public key"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\n\nObtain an SSH public key from the technical support team, or generate an SSH key pair on a client by using the ssh-keygen utility:\n\n\nOpen the terminal and run the command:# ssh-keygen -t rsa\nAfter the following dialog appears, press Enter:Enter file in which to save the key (/home/user/.ssh/id_rsa):\nWhen prompted to enter a passphrase to secure the SSH connection, press Enter to skip this step:Enter passphrase (empty for no passphrase):\nThe key will be created with the following message:Your public key has been saved in /home/user/.ssh/id_rsa.pub.\r\nThe key fingerprint is:\r\n476:b2:a8:7f:08:b4:c0:af:81:25:7e:21:48:01:0e:98 user@localhost\r\n\r\nThe key's randomart image is:\r\n+---[RSA 3072]----+\r\n|            oo.o+|\r\n|           oo.o.+|\r\n|        . ..+E..=|\r\n|   .     ooB+o...|\r\n|  o . . So.o&    |\r\n|   = . o ..O O   |\r\n|    + . o = B o  |\r\n|     .   . + +   |\r\n|          .      |\r\n+----[SHA256]-----+\n\n\nRun the following command to display the public key:$ cat ~/.ssh/id_rsa.pub\n\nCopy the displayed key.\n\n\nGo to Settings > System settings > SSH keys, and then click Add.\n\nIn the Add SSH key window, paste the key, and then click Add.\n\n\n\n\nAlternatively, you can upload the SSH key to the admin panel by clicking Upload and selecting the public key from your local machine. By default, the generated public key is located in /root/.ssh/id_rsa.pub.\n\n\n",
                "title": "To create and upload a public key"
            },
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > SSH keys.\nSelect the required SSH key, and then click Delete.\nClick Yes in the confirmation window.\n\n",
                "title": "To delete a public key"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/securing-root-access-to-nodes.html"
    },
    {
        "title": "Your search for  returned  result(s).",
        "content": "\u00ef\u00bb\u00bf\n\nVirtuozzo Hybrid Infrastructure 6.2 \u00e2\u0080\u0093 Administrator Guide\n\n\r\n            Log Console\n\nSkip To Main Content\n Virtuozzo Hybrid Infrastructure\n\nAccount\nSettings\nLogout\n\nAll Files\n\nAll Files\n\nSubmit Search\n\nAdministrator Guide\n\nHome\n\nContents\n\nIndex\n\nBrowse\n\nCommunity\n\nSearch Filters\n\nAll Files\n\n Virtuozzo Hybrid InfrastructureAdministrator Guide\n\nAccount\nSettings\nLogout\n\n \n\n \n\n \n\n \n\n \n\nYour search for  returned  result(s).\nPreviousNext\n\n\r\n            Create Profile\r\n        \n\nUsername *\n\nEmail Address *\n\n\r\n                    Email Notifications\r\n                \n\r\n                    I want to receive an email when...\r\n                    a reply is left to one of my commentsa comment is left on a topic that I commented ona comment is left on any topic in the Help system\n\nSubmit\nCancel\n\nAn email has been sent to verify your new profile.Please fill out all required fields before submitting your information.\n\nFilter: ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/index.html"
    },
    {
        "title": "Logging in to the user panel",
        "content": "Logging in to the user panel\nTo log in to the Virtuozzo Hybrid Infrastructure user panel, do the following:\n\nOn any computer with access to the web interface, in a web browser visit http://<user_panel_IP_address>:8888/s3/.\n\nIf you use a self-signed certificate, add it to the browser\u00e2\u0080\u0099s exceptions.\n\nOn the login screen, enter your credentials, and then click Log in.\n\nIf logging in to the user panel fails, this can be caused by one of the following reasons:\n\nError: \"Network failure. Check your S3 endpoint or access protocol (HTTP/HTTPS).\"\n\nThe client is trying to access a bucket over HTTP. This does not work in most browsers, as parts of the web interface are served over HTTPS and mixed HTTP/HTTPS connections are forbidden. To solve the problem, access the service over HTTPS.\nThe client cannot resolve the DNS name associated with the service. In this case, add the mapping in your DNS. Alternatively, you can solve the problem by adding static mappings to the hosts file (/etc/hosts on Linux or %windir%\\System32\\drivers\\etc\\hosts on Windows); note that this needs to be done on all clients.\nThe service is using a self-signed or invalid SSL certificate. In this case, use a valid SSL certificate recognized by a certificate authority. Alternatively, you can temporarily solve the problem by pointing the browser to the service URL (for example, https://s3.example.com) and manually accepting the certificate; note that this only works on the client where the certificate has been manually accepted.\n\nError: \"Bad signature. Check your key and signing method.\"\n\nThe client or server time or timezone are incorrect.\nThe user credentials are incorrect.\nThe S3 user is disabled.\n\nOnce you log in to the web interface, you will see the Buckets screen with the list of your buckets. From here, you can manage buckets, as well as folders and files stored inside the buckets.\nTo log out, click the user icon in the upper right corner of any screen, and then click Log out.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_users_guide/logging-in-to-the-user-panel.html"
    },
    {
        "title": "Managing SSH keys",
        "content": "Managing SSH keys",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-ssh-keys.html"
    },
    {
        "title": "Managing placements",
        "content": "Managing placements\nMost high-level operations on placements (\u00e2\u0080\u009ctraits\u00e2\u0080\u009d in OpenStack terminology) involve multiple requests to multiple endpoints. This section lists steps required to perform each operation on a placement. Examples of each step are provided in linked subsections.\nCreate a placement:\n\nCreate a trait. Refer to Creating traits.\nCreate a host aggregate named after the trait. Refer to Creating host aggregates.\nAdd the trait to host aggregate\u00e2\u0080\u0099s metadata. Refer to Updating aggregate metadata.\n\nAdd a host to a placement:\n\nList resource providers and identify the one you need. Refer to Listing resource providers.\nAssociate the trait with the resource provider. Refer to Updating resource provider traits.\nAdd the host to the host aggregate associated with the trait. Refer to Adding hosts to aggregates.\n\nRemove a host from a placement:\n\nRemove the host from the host aggregate associated with the trait. Refer to Removing hosts from aggregates.\nDisassociate the trait from the resource provider. Refer to Updating resource provider traits.\n\nAdd an image to or remove an image from a placement:\n\nUpdate the image details. Refer to Updating images.\n\nList placements:\n\nList custom traits to identify the one you need. Refer to Listing traits.\nList host aggregates and find the one associated with the trait. Refer to Listing host aggregates.\nList images associated with the trait. Refer to Listing images.\n\nDelete a placement:\n\nRemove all hosts from the host aggregate associated with the trait. Refer to Removing hosts from aggregates.\nDelete the host aggregate. Refer to Deleting host aggregates.\nRemove the trait from details of images. Refer to Updating images.\nRemove the trait from resource providers. Refer to Updating resource provider traits.\nDelete the trait. Refer to Deleting traits.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/managing-placements.html"
    },
    {
        "title": "Listing public endpoints",
        "content": "Listing public endpoints\nEach request needs to be sent to the public endpoint of the appropriate service. You can obtain the list of public endpoints by sending a request to https://<node_IP_addr>:5000/v3/auth/catalog. For more readability, you can filter the response with the jq tool that is installed on each node by default.\nSample request:# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:5000/v3/auth/catalog | jq '.catalog[] | . as {\r\n   endpoints: $e,\r\n   name: $n\r\n} | $e[] | {\r\n   serviceName: $n,\r\n   publicEndpoint: select(.interface==\"public\").url\r\n}'\r\n\nSample response:{\r\n  \"serviceName\": \"keystone\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:5000/v3\"\r\n}\r\n{\r\n  \"serviceName\": \"glance\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:9292\"\r\n}\r\n{\r\n  \"serviceName\": \"cinderv2\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:8776/v2/f5d834d636c642c7bfe8af86139c6f26\"\r\n}\r\n{\r\n  \"serviceName\": \"cinderv3\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26\"\r\n}\r\n{\r\n  \"serviceName\": \"placement\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:8780\"\r\n}\r\n{\r\n  \"serviceName\": \"nova\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:8774/v2.1/f5d834d636c642c7bfe8af86139c6f26\"\r\n}\r\n{\r\n  \"serviceName\": \"neutron\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:9696\"\r\n}\r\n{\r\n  \"serviceName\": \"heat\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:8004/v1/f5d834d636c642c7bfe8af86139c6f26\"\r\n}\r\n{\r\n  \"serviceName\": \"barbican\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:9313\"\r\n}\r\n{\r\n  \"serviceName\": \"octavia\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:9888\"\r\n}\r\n{\r\n  \"serviceName\": \"magnum\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:9513/v1\"\r\n}\r\n{\r\n  \"serviceName\": \"gnocchi\",\r\n  \"publicEndpoint\": \"https://<node_IP_addr>:8041\"\r\n}\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/listing-public-endpoints.html"
    },
    {
        "title": "Copyright statement",
        "content": "Copyright statement\nCopyright \u00c2\u00a9 2016-2024 Virtuozzo International GmbH. All rights reserved.\nThis product is protected by United States and international copyright laws. The product\u00e2\u0080\u0099s underlying technology, patents, and trademarks are listed at https://virtuozzo.com.\nMicrosoft, Windows, Windows Server, Windows NT, Windows Vista, and MS-DOS are registered trademarks of Microsoft Corporation.\nApple, Mac, the Mac logo, Mac OS, iPad, iPhone, iPod touch, FaceTime HD camera and iSight are trademarks of Apple Inc., registered in the US and other countries.\nLinux is a registered trademark of Linus Torvalds. All other marks and names mentioned herein may be trademarks of their respective owners.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/copyright-vz.html"
    },
    {
        "title": "4. Troubleshooting\u00c2\u00b6",
        "content": "4. Troubleshooting | Hystax Acura Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\n1. Hystax Acura Overview\n2. Migration Steps\n2.1. Resource Planning and Configuration for VMware\n2.2. Deploying HVRAgent on VMware ESXi Hypervisor\n\n3. Providing Access to Hystax Acura Portal\n4. Troubleshooting\n5. Limitations\n\nHystax Acura Migration from VMwarePDF, 3477 KB\n\nPrev\nNext\n\n4. Troubleshooting\u00c2\u00b6\nHystax Acura automatically checks cloud access and the necessary permissions for assuring successful operation. It provides detailed error messages that describe their potential causes.\nIn case of an error, please check the correctness of the data entered and availability of the necessary permissions.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 14, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_migration_from_vmware/troubleshooting.html"
    },
    {
        "title": "Setting a password inside virtual machines",
        "content": "Setting a password inside virtual machines\nInstead of an SSH key, you can use a password of the default administrator, to access a virtual machine created from a template. To be able to set a password for a VM, you need to configure a template to allow password setting. By default, this possibility is enabled for all templates. However, VM password setting is not available unless a template has the default administrator created inside the guest OS and this user name is specified as a template property.\nSetting a password inside virtual machines is supported for both Linux and Windows guest operating systems.\nLimitations\n\nSetting passwords is only available for new virtual machines. Existing VMs that were created before enabling password setting for their template will stay unchanged.\nSystem administrators do not have the permission to set VM passwords in self-service projects where they have no administrative privileges.\n\nPrerequisites\n\nThe template that you want to enable password authentication for must be prepared, as instructed in Preparing templates, and it must have the default administrator account created.\nThe guest tools are installed inside a guest operating system, as described in Installing guest tools.\nTo authorize further OpenStack commands, the OpenStack command-line client must be configured, as outlined in Connecting to OpenStack command-line interface.\n\nTo enable password setting for a template\n\nFind out the ID of the required image by running:# openstack --insecure image list\r\n+--------------------------------------+--------------------------+--------+\r\n| ID                                   | Name                     | Status |\r\n+--------------------------------------+--------------------------+--------+\r\n| c6d4a56f-b0b9-4bf3-a641-5fea8f70bbb3 | centos8-with-guest-tools | active |\r\n| 5d10e5ee-9389-4a2f-838e-fe5ec915374e | cirros                   | active |\r\n+--------------------------------------+--------------------------+--------+\n\nFor the required template, set the hci_allow_set_password property to True and specify the default administrator name with the os_admin_user property. For example:# openstack --insecure image set --property hci_allow_set_password=True --property os_admin_user=centos \\\r\nc6d4a56f-b0b9-4bf3-a641-5fea8f70bbb3\n\nOn the Compute > Virtual machines > Images tab in the admin panel, you can check the newly set properties  on the template right pane. The Password setting property will be displayed as Yes, and the Default admin login property will show the default administrator name, which should be used when accessing VMs created from this template.\nTo set a password inside a virtual machine\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM.\nOn the VM right pane, click Set password.\n\nIn the Set password window, specify a password for the default administrator login. The password must meet the following complexity requirements:\n\nIt must be at least 12 characters long.\n\nIt must contain characters from all of the following categories:\n\nUppercase Latin letters\nLowercase Latin letters\nBase 10 digits (0 through 9)\nNon-alphanumeric characters (special characters)\n\nAlternatively, click Generate to automatically generate a random password and copy it to the clipboard.\n\nSave this password. After closing this window, the password will be hidden and unavailable for recovery.\n\nClick Set to set the specified password for the default administrator account inside the VM.\n\nOnce the password is injected inside the virtual machine, you can use it to log in to the guest operating system with the default admin login. The Default admin login is displayed on the VM right pane in the VM properties.\n\nCommand-line interface\nUse the following command:vinfra service compute server set [--password] <server>\n\n--password\n\nRequest the password from stdin. This option must be used separately from other options.\n<server>\n\nCompute server ID or name\n\nFor example, to set a password inside the virtual machine myvm, run:# vinfra service compute server set myvm --password\nSpecify the VM password when prompted. The password must meet the following complexity requirements:\n\nIt must be at least 12 characters long.\n\nIt must contain characters from all of the following categories:\n\nUppercase Latin letters\nLowercase Latin letters\nBase 10 digits (0 through 9)\nNon-alphanumeric characters (special characters)\n\nTo disable password setting for a template\n\nFind out the ID of the required image by running:# openstack --insecure image list\r\n+--------------------------------------+--------------------------+--------+\r\n| ID                                   | Name                     | Status |\r\n+--------------------------------------+--------------------------+--------+\r\n| c6d4a56f-b0b9-4bf3-a641-5fea8f70bbb3 | centos8-with-guest-tools | active |\r\n| 5d10e5ee-9389-4a2f-838e-fe5ec915374e | cirros                   | active |\r\n+--------------------------------------+--------------------------+--------+\n\nFor the required template, set the hci_allow_set_password property to False and unset the os_admin_user property. For example:# openstack --insecure image set --property hci_allow_set_password=False c6d4a56f-b0b9-4bf3-a641-5fea8f70bbb3\r\n# openstack --insecure image unset --property os_admin_user c6d4a56f-b0b9-4bf3-a641-5fea8f70bbb3\n\nOn the Compute > Virtual machines > Images tab in the admin panel, you can check that the Password setting and Default admin login properties  are not displayed on the template right pane.\nSee also\n\nManaging virtual machine power state\n\nReconfiguring virtual machines\n\nMigrating virtual machines\n\nShelving virtual machines\n\nWhat's next\n\nConnecting to virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server set [--password] <server>\n\n--password\n\nRequest the password from stdin. This option must be used separately from other options.\n<server>\n\nCompute server ID or name\n\nFor example, to set a password inside the virtual machine myvm, run:# vinfra service compute server set myvm --password\nSpecify the VM password when prompted. The password must meet the following complexity requirements:\n\nIt must be at least 12 characters long.\n\nIt must contain characters from all of the following categories:\n\nUppercase Latin letters\nLowercase Latin letters\nBase 10 digits (0 through 9)\nNon-alphanumeric characters (special characters)\n\n\n\n",
                "title": "To set a password inside a virtual machine"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM.\nOn the VM right pane, click Set password.\n\nIn the Set password window, specify a password for the default administrator login. The password must meet the following complexity requirements:\n\nIt must be at least 12 characters long.\n\nIt must contain characters from all of the following categories:\n\nUppercase Latin letters\nLowercase Latin letters\nBase 10 digits (0 through 9)\nNon-alphanumeric characters (special characters)\n\n\n\nAlternatively, click Generate to automatically generate a random password and copy it to the clipboard.\n\nSave this password. After closing this window, the password will be hidden and unavailable for recovery.\n\n\n\n\n\n\nClick Set to set the specified password for the default administrator account inside the VM.\n\nOnce the password is injected inside the virtual machine, you can use it to log in to the guest operating system with the default admin login. The Default admin login is displayed on the VM right pane in the VM properties.\n",
                "title": "To set a password inside a virtual machine"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/setting-password-inside-vms.html"
    },
    {
        "title": "Configuring RDMA automatically",
        "content": "Configuring RDMA automatically\nLimitations\n\nYou can only configure RDMA automatically before creating the storage cluster.\n\nPrerequisites\n\nYou have checked the RDMA network by following the instructions in Checking the RDMA network.\n\nTo configure RDMA automatically\n\nAdmin panel\nUse the Enable RDMA toggle switch on the Settings > System settings > Storage performance screen. \n\nCommand-line interface\nUse the following command:vinfra cses-config change (--enable | --disable)\n\n--enable\n\nEnable RDMA\n--disable\n\nDisable RDMA\n\nFor example, to enable RDMA for the storage cluster, run:# vinfra cses-config change --enable\nYou can check that the setting has been applied by running vinfra cses-config show:# vinfra cses-config show\r\n+-------+-------+\r\n| Field | Value |\r\n+-------+-------+\r\n| rdma  | True  |\r\n+-------+-------+\r\n\n\nWhat's next\n\nAdding external DNS servers",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cses-config change (--enable | --disable)\n\n--enable\n\nEnable RDMA\n--disable\n\nDisable RDMA\n\nFor example, to enable RDMA for the storage cluster, run:# vinfra cses-config change --enable\nYou can check that the setting has been applied by running vinfra cses-config show:# vinfra cses-config show\r\n+-------+-------+\r\n| Field | Value |\r\n+-------+-------+\r\n| rdma  | True  |\r\n+-------+-------+\r\n\n",
                "title": "To configure RDMA automatically"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\nUse the Enable RDMA toggle switch on the Settings > System settings > Storage performance screen. \n",
                "title": "To configure RDMA automatically"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-rdma-automatically.html"
    },
    {
        "title": "Creating the compute cluster",
        "content": "Creating the compute cluster\nLimitations\n\nThe compute cluster must have at least three nodes to allow self-service users to enable high availability for Kubernetes master nodes.\n\nThe compute cluster must have at least one physical network.\nYou can create only one untagged network over an infrastructure network.\nA physical network MTU cannot exceed that of the underlying network interface.\nAfter the default storage policy is created, its redundancy type cannot be changed.\n\nPrerequisites\n\nThe storage cluster has at least one disk with the Storage role.\n\nTo create the compute cluster\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that these traffic types are added to the networks you intend to use: VM private, VM public, Compute API, VM backups.\nOpen the Compute screen, and then click Create compute cluster.\n\nOn the Nodes step, select the nodes to add to the compute cluster. You can only select nodes with the Configured network state. Nodes in the management node high availability cluster are automatically selected to join the compute cluster. Then, click Next.\n\nOn the Physical network step, do the following:\n\nEnable or disable IP address management:\n\nWith IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.\nWith IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.\n\nIn any case, you will be able to manually assign static IP addresses from inside the VMs.\n\nProvide the required details for the physical network:\n\nSelect an infrastructure network to connect the physical network to.\nSelect the physical network type: select VLAN and specify a VLAN ID to create a VLAN-based network, or select Untagged to create a flat physical network.\nThe network MTU is set to 1500 by default. If required, you can adjust this value according to the MTU of the underlying network interface.\nIf you enabled IP address management, the subnet IP range in the CIDR format will be filled in automatically. Optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\nClick Next.\n\nThe selected physical network will appear in the list of compute networks on compute cluster\u00e2\u0080\u0099s Network tab. By default, it will be shared between all future projects. You can disable the network access on the network right pane later.\n\nIf you enabled IP address management, you will move on to the DHCP and DNS step, where you can configure the network settings for IP address management:\n\nEnable or disable the built-in DHCP server:\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\nOn the Add-on services step, enable the additional services that will be installed during the compute cluster deployment. You can also install these services later. Then, click Next.\n\nInstalling Kubernetes automatically installs the load balancer service as well.\n\nOn the Storage policy step, select a redundancy mode, storage tier, and failure domain for the default policy, which will be applied to uploaded images and base volumes created from these images. You can also use the default parameters, which include the first available storage tier, the host failure domain, and the best replication scheme allowed by the number of nodes in the storage cluster:\n\nThe 3 replicas mode is used if the storage cluster has three or more nodes.\nThe 2 replicas mode is used if the storage cluster has two nodes.\nThe No redundancy mode is used for a single-node deployment.\n\nTo discard your changes to the storage policy parameters and reset them to their defaults, click Reset to default parameters.\nThen, click Next.\n\nOn the Summary step, review the configuration, and then click Create cluster.\n\nYou can monitor compute cluster deployment on the Compute screen.\n\nCommand-line interface\nUse the following command:vinfra service compute create [--public-network <network>] [--subnet cidr=CIDR[,key=value,\u00e2\u0080\u00a6]]\r\n                              [--vlan-id <vlan-id>] [--mtu <mtu>] [--force] [--enable-k8saas]\r\n                              [--enable-lbaas] [--enable-metering] [--enable-backup]\r\n                              [--notification-forwarding <transport-url>] [--disable-notification-forwarding]\r\n                              [--default-storage-policy-tier {0,1,2,3}]\r\n                              [--default-storage-policy-replicas <norm>[:<min>] | --default-storage-policy-encoding <M>+<N>]\r\n                              [--default-storage-policy-failure-domain {0,1,2,3,4}] --nodes <nodes>\n\n--public-network <network>\n\nAn infrastructure network to connect the compute physical network to. It must include the \"VM public\" traffic type.\n--subnet cidr=CIDR[,key=value,\u00e2\u0080\u00a6]\n\nSubnet for IP address management in the compute physical network (the --public-network option is required):\n\ncidr: subnet range in CIDR notation;\ncomma-separated key=value pairs with keys (optional):gateway: gateway IP address.dhcp: enable/disable the virtual DHCP server.allocation-pool: allocation pool of IP addresses from CIDR in the format ip1-ip2, where ip1 and ip2 are starting and ending IP addresses. Specify the key multiple times to create multiple IP pools.dns-server: DNS server IP address, specify multiple times to set multiple DNS servers.\n\nExample: --subnet cidr=192.168.5.0/24,dhcp=enable.\n\n--vlan-id <vlan-id>\n\nCreate VLAN-based physical network by the given VLAN ID.\n--mtu <mtu>\n\nCustom MTU value for the compute physical network.\n--force\n\nSkip checks for minimal hardware requirements.\n--enable-k8saas\n\nEnable Kubernetes-as-a-Service services.\n--enable-lbaas\n\nEnable Load-Balancing-as-a-Service services.\n--enable-metering\n\nEnable metering services.\n--enable-backup\n\nEnable volume backup services.\n--notification-forwarding <transport-url>\n\nEnable notification forwarding through the specified transport URL in the format driver://[user:pass@]host:port[,[userN:passN@]hostN:portN], where:\n\ndriver is the supported transport driver (kafka, ampq, or rabbit)\nuser:pass are the username and password used for authentication with the messaging broker\nhost:port specifies the hostname or IP address and port number of the messaging broker\n\nMessages will be published to the \"notifications\" topic.\n\nExample: kafka://10.10.10.10:9092\n\n--disable-notification-forwarding\n\nDisable notification forwarding\n--default-storage-policy-tier {0,1,2,3}\n\nStorage tier\n--default-storage-policy-replicas <norm>[:<min>]\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\nmin: minimum required number of replicas (optional)\n\n--default-storage-policy-encoding <M>+<N>\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n--default-storage-policy-failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames.\n\nFor example, to create the compute cluster from five nodes that will use the infrastructure network Public with the IP address pool 10.94.129.64-10.94.129.79 to allocate to VMs, run:# vinfra service compute create --nodes node001,node002,node003,node004,node005 \\\r\n--public-network Public --subnet cidr=10.94.0.0/16,dhcp=enable,gateway=10.94.0.1,\\\r\nallocation-pool=10.94.129.64-10.94.129.79,dns-server=10.30.0.27\nYou can view the compute cluster details in the vinfra service compute show output:# vinfra service compute show\r\n+--------------+-----------------------------------------------------------------------------------------------------------------+\r\n| Field        | Value                                                                                                           |\r\n+--------------+-----------------------------------------------------------------------------------------------------------------+\r\n| capabilities | cpu_models:                                                                                                     |\r\n|              | - EPYC-IBPB                                                                                                     |\r\n|              | - Nehalem                                                                                                       |\r\n|              | - Nehalem-IBRS                                                                                                  |\r\n|              | - SandyBridge                                                                                                   |\r\n|              | - SandyBridge-IBRS                                                                                              |\r\n|              | - IvyBridge                                                                                                     |\r\n|              | - IvyBridge-IBRS                                                                                                |\r\n|              | - Haswell                                                                                                       |\r\n|              | - Haswell-IBRS                                                                                                  |\r\n|              | - Haswell-noTSX                                                                                                 |\r\n|              | - Haswell-noTSX-IBRS                                                                                            |\r\n|              | - Broadwell                                                                                                     |\r\n|              | - Broadwell-IBRS                                                                                                |\r\n|              | - Broadwell-noTSX                                                                                               |\r\n|              | - Broadwell-noTSX-IBRS                                                                                          |\r\n|              | - Skylake-Client                                                                                                |\r\n|              | - Skylake-Client-IBRS                                                                                           |\r\n|              | - Skylake-Server                                                                                                |\r\n|              | - Skylake-Server-IBRS                                                                                           |\r\n|              | - HostPassthrough                                                                                               |\r\n|              | k8saas_capabilities:                                                                                            |\r\n|              |   v1.18.6:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     release: v1.18                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.19.9                                                                                                   |\r\n|              |   v1.19.9:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://v1-19.docs.kubernetes.io/docs/setup/release/notes/#deprecation                       |\r\n|              |     release: v1.19                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.20.7                                                                                                   |\r\n|              |   v1.20.7:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://v1-20.docs.kubernetes.io/docs/setup/release/notes/#deprecation                       |\r\n|              |     release: v1.20                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.21.3                                                                                                   |\r\n|              |   v1.21.3:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.21.md#deprecation |\r\n|              |     release: v1.21                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.22.2                                                                                                   |\r\n|              |   v1.22.2:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.22.md#deprecation |\r\n|              |     release: v1.22                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.23.5                                                                                                   |\r\n|              |   v1.23.5:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md#deprecation |\r\n|              |     release: v1.23                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.24.3                                                                                                   |\r\n|              |   v1.24.3:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md#deprecation |\r\n|              |     release: v1.24                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.25.7                                                                                                   |\r\n|              |   v1.25.7:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.25.md#deprecation |\r\n|              |     release: v1.25                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.26.11                                                                                                  |\r\n|              |   v1.26.11:                                                                                                     |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.26.md#deprecation |\r\n|              |     release: v1.26                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.27.8                                                                                                   |\r\n|              |   v1.27.8:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.27.md#deprecation |\r\n|              |     release: v1.27                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.28.4                                                                                                   |\r\n|              |   v1.28.4:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.28.md#deprecation |\r\n|              |     release: v1.28                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.29.3                                                                                                   |\r\n|              |   v1.29.3:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#deprecation |\r\n|              |     release: v1.29                                                                                              |\r\n|              |     upgrade: []                                                                                                 |\r\n|              | k8saas_versions:                                                                                                |\r\n|              | - v1.29.3                                                                                                       |\r\n|              | - v1.28.4                                                                                                       |\r\n|              | - v1.27.8                                                                                                       |\r\n|              | - v1.26.11                                                                                                      |\r\n|              | - v1.25.7                                                                                                       |\r\n|              | - v1.24.3                                                                                                       |\r\n|              | os_distributions:                                                                                               |\r\n|              | - id: linux                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Generic Linux                                                                                          |\r\n|              | - id: rockylinux8                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Rocky Linux 8                                                                                          |\r\n|              | - id: rockylinux9                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Rocky Linux 9                                                                                          |\r\n|              | - id: almalinux8                                                                                                |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Alma Linux 8                                                                                           |\r\n|              | - id: almalinux9                                                                                                |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Alma Linux 9                                                                                           |\r\n|              | - id: centos8                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: CentOS 8                                                                                               |\r\n|              | - id: centos7                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: CentOS 7                                                                                               |\r\n|              | - id: centos6                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: CentOS 6                                                                                               |\r\n|              | - id: rhel9                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Red Hat Enterprise Linux 9                                                                             |\r\n|              | - id: rhel8                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Red Hat Enterprise Linux 8                                                                             |\r\n|              | - id: rhel7                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Red Hat Enterprise Linux 7                                                                             |\r\n|              | - id: ubuntu22.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 22.04                                                                                           |\r\n|              | - id: ubuntu20.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 20.04                                                                                           |\r\n|              | - id: ubuntu18.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 18.04                                                                                           |\r\n|              | - id: ubuntu16.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 16.04                                                                                           |\r\n|              | - id: debian10                                                                                                  |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Debian 10                                                                                              |\r\n|              | - id: debian9                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Debian 9                                                                                               |\r\n|              | - id: oracle7                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Oracle Linux 7                                                                                         |\r\n|              | - id: sles15                                                                                                    |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: SUSE Linux Enterprise 15                                                                               |\r\n|              | - id: windows                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Generic Windows                                                                                        |\r\n|              | - id: win2k22                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2022                                                                                    |\r\n|              | - id: win2k19                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2019                                                                                    |\r\n|              | - id: win2k16                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2016                                                                                    |\r\n|              | - id: win2k12r2                                                                                                 |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2012 R2                                                                                 |\r\n|              | - id: win2k12                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2012                                                                                    |\r\n|              | - id: win2k8r2                                                                                                  |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2008 R2                                                                                 |\r\n|              | - id: win2k8                                                                                                    |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2008                                                                                    |\r\n|              | - id: win10                                                                                                     |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows 10                                                                                             |\r\n|              | - id: win8.1                                                                                                    |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows 8.1                                                                                            |\r\n| features     | []                                                                                                              |\r\n| options      | cpu_model: ''                                                                                                   |\r\n|              | custom_params: []                                                                                               |\r\n|              | endpoint_hostname: 10.10.10.10                                                                                  |\r\n|              | notification_forwarding: disabled                                                                               |\r\n|              | scheduler:                                                                                                      |\r\n|              |   cpu_weight_multiplier: 1.0                                                                                    |\r\n|              |   metrics_weight_multiplier: 1.0                                                                                |\r\n|              |   metrics_weight_setting: {}                                                                                    |\r\n|              |   pci_weight_multiplier: 1.0                                                                                    |\r\n|              |   ram_weight_multiplier: 1.0                                                                                    |\r\n|              |   soft_anti_affinity_weight_multiplier: 5.0                                                                     |\r\n| status       | active                                                                                                          |\r\n| storages     | - vstorage                                                                                                      |\r\n+--------------+-----------------------------------------------------------------------------------------------------------------+\n\nSee also\n\nCreating virtual machines\n\nWhat's next\n\nSetting virtual machine CPU model",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute create [--public-network <network>] [--subnet cidr=CIDR[,key=value,\u00e2\u0080\u00a6]]\r\n                              [--vlan-id <vlan-id>] [--mtu <mtu>] [--force] [--enable-k8saas]\r\n                              [--enable-lbaas] [--enable-metering] [--enable-backup]\r\n                              [--notification-forwarding <transport-url>] [--disable-notification-forwarding]\r\n                              [--default-storage-policy-tier {0,1,2,3}]\r\n                              [--default-storage-policy-replicas <norm>[:<min>] | --default-storage-policy-encoding <M>+<N>]\r\n                              [--default-storage-policy-failure-domain {0,1,2,3,4}] --nodes <nodes>\n\n--public-network <network>\n\nAn infrastructure network to connect the compute physical network to. It must include the \"VM public\" traffic type.\n--subnet cidr=CIDR[,key=value,\u00e2\u0080\u00a6]\n\n\nSubnet for IP address management in the compute physical network (the --public-network option is required):\n\ncidr: subnet range in CIDR notation;\ncomma-separated key=value pairs with keys (optional):gateway: gateway IP address.dhcp: enable/disable the virtual DHCP server.allocation-pool: allocation pool of IP addresses from CIDR in the format ip1-ip2, where ip1 and ip2 are starting and ending IP addresses. Specify the key multiple times to create multiple IP pools.dns-server: DNS server IP address, specify multiple times to set multiple DNS servers.\n\nExample: --subnet cidr=192.168.5.0/24,dhcp=enable.\n\n--vlan-id <vlan-id>\n\nCreate VLAN-based physical network by the given VLAN ID.\n--mtu <mtu>\n\nCustom MTU value for the compute physical network.\n--force\n\nSkip checks for minimal hardware requirements.\n--enable-k8saas\n\nEnable Kubernetes-as-a-Service services.\n--enable-lbaas\n\nEnable Load-Balancing-as-a-Service services.\n--enable-metering\n\nEnable metering services.\n--enable-backup\n\nEnable volume backup services.\n--notification-forwarding <transport-url>\n\n\nEnable notification forwarding through the specified transport URL in the format driver://[user:pass@]host:port[,[userN:passN@]hostN:portN], where:\n\ndriver is the supported transport driver (kafka, ampq, or rabbit)\nuser:pass are the username and password used for authentication with the messaging broker\nhost:port specifies the hostname or IP address and port number of the messaging broker\n\n\nMessages will be published to the \"notifications\" topic.\n\nExample: kafka://10.10.10.10:9092\n\n--disable-notification-forwarding\n\nDisable notification forwarding\n--default-storage-policy-tier {0,1,2,3}\n\nStorage tier\n--default-storage-policy-replicas <norm>[:<min>]\n\n\nStorage replication mapping in the format:\n\nnorm: number of replicas to maintain\nmin: minimum required number of replicas (optional)\n\n\n--default-storage-policy-encoding <M>+<N>\n\n\nStorage erasure encoding mapping in the format:\n\nM: number of data blocks\nN: number of parity blocks\n\n\n--default-storage-policy-failure-domain {0,1,2,3,4}\n\nStorage failure domain\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames.\n\nFor example, to create the compute cluster from five nodes that will use the infrastructure network Public with the IP address pool 10.94.129.64-10.94.129.79 to allocate to VMs, run:# vinfra service compute create --nodes node001,node002,node003,node004,node005 \\\r\n--public-network Public --subnet cidr=10.94.0.0/16,dhcp=enable,gateway=10.94.0.1,\\\r\nallocation-pool=10.94.129.64-10.94.129.79,dns-server=10.30.0.27\nYou can view the compute cluster details in the vinfra service compute show output:# vinfra service compute show\r\n+--------------+-----------------------------------------------------------------------------------------------------------------+\r\n| Field        | Value                                                                                                           |\r\n+--------------+-----------------------------------------------------------------------------------------------------------------+\r\n| capabilities | cpu_models:                                                                                                     |\r\n|              | - EPYC-IBPB                                                                                                     |\r\n|              | - Nehalem                                                                                                       |\r\n|              | - Nehalem-IBRS                                                                                                  |\r\n|              | - SandyBridge                                                                                                   |\r\n|              | - SandyBridge-IBRS                                                                                              |\r\n|              | - IvyBridge                                                                                                     |\r\n|              | - IvyBridge-IBRS                                                                                                |\r\n|              | - Haswell                                                                                                       |\r\n|              | - Haswell-IBRS                                                                                                  |\r\n|              | - Haswell-noTSX                                                                                                 |\r\n|              | - Haswell-noTSX-IBRS                                                                                            |\r\n|              | - Broadwell                                                                                                     |\r\n|              | - Broadwell-IBRS                                                                                                |\r\n|              | - Broadwell-noTSX                                                                                               |\r\n|              | - Broadwell-noTSX-IBRS                                                                                          |\r\n|              | - Skylake-Client                                                                                                |\r\n|              | - Skylake-Client-IBRS                                                                                           |\r\n|              | - Skylake-Server                                                                                                |\r\n|              | - Skylake-Server-IBRS                                                                                           |\r\n|              | - HostPassthrough                                                                                               |\r\n|              | k8saas_capabilities:                                                                                            |\r\n|              |   v1.18.6:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     release: v1.18                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.19.9                                                                                                   |\r\n|              |   v1.19.9:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://v1-19.docs.kubernetes.io/docs/setup/release/notes/#deprecation                       |\r\n|              |     release: v1.19                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.20.7                                                                                                   |\r\n|              |   v1.20.7:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://v1-20.docs.kubernetes.io/docs/setup/release/notes/#deprecation                       |\r\n|              |     release: v1.20                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.21.3                                                                                                   |\r\n|              |   v1.21.3:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.21.md#deprecation |\r\n|              |     release: v1.21                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.22.2                                                                                                   |\r\n|              |   v1.22.2:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.22.md#deprecation |\r\n|              |     release: v1.22                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.23.5                                                                                                   |\r\n|              |   v1.23.5:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md#deprecation |\r\n|              |     release: v1.23                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.24.3                                                                                                   |\r\n|              |   v1.24.3:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md#deprecation |\r\n|              |     release: v1.24                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.25.7                                                                                                   |\r\n|              |   v1.25.7:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.25.md#deprecation |\r\n|              |     release: v1.25                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.26.11                                                                                                  |\r\n|              |   v1.26.11:                                                                                                     |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.26.md#deprecation |\r\n|              |     release: v1.26                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.27.8                                                                                                   |\r\n|              |   v1.27.8:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.27.md#deprecation |\r\n|              |     release: v1.27                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.28.4                                                                                                   |\r\n|              |   v1.28.4:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.28.md#deprecation |\r\n|              |     release: v1.28                                                                                              |\r\n|              |     upgrade:                                                                                                    |\r\n|              |     - v1.29.3                                                                                                   |\r\n|              |   v1.29.3:                                                                                                      |\r\n|              |     features:                                                                                                   |\r\n|              |     - nodegroups                                                                                                |\r\n|              |     links:                                                                                                      |\r\n|              |       deprecation: https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.29.md#deprecation |\r\n|              |     release: v1.29                                                                                              |\r\n|              |     upgrade: []                                                                                                 |\r\n|              | k8saas_versions:                                                                                                |\r\n|              | - v1.29.3                                                                                                       |\r\n|              | - v1.28.4                                                                                                       |\r\n|              | - v1.27.8                                                                                                       |\r\n|              | - v1.26.11                                                                                                      |\r\n|              | - v1.25.7                                                                                                       |\r\n|              | - v1.24.3                                                                                                       |\r\n|              | os_distributions:                                                                                               |\r\n|              | - id: linux                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Generic Linux                                                                                          |\r\n|              | - id: rockylinux8                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Rocky Linux 8                                                                                          |\r\n|              | - id: rockylinux9                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Rocky Linux 9                                                                                          |\r\n|              | - id: almalinux8                                                                                                |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Alma Linux 8                                                                                           |\r\n|              | - id: almalinux9                                                                                                |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Alma Linux 9                                                                                           |\r\n|              | - id: centos8                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: CentOS 8                                                                                               |\r\n|              | - id: centos7                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: CentOS 7                                                                                               |\r\n|              | - id: centos6                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: CentOS 6                                                                                               |\r\n|              | - id: rhel9                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Red Hat Enterprise Linux 9                                                                             |\r\n|              | - id: rhel8                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Red Hat Enterprise Linux 8                                                                             |\r\n|              | - id: rhel7                                                                                                     |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Red Hat Enterprise Linux 7                                                                             |\r\n|              | - id: ubuntu22.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 22.04                                                                                           |\r\n|              | - id: ubuntu20.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 20.04                                                                                           |\r\n|              | - id: ubuntu18.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 18.04                                                                                           |\r\n|              | - id: ubuntu16.04                                                                                               |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Ubuntu 16.04                                                                                           |\r\n|              | - id: debian10                                                                                                  |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Debian 10                                                                                              |\r\n|              | - id: debian9                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Debian 9                                                                                               |\r\n|              | - id: oracle7                                                                                                   |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: Oracle Linux 7                                                                                         |\r\n|              | - id: sles15                                                                                                    |\r\n|              |   os_type: linux                                                                                                |\r\n|              |   title: SUSE Linux Enterprise 15                                                                               |\r\n|              | - id: windows                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Generic Windows                                                                                        |\r\n|              | - id: win2k22                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2022                                                                                    |\r\n|              | - id: win2k19                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2019                                                                                    |\r\n|              | - id: win2k16                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2016                                                                                    |\r\n|              | - id: win2k12r2                                                                                                 |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2012 R2                                                                                 |\r\n|              | - id: win2k12                                                                                                   |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2012                                                                                    |\r\n|              | - id: win2k8r2                                                                                                  |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2008 R2                                                                                 |\r\n|              | - id: win2k8                                                                                                    |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows Server 2008                                                                                    |\r\n|              | - id: win10                                                                                                     |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows 10                                                                                             |\r\n|              | - id: win8.1                                                                                                    |\r\n|              |   os_type: windows                                                                                              |\r\n|              |   title: Windows 8.1                                                                                            |\r\n| features     | []                                                                                                              |\r\n| options      | cpu_model: ''                                                                                                   |\r\n|              | custom_params: []                                                                                               |\r\n|              | endpoint_hostname: 10.10.10.10                                                                                  |\r\n|              | notification_forwarding: disabled                                                                               |\r\n|              | scheduler:                                                                                                      |\r\n|              |   cpu_weight_multiplier: 1.0                                                                                    |\r\n|              |   metrics_weight_multiplier: 1.0                                                                                |\r\n|              |   metrics_weight_setting: {}                                                                                    |\r\n|              |   pci_weight_multiplier: 1.0                                                                                    |\r\n|              |   ram_weight_multiplier: 1.0                                                                                    |\r\n|              |   soft_anti_affinity_weight_multiplier: 5.0                                                                     |\r\n| status       | active                                                                                                          |\r\n| storages     | - vstorage                                                                                                      |\r\n+--------------+-----------------------------------------------------------------------------------------------------------------+\n",
                "title": "To create the compute cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that these traffic types are added to the networks you intend to use: VM private, VM public, Compute API, VM backups.\nOpen the Compute screen, and then click Create compute cluster.\n\nOn the Nodes step, select the nodes to add to the compute cluster. You can only select nodes with the Configured network state. Nodes in the management node high availability cluster are automatically selected to join the compute cluster. Then, click Next.\n\n\n\n\n\n\nOn the Physical network step, do the following:\n\n\nEnable or disable IP address management:\n\nWith IP address management enabled, VMs connected to the network will automatically be assigned IP addresses from allocation pools by the built-in DHCP server and use custom DNS servers. Additionally, spoofing protection will be enabled for all VM network ports by default. Each VM network interface will be able to accept and send IP packets only if it has IP and MAC addresses assigned. You can disable spoofing protection manually for a VM interface, if required.\nWith IP address management disabled, VMs connected to the network will obtain IP addresses from the DHCP servers in that network, if any. Also, spoofing protection will be disabled for all VM network ports, and you cannot enable it manually. This means that each VM network interface, with or without assigned IP and MAC addresses, will be able to accept and send IP packets.\n\nIn any case, you will be able to manually assign static IP addresses from inside the VMs.\n\n\nProvide the required details for the physical network:\n\nSelect an infrastructure network to connect the physical network to.\nSelect the physical network type: select VLAN and specify a VLAN ID to create a VLAN-based network, or select Untagged to create a flat physical network.\nThe network MTU is set to 1500 by default. If required, you can adjust this value according to the MTU of the underlying network interface.\nIf you enabled IP address management, the subnet IP range in the CIDR format will be filled in automatically. Optionally, specify a gateway. If you leave the Gateway field blank, the gateway will be omitted from network settings.\n\n\nClick Next.\n\n\n\n\n\nThe selected physical network will appear in the list of compute networks on compute cluster\u00e2\u0080\u0099s Network tab. By default, it will be shared between all future projects. You can disable the network access on the network right pane later.\n\n\nIf you enabled IP address management, you will move on to the DHCP and DNS step, where you can configure the network settings for IP address management:\n\n\nEnable or disable the built-in DHCP server:\n\n\nWith the DHCP server enabled, VM network interfaces will automatically be assigned IP addresses: either from allocation pools or, if there are no pools, from the network\u00e2\u0080\u0099s entire IP range. The DHCP server will receive the first two IP addresses from the IP pool. For example:\n\n In a subnet with CIDR 192.168.128.0/24 and without a gateway, the DHCP server will be assigned the IP addresses 192.168.128.1 and 192.168.128.2.\n In a subnet with CIDR 192.168.128.0/24 and the gateway IP address set to 192.168.128.1, the DHCP server will be assigned the IP addresses 192.168.128.2 and 192.168.128.3.\n\n\nWith the DHCP server disabled, VM network interfaces will still get IP addresses, but you will have to manually assign them inside VMs.\n\nThe virtual DHCP service will work only within the current network and will not be exposed to other networks.\n\nSpecify one or more allocation pools (ranges of IP addresses that will be automatically assigned to VMs).\nSpecify DNS servers that will be used by virtual machines. These servers can be delivered to VMs via the built-in DHCP server or by using the cloud-init network configuration (if cloud-init is installed in the VM).\nClick Add.\n\n\n\n\n\n\n\nOn the Add-on services step, enable the additional services that will be installed during the compute cluster deployment. You can also install these services later. Then, click Next.\n\nInstalling Kubernetes automatically installs the load balancer service as well.\n\n\n\n\n\n\n\nOn the Storage policy step, select a redundancy mode, storage tier, and failure domain for the default policy, which will be applied to uploaded images and base volumes created from these images. You can also use the default parameters, which include the first available storage tier, the host failure domain, and the best replication scheme allowed by the number of nodes in the storage cluster:\n\nThe 3 replicas mode is used if the storage cluster has three or more nodes.\nThe 2 replicas mode is used if the storage cluster has two nodes.\nThe No redundancy mode is used for a single-node deployment.\n\nTo discard your changes to the storage policy parameters and reset them to their defaults, click Reset to default parameters.\nThen, click Next.\n\n\n\n\n\nOn the Summary step, review the configuration, and then click Create cluster.\n\nYou can monitor compute cluster deployment on the Compute screen.\n",
                "title": "To create the compute cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-the-compute-cluster.html"
    },
    {
        "title": "Storage cluster architecture",
        "content": "Storage cluster architecture\nThe fundamental component of Virtuozzo Hybrid Infrastructure is a storage cluster, a group of physical servers interconnected by the network. The core storage comprises server disks, which are assigned one or more roles. Typically, each server in the cluster runs core storage services that correspond to the following disk roles:\n\nMetadata\n\nMetadata nodes run metadata services (MDS), store cluster metadata, and control how user files are split into chunks and where these chunks are located. Metadata nodes also ensure that chunks have the required amount of replicas. Finally, they log all important events that happen in the cluster. To provide system reliability, Virtuozzo Hybrid Infrastructure uses the Paxos consensus algorithm. It guarantees fault-tolerance if the majority of nodes running metadata services are healthy. \nTo ensure high availability of metadata in a production environment, metadata services must be run on at least three cluster nodes. In this case, if one metadata service fails, the remaining two will still be controlling the cluster. However, it is recommended to have maximum five metadata services in a cluster, to ensure that the cluster can survive simultaneous failure of two nodes and without data loss.\nThe primary metadata node is the master node in the metadata quorum. If the master MDS fails, another available MDS is selected as master.\n\nStorage\n\nStorage nodes run chunk services (CS), store all data in the form of fixed-size chunks, and provide access to these chunks. All data chunks are replicated and the replicas are kept on different storage nodes to achieve high availability of data. If one of the storage nodes fails, the remaining healthy storage nodes continue providing the data chunks that were stored on the failed node. The storage role can only be assigned to a server with disks of a certain capacity.\nStorage nodes can also benefit from data caching and checksumming:\n\nData caching improves cluster performance by placing frequently accessed data on an SSD.\n\nData checksumming generates checksums each time some data in the cluster is modified. When this data is then read, a new checksum is computed and compared with the old checksum. If the two are not identical, a read operation is performed again, thus providing better data reliability and integrity.\nIf a node has an SSD, it will be automatically configured to keep checksums when you add a node to a cluster. This is the recommended setup. However, if a node does not have an SSD drive, checksums will be stored on a rotational disk by default. It means that this disk will have to handle double the I/O, because for each data read/write operation there will be a corresponding checksum read/write operation. For this reason, you may want to disable checksumming on nodes without SSDs to gain performance at the expense of checksums. This can be especially useful for hot data storage.\n\nSupplementary roles:\n\nCache\r\n                        \n\nBoosts chunk read/write performance by creating write caches on selected solid-state drives (SSDs). It is also recommended to use such SSDs for metadata. The use of write journals may more than double the write speed in the cluster.\n\nSystem\r\n                        \n\nOne disk per node that is reserved for the operating system and unavailable for data storage.\nNote the following:\n\nThe System role cannot be unassigned from a disk. \n\nIf a physical server has a system disk with the capacity greater than 100 GB, that disk can be additionally assigned the Metadata or Storage role.\nIt is recommended to assign the System+Metadata role to an SSD. Assigning both of these roles to an HDD will result in mediocre performance suitable only for cold data (for example, archiving).\nThe System role cannot be combined with the Cache and Metadata+Cache roles. The reason is that the I/O generated by the operating system and applications would contend with the I/O generated by journaling, thus negating its performance benefits.\n\nAlong with the core storage services, servers run storage access points that allow top-level virtualization and storage services to access the storage cluster.\n\nIn addition, a server joined to the storage cluster can run neither metadata nor chunk services. In this case, the node will run only storage access points and serve as a storage cluster client.\nSee also\n\nStorage cache architecture",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/storage-cluster-architecture.html"
    },
    {
        "title": "Prometheus metrics",
        "content": "Prometheus metrics\nVirtuozzo Hybrid Infrastructure uses three types of metrics in Prometheus:\n\nCounter metrics (usually, with the \"_total\" suffix) are cumulative and increase over time\nGauge metrics show fluctuating values\nHistogram metrics are cumulative and store measurements in different buckets depending on the measurement value:Metrics with the \"_bucket\" suffix show the current value per bucketMetrics with the \"_sum\" suffix show the total sum of all values per bucketMetrics with the \"_count\" suffix show the number of stored measurements per bucket",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/prometheus-metrics.html"
    },
    {
        "title": "Monitoring the cluster remotely",
        "content": "Monitoring the cluster remotely\nYou can monitor your storage cluster remotely via the built-in Prometheus and Alertmanager monitoring toolkit. The built-in Prometheus server stores collected information for seven days. If you want to store metric values for a longer period, use an external Prometheus server. Alertmanager handles alerts generated by the Prometheus alerting rules. It can also be configured to send notifications to external systems, such as PagerDuty.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-the-cluster-remotely.html"
    },
    {
        "title": "Adding backup locations to Acronis Cyber Protect and Acronis Cyber Protect Cloud",
        "content": "Adding backup locations to Acronis Cyber Protect and Acronis Cyber Protect Cloud\nPrerequisites\n\nThe backup storage is created by following the instructions in Creating backup storage on the local cluster, Creating backup storage on an external NFS share, or Creating backup storage in a public cloud.\n\nTo create a new customer and assign the new backup destination in Acronis Cyber Protect Cloud\n\nLog in to the Acronis Cyber Protect Cloud management console. \nNavigate to Settings > Locations. Ensure the system created a new backup destination with the corresponding name derived from the DNS name. \nCreate a new customer account: Click New in the upper-right corner and select Customer. Provide the customer general information: name, mode and language. Then specify customer\u00e2\u0080\u0099s email, language, first and last names for an administrator account. Select services that you would like to provide to the new customer. Specify the customer\u00e2\u0080\u0099s devices and workloads, such as servers and workstations. In the section Location, click the current location name to display all the available options. Select the required storage. Click Done to complete the whole process.\nTo confirm your account, check your email and follow the steps in the activation request.\n\nTo configure backups in Acronis Cyber Protect Cloud or Acronis Cyber Protect\n\nLog in to Acronis Cyber Protect Cloud as the administrator.\n Open the Clients screen. Click the created customer, and then click Manage service on the Overview screen. The customer\u00e2\u0080\u0099s Cyber Backup Management Console will open.\nOn the Devices screen, click Add on the toolbar. Select the device you want to add. The backup agent installer will be downloaded.\nIn the backup agent installer: Click Install. On the Almost done\u00e2\u0080\u00a6 screen, click Register the machine. Enter the device registration info and confirm it. Ensure you are using the customer\u00e2\u0080\u0099s account you\u00e2\u0080\u0099ve created: check the user in the upper-right corner. \n\nWhen the registration is complete, the added device will be displayed on the Devices > All devices screen of the customer\u00e2\u0080\u0099s Backup Management Console.\nWhat's next\n\nManaging Acronis Backup Storage\n\nMonitoring Acronis Backup Storage",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/adding-backup-locations.html"
    },
    {
        "title": "3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nAt this stage we will log in to our Acura Service Project, create an overlay network and a router which will be configured to enable SNAT for the Acura Instance. We will then have the necessary resources to deploy the Hystax Acura migration Solution and assign a Floating IP to the instance.\n\nLogin to the Acura Service Project from the self-service portal using the URL https://fqdn:8800.\n\nCreate a Network. This will be a virtual network, which later will be attached to the Hystax Acura Solution instance. Networks > Create Virtual Network. We will name this network vm-network in this example.\n\nCreate a Router. This router will Allow us to provide SNAT (Outbound access) to the Hystax Acura Solution instance.  Please note how we connect the physical external network named \u00e2\u0080\u009cpublic\u00e2\u0080\u009d with the newly created virtual network named vm-network.\n\nDeploy an instance using the Hystax Acura golden image downloaded. Remember to attach a keypair, this will grant you access to the Acura instance. Create the instance with the following info:\n\n8 vCPUs, 16 GB RAM, 100 GB disk (Xlarge flavour).\nImage Hystax_Acura_VA_MGR_Virtuozzo_X_XXX\nUse the Default Security Group.\nImage Hystax_Acura_VA_MGR_Virtuozzo_X_XX\nAdd a network interface, in this case we will add the vm-network to this instance.\nAdd your SSH key pair to the instance.\n\nNote\nAdding a key pair is highly recommended to provide you with SSH access to the machine. Although Hystax Engineering team will be able to perform maintenance checks and troubleshooting (as long as the network is reachable and your security groups allow the corresponding traffic), it is better to have your own means of accessing the Acura instance.\n\nIt takes from 10 to 20 minutes for the services to start and the Web UI to become available.\n\nAssing a floating IP to the newly created Hystax Acura instance. Logged to the self-service portal https://your-fqdn-vhi.com:8800. And login to the Acura Service domain using the user defined for this domain. Go to Floating IPs, click on add. Note that we are using Private IPs, but in a real scenario this should be a Public IP.\n\nTroubleshooting tip: The web UI for the Hystax Acura Solution instance, will take from 10 to 20 minutes to bring all the services up. Hystax Acura uses Kubernetes to manage the services inside the instance. If after 20 minutes you still have no access to the web UI, SSH in to the Acura instance and check the status of the services. SSH with the user \u00e2\u0080\u009cuser\u00e2\u0080\u009d and execute the command kubectl get pods (This command will gather information about pod(services) status). When you see all the pods in Running status (except for four that will be in completed status) the web UI will be available.\n\nIf after 20 minutes, instead of getting the pod status you get a connection refused message, please contact us.\n\nOpen a web browser and go to https://<ip_address of the machine>/. You will be redirected to the Hystax Setup Wizard. After you perform all the steps, the installation will be complete, and you will be able to start using Hystax Acura.\n\nStep 1: Enter the organization name, you can enter here your company name, this step creates the login user and password and associates it to whatever organization name you wish to provide. Add the Admin user login and Password. This will be the user account for logging in to Hystax Acura Control Panel and managing the system. If there are any errors, the system will notify you.\n\nStep 2: Fill in your Hystax License key that was supposed to be shared with you in advance as well as the settings for accessing your mail server, which will be used to send notifications from Acura and generate periodic reports.\n\nNote\nSMTP server with TLS/SSL encryption is required to proceed with deployment.\n\nIf you prefer a public SMTP server associated with your email address (gmail, yahoo etc.), please find its settings online. In the case of a private SMTP server, contact your network administrator for further details.\nA sample notification will be sent to the specified \u00e2\u0080\u009cTest email\u00e2\u0080\u009d to verify the functionality when you click \u00e2\u0080\u009cNext\u00e2\u0080\u009d.\n\nStep 3: Fill in all the fields by providing cloud configuration details. Use question mark icons to get hints on the fields. After you click \u00e2\u0080\u009cNext\u00e2\u0080\u009d, the Setup Wizard will validate the entered data and notify you in case of an error.\n\nStep 3 of the configuration wizard goal, is to configure what we refer to as target cloud. We are configuring our customer target project, where the replicated workloads will be migrated to.\n\nThe Keystone API endpoint URL, is the fqdn of your Virtuozzo Hybrid infrastructure Admin panel listening on port 5000 (make sure the compute API traffic type is on the public network) will be used to authenticate for authentication.\nUser Domain, this field refers to the domain name the user is part of. Remember in our example, the domain for our customer is Ringo-Cloud then we created the project named migration-infra and a user migration-user which was assigned to the project and belongs to the Ringo-Cloud domain.\nUsername, the user we created an associated to the target project migration-infra as Project Member. In this case the user is migration-user.\nTarget Project Domain, this is the customer domain, the same as the User Domain and is the domain where we created the project. In our example the name is Ringo-Cloud.\nTarget Project ID, the UID for the project migration-project. The Target project ID, can be found by logging in to your Virtuozzo Hybrid Infrastructure Admin Panel > Projects and Users > Click on the Domain > Click on the Target Project and the ID will be visible on the left-hand side sliding panel that will appear.\n\nHystax Service Network, Network that will be used for Hystax Cloud Agent machines. Should be the same or routable to the network in which a Hystax Acura instance is located. In our case we have already prepared a physical external network type named public for this purpose in previous steps.\nFloating IP network, this is the name of the network you wish to use to provide floating IPs to your migrated instances. In our case is the same physical external network named public.\nHystax Acura Control Panel Public IP, Public IP that will be used to access the Hystax Control Panel via web browser and by replication agents.\nAdditional Parameters, add additional parameters to customize integration.\n\nExample information gathering form:\n\nField\nDescription\nExample\n\nKeystone API Endpoint\nVHI Keystone Auth URL\nhttp://fqdn-vhi-admin-panel:5000/v3\n\nUser Domain\nUser domain name to access VHI\nRingo-Cloud\n\nUsername\nUsername to access VHI Project\nmigration-user\n\nPassword\nPassword to access VHI\npassword\n\nTarget Project Domain\nTarget VHI project domain name\nRingo-Cloud\n\nTarget Project ID*\nTarget VHI project ID where replicated workloads will be spun up\nc57dd14c08bc4d6780ab17\n87774fd6e8\n\nHystax Service Network\nNetwork that will be used for Hystax Cloud Agent machines.\npublic\n\nFloating IP Network\nExternal network that will be used to attach Floating IPs to migrated machines\npublic\n\nHystax Acura Control Panel Public IP\nPublic IP that will be used to access the Hystax Control Panel via web browser and by replication agents\nPublic IP\n\nAdditional Parameters\n\np2v - Sets type of Physical to Virtual to integration (Virtuozzo)\nExtends cloud site timeout (adds support for virtuozzo cinder (vstorage))\n\n{\u00e2\u0080\u009cp2v_type\u00e2\u0080\u009d: \u00e2\u0080\u009cvirtuozzo\u00e2\u0080\u009d, \u00e2\u0080\u009ccloud_site_timeout_min\u00e2\u0080\u009d: 2880}\n\nThe specified Virtuozzo Hybrid Infrastructure Platform user should have the following rights for Hystax Acura to operate correctly.\n\nImport image\nLaunch instance\nCreate volume\nAttach volume to instance\nDetach volume from instance\nCreate volume snapshot\nCreate volume from snapshot\nRemove snapshot\nRemove volume\nManage networks\n\nThe user we created had the assigned role \u00e2\u0080\u009cProject Member\u00e2\u0080\u009d which include all of the above.\n\nStep 4: Installation is complete, and you can now log in to the system using credentials entered in the previous step.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/installation-steps/deploying-hystax-acura.html"
    },
    {
        "title": "Configuring data-in-transit encryption",
        "content": "Configuring data-in-transit encryption\nTo protect networks against eavesdropping attacks and traffic hijacking, Virtuozzo Hybrid Infrastructure supports data-in-transit encryption between cluster nodes. Data transmitted over a network is encrypted by using the AES-128 standard. Data-in-transit encryption is implemented via the IP Security (IPsec) protocol in transport mode. Authentication is based on X.509 certificates, which are installed on nodes during registration when installing the product, or during an upgrade to version 5.2 and later. Node certificates are rotated automatically once per year.\nBy default, data-in-transit encryption is disabled. You can enable it for an infrastructure network to encrypt all traffic that moves between cluster nodes in this subnet.\n\nIf you have services that operate in the same subnet and exchange data externally, you need to add exceptions for them. In this case, a particular IP address, prefix, or port added to the exceptions will bypass the encryption.\n\nWhen encryption is enabled for a network, the following traffic types bypass data-in-transit encryption if they are assigned to this network:\n\nBackup (ABGW) private (this traffic is encrypted by default with the TLS protocol)\nCompute API\n\nSSH\n\niSCSI\n\nS3 public\n\nBackup (ABGW) public\n\nAdmin panel\n\nNFS\n\nVM public\n\nSelf-service panel\n\nSNMP\n\nCustom traffic types\n\nTherefore, data-in-transit encryption only applies to the following exclusive traffic : Internal management, Storage, OSTOR private, VM private, and VM backups. When encryption is enabled for a network with the Storage traffic type, internal IP addresses of the storage services are automatically reconfigured to the IPv6 mode.\nLimitations\n\nYou cannot reassign the Storage traffic type from an encrypted network to an unencrypted one. You can either disable encryption for the source network or enable it for the target network, and then proceed to the traffic type reassignment.\nWith data-in-transit encryption enabled, the iSCSI service has degraded write I/O performance, which may decrease by half, compared to clusters with encryption disabled.\n\nSee also\n\nManaging networks\n\nConfiguring inbound firewall rules\n\nConfiguring outbound firewall rules",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-data-in-transit-encryption.html"
    },
    {
        "title": "Connecting to the server via VNC",
        "content": "Connecting to the server via VNC\nTo configure the server for VNC connection\n\nBoot from the installation media and wait for the Welcome screen.\nSelect Install Virtuozzo Hybrid Infrastructure and press E to edit the menu entry.\n\nAdd text at the end of the line starting with linux /images/pxeboot/vmlinuz. For example:linux /images/pxeboot/vmlinuz inst.stage2=hd:LABEL=<ISO_img> quiet ip=dhcp logo.nologo=1 text\r\n\n\nPress Ctrl+X to start booting the chosen installation option.\n\nChoose to start VNC by pressing 1 and then Enter.\n\nEnter a VNC password twice and press Enter.\n\nIn the output that follows, look up the hostname or IP address and VNC port of the server. For example:\n\nTo connect to the server from a remote machine\n\nOn the remote machine, install a VNC client of your choice (for example, TigerVNC Viewer) and launch it.\n\nSpecify the server address and the VNC port, and then click Connect.\n \n\nAfter the VNC client connects to the server, enter the VNC password and click OK. \n\nA new window with the established VNC connection will open, where you can proceed to install Virtuozzo Hybrid Infrastructure by using the graphical user interface.\nWhat's next\n\nInstalling in the attended mode",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/connecting-via-vnc.html"
    },
    {
        "title": "Enabling data encryption",
        "content": "Enabling data encryption\nVirtuozzo Hybrid Infrastructure can encrypt data stored on disks by using the AES-256 standard, so if a disk gets lost or stolen the data will be safe. Virtuozzo Hybrid Infrastructure stores disk encryption keys in cluster\u00e2\u0080\u0099s metadata (MDS).\nEncryption can be enabled or disabled only for the newly created chunk services (CS). Once tier encryption is enabled, you can decrypt disks (CSs) by manually releasing them from encrypted tiers. Correspondingly, simply enabling encryption on the disk\u00e2\u0080\u0099s tier will not encrypt its data (CS). To encrypt a disk, you must assign it to an encrypted tier.\nLimitations\n\nVirtuozzo Hybrid Infrastructure does not encrypt data transmitted over the internal network.\nEnabled encryption slightly decreases performance.\n\nTo enable tier encryption\n\nAdmin panel\n\nGo to Settings > System settings > Storage encryption.\nTurn on the toggle switch Enable AES-256 encryption for data stored on disks.\n\nSelect the tiers that you want to encrypt, and then click Save.\n\nCommand-line interface\nUse the following command:vinfra cluster settings encryption set [--tier-enable {0,1,2,3}] [--tier-disable {0,1,2,3}]\r\n\n\n--tier-enable {0,1,2,3}\n\nEnable encryption for storage tiers. This option can be used multiple times.\n--tier-disable {0,1,2,3}\n\nDisable encryption for storage tiers. This option can be used multiple times.\n\nFor example, to enable encryption for the storage tier 2, run:# vinfra cluster settings encryption set --tier-enable 2\nYou can view the encryption status of each storage tier in the vinfra cluster settings encryption show output:# vinfra cluster settings encryption show\r\n+-------+-------+\r\n| Field | Value |\r\n+-------+-------+\r\n| tier0 | False |\r\n| tier1 | False |\r\n| tier2 | True  |\r\n| tier3 | False |\r\n+-------+-------+\r\n\n\nSee also\n\nBest practices for cluster security\n\nAccessing the admin panel via SSL\n\nSecuring root access to cluster nodes over SSH",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra cluster settings encryption set [--tier-enable {0,1,2,3}] [--tier-disable {0,1,2,3}]\r\n\n\n--tier-enable {0,1,2,3}\n\nEnable encryption for storage tiers. This option can be used multiple times.\n--tier-disable {0,1,2,3}\n\nDisable encryption for storage tiers. This option can be used multiple times.\n\nFor example, to enable encryption for the storage tier 2, run:# vinfra cluster settings encryption set --tier-enable 2\nYou can view the encryption status of each storage tier in the vinfra cluster settings encryption show output:# vinfra cluster settings encryption show\r\n+-------+-------+\r\n| Field | Value |\r\n+-------+-------+\r\n| tier0 | False |\r\n| tier1 | False |\r\n| tier2 | True  |\r\n| tier3 | False |\r\n+-------+-------+\r\n\n",
                "title": "To enable tier encryption"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nGo to Settings > System settings > Storage encryption.\nTurn on the toggle switch Enable AES-256 encryption for data stored on disks.\n\nSelect the tiers that you want to encrypt, and then click Save.\n\n\n\n\n\n\n",
                "title": "To enable tier encryption"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/enabling-data-encryption.html"
    },
    {
        "title": "Using network QoS policies",
        "content": "Using network QoS policies\nYou can use quality of service (QoS) policies to guarantee or limit network bandwidth for egress and ingress VM traffic in different projects. QoS policies can be applied to separate network ports and floating IP addresses, as well as to entire networks. In addition,  you can set a QoS policy as default for a project to automatically assign the policy to all new networks created within the project. The default QoS policy will be applied to a network if no other policy is explicitly assigned during the network creation process.\nWhen you assign a policy to a network, all ports connected to this network inherit the policy unless the port has a specific policy assigned to it. The assigned policy is applied to both existing and new virtual machines. Internal network ports, like DHCP, and internal router ports are excluded from network policy application.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-network-qos-policies.html"
    },
    {
        "title": "Using Alertmanager for notifications",
        "content": "Using Alertmanager for notifications\nTo configure the built-in Alertmanager to send notifications, you need to open a TCP port for the Alertmanager API to be accessible from the outside.\nTo open a port for the Alertmanager API\n\nOn the Infrastructure > Networks screen, click Edit and then Create traffic type.\n\nIn the Create traffic type window, specify a custom name in the Name field and 9093 in the Port field. Then, click Create.\n\nClick Assign to networks next to the Custom traffic types section, and then add the created traffic type to your public network by selecting the corresponding check box.\nClick Save to apply the changes.\n\nYou can now access the Alertmanager API at http://<admin_panel_IP_address>:9093. For more information on configuring Alertmanager, refer to its documentation.\nSee also\n\nUsing external Prometheus for monitoring\n\nConfiguring retention policy for Prometheus metrics\n\nPrometheus metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-alertmanager-for-notifications.html"
    },
    {
        "title": "Using Filebeat for log forwarding",
        "content": "Using Filebeat for log forwarding\nCluster logs cannot be stored on nodes for a long period of time due to log rotation and limited storage space. Their retention period may be insufficient for troubleshooting purposes. You can use the built-in Filebeat service to forward log data to a centralized log management system. Filebeat monitors the predefined log files on all cluster nodes or a particular node, collects log events, and then sends them to a specific destination. By default, Filebeat is configured to work with Elasticsearch. You can, however, create a custom configuration for Filebeat to work with other log management systems, such as Logstash, Kafka, or Redis.\nThe Filebeat service is disabled by default. To start using it, you need to enable it first.\nTo configure Filebeat for Elasticsearch\nUse the following command:vinfra cluster filebeat config set --elasticsearch [--host <host>] [--port <port>] [--username <username>]\r\n                                   [--password <password>] [--ca_cert <ca_cert>] [--cert <cert>]\r\n                                   [--key <key>] [--nodes <nodes> | --all]\n\n--elasticsearch\n\nSet options for the predefined Filebeat configuration (Elasticsearch template)\n--host <host>\n\nElasticsearch hostname or IP address\n--port <port>\n\nElasticsearch port (default is 9200)\n--username <username>\n\nElasticsearch username\n--password <password>\n\nElasticsearch password\n--ca_cert <ca_cert>\n\nPath to CA certificate\n--cert <cert>\n\nPath to client certificate\n--key <key>\n\nPath to certificate key\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--all\n\nApply the configuration on all cluster nodes\n\nFor example, to configure Filebeat to forward logs from all cluster nodes to the Elasticsearch server with the IP address 10.10.10.10, run:# vinfra cluster filebeat config set --all --elasticsearch --host 10.10.10.10 --username root --password password\nTo configure Filebeat for other destinations\n\nCreate a custom Filebeat configuration file. For example, to configure Filebeat to forward the audit log from the management node node001 to the Logstash server with the IP address 10.10.10.10, update the /etc/filebeat/filebeat.yml file as follows:# cat > /etc/filebeat/filebeat.yml <<\\EOT \r\nfilebeat.inputs:\r\n - type: type: filestream\r\n   id: my-filestream-id\r\n   enabled: true\r\n   paths:\r\n    - /var/log/vstorage-ui-backend/audit.log\r\n   fields:\r\n    log_type: audit_log\r\n   fields_under_root: true \r\noutput.logstash:\r\n  hosts: [\"10.10.10.10:5044\"]\r\nEOT\nFor more details on Filebeat options, refer to the official documentation.\n\nUse the created file to update the Filebeat configuration:vinfra cluster filebeat config set --filename <filename> [--nodes <nodes> | --all]\n\n--filename <filename>\n\nPath to the Filebeat configuration file to upload\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--all\n\nApply the configuration on all cluster nodes\n\nFor example, to configure Filebeat to forward the specified logs from the management node node001, run:# vinfra cluster filebeat config set --nodes node001 --filename /etc/filebeat/filebeat.yml\n\nTo enable and start Filebeat\n\nEnable the service:# vinfra cluster filebeat enable [--nodes <nodes> | --all]\n\nStart Filebeat:# vinfra cluster filebeat start [--nodes <nodes> | --all]\n\nTo update the Filebeat configuration\n\nReload the Filebeat configuration:# vinfra cluster filebeat config reload [--nodes <nodes> | --all]\n\nRestart the service:# vinfra cluster filebeat restart [--nodes <nodes> | --all]\n\nTo stop and disable Filebeat\n\nStop Filebeat:# vinfra cluster filebeat stop [--nodes <nodes> | --all]\n\nDisable the service:# vinfra cluster filebeat disable [--nodes <nodes> | --all]\n\nTo delete the Filebeat configuration\nUse the following command:vinfra cluster filebeat config delete [--nodes <nodes> | --all]\n\n--nodes <nodes>\n\nA comma-separated list of node IDs or hostnames\n--all\n\nDelete the Filebeat configuration from all cluster nodes\n\nFor example, to delete the Filebeat configuration from the node node003, run:# vinfra cluster filebeat config delete --nodes node003\nSee also\n\nViewing cluster logs\n\nUsing Alertmanager for notifications\n\nUsing built-in Prometheus for monitoring\n\nUsing external Prometheus for monitoring",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/using-filebeat-for-log-forwarding.html"
    },
    {
        "title": "Creating and deleting Kubernetes clusters",
        "content": "Creating and deleting Kubernetes clusters\nLimitations\n\nOnly users that have access to the corresponding project can perform operations with Kubernetes clusters.\nTo create two or more Kubernetes clusters in one private network, you need to split the network into subnets by using the flannel_network_cidr label.\nIn Kubernetes version 1.21.x and earlier, autoscaling to zero nodes is not supported.\n\nPrerequisites\n\nThe Kubernetes-as-a-service component is installed by a system administrator. It can be deployed along with the compute cluster or later.\nYou have a network that will interconnect the Kubernetes master and worker nodes. It can be either a shared physical network or a virtual network linked to a physical one via a virtual router. The virtual network needs to have a gateway and a DNS server specified.\nAn SSH key is added. It will be installed on both the master and worker nodes.\nYou have enough resources for all of the Kubernetes nodes, taking their flavors into account.\n\nIt is also required that the network where you create a Kubernetes cluster does not overlap with these default networks:\n\n10.100.0.0/16\u00e2\u0080\u0094Used for pod-level networking\n10.254.0.0/16\u00e2\u0080\u0094Used for allocating Kubernetes cluster IP addresses\n\nTo create a Kubernetes cluster\n\nGo to the Kubernetes clusters screen, and then click Create on the right. A window will open where you can set your cluster parameters.\nEnter the cluster name, and then select a Kubernetes version and an SSH key.\n\nIn the Network section, select a network that will interconnect the Kubernetes nodes in the cluster. If you select a virtual network, decide whether you need access to your Kubernetes cluster via a floating IP address:\n\nIf you select None, you will not have access to the Kubernetes API.\nIf you select For Kubernetes API, a floating IP address will be assigned to the master node or to the load balancer if the master node is highly available.\nIf you select For Kubernetes API and nodes, floating IP addresses will be additionally assigned to all of the Kubernetes nodes (masters and workers).\n\nThen, choose whether or not to enable High availability for the master node. If you enable high availability, three master node instances will be created. They will work in the Active/Active mode.\n\nIn the Master node section, select a flavor for the master node. For production clusters, it is strongly recommended to use a flavor with at least 2 vCPUs and 8 GiB of RAM.\n\nOptionally, enable Integrated monitoring to automatically deploy the cluster-wide monitoring solution, which includes the following components: Prometheus, Alertmanager, and Grafana.\n\nThis feature is experimental and not intended for use in production environments.\n\nIn the Container volume section, select a storage policy, and then enter the size for volumes on both master and worker nodes.\n\nIn the Default worker group section,  select a flavor for each worker, and then decide whether you want to allow automatic scaling of the worker group:\n\nWith Autoscaling enabled, the number of workers will be automatically increased if there are pods stuck in the pending state due to insufficient resources, and reduced if there are workers with no pods running on them. For scaling of the worker group, set its minimum and maximum size.\n\nSome types of pods can prevent the autoscaler from removing a worker. To see a list of such pod types, refer to the official Kubernetes Autoscaler documentation.\n\nWith Autoscaling disabled, the number of worker nodes that you set will be permanent.\n\nIn the Labels section, enter labels that will be used to specify supplementary parameters for this Kubernetes cluster in the key=value format. For example: selinux_mode=permissive. Currently, only the selinux and flannel_network_cidr labels are supported. You can use other labels at your own risk. To see the full list of supported labels, refer to the OpenStack documentation.\n\nClick Create.\n\nCreation of the Kubernetes cluster will start. The master and worker nodes will appear on the Virtual machines screen, while their volumes will show up on the Volumes screen.\nAfter the cluster is ready, click Kubernetes access for instructions on how you can access the dashboard. You can also access the Kubernetes master and worker nodes via SSH, by using the assigned SSH key and the user name core.\nTo delete a Kubernetes cluster\nClick the required Kubernetes cluster on the Kubernetes clusters screen and click Delete. The master and worker VMs will be deleted along with their volumes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/creating-and-deleting-kubernetes-clusters.html"
    },
    {
        "title": "Deleting default quotas via CLI",
        "content": "Deleting default quotas via CLI\nYou can delete the current default quotas for all users or buckets with the rm-quotas command and the following parameters: -o specifying user for users or bucket for buckets:# ostor-s3-admin rm-quotas -o user -V 0100000000000002\r\nsuccessfully removed quotas# ostor-s3-admin rm-quotas -o bucket -V 0100000000000002\r\nsuccessfully removed quotas",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/deleting-default-quotas-via-cli.html"
    },
    {
        "title": "Attaching ISO images to virtual machines",
        "content": "Attaching ISO images to virtual machines\nYou can attach ISO images to running or stopped virtual machines, for example, to install additional software inside them or to restore their operating system in the rescue mode. To attach an ISO image, you need to convert it to a volume, and then attach this volume to a VM.\nWhen you finish installing software from an ISO volume, you can detach it without stopping the VM first.\nTo create a volume from an ISO image\n\nOn the Images screen, click the required ISO image.\nOn the image right pane, click Create volume.\nIn the Create volume from image window, specify a name for the volume, and then click Create.\n\nTo attach an ISO volume to a virtual machine\n\nOn the Virtual machines screen, click the required VM.\nOn the Overview tab, click the pencil icon in the Volumes field.\nIn the Volumes window, click Attach.\nIn the Attach volume window, select the created volume, and then click Attach. The attached volume will be marked as ISO.\nIn the Volumes window, click Done to save your changes.\n\nThe attached volume will appear inside the VM operating system.\n\nTo detach an ISO volume from a virtual machine\n\nOn the Virtual machines screen, click the required VM.\nOn the Overview tab, click the pencil icon in the Volumes field.\nIn the Volumes window, click the ellipsis icon next to the ISO volume, and then click Force detach.\nClick Done to save your changes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/attaching-iso-images-to-vms.html"
    },
    {
        "title": "Deleting snapshots",
        "content": "Deleting snapshotsDELETE /v3/{project_id}/snapshots/{snapshot_id}\r\n\nDeletes a snapshot with the specified ID.\nSnapshot status must be available or error\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html?expanded=delete-a-snapshot-detail#delete-a-snapshot\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nproject_id\n\npath\nstring\nThe UUID of the project in a multi-tenancy cloud.\n\nsnapshot_id\n\npath\nstring\nThe UUID of the snapshot.\n\nExample# curl -ks -X DELETE -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/snapshots/a370cf02-f469-4acc-be91-2b27a856806d\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/deleting-snapshots.html"
    },
    {
        "title": "Setting bandwidth per second for users via CLI",
        "content": "Setting bandwidth per second for users via CLI\nYou can limit outgoing bandwidth of a response with the set-limits command and the following parameters: -e specifying the email address, -t bandwidth specifying the limit type, and -L out= specifying the limit key:# ostor-s3-admin set-limits -e client@example.com -t bandwidth -L out=100\r\nops:default=0.00ops/s\r\nops:get=3600.00ops/s\r\nops:put=0.00ops/s\r\nops:list=0.00ops/s\r\nops:delete=0.00ops/s\r\nbandwidth:out=100kbs/s\r\n",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_staas_integration_guide/setting-bandwidth-per-second-for-users-via-cli.html"
    },
    {
        "title": "Creating IPsec policies",
        "content": "Creating IPsec policiesPOST /v2.0/vpn/ipsecpolicies\nCreate an IP security (IPsec) policy.\nThe IPsec policy specifies the authentication and encryption algorithms and encapsulation mode to use for the established VPN connection.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=create-ipsec-policies-detail#create-ipsec-policies\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicy\n\nbody\nobject\nAn ipsecpolicy object.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencapsulation_mode (Optional)\nbody\nstring\nThe encapsulation mode. A valid value is tunnel or transport. Default is tunnel.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\ntransform_protocol (Optional)\nbody\nstring\nThe transform protocol. A valid value is ESP, AH, or AH- ESP. Default is ESP.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"ipsecpolicy\": {\r\n        \"name\": \"ipsecpolicy1\",\r\n        \"transform_protocol\": \"esp\",\r\n        \"auth_algorithm\": \"sha1\",\r\n        \"encapsulation_mode\": \"tunnel\",\r\n        \"encryption_algorithm\": \"aes-128\",\r\n        \"pfs\": \"group5\",\r\n        \"lifetime\": {\r\n            \"units\": \"seconds\",\r\n            \"value\": 7200\r\n        }\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/ipsecpolicies\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nipsecpolicies\n\nbody\narray\nA list of ipsecpolicy objects.\n\nipsecpolicy\n\nbody\nobject\nAn ipsecpolicy object.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencapsulation_mode (Optional)\nbody\nstring\nThe encapsulation mode. A valid value is tunnel or transport. Default is tunnel.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\ntransform_protocol (Optional)\nbody\nstring\nThe transform protocol. A valid value is ESP, AH, or AH- ESP. Default is ESP.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IPsec policy.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n201 - Created\n\nResource was created and is ready to use.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\nExample{\r\n  \"ipsecpolicy\": {\r\n    \"id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"ipsecpolicy1\",\r\n    \"description\": \"\",\r\n    \"transform_protocol\": \"esp\",\r\n    \"auth_algorithm\": \"sha1\",\r\n    \"encryption_algorithm\": \"aes-128\",\r\n    \"encapsulation_mode\": \"tunnel\",\r\n    \"lifetime\": {\r\n      \"units\": \"seconds\",\r\n      \"value\": 7200\r\n    },\r\n    \"pfs\": \"group5\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/creating-ipsec-policies.html"
    },
    {
        "title": "Updating IPsec connections",
        "content": "Updating IPsec connectionsPUT /v2.0/vpn/ipsec-site-connections/{connection_id}\nUpdate connection settings for an IPsec connection.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=update-ipsec-connection-detail#update-ipsec-connection\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nconnection_id\n\npath\nstring\nThe ID of the IPsec site-to-site connection.\n\nipsec_site_connection\n\nbody\nobject\nAn ipsec_site_connection object.\n\nlocal_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private subnets for the local side of the connection. You must specify this parameter with the peer_ep_group_id parameter.\n\npeer_address\n\nbody\nstring\nThe peer gateway public IPv4 or IPv6 address or FQDN.\n\npeer_id\n\nbody\nstring\nThe peer router identity for authentication. A valid value is an IPv4 address, IPv6 address, e-mail address, key ID, or FQDN. Typically, this value matches the peer_address value.\n\npsk\n\nbody\nstring\nThe pre-shared key. A valid value is any string.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ninitiator (Optional)\nbody\nstring\nIndicates whether this VPN can only respond to connections or both respond to and initiate connections. A valid value is response-only or bi-directional. Default is bi-directional.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\ninterval (Optional)\nbody\ninteger\nThe dead peer detection (DPD) interval, in seconds. A valid value is a positive integer. Default is 30.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6.\n\npeer_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private CIDRs in the form <net_address>/<prefix> for the peer side of the connection. You must specify this parameter with the local_ep_group_id parameter.\n\ndpd (Optional)\nbody\nobject\nA dictionary with dead peer detection (DPD) protocol controls.\n\ntimeout\n\nbody\ninteger\nThe dead peer detection (DPD) timeout in seconds. A valid value is a positive integer that is greater than the DPD interval value. Default is 120.\n\naction\n\nbody\nstring\nThe dead peer detection (DPD) action. A valid value is clear, hold, restart, disabled, or restart-by-peer. Default value is hold.\n\nlocal_id (Optional)\nbody\nstring\nAn ID to be used instead of the external IP address for a virtual router used in traffic between instances on different networks in east-west traffic. Most often, local ID would be domain name, email address, etc. If this is not configured then the external IP address will be used as the ID.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"ipsec_site_connection\": {\r\n        \"description\": \"New IPsec connection\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/ipsec-site-connections/324dc68b-bdee-4a78-9d14-3484d8ee97a9\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nipsec_site_connection\n\nbody\nobject\nAn ipsec_site_connection object.\n\nauth_mode (Optional)\nbody\nstring\nThe authentication mode. A valid value is psk, which is the default.\n\nikepolicy_id\n\nbody\nstring\nThe ID of the IKE policy.\n\nvpnservice_id\n\nbody\nstring\nThe ID of the VPN service.\n\nlocal_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private subnets for the local side of the connection. You must specify this parameter with the peer_ep_group_id parameter.\n\npeer_address\n\nbody\nstring\nThe peer gateway public IPv4 or IPv6 address or FQDN.\n\nid (Optional)\nbody\nstring\nThe ID of the IPsec site-to-site connection.\n\nroute_mode (Optional)\nbody\nstring\nThe route mode. A valid value is static, which is the default.\n\nipsecpolicy_id\n\nbody\nstring\nThe ID of the IPsec policy.\n\npeer_id\n\nbody\nstring\nThe peer router identity for authentication. A valid value is an IPv4 address, IPv6 address, e-mail address, key ID, or FQDN. Typically, this value matches the peer_address value.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec connection is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\npsk\n\nbody\nstring\nThe pre-shared key. A valid value is any string.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ninitiator (Optional)\nbody\nstring\nIndicates whether this VPN can only respond to connections or both respond to and initiate connections. A valid value is response-only or bi-directional. Default is bi-directional.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ninterval (Optional)\nbody\ninteger\nThe dead peer detection (DPD) interval, in seconds. A valid value is a positive integer. Default is 30.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6.\n\npeer_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private CIDRs in the form <net_address>/<prefix> for the peer side of the connection. You must specify this parameter with the local_ep_group_id parameter.\n\ndpd (Optional)\nbody\nobject\nA dictionary with dead peer detection (DPD) protocol controls.\n\ntimeout\n\nbody\ninteger\nThe dead peer detection (DPD) timeout in seconds. A valid value is a positive integer that is greater than the DPD interval value. Default is 120.\n\naction\n\nbody\nstring\nThe dead peer detection (DPD) action. A valid value is clear, hold, restart, disabled, or restart-by-peer. Default value is hold.\n\nlocal_id (Optional)\nbody\nstring\nAn ID to be used instead of the external IP address for a virtual router used in traffic between instances on different networks in east-west traffic. Most often, local ID would be domain name, email address, etc. If this is not configured then the external IP address will be used as the ID.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"ipsec_site_connection\": {\r\n    \"id\": \"324dc68b-bdee-4a78-9d14-3484d8ee97a9\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"vpnconnection1\",\r\n    \"description\": \"New IPsec connection\",\r\n    \"peer_address\": \"10.136.18.138\",\r\n    \"peer_id\": \"10.136.18.138\",\r\n    \"local_id\": \"\",\r\n    \"route_mode\": \"static\",\r\n    \"mtu\": 1500,\r\n    \"auth_mode\": \"psk\",\r\n    \"psk\": \"secret\",\r\n    \"initiator\": \"bi-directional\",\r\n    \"dpd\": {\r\n      \"action\": \"hold\",\r\n      \"interval\": 30,\r\n      \"timeout\": 120\r\n    },\r\n    \"admin_state_up\": true,\r\n    \"status\": \"DOWN\",\r\n    \"vpnservice_id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n    \"ikepolicy_id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n    \"ipsecpolicy_id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n    \"peer_cidrs\": [],\r\n    \"local_ep_group_id\": \"646938a8-322e-44b3-ac35-60deadcd4252\",\r\n    \"peer_ep_group_id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n    \"split_selector\": false,\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-ipsec-connections.html"
    },
    {
        "title": "Managing block storage",
        "content": "Managing block storage\nThis section describes how to manage iSCSI target groups, targets, and volumes. It also explains how to restrict access to target groups by using CHAP or ACL.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/managing-block-storage.html"
    },
    {
        "title": "Configuring virtual machine volumes",
        "content": "Configuring virtual machine volumes\nYou can add new volumes to your virtual machines, attach existing volumes, and detach unneeded volumes from virtual machines.\nLimitations\n\nYou cannot change, detach, or delete the boot volume.\nYou can only attach and detach non-boot volumes.\nYou cannot manage volumes of shelved VMs.\n\nPrerequisites\n\nTo be able to use volumes attached to VMs, they must be initialized inside the guest OS by standard means.\n\nTo attach a volume to a virtual machine\n\nOn the Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Disks field.\n\nIn the Volumes window:\n\nClick Attach to attach an existing volume, and then select the volume in the Attach volume window.\nClick Add to create a new volume, and then specify the volume name, size, and storage policy. The created volume will be automatically added to the VM disks.\n\nClick Done to finish editing VM disks and save your changes.\n\nTo detach a volume from a virtual machine\n\nOn the Virtual machines screen, click the required virtual machine.\nOn the Overview tab, click the pencil icon in the Disks field.\n\nIn the Volumes window:\n\nClick Detach to detach a volume from a stopped virtual machine.\n\nClick Force detach to detach a volume from a running virtual machine.\n\nThere is a risk of data loss.\n\nClick Done to finish editing VM disks and save your changes.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/configuring-vm-volumes.html"
    },
    {
        "title": "Attaching volumes to target groups",
        "content": "Attaching volumes to target groups\nPrerequisites\n\nVolumes are created, as described in Creating volumes.\n\nTo add a volume as a LUN to a target group\n\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, click the ellipsis icon of the desired target group, and then click Add LUNs.\n\nIn the Attach window, select volumes to attach to the target group (create them if needed), and then click Attach.\n\nAlternatively, you can do the same on the Volumes tab:\n\nClick the ellipsis icon of the desired volume then click Attach.\n\nIn the Attach window, select a target group, and then click Attach.\n\nCommand-line interface\nUse the following command:vinfra service block-storage target-group volume attach [--lun <lun>] <target-group> <name>\n\n--lun <lun>\n\nLun ID\n<target-group>\n\nTarget group name or ID\n<name>\n\nVolume name or ID\n\nFor example, to attach the volume vol1 to the target group tg1 as LUN 0, run:# vinfra service block-storage target-group volume attach --lun 0 tg1 vol1\nThe attached volume will appear in the vinfra service block-storage target-group volume list output:# vinfra service block-storage target-group volume list tg1\r\n+--------------------------------------+--------------+------+--------------+-----------+\r\n| id                                   | serial       | name | size         | used_size |\r\n+--------------------------------------+--------------+------+--------------+-----------+\r\n| 9841d72f-5d68-4659-82d5-cd96cf1031b6 | cd96cf1031b6 | vol1 | 107374182400 | 1048576   |\r\n+--------------------------------------+--------------+------+--------------+-----------+\r\n\n\nWhat's next\n\nManaging block storage\n\nMonitoring block storage",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service block-storage target-group volume attach [--lun <lun>] <target-group> <name>\n\n--lun <lun>\n\nLun ID\n<target-group>\n\nTarget group name or ID\n<name>\n\nVolume name or ID\n\nFor example, to attach the volume vol1 to the target group tg1 as LUN 0, run:# vinfra service block-storage target-group volume attach --lun 0 tg1 vol1\nThe attached volume will appear in the vinfra service block-storage target-group volume list output:# vinfra service block-storage target-group volume list tg1\r\n+--------------------------------------+--------------+------+--------------+-----------+\r\n| id                                   | serial       | name | size         | used_size |\r\n+--------------------------------------+--------------+------+--------------+-----------+\r\n| 9841d72f-5d68-4659-82d5-cd96cf1031b6 | cd96cf1031b6 | vol1 | 107374182400 | 1048576   |\r\n+--------------------------------------+--------------+------+--------------+-----------+\r\n\n",
                "title": "To add a volume as a LUN to a target group"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOpen Storage services > Block storage > Target groups, click the ellipsis icon of the desired target group, and then click Add LUNs.\n\nIn the Attach window, select volumes to attach to the target group (create them if needed), and then click Attach.\n\n\n\n\n\n\nAlternatively, you can do the same on the Volumes tab:\n\nClick the ellipsis icon of the desired volume then click Attach.\n\nIn the Attach window, select a target group, and then click Attach.\n\n\n\n\n\n\n",
                "title": "To add a volume as a LUN to a target group"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/attaching-volumes.html"
    },
    {
        "title": "Acronis Backup Storage requirements",
        "content": "Acronis Backup Storage requirements\nBackup storage requirements depend on the destination storage you choose. Backup storage supports the following backup destinations:\n\nVirtuozzo Hybrid Infrastructure storage clusters\nNFS shares\nPublic clouds, including a number of S3 solutions, as well as Microsoft Azure, OpenStack Swift, and Google Cloud Platform\n\nWith the public cloud destination, you can also deploy backup storage inside virtual machines.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/backup-storage-requirements.html"
    },
    {
        "title": "Maintenance",
        "content": "Maintenance\nRoutine cluster maintenance implies installing updates, replacing failed disks, backing up and restoring the management database. The cluster maintenance also includes gracefully releasing nodes from the storage cluster without data loss and removing them from the infrastructure. You can perform node maintenance by placing a node into the maintenance mode. When changing cluster nodes, you might need to modify the high availability configuration or even destroy and re-create it. Additionally, it is important to know the recommended way to gracefully shut down all nodes and start up the cluster later. ",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/maintenance.html"
    },
    {
        "title": "2.3. Prerequisites\u00c2\u00b6",
        "content": "2.3. Prerequisites | Leostream Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nLeostream Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\n1. What is Leostream?\n1.1. Leostream Platform Components\n\n2. Integrating Leostream with Virtuozzo Hybrid Infrastructure\n2.1. Example Overview\n2.2. Integration Overview\n2.3. Prerequisites\n\n3. Creating Virtuozzo Hybrid Infrastructure Resources\n4. Creating Networks for Leostream\n5. Installing Leostream in Virtuozzo Hybrid Infrastructure\n5.1. Security Groups Requirements\n5.2. Creating Leostream Infrastructure VMs (Broker and Gateway)\n\n6. Adding Floating IP to Gateway VM (DNAT Access)\n7. Installing and Configuring Leostream Gateway\n8. Installing Leostream Connection Broker\n9. Configuring Leostream Connection Broker\n9.1. Enabling Connection Broker Forwarding\n9.2. Licensing Leostream Connection Broker\n9.3. Changing Default Admin Password\n\n10. Preparing Master Images\n10.1. Supported Operating Systems\n10.2. Installing Leostream Agent\n10.3. Requirements for Performing Domain Joins\n\n11. Integrating External Systems\n11.1. Connecting to Authentication Servers\n11.2. Integration with Virtuozzo Hybrid Infrastructure\n11.3. Adding Leostream Gateway\n\n12. Pooling and Provisioning in Virtuozzo Hybrid Infrastructure\n12.1. Creating Pools\n12.2. Provisioning New Instances\n12.3. Disable Provisioning\n12.4. Joining Instances to Domain\n\n13. Offering Virtuozzo Hybrid Infrastructure Desktops to Users\n13.1. Defining Pool-Based Plans\n13.2. Building User Policies\n13.3. Assigning Policies to Users\n13.4. Testing Connection Broker Configuration\n\n14. Connecting Virtual Desktop Using Leostream\n15. Leostream Official Documentation and FAQs\n\nLeostream Integration for Virtuozzo Hybrid InfrastructurePDF, 8353 KB\n\nPrev\nNext\n\n2.3. Prerequisites\u00c2\u00b6\n\nThe Leostream Connection Broker needs to access the OpenStack API endpoint in order to manage the infrastructure.\n\nA user with admin rights for Virtuozzo Hybrid Infrastructure, which will be used to create a Domain, Users and Project described in the next section. The project in Virtuozzo Hybrid Infrastructure must include enough resources for the Leostream components and the VDI infrastructure.\nYou will also need an image for CentOS 7 available on your Virtuozzo Hybrid Infrastructure project.\nA VM with Active Directory Configured, we will be using Active Directory as the authentication method to access Virtual Desktops.\nA golden Virtual Desktop image (a Windows Desktop image with the Leostream Agent installed ensure this image is created after installing the Leostream Connection Broker, as we will need the IP of the Leostream Connection Broker for the agent). This image will be used as a base for the creation of the Pools.\nA Leostream Serial Number to generate the License.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 11, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_leostream/integrating-leostream/prerequisites.html"
    },
    {
        "title": "Creating the NFS cluster",
        "content": "Creating the NFS cluster\nPrerequisites\n\nThe storage cluster has at least one disk with the Storage role.\n\nTo create the NFS storage cluster\n\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the OSTOR private and NFS traffic types are added to the networks you intend to use.\nOpen the Storage services > NFS screen, and then click Create NFS storage.\nSelect one or more nodes to add to the NFS storage cluster, and then click Create.\n\nAfter the NFS storage is created, you can proceed to create NFS shares.\n\nCommand-line interface\nUse the following command:vinfra service nfs cluster create --nodes <node>[:<ip_address>]\n\n--nodes <node>[:<ip_address>]\n\nA comma-separated list of node hostnames or IDs, and optionally their IP addresses\n\nFor example, to create the NFS cluster from node node001, run:# vinfra service nfs cluster create --nodes node001\n\nWhat's next\n\nCreating NFS shares",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service nfs cluster create --nodes <node>[:<ip_address>]\n\n--nodes <node>[:<ip_address>]\n\nA comma-separated list of node hostnames or IDs, and optionally their IP addresses\n\nFor example, to create the NFS cluster from node node001, run:# vinfra service nfs cluster create --nodes node001\n",
                "title": "To create the NFS storage cluster"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Networks screen, make sure that the OSTOR private and NFS traffic types are added to the networks you intend to use.\nOpen the Storage services > NFS screen, and then click Create NFS storage.\nSelect one or more nodes to add to the NFS storage cluster, and then click Create.\n\nAfter the NFS storage is created, you can proceed to create NFS shares.\n",
                "title": "To create the NFS storage cluster"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/creating-the-nfs-cluster.html"
    },
    {
        "title": "Removing hosts from aggregates",
        "content": "Removing hosts from aggregatesPOST /os-aggregates/{aggregate_id}/action\r\n\nRemoves a host from an aggregate.\nSpecify the remove_host action and host name in the request body.\nSource: https://docs.openstack.org/api-ref/compute/?expanded=remove-host-detail#remove-host\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\naggregate_id\n\npath\ninteger\nThe aggregate ID.\n\nremove_host\n\nbody\nobject\nThe add_host object used to remove host from aggregate.\n\nhost\n\nbody\nstring\nThe name of the host.\n\nExamplecurl -ks -X POST -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n    \"remove_host\": {\r\n        \"host\": \"node1.vstoragedomain\"\r\n    }\r\n}' https://<node_IP_addr>:8774/v2.1/6ef5371261ea42008e3d1d41ba051977/os-aggregates/4/action\r\n\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\naggregate\n\nbody\nobject\nThe host aggregate object.\n\nname\n\nbody\nstring\nThe name of the host aggregate.\n\navailability_zone\n\nbody\nstring\nThe availability zone of the host aggregate.\n\ncreated_at\n\nbody\nstring\n\nThe date and time when the resource was created.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted_at\n\nbody\nstring\n\nThe date and time when the resource was deleted. If the resource has\r\nnot been deleted yet, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\ndeleted\n\nbody\nboolean\nA boolean indicates whether this aggregate is deleted or not, if it has\r\nnot been deleted, false will appear.\n\nhosts\n\nbody\narray\nAn array of host information.\n\nid\n\nbody\ninteger\nThe ID of the host aggregate.\n\nmetadata\n\nbody\nobject\nMetadata key and value pairs associated with the aggregate.\n\nupdated_at\n\nbody\nstring\n\nThe date and time when the resource was updated. If the resource has\r\nnot been updated, this field will be null.\nThe date and time stamp format is ISO 8601:CCYY-MM-DDThh:mm:ss\u00c2\u00b1hh:mm\r\n\nFor example, 2015-08-27T09:49:58-05:00.\nThe \u00c2\u00b1hh:mm\r\nvalue, if included, is the time zone as an offset from UTC. In\r\nthis example, the offset value is -05:00.\n\nuuid\n\nbody\nstring\n\nThe UUID of the host aggregate.\nNew in version 2.41\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\n409 - Conflict\n\nThis operation conflicted with another operation on this resource.\n\nExample{\r\n  \"aggregate\": {\r\n    \"name\": \"CUSTOM_HCI_0A7F6A35E650420CB30200A8359861D9\",\r\n    \"availability_zone\": null,\r\n    \"deleted\": false,\r\n    \"created_at\": \"2020-04-19T12:56:10.191466\",\r\n    \"updated_at\": null,\r\n    \"hosts\": [],\r\n    \"deleted_at\": null,\r\n    \"id\": 4,\r\n    \"metadata\": {}\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/removing-hosts-from-aggregates.html"
    },
    {
        "title": "Showing IPsec connection details",
        "content": "Showing IPsec connection detailsGET /v2.0/vpn/ipsec-site-connections/{connection_id}\nShows details for an IPsec connection.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=show-ipsec-connection-detail#show-ipsec-connection\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nconnection_id\n\npath\nstring\nThe ID of the IPsec site-to-site connection.\n\nExample# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' \\\r\nhttps://<node_IP_addr>:9696/v2.0/vpn/ipsec-site-connections/324dc68b-bdee-4a78-9d14-3484d8ee97a9\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nipsec_site_connection\n\nbody\nobject\nAn ipsec_site_connection object.\n\nauth_mode (Optional)\nbody\nstring\nThe authentication mode. A valid value is psk, which is the default.\n\nikepolicy_id\n\nbody\nstring\nThe ID of the IKE policy.\n\nvpnservice_id\n\nbody\nstring\nThe ID of the VPN service.\n\nlocal_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private subnets for the local side of the connection. You must specify this parameter with the peer_ep_group_id parameter.\n\npeer_address\n\nbody\nstring\nThe peer gateway public IPv4 or IPv6 address or FQDN.\n\nid (Optional)\nbody\nstring\nThe ID of the IPsec site-to-site connection.\n\nroute_mode (Optional)\nbody\nstring\nThe route mode. A valid value is static, which is the default.\n\nipsecpolicy_id\n\nbody\nstring\nThe ID of the IPsec policy.\n\npeer_id\n\nbody\nstring\nThe peer router identity for authentication. A valid value is an IPv4 address, IPv6 address, e-mail address, key ID, or FQDN. Typically, this value matches the peer_address value.\n\nstatus\n\nbody\nstring\nIndicates whether the IPsec connection is currently operational. Values are ACTIVE, DOWN, BUILD, ERROR, PENDING_CREATE, PENDING_UPDATE, or PENDING_DELETE.\n\npsk\n\nbody\nstring\nThe pre-shared key. A valid value is any string.\n\nname (Optional)\nbody\nstring\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ninitiator (Optional)\nbody\nstring\nIndicates whether this VPN can only respond to connections or both respond to and initiate connections. A valid value is response-only or bi-directional. Default is bi-directional.\n\nadmin_state_up\n\nbody\nboolean\nThe administrative state of the resource, which is up (true) or down (false).\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\ninterval (Optional)\nbody\ninteger\nThe dead peer detection (DPD) interval, in seconds. A valid value is a positive integer. Default is 30.\n\nmtu\n\nbody\ninteger\nThe maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6.\n\npeer_ep_group_id (Optional)\nbody\nstring\nThe ID for the endpoint group that contains private CIDRs in the form <net_address>/<prefix> for the peer side of the connection. You must specify this parameter with the local_ep_group_id parameter.\n\ndpd (Optional)\nbody\nobject\nA dictionary with dead peer detection (DPD) protocol controls.\n\ntimeout\n\nbody\ninteger\nThe dead peer detection (DPD) timeout in seconds. A valid value is a positive integer that is greater than the DPD interval value. Default is 120.\n\naction\n\nbody\nstring\nThe dead peer detection (DPD) action. A valid value is clear, hold, restart, disabled, or restart-by-peer. Default value is hold.\n\nlocal_id (Optional)\nbody\nstring\nAn ID to be used instead of the external IP address for a virtual router used in traffic between instances on different networks in east-west traffic. Most often, local ID would be domain name, email address, etc. If this is not configured then the external IP address will be used as the ID.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n403 - Forbidden\n\nPolicy does not allow current user to do this operation.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"ipsec_site_connection\": {\r\n    \"id\": \"324dc68b-bdee-4a78-9d14-3484d8ee97a9\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"vpnconnection1\",\r\n    \"description\": \"\",\r\n    \"peer_address\": \"10.136.18.138\",\r\n    \"peer_id\": \"10.136.18.138\",\r\n    \"local_id\": \"\",\r\n    \"route_mode\": \"static\",\r\n    \"mtu\": 1500,\r\n    \"auth_mode\": \"psk\",\r\n    \"psk\": \"secret\",\r\n    \"initiator\": \"bi-directional\",\r\n    \"dpd\": {\r\n      \"action\": \"hold\",\r\n      \"interval\": 30,\r\n      \"timeout\": 120\r\n    },\r\n    \"admin_state_up\": true,\r\n    \"status\": \"DOWN\",\r\n    \"vpnservice_id\": \"d6116b75-db78-4d07-9911-226b4655838a\",\r\n    \"ikepolicy_id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n    \"ipsecpolicy_id\": \"805ab779-e91c-42db-b6b9-591156d9634e\",\r\n    \"peer_cidrs\": [],\r\n    \"local_ep_group_id\": \"646938a8-322e-44b3-ac35-60deadcd4252\",\r\n    \"peer_ep_group_id\": \"e3b89342-73ee-42b9-8ee9-fd91ec36aceb\",\r\n    \"split_selector\": false,\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/showing-ipsec-connection-details.html"
    },
    {
        "title": "Monitoring Acronis Backup Storage",
        "content": "Monitoring Acronis Backup Storage\nAfter you create backup storage, you can monitor it on the Storage services > Backup storage > Overview screen. The charts show the following information:\n\nNodes. The chart shows the number and availability of  nodes in the backup storage cluster.\nPerformance. The chart shows the read and write activity  of backup storage services over time.\nGeo-replication. The chart shows the geo-replication speed and backlog, which is the amount of data waiting to be replicated. If the geo-replication backlog does not decrease over time, it means the data cannot be replicated fast enough. The reason may be insufficient network transfer speed, and you may need to check or upgrade your network.\nAppend latency. The chart shows the time spent on processing requests from backup agents to the storage.\n\nAppend throttle. If the chart is not empty, it means the underlying storage lacks free space and the backup storage is throttling user requests to slow down the data flow.\nTwo thresholds, soft and hard, are set on 85% and 93% of used storage space, accordingly. When the soft threshold is reached, backup storage starts to throttle write operations. Throttling intensity depends on consumed space and increases until the hard threshold is reached. When the used space passes the hard threshold, throttling works with maximum intensity.\n\nObject storage. The chart shows the object storage speed and backlog, which is the amount of data waiting to be uploaded to public cloud. If the object storage backlog does not decrease over time, it means the data cannot be uploaded fast enough. The reason may be insufficient network transfer speed, and you may need to check or upgrade your network.\n\nYou can also monitor backups storage nodes. To do this, go to Storage services > Backup storage > Nodes and click the required node. On the right pane, the Overview tab displays the performance statistics:\n\nCPU/RAM: CPU usage in percent over time, and RAM usage, in GiB over time\nSuccessful/Failed request rate: the number of successful and failed append requests per second\nEgress/Ingress request rate: the number of read and write requests per second\nThroughput: the amount of data read from or written to the backup storage per second\nRequest latency: the time spent on processing requests\n\nAdvanced Backup Gateway monitoring via Grafana\nFor advanced monitoring of the Backup Gateway cluster, go to the Monitoring > Dashboard screen, and then click Grafana dashboard. A separate browser tab will open with preconfigured Grafana dashboards, two of which are dedicated to Acronis Backup Gateway. To see a detailed description for each chart, click the i icon on its left corner.\nOn the Acronis Backup Gateway dashboard, you need to pay attention to the following charts:\n\nAvailability. Any time period during which the gateways have not been available will be highlighted in red. In this case, you will need to look into logs on the nodes with the failed service and report a problem. To see the Backup Gateway log, use the following command:# zstdcat /var/log/abgw/abgw.log.zst\r\n\n\nMigration/Replication throughput. The migration chart should be displayed during migration or if the cluster serves as master in a geo-replication configuration. The replication chart should mirror the ingress bandwidth chart.\n\nMigration/replication backlog. The migration chart should decrease over time. The replication chart should be near zero, high values indicate network issues.\n\nRate limiting/ingress throttling. If the chart is not empty, it means the underlying storage lacks free space and the Backup Gateway is throttling user requests to slow down the data flow. Add more storage space to the cluster to solve the issue. For more information, refer to https://kb.acronis.com/content/62823.\n\nNew client connections. A high rate of failed connections due to SSL certificate verification problems on the chart means that clients uploaded an invalid certificate chain.\n\nIO watchdog timeouts. If the chart is not empty, it means the underlying storage is not healthy and cannot deliver the required performance.\n\nTo see the charts for a particular client request, file, and I/O operation, select them from the drop-down menus above. A high rate of failed requests or operations and high latencies on these charts indicate that the Backup Gateway experiences issues that need to be reported. For example, you can check charts for the \u00e2\u0080\u009cAppend\u00e2\u0080\u009d request:\n\nThe Append rate chart displays the backup data flow from backup agents to the storage in operations per second (one operation equals one big block of backup data; blocks can be of various size).\nThe Append latency chart shows the time spent on processing requests and should average several tens of milliseconds with peak values below one second.\n\nThe Acronis Backup Gateway Details dashboard is intended for low-level troubleshooting by the support team. To monitor a particular node, client request, file, and I/O operation, select them from the drop-down menus above. On the dashboard, you can make sure the Event loop inactivity chart is empty. Otherwise, the Backup Gateway is not healthy on this node and the issue needs to be reported.\n\nSee also\n\nManaging Acronis Backup Storage\n\nBackup storage metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/monitoring-backup-storage.html"
    },
    {
        "title": "Performing actions on volumes",
        "content": "Performing actions on volumesPOST /v3/{project_id}/volumes/{volume_id}/action\r\n\nThe request parameters depend on the action. For the list of parameters, follow the source link below.\nSource: https://docs.openstack.org/api-ref/block-storage/v3/index.html#volume-actions-volumes-action\nRequest\nExample 1\nExtends the size of a volume to a requested size, in gibibytes (GiB).\r\nSpecify the os-extend action in the request body.\nPreconditions:\n\nPrior to microversion 3.42 the volume status must be available.\r\nStarting with microversion 3.42, attached volumes with status in-use\r\nmay be able to be extended depending on policy and backend volume and\r\ncompute driver constraints in the cloud. Note that reserved is not a\r\nvalid state for extend.\nSufficient amount of storage must exist to extend the volume.\nThe user quota must have sufficient volume storage.\n\nPostconditions:\n\nIf the request is processed successfully, the volume status will change to\r\nextending while the volume size is being extended.\nUpon successful completion of the extend operation, the volume status will\r\ngo back to its original value.\nStarting with microversion 3.42, when extending the size of an attached\r\nvolume, the Block Storage service will notify the Compute service that an\r\nattached volume has been extended. The Compute service will asynchronously\r\nprocess the volume size change for the related server instance. This can be\r\nmonitored using the GET /servers/{server_id}/os-instance-actions API in\r\nthe Compute service.\n\nTroubleshooting:\n\nAn error_extending volume status indicates that the request\r\nfailed. Ensure that you meet the preconditions and retry the\r\nrequest. If the request fails again, investigate the storage back\r\nend.\n# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"os-extend\": {\r\n    \"new_size\": 3\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329/action\r\n\nExample 2\nAttach an available volume to a VM. Specify the os-attach action in the request body. Also specify either instance_uuid or host_name.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"os-attach\": {\r\n    \"instance_uuid\": \"e1ae6f7e-c35d-4656-a4fd-2371f9a791d4\",\r\n    \"mountpoint\": \"/dev/vdb\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329/action\r\n\nExample 3\nDetach an in-use volume from a VM. Specify the os-detach action in the request body. You can find out the attachment ID in volume details.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"os-detach\": {\r\n    \"attachment_id\": \"2b04f3a1-b16c-4c13-aa7f-d1d7f7934a12\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329/actio\r\n\nExample 4\nChange volume storage policy (\u00e2\u0080\u009ctype\u00e2\u0080\u009d in OpenStack terms). Specify the os-retype action in the request body.\nCinder may migrate the volume to proper volume host according to the new volume type.\nPolicy defaults enable only users with the administrative role or the owner of\r\nthe volume to perform this operation. These permissions are controlled by the policy.json file.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"os-retype\": {\r\n    \"new_type\": \"default\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329/action\r\n\nExample 5\nCreate an image from a volume. QCOW2 format is required.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"os-volume_upload_image\": {\r\n    \"image_name\": \"vol3_image\",\r\n    \"disk_format\": \"qcow2\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329/action\r\n\nExample 6\nCreate an image from a volume snapshot. This custom API call is only supported in Virtuozzo Hybrid Infrastructure.# curl -ks -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"os-volume_upload_image\": {\r\n    \"image_name\": \"vol4_image\",\r\n    \"disk_format\": \"qcow2\",\r\n    \"snapshot_id\": \"ca4e9232-96d3-41a6-ac28-ca3471a05b47\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329/action\r\n\nExample 7\nRevert a volume to its snapshot. Reverting to a snapshot is supported for detached volumes with status available or volumes with status in-use if they are attached to stopped VMs.\nAvailable since API microversion 3.40. Specify the microversion in the request, for example, OpenStack-API-Version: volume 3.59.# curl -ks -H 'Content-Type: application/json' -H 'OpenStack-API-Version: volume 3.59' \\\r\n-H 'X-Auth-Token: gAAAAA<...>' -d '\r\n{\r\n  \"revert\": {\r\n    \"snapshot_id\": \"ca4e9232-96d3-41a6-ac28-ca3471a05b47\"\r\n  }\r\n}' https://<node_IP_addr>:8776/v3/f5d834d636c642c7bfe8af86139c6f26/volumes/de5b7dfc-e3e8-4f14-9969-98d61af40329/action\r\n\nResponse\nStatus codes\nSuccess\n\nCode\nReason\n\n202 - Accepted\n\nRequest was accepted for processing, but the processing has not been completed. A \u00e2\u0080\u0098location\u00e2\u0080\u0099 header is included in the response which contains a link to check the progress of the request.\n\nExample 1\nMost requests only return the response code 202. Two exceptions follow.\nCreate an image from a volume:{\r\n  \"os-volume_upload_image\": {\r\n    \"status\": \"uploading\",\r\n    \"container_format\": \"bare\",\r\n    \"image_name\": \"vol3_image\",\r\n    \"visibility\": \"shared\",\r\n    \"updated_at\": \"2020-03-11T12:48:21.462203\",\r\n    \"image_id\": \"6b84c6e2-494e-426c-8138-86094a6c784c\",\r\n    \"display_description\": \"Volume 2\",\r\n    \"id\": \"de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n    \"size\": 3,\r\n    \"disk_format\": \"qcow2\",\r\n    \"volume_type\": {\r\n      \"name\": \"default\",\r\n      \"qos_specs_id\": null,\r\n      \"deleted\": false,\r\n      \"created_at\": \"2020-01-28T12:59:27.098490\",\r\n      \"updated_at\": null,\r\n      \"extra_specs\": {\r\n        \"vz:encoding\": \"\",\r\n        \"vz:volume_format\": \"qcow2\",\r\n        \"volume_backend_name\": \"vstorage\",\r\n        \"vz:failure-domain\": \"host\",\r\n        \"vz:tier\": \"0\",\r\n        \"vz:replicas\": \"1\"\r\n      },\r\n      \"is_public\": true,\r\n      \"deleted_at\": null,\r\n      \"id\": \"f6ab4526-2eb4-4a2d-a6bb-e527f8263304\",\r\n      \"description\": null\r\n    },\r\n    \"protected\": false\r\n  }\r\n}\nExample 2\nCreate an image from a snapshot:{\r\n  \"os-volume_upload_image\": {\r\n    \"status\": \"uploading\",\r\n    \"container_format\": \"bare\",\r\n    \"image_name\": \"vol4_image\",\r\n    \"visibility\": \"shared\",\r\n    \"updated_at\": \"2020-03-11T15:15:40.936836\",\r\n    \"image_id\": \"cb80ce16-683a-41cc-a878-02b75ba2e90f\",\r\n    \"display_description\": \"Volume 2\",\r\n    \"id\": \"de5b7dfc-e3e8-4f14-9969-98d61af40329\",\r\n    \"size\": 1,\r\n    \"disk_format\": \"qcow2\",\r\n    \"volume_type\": {\r\n      \"name\": \"policy1\",\r\n      \"qos_specs_id\": null,\r\n      \"deleted\": false,\r\n      \"created_at\": \"2020-01-31T12:14:46.143657\",\r\n      \"updated_at\": null,\r\n      \"extra_specs\": {\r\n        \"volume_backend_name\": \"vstorage\",\r\n        \"vz:failure-domain\": \"disk\",\r\n        \"vz:tier\": \"0\",\r\n        \"vz:replicas\": \"2\",\r\n        \"vz:encoding\": \"\"\r\n      },\r\n      \"is_public\": true,\r\n      \"deleted_at\": null,\r\n      \"id\": \"e90a828e-2b81-43e1-ab14-2d22ab30d175\",\r\n      \"description\": null\r\n    },\r\n    \"protected\": false\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/performing-actions-on-volumes.html"
    },
    {
        "title": "Configuring new disks manually",
        "content": "Configuring new disks manually\nLimitations\n\nYou can assign a role to a disk only if its size is greater than 1 GiB.\nYou can assign an additional role to a system disk only if its size is at least 100 GiB.\nIt is recommended to assign the System and Metadata roles to either an SSD disk or different HDDs. Assigning both of these roles to the same HDD disk will result in mediocre performance suitable only for cold data (for example, archiving).\nThe System role cannot be combined with the Cache and Metadata+Cache roles. The reason is that the I/O generated by the operating system and applications would contend with the I/O generated by journaling, thus negating its performance benefits.\nYou can use shingled magnetic recording (SMR) HDDs only with the Storage role and only if the node has an SSD disk with the Cache role. Host-managed SMR disks are not supported.\nYou cannot use SMR and standard disks in the same tier.\nYou cannot assign roles to system and non-system disks at a time.\n\nPrerequisites\n\nA clear understanding of the storage cluster architecture and disk roles, which are explained in About the storage cluster.\nThe failed disk is released, as described in Releasing node disks, and the new disk for replacement is connected to the node.\n\nTo manually assign roles to a new disk\n\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node.\nOn the Disks tab, click the new disk without a role.\nOn the disk right pane, click Assign role.\n\nIn the Assign role window, select a disk role, that is how you want to use the disk:\n\n[Only for SSD drives] To store write cache\n\nSelect the Cache role.\nSelect a storage tier that you want to cache.\n\nFor storage disks to use cache, the Cache role must be assigned before the Storage role. You can also assign both of these roles to disks at the same time, and the system will configure the cache disk first.\n\nTo store data\n\nSelect the Storage role.\nSelect a storage tier where to store your data. To make better use of data redundancy, do not assign all of the disks on a node to the same tier. Instead, make sure that each tier is evenly distributed across the cluster.\n\nEnable data caching and checksumming:\n\nEnable SSD caching and checksumming. Available and recommended only for nodes with SSDs.\nEnable checksumming (default). Recommended for nodes with HDDs as it provides better reliability.\nDisable checksumming. Not recommended for production. For an evaluation or testing environment, you can disable checksumming for nodes with HDDs, to provide better performance.\n\nTo store cluster metadata\n\nSelect the Metadata role.\n\nIt is recommended to have only one disk with the Metadata role per node and maximum five such disks in a cluster.\n\n[Only for SSD drives] To store both metadata and write cache\n\nSelect the Metadata+Cache role.\nSelect a storage tier that you want to cache.\n\nClick Assign.\n\nCommand-line interface\nUse the following command:vinfra node disk assign --disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]\r\n                        [--node <node>]\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n\nFor example, to assign the role cs to the disk sdc on the node node003, run:# vinfra node disk assign --disk sdc:cs --node node003\nYou can view the node's disk configuration in the vinfra node disk list output:# vinfra node disk list --node node003\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| id                                   | device | type | role       | disk_status | used    | size     | physical_size | service_id | service_status |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| 2A006CA5-732F-4E17-8FB0-B82CE0F28DB2 | sdc    | hdd  | cs         | ok          | 11.2GiB | 125.8GiB | 128.0GiB      | 1026       | active         |\r\n| 642A7162-B66C-4550-9FB2-F06866FB7EA1 | sdb    | hdd  | cs         | ok          | 8.7GiB  | 125.8GiB | 128.0GiB      | 1025       | active         |\r\n| 45D38CD2-3B94-4F0F-8864-9D51F716D3B1 | sda    | hdd  | mds-system | ok          | 21.0GiB | 125.9GiB | 128.0GiB      | 1          | avail          |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n\n\nSee also\n\nMonitoring node disks",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra node disk assign --disk <disk>:<role>[:<key=value,\u00e2\u0080\u00a6>]\r\n                        [--node <node>]\r\n\n\n--disk <disk>:<role> [:<key=value,\u00e2\u0080\u00a6>]\n\n\nDisk configuration in the format:\n\n<disk>: disk device ID or name\n<role>: disk role (cs, mds, journal, mds-journal, mds-system, cs-system, system)\ncomma-separated key=value pairs with keys (optional):tier: disk tier (0, 1, 2 or 3)journal-tier: journal (cache) disk tier (0, 1, 2 or 3)journal-type: journal (cache) disk type (no_cache, inner_cache or external_cache)journal-disk: journal (cache) disk ID or device namebind-address: bind IP address for the metadata service\n\nExample: sda:cs:tier=0,journal-type=inner_cache. This option can be used multiple times.\n\n--node <node>\n\nNode ID or hostname (default: node001.vstoragedomain)\n\nFor example, to assign the role cs to the disk sdc on the node node003, run:# vinfra node disk assign --disk sdc:cs --node node003\nYou can view the node's disk configuration in the vinfra node disk list output:# vinfra node disk list --node node003\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| id                                   | device | type | role       | disk_status | used    | size     | physical_size | service_id | service_status |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n| 2A006CA5-732F-4E17-8FB0-B82CE0F28DB2 | sdc    | hdd  | cs         | ok          | 11.2GiB | 125.8GiB | 128.0GiB      | 1026       | active         |\r\n| 642A7162-B66C-4550-9FB2-F06866FB7EA1 | sdb    | hdd  | cs         | ok          | 8.7GiB  | 125.8GiB | 128.0GiB      | 1025       | active         |\r\n| 45D38CD2-3B94-4F0F-8864-9D51F716D3B1 | sda    | hdd  | mds-system | ok          | 21.0GiB | 125.9GiB | 128.0GiB      | 1          | avail          |\r\n+--------------------------------------+--------+------+------------+-------------+---------+----------+---------------+------------+----------------+\r\n\n",
                "title": "To manually assign roles to a new disk"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Infrastructure > Nodes screen, click the name of the node.\nOn the Disks tab, click the new disk without a role.\nOn the disk right pane, click Assign role.\n\nIn the Assign role window, select a disk role, that is how you want to use the disk:\n\n\n[Only for SSD drives] To store write cache\n\n\nSelect the Cache role.\nSelect a storage tier that you want to cache.\n\n\nFor storage disks to use cache, the Cache role must be assigned before the Storage role. You can also assign both of these roles to disks at the same time, and the system will configure the cache disk first.\n\n\n\n\n\nTo store data\n\n\nSelect the Storage role.\nSelect a storage tier where to store your data. To make better use of data redundancy, do not assign all of the disks on a node to the same tier. Instead, make sure that each tier is evenly distributed across the cluster.\n\nEnable data caching and checksumming:\n\nEnable SSD caching and checksumming. Available and recommended only for nodes with SSDs.\nEnable checksumming (default). Recommended for nodes with HDDs as it provides better reliability.\nDisable checksumming. Not recommended for production. For an evaluation or testing environment, you can disable checksumming for nodes with HDDs, to provide better performance.\n\n\n\n\n\n\n\nTo store cluster metadata\n\nSelect the Metadata role.\n\nIt is recommended to have only one disk with the Metadata role per node and maximum five such disks in a cluster.\n\n\n\n\n\n[Only for SSD drives] To store both metadata and write cache\n\n\nSelect the Metadata+Cache role.\nSelect a storage tier that you want to cache.\n\n\n\n\n\n\n\n\nClick Assign.\n\n",
                "title": "To manually assign roles to a new disk"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-new-disks-manually.html"
    },
    {
        "title": "Configuring retention policy for Prometheus metrics",
        "content": "Configuring retention policy for Prometheus metrics\nThe Prometheus service used for monitoring the cluster runs and stores its data on the management node. By default, Prometheus metrics are stored for seven days. This retention period can be insufficient for troubleshooting purposes. You can increase it manually by modifying the Prometheus configuration file.\nHowever, with a long retention period, the root partition where the data is stored may run out of free space. To prevent this, you can define the maximum size for the Prometheus metrics. The oldest data will be removed first.\nTo increase the retention period\n\nOn the management node, open the file /etc/sysconfig/prometheus to edit, set the needed retention period for the STORAGE_RETENTION option, and then save your changes. For example:STORAGE_RETENTION=\"--storage.tsdb.retention.time=30d\"\r\n\n\nRestart the Prometheus service:systemctl restart prometheus.service\r\n\n\nIf high availability is enabled in the storage cluster, repeat these steps for the other two management nodes.\nTo change the time retention policy to the size retention policy\n\nOn the management node, open the file /etc/sysconfig/prometheus to edit, change the flag for the STORAGE_RETENTION option, and then save your changes. For example:STORAGE_RETENTION=\"--storage.tsdb.retention.size=10GB\"\r\n\n\nRestart the Prometheus service:systemctl restart prometheus.service\r\n\n\nIf high availability is enabled in the storage cluster, repeat these steps for the other two management nodes.\nSee also\n\nUsing built-in Prometheus for monitoring\n\nUsing external Prometheus for monitoring\n\nPrometheus metrics",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/configuring-retention-policy-for-prometheus-metrics.html"
    },
    {
        "title": "Logging in to the self-service panel",
        "content": "Logging in to the self-service panel\nTo log in to the self-service panel\n\n\r\n                    Visit the panel\u00e2\u0080\u0099s IP address on port 8800.\r\n                \n\nEnter your domain name (case sensitive) as well as user name and password. Alternatively, if you are given the link to the self-service panel for a specific domain, you will only need to provide the user name and password.",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_self_service_guide/logging-in-to-the-self-service-panel.html"
    },
    {
        "title": "Updating IKE policies",
        "content": "Updating IKE policiesPUT /v2.0/vpn/ikepolicies/{ikepolicy_id}\nUpdate policy settings in an IKE policy.\nSource: https://docs.openstack.org/api-ref/network/v2/index.html?expanded=update-ike-policy-detail#update-ike-policy\nRequest\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicy_id\n\npath\nstring\nThe ID of the IKE policy.\n\nike_version (Optional)\n\nbody\nstring\n\nThe IKE version. A valid value is v1 or v2. Default is v1.\n\nExample# curl -ks -X PUT -H 'Content-Type: application/json' -H 'X-Auth-Token: gAAAAA<...>' -d '\\\r\n{\r\n    \"ikepolicy\": {\r\n        \"encryption_algorithm\": \"aes-256\"\r\n    }\r\n}' https://<node_IP_addr>:9696/v2.0/vpn/ikepolicies/94edd562-8b10-4e96-98d7-7b8b99d3ca5d\nResponse\nParameters\n\nName\nIn\nType\nDescription\n\nikepolicies\n\nbody\narray\nA list of ikepolicy objects.\n\nikepolicy\n\nbody\nobject\nAn ikepolicy object.\n\nname (Optional)\r\n                    \nbody\nstring\n\nA human-readable name of the resource. Default is an empty string.\n\ndescription (Optional)\nbody\nstring\nA human-readable description for the resource. Default is an empty string.\n\ntenant_id\n\nbody\nstring\nThe ID of the project.\n\nproject_id\n\nbody\nstring\nThe ID of the project.\n\nauth_algorithm (Optional)\nbody\nstring\nThe authentication hash algorithm. Valid values are sha1, sha256, sha384, sha512, aes-xcbc, and aes-cmac. The default is sha1.\n\nencryption_algorithm (Optional)\nbody\nstring\nThe encryption algorithm. Valid values are 3des, aes-128, aes-192, and aes-256. Additional values for AES CCM and GCM modes are defined (for example, aes-256-ccm-16, aes-256-gcm-16) for all combinations of key length 128, 192, 256 bits and ICV length 8, 12, 16 octets. Default is aes-128.\n\npfs (Optional)\nbody\nstring\nPerfect forward secrecy (PFS). A valid value is Group2, Group5, Group14 to Group31. Default is Group5.\n\nvalue (Optional)\nbody\ninteger\n\nThe lifetime value, as a positive integer. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nphase1_negotiation_mode (Optional)\nbody\nstring\nThe IKE mode. A valid value is main, which is the default.\n\nunits (Optional)\nbody\nstring\nThe units for the lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nlifetime (Optional)\nbody\nobject\n\nThe lifetime of the security association. The lifetime consists of a unit and integer value. You can omit either the unit or value portion of the lifetime. Default unit is seconds and default value is 3600.\n\nid\n\nbody\nstring\nThe ID of the IKE policy.\n\nike_version (Optional)\n\nbody\nstring\n\nThe IKE version. A valid value is v1 or v2. Default is v1.\n\nStatus codes\nSuccess\n\nCode\nReason\n\n200 - OK\n\nRequest was successful.\n\nError\n\nCode\nReason\n\n400 - Bad Request\n\nSome content in the request was invalid.\n\n401 - Unauthorized\n\nUser must authenticate before making a request.\n\n404 - Not Found\n\nThe requested resource could not be found.\n\nExample{\r\n  \"ikepolicy\": {\r\n    \"id\": \"94edd562-8b10-4e96-98d7-7b8b99d3ca5d\",\r\n    \"tenant_id\": \"284a2547ea8445d1be0e68ef2d76672c\",\r\n    \"name\": \"ikepolicy1\",\r\n    \"description\": \"\",\r\n    \"auth_algorithm\": \"sha1\",\r\n    \"encryption_algorithm\": \"aes-256\",\r\n    \"phase1_negotiation_mode\": \"main\",\r\n    \"lifetime\": {\r\n      \"units\": \"seconds\",\r\n      \"value\": 7200\r\n    },\r\n    \"ike_version\": \"v1\",\r\n    \"pfs\": \"group5\",\r\n    \"project_id\": \"284a2547ea8445d1be0e68ef2d76672c\"\r\n  }\r\n}",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_compute_api_reference/updating-ike-policies.html"
    },
    {
        "title": "5. Troubleshooting\u00c2\u00b6",
        "content": "5. Troubleshooting | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n5. Troubleshooting\u00c2\u00b6\nHystax Acura automatically checks cloud access and the necessary permissions for assuring successful operation. It provides detailed error messages that describe their potential causes.\nIn case of an error, please check the correctness of the data entered and availability of the necessary permissions.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/troubleshooting.html"
    },
    {
        "title": "3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\u00c2\u00b6",
        "content": "3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure | Acronis Cyber Cloud Migration from VMware\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nAcronis Cyber Cloud Migration from VMware\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\n1. About This Guide\n2. Deploying the Acronis Agent for VMware from an OVF Template\n2.1. Creating an Appliance with the Acronis Agent for VMware\n2.2. Configuring the Acronis Agent for VMware\n\n3. Deploying the Agent for Virtuozzo Hybrid Infrastructure from a QCOW2 Template\n3.1. Configuring Networks in Virtuozzo Hybrid Infrastructure\n3.2. Configuring User Accounts in Virtuozzo Hybrid Infrastructure\n3.3. Creating an Appliance with the Agent for Virtuozzo Hybrid Infrastructure\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\n\n4. Migrating Virtual Machines\n4.1. Backing Up Virtual Machines\n4.2. Recovering Virtual Machines\n\nAcronis Cyber Cloud Migration from VMwarePDF, 1399 KB\n\nPrev\nNext\n\n3.4. Configuring the Agent for Virtuozzo Hybrid Infrastructure\u00c2\u00b6\nAfter creating the agent appliance, you need to configure it so that it can reach both the Virtuozzo Hybrid Infrastructure cluster that it will protect and the Cyber Protection cloud service.\nTo configure the virtual appliance:\n\nLog in to your Virtuozzo Hybrid Infrastructure account.\nOn the Compute > Virtual machines > Virtual Machines tab, select the virtual machine that you created. Then, click Console.\n\nThe console to the appliance virtual machine will open.\n\nConfigure the network interfaces of the appliance. There may be one or more interfaces to configure, it depends on the number of virtual networks that the appliance uses. Ensure that automatically assigned DHCP addresses (if any) are valid within the networks that your virtual machine uses, or assign them manually.\n\nSpecify the Virtuozzo cluster address and credentials:\n\nThe DNS name or IP address of the Virtuozzo Hybrid Infrastructure cluster. This is the address of the cluster\u00e2\u0080\u0099s management node. The default port 5000 will be automatically set. If you use a different port, specify it manually.\nIn the User domain name field, specify your domain in Virtuozzo Hybrid Infrastructure. For example, Default. The domain name is case-sensitive.\nIn the User name and Password fields, enter the credentials for the Virtuozzo Hybrid Infrastructure user account with the Administrator role in the specified domain. For more information about users, roles, and domains, refer to the Virtuozzo Hybrid Infrastructure documentation.\n\nSpecify the Cyber Protection management server address and credentials for accessing it.\n\nVersion 7.5 \u00e2\u0080\u0094 Jan 27, 2023\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_acronis_cyber_cloud_migration_from_vmware/deploying-agent-for-virtuozzo-hybrid-infrastructure-from-qcow2-template/configuring-agent-for-virtuozzo-hybrid-infrastructure.html"
    },
    {
        "title": "Limiting performance",
        "content": "Limiting performance\nIn some cases, it is preferable to limit the performance of the system or one of its components, usually to slow down the usage growth or avoid interference between different services.\nBackup storage throttling\nThe backup storage service automatically starts to throttle incoming traffic when the storage usage exceeds a certain threshold, to slow down the growth rate and avoid filling the system. To tune the throttling parameters, navigate to the Throttling configuration tab on the backup storage Settings screen in the admin panel.\nRe-encoding throttling\nThe re-encoding process is usually limited, to avoid an impact on other services. We do not recommend changing the default settings, unless re-encoding is the only service running in the cluster.\nThe default number of re-encoding processes is 1. To check the number of concurrent re-encoding processes, run:# cat /mnt/vstorage/.vstorage.info/ls_reencoding_chunks\nTo change the number of concurrent re-encoding processes, run:# echo <NUMBER> > /mnt/vstorage/.vstorage.info/ls_reencoding_chunks\nFor example:# echo 4 > /mnt/vstorage/.vstorage.info/ls_reencoding_chunks\nSee also\n\nStorage cluster best practices\n\nConfiguration examples\n\nTroubleshooting performance issues",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/limiting-performance.html"
    },
    {
        "title": "Rescuing virtual machines",
        "content": "Rescuing virtual machines\nIf a VM experiences boot problems, you can send it to the rescue mode to access its boot volume. When a VM in the \u00e2\u0080\u009cActive\u00e2\u0080\u009d state is sent to the rescue mode, it is shut down softly first. Once the VM is in the rescue mode, you can connect to it via SSH or via the console. Its previous boot disk is now attached as a secondary one. You can mount the disk and repair it.\nLimitations\n\nThe rescue mode can use ISO images for booting both Linux and Wndows virtual machines and QCOW2 images (templates) for booting Linux VMs. For instructions on making templates, refer to Preparing templates.\nYou can send a VM to the rescue mode only if its current status is \u00e2\u0080\u009cActive\u00e2\u0080\u009d or \u00e2\u0080\u009cShut down\u00e2\u0080\u009d.\nThere are only three actions available for the VM in the rescue mode: Console, Exit rescue mode, and Delete.\nIf a rescue image has cloud-init installed, then the VM booted from it can be accessed with the same SSH key that was used for its creation.\n\nPrerequisites\n\nVirtual machines are created, as described in Creating virtual machines.\n\nTo put a virtual machine to the rescue mode\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM on the list.\nOn the VM right pane, click the ellipsis button on the toolbar. Then, click Enter rescue mode.\n\nIn the Enter rescue mode window, select an image to rescue the VM with. By default, the initial image used for creating the VM is selected. Click Enter.\n\nThe machine status changes to \u00e2\u0080\u009cRescue\u00e2\u0080\u009d. \n\nCommand-line interface\nUse the following command:vinfra service compute server rescue [--image <image>] <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n--image <image>\n\nBoot from image ID or name\n\nFor example, to send the myvm virtual machine to the rescue mode with the cirros image, run:# vinfra service compute server rescue myvm --image cirros\n\nTo return a virtual machine to normal operation\n\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM on the list.\nOn the VM right pane, click Exit rescue mode.\nIn the Exit rescue mode window, click Exit. The VM will be automatically rebooted.\n\nThe VM status changes to \u00e2\u0080\u009cActive\u00e2\u0080\u009d and it boots from the original root disk.\n\nIf the VM status changes to \u00e2\u0080\u009cError\u00e2\u0080\u009d when exiting the rescue mode, you can reset its status with the Reset state action. The VM should then return to the \u00e2\u0080\u009cRescue\u00e2\u0080\u009d status again.\n\nCommand-line interface\nUse the following command:vinfra service compute server unrescue <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to stop the rescue mode for the myvm virtual machine, run:# vinfra service compute server unrescue myvm\n\nTo exit the rescue mode for a Windows VM\nThere might be an issue of exiting the rescue mode for a Windows VM. If in the rescue mode you set the original system disk online, its ID becomes the same as that of the rescue disk. Then, when you try to exit the rescue mode, the boot loader cannot find the proper boot disk. To resolve the ID conflict, follow the steps:\n\nWith the VM in the rescue mode, open the Disk Management window and note the numbers of the original system disk (offline) and the rescue disk (online). Set the original system disk to Online.\n\nTo edit the boot configuration, enter the following command in the Command Prompt window:> bcdedit /store <the original system disk name>:\\boot\\bcd\r\n\n\nReview the output and check that the rescue disk is the target for objects in the output (partition=<the rescue disk name>).\nIf the objects do not point to drive C, fix it with the following commands:> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {default} osdevice partition=<the rescue disk name>:\r\n> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {default} device partition=<the rescue disk name>:\r\n> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {bootmgr} device partition=<the rescue disk name>:\r\n> bcdedit /store <the original system disk name>:\\boot\\bcd \\\r\n/set {memdiag} device partition=<the rescue disk name>:\r\n\n\nTo view the available disks, enter the following commands in the command line:> DISKPART\r\n> LIST DISK\r\n\nMatch the disk number and name to those displayed in the Disk Management window.\n\nTo get the ID of the rescue disk, run the following commands:> SELECT DISK <the rescue disk number>\r\n> UNIQUEID DISK\r\n\nRecord the disk ID, you will need it later.\n\nChange this ID by using the following command:> UNIQUEID DISK id=<any hex value of 8 characters>\r\n\nMake sure that the value has changed with the UNIQUEID DISK command.\n\nAssign the ID that you recorded previusly to the original system disk:> SELECT DISK <the original system disk number>\r\n> UNIQUEID DISK id=<the recorded disk ID>\r\n\nMake sure that the value has changed with the UNIQUEID DISK command.\n\nYou should now be able to exit the rescue mode.\n\nSee also\n\nConnecting to virtual machines\n\nManaging virtual machine power state\n\nAttaching ISO images to virtual machines\n\nTroubleshooting virtual machines",
        "paragraphs": [],
        "cli_examples": [
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server rescue [--image <image>] <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n--image <image>\n\nBoot from image ID or name\n\nFor example, to send the myvm virtual machine to the rescue mode with the cirros image, run:# vinfra service compute server rescue myvm --image cirros\n",
                "title": "To put a virtual machine to the rescue mode"
            },
            {
                "example": "\nCommand-line interface\nUse the following command:vinfra service compute server unrescue <server>\r\n\n\n<server>\n\nVirtual machine ID or name\n\nFor example, to stop the rescue mode for the myvm virtual machine, run:# vinfra service compute server unrescue myvm\n",
                "title": "To return a virtual machine to normal operation"
            }
        ],
        "panel_examples": [
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM on the list.\nOn the VM right pane, click the ellipsis button on the toolbar. Then, click Enter rescue mode.\n\nIn the Enter rescue mode window, select an image to rescue the VM with. By default, the initial image used for creating the VM is selected. Click Enter.\n\n\n\n\n\n\nThe machine status changes to \u00e2\u0080\u009cRescue\u00e2\u0080\u009d. \n",
                "title": "To put a virtual machine to the rescue mode"
            },
            {
                "example": "\nAdmin panel\n\nOn the Compute > Virtual machines > Virtual machines tab, click the required VM on the list.\nOn the VM right pane, click Exit rescue mode.\nIn the Exit rescue mode window, click Exit. The VM will be automatically rebooted.\n\nThe VM status changes to \u00e2\u0080\u009cActive\u00e2\u0080\u009d and it boots from the original root disk.\n\nIf the VM status changes to \u00e2\u0080\u009cError\u00e2\u0080\u009d when exiting the rescue mode, you can reset its status with the Reset state action. The VM should then return to the \u00e2\u0080\u009cRescue\u00e2\u0080\u009d status again.\n\n",
                "title": "To return a virtual machine to normal operation"
            }
        ],
        "url": "https://docs.virtuozzo.com/virtuozzo_hybrid_infrastructure_6_2_admins_guide/rescuing-virtual-machines.html"
    },
    {
        "title": "1. Hystax Acura Overview\u00c2\u00b6",
        "content": "1. Hystax Acura Overview | Hystax Acura Integration for Virtuozzo Hybrid Infrastructure\n\nDocumentation\n\nBack to guides list\n\nPrev\nNext\n\nBack to guides list\nHystax Acura Integration for Virtuozzo Hybrid Infrastructure\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\n1. Hystax Acura Overview\n2. Installation Requirements\n3. Installation Steps\n3.1. Resource Planning and Configuration for Virtuozzo Hybrid Infrastructure\n3.2. Deploying Hystax Acura Solution on Virtuozzo Hybrid Infrastructure\n3.3. Performing Test Migration\n\n4. Providing Access to Hystax Acura Portal\n5. Troubleshooting\n6. Limitations\n\nHystax Acura Integration for Virtuozzo Hybrid InfrastructurePDF, 5483 KB\n\nPrev\nNext\n\n1. Hystax Acura Overview\u00c2\u00b6\nHystax is a cloud migration and Disaster Recovery company focusing on consistent replication of IT workloads and providing real-time migration and Best-In-Class Disaster Recovery.\nTo deploy the Hystax Acura solution, a customer needs to request Hystax (migrations@virtuozzo.com) for the golden image of the solution and follow the steps described in this document.\n\nVersion 7.5 \u00e2\u0080\u0094 Jul 22, 2022\n\nEdit\nPrint\nShare\n\nPrev\nNext\n\n \n\nGPG Keys\nLegal",
        "paragraphs": [],
        "cli_examples": [],
        "panel_examples": [],
        "url": "https://docs.virtuozzo.com/virtuozzo_integrations_hystax_acura/overview.html"
    }
]